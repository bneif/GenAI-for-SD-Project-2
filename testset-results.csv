Input Function with Masked If Condition,Exact Match (true/false),Expected If Condition,Predicted If Condition,CodeBLEU Score (0-100),BLEU-4 Score (0-100)
"def read(self, count=True, timeout=None, ignore_non_errors=True, ignore_timeouts=True): <TAB> try: <TAB> <TAB> return self._read(count, timeout) <TAB> except usb.USBError as e: <TAB> <TAB> if DEBUG_COMM: <TAB> <TAB> <TAB> log.info( <TAB> <TAB> <TAB> <TAB> ""read: e.errno=%s e.strerror=%s e.message=%s repr=%s"" <TAB> <TAB> <TAB> <TAB> % (e.errno, e.strerror, e.message, repr(e)) <TAB> <TAB> <TAB> ) <TAB> <TAB> if ignore_timeouts and is_timeout(e): <TAB> <TAB> <TAB> return [] <TAB> <TAB> if ignore_non_errors and is_noerr(e): <TAB> <TAB> <TAB> return [] <TAB> <TAB> raise",false,if ignore_timeouts and is_timeout ( e ) :,if ignore_non_errors and is_noerr ( e ) :,0.44,0.0
"def _cache_mem(curr_out, prev_mem, mem_len, reuse_len=None): <TAB> """"""cache hidden states into memory."""""" <TAB> if mem_len is None or mem_len == 0: <TAB> <TAB> return None <TAB> else: <TAB> <TAB> if reuse_len is not None and reuse_len > 0: <TAB> <TAB> <TAB> curr_out = curr_out[:reuse_len] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> new_mem = curr_out[-mem_len:] <TAB> <TAB> else: <TAB> <TAB> <TAB> new_mem = tf.concat([prev_mem, curr_out], 0)[-mem_len:] <TAB> new_mem.stop_gradient = True <TAB> return new_mem",true,if prev_mem is None :,if prev_mem is None :,0.75,0.0
def filtered(gen): <TAB> for example in gen: <TAB> <TAB> example_len = length_fn(example) <TAB> <TAB> # Checking max length boundary. <TAB> <TAB> if max_length is not None: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Checking min length boundary. <TAB> <TAB> if min_length is not None: <TAB> <TAB> <TAB> if example_len < min_length: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Within bounds. <TAB> <TAB> yield example,true,if example_len > max_length :,if example_len > max_length :,0.75,0.0
"def search(self, query): <TAB> # ""Search.ashx?query="" + query + filterVal <TAB> if not query: <TAB> <TAB> logger.debug(""Empty search query"") <TAB> <TAB> return [] <TAB> logger.debug('Searching TuneIn for ""%s""' % query) <TAB> args = ""&query="" + query <TAB> search_results = self._tunein(""Search.ashx"", args) <TAB> results = [] <TAB> for item in self._flatten(search_results): <TAB> <TAB> if item.get(""type"", """") == ""audio"": <TAB> <TAB> <TAB> # Only return stations <TAB> <TAB> <TAB> self._stations[item[""guide_id""]] = item <TAB> <TAB> <TAB> results.append(item) <TAB> return results",true,"if item . get ( ""type"" , """" ) == ""audio"" :","if item . get ( ""type"" , """" ) == ""audio"" :",0.75,0.0
"def _check_script(self, script, directive): <TAB> for var in compile_script(script): <TAB> <TAB> if var.must_contain(""/""): <TAB> <TAB> <TAB> # Skip variable checks <TAB> <TAB> <TAB> return False <TAB> <TAB> if var.can_contain("".""): <TAB> <TAB> <TAB> # Yay! Our variable can contain any symbols! <TAB> <TAB> <TAB> reason = ( <TAB> <TAB> <TAB> <TAB> 'At least variable ""${var}"" can contain untrusted user input'.format( <TAB> <TAB> <TAB> <TAB> <TAB> var=var.name <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self.add_issue(directive=[directive] + var.providers, reason=reason) <TAB> <TAB> <TAB> return True <TAB> return False",false,"if var . must_contain ( ""/"" ) :","if var . can_contain ( ""."" ) :",0.34,0.0
"def getAllDataLinkIDs(): <TAB> linkDataIDs = set() <TAB> dataType = _forestData.dataTypeBySocket <TAB> for socketID, linkedIDs in _forestData.linkedSockets.items(): <TAB> <TAB> for linkedID in linkedIDs: <TAB> <TAB> <TAB> if socketID[1]:  # check which one is origin/target <TAB> <TAB> <TAB> <TAB> linkDataIDs.add( <TAB> <TAB> <TAB> <TAB> <TAB> (socketID, linkedID, dataType[socketID], dataType[linkedID]) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> linkDataIDs.add( <TAB> <TAB> <TAB> <TAB> <TAB> (linkedID, socketID, dataType[linkedID], dataType[socketID]) <TAB> <TAB> <TAB> <TAB> ) <TAB> return linkDataIDs",true,if socketID [ 1 ] :,if socketID [ 1 ] :,0.75,0.0
"def _stderr_supports_color(): <TAB> try: <TAB> <TAB> if hasattr(sys.stderr, ""isatty"") and sys.stderr.isatty(): <TAB> <TAB> <TAB> if curses: <TAB> <TAB> <TAB> <TAB> curses.setupterm() <TAB> <TAB> <TAB> <TAB> if curses.tigetnum(""colors"") > 0: <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> elif colorama: <TAB> <TAB> <TAB> <TAB> if sys.stderr is getattr( <TAB> <TAB> <TAB> <TAB> <TAB> colorama.initialise, ""wrapped_stderr"", object() <TAB> <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> except Exception: <TAB> <TAB> # Very broad exception handling because it's always better to <TAB> <TAB> # fall back to non-colored logs than to break at startup. <TAB> <TAB> pass <TAB> return False",true,"if curses . tigetnum ( ""colors"" ) > 0 :","if curses . tigetnum ( ""colors"" ) > 0 :",0.75,0.0
"def offsets(self): <TAB> offsets = {} <TAB> offset_so_far = 0 <TAB> for name, ty in self.fields.items(): <TAB> <TAB> if isinstance(ty, SimTypeBottom): <TAB> <TAB> <TAB> l.warning( <TAB> <TAB> <TAB> <TAB> ""Found a bottom field in struct %s. Ignore and increment the offset using the default "" <TAB> <TAB> <TAB> <TAB> ""element size."", <TAB> <TAB> <TAB> <TAB> self.name, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if not self._pack: <TAB> <TAB> <TAB> align = ty.alignment <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> offset_so_far += align - offset_so_far % align <TAB> <TAB> offsets[name] = offset_so_far <TAB> <TAB> offset_so_far += ty.size // self._arch.byte_width <TAB> return offsets",false,if offset_so_far % align != 0 :,if align :,0.02,0.0
"def Restore(self): <TAB> picker, obj = self._window, self._pObject <TAB> value = obj.RestoreValue(PERSIST_FILEDIRPICKER_PATH) <TAB> if value is not None: <TAB> <TAB> if issubclass(picker.__class__, wx.FileDialog): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> value = value[-1] <TAB> <TAB> picker.SetPath(value) <TAB> <TAB> return True <TAB> return False",false,if type ( value ) == list :,if len ( value ) > 1 :,0.18,0.0
"def dt_s_tup_to_string(dt_s_tup): <TAB> dt_string = dt_s_tup[0]  # string for identifying the file to parse. <TAB> if dt_s_tup[1] > 0:  # if there are seasons in the model <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> dt_string = dt_string[:2] + ""s"" + dt_string[2:] <TAB> <TAB> else: <TAB> <TAB> <TAB> dt_string = ""s"" + dt_string <TAB> return dt_string",false,"if ""co"" in dt_string or ""ci"" in dt_string or ""nc"" in dt_string :",if len ( dt_string ) > 2 :,0.01,0.0
"def writer(stream, items): <TAB> sep = """" <TAB> for item in items: <TAB> <TAB> stream.write(sep) <TAB> <TAB> sep = "" "" <TAB> <TAB> if not isinstance(item, str): <TAB> <TAB> <TAB> item = str(item) <TAB> <TAB> if not PY3K: <TAB> <TAB> <TAB> if not isinstance(item, unicode): <TAB> <TAB> <TAB> <TAB> item = str(item) <TAB> <TAB> stream.write(item) <TAB> stream.write(""\n"")",false,"if not isinstance ( item , str ) :","if not isinstance ( item , unicode ) :",0.58,0.0
"def _get_result_keys(self, config): <TAB> result_key = config.get(""result_key"") <TAB> if result_key is not None: <TAB> <TAB> if not isinstance(result_key, list): <TAB> <TAB> <TAB> result_key = [result_key] <TAB> <TAB> result_key = [jmespath.compile(rk) for rk in result_key] <TAB> <TAB> return result_key",true,"if not isinstance ( result_key , list ) :","if not isinstance ( result_key , list ) :",0.75,0.0
"def _download_build_artifacts(self, build: Dict[str, Any]) -> None: <TAB> arch = build[""arch_tag""] <TAB> snap_build = self._lp_load_url(build[""self_link""]) <TAB> urls = snap_build.getFileUrls() <TAB> if not urls: <TAB> <TAB> logger.error(f""Snap file not available for arch {arch!r}."") <TAB> <TAB> return <TAB> for url in urls: <TAB> <TAB> file_name = _get_url_basename(url) <TAB> <TAB> self._download_file(url=url, dst=file_name) <TAB> <TAB> if file_name.endswith("".snap""): <TAB> <TAB> <TAB> logger.info(f""Snapped {file_name}"") <TAB> <TAB> else: <TAB> <TAB> <TAB> logger.info(f""Fetched {file_name}"")",true,"if file_name . endswith ( "".snap"" ) :","if file_name . endswith ( "".snap"" ) :",0.75,0.0
"def _add_custom_statement(self, custom_statements): <TAB> if custom_statements is None: <TAB> <TAB> return <TAB> self.resource_policy[""Version""] = ""2012-10-17"" <TAB> if self.resource_policy.get(""Statement"") is None: <TAB> <TAB> self.resource_policy[""Statement""] = custom_statements <TAB> else: <TAB> <TAB> if not isinstance(custom_statements, list): <TAB> <TAB> <TAB> custom_statements = [custom_statements] <TAB> <TAB> statement = self.resource_policy[""Statement""] <TAB> <TAB> if not isinstance(statement, list): <TAB> <TAB> <TAB> statement = [statement] <TAB> <TAB> for s in custom_statements: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> statement.append(s) <TAB> <TAB> self.resource_policy[""Statement""] = statement",true,if s not in statement :,if s not in statement :,0.75,0.0
"def display_failures_for_single_test(result: TestResult) -> None: <TAB> """"""Display a failure for a single method / endpoint."""""" <TAB> display_subsection(result) <TAB> checks = _get_unique_failures(result.checks) <TAB> for idx, check in enumerate(checks, 1): <TAB> <TAB> message: Optional[str] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> message = f""{idx}. {check.message}"" <TAB> <TAB> else: <TAB> <TAB> <TAB> message = None <TAB> <TAB> example = cast(Case, check.example)  # filtered in `_get_unique_failures` <TAB> <TAB> display_example(example, check.name, message, result.seed) <TAB> <TAB> # Display every time except the last check <TAB> <TAB> if idx != len(checks): <TAB> <TAB> <TAB> click.echo(""\n"")",true,if check . message :,if check . message :,0.75,0.0
"def build(opt): <TAB> dpath = os.path.join(opt[""datapath""], ""qangaroo"") <TAB> version = ""v1.1"" <TAB> if not build_data.built(dpath, version_string=version): <TAB> <TAB> print(""[building data: "" + dpath + ""]"") <TAB> <TAB> if build_data.built(dpath): <TAB> <TAB> <TAB> # An older version exists, so remove these outdated files. <TAB> <TAB> <TAB> build_data.remove_dir(dpath) <TAB> <TAB> build_data.make_dir(dpath) <TAB> <TAB> # Download the data. <TAB> <TAB> for downloadable_file in RESOURCES: <TAB> <TAB> <TAB> downloadable_file.download_file(dpath) <TAB> <TAB> # Mark the data as built. <TAB> <TAB> build_data.mark_done(dpath, version_string=version)",true,if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,0.75,0.0
"def call(self, step_input, states): <TAB> new_states = [] <TAB> for i in range(self.num_layers): <TAB> <TAB> out, new_state = self.lstm_cells[i](step_input, states[i]) <TAB> <TAB> step_input = ( <TAB> <TAB> <TAB> layers.dropout( <TAB> <TAB> <TAB> <TAB> out, self.dropout_prob, dropout_implementation=""upscale_in_train"" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> else out <TAB> <TAB> ) <TAB> <TAB> new_states.append(new_state) <TAB> return step_input, new_states",false,if self . dropout_prob > 0.0,if i == self . num_layers - 1,0.1,0.0
"def jupyter_progress_bar(min=0, max=1.0): <TAB> """"""Returns an ipywidget progress bar or None if we can't import it"""""" <TAB> widgets = wandb.util.get_module(""ipywidgets"") <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # TODO: this currently works in iPython but it's deprecated since 4.0 <TAB> <TAB> <TAB> from IPython.html import widgets  # type: ignore <TAB> <TAB> assert hasattr(widgets, ""VBox"") <TAB> <TAB> assert hasattr(widgets, ""Label"") <TAB> <TAB> assert hasattr(widgets, ""FloatProgress"") <TAB> <TAB> return ProgressWidget(widgets, min=min, max=max) <TAB> except (ImportError, AssertionError): <TAB> <TAB> return None",false,if widgets is None :,if widgets :,0.07,0.0
"def _record_event(self, path, fsevent_handle, filename, events, error): <TAB> with self.lock: <TAB> <TAB> self.events[path].append(events) <TAB> <TAB> if events | pyuv.fs.UV_RENAME: <TAB> <TAB> <TAB> if not os.path.exists(path): <TAB> <TAB> <TAB> <TAB> self.watches.pop(path).close()",false,if events | pyuv . fs . UV_RENAME :,if not os . path . exists ( path ) :,0.02,0.0
"def _get_v1_id_from_tags(self, tags_obj, tag): <TAB> """"""Get image id from array of tags"""""" <TAB> if isinstance(tags_obj, dict): <TAB> <TAB> try: <TAB> <TAB> <TAB> return tags_obj[tag] <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> pass <TAB> elif isinstance(tags_obj, []): <TAB> <TAB> try: <TAB> <TAB> <TAB> for tag_dict in tags_obj: <TAB> <TAB> <TAB> <TAB> if tag_dict[""name""] == tag: <TAB> <TAB> <TAB> <TAB> <TAB> return tag_dict[""layer""] <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> pass <TAB> return """"",true,"if tag_dict [ ""name"" ] == tag :","if tag_dict [ ""name"" ] == tag :",0.75,0.0
"def query_lister(domain, query="""", max_items=None, attr_names=None): <TAB> more_results = True <TAB> num_results = 0 <TAB> next_token = None <TAB> while more_results: <TAB> <TAB> rs = domain.connection.query_with_attributes( <TAB> <TAB> <TAB> domain, query, attr_names, next_token=next_token <TAB> <TAB> ) <TAB> <TAB> for item in rs: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if num_results == max_items: <TAB> <TAB> <TAB> <TAB> <TAB> raise StopIteration <TAB> <TAB> <TAB> yield item <TAB> <TAB> <TAB> num_results += 1 <TAB> <TAB> next_token = rs.next_token <TAB> <TAB> more_results = next_token != None",true,if max_items :,if max_items :,0.53,0.0
"def filter(this, args): <TAB> array = to_object(this, args.space) <TAB> callbackfn = get_arg(args, 0) <TAB> arr_len = js_arr_length(array) <TAB> if not is_callable(callbackfn): <TAB> <TAB> raise MakeError(""TypeError"", ""callbackfn must be a function"") <TAB> _this = get_arg(args, 1) <TAB> k = 0 <TAB> res = [] <TAB> while k < arr_len: <TAB> <TAB> if array.has_property(unicode(k)): <TAB> <TAB> <TAB> kValue = array.get(unicode(k)) <TAB> <TAB> <TAB> if to_boolean(callbackfn.call(_this, (kValue, float(k), array))): <TAB> <TAB> <TAB> <TAB> res.append(kValue) <TAB> <TAB> k += 1 <TAB> return args.space.ConstructArray(res)",false,if array . has_property ( unicode ( k ) ) :,"if to_boolean ( callbackfn . call ( _this , ( kValue , float ( k ) , array ) ) ) :",0.06,0.0
"def every_one_is(self, dst): <TAB> msg = ""all members of %r should be %r, but the %dth is %r"" <TAB> for index, item in enumerate(self._src): <TAB> <TAB> if self._range: <TAB> <TAB> <TAB> if index < self._range[0] or index > self._range[1]: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> error = msg % (self._src, dst, index, item) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise AssertionError(error) <TAB> return True",false,if item != dst :,if error :,0.04,0.0
"def schedule_logger(job_id=None, delete=False): <TAB> if not job_id: <TAB> <TAB> return getLogger(""fate_flow_schedule"") <TAB> else: <TAB> <TAB> if delete: <TAB> <TAB> <TAB> with LoggerFactory.lock: <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> for key in LoggerFactory.schedule_logger_dict.keys(): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> del LoggerFactory.schedule_logger_dict[key] <TAB> <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> return True <TAB> <TAB> key = job_id + ""schedule"" <TAB> <TAB> if key in LoggerFactory.schedule_logger_dict: <TAB> <TAB> <TAB> return LoggerFactory.schedule_logger_dict[key] <TAB> <TAB> return LoggerFactory.get_schedule_logger(job_id)",false,if job_id in key :,if key in LoggerFactory . schedule_logger_dict :,0.16,0.0
"def Tokenize(s): <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE.findall(s): <TAB> <TAB> # The type checker can't know the true type of item! <TAB> <TAB> item = cast(TupleStr4, item) <TAB> <TAB> if item[0]: <TAB> <TAB> <TAB> typ = ""number"" <TAB> <TAB> <TAB> val = item[0] <TAB> <TAB> elif item[1]: <TAB> <TAB> <TAB> typ = ""name"" <TAB> <TAB> <TAB> val = item[1] <TAB> <TAB> elif item[2]: <TAB> <TAB> <TAB> typ = item[2] <TAB> <TAB> <TAB> val = item[2] <TAB> <TAB> elif item[3]: <TAB> <TAB> <TAB> typ = item[3] <TAB> <TAB> <TAB> val = item[3] <TAB> <TAB> yield Token(typ, val)",false,elif item [ 2 ] :,elif item [ 3 ] :,0.38,0.0
"def _read_data_from_all_categories(self, directory, config, categories): <TAB> lines = [] <TAB> for category in categories: <TAB> <TAB> data_file = os.path.join(directory, _DATASET_VERSION, category, config) <TAB> <TAB> if os.path.exists(data_file): <TAB> <TAB> <TAB> with open(data_file) as f: <TAB> <TAB> <TAB> <TAB> ls = f.read().split(""\n"") <TAB> <TAB> <TAB> <TAB> for l in ls[::-1]: <TAB> <TAB> <TAB> <TAB> <TAB> if not l: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ls.remove(l) <TAB> <TAB> <TAB> <TAB> lines.extend(ls) <TAB> return lines",true,if os . path . exists ( data_file ) :,if os . path . exists ( data_file ) :,0.75,0.0
"def find_handlers(self, forms): <TAB> handlers = {} <TAB> for form in forms.itervalues(): <TAB> <TAB> for action_name, _action_label in form.actions: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> handlers[action_name] = form <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise HandlerError( <TAB> <TAB> <TAB> <TAB> <TAB> ""More than one form defines the handler %s"" % action_name <TAB> <TAB> <TAB> <TAB> ) <TAB> return handlers",false,if action_name not in handlers :,if action_name in self . handlers :,0.21,0.0
"def get_story_task_completed_body(payload: Dict[str, Any]) -> Optional[str]: <TAB> action = get_action_with_primary_id(payload) <TAB> kwargs = { <TAB> <TAB> ""task_description"": action[""description""], <TAB> } <TAB> story_id = action[""story_id""] <TAB> for ref in payload[""references""]: <TAB> <TAB> if ref[""id""] == story_id: <TAB> <TAB> <TAB> kwargs[""name_template""] = STORY_NAME_TEMPLATE.format( <TAB> <TAB> <TAB> <TAB> name=ref[""name""], <TAB> <TAB> <TAB> <TAB> app_url=ref[""app_url""], <TAB> <TAB> <TAB> ) <TAB> if action[""changes""][""complete""][""new""]: <TAB> <TAB> return STORY_TASK_COMPLETED_TEMPLATE.format(**kwargs) <TAB> else: <TAB> <TAB> return None",true,"if ref [ ""id"" ] == story_id :","if ref [ ""id"" ] == story_id :",0.75,0.0
"def _create_valid_graph(graph): <TAB> nodes = graph.nodes() <TAB> for i in range(len(nodes)): <TAB> <TAB> for j in range(len(nodes)): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> edge = (nodes[i], nodes[j]) <TAB> <TAB> <TAB> if graph.has_edge(edge): <TAB> <TAB> <TAB> <TAB> graph.del_edge(edge) <TAB> <TAB> <TAB> graph.add_edge(edge, 1)",true,if i == j :,if i == j :,0.75,0.0
"def _post_order(op): <TAB> if isinstance(op, tvm.tir.Allocate): <TAB> <TAB> lift_stmt[-1].append(op) <TAB> <TAB> return op.body <TAB> if isinstance(op, tvm.tir.AttrStmt): <TAB> <TAB> if op.attr_key == ""storage_scope"": <TAB> <TAB> <TAB> lift_stmt[-1].append(op) <TAB> <TAB> <TAB> return op.body <TAB> <TAB> if op.attr_key == ""virtual_thread"": <TAB> <TAB> <TAB> return _merge_block(lift_stmt.pop() + [op], op.body) <TAB> <TAB> return op <TAB> if isinstance(op, tvm.tir.For): <TAB> <TAB> return _merge_block(lift_stmt.pop() + [op], op.body) <TAB> raise RuntimeError(""not reached"")",true,"if op . attr_key == ""storage_scope"" :","if op . attr_key == ""storage_scope"" :",0.75,0.0
"def format_lazy_import(names): <TAB> """"""Formats lazy import lines"""""" <TAB> lines = """" <TAB> for _, name, asname in names: <TAB> <TAB> pkg, _, _ = name.partition(""."") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> line = ""{pkg} = _LazyModule.load({pkg!r}, {mod!r})\n"" <TAB> <TAB> else: <TAB> <TAB> <TAB> line = ""{asname} = _LazyModule.load({pkg!r}, {mod!r}, {asname!r})\n"" <TAB> <TAB> lines += line.format(pkg=pkg, mod=name, asname=asname) <TAB> return lines",true,if asname is None :,if asname is None :,0.75,0.0
"def evaluateWord(self, argument): <TAB> wildcard_count = argument[0].count(""*"") <TAB> if wildcard_count > 0: <TAB> <TAB> if wildcard_count == 1 and argument[0].startswith(""*""): <TAB> <TAB> <TAB> return self.GetWordWildcard(argument[0][1:], method=""endswith"") <TAB> <TAB> if wildcard_count == 1 and argument[0].endswith(""*""): <TAB> <TAB> <TAB> return self.GetWordWildcard(argument[0][:-1], method=""startswith"") <TAB> <TAB> else: <TAB> <TAB> <TAB> _regex = argument[0].replace(""*"", "".+"") <TAB> <TAB> <TAB> matched = False <TAB> <TAB> <TAB> for w in self.words: <TAB> <TAB> <TAB> <TAB> matched = bool(re.search(_regex, w)) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> return matched <TAB> return self.GetWord(argument[0])",true,if matched :,if matched :,0.53,0.0
"def setup(self, ir: ""IR"", aconf: Config) -> bool: <TAB> if self.kind == ""ConsulResolver"": <TAB> <TAB> self.resolve_with = ""consul"" <TAB> <TAB> if not self.get(""datacenter""): <TAB> <TAB> <TAB> self.post_error(""ConsulResolver is required to have a datacenter"") <TAB> <TAB> <TAB> return False <TAB> elif self.kind == ""KubernetesServiceResolver"": <TAB> <TAB> self.resolve_with = ""k8s"" <TAB> elif self.kind == ""KubernetesEndpointResolver"": <TAB> <TAB> self.resolve_with = ""k8s"" <TAB> else: <TAB> <TAB> self.post_error(f""Resolver kind {self.kind} unknown"") <TAB> <TAB> return False <TAB> return True",true,"if not self . get ( ""datacenter"" ) :","if not self . get ( ""datacenter"" ) :",0.75,0.0
"def get_success_url(self): <TAB> """"""Continue to the flow index or redirect according `?back` parameter."""""" <TAB> if ""back"" in self.request.GET: <TAB> <TAB> back_url = self.request.GET[""back""] <TAB> <TAB> if not is_safe_url(url=back_url, allowed_hosts={self.request.get_host()}): <TAB> <TAB> <TAB> back_url = ""/"" <TAB> <TAB> return back_url <TAB> return reverse(self.success_url)",true,"if not is_safe_url ( url = back_url , allowed_hosts = { self . request . get_host ( ) } ) :","if not is_safe_url ( url = back_url , allowed_hosts = { self . request . get_host ( ) } ) :",1.0,0.0
"def download_main( <TAB> download, download_playlist, urls, playlist, output_dir, merge, info_only ): <TAB> for url in urls: <TAB> <TAB> if url.startswith(""https://""): <TAB> <TAB> <TAB> url = url[8:] <TAB> <TAB> if not url.startswith(""http://""): <TAB> <TAB> <TAB> url = ""http://"" + url <TAB> <TAB> if playlist: <TAB> <TAB> <TAB> download_playlist( <TAB> <TAB> <TAB> <TAB> url, output_dir=output_dir, merge=merge, info_only=info_only <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> download(url, output_dir=output_dir, merge=merge, info_only=info_only)",false,"if not url . startswith ( ""http://"" ) :","if url . startswith ( ""https://"" ) :",0.19,0.0
"def __str__(self): <TAB> buf = [""""] <TAB> if self.fileName: <TAB> <TAB> buf.append(self.fileName + "":"") <TAB> if self.line != -1: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> buf.append(""line "") <TAB> <TAB> buf.append(str(self.line)) <TAB> <TAB> if self.column != -1: <TAB> <TAB> <TAB> buf.append("":"" + str(self.column)) <TAB> <TAB> buf.append("":"") <TAB> buf.append("" "") <TAB> return str("""").join(buf)",false,if not self . fileName :,if self . line != 0 :,0.05,0.0
"def parse_bash_set_output(output): <TAB> """"""Parse Bash-like 'set' output"""""" <TAB> if not sys.platform.startswith(""win""): <TAB> <TAB> # Replace ""\""-continued lines in *Linux* environment dumps. <TAB> <TAB> # Cannot do this on Windows because a ""\"" at the end of the <TAB> <TAB> # line does not imply a continuation. <TAB> <TAB> output = output.replace(""\\\n"", """") <TAB> environ = {} <TAB> for line in output.splitlines(0): <TAB> <TAB> line = line.rstrip() <TAB> <TAB> if not line: <TAB> <TAB> <TAB> continue  # skip black lines <TAB> <TAB> item = _ParseBashEnvStr(line) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> environ[item[0]] = item[1] <TAB> return environ",true,if item :,if item :,0.53,0.0
"def remove_selected(self): <TAB> """"""Removes selected items from list."""""" <TAB> to_delete = [] <TAB> for i in range(len(self)): <TAB> <TAB> if self[i].selected: <TAB> <TAB> <TAB> to_delete.append(i) <TAB> to_delete.reverse() <TAB> for i in to_delete: <TAB> <TAB> self.pop(i) <TAB> if len(to_delete) > 0: <TAB> <TAB> first_to_delete = to_delete[-1] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self[0].selected = True <TAB> <TAB> elif first_to_delete > 0: <TAB> <TAB> <TAB> self[first_to_delete - 1].selected = True",false,if first_to_delete == 0 and len ( self ) > 0 :,if first_to_delete == 0 :,0.14,0.0
"def update(self, update_tracks=True): <TAB> self.enable_update_metadata_images(False) <TAB> old_album_title = self.metadata[""album""] <TAB> self.metadata[""album""] = config.setting[""nat_name""] <TAB> for track in self.tracks: <TAB> <TAB> if old_album_title == track.metadata[""album""]: <TAB> <TAB> <TAB> track.metadata[""album""] = self.metadata[""album""] <TAB> <TAB> for file in track.linked_files: <TAB> <TAB> <TAB> track.update_file_metadata(file) <TAB> self.enable_update_metadata_images(True) <TAB> super().update(update_tracks)",true,"if old_album_title == track . metadata [ ""album"" ] :","if old_album_title == track . metadata [ ""album"" ] :",0.75,0.0
"def on_input(self, target, message): <TAB> if message.strip() == """": <TAB> <TAB> self.panel(""No commit message provided"") <TAB> <TAB> return <TAB> if target: <TAB> <TAB> command = [""git"", ""add""] <TAB> <TAB> if target == ""*"": <TAB> <TAB> <TAB> command.append(""--all"") <TAB> <TAB> else: <TAB> <TAB> <TAB> command.extend((""--"", target)) <TAB> <TAB> self.run_command(command, functools.partial(self.add_done, message)) <TAB> else: <TAB> <TAB> self.add_done(message, """")",true,"if target == ""*"" :","if target == ""*"" :",0.75,0.0
"def go_to_last_edit_location(self): <TAB> if self.last_edit_cursor_pos is not None: <TAB> <TAB> filename, position = self.last_edit_cursor_pos <TAB> <TAB> if not osp.isfile(filename): <TAB> <TAB> <TAB> self.last_edit_cursor_pos = None <TAB> <TAB> <TAB> return <TAB> <TAB> else: <TAB> <TAB> <TAB> self.load(filename) <TAB> <TAB> <TAB> editor = self.get_current_editor() <TAB> <TAB> <TAB> if position < editor.document().characterCount(): <TAB> <TAB> <TAB> <TAB> editor.set_cursor_position(position)",false,if not osp . isfile ( filename ) :,if position < editor . document ( ) . characterCount ( ) :,0.03,0.0
"def returnByType(self, results): <TAB> new_results = {} <TAB> for r in results: <TAB> <TAB> type_name = r.get(""type"", ""movie"") + ""s"" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> new_results[type_name] = [] <TAB> <TAB> new_results[type_name].append(r) <TAB> # Combine movies, needs a cleaner way.. <TAB> if ""movies"" in new_results: <TAB> <TAB> new_results[""movies""] = self.combineOnIMDB(new_results[""movies""]) <TAB> return new_results",true,if type_name not in new_results :,if type_name not in new_results :,0.75,0.0
"def cache_sns_topics_across_accounts() -> bool: <TAB> function: str = f""{__name__}.{sys._getframe().f_code.co_name}"" <TAB> # First, get list of accounts <TAB> accounts_d: list = async_to_sync(get_account_id_to_name_mapping)() <TAB> for account_id in accounts_d.keys(): <TAB> <TAB> if config.get(""environment"") == ""prod"": <TAB> <TAB> <TAB> cache_sns_topics_for_account.delay(account_id) <TAB> <TAB> else: <TAB> <TAB> <TAB> if account_id in config.get(""celery.test_account_ids"", []): <TAB> <TAB> <TAB> <TAB> cache_sns_topics_for_account.delay(account_id) <TAB> stats.count(f""{function}.success"") <TAB> return True",true,"if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :","if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :",0.75,0.0
"def get(self, subject, topic): <TAB> """"""Handles GET requests."""""" <TAB> if subject in feconf.AVAILABLE_LANDING_PAGES: <TAB> <TAB> if topic in feconf.AVAILABLE_LANDING_PAGES[subject]: <TAB> <TAB> <TAB> self.render_template(""topic-landing-page.mainpage.html"") <TAB> <TAB> else: <TAB> <TAB> <TAB> raise self.PageNotFoundException <TAB> else: <TAB> <TAB> raise self.PageNotFoundException",true,if topic in feconf . AVAILABLE_LANDING_PAGES [ subject ] :,if topic in feconf . AVAILABLE_LANDING_PAGES [ subject ] :,0.75,0.0
"def callback(compiled): <TAB><IF-STMT> <TAB> <TAB> logger.show_tabulated( <TAB> <TAB> <TAB> ""Compiled"", showpath(codepath), ""without writing to file."" <TAB> <TAB> ) <TAB> else: <TAB> <TAB> with univ_open(destpath, ""w"") as opened: <TAB> <TAB> <TAB> writefile(opened, compiled) <TAB> <TAB> logger.show_tabulated(""Compiled to"", showpath(destpath), ""."") <TAB> if self.show: <TAB> <TAB> print(compiled) <TAB> if run: <TAB> <TAB> if destpath is None: <TAB> <TAB> <TAB> self.execute(compiled, path=codepath, allow_show=False) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.execute_file(destpath)",false,if destpath is None :,if run :,0.04,0.0
"def _find_start_index(self, string, start, end): <TAB> while True: <TAB> <TAB> index = string.find(""{"", start, end) - 1 <TAB> <TAB> if index < 0: <TAB> <TAB> <TAB> return -1 <TAB> <TAB> if self._start_index_is_ok(string, index): <TAB> <TAB> <TAB> return index <TAB> <TAB> start = index + 2",true,"if self . _start_index_is_ok ( string , index ) :","if self . _start_index_is_ok ( string , index ) :",0.75,0.0
"def _get_nlu_target_format(export_path: Text) -> Text: <TAB> guessed_format = loading.guess_format(export_path) <TAB> if guessed_format not in {MARKDOWN, RASA, RASA_YAML}: <TAB> <TAB> if rasa.shared.data.is_likely_json_file(export_path): <TAB> <TAB> <TAB> guessed_format = RASA <TAB> <TAB> elif rasa.shared.data.is_likely_markdown_file(export_path): <TAB> <TAB> <TAB> guessed_format = MARKDOWN <TAB> <TAB> elif rasa.shared.data.is_likely_yaml_file(export_path): <TAB> <TAB> <TAB> guessed_format = RASA_YAML <TAB> return guessed_format",false,elif rasa . shared . data . is_likely_yaml_file ( export_path ) :,elif rasa . shared . data . is_likely_markdown_file ( export_path ) :,0.62,0.0
"def moveToThreadNext(self): <TAB> """"""Move a position to threadNext position."""""" <TAB> p = self <TAB> if p.v: <TAB> <TAB> if p.v.children: <TAB> <TAB> <TAB> p.moveToFirstChild() <TAB> <TAB> elif p.hasNext(): <TAB> <TAB> <TAB> p.moveToNext() <TAB> <TAB> else: <TAB> <TAB> <TAB> p.moveToParent() <TAB> <TAB> <TAB> while p: <TAB> <TAB> <TAB> <TAB> if p.hasNext(): <TAB> <TAB> <TAB> <TAB> <TAB> p.moveToNext() <TAB> <TAB> <TAB> <TAB> <TAB> break  # found <TAB> <TAB> <TAB> <TAB> p.moveToParent() <TAB> <TAB> <TAB> # not found. <TAB> return p",false,if p . hasNext ( ) :,if p . v . children :,0.09,0.0
"def copy_attributes(info_add, obj, name_fmt, attributes, formatter=None): <TAB> for attr in attributes: <TAB> <TAB> value = getattr(obj, attr, None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> name = name_fmt % attr <TAB> <TAB> if formatter is not None: <TAB> <TAB> <TAB> value = formatter(attr, value) <TAB> <TAB> info_add(name, value)",true,if value is None :,if value is None :,0.75,0.0
"def getElement(self, aboutUri, namespace, name): <TAB> for desc in self.rdfRoot.getElementsByTagNameNS(RDF_NAMESPACE, ""Description""): <TAB> <TAB> if desc.getAttributeNS(RDF_NAMESPACE, ""about"") == aboutUri: <TAB> <TAB> <TAB> attr = desc.getAttributeNodeNS(namespace, name) <TAB> <TAB> <TAB> if attr != None: <TAB> <TAB> <TAB> <TAB> yield attr <TAB> <TAB> <TAB> for element in desc.getElementsByTagNameNS(namespace, name): <TAB> <TAB> <TAB> <TAB> yield element",true,"if desc . getAttributeNS ( RDF_NAMESPACE , ""about"" ) == aboutUri :","if desc . getAttributeNS ( RDF_NAMESPACE , ""about"" ) == aboutUri :",0.75,0.0
def run(self): <TAB> while not self.completed: <TAB> <TAB> if self.block: <TAB> <TAB> <TAB> time.sleep(self.period) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._completed.wait(self.period) <TAB> <TAB> self.counter += 1 <TAB> <TAB> try: <TAB> <TAB> <TAB> self.callback(self.counter) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> self.stop() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> dt = time.time() - self._start_time <TAB> <TAB> <TAB> if dt > self.timeout: <TAB> <TAB> <TAB> <TAB> self.stop() <TAB> <TAB> if self.counter == self.count: <TAB> <TAB> <TAB> self.stop(),false,if self . timeout is not None :,if self . timeout :,0.23,0.0
"def _parse_fixits(message, titer, line): <TAB> """"""Parses fixit messages."""""" <TAB> while ( <TAB> <TAB> OutputParser.message_line_re.match(line) is None <TAB> <TAB> and OutputParser.note_line_re.match(line) is None <TAB> ): <TAB> <TAB> message_text = line.strip() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> message.fixits.append( <TAB> <TAB> <TAB> <TAB> Note( <TAB> <TAB> <TAB> <TAB> <TAB> message.path, <TAB> <TAB> <TAB> <TAB> <TAB> message.line, <TAB> <TAB> <TAB> <TAB> <TAB> line.find(message_text) + 1, <TAB> <TAB> <TAB> <TAB> <TAB> message_text, <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> line = next(titer) <TAB> return line",false,"if message_text != """" :",if message_text :,0.07,0.0
"def _connect_db(self, force_reconnect=False): <TAB> thread_id = thread.get_ident() <TAB> if force_reconnect and thread_id in ENGINES: <TAB> <TAB> del ENGINES[thread_id] <TAB> conn = None <TAB> try: <TAB> <TAB> engine = ENGINES[thread_id] <TAB> <TAB> conn = engine.connect() <TAB> <TAB> _test = conn.execute(""SELECT 1"") <TAB> <TAB> _test.fetchall() <TAB> except (KeyError, MySQLdb.OperationalError): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> conn.close() <TAB> <TAB> engine = sqla.create_engine(self.db_url, pool_recycle=3600) <TAB> <TAB> ENGINES[thread_id] = engine <TAB> <TAB> conn = engine.connect() <TAB> return conn",true,if conn :,if conn :,0.53,0.0
"def read(self, n): <TAB> if self.current_frame: <TAB> <TAB> data = self.current_frame.read(n) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.current_frame = None <TAB> <TAB> <TAB> return self.file_read(n) <TAB> <TAB> if len(data) < n: <TAB> <TAB> <TAB> raise UnpicklingError(""pickle exhausted before end of frame"") <TAB> <TAB> return data <TAB> else: <TAB> <TAB> return self.file_read(n)",false,if not data and n != 0 :,if not data :,0.08,0.0
"def __setLoadCmd(self): <TAB> base = self.__rawLoadCmd <TAB> for _ in range(self.__machHeader.ncmds): <TAB> <TAB> command = LOAD_COMMAND.from_buffer_copy(base) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> segment = SEGMENT_COMMAND.from_buffer_copy(base) <TAB> <TAB> <TAB> self.__setSections(segment, base[56:], 32) <TAB> <TAB> elif command.cmd == MACHOFlags.LC_SEGMENT_64: <TAB> <TAB> <TAB> segment = SEGMENT_COMMAND64.from_buffer_copy(base) <TAB> <TAB> <TAB> self.__setSections(segment, base[72:], 64) <TAB> <TAB> base = base[command.cmdsize :]",false,if command . cmd == MACHOFlags . LC_SEGMENT :,if command . cmd == MACHOFlags . LC_SEGMENT_128 :,0.63,0.0
"def emit_post_sync_signal(created_models, verbosity, interactive, db): <TAB> # Emit the post_sync signal for every application. <TAB> for app in models.get_apps(): <TAB> <TAB> app_name = app.__name__.split(""."")[-2] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(""Running post-sync handlers for application %s"" % app_name) <TAB> <TAB> models.signals.post_syncdb.send( <TAB> <TAB> <TAB> sender=app, <TAB> <TAB> <TAB> app=app, <TAB> <TAB> <TAB> created_models=created_models, <TAB> <TAB> <TAB> verbosity=verbosity, <TAB> <TAB> <TAB> interactive=interactive, <TAB> <TAB> <TAB> db=db, <TAB> <TAB> )",false,if verbosity >= 2 :,if verbosity > 1 :,0.31,0.0
"def git_pull(args): <TAB> if len(args) <= 1: <TAB> <TAB> repo = _get_repo() <TAB> <TAB> _confirm_dangerous() <TAB> <TAB> url = args[0] if len(args) == 1 else repo.remotes.get(""origin"", """") <TAB> <TAB> if url in repo.remotes: <TAB> <TAB> <TAB> origin = url <TAB> <TAB> <TAB> url = repo.remotes.get(origin) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> repo.pull(origin_uri=url) <TAB> <TAB> else: <TAB> <TAB> <TAB> print(""No pull URL."") <TAB> else: <TAB> <TAB> print(command_help[""git pull""])",true,if url :,if url :,0.53,0.0
"def version(self): <TAB> try: <TAB> <TAB> return self._version <TAB> except AttributeError: <TAB> <TAB> for line in self._get_metadata(self.PKG_INFO): <TAB> <TAB> <TAB> if line.lower().startswith(""version:""): <TAB> <TAB> <TAB> <TAB> self._version = safe_version(line.split("":"", 1)[1].strip()) <TAB> <TAB> <TAB> <TAB> return self._version <TAB> <TAB> else: <TAB> <TAB> <TAB> tmpl = ""Missing 'Version:' header and/or %s file"" <TAB> <TAB> <TAB> raise ValueError(tmpl % self.PKG_INFO, self)",true,"if line . lower ( ) . startswith ( ""version:"" ) :","if line . lower ( ) . startswith ( ""version:"" ) :",0.75,0.0
"def increment(self, metric, labels, delta): <TAB> """"""Increment a value by |delta|."""""" <TAB> with self._lock: <TAB> <TAB> key = self._get_key(metric.name, labels) <TAB> <TAB> if key in self._store: <TAB> <TAB> <TAB> start_time = self._store[key].start_time <TAB> <TAB> <TAB> value = self._store[key].value + delta <TAB> <TAB> else: <TAB> <TAB> <TAB> start_time = time.time() <TAB> <TAB> <TAB> value = metric.default_value + delta <TAB> <TAB> self._store[key] = _StoreValue(metric, labels, start_time, value)",true,if key in self . _store :,if key in self . _store :,0.75,0.0
"def get_current_connections(session): <TAB> """"""Retrieves open connections using the the given session"""""" <TAB> # Use Show process list to count the open sesions. <TAB> res = session.sql(""SHOW PROCESSLIST"").execute() <TAB> rows = res.fetch_all() <TAB> connections = {} <TAB> for row in rows: <TAB> <TAB> if row.get_string(""User"") not in connections: <TAB> <TAB> <TAB> connections[row.get_string(""User"")] = [row.get_string(""Host"")] <TAB> <TAB> else: <TAB> <TAB> <TAB> connections[row.get_string(""User"")].append(row.get_string(""Host"")) <TAB> return connections",true,"if row . get_string ( ""User"" ) not in connections :","if row . get_string ( ""User"" ) not in connections :",0.75,0.0
"def asset(*paths): <TAB> for path in paths: <TAB> <TAB> fspath = www_root + ""/assets/"" + path <TAB> <TAB> etag = """" <TAB> <TAB> try: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> etag = asset_etag(fspath) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> os.stat(fspath) <TAB> <TAB> except FileNotFoundError as e: <TAB> <TAB> <TAB> if path == paths[-1]: <TAB> <TAB> <TAB> <TAB> if not os.path.exists(fspath + "".spt""): <TAB> <TAB> <TAB> <TAB> <TAB> tell_sentry(e, {}) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> tell_sentry(e, {}) <TAB> <TAB> return asset_url + path + (etag and ""?etag="" + etag)",false,if env . cache_static :,if path == asset_path :,0.03,0.0
def thread_loop(self) -> None: <TAB> while not self.stop_event.is_set(): <TAB> <TAB> time.sleep(1) <TAB> <TAB> new_trials = self.study.trials <TAB> <TAB> with self.lock: <TAB> <TAB> <TAB> need_to_add_callback = self.new_trials is None <TAB> <TAB> <TAB> self.new_trials = new_trials <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.doc.add_next_tick_callback(self.update_callback),true,if need_to_add_callback :,if need_to_add_callback :,0.53,0.0
"def _cache_db_tables_iterator(tables, cache_alias, db_alias): <TAB> no_tables = not tables <TAB> cache_aliases = settings.CACHES if cache_alias is None else (cache_alias,) <TAB> db_aliases = settings.DATABASES if db_alias is None else (db_alias,) <TAB> for db_alias in db_aliases: <TAB> <TAB> if no_tables: <TAB> <TAB> <TAB> tables = connections[db_alias].introspection.table_names() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for cache_alias in cache_aliases: <TAB> <TAB> <TAB> <TAB> yield cache_alias, db_alias, tables",false,if tables :,if cache_aliases :,0.32,0.0
"def remove_subscriber(self, topic, subscriber): <TAB> if subscriber in self.subscribers[topic]: <TAB> <TAB> if hasattr(subscriber, ""_pyroRelease""): <TAB> <TAB> <TAB> subscriber._pyroRelease() <TAB> <TAB> if hasattr(subscriber, ""_pyroUri""): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> proxy = self.proxy_cache[subscriber._pyroUri] <TAB> <TAB> <TAB> <TAB> proxy._pyroRelease() <TAB> <TAB> <TAB> <TAB> del self.proxy_cache[subscriber._pyroUri] <TAB> <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> self.subscribers[topic].discard(subscriber)",false,"if hasattr ( subscriber , ""_pyroUri"" ) :","if hasattr ( subscriber , ""_pyroRelease"" ) :",0.55,0.0
"def test_constructor(job_id): <TAB> with patch(""apscheduler.job.Job._modify"") as _modify: <TAB> <TAB> scheduler_mock = MagicMock(BaseScheduler) <TAB> <TAB> job = Job(scheduler_mock, id=job_id) <TAB> <TAB> assert job._scheduler is scheduler_mock <TAB> <TAB> assert job._jobstore_alias is None <TAB> <TAB> modify_kwargs = _modify.call_args[1] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> assert len(modify_kwargs[""id""]) == 32 <TAB> <TAB> else: <TAB> <TAB> <TAB> assert modify_kwargs[""id""] == job_id",false,if job_id is None :,"if ""id"" in modify_kwargs :",0.03,0.0
"def get_connection(self): <TAB> if self.config.proxy_host != """": <TAB> <TAB> return httplib.HTTPConnection(self.config.proxy_host, self.config.proxy_port) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return httplib.HTTPSConnection(self.config.simpledb_host) <TAB> <TAB> else: <TAB> <TAB> <TAB> return httplib.HTTPConnection(self.config.simpledb_host)",false,if self . config . use_https :,if self . config . secure :,0.57,0.0
"def notify_login(self, ipaddress=""""): <TAB> if app.NOTIFY_ON_LOGIN: <TAB> <TAB> update_text = common.notifyStrings[common.NOTIFY_LOGIN_TEXT] <TAB> <TAB> title = common.notifyStrings[common.NOTIFY_LOGIN] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._notify_pht(title, update_text.format(ipaddress))",false,if update_text and title and ipaddress :,if title :,0.02,0.0
"def _getItemHeight(self, item, ctrl=None): <TAB> """"""Returns the full height of the item to be inserted in the form"""""" <TAB> if type(ctrl) == psychopy.visual.TextBox2: <TAB> <TAB> return ctrl.size[1] <TAB> if type(ctrl) == psychopy.visual.Slider: <TAB> <TAB> # Set radio button layout <TAB> <TAB> if item[""layout""] == ""horiz"": <TAB> <TAB> <TAB> return 0.03 + ctrl.labelHeight * 3 <TAB> <TAB> elif item[""layout""] == ""vert"": <TAB> <TAB> <TAB> # for vertical take into account the nOptions <TAB> <TAB> <TAB> return ctrl.labelHeight * len(item[""options""])",true,"elif item [ ""layout"" ] == ""vert"" :","elif item [ ""layout"" ] == ""vert"" :",1.0,0.0
"def _get_errors_lines(self): <TAB> """"""Return the number of lines that contains errors to highlight."""""" <TAB> errors_lines = [] <TAB> block = self.document().begin() <TAB> while block.isValid(): <TAB> <TAB> user_data = get_user_data(block) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> errors_lines.append(block.blockNumber()) <TAB> <TAB> block = block.next() <TAB> return errors_lines",false,if user_data . error :,if user_data . errors :,0.39,0.0
"def set_pbar_fraction(self, frac, progress, stage=None): <TAB> gtk.gdk.threads_enter() <TAB> try: <TAB> <TAB> self.is_pulsing = False <TAB> <TAB> self.set_stage_text(stage or _(""Processing..."")) <TAB> <TAB> self.pbar.set_text(progress) <TAB> <TAB> if frac > 1: <TAB> <TAB> <TAB> frac = 1.0 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> frac = 0 <TAB> <TAB> self.pbar.set_fraction(frac) <TAB> finally: <TAB> <TAB> gtk.gdk.threads_leave()",true,if frac < 0 :,if frac < 0 :,0.75,0.0
"def list_files(basedir): <TAB> """"""List files in the directory rooted at |basedir|."""""" <TAB> if not os.path.isdir(basedir): <TAB> <TAB> raise NoSuchDirectory(basedir) <TAB> directories = [""""] <TAB> while directories: <TAB> <TAB> d = directories.pop() <TAB> <TAB> for basename in os.listdir(os.path.join(basedir, d)): <TAB> <TAB> <TAB> filename = os.path.join(d, basename) <TAB> <TAB> <TAB> if os.path.isdir(os.path.join(basedir, filename)): <TAB> <TAB> <TAB> <TAB> directories.append(filename) <TAB> <TAB> <TAB> elif os.path.exists(os.path.join(basedir, filename)): <TAB> <TAB> <TAB> <TAB> yield filename",true,"elif os . path . exists ( os . path . join ( basedir , filename ) ) :","elif os . path . exists ( os . path . join ( basedir , filename ) ) :",1.0,0.0
"def assistive(self): <TAB> """"""Detects if item can be used as assistance"""""" <TAB> # Make sure we cache results <TAB> if self.__assistive is None: <TAB> <TAB> assistive = False <TAB> <TAB> # Go through all effects and find first assistive <TAB> <TAB> for effect in self.effects.values(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> # If we find one, stop and mark item as assistive <TAB> <TAB> <TAB> <TAB> assistive = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> self.__assistive = assistive <TAB> return self.__assistive",false,if effect . isAssistance is True :,if effect . assistive is True :,0.39,0.0
"def closest_unseen(self, row1, col1, filter=None): <TAB> # find the closest unseen from this row/col <TAB> min_dist = maxint <TAB> closest_unseen = None <TAB> for row in range(self.height): <TAB> <TAB> for col in range(self.width): <TAB> <TAB> <TAB> if filter is None or (row, col) not in filter: <TAB> <TAB> <TAB> <TAB> if self.map[row][col] == UNSEEN: <TAB> <TAB> <TAB> <TAB> <TAB> dist = self.distance(row1, col1, row, col) <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> min_dist = dist <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> closest_unseen = (row, col) <TAB> return closest_unseen",true,if dist < min_dist :,if dist < min_dist :,0.75,0.0
"def _maybe_has_default_route(self): <TAB> for route in self.iter_routes(): <TAB> <TAB> if self._is_default_route(route): <TAB> <TAB> <TAB> return True <TAB> for iface in self.iter_interfaces(): <TAB> <TAB> for subnet in iface.get(""subnets"", []): <TAB> <TAB> <TAB> for route in subnet.get(""routes"", []): <TAB> <TAB> <TAB> <TAB> if self._is_default_route(route): <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",true,if self . _is_default_route ( route ) :,if self . _is_default_route ( route ) :,0.75,0.0
"def data(self, data): <TAB> if data is None: <TAB> <TAB> raise Exception(""Data cannot be None"") <TAB> val = [] <TAB> for d in data: <TAB> <TAB> if isinstance(d, str): <TAB> <TAB> <TAB> val.append(bytes(d, ""utf-8"")) <TAB> <TAB> elif isinstance(d, bytes): <TAB> <TAB> <TAB> val.append(d) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> ""Invalid type, data can only be an str or a bytes not {}: {}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> type(data), d <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> self.__data = val",true,"elif isinstance ( d , bytes ) :","elif isinstance ( d , bytes ) :",0.75,0.0
"def get_one_segment_function(data, context, echoerr): <TAB> ext = data[""ext""] <TAB> function_name = context[-2][1].get(""function"") <TAB> if function_name: <TAB> <TAB> module, function_name = get_function_strings(function_name, context, ext) <TAB> <TAB> func = import_segment(function_name, data, context, echoerr, module=module) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield func",true,if func :,if func :,0.53,0.0
"def generic_visit(self, node, parents=None): <TAB> parents = (parents or []) + [node] <TAB> for field, value in iter_fields(node): <TAB> <TAB> if isinstance(value, list): <TAB> <TAB> <TAB> for item in value: <TAB> <TAB> <TAB> <TAB> if isinstance(item, AST): <TAB> <TAB> <TAB> <TAB> <TAB> self.visit(item, parents) <TAB> <TAB> elif isinstance(value, AST): <TAB> <TAB> <TAB> self.visit(value, parents)",false,"if isinstance ( item , AST ) :","if isinstance ( value , list ) :",0.34,0.0
"def find_scintilla_constants(f): <TAB> lexers = [] <TAB> states = [] <TAB> for name in f.order: <TAB> <TAB> v = f.features[name] <TAB> <TAB> if v[""Category""] != ""Deprecated"": <TAB> <TAB> <TAB> if v[""FeatureType""] == ""val"": <TAB> <TAB> <TAB> <TAB> if name.startswith(""SCE_""): <TAB> <TAB> <TAB> <TAB> <TAB> states.append((name, v[""Value""])) <TAB> <TAB> <TAB> <TAB> elif name.startswith(""SCLEX_""): <TAB> <TAB> <TAB> <TAB> <TAB> lexers.append((name, v[""Value""])) <TAB> return (lexers, states)",false,"if v [ ""Category"" ] != ""Deprecated"" :","if v [ ""FeatureType"" ] == ""val"" :",0.33,0.0
"def things(self, query): <TAB> limit = query.pop(""limit"", 100) <TAB> offset = query.pop(""offset"", 0) <TAB> keys = set(self.docs) <TAB> for k, v in query.items(): <TAB> <TAB> if isinstance(v, dict): <TAB> <TAB> <TAB> # query keys need to be flattened properly, <TAB> <TAB> <TAB> # this corrects any nested keys that have been included <TAB> <TAB> <TAB> # in values. <TAB> <TAB> <TAB> flat = common.flatten_dict(v)[0] <TAB> <TAB> <TAB> k += ""."" + web.rstrips(flat[0], "".key"") <TAB> <TAB> <TAB> v = flat[1] <TAB> <TAB> keys = set(k for k in self.filter_index(self.index, k, v) if k in keys) <TAB> keys = sorted(keys) <TAB> return keys[offset : offset + limit]",true,"if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",0.75,0.0
"def del_(self, key): <TAB> initial_hash = hash_ = self.hash(key) <TAB> while True: <TAB> <TAB> if self._keys[hash_] is self._empty: <TAB> <TAB> <TAB> # That key was never assigned <TAB> <TAB> <TAB> return None <TAB> <TAB> elif self._keys[hash_] == key: <TAB> <TAB> <TAB> # key found, assign with deleted sentinel <TAB> <TAB> <TAB> self._keys[hash_] = self._deleted <TAB> <TAB> <TAB> self._values[hash_] = self._deleted <TAB> <TAB> <TAB> self._len -= 1 <TAB> <TAB> <TAB> return <TAB> <TAB> hash_ = self._rehash(hash_) <TAB> <TAB> if initial_hash == hash_: <TAB> <TAB> <TAB> # table is full and wrapped around <TAB> <TAB> <TAB> return None",true,elif self . _keys [ hash_ ] == key :,elif self . _keys [ hash_ ] == key :,0.75,0.0
"def test_204_invalid_content_length(self): <TAB> # 204 status with non-zero content length is malformed <TAB> with ExpectLog(gen_log, "".*Response with code 204 should not have body""): <TAB> <TAB> response = self.fetch(""/?error=1"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.skipTest(""requires HTTP/1.x"") <TAB> <TAB> if self.http_client.configured_class != SimpleAsyncHTTPClient: <TAB> <TAB> <TAB> self.skipTest(""curl client accepts invalid headers"") <TAB> <TAB> self.assertEqual(response.code, 599)",false,if not self . http1 :,if response is None :,0.03,0.0
"def __str__(self) -> str: <TAB> text = ""\n"" <TAB> for k, r in self.result.items(): <TAB> <TAB> text += ""{}\n"".format(""#"" * 40) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> text += ""# {} (failed)\n"".format(k) <TAB> <TAB> else: <TAB> <TAB> <TAB> text += ""# {} (succeeded)\n"".format(k) <TAB> <TAB> text += ""{}\n"".format(""#"" * 40) <TAB> <TAB> for sub_r in r: <TAB> <TAB> <TAB> text += ""**** {}\n"".format(sub_r.name) <TAB> <TAB> <TAB> text += ""{}\n"".format(sub_r) <TAB> return text",false,if r . failed :,if r is None :,0.06,0.0
"def DeleteTask(): <TAB> oid = request.form.get(""oid"", """") <TAB> if oid: <TAB> <TAB> result = Mongo.coll[""Task""].delete_one({""_id"": ObjectId(oid)}) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result = Mongo.coll[""Result""].delete_many({""task_id"": ObjectId(oid)}) <TAB> <TAB> <TAB> if result: <TAB> <TAB> <TAB> <TAB> return ""success"" <TAB> return ""fail""",false,if result . deleted_count > 0 :,if result :,0.04,0.0
"def _replace_vars(self, line, extracted, env_variables): <TAB> for e in extracted: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> value = env_variables.get(e) <TAB> <TAB> <TAB> if isinstance(value, dict) or isinstance(value, list): <TAB> <TAB> <TAB> <TAB> value = pprint.pformat(value) <TAB> <TAB> <TAB> decorated = self._decorate_var(e) <TAB> <TAB> <TAB> line = line.replace(decorated, str(value)) <TAB> return line",true,if e in env_variables :,if e in env_variables :,0.75,0.0
"def should_include(service): <TAB> for f in filt: <TAB> <TAB> if f == ""status"": <TAB> <TAB> <TAB> state = filt[f] <TAB> <TAB> <TAB> containers = project.containers([service.name], stopped=True) <TAB> <TAB> <TAB> if not has_container_with_state(containers, state): <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif f == ""source"": <TAB> <TAB> <TAB> source = filt[f] <TAB> <TAB> <TAB> if source == ""image"" or source == ""build"": <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise UserError(""Invalid value for source filter: %s"" % source) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise UserError(""Invalid filter: %s"" % f) <TAB> return True",false,if source not in service . options :,if not source :,0.02,0.0
def state_callback_loop(): <TAB> if usercallback: <TAB> <TAB> when = 1 <TAB> <TAB> while ( <TAB> <TAB> <TAB> when <TAB> <TAB> <TAB> and not self.future_removed.done() <TAB> <TAB> <TAB> and not self.session.shutdownstarttime <TAB> <TAB> ): <TAB> <TAB> <TAB> result = usercallback(self.get_state()) <TAB> <TAB> <TAB> when = (await result) if iscoroutine(result) else result <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> await sleep(when),false,if when > 0.0 and not self . session . shutdownstarttime :,if when :,0.01,0.0
"def __get_new_timeout(self, timeout): <TAB> """"""When using --timeout_multiplier=#.#"""""" <TAB> self.__check_scope() <TAB> try: <TAB> <TAB> timeout_multiplier = float(self.timeout_multiplier) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> timeout_multiplier = 0.5 <TAB> <TAB> timeout = int(math.ceil(timeout_multiplier * timeout)) <TAB> <TAB> return timeout <TAB> except Exception: <TAB> <TAB> # Wrong data type for timeout_multiplier (expecting int or float) <TAB> <TAB> return timeout",false,if timeout_multiplier <= 0.5 :,if timeout_multiplier < 0.5 :,0.33,0.0
"def readexactly(self, n): <TAB> buf = b"""" <TAB> while n: <TAB> <TAB> yield IORead(self.s) <TAB> <TAB> res = self.s.read(n) <TAB> <TAB> assert res is not None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield IOReadDone(self.s) <TAB> <TAB> <TAB> break <TAB> <TAB> buf += res <TAB> <TAB> n -= len(res) <TAB> return buf",false,if not res :,if len ( res ) == 0 :,0.04,0.0
"def contract_rendering_pane(event): <TAB> """"""Expand the rendering pane."""""" <TAB> c = event.get(""c"") <TAB> if c: <TAB> <TAB> vr = c.frame.top.findChild(QtWidgets.QWidget, ""viewrendered_pane"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> vr.contract() <TAB> <TAB> else: <TAB> <TAB> <TAB> # Just open the pane. <TAB> <TAB> <TAB> viewrendered(event)",true,if vr :,if vr :,0.53,0.0
"def translate_headers(self, environ): <TAB> """"""Translate CGI-environ header names to HTTP header names."""""" <TAB> for cgiName in environ: <TAB> <TAB> # We assume all incoming header keys are uppercase already. <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield self.headerNames[cgiName], environ[cgiName] <TAB> <TAB> elif cgiName[:5] == ""HTTP_"": <TAB> <TAB> <TAB> # Hackish attempt at recovering original header names. <TAB> <TAB> <TAB> translatedHeader = cgiName[5:].replace(""_"", ""-"") <TAB> <TAB> <TAB> yield translatedHeader, environ[cgiName]",true,if cgiName in self . headerNames :,if cgiName in self . headerNames :,0.75,0.0
"def get_value_from_string(self, string_value): <TAB> """"""Return internal representation starting from CFN/user-input value."""""" <TAB> param_value = self.get_default_value() <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> string_value = str(string_value).strip() <TAB> <TAB> <TAB> if string_value != ""NONE"": <TAB> <TAB> <TAB> <TAB> param_value = int(string_value) <TAB> except ValueError: <TAB> <TAB> self.pcluster_config.warn( <TAB> <TAB> <TAB> ""Unable to convert the value '{0}' to an Integer. "" <TAB> <TAB> <TAB> ""Using default value for parameter '{1}'"".format(string_value, self.key) <TAB> <TAB> ) <TAB> return param_value",false,if string_value is not None :,if string_value :,0.05,0.0
"def monitor_filter(self): <TAB> """"""Return filtered service objects list"""""" <TAB> services = self.client.services.list(filters={""label"": ""com.ouroboros.enable""}) <TAB> monitored_services = [] <TAB> for service in services: <TAB> <TAB> ouro_label = service.attrs[""Spec""][""Labels""].get(""com.ouroboros.enable"") <TAB> <TAB> if not self.config.label_enable or ouro_label.lower() in [""true"", ""yes""]: <TAB> <TAB> <TAB> monitored_services.append(service) <TAB> self.data_manager.monitored_containers[self.socket] = len(monitored_services) <TAB> self.data_manager.set(self.socket) <TAB> return monitored_services",true,"if not self . config . label_enable or ouro_label . lower ( ) in [ ""true"" , ""yes"" ] :","if not self . config . label_enable or ouro_label . lower ( ) in [ ""true"" , ""yes"" ] :",0.75,0.0
"def nextEditable(self): <TAB> """"""Moves focus of the cursor to the next editable window"""""" <TAB> if self.currentEditable is None: <TAB> <TAB> if len(self._editableChildren): <TAB> <TAB> <TAB> self._currentEditableRef = self._editableChildren[0] <TAB> else: <TAB> <TAB> for ref in weakref.getweakrefs(self.currentEditable): <TAB> <TAB> <TAB> if ref in self._editableChildren: <TAB> <TAB> <TAB> <TAB> cei = self._editableChildren.index(ref) <TAB> <TAB> <TAB> <TAB> nei = cei + 1 <TAB> <TAB> <TAB> <TAB> if nei >= len(self._editableChildren): <TAB> <TAB> <TAB> <TAB> <TAB> nei = 0 <TAB> <TAB> <TAB> <TAB> self._currentEditableRef = self._editableChildren[nei] <TAB> return self.currentEditable",false,if nei >= len ( self . _editableChildren ) :,if ref in self . _editableChildren :,0.06,0.0
"def linkify_cm_by_tp(self, timeperiods): <TAB> for rm in self: <TAB> <TAB> mtp_name = rm.modulation_period.strip() <TAB> <TAB> # The new member list, in id <TAB> <TAB> mtp = timeperiods.find_by_name(mtp_name) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> err = ( <TAB> <TAB> <TAB> <TAB> ""Error: the business impact modulation '%s' got an unknown "" <TAB> <TAB> <TAB> <TAB> ""modulation_period '%s'"" % (rm.get_name(), mtp_name) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> rm.configuration_errors.append(err) <TAB> <TAB> rm.modulation_period = mtp",false,"if mtp_name != """" and mtp is None :",if mtp is None :,0.23,0.0
def close_open_fds(keep=None):  # noqa <TAB> keep = [maybe_fileno(f) for f in (keep or []) if maybe_fileno(f) is not None] <TAB> for fd in reversed(range(get_fdmax(default=2048))): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> os.close(fd) <TAB> <TAB> <TAB> except OSError as exc: <TAB> <TAB> <TAB> <TAB> if exc.errno != errno.EBADF: <TAB> <TAB> <TAB> <TAB> <TAB> raise,true,if fd not in keep :,if fd not in keep :,0.75,0.0
"def _append_child_from_unparsed_xml(father_node, unparsed_xml): <TAB> """"""Append child xml nodes to a node."""""" <TAB> dom_tree = parseString(unparsed_xml) <TAB> if dom_tree.hasChildNodes(): <TAB> <TAB> first_child = dom_tree.childNodes[0] <TAB> <TAB> if first_child.hasChildNodes(): <TAB> <TAB> <TAB> child_nodes = first_child.childNodes <TAB> <TAB> <TAB> for _ in range(len(child_nodes)): <TAB> <TAB> <TAB> <TAB> childNode = child_nodes.item(0) <TAB> <TAB> <TAB> <TAB> father_node.appendChild(childNode) <TAB> <TAB> <TAB> return <TAB> raise DistutilsInternalError( <TAB> <TAB> ""Could not Append append elements to "" ""the Windows msi descriptor."" <TAB> )",true,if first_child . hasChildNodes ( ) :,if first_child . hasChildNodes ( ) :,0.75,0.0
"def process_request(self, request): <TAB> for old, new in self.names_name: <TAB> <TAB> request.uri = request.uri.replace(old, new) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> body = six.ensure_str(request.body) <TAB> <TAB> <TAB> if old in body: <TAB> <TAB> <TAB> <TAB> request.body = body.replace(old, new) <TAB> return request",false,if is_text_payload ( request ) and request . body :,if request . body :,0.14,0.0
"def __init__(self, **options): <TAB> self.func_name_highlighting = get_bool_opt(options, ""func_name_highlighting"", True) <TAB> self.disabled_modules = get_list_opt(options, ""disabled_modules"", []) <TAB> self._functions = set() <TAB> if self.func_name_highlighting: <TAB> <TAB> from pygments.lexers._luabuiltins import MODULES <TAB> <TAB> for mod, func in MODULES.iteritems(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self._functions.update(func) <TAB> RegexLexer.__init__(self, **options)",false,if mod not in self . disabled_modules :,if mod in disabled_modules :,0.13,0.0
"def GetBestSizeForParentSize(self, parentSize): <TAB> """"""Finds the best width and height given the parent's width and height."""""" <TAB> if len(self.GetChildren()) == 1: <TAB> <TAB> win = self.GetChildren()[0] <TAB> <TAB> if isinstance(win, RibbonControl): <TAB> <TAB> <TAB> temp_dc = wx.ClientDC(self) <TAB> <TAB> <TAB> childSize = win.GetBestSizeForParentSize(parentSize) <TAB> <TAB> <TAB> clientParentSize = self._art.GetPanelClientSize( <TAB> <TAB> <TAB> <TAB> temp_dc, self, wx.Size(*parentSize), None <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> overallSize = self._art.GetPanelSize( <TAB> <TAB> <TAB> <TAB> temp_dc, self, wx.Size(*clientParentSize), None <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return overallSize <TAB> return self.GetSize()",true,"if isinstance ( win , RibbonControl ) :","if isinstance ( win , RibbonControl ) :",0.75,0.0
"def pid_from_name(name): <TAB> processes = [] <TAB> for pid in os.listdir(""/proc""): <TAB> <TAB> try: <TAB> <TAB> <TAB> pid = int(pid) <TAB> <TAB> <TAB> pname, cmdline = SunProcess._name_args(pid) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return pid <TAB> <TAB> <TAB> if name in cmdline.split("" "", 1)[0]: <TAB> <TAB> <TAB> <TAB> return pid <TAB> <TAB> except: <TAB> <TAB> <TAB> pass <TAB> raise ProcessException(""No process with such name: %s"" % name)",false,if name in pname :,if pname in processes :,0.29,0.0
"def __get_file_by_num(self, num, file_list, idx=0): <TAB> for element in file_list: <TAB> <TAB> if idx == num: <TAB> <TAB> <TAB> return element <TAB> <TAB> if element[3] and element[4]: <TAB> <TAB> <TAB> i = self.__get_file_by_num(num, element[3], idx + 1) <TAB> <TAB> <TAB> if not isinstance(i, int): <TAB> <TAB> <TAB> <TAB> return i <TAB> <TAB> <TAB> idx = i <TAB> <TAB> else: <TAB> <TAB> <TAB> idx += 1 <TAB> return idx",false,if element [ 3 ] and element [ 4 ] :,"if not isinstance ( i , int ) :",0.01,0.0
"def scan_block_scalar_indentation(self): <TAB> # See the specification for details. <TAB> chunks = [] <TAB> max_indent = 0 <TAB> end_mark = self.get_mark() <TAB> while self.peek() in "" \r\n\x85\u2028\u2029"": <TAB> <TAB> if self.peek() != "" "": <TAB> <TAB> <TAB> chunks.append(self.scan_line_break()) <TAB> <TAB> <TAB> end_mark = self.get_mark() <TAB> <TAB> else: <TAB> <TAB> <TAB> self.forward() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> max_indent = self.column <TAB> return chunks, max_indent, end_mark",false,if self . column > max_indent :,if max_indent > self . column :,0.1,0.0
"def ant_map(m): <TAB> tmp = ""rows %s\ncols %s\n"" % (len(m), len(m[0])) <TAB> players = {} <TAB> for row in m: <TAB> <TAB> tmp += ""m "" <TAB> <TAB> for col in row: <TAB> <TAB> <TAB> if col == LAND: <TAB> <TAB> <TAB> <TAB> tmp += ""."" <TAB> <TAB> <TAB> elif col == BARRIER: <TAB> <TAB> <TAB> <TAB> tmp += ""%"" <TAB> <TAB> <TAB> elif col == FOOD: <TAB> <TAB> <TAB> <TAB> tmp += ""*"" <TAB> <TAB> <TAB> elif col == UNSEEN: <TAB> <TAB> <TAB> <TAB> tmp += ""?"" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> players[col] = True <TAB> <TAB> <TAB> <TAB> tmp += chr(col + 97) <TAB> <TAB> tmp += ""\n"" <TAB> tmp = (""players %s\n"" % len(players)) + tmp <TAB> return tmp",true,elif col == FOOD :,elif col == FOOD :,1.0,0.0
"def prepare_data(entry): <TAB> branch_wise_entries = {} <TAB> gross_pay = 0 <TAB> for d in entry: <TAB> <TAB> gross_pay += d.gross_pay <TAB> <TAB> if branch_wise_entries.get(d.branch): <TAB> <TAB> <TAB> branch_wise_entries[d.branch][d.mode_of_payment] = d.net_pay <TAB> <TAB> else: <TAB> <TAB> <TAB> branch_wise_entries.setdefault(d.branch, {}).setdefault( <TAB> <TAB> <TAB> <TAB> d.mode_of_payment, d.net_pay <TAB> <TAB> <TAB> ) <TAB> return branch_wise_entries, gross_pay",true,if branch_wise_entries . get ( d . branch ) :,if branch_wise_entries . get ( d . branch ) :,0.75,0.0
"def __init__(self, uuid=None, cluster_state=None, children=None, **kwargs): <TAB> self.uuid = uuid <TAB> self.cluster_state = cluster_state <TAB> if self.cluster_state is not None: <TAB> <TAB> self.children = WeakSet( <TAB> <TAB> <TAB> self.cluster_state.tasks.get(task_id) <TAB> <TAB> <TAB> for task_id in children or () <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> ) <TAB> else: <TAB> <TAB> self.children = WeakSet() <TAB> self._serializer_handlers = { <TAB> <TAB> ""children"": self._serializable_children, <TAB> <TAB> ""root"": self._serializable_root, <TAB> <TAB> ""parent"": self._serializable_parent, <TAB> } <TAB> if kwargs: <TAB> <TAB> self.__dict__.update(kwargs)",false,if task_id in self . cluster_state . tasks,if task_id is not None,0.14,0.0
"def listdir(self, d): <TAB> try: <TAB> <TAB> return [ <TAB> <TAB> <TAB> p <TAB> <TAB> <TAB> for p in os.listdir(d) <TAB> <TAB> <TAB> if os.path.basename(p) != ""CVS"" and os.path.isdir(os.path.join(d, p)) <TAB> <TAB> ] <TAB> except OSError: <TAB> <TAB> return []",true,"if os . path . basename ( p ) != ""CVS"" and os . path . isdir ( os . path . join ( d , p ) )","if os . path . basename ( p ) != ""CVS"" and os . path . isdir ( os . path . join ( d , p ) )",1.0,0.0
"def send_packed_command(self, command, check_health=True): <TAB> if not self._sock: <TAB> <TAB> self.connect() <TAB> try: <TAB> <TAB> if isinstance(command, str): <TAB> <TAB> <TAB> command = [command] <TAB> <TAB> for item in command: <TAB> <TAB> <TAB> self._sock.sendall(item) <TAB> except socket.error as e: <TAB> <TAB> self.disconnect() <TAB> <TAB> if len(e.args) == 1: <TAB> <TAB> <TAB> _errno, errmsg = ""UNKNOWN"", e.args[0] <TAB> <TAB> else: <TAB> <TAB> <TAB> _errno, errmsg = e.args <TAB> <TAB> raise ConnectionError( <TAB> <TAB> <TAB> ""Error %s while writing to socket. %s."" % (_errno, errmsg) <TAB> <TAB> ) <TAB> except Exception: <TAB> <TAB> self.disconnect() <TAB> <TAB> raise",true,"if isinstance ( command , str ) :","if isinstance ( command , str ) :",0.75,0.0
"def run(self): <TAB> """"""Start the scanner"""""" <TAB> logging.info(""Dirscanner starting up"") <TAB> self.shutdown = False <TAB> while not self.shutdown: <TAB> <TAB> # Wait to be woken up or triggered <TAB> <TAB> with self.loop_condition: <TAB> <TAB> <TAB> self.loop_condition.wait(self.dirscan_speed) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.scan()",false,if self . dirscan_speed and not self . shutdown :,if self . scan_done :,0.09,0.0
"def __aexit__( <TAB> self, exc_type: type, exc_value: BaseException, tb: TracebackType ) -> None: <TAB> if exc_type is not None: <TAB> <TAB> await self.close() <TAB> await self._task <TAB> while not self._receive_queue.empty(): <TAB> <TAB> data = await self._receive_queue.get() <TAB> <TAB> if isinstance(data, bytes): <TAB> <TAB> <TAB> self.response_data.extend(data) <TAB> <TAB> elif not isinstance(data, HTTPDisconnect): <TAB> <TAB> <TAB> raise data",true,"elif not isinstance ( data , HTTPDisconnect ) :","elif not isinstance ( data , HTTPDisconnect ) :",0.75,0.0
"def f(msg): <TAB> text = extractor(msg) <TAB> for px in prefix: <TAB> <TAB> if text.startswith(px): <TAB> <TAB> <TAB> chunks = text[len(px) :].split(separator) <TAB> <TAB> <TAB> return chunks[0], (chunks[1:],) if pass_args else () <TAB> return ((None,),)  # to distinguish with `None`",true,if text . startswith ( px ) :,if text . startswith ( px ) :,0.75,0.0
"def _flatten(*args): <TAB> ahs = set() <TAB> if len(args) > 0: <TAB> <TAB> for item in args: <TAB> <TAB> <TAB> if type(item) is ActionHandle: <TAB> <TAB> <TAB> <TAB> ahs.add(item) <TAB> <TAB> <TAB> elif type(item) in (list, tuple, dict, set): <TAB> <TAB> <TAB> <TAB> for ah in item: <TAB> <TAB> <TAB> <TAB> <TAB> if type(ah) is not ActionHandle:  # pragma:nocover <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ActionManagerError(""Bad argument type %s"" % str(ah)) <TAB> <TAB> <TAB> <TAB> <TAB> ahs.add(ah) <TAB> <TAB> <TAB> else:  # pragma:nocover <TAB> <TAB> <TAB> <TAB> raise ActionManagerError(""Bad argument type %s"" % str(item)) <TAB> return ahs",true,"elif type ( item ) in ( list , tuple , dict , set ) :","elif type ( item ) in ( list , tuple , dict , set ) :",0.75,0.0
"def find_class(self, module, name): <TAB> # Subclasses may override this. <TAB> sys.audit(""pickle.find_class"", module, name) <TAB> if self.proto < 3 and self.fix_imports: <TAB> <TAB> if (module, name) in _compat_pickle.NAME_MAPPING: <TAB> <TAB> <TAB> module, name = _compat_pickle.NAME_MAPPING[(module, name)] <TAB> <TAB> elif module in _compat_pickle.IMPORT_MAPPING: <TAB> <TAB> <TAB> module = _compat_pickle.IMPORT_MAPPING[module] <TAB> __import__(module, level=0) <TAB> if self.proto >= 4: <TAB> <TAB> return _getattribute(sys.modules[module], name)[0] <TAB> else: <TAB> <TAB> return getattr(sys.modules[module], name)",true,elif module in _compat_pickle . IMPORT_MAPPING :,elif module in _compat_pickle . IMPORT_MAPPING :,0.75,0.0
"def _send_until_done(self, data): <TAB> while True: <TAB> <TAB> try: <TAB> <TAB> <TAB> return self.connection.send(data) <TAB> <TAB> except OpenSSL.SSL.WantWriteError: <TAB> <TAB> <TAB> wr = util.wait_for_write(self.socket, self.socket.gettimeout()) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise timeout() <TAB> <TAB> <TAB> continue <TAB> <TAB> except OpenSSL.SSL.SysCallError as e: <TAB> <TAB> <TAB> raise SocketError(str(e))",false,if not wr :,if wr is None :,0.05,0.0
"def __new__(cls, *args, **kwargs): <TAB> """"""Hack to ensure method defined as async are implemented as such."""""" <TAB> coroutines = inspect.getmembers(BaseManager, predicate=inspect.iscoroutinefunction) <TAB> for coroutine in coroutines: <TAB> <TAB> implemented_method = getattr(cls, coroutine[0]) <TAB> <TAB> if not inspect.iscoroutinefunction(implemented_method): <TAB> <TAB> <TAB> raise RuntimeError(""The method %s must be a coroutine"" % implemented_method) <TAB> return super().__new__(cls, *args, **kwargs)",true,if not inspect . iscoroutinefunction ( implemented_method ) :,if not inspect . iscoroutinefunction ( implemented_method ) :,0.75,0.0
"def add_directive(self, name, obj, content=None, arguments=None, **options): <TAB> if isinstance(obj, clstypes) and issubclass(obj, Directive): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ExtensionError( <TAB> <TAB> <TAB> <TAB> ""when adding directive classes, no "" ""additional arguments may be given"" <TAB> <TAB> <TAB> ) <TAB> <TAB> directives.register_directive(name, directive_dwim(obj)) <TAB> else: <TAB> <TAB> obj.content = content <TAB> <TAB> obj.arguments = arguments <TAB> <TAB> obj.options = options <TAB> <TAB> directives.register_directive(name, obj)",false,if content or arguments or options :,if arguments is None :,0.19,0.0
"def create(self, w): <TAB> if w.use_eventloop: <TAB> <TAB> # does not use dedicated timer thread. <TAB> <TAB> w.timer = _Timer(max_interval=10.0) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # Default Timer is set by the pool, as for example, the <TAB> <TAB> <TAB> # eventlet pool needs a custom timer implementation. <TAB> <TAB> <TAB> w.timer_cls = w.pool_cls.Timer <TAB> <TAB> w.timer = self.instantiate( <TAB> <TAB> <TAB> w.timer_cls, <TAB> <TAB> <TAB> max_interval=w.timer_precision, <TAB> <TAB> <TAB> on_error=self.on_timer_error, <TAB> <TAB> <TAB> on_tick=self.on_timer_tick, <TAB> <TAB> )",false,if not w . timer_cls :,if w . timer_precision is None :,0.05,0.0
"def _config(_molecule_file, request): <TAB> with open(_molecule_file) as f: <TAB> <TAB> d = util.safe_load(f) <TAB> if hasattr(request, ""param""): <TAB> <TAB> if isinstance(request.getfixturevalue(request.param), str): <TAB> <TAB> <TAB> d2 = util.safe_load(request.getfixturevalue(request.param)) <TAB> <TAB> else: <TAB> <TAB> <TAB> d2 = request.getfixturevalue(request.param) <TAB> <TAB> # print(100, d) <TAB> <TAB> # print(200, d2) <TAB> <TAB> d = util.merge_dicts(d, d2) <TAB> <TAB> # print(300, d) <TAB> return d",true,"if isinstance ( request . getfixturevalue ( request . param ) , str ) :","if isinstance ( request . getfixturevalue ( request . param ) , str ) :",1.0,0.0
"def _instrument_model(self, model): <TAB> for key, value in list( <TAB> <TAB> model.__dict__.items() <TAB> ):  # avoid ""dictionary keys changed during iteration"" <TAB> <TAB> if isinstance(value, tf.keras.layers.Layer): <TAB> <TAB> <TAB> new_layer = self._instrument(value) <TAB> <TAB> <TAB> if new_layer is not value: <TAB> <TAB> <TAB> <TAB> setattr(model, key, new_layer) <TAB> <TAB> elif isinstance(value, list): <TAB> <TAB> <TAB> for i, item in enumerate(value): <TAB> <TAB> <TAB> <TAB> if isinstance(item, tf.keras.layers.Layer): <TAB> <TAB> <TAB> <TAB> <TAB> value[i] = self._instrument(item) <TAB> return model",false,"if isinstance ( value , tf . keras . layers . Layer ) :","if isinstance ( item , tf . keras . layers . Layer ) :",0.64,0.0
"def is_accepted_drag_event(self, event): <TAB> if event.source() == self.table: <TAB> <TAB> return True <TAB> mime = event.mimeData() <TAB> if mime.hasUrls(): <TAB> <TAB> for url in mime.urls(): <TAB> <TAB> <TAB> # Only support local files. <TAB> <TAB> <TAB> if not url.isLocalFile(): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> # And only allow supported extensions. <TAB> <TAB> <TAB> filename = url.toLocalFile() <TAB> <TAB> <TAB> extension = os.path.splitext(filename)[1].lower()[1:] <TAB> <TAB> <TAB> if extension not in _dictionary_formats(): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> return True <TAB> return False",false,if not url . isLocalFile ( ) :,if extension not in _dictionary_formats ( ) :,0.14,0.0
"def explain(self, other, depth=0): <TAB> exp = super(UnionType, self).explain(other, depth) <TAB> for ndx, subtype in enumerate(self.params[""allowed_types""]): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> exp += ""\n{}and"".format("""".join([""\t""] * depth)) <TAB> <TAB> exp += ""\n"" + subtype.explain(other, depth=depth + 1) <TAB> return exp",true,if ndx > 0 :,if ndx > 0 :,0.75,0.0
"def test_k_is_stochastic_parameter(self): <TAB> # k as stochastic parameter <TAB> aug = iaa.MedianBlur(k=iap.Choice([3, 5])) <TAB> seen = [False, False] <TAB> for i in sm.xrange(100): <TAB> <TAB> observed = aug.augment_image(self.base_img) <TAB> <TAB> if np.array_equal(observed, self.blur3x3): <TAB> <TAB> <TAB> seen[0] += True <TAB> <TAB> elif np.array_equal(observed, self.blur5x5): <TAB> <TAB> <TAB> seen[1] += True <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception(""Unexpected result in MedianBlur@2"") <TAB> <TAB> if all(seen): <TAB> <TAB> <TAB> break <TAB> assert np.all(seen)",false,"elif np . array_equal ( observed , self . blur5x5 ) :","if np . array_equal ( observed , self . blur3x3 ) :",0.34,0.0
"def test_get_message(self): <TAB> async with self.chat_client: <TAB> <TAB> await self._create_thread() <TAB> <TAB> async with self.chat_thread_client: <TAB> <TAB> <TAB> message_id = await self._send_message() <TAB> <TAB> <TAB> message = await self.chat_thread_client.get_message(message_id) <TAB> <TAB> <TAB> assert message.id == message_id <TAB> <TAB> <TAB> assert message.type == ChatMessageType.TEXT <TAB> <TAB> <TAB> assert message.content.message == ""hello world"" <TAB> <TAB> # delete chat threads <TAB> <TAB> if not self.is_playback(): <TAB> <TAB> <TAB> await self.chat_client.delete_chat_thread(self.thread_id)",true,if not self . is_playback ( ) :,if not self . is_playback ( ) :,0.75,0.0
"def do_write_property(self, device, callback=None): <TAB> try: <TAB> <TAB> iocb = ( <TAB> <TAB> <TAB> device <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> else self.form_iocb(device, request_type=""writeProperty"") <TAB> <TAB> ) <TAB> <TAB> deferred(self.request_io, iocb) <TAB> <TAB> self.requests_in_progress.update({iocb: {""callback"": callback}}) <TAB> <TAB> iocb.add_callback(self.__general_cb) <TAB> except Exception as error: <TAB> <TAB> log.exception(""exception: %r"", error)",false,"if isinstance ( device , IOCB )",if device,0.02,0.0
"def fit(self, dataset, force_retrain): <TAB> if force_retrain: <TAB> <TAB> self.sub_unit_1[""fitted""] = True <TAB> <TAB> self.sub_unit_1[""calls""] += 1 <TAB> <TAB> self.sub_unit_2[""fitted""] = True <TAB> <TAB> self.sub_unit_2[""calls""] += 1 <TAB> else: <TAB> <TAB> if not self.sub_unit_1[""fitted""]: <TAB> <TAB> <TAB> self.sub_unit_1[""fitted""] = True <TAB> <TAB> <TAB> self.sub_unit_1[""calls""] += 1 <TAB> <TAB> if not self.sub_unit_2[""fitted""]: <TAB> <TAB> <TAB> self.sub_unit_2[""fitted""] = True <TAB> <TAB> <TAB> self.sub_unit_2[""calls""] += 1 <TAB> return self",false,"if not self . sub_unit_2 [ ""fitted"" ] :","if not self . sub_unit_1 [ ""fitted"" ] :",0.55,0.0
"def _insert_with_loop(self): <TAB> id_list = [] <TAB> last_id = None <TAB> return_id_list = self._return_id_list <TAB> for row in self._rows: <TAB> <TAB> last_id = InsertQuery(self.model_class, row).upsert(self._upsert).execute() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> id_list.append(last_id) <TAB> if return_id_list: <TAB> <TAB> return id_list <TAB> else: <TAB> <TAB> return last_id",false,if return_id_list :,if last_id :,0.32,0.0
"def merge_block(self): <TAB> """"""merges a block in the map"""""" <TAB> for i in range(self.block.x): <TAB> <TAB> for j in range(self.block.x): <TAB> <TAB> <TAB> c = self.block.get(i, j) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.map[(i + self.block.pos.x, j + self.block.pos.y)] = c",false,if c :,if c is not None :,0.09,0.0
"def configure_plex(config): <TAB> core.PLEX_SSL = int(config[""Plex""][""plex_ssl""]) <TAB> core.PLEX_HOST = config[""Plex""][""plex_host""] <TAB> core.PLEX_PORT = config[""Plex""][""plex_port""] <TAB> core.PLEX_TOKEN = config[""Plex""][""plex_token""] <TAB> plex_section = config[""Plex""][""plex_sections""] or [] <TAB> if plex_section: <TAB> <TAB> if isinstance(plex_section, list): <TAB> <TAB> <TAB> plex_section = "","".join(plex_section)  # fix in case this imported as list. <TAB> <TAB> plex_section = [tuple(item.split("","")) for item in plex_section.split(""|"")] <TAB> core.PLEX_SECTION = plex_section",true,"if isinstance ( plex_section , list ) :","if isinstance ( plex_section , list ) :",0.75,0.0
"def select(self): <TAB> e = xlib.XEvent() <TAB> while xlib.XPending(self._display): <TAB> <TAB> xlib.XNextEvent(self._display, e) <TAB> <TAB> # Key events are filtered by the xlib window event <TAB> <TAB> # handler so they get a shot at the prefiltered event. <TAB> <TAB> if e.xany.type not in (xlib.KeyPress, xlib.KeyRelease): <TAB> <TAB> <TAB> if xlib.XFilterEvent(e, e.xany.window): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> dispatch = self._window_map[e.xany.window] <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> continue <TAB> <TAB> dispatch(e)",false,"if e . xany . type not in ( xlib . KeyPress , xlib . KeyRelease ) :","if xlib . XFilterEvent ( e , e . xany . window ) :",0.39,0.0
"def format_message(self): <TAB> bits = [self.message] <TAB> if self.possibilities: <TAB> <TAB> if len(self.possibilities) == 1: <TAB> <TAB> <TAB> bits.append(""Did you mean %s?"" % self.possibilities[0]) <TAB> <TAB> else: <TAB> <TAB> <TAB> possibilities = sorted(self.possibilities) <TAB> <TAB> <TAB> bits.append(""(Possible options: %s)"" % "", "".join(possibilities)) <TAB> return ""  "".join(bits)",true,if len ( self . possibilities ) == 1 :,if len ( self . possibilities ) == 1 :,0.75,0.0
"def _collect_logs(model): <TAB> page_token = None <TAB> all_logs = [] <TAB> while True: <TAB> <TAB> paginated_logs = model.lookup_logs(now, later, page_token=page_token) <TAB> <TAB> page_token = paginated_logs.next_page_token <TAB> <TAB> all_logs.extend(paginated_logs.logs) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> return all_logs",false,if page_token is None :,if not paginated_logs :,0.04,0.0
"def run(self): <TAB> while True: <TAB> <TAB> context_id_list_tuple = self._inflated_addresses.get(block=True) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> c_id, inflated_address_list = context_id_list_tuple <TAB> <TAB> inflated_value_map = dict(inflated_address_list) <TAB> <TAB> if c_id in self._contexts: <TAB> <TAB> <TAB> self._contexts[c_id].set_from_tree(inflated_value_map)",false,if context_id_list_tuple is _SHUTDOWN_SENTINEL :,if not context_id_list_tuple :,0.04,0.0
"def _setup_prefix(self): <TAB> # we assume here that our metadata may be nested inside a ""basket"" <TAB> # of multiple eggs; that's why we use module_path instead of .archive <TAB> path = self.module_path <TAB> old = None <TAB> while path != old: <TAB> <TAB> if path.lower().endswith("".egg""): <TAB> <TAB> <TAB> self.egg_name = os.path.basename(path) <TAB> <TAB> <TAB> self.egg_info = os.path.join(path, ""EGG-INFO"") <TAB> <TAB> <TAB> self.egg_root = path <TAB> <TAB> <TAB> break <TAB> <TAB> old = path <TAB> <TAB> path, base = os.path.split(path)",true,"if path . lower ( ) . endswith ( "".egg"" ) :","if path . lower ( ) . endswith ( "".egg"" ) :",0.75,0.0
"def get_filename(self, prompt): <TAB> okay = False <TAB> val = """" <TAB> while not okay: <TAB> <TAB> val = raw_input(""%s: %s"" % (prompt, val)) <TAB> <TAB> val = os.path.expanduser(val) <TAB> <TAB> if os.path.isfile(val): <TAB> <TAB> <TAB> okay = True <TAB> <TAB> elif os.path.isdir(val): <TAB> <TAB> <TAB> path = val <TAB> <TAB> <TAB> val = self.choose_from_list(os.listdir(path)) <TAB> <TAB> <TAB> if val: <TAB> <TAB> <TAB> <TAB> val = os.path.join(path, val) <TAB> <TAB> <TAB> <TAB> okay = True <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> val = """" <TAB> <TAB> else: <TAB> <TAB> <TAB> print(""Invalid value: %s"" % val) <TAB> <TAB> <TAB> val = """" <TAB> return val",false,elif os . path . isdir ( val ) :,if os . path . isfile ( val ) :,0.26,0.0
"def versions(self, sitename, data): <TAB> # handle the query of type {""query"": '{""key"": ""/books/ia:foo00bar"", ...}} <TAB> if ""query"" in data: <TAB> <TAB> q = json.loads(data[""query""]) <TAB> <TAB> itemid = self._get_itemid(q.get(""key"")) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> key = q[""key""] <TAB> <TAB> <TAB> return json.dumps([self.dummy_edit(key)]) <TAB> # if not just go the default way <TAB> return ConnectionMiddleware.versions(self, sitename, data)",true,if itemid :,if itemid :,0.53,0.0
"def read_stanza(self): <TAB> while True: <TAB> <TAB> try: <TAB> <TAB> <TAB> stanza_end = self._buffer.index(b""\n"") <TAB> <TAB> <TAB> stanza = self.decoder.decode(self._buffer[:stanza_end]) <TAB> <TAB> <TAB> self._buffer = self._buffer[stanza_end + 1 :] <TAB> <TAB> <TAB> colon = stanza.index("":"") <TAB> <TAB> <TAB> return stanza[:colon], stanza[colon + 1 :] <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> bytes = self.read_bytes() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self._buffer += bytes",true,if not bytes :,if not bytes :,0.75,0.0
def decodeattrs(attrs): <TAB> names = [] <TAB> for bit in range(16): <TAB> <TAB> mask = 1 << bit <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if attrnames.has_key(mask): <TAB> <TAB> <TAB> <TAB> names.append(attrnames[mask]) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> names.append(hex(mask)) <TAB> return names,false,if attrs & mask :,if mask in attrs :,0.04,0.0
"def _set_http_cookie(): <TAB> if conf.cookie: <TAB> <TAB> if isinstance(conf.cookie, dict): <TAB> <TAB> <TAB> conf.http_headers[HTTP_HEADER.COOKIE] = ""; "".join( <TAB> <TAB> <TAB> <TAB> map(lambda x: ""="".join(x), conf.cookie.items()) <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> conf.http_headers[HTTP_HEADER.COOKIE] = conf.cookie",true,"if isinstance ( conf . cookie , dict ) :","if isinstance ( conf . cookie , dict ) :",0.75,0.0
"def __ne__(self, other): <TAB> if isinstance(other, WeakMethod): <TAB> <TAB> if not self._alive or not other._alive: <TAB> <TAB> <TAB> return self is not other <TAB> <TAB> return weakref.ref.__ne__(self, other) or self._func_ref != other._func_ref <TAB> return True",true,if not self . _alive or not other . _alive :,if not self . _alive or not other . _alive :,1.0,0.0
"def update_unread(self, order_id, reset=False): <TAB> conn = Database.connect_database(self.PATH) <TAB> with conn: <TAB> <TAB> cursor = conn.cursor() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> cursor.execute( <TAB> <TAB> <TAB> <TAB> """"""UPDATE sales SET unread = unread + 1 WHERE id=?;"""""", (order_id,) <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> cursor.execute(""""""UPDATE sales SET unread=0 WHERE id=?;"""""", (order_id,)) <TAB> <TAB> conn.commit() <TAB> conn.close()",false,if reset is False :,if reset :,0.07,0.0
"def _get_field_value(self, test, key, match): <TAB> if test.ver == ofproto_v1_0.OFP_VERSION: <TAB> <TAB> members = inspect.getmembers(match) <TAB> <TAB> for member in members: <TAB> <TAB> <TAB> if member[0] == key: <TAB> <TAB> <TAB> <TAB> field_value = member[1] <TAB> <TAB> <TAB> elif member[0] == ""wildcards"": <TAB> <TAB> <TAB> <TAB> wildcards = member[1] <TAB> <TAB> if key == ""nw_src"": <TAB> <TAB> <TAB> field_value = test.nw_src_to_str(wildcards, field_value) <TAB> <TAB> elif key == ""nw_dst"": <TAB> <TAB> <TAB> field_value = test.nw_dst_to_str(wildcards, field_value) <TAB> else: <TAB> <TAB> field_value = match[key] <TAB> return field_value",false,"elif key == ""nw_dst"" :","elif member [ 0 ] == ""wildcards"" :",0.34,0.0
"def nested_filter(self, items, mask): <TAB> keep_current = self.current_mask(mask) <TAB> keep_nested_lookup = self.nested_masks(mask) <TAB> for k, v in items: <TAB> <TAB> keep_nested = keep_nested_lookup.get(k) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if keep_nested is not None: <TAB> <TAB> <TAB> <TAB> if isinstance(v, dict): <TAB> <TAB> <TAB> <TAB> <TAB> yield k, dict(self.nested_filter(v.items(), keep_nested)) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> yield k, v",false,if k in keep_current :,if keep_current is not None and k not in keep_current :,0.1,0.0
"def goToPrevMarkedHeadline(self, event=None): <TAB> """"""Select the next marked node."""""" <TAB> c = self <TAB> p = c.p <TAB> if not p: <TAB> <TAB> return <TAB> p.moveToThreadBack() <TAB> wrapped = False <TAB> while 1: <TAB> <TAB> if p and p.isMarked(): <TAB> <TAB> <TAB> break <TAB> <TAB> elif p: <TAB> <TAB> <TAB> p.moveToThreadBack() <TAB> <TAB> elif wrapped: <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> wrapped = True <TAB> <TAB> <TAB> p = c.rootPosition() <TAB> if not p: <TAB> <TAB> g.blue(""done"") <TAB> c.treeSelectHelper(p)  # Sets focus.",false,if p and p . isMarked ( ) :,elif wrapped :,0.01,0.0
"def sample(self, **config): <TAB> """"""Sample a configuration from this search space."""""" <TAB> ret = {} <TAB> ret.update(self.data) <TAB> kwspaces = self.kwspaces <TAB> kwspaces.update(config) <TAB> striped_keys = [k.split(SPLITTER)[0] for k in config.keys()] <TAB> for k, v in kwspaces.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if isinstance(v, NestedSpace): <TAB> <TAB> <TAB> <TAB> sub_config = _strip_config_space(config, prefix=k) <TAB> <TAB> <TAB> <TAB> ret[k] = v.sample(**sub_config) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> ret[k] = v <TAB> return ret",true,if k in striped_keys :,if k in striped_keys :,0.75,0.0
"def update_gradients_full(self, dL_dK, X, X2=None): <TAB> if self.ARD: <TAB> <TAB> phi1 = self.phi(X) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.variance.gradient = np.einsum(""ij,iq,jq->q"", dL_dK, phi1, phi1) <TAB> <TAB> else: <TAB> <TAB> <TAB> phi2 = self.phi(X2) <TAB> <TAB> <TAB> self.variance.gradient = np.einsum(""ij,iq,jq->q"", dL_dK, phi1, phi2) <TAB> else: <TAB> <TAB> self.variance.gradient = np.einsum(""ij,ij"", dL_dK, self._K(X, X2)) * self.beta",false,if X2 is None or X is X2 :,if X2 is None :,0.16,0.0
"def post(self): <TAB> host_json = json.loads(request.data) <TAB> host_os = host_json.get(""os"") <TAB> if host_os: <TAB> <TAB> result = get_monkey_executable(host_os.get(""type""), host_os.get(""machine"")) <TAB> <TAB> if result: <TAB> <TAB> <TAB> # change resulting from new base path <TAB> <TAB> <TAB> executable_filename = result[""filename""] <TAB> <TAB> <TAB> real_path = MonkeyDownload.get_executable_full_path(executable_filename) <TAB> <TAB> <TAB> if os.path.isfile(real_path): <TAB> <TAB> <TAB> <TAB> result[""size""] = os.path.getsize(real_path) <TAB> <TAB> <TAB> <TAB> return result <TAB> return {}",true,if os . path . isfile ( real_path ) :,if os . path . isfile ( real_path ) :,0.75,0.0
"def _encode_data( <TAB> self, <TAB> data, <TAB> content_type, ): <TAB> if content_type is MULTIPART_CONTENT: <TAB> <TAB> return encode_multipart(BOUNDARY, data) <TAB> else: <TAB> <TAB> # Encode the content so that the byte representation is correct. <TAB> <TAB> match = CONTENT_TYPE_RE.match(content_type) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> charset = match.group(1) <TAB> <TAB> else: <TAB> <TAB> <TAB> charset = settings.DEFAULT_CHARSET <TAB> <TAB> return force_bytes(data, encoding=charset)",true,if match :,if match :,0.53,0.0
"def _merge_scientific_float_tokens(tokens: Iterable[str]) -> List[str]: <TAB> tokens = list(tokens) <TAB> i = 0 <TAB> while ""e"" in tokens[i + 1 :]: <TAB> <TAB> i = tokens.index(""e"", i + 1) <TAB> <TAB> s = i - 1 <TAB> <TAB> e = i + 1 <TAB> <TAB> if not re.match(""[0-9]"", str(tokens[s])): <TAB> <TAB> <TAB> continue <TAB> <TAB> if re.match(""[+-]"", str(tokens[e])): <TAB> <TAB> <TAB> e += 1 <TAB> <TAB> if re.match(""[0-9]"", str(tokens[e])): <TAB> <TAB> <TAB> e += 1 <TAB> <TAB> <TAB> tokens[s:e] = ["""".join(tokens[s:e])] <TAB> <TAB> <TAB> i -= 1 <TAB> return tokens",false,"if re . match ( ""[0-9]"" , str ( tokens [ e ] ) ) :","if re . match ( ""[+-]"" , str ( tokens [ e ] ) ) :",0.66,0.0
"def convert_with_key(self, key, value, replace=True): <TAB> result = self.configurator.convert(value) <TAB> # If the converted value is different, save for next time <TAB> if value is not result: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self[key] = result <TAB> <TAB> if type(result) in (ConvertingDict, ConvertingList, ConvertingTuple): <TAB> <TAB> <TAB> result.parent = self <TAB> <TAB> <TAB> result.key = key <TAB> return result",true,if replace :,if replace :,0.53,0.0
"def OnListEndLabelEdit(self, std, extra): <TAB> item = extra[0] <TAB> text = item[4] <TAB> if text is None: <TAB> <TAB> return <TAB> item_id = self.GetItem(item[0])[6] <TAB> from bdb import Breakpoint <TAB> for bplist in Breakpoint.bplist.itervalues(): <TAB> <TAB> for bp in bplist: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if text.strip().lower() == ""none"": <TAB> <TAB> <TAB> <TAB> <TAB> text = None <TAB> <TAB> <TAB> <TAB> bp.cond = text <TAB> <TAB> <TAB> <TAB> break <TAB> self.RespondDebuggerData()",false,if id ( bp ) == item_id :,if bp . cond == item_id :,0.08,0.0
"def add(self, url: str, future_nzo: NzbObject, when: Optional[int] = None): <TAB> """"""Add an URL to the URLGrabber queue, 'when' is seconds from now"""""" <TAB> if future_nzo and when: <TAB> <TAB> # Always increase counter <TAB> <TAB> future_nzo.url_tries += 1 <TAB> <TAB> # Too many tries? Cancel <TAB> <TAB> if future_nzo.url_tries > cfg.max_url_retries(): <TAB> <TAB> <TAB> self.fail_to_history(future_nzo, url, T(""Maximum retries"")) <TAB> <TAB> <TAB> return <TAB> <TAB> future_nzo.url_wait = time.time() + when <TAB> self.queue.put((url, future_nzo))",true,if future_nzo . url_tries > cfg . max_url_retries ( ) :,if future_nzo . url_tries > cfg . max_url_retries ( ) :,0.75,0.0
def _is_datetime_string(series): <TAB> if series.dtype == object: <TAB> <TAB> not_numeric = False <TAB> <TAB> try: <TAB> <TAB> <TAB> pd.to_numeric(series) <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> not_numeric = True <TAB> <TAB> datetime_col = None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> datetime_col = pd.to_datetime(series) <TAB> <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> if datetime_col is not None: <TAB> <TAB> <TAB> return True <TAB> return False,true,if not_numeric :,if not_numeric :,0.53,0.0
"def _getEventAndObservers(self, event): <TAB> if isinstance(event, xpath.XPathQuery): <TAB> <TAB> # Treat as xpath <TAB> <TAB> observers = self._xpathObservers <TAB> else: <TAB> <TAB> if self.prefix == event[: len(self.prefix)]: <TAB> <TAB> <TAB> # Treat as event <TAB> <TAB> <TAB> observers = self._eventObservers <TAB> <TAB> else: <TAB> <TAB> <TAB> # Treat as xpath <TAB> <TAB> <TAB> event = xpath.internQuery(event) <TAB> <TAB> <TAB> observers = self._xpathObservers <TAB> return event, observers",true,if self . prefix == event [ : len ( self . prefix ) ] :,if self . prefix == event [ : len ( self . prefix ) ] :,1.0,0.0
"def test_wildcard_import(): <TAB> bonobo = __import__(""bonobo"") <TAB> assert bonobo.__version__ <TAB> for name in dir(bonobo): <TAB> <TAB> # ignore attributes starting by underscores <TAB> <TAB> if name.startswith(""_""): <TAB> <TAB> <TAB> continue <TAB> <TAB> attr = getattr(bonobo, name) <TAB> <TAB> if inspect.ismodule(attr): <TAB> <TAB> <TAB> continue <TAB> <TAB> assert name in bonobo.__all__",true,if inspect . ismodule ( attr ) :,if inspect . ismodule ( attr ) :,0.75,0.0
"def relint_views(wid=None): <TAB> windows = [sublime.Window(wid)] if wid else sublime.windows() <TAB> for window in windows: <TAB> <TAB> for view in window.views(): <TAB> <TAB> <TAB> if view.buffer_id() in persist.assigned_linters and view.is_primary(): <TAB> <TAB> <TAB> <TAB> hit(view, ""relint_views"")",true,if view . buffer_id ( ) in persist . assigned_linters and view . is_primary ( ) :,if view . buffer_id ( ) in persist . assigned_linters and view . is_primary ( ) :,1.0,0.0
def _check_for_unknown_gender(self): <TAB> if self.obj.get_gender() == Person.UNKNOWN: <TAB> <TAB> d = GenderDialog(parent=self.window) <TAB> <TAB> gender = d.run() <TAB> <TAB> d.destroy() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.obj.set_gender(gender),false,if gender >= 0 :,if gender :,0.07,0.0
"def add_to_path(self, fnames): <TAB> """"""Add fnames to path"""""" <TAB> indexes = [] <TAB> for path in fnames: <TAB> <TAB> project = self.get_source_project(path) <TAB> <TAB> if project.add_to_pythonpath(path): <TAB> <TAB> <TAB> self.parent_widget.emit(SIGNAL(""pythonpath_changed()"")) <TAB> <TAB> <TAB> indexes.append(self.get_index(path)) <TAB> if indexes: <TAB> <TAB> self.reset_icon_provider() <TAB> <TAB> for index in indexes: <TAB> <TAB> <TAB> self.update(index)",true,if project . add_to_pythonpath ( path ) :,if project . add_to_pythonpath ( path ) :,0.75,0.0
"def validate(self, value): <TAB> if value.grid_id is not None: <TAB> <TAB> if not isinstance(value, self.proxy_class): <TAB> <TAB> <TAB> self.error(""FileField only accepts GridFSProxy values"") <TAB> <TAB> if not isinstance(value.grid_id, ObjectId): <TAB> <TAB> <TAB> self.error(""Invalid GridFSProxy value"")",true,"if not isinstance ( value . grid_id , ObjectId ) :","if not isinstance ( value . grid_id , ObjectId ) :",0.75,0.0
"def shortcut(self, input, ch_out, stride, name, if_first=False): <TAB> ch_in = input.shape[1] <TAB> if ch_in != ch_out or stride != 1: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return self.conv_bn_layer(input, ch_out, 1, stride, name=name) <TAB> <TAB> else: <TAB> <TAB> <TAB> return self.conv_bn_layer_new(input, ch_out, 1, stride, name=name) <TAB> else: <TAB> <TAB> return input",true,if if_first :,if if_first :,0.53,0.0
"def convert_path(ctx, tpath): <TAB> for points, code in tpath.iter_segments(): <TAB> <TAB> if code == Path.MOVETO: <TAB> <TAB> <TAB> ctx.move_to(*points) <TAB> <TAB> elif code == Path.LINETO: <TAB> <TAB> <TAB> ctx.line_to(*points) <TAB> <TAB> elif code == Path.CURVE3: <TAB> <TAB> <TAB> ctx.curve_to( <TAB> <TAB> <TAB> <TAB> points[0], points[1], points[0], points[1], points[2], points[3] <TAB> <TAB> <TAB> ) <TAB> <TAB> elif code == Path.CURVE4: <TAB> <TAB> <TAB> ctx.curve_to(*points) <TAB> <TAB> elif code == Path.CLOSEPOLY: <TAB> <TAB> <TAB> ctx.close_path()",false,elif code == Path . CURVE4 :,elif code == Path . LINETO :,0.57,0.0
"def _get_build_status(self, job_name, build_number): <TAB> try: <TAB> <TAB> build_info = self.server.get_build_info(job_name, build_number) <TAB> <TAB> if build_info[""building""]: <TAB> <TAB> <TAB> return ""building"" <TAB> <TAB> else: <TAB> <TAB> <TAB> return ""built"" <TAB> except jenkins.NotFoundException: <TAB> <TAB> return ""not found""",true,"if build_info [ ""building"" ] :","if build_info [ ""building"" ] :",0.75,0.0
"def _parse_param_value(name, datatype, default): <TAB> if datatype == ""bool"": <TAB> <TAB> if default.lower() == ""true"": <TAB> <TAB> <TAB> return True <TAB> <TAB> elif default.lower() == ""false"": <TAB> <TAB> <TAB> return False <TAB> <TAB> else: <TAB> <TAB> <TAB> _s = ""{}: Invalid default value '{}' for bool parameter {}"" <TAB> <TAB> <TAB> raise SyntaxError(_s.format(self.name, default, p)) <TAB> elif datatype == ""int"": <TAB> <TAB> if type(default) == int: <TAB> <TAB> <TAB> return default <TAB> <TAB> else: <TAB> <TAB> <TAB> return int(default, 0) <TAB> elif datatype == ""real"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return default <TAB> <TAB> else: <TAB> <TAB> <TAB> return float(default) <TAB> else: <TAB> <TAB> return str(default)",true,if type ( default ) == float :,if type ( default ) == float :,0.75,0.0
"def get_fills(self, exchange_order_id): <TAB> async with aiohttp.ClientSession() as client: <TAB> <TAB> response: aiohttp.ClientResponse = await client.get( <TAB> <TAB> <TAB> f""{BASE_URL}{FILLS_ROUTE}"", <TAB> <TAB> <TAB> params={""orderId"": exchange_order_id, ""limit"": 100}, <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> msg = await response.json() <TAB> <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> <TAB> msg = await response.text() <TAB> <TAB> <TAB> raise DydxAsyncAPIError(response.status, msg) <TAB> <TAB> return await response.json()",false,if response . status >= 300 :,if response . status == 200 :,0.47,0.0
"def semanticTags(self, semanticTags): <TAB> if semanticTags is None: <TAB> <TAB> self.__semanticTags = OrderedDict() <TAB> # check <TAB> for key, value in list(semanticTags.items()): <TAB> <TAB> if not isinstance(key, int): <TAB> <TAB> <TAB> raise TypeError(""At least one key is not a valid int position"") <TAB> <TAB> if not isinstance(value, list): <TAB> <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> <TAB> ""At least one value of the provided dict is not a list of string"" <TAB> <TAB> <TAB> ) <TAB> <TAB> for x in value: <TAB> <TAB> <TAB> if not isinstance(x, str): <TAB> <TAB> <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> <TAB> <TAB> ""At least one value of the provided dict is not a list of string"" <TAB> <TAB> <TAB> <TAB> ) <TAB> self.__semanticTags = semanticTags",false,"if not isinstance ( x , str ) :","if not isinstance ( key , int ) :",0.44,0.0
"def start_cutting_tool(self, event, axis, direction): <TAB> toggle = event.EventObject <TAB> self.cutting = toggle.Value <TAB> if toggle.Value: <TAB> <TAB> # Disable the other toggles <TAB> <TAB> for child in self.cutsizer.Children: <TAB> <TAB> <TAB> child = child.Window <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> child.Value = False <TAB> <TAB> self.cutting_axis = axis <TAB> <TAB> self.cutting_direction = direction <TAB> else: <TAB> <TAB> self.cutting_axis = None <TAB> <TAB> self.cutting_direction = None <TAB> self.cutting_dist = None",false,if child != toggle :,if child . Value == toggle :,0.07,0.0
"def decoration_helper(self, patched, args, keywargs): <TAB> extra_args = [] <TAB> with contextlib.ExitStack() as exit_stack: <TAB> <TAB> for patching in patched.patchings: <TAB> <TAB> <TAB> arg = exit_stack.enter_context(patching) <TAB> <TAB> <TAB> if patching.attribute_name is not None: <TAB> <TAB> <TAB> <TAB> keywargs.update(arg) <TAB> <TAB> <TAB> elif patching.new is DEFAULT: <TAB> <TAB> <TAB> <TAB> extra_args.append(arg) <TAB> <TAB> args += tuple(extra_args) <TAB> <TAB> yield (args, keywargs)",true,elif patching . new is DEFAULT :,elif patching . new is DEFAULT :,0.75,0.0
def decodeattrs(attrs): <TAB> names = [] <TAB> for bit in range(16): <TAB> <TAB> mask = 1 << bit <TAB> <TAB> if attrs & mask: <TAB> <TAB> <TAB> if attrnames.has_key(mask): <TAB> <TAB> <TAB> <TAB> names.append(attrnames[mask]) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> names.append(hex(mask)) <TAB> return names,true,if attrnames . has_key ( mask ) :,if attrnames . has_key ( mask ) :,0.75,0.0
"def pytest_collection_modifyitems(items): <TAB> for item in items: <TAB> <TAB> if item.nodeid.startswith(""tests/params""): <TAB> <TAB> <TAB> if ""stage"" not in item.keywords: <TAB> <TAB> <TAB> <TAB> item.add_marker(pytest.mark.stage(""unit"")) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> item.add_marker(pytest.mark.init(rng_seed=123))",true,"if ""init"" not in item . keywords :","if ""init"" not in item . keywords :",0.75,0.0
"def handle_socket(self, request): <TAB> conn = request.connection <TAB> while True: <TAB> <TAB> chunk = conn.recv(4) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> slen = struct.unpack("">L"", chunk)[0] <TAB> <TAB> chunk = conn.recv(slen) <TAB> <TAB> while len(chunk) < slen: <TAB> <TAB> <TAB> chunk = chunk + conn.recv(slen - len(chunk)) <TAB> <TAB> obj = pickle.loads(chunk) <TAB> <TAB> record = logging.makeLogRecord(obj) <TAB> <TAB> self.log_output += record.msg + ""\n"" <TAB> <TAB> self.handled.release()",false,if len ( chunk ) < 4 :,if not chunk :,0.02,0.0
"def on_source_foreach(self, model, path, iter, id): <TAB> m_id = model.get_value(iter, self.COLUMN_ID) <TAB> if m_id == id: <TAB> <TAB> if self._foreach_mode == ""get"": <TAB> <TAB> <TAB> self._foreach_take = model.get_value(iter, self.COLUMN_ENABLED) <TAB> <TAB> elif self._foreach_mode == ""set"": <TAB> <TAB> <TAB> self._foreach_take = iter",false,"elif self . _foreach_mode == ""set"" :","if self . _foreach_mode == ""get"" :",0.22,0.0
"def parts(): <TAB> for l in lists.leaves: <TAB> <TAB> head_name = l.get_head_name() <TAB> <TAB> if head_name == ""System`List"": <TAB> <TAB> <TAB> yield l.leaves <TAB> <TAB> elif head_name != ""System`Missing"": <TAB> <TAB> <TAB> raise MessageException(""Catenate"", ""invrp"", l)",true,"elif head_name != ""System`Missing"" :","elif head_name != ""System`Missing"" :",0.75,0.0
"def __fill_counter_values(self, command: str): <TAB> result = [] <TAB> regex = r""(item[0-9]+\.counter_value)"" <TAB> for token in re.split(regex, command): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> result.append(str(self.simulator_config.item_dict[token].value)) <TAB> <TAB> <TAB> except (KeyError, ValueError, AttributeError): <TAB> <TAB> <TAB> <TAB> logger.error(""Could not get counter value for "" + token) <TAB> <TAB> else: <TAB> <TAB> <TAB> result.append(token) <TAB> return """".join(result)",false,"if re . match ( regex , token ) is not None :",if token in self . simulator_config . item_dict :,0.09,0.0
"def IMPORTFROM(self, node): <TAB> if node.module == ""__future__"": <TAB> <TAB> if not self.futuresAllowed: <TAB> <TAB> <TAB> self.report(messages.LateFutureImport, node, [n.name for n in node.names]) <TAB> else: <TAB> <TAB> self.futuresAllowed = False <TAB> for alias in node.names: <TAB> <TAB> if alias.name == ""*"": <TAB> <TAB> <TAB> self.scope.importStarred = True <TAB> <TAB> <TAB> self.report(messages.ImportStarUsed, node, node.module) <TAB> <TAB> <TAB> continue <TAB> <TAB> name = alias.asname or alias.name <TAB> <TAB> importation = Importation(name, node) <TAB> <TAB> if node.module == ""__future__"": <TAB> <TAB> <TAB> importation.used = (self.scope, node) <TAB> <TAB> self.addBinding(node, importation)",false,"if node . module == ""__future__"" :","if alias . name == ""*"" :",0.27,0.0
"def _split_batch_list(args, batch_list): <TAB> new_list = [] <TAB> for batch in batch_list.batches: <TAB> <TAB> new_list.append(batch) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield batch_pb2.BatchList(batches=new_list) <TAB> <TAB> <TAB> new_list = [] <TAB> if new_list: <TAB> <TAB> yield batch_pb2.BatchList(batches=new_list)",false,if len ( new_list ) == args . batch_size_limit :,if len ( new_list ) == batch_list . size :,0.53,0.0
"def get_branch_or_use_upstream(branch_name, arg, repo): <TAB> if not branch_name:  # use upstream branch <TAB> <TAB> current_b = repo.current_branch <TAB> <TAB> upstream_b = current_b.upstream <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""No {0} branch specified and the current branch has no upstream "" <TAB> <TAB> <TAB> <TAB> ""branch set"".format(arg) <TAB> <TAB> <TAB> ) <TAB> <TAB> ret = current_b.upstream <TAB> else: <TAB> <TAB> ret = get_branch(branch_name, repo) <TAB> return ret",false,if not upstream_b :,if upstream_b == arg :,0.05,0.0
"def __init__(self, **settings): <TAB> default_settings = self.get_default_settings() <TAB> for name, value in default_settings.items(): <TAB> <TAB> if not hasattr(self, name): <TAB> <TAB> <TAB> setattr(self, name, value) <TAB> for name, value in settings.items(): <TAB> <TAB> if name not in default_settings: <TAB> <TAB> <TAB> raise ImproperlyConfigured( <TAB> <TAB> <TAB> <TAB> ""Invalid setting '{}' for {}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> name, <TAB> <TAB> <TAB> <TAB> <TAB> self.__class__.__name__, <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> setattr(self, name, value)",true,"if not hasattr ( self , name ) :","if not hasattr ( self , name ) :",0.75,0.0
"def _declare(self, name, obj, included=False, quals=0): <TAB> if name in self._declarations: <TAB> <TAB> prevobj, prevquals = self._declarations[name] <TAB> <TAB> if prevobj is obj and prevquals == quals: <TAB> <TAB> <TAB> return <TAB> <TAB> if not self._override: <TAB> <TAB> <TAB> raise api.FFIError( <TAB> <TAB> <TAB> <TAB> ""multiple declarations of %s (for interactive usage, "" <TAB> <TAB> <TAB> <TAB> ""try cdef(xx, override=True))"" % (name,) <TAB> <TAB> <TAB> ) <TAB> assert ""__dotdotdot__"" not in name.split() <TAB> self._declarations[name] = (obj, quals) <TAB> if included: <TAB> <TAB> self._included_declarations.add(obj)",true,if not self . _override :,if not self . _override :,0.75,0.0
"def include_file(name, fdir=tmp_dir, b64=False): <TAB> try: <TAB> <TAB> if fdir is None: <TAB> <TAB> <TAB> fdir = """" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> with io.open(os.path.join(fdir, name), ""rb"") as f: <TAB> <TAB> <TAB> <TAB> return base64.b64encode(f.read()).decode(""utf-8"") <TAB> <TAB> else: <TAB> <TAB> <TAB> with io.open(os.path.join(fdir, name), ""r"", encoding=""utf-8"") as f: <TAB> <TAB> <TAB> <TAB> return f.read() <TAB> except (OSError, IOError) as e: <TAB> <TAB> logger.error(""Could not include file '{}': {}"".format(name, e))",true,if b64 :,if b64 :,0.53,0.0
"def to_raw_json(self): <TAB> parts = {} <TAB> for p in self.parts: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> parts[p[0]] = [] <TAB> <TAB> parts[p[0]].append({""value"": p[2], ""parameters"": p[1]}) <TAB> children = [x.to_raw_json() for x in self.children] <TAB> return { <TAB> <TAB> ""type"": self.__class__.__name__, <TAB> <TAB> ""children"": children, <TAB> <TAB> ""parts"": parts, <TAB> }",true,if p [ 0 ] not in parts :,if p [ 0 ] not in parts :,0.75,0.0
"def process_output( <TAB> output: str, filename: str, start_line: int ) -> Tuple[Optional[str], bool]: <TAB> error_found = False <TAB> for line in output.splitlines(): <TAB> <TAB> t = get_revealed_type(line, filename, start_line) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return t, error_found <TAB> <TAB> elif ""error:"" in line: <TAB> <TAB> <TAB> error_found = True <TAB> return None, True  # finding no reveal_type is an error",false,if t :,if t is not None :,0.09,0.0
"def __init__( <TAB> self, resize_keyboard=None, one_time_keyboard=None, selective=None, row_width=3 ): <TAB> if row_width > self.max_row_keys: <TAB> <TAB> # Todo: Will be replaced with Exception in future releases <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> logger.error( <TAB> <TAB> <TAB> <TAB> ""Telegram does not support reply keyboard row width over %d."" <TAB> <TAB> <TAB> <TAB> % self.max_row_keys <TAB> <TAB> <TAB> ) <TAB> <TAB> row_width = self.max_row_keys <TAB> self.resize_keyboard = resize_keyboard <TAB> self.one_time_keyboard = one_time_keyboard <TAB> self.selective = selective <TAB> self.row_width = row_width <TAB> self.keyboard = []",false,if not DISABLE_KEYLEN_ERROR :,if resize_keyboard is not None and resize_keyboard is not None :,0.03,0.0
"def realizeElementExpressions(innerElement): <TAB> elementHasBeenRealized = False <TAB> for exp in innerElement.expressions: <TAB> <TAB> if not hasattr(exp, ""realize""): <TAB> <TAB> <TAB> continue <TAB> <TAB> # else: <TAB> <TAB> before, during, after = exp.realize(innerElement) <TAB> <TAB> elementHasBeenRealized = True <TAB> <TAB> for n in before: <TAB> <TAB> <TAB> newStream.append(n) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> newStream.append(during) <TAB> <TAB> for n in after: <TAB> <TAB> <TAB> newStream.append(n) <TAB> if elementHasBeenRealized is False: <TAB> <TAB> newStream.append(innerElement)",true,if during is not None :,if during is not None :,0.75,0.0
"def lex_number(self, pos): <TAB> # numeric literal <TAB> start = pos <TAB> found_dot = False <TAB> while pos < len(self.string) and ( <TAB> <TAB> self.string[pos].isdigit() or self.string[pos] == ""."" <TAB> ): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if found_dot is True: <TAB> <TAB> <TAB> <TAB> raise ValueError(""Invalid number. Found multiple '.'"") <TAB> <TAB> <TAB> found_dot = True <TAB> <TAB> # technically we allow more than one ""."" and let float()'s parsing <TAB> <TAB> # complain later <TAB> <TAB> pos += 1 <TAB> val = self.string[start:pos] <TAB> return Token(TokenType.LNUM, val, len(val))",true,"if self . string [ pos ] == ""."" :","if self . string [ pos ] == ""."" :",0.75,0.0
"def rename(src, dst): <TAB> # Try atomic or pseudo-atomic rename <TAB> if _rename(src, dst): <TAB> <TAB> return <TAB> # Fall back to ""move away and replace"" <TAB> try: <TAB> <TAB> os.rename(src, dst) <TAB> except OSError as e: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise <TAB> <TAB> old = ""%s-%08x"" % (dst, random.randint(0, sys.maxsize)) <TAB> <TAB> os.rename(dst, old) <TAB> <TAB> os.rename(src, dst) <TAB> <TAB> try: <TAB> <TAB> <TAB> os.unlink(old) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> pass",true,if e . errno != errno . EEXIST :,if e . errno != errno . EEXIST :,1.0,0.0
"def _the_callback(widget, event_id): <TAB> point = widget.GetCenter() <TAB> index = widget.WIDGET_INDEX <TAB> if hasattr(callback, ""__call__""): <TAB> <TAB> if num > 1: <TAB> <TAB> <TAB> args = [point, index] <TAB> <TAB> else: <TAB> <TAB> <TAB> args = [point] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> args.append(widget) <TAB> <TAB> try_callback(callback, *args) <TAB> return",false,if pass_widget :,if num > 1 :,0.05,0.0
"def run(self): <TAB> for _ in range(self.n): <TAB> <TAB> error = True <TAB> <TAB> try: <TAB> <TAB> <TAB> self.collection.insert_one({""test"": ""insert""}) <TAB> <TAB> <TAB> error = False <TAB> <TAB> except: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> if self.expect_exception: <TAB> <TAB> <TAB> assert error",false,if not self . expect_exception :,if self . fail_silently :,0.05,0.0
"def handle(self, *args: Any, **options: Any) -> None: <TAB> realm = self.get_realm(options) <TAB> if options[""all""]: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise CommandError( <TAB> <TAB> <TAB> <TAB> ""You must specify a realm if you choose the --all option."" <TAB> <TAB> <TAB> ) <TAB> <TAB> self.fix_all_users(realm) <TAB> <TAB> return <TAB> self.fix_emails(realm, options[""emails""])",true,if realm is None :,if realm is None :,0.75,0.0
"def recv_tdi(self, nbits, pos): <TAB> bits = 0 <TAB> for n in range(nbits * 2): <TAB> <TAB> yield from self._wait_for_tck() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> bits = (bits << 1) | (yield self.tdi.o) <TAB> return bits",false,if ( yield self . tck . o ) == pos :,if n == pos :,0.04,0.0
"def _split_head(self): <TAB> if not hasattr(self, ""_severed_head""): <TAB> <TAB> if self._tree: <TAB> <TAB> <TAB> tree = self._tree.copy() <TAB> <TAB> <TAB> head = tree.get_heading_text() <TAB> <TAB> <TAB> tree.remove_heading() <TAB> <TAB> <TAB> self._severed_head = (head, tree) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._severed_head = (None, None) <TAB> return self._severed_head",true,if self . _tree :,if self . _tree :,0.75,0.0
"def buildSearchTrie(self, choices): <TAB> searchtrie = trie.Trie() <TAB> for choice in choices: <TAB> <TAB> for token in self.tokenizeChoice(choice): <TAB> <TAB> <TAB> if not searchtrie.has_key(token): <TAB> <TAB> <TAB> <TAB> searchtrie[token] = [] <TAB> <TAB> <TAB> searchtrie[token].append(choice) <TAB> return searchtrie",true,if not searchtrie . has_key ( token ) :,if not searchtrie . has_key ( token ) :,0.75,0.0
"def format_sql(sql, params): <TAB> rv = [] <TAB> if isinstance(params, dict): <TAB> <TAB> # convert sql with named parameters to sql with unnamed parameters <TAB> <TAB> conv = _FormatConverter(params) <TAB> <TAB> if params: <TAB> <TAB> <TAB> sql = sql_to_string(sql) <TAB> <TAB> <TAB> sql = sql % conv <TAB> <TAB> <TAB> params = conv.params <TAB> <TAB> else: <TAB> <TAB> <TAB> params = () <TAB> for param in params or (): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> rv.append(""NULL"") <TAB> <TAB> param = safe_repr(param) <TAB> <TAB> rv.append(param) <TAB> return sql, rv",true,if param is None :,if param is None :,0.75,0.0
def on_completed2(): <TAB> doner[0] = True <TAB> if not qr: <TAB> <TAB> if len(ql) > 0: <TAB> <TAB> <TAB> observer.on_next(False) <TAB> <TAB> <TAB> observer.on_completed() <TAB> <TAB> elif donel[0]: <TAB> <TAB> <TAB> observer.on_next(True) <TAB> <TAB> <TAB> observer.on_completed(),true,elif donel [ 0 ] :,elif donel [ 0 ] :,0.75,0.0
"def notify_digest(self, frequency, changes): <TAB> notifications = defaultdict(list) <TAB> users = {} <TAB> for change in changes: <TAB> <TAB> for user in self.get_users(frequency, change): <TAB> <TAB> <TAB> if change.project is None or user.can_access_project(change.project): <TAB> <TAB> <TAB> <TAB> notifications[user.pk].append(change) <TAB> <TAB> <TAB> <TAB> users[user.pk] = user <TAB> for user in users.values(): <TAB> <TAB> self.send_digest( <TAB> <TAB> <TAB> user.profile.language, <TAB> <TAB> <TAB> user.email, <TAB> <TAB> <TAB> notifications[user.pk], <TAB> <TAB> <TAB> subscription=user.current_subscription, <TAB> <TAB> )",true,if change . project is None or user . can_access_project ( change . project ) :,if change . project is None or user . can_access_project ( change . project ) :,0.75,0.0
"def _any_listener_using(self, target_group_arn): <TAB> for load_balancer in self.load_balancers.values(): <TAB> <TAB> for listener in load_balancer.listeners.values(): <TAB> <TAB> <TAB> for rule in listener.rules: <TAB> <TAB> <TAB> <TAB> for action in rule.actions: <TAB> <TAB> <TAB> <TAB> <TAB> if action.data.get(""target_group_arn"") == target_group_arn: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",true,"if action . data . get ( ""target_group_arn"" ) == target_group_arn :","if action . data . get ( ""target_group_arn"" ) == target_group_arn :",0.75,0.0
"def train_dict(self, triples): <TAB> """"""Train a dict lemmatizer given training (word, pos, lemma) triples."""""" <TAB> # accumulate counter <TAB> ctr = Counter() <TAB> ctr.update([(p[0], p[1], p[2]) for p in triples]) <TAB> # find the most frequent mappings <TAB> for p, _ in ctr.most_common(): <TAB> <TAB> w, pos, l = p <TAB> <TAB> if (w, pos) not in self.composite_dict: <TAB> <TAB> <TAB> self.composite_dict[(w, pos)] = l <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.word_dict[w] = l <TAB> return",false,if w not in self . word_dict :,"if ( w , pos ) not in self . word_dict :",0.5,0.0
"def parse_git_config(path): <TAB> """"""Parse git config file."""""" <TAB> config = dict() <TAB> section = None <TAB> with open(os.path.join(path, ""config""), ""r"") as f: <TAB> <TAB> for line in f: <TAB> <TAB> <TAB> line = line.strip() <TAB> <TAB> <TAB> if line.startswith(""[""): <TAB> <TAB> <TAB> <TAB> section = line[1:-1].strip() <TAB> <TAB> <TAB> <TAB> config[section] = dict() <TAB> <TAB> <TAB> elif section: <TAB> <TAB> <TAB> <TAB> key, value = line.replace("" "", """").split(""="") <TAB> <TAB> <TAB> <TAB> config[section][key] = value <TAB> return config",false,"if line . startswith ( ""["" ) :",elif section :,0.01,0.0
"def send_signal(self, pid, signum): <TAB> if pid in self.processes: <TAB> <TAB> process = self.processes[pid] <TAB> <TAB> hook_result = self.call_hook(""before_signal"", pid=pid, signum=signum) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> logger.debug( <TAB> <TAB> <TAB> <TAB> ""before_signal hook didn't return True "" <TAB> <TAB> <TAB> <TAB> ""=> signal %i is not sent to %i"" % (signum, pid) <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> process.send_signal(signum) <TAB> <TAB> self.call_hook(""after_signal"", pid=pid, signum=signum) <TAB> else: <TAB> <TAB> logger.debug(""process %s does not exist"" % pid)",false,if signum != signal . SIGKILL and not hook_result :,if hook_result is False :,0.01,0.0
"def validate_pos_return(self): <TAB> if self.is_pos and self.is_return: <TAB> <TAB> total_amount_in_payments = 0 <TAB> <TAB> for payment in self.payments: <TAB> <TAB> <TAB> total_amount_in_payments += payment.amount <TAB> <TAB> invoice_total = self.rounded_total or self.grand_total <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> frappe.throw( <TAB> <TAB> <TAB> <TAB> _(""Total payments amount can't be greater than {}"").format( <TAB> <TAB> <TAB> <TAB> <TAB> -invoice_total <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> )",false,if total_amount_in_payments < invoice_total :,if total_amount_in_payments > invoice_total :,0.08,0.0
"def delete(key, inner_key=None): <TAB> if inner_key is not None: <TAB> <TAB> try: <TAB> <TAB> <TAB> del cache[key][inner_key] <TAB> <TAB> <TAB> del use_count[key][inner_key] <TAB> <TAB> <TAB> if not cache[key]: <TAB> <TAB> <TAB> <TAB> del cache[key] <TAB> <TAB> <TAB> <TAB> del use_count[key] <TAB> <TAB> <TAB> wrapper.cache_size -= 1 <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> return False <TAB> <TAB> else: <TAB> <TAB> <TAB> return True <TAB> else: <TAB> <TAB> try: <TAB> <TAB> <TAB> wrapper.cache_size -= len(cache[key]) <TAB> <TAB> <TAB> del cache[key] <TAB> <TAB> <TAB> del use_count[key] <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> return False <TAB> <TAB> else: <TAB> <TAB> <TAB> return True",true,if not cache [ key ] :,if not cache [ key ] :,0.75,0.0
"def insertionsort(array): <TAB> size = array.getsize() <TAB> array.reset(""Insertion sort"") <TAB> for i in range(1, size): <TAB> <TAB> j = i - 1 <TAB> <TAB> while j >= 0: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> array.swap(j, j + 1) <TAB> <TAB> <TAB> j = j - 1 <TAB> array.message(""Sorted"")",false,"if array . compare ( j , j + 1 ) <= 0 :",if j == i :,0.01,0.0
"def publish_state(cls, payload, state): <TAB> try: <TAB> <TAB> if isinstance(payload, LiveActionDB): <TAB> <TAB> <TAB> if state == action_constants.LIVEACTION_STATUS_REQUESTED: <TAB> <TAB> <TAB> <TAB> cls.process(payload) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> worker.get_worker().process(payload) <TAB> except Exception: <TAB> <TAB> traceback.print_exc() <TAB> <TAB> print(payload)",false,if state == action_constants . LIVEACTION_STATUS_REQUESTED :,"if isinstance ( payload , LiveActionDB ) :",0.02,0.0
"def change_opacity_function(self, new_f): <TAB> self.opacity_function = new_f <TAB> dr = self.radius / self.num_levels <TAB> sectors = [] <TAB> for submob in self.submobjects: <TAB> <TAB> if type(submob) == AnnularSector: <TAB> <TAB> <TAB> sectors.append(submob) <TAB> for (r, submob) in zip(np.arange(0, self.radius, dr), sectors): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # it's the shadow, don't dim it <TAB> <TAB> <TAB> continue <TAB> <TAB> alpha = self.opacity_function(r) <TAB> <TAB> submob.set_fill(opacity=alpha)",false,if type ( submob ) != AnnularSector :,if r == 0 :,0.02,0.0
"def is_suppressed_warning( <TAB> type: str, subtype: str, suppress_warnings: List[str] ) -> bool: <TAB> """"""Check the warning is suppressed or not."""""" <TAB> if type is None: <TAB> <TAB> return False <TAB> for warning_type in suppress_warnings: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> target, subtarget = warning_type.split(""."", 1) <TAB> <TAB> else: <TAB> <TAB> <TAB> target, subtarget = warning_type, None <TAB> <TAB> if target == type: <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> subtype is None <TAB> <TAB> <TAB> <TAB> or subtarget is None <TAB> <TAB> <TAB> <TAB> or subtarget == subtype <TAB> <TAB> <TAB> <TAB> or subtarget == ""*"" <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",true,"if ""."" in warning_type :","if ""."" in warning_type :",0.75,0.0
"def set_many(self, mapping, timeout=None): <TAB> timeout = self._normalize_timeout(timeout) <TAB> # Use transaction=False to batch without calling redis MULTI <TAB> # which is not supported by twemproxy <TAB> pipe = self._client.pipeline(transaction=False) <TAB> for key, value in _items(mapping): <TAB> <TAB> dump = self.dump_object(value) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> pipe.set(name=self.key_prefix + key, value=dump) <TAB> <TAB> else: <TAB> <TAB> <TAB> pipe.setex(name=self.key_prefix + key, value=dump, time=timeout) <TAB> return pipe.execute()",false,if timeout == - 1 :,if timeout is None :,0.05,0.0
"def maybe_relative_path(path): <TAB> if not os.path.isabs(path): <TAB> <TAB> return path  # already relative <TAB> dir = path <TAB> names = [] <TAB> while True: <TAB> <TAB> prevdir = dir <TAB> <TAB> dir, name = os.path.split(prevdir) <TAB> <TAB> if dir == prevdir or not dir: <TAB> <TAB> <TAB> return path  # failed to make it relative <TAB> <TAB> names.append(name) <TAB> <TAB> try: <TAB> <TAB> <TAB> if samefile(dir, os.curdir): <TAB> <TAB> <TAB> <TAB> names.reverse() <TAB> <TAB> <TAB> <TAB> return os.path.join(*names) <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> pass",true,"if samefile ( dir , os . curdir ) :","if samefile ( dir , os . curdir ) :",0.75,0.0
"def word_range(word): <TAB> for ind in range(len(word)): <TAB> <TAB> temp = word[ind] <TAB> <TAB> for c in [chr(x) for x in range(ord(""a""), ord(""z"") + 1)]: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> yield word[:ind] + c + word[ind + 1 :]",false,if c != temp :,if c in temp :,0.08,0.0
"def validate(self): <TAB> self.update_soil_edit(""sand_composition"") <TAB> for soil_type in self.soil_types: <TAB> <TAB> if self.get(soil_type) > 100 or self.get(soil_type) < 0: <TAB> <TAB> <TAB> frappe.throw(_(""{0} should be a value between 0 and 100"").format(soil_type)) <TAB> if sum(self.get(soil_type) for soil_type in self.soil_types) != 100: <TAB> <TAB> frappe.throw(_(""Soil compositions do not add up to 100""))",true,if self . get ( soil_type ) > 100 or self . get ( soil_type ) < 0 :,if self . get ( soil_type ) > 100 or self . get ( soil_type ) < 0 :,1.0,0.0
"def on_click(self, event): <TAB> run = self._is_running() <TAB> if event[""button""] == self.button_activate: <TAB> <TAB> self.py3.command_run([""xscreensaver-command"", ""-activate""]) <TAB> if event[""button""] == self.button_toggle: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.py3.command_run([""xscreensaver-command"", ""-exit""]) <TAB> <TAB> else: <TAB> <TAB> <TAB> # Because we want xscreensaver to continue running after <TAB> <TAB> <TAB> # exit, we instead use preexec_fn=setpgrp here. <TAB> <TAB> <TAB> Popen( <TAB> <TAB> <TAB> <TAB> [""xscreensaver"", ""-no-splash"", ""-no-capture-stderr""], <TAB> <TAB> <TAB> <TAB> stdout=PIPE, <TAB> <TAB> <TAB> <TAB> stderr=PIPE, <TAB> <TAB> <TAB> <TAB> preexec_fn=setpgrp, <TAB> <TAB> <TAB> )",true,if run :,if run :,0.53,0.0
"def maybe_relative_path(path): <TAB> if not os.path.isabs(path): <TAB> <TAB> return path  # already relative <TAB> dir = path <TAB> names = [] <TAB> while True: <TAB> <TAB> prevdir = dir <TAB> <TAB> dir, name = os.path.split(prevdir) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return path  # failed to make it relative <TAB> <TAB> names.append(name) <TAB> <TAB> try: <TAB> <TAB> <TAB> if samefile(dir, os.curdir): <TAB> <TAB> <TAB> <TAB> names.reverse() <TAB> <TAB> <TAB> <TAB> return os.path.join(*names) <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> pass",false,if dir == prevdir or not dir :,if name in names :,0.02,0.0
"def _format_micros(self, datestring): <TAB> parts = datestring[:-1].split(""."") <TAB> if len(parts) == 1: <TAB> <TAB> if datestring.endswith(""Z""): <TAB> <TAB> <TAB> return datestring[:-1] + "".000000Z"" <TAB> <TAB> else: <TAB> <TAB> <TAB> return datestring + "".000000Z"" <TAB> else: <TAB> <TAB> micros = parts[-1][:6] if len(parts[-1]) > 6 else parts[-1] <TAB> <TAB> return ""."".join(parts[:-1] + [""{:06d}"".format(int(micros))]) + ""Z""",true,"if datestring . endswith ( ""Z"" ) :","if datestring . endswith ( ""Z"" ) :",0.75,0.0
"def preprocess_raw_enwik9(input_filename, output_filename): <TAB> with open(input_filename, ""r"") as f1: <TAB> <TAB> with open(output_filename, ""w"") as f2: <TAB> <TAB> <TAB> while True: <TAB> <TAB> <TAB> <TAB> line = f1.readline() <TAB> <TAB> <TAB> <TAB> if not line: <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> line = list(enwik9_norm_transform([line]))[0] <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> if line[0] == "" "": <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> line = line[1:] <TAB> <TAB> <TAB> <TAB> <TAB> f2.writelines(line + ""\n"")",false,"if line != "" "" and line != """" :",if line :,0.02,0.0
"def set(self, item, data): <TAB> if not type(item) is slice: <TAB> <TAB> item = slice(item, item + len(data), None) <TAB> virt_item = self.item2virtitem(item) <TAB> if not virt_item: <TAB> <TAB> return <TAB> off = 0 <TAB> for s, n_item in virt_item: <TAB> <TAB> if isinstance(s, ProgBits): <TAB> <TAB> <TAB> i = slice(off, n_item.stop + off - n_item.start, n_item.step) <TAB> <TAB> <TAB> data_slice = data.__getitem__(i) <TAB> <TAB> <TAB> s.content.__setitem__(n_item, data_slice) <TAB> <TAB> <TAB> off = i.stop <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""TODO XXX"") <TAB> return",true,"if isinstance ( s , ProgBits ) :","if isinstance ( s , ProgBits ) :",0.75,0.0
"def walk(msg, callback, data): <TAB> partnum = 0 <TAB> for part in msg.walk(): <TAB> <TAB> # multipart/* are just containers <TAB> <TAB> if part.get_content_maintype() == ""multipart"": <TAB> <TAB> <TAB> continue <TAB> <TAB> ctype = part.get_content_type() <TAB> <TAB> if ctype is None: <TAB> <TAB> <TAB> ctype = OCTET_TYPE <TAB> <TAB> filename = part.get_filename() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> filename = PART_FN_TPL % (partnum) <TAB> <TAB> headers = dict(part) <TAB> <TAB> LOG.debug(headers) <TAB> <TAB> headers[""Content-Type""] = ctype <TAB> <TAB> payload = util.fully_decoded_payload(part) <TAB> <TAB> callback(data, filename, payload, headers) <TAB> <TAB> partnum = partnum + 1",false,if not filename :,if filename is None :,0.05,0.0
"def _run_wes(args): <TAB> """"""Run CWL using a Workflow Execution Service (WES) endpoint"""""" <TAB> main_file, json_file, project_name = _get_main_and_json(args.directory) <TAB> main_file = _pack_cwl(main_file) <TAB> if args.host and ""stratus"" in args.host: <TAB> <TAB> _run_wes_stratus(args, main_file, json_file) <TAB> else: <TAB> <TAB> opts = [""--no-wait""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> opts += [""--host"", args.host] <TAB> <TAB> if args.auth: <TAB> <TAB> <TAB> opts += [""--auth"", args.auth] <TAB> <TAB> cmd = [""wes-client""] + opts + [main_file, json_file] <TAB> <TAB> _run_tool(cmd)",true,if args . host :,if args . host :,0.75,0.0
"def insertTestData(self, rows): <TAB> for row in rows: <TAB> <TAB> if isinstance(row, Worker): <TAB> <TAB> <TAB> self.workers[row.id] = dict( <TAB> <TAB> <TAB> <TAB> id=row.id, name=row.name, paused=0, graceful=0, info=row.info <TAB> <TAB> <TAB> ) <TAB> <TAB> elif isinstance(row, ConfiguredWorker): <TAB> <TAB> <TAB> row.id = row.buildermasterid * 10000 + row.workerid <TAB> <TAB> <TAB> self.configured[row.id] = dict( <TAB> <TAB> <TAB> <TAB> buildermasterid=row.buildermasterid, workerid=row.workerid <TAB> <TAB> <TAB> ) <TAB> <TAB> elif isinstance(row, ConnectedWorker): <TAB> <TAB> <TAB> self.connected[row.id] = dict(masterid=row.masterid, workerid=row.workerid)",false,"elif isinstance ( row , ConfiguredWorker ) :","elif isinstance ( row , ConnectedWorker ) :",0.55,0.0
"def local_shape_to_shape_i(node): <TAB> if node.op == T.shape: <TAB> <TAB> # This optimization needs ShapeOpt and fgraph.shape_feature <TAB> <TAB> if not hasattr(node.fgraph, ""shape_feature""): <TAB> <TAB> <TAB> return <TAB> <TAB> shape_feature = node.fgraph.shape_feature <TAB> <TAB> ret = shape_feature.make_vector_shape(node.inputs[0]) <TAB> <TAB> # We need to copy over stack trace from input to output <TAB> <TAB> copy_stack_trace(node.outputs[0], ret) <TAB> <TAB> return [ret]",true,"if not hasattr ( node . fgraph , ""shape_feature"" ) :","if not hasattr ( node . fgraph , ""shape_feature"" ) :",0.75,0.0
"def get_config(): <TAB> """"""Get INI parser with version.ini data."""""" <TAB> # TODO(hanuszczak): See comment in `setup.py` for `grr-response-proto`. <TAB> ini_path = os.path.join(THIS_DIRECTORY, ""version.ini"") <TAB> if not os.path.exists(ini_path): <TAB> <TAB> ini_path = os.path.join(THIS_DIRECTORY, ""../../version.ini"") <TAB> <TAB> if not os.path.exists(ini_path): <TAB> <TAB> <TAB> raise RuntimeError(""Couldn't find version.ini"") <TAB> config = configparser.ConfigParser() <TAB> config.read(ini_path) <TAB> return config",true,if not os . path . exists ( ini_path ) :,if not os . path . exists ( ini_path ) :,0.75,0.0
"def init_weights(self, pretrained=None): <TAB> if isinstance(pretrained, str): <TAB> <TAB> logger = logging.getLogger() <TAB> <TAB> load_checkpoint(self, pretrained, strict=False, logger=logger) <TAB> elif pretrained is None: <TAB> <TAB> for m in self.modules(): <TAB> <TAB> <TAB> if isinstance(m, nn.Conv2d): <TAB> <TAB> <TAB> <TAB> kaiming_init(m) <TAB> <TAB> <TAB> elif isinstance(m, (_BatchNorm, nn.GroupNorm)): <TAB> <TAB> <TAB> <TAB> constant_init(m, 1) <TAB> else: <TAB> <TAB> raise TypeError(""pretrained must be a str or None"")",true,"if isinstance ( m , nn . Conv2d ) :","if isinstance ( m , nn . Conv2d ) :",0.75,0.0
"def isValidDateString(config_param_name, value, valid_value): <TAB> try: <TAB> <TAB> if value == ""DD-MM-YYYY"": <TAB> <TAB> <TAB> return value <TAB> <TAB> day, month, year = value.split(""-"") <TAB> <TAB> if int(day) < 1 or int(day) > 31: <TAB> <TAB> <TAB> raise DateStringValueError(config_param_name, value) <TAB> <TAB> if int(month) < 1 or int(month) > 12: <TAB> <TAB> <TAB> raise DateStringValueError(config_param_name, value) <TAB> <TAB> if int(year) < 1900 or int(year) > 2013: <TAB> <TAB> <TAB> raise DateStringValueError(config_param_name, value) <TAB> <TAB> return value <TAB> except Exception: <TAB> <TAB> raise DateStringValueError(config_param_name, value)",true,"if value == ""DD-MM-YYYY"" :","if value == ""DD-MM-YYYY"" :",0.75,0.0
"def from_obj(cls, py_obj): <TAB> if not isinstance(py_obj, Image): <TAB> <TAB> raise TypeError(""py_obj must be a wandb.Image"") <TAB> else: <TAB> <TAB> if hasattr(py_obj, ""_boxes"") and py_obj._boxes: <TAB> <TAB> <TAB> box_keys = list(py_obj._boxes.keys()) <TAB> <TAB> else: <TAB> <TAB> <TAB> box_keys = [] <TAB> <TAB> if hasattr(py_obj, ""masks"") and py_obj.masks: <TAB> <TAB> <TAB> mask_keys = list(py_obj.masks.keys()) <TAB> <TAB> else: <TAB> <TAB> <TAB> mask_keys = [] <TAB> <TAB> return cls(box_keys, mask_keys)",false,"if hasattr ( py_obj , ""_boxes"" ) and py_obj . _boxes :","if hasattr ( py_obj , ""masks"" ) and py_obj . masks :",0.77,0.0
"def _path_type(st, lst): <TAB> parts = [] <TAB> if st: <TAB> <TAB> if stat.S_ISREG(st.st_mode): <TAB> <TAB> <TAB> parts.append(""file"") <TAB> <TAB> elif stat.S_ISDIR(st.st_mode): <TAB> <TAB> <TAB> parts.append(""dir"") <TAB> <TAB> else: <TAB> <TAB> <TAB> parts.append(""other"") <TAB> if lst: <TAB> <TAB> if stat.S_ISLNK(lst.st_mode): <TAB> <TAB> <TAB> parts.append(""link"") <TAB> return "" "".join(parts)",false,elif stat . S_ISDIR ( st . st_mode ) :,if stat . S_ISREG ( st . st_mode ) :,0.29,0.0
"def is_destructive(queries): <TAB> """"""Returns if any of the queries in *queries* is destructive."""""" <TAB> keywords = (""drop"", ""shutdown"", ""delete"", ""truncate"", ""alter"") <TAB> for query in sqlparse.split(queries): <TAB> <TAB> if query: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> elif query_starts_with( <TAB> <TAB> <TAB> <TAB> query, [""update""] <TAB> <TAB> <TAB> ) is True and not query_has_where_clause(query): <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",false,"if query_starts_with ( query , keywords ) is True :",if query in keywords :,0.02,0.0
"def _store_gsuite_membership_post(self): <TAB> """"""Flush storing gsuite memberships."""""" <TAB> if not self.member_cache: <TAB> <TAB> return <TAB> self.session.flush() <TAB> # session.execute automatically flushes <TAB> if self.membership_items: <TAB> <TAB> if get_sql_dialect(self.session) == ""sqlite"": <TAB> <TAB> <TAB> # SQLite doesn't support bulk insert <TAB> <TAB> <TAB> for item in self.membership_items: <TAB> <TAB> <TAB> <TAB> stmt = self.dao.TBL_MEMBERSHIP.insert(item) <TAB> <TAB> <TAB> <TAB> self.session.execute(stmt) <TAB> <TAB> else: <TAB> <TAB> <TAB> stmt = self.dao.TBL_MEMBERSHIP.insert(self.membership_items) <TAB> <TAB> <TAB> self.session.execute(stmt)",true,"if get_sql_dialect ( self . session ) == ""sqlite"" :","if get_sql_dialect ( self . session ) == ""sqlite"" :",0.75,0.0
"def forward(self, inputs: paddle.Tensor): <TAB> outputs = [] <TAB> blocks = self.block(inputs) <TAB> route = None <TAB> for i, block in enumerate(blocks): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> block = paddle.concat([route, block], axis=1) <TAB> <TAB> route, tip = self.yolo_blocks[i](block) <TAB> <TAB> block_out = self.block_outputs[i](tip) <TAB> <TAB> outputs.append(block_out) <TAB> <TAB> if i < 2: <TAB> <TAB> <TAB> route = self.route_blocks_2[i](route) <TAB> <TAB> <TAB> route = self.upsample(route) <TAB> return outputs",false,if i > 0 :,if i < 2 :,0.31,0.0
"def deep_dict(self, root=None): <TAB> if root is None: <TAB> <TAB> root = self <TAB> result = {} <TAB> for key, value in root.items(): <TAB> <TAB> if isinstance(value, dict): <TAB> <TAB> <TAB> result[key] = self.deep_dict(root=self.__class__._get_next(key, root)) <TAB> <TAB> else: <TAB> <TAB> <TAB> result[key] = value <TAB> return result",true,"if isinstance ( value , dict ) :","if isinstance ( value , dict ) :",0.75,0.0
"def _parse_param_list(self, content): <TAB> r = Reader(content) <TAB> params = [] <TAB> while not r.eof(): <TAB> <TAB> header = r.read().strip() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> arg_name, arg_type = header.split("" : "")[:2] <TAB> <TAB> else: <TAB> <TAB> <TAB> arg_name, arg_type = header, """" <TAB> <TAB> desc = r.read_to_next_unindented_line() <TAB> <TAB> desc = dedent_lines(desc) <TAB> <TAB> params.append((arg_name, arg_type, desc)) <TAB> return params",true,"if "" : "" in header :","if "" : "" in header :",0.75,0.0
"def _ungroup(sequence, groups=None): <TAB> for v in sequence: <TAB> <TAB> if isinstance(v, (list, tuple)): <TAB> <TAB> <TAB> if groups is not None: <TAB> <TAB> <TAB> <TAB> groups.append(list(_ungroup(v, groups=None))) <TAB> <TAB> <TAB> for v in _ungroup(v, groups): <TAB> <TAB> <TAB> <TAB> yield v <TAB> <TAB> else: <TAB> <TAB> <TAB> yield v",true,"if isinstance ( v , ( list , tuple ) ) :","if isinstance ( v , ( list , tuple ) ) :",0.75,0.0
"def _add_resource_group(obj): <TAB> if isinstance(obj, list): <TAB> <TAB> for array_item in obj: <TAB> <TAB> <TAB> _add_resource_group(array_item) <TAB> elif isinstance(obj, dict): <TAB> <TAB> try: <TAB> <TAB> <TAB> if ""resourcegroup"" not in [x.lower() for x in obj.keys()]: <TAB> <TAB> <TAB> <TAB> if obj[""id""]: <TAB> <TAB> <TAB> <TAB> <TAB> obj[""resourceGroup""] = _parse_id(obj[""id""])[""resource-group""] <TAB> <TAB> except (KeyError, IndexError, TypeError): <TAB> <TAB> <TAB> pass <TAB> <TAB> for item_key in obj: <TAB> <TAB> <TAB> if item_key != ""sourceVault"": <TAB> <TAB> <TAB> <TAB> _add_resource_group(obj[item_key])",true,"if item_key != ""sourceVault"" :","if item_key != ""sourceVault"" :",0.75,0.0
"def haslayer(self, cls): <TAB> """"""true if self has a layer that is an instance of cls. Superseded by ""cls in self"" syntax."""""" <TAB> if self.__class__ == cls or self.__class__.__name__ == cls: <TAB> <TAB> return 1 <TAB> for f in self.packetfields: <TAB> <TAB> fvalue_gen = self.getfieldval(f.name) <TAB> <TAB> if fvalue_gen is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> if not f.islist: <TAB> <TAB> <TAB> fvalue_gen = SetGen(fvalue_gen, _iterpacket=0) <TAB> <TAB> for fvalue in fvalue_gen: <TAB> <TAB> <TAB> if isinstance(fvalue, Packet): <TAB> <TAB> <TAB> <TAB> ret = fvalue.haslayer(cls) <TAB> <TAB> <TAB> <TAB> if ret: <TAB> <TAB> <TAB> <TAB> <TAB> return ret <TAB> return self.payload.haslayer(cls)",true,"if isinstance ( fvalue , Packet ) :","if isinstance ( fvalue , Packet ) :",0.75,0.0
"def _post_attachment(self, message, channel, color, sub_fields=None): <TAB> if channel is None: <TAB> <TAB> message_channels = self.channels <TAB> else: <TAB> <TAB> message_channels = [channel] <TAB> for message_channel in message_channels: <TAB> <TAB> attachment = { <TAB> <TAB> <TAB> ""fallback"": message, <TAB> <TAB> <TAB> ""text"": message, <TAB> <TAB> <TAB> ""color"": color, <TAB> <TAB> } <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> attachment[""fields""] = sub_fields <TAB> <TAB> self.slack_client.api_call( <TAB> <TAB> <TAB> ""chat.postMessage"", <TAB> <TAB> <TAB> channel=message_channel, <TAB> <TAB> <TAB> attachments=[attachment], <TAB> <TAB> <TAB> as_user=True, <TAB> <TAB> )",false,if sub_fields is not None :,if sub_fields :,0.05,0.0
"def create(cls, repository, args): <TAB> key = cls() <TAB> passphrase = os.environ.get(""ATTIC_PASSPHRASE"") <TAB> if passphrase is not None: <TAB> <TAB> passphrase2 = passphrase <TAB> else: <TAB> <TAB> passphrase, passphrase2 = 1, 2 <TAB> while passphrase != passphrase2: <TAB> <TAB> passphrase = getpass(""Enter passphrase: "") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(""Passphrase must not be blank"") <TAB> <TAB> <TAB> continue <TAB> <TAB> passphrase2 = getpass(""Enter same passphrase again: "") <TAB> <TAB> if passphrase != passphrase2: <TAB> <TAB> <TAB> print(""Passphrases do not match"") <TAB> key.init(repository, passphrase) <TAB> if passphrase: <TAB> <TAB> print(""Remember your passphrase. Your data will be inaccessible without it."") <TAB> return key",false,if not passphrase :,if passphrase is None :,0.05,0.0
"def _generate_create_date(self): <TAB> if self.timezone is not None: <TAB> <TAB> # First, assume correct capitalization <TAB> <TAB> tzinfo = tz.gettz(self.timezone) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # Fall back to uppercase <TAB> <TAB> <TAB> tzinfo = tz.gettz(self.timezone.upper()) <TAB> <TAB> if tzinfo is None: <TAB> <TAB> <TAB> raise util.CommandError(""Can't locate timezone: %s"" % self.timezone) <TAB> <TAB> create_date = ( <TAB> <TAB> <TAB> datetime.datetime.utcnow().replace(tzinfo=tz.tzutc()).astimezone(tzinfo) <TAB> <TAB> ) <TAB> else: <TAB> <TAB> create_date = datetime.datetime.now() <TAB> return create_date",true,if tzinfo is None :,if tzinfo is None :,0.75,0.0
"def _read_header_lines(fp): <TAB> """"""Read lines with headers until the start of body"""""" <TAB> lines = deque() <TAB> for line in fp: <TAB> <TAB> if is_empty(line): <TAB> <TAB> <TAB> break <TAB> <TAB> # tricky case if it's not a header and not an empty line <TAB> <TAB> # usually means that user forgot to separate the body and newlines <TAB> <TAB> # so ""unread"" this line here, what means to treat it like a body <TAB> <TAB> if not _RE_HEADER.match(line): <TAB> <TAB> <TAB> fp.seek(fp.tell() - len(line)) <TAB> <TAB> <TAB> break <TAB> <TAB> lines.append(line) <TAB> return lines",false,if not _RE_HEADER . match ( line ) :,if is_empty ( line ) :,0.16,0.0
"def _media_files_drag_received(widget, context, x, y, data, info, timestamp): <TAB> uris = data.get_uris() <TAB> files = [] <TAB> for uri in uris: <TAB> <TAB> try: <TAB> <TAB> <TAB> uri_tuple = GLib.filename_from_uri(uri) <TAB> <TAB> except: <TAB> <TAB> <TAB> continue <TAB> <TAB> uri, unused = uri_tuple <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if utils.is_media_file(uri) == True: <TAB> <TAB> <TAB> <TAB> files.append(uri) <TAB> if len(files) == 0: <TAB> <TAB> return <TAB> open_dropped_files(files)",false,if os . path . exists ( uri ) == True :,if uri :,0.01,0.0
"def remove_importlib(frame, options): <TAB> if frame is None: <TAB> <TAB> return None <TAB> for child in frame.children: <TAB> <TAB> remove_importlib(child, options=options) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # remove this node, moving the self_time and children up to the parent <TAB> <TAB> <TAB> frame.self_time += child.self_time <TAB> <TAB> <TAB> frame.add_children(child.children, after=child) <TAB> <TAB> <TAB> child.remove_from_parent() <TAB> return frame",false,"if ""<frozen importlib._bootstrap"" in child . file_path :",if child . parent is None :,0.04,0.0
"def __call__(self, graph): <TAB> for layer_name, data in self.params: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> node = graph.get_node(layer_name) <TAB> <TAB> <TAB> node.data = self.adjust_parameters(node, data) <TAB> <TAB> else: <TAB> <TAB> <TAB> print_stderr(""Ignoring parameters for non-existent layer: %s"" % layer_name) <TAB> return graph",true,if layer_name in graph :,if layer_name in graph :,0.75,0.0
"def test_with_three_points(self): <TAB> cba = ia.Polygon([(1, 2), (3, 4), (5, 5)]) <TAB> for i, xy in enumerate(cba): <TAB> <TAB> assert i in [0, 1, 2] <TAB> <TAB> if i == 0: <TAB> <TAB> <TAB> assert np.allclose(xy, (1, 2)) <TAB> <TAB> elif i == 1: <TAB> <TAB> <TAB> assert np.allclose(xy, (3, 4)) <TAB> <TAB> elif i == 2: <TAB> <TAB> <TAB> assert np.allclose(xy, (5, 5)) <TAB> assert i == 2",false,elif i == 1 :,elif i == 2 :,0.64,0.0
"def _serve(self): <TAB> self._conn = self.manager.request(REQUEST_DNS_LISTENER, self.domain) <TAB> conn = MsgPackMessages(self._conn) <TAB> while self.active: <TAB> <TAB> request = conn.recv() <TAB> <TAB> if not request: <TAB> <TAB> <TAB> logger.warning(""DNS: Recieved empty request. Shutdown"") <TAB> <TAB> <TAB> self.stop() <TAB> <TAB> <TAB> break <TAB> <TAB> now = time.time() <TAB> <TAB> response = self.handler.process(request) <TAB> <TAB> if not response: <TAB> <TAB> <TAB> response = [] <TAB> <TAB> used = time.time() - now <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> logger.warning(""DNS: Slow processing speed (%s)s"", used) <TAB> <TAB> conn.send(response)",false,if used > 1 :,if used > self . speed :,0.12,0.0
"def read(cls, fp, **kwargs): <TAB> major_version, minor_version, count = read_fmt(""2HI"", fp) <TAB> items = [] <TAB> for _ in range(count): <TAB> <TAB> length = read_fmt(""I"", fp)[0] - 4 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> with io.BytesIO(fp.read(length)) as f: <TAB> <TAB> <TAB> <TAB> items.append(Annotation.read(f)) <TAB> return cls(major_version=major_version, minor_version=minor_version, items=items)",true,if length > 0 :,if length > 0 :,0.75,0.0
"def save_uploaded_files(): <TAB> files = [] <TAB> unzip = bool(request.form.get(""unzip"") in [""true"", ""on""]) <TAB> for uploaded_file in request.files.getlist(""files""): <TAB> <TAB> if unzip and zipfile.is_zipfile(uploaded_file): <TAB> <TAB> <TAB> with zipfile.ZipFile(uploaded_file, ""r"") as zf: <TAB> <TAB> <TAB> <TAB> for info in zf.infolist(): <TAB> <TAB> <TAB> <TAB> <TAB> name = info.filename <TAB> <TAB> <TAB> <TAB> <TAB> size = info.file_size <TAB> <TAB> <TAB> <TAB> <TAB> data = zf.read(name) <TAB> <TAB> <TAB> <TAB> <TAB> if size > 0: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> files.append(save_file(data, filename=name.split(""/"")[-1])) <TAB> <TAB> else: <TAB> <TAB> <TAB> files.append(save_file(uploaded_file)) <TAB> return files",true,if unzip and zipfile . is_zipfile ( uploaded_file ) :,if unzip and zipfile . is_zipfile ( uploaded_file ) :,0.75,0.0
"def analyze_string_content(self, string, line_num, filename): <TAB> output = {} <TAB> if self.keyword_exclude and self.keyword_exclude.search(string): <TAB> <TAB> return output <TAB> for identifier in self.secret_generator( <TAB> <TAB> string, <TAB> <TAB> filetype=determine_file_type(filename), <TAB> ): <TAB> <TAB> if self.is_secret_false_positive(identifier): <TAB> <TAB> <TAB> continue <TAB> <TAB> secret = PotentialSecret( <TAB> <TAB> <TAB> self.secret_type, <TAB> <TAB> <TAB> filename, <TAB> <TAB> <TAB> identifier, <TAB> <TAB> <TAB> line_num, <TAB> <TAB> ) <TAB> <TAB> output[secret] = secret <TAB> return output",true,if self . is_secret_false_positive ( identifier ) :,if self . is_secret_false_positive ( identifier ) :,0.75,0.0
"def _validate_and_set_default_hyperparameters(self): <TAB> """"""Placeholder docstring"""""" <TAB> # Check if all the required hyperparameters are set. If there is a default value <TAB> # for one, set it. <TAB> for name, definition in self.hyperparameter_definitions.items(): <TAB> <TAB> if name not in self.hyperparam_dict: <TAB> <TAB> <TAB> spec = definition[""spec""] <TAB> <TAB> <TAB> if ""DefaultValue"" in spec: <TAB> <TAB> <TAB> <TAB> self.hyperparam_dict[name] = spec[""DefaultValue""] <TAB> <TAB> <TAB> elif ""IsRequired"" in spec and spec[""IsRequired""]: <TAB> <TAB> <TAB> <TAB> raise ValueError(""Required hyperparameter: %s is not set"" % name)",true,"elif ""IsRequired"" in spec and spec [ ""IsRequired"" ] :","elif ""IsRequired"" in spec and spec [ ""IsRequired"" ] :",1.0,0.0
"def get_code(self, fullname=None): <TAB> fullname = self._fix_name(fullname) <TAB> if self.code is None: <TAB> <TAB> mod_type = self.etc[2] <TAB> <TAB> if mod_type == imp.PY_SOURCE: <TAB> <TAB> <TAB> source = self.get_source(fullname) <TAB> <TAB> <TAB> self.code = compile(source, self.filename, ""exec"") <TAB> <TAB> elif mod_type == imp.PY_COMPILED: <TAB> <TAB> <TAB> self._reopen() <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> self.code = read_code(self.file) <TAB> <TAB> <TAB> finally: <TAB> <TAB> <TAB> <TAB> self.file.close() <TAB> <TAB> elif mod_type == imp.PKG_DIRECTORY: <TAB> <TAB> <TAB> self.code = self._get_delegate().get_code() <TAB> return self.code",true,elif mod_type == imp . PKG_DIRECTORY :,elif mod_type == imp . PKG_DIRECTORY :,0.75,0.0
"def eigh_abstract_eval(operand, lower): <TAB> if isinstance(operand, ShapedArray): <TAB> <TAB> if operand.ndim < 2 or operand.shape[-2] != operand.shape[-1]: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""Argument to symmetric eigendecomposition must have shape [..., n, n],"" <TAB> <TAB> <TAB> <TAB> ""got shape {}"".format(operand.shape) <TAB> <TAB> <TAB> ) <TAB> <TAB> batch_dims = operand.shape[:-2] <TAB> <TAB> n = operand.shape[-1] <TAB> <TAB> v = ShapedArray(batch_dims + (n, n), operand.dtype) <TAB> <TAB> w = ShapedArray(batch_dims + (n,), lax.lax._complex_basetype(operand.dtype)) <TAB> else: <TAB> <TAB> v, w = operand, operand <TAB> return v, w",true,if operand . ndim < 2 or operand . shape [ - 2 ] != operand . shape [ - 1 ] :,if operand . ndim < 2 or operand . shape [ - 2 ] != operand . shape [ - 1 ] :,0.75,0.0
"def conninfo_parse(dsn): <TAB> ret = {} <TAB> length = len(dsn) <TAB> i = 0 <TAB> while i < length: <TAB> <TAB> if dsn[i].isspace(): <TAB> <TAB> <TAB> i += 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> param_match = PARAMETER_RE.match(dsn[i:]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> param = param_match.group(1) <TAB> <TAB> i += param_match.end() <TAB> <TAB> if i >= length: <TAB> <TAB> <TAB> return <TAB> <TAB> value, end = read_param_value(dsn[i:]) <TAB> <TAB> if value is None: <TAB> <TAB> <TAB> return <TAB> <TAB> i += end <TAB> <TAB> ret[param] = value <TAB> return ret",false,if not param_match :,if param_match is None :,0.05,0.0
"def load_weights_from_unsupervised(self, unsupervised_model): <TAB> update_state_dict = copy.deepcopy(self.network.state_dict()) <TAB> for param, weights in unsupervised_model.network.state_dict().items(): <TAB> <TAB> if param.startswith(""encoder""): <TAB> <TAB> <TAB> # Convert encoder's layers name to match <TAB> <TAB> <TAB> new_param = ""tabnet."" + param <TAB> <TAB> else: <TAB> <TAB> <TAB> new_param = param <TAB> <TAB> if self.network.state_dict().get(new_param) is not None: <TAB> <TAB> <TAB> # update only common layers <TAB> <TAB> <TAB> update_state_dict[new_param] = weights <TAB> self.network.load_state_dict(update_state_dict)",false,if self . network . state_dict ( ) . get ( new_param ) is not None :,"if param . startswith ( ""encoder"" ) :",0.01,0.0
"def viewer_setup(self): <TAB> for key, value in DEFAULT_CAMERA_CONFIG.items(): <TAB> <TAB> if isinstance(value, np.ndarray): <TAB> <TAB> <TAB> getattr(self.viewer.cam, key)[:] = value <TAB> <TAB> else: <TAB> <TAB> <TAB> setattr(self.viewer.cam, key, value)",true,"if isinstance ( value , np . ndarray ) :","if isinstance ( value , np . ndarray ) :",0.75,0.0
"def colormap_changed(change): <TAB> if change[""new""]: <TAB> <TAB> cmap_colors = [ <TAB> <TAB> <TAB> color[1:] for color in cmap.step.__dict__[""_schemes""][colormap.value] <TAB> <TAB> ] <TAB> <TAB> palette.value = "", "".join(cmap_colors) <TAB> <TAB> colorbar = getattr(cmap.step, colormap.value) <TAB> <TAB> colorbar_output = self.colorbar_widget <TAB> <TAB> with colorbar_output: <TAB> <TAB> <TAB> colorbar_output.clear_output() <TAB> <TAB> <TAB> display(colorbar) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> labels = [f""Class {i+1}"" for i in range(len(palette.value.split("","")))] <TAB> <TAB> <TAB> legend_labels.value = "", "".join(labels)",false,"if len ( palette . value ) > 0 and "","" in palette . value :",if colormap . value :,0.03,0.0
"def invalidate(self, layers=None): <TAB> if layers is None: <TAB> <TAB> layers = Layer.AllLayers <TAB> if layers: <TAB> <TAB> layers = set(layers) <TAB> <TAB> self.invalidLayers.update(layers) <TAB> <TAB> blockRenderers = [ <TAB> <TAB> <TAB> br <TAB> <TAB> <TAB> for br in self.blockRenderers <TAB> <TAB> <TAB> if br.layer is Layer.Blocks or br.layer not in layers <TAB> <TAB> ] <TAB> <TAB> if len(blockRenderers) < len(self.blockRenderers): <TAB> <TAB> <TAB> self.forgetDisplayLists() <TAB> <TAB> self.blockRenderers = blockRenderers <TAB> <TAB> if self.renderer.showRedraw and Layer.Blocks in layers: <TAB> <TAB> <TAB> self.needsRedisplay = True",false,if len ( blockRenderers ) < len ( self . blockRenderers ) :,if br . layer is Layer . Blocks or br . layer not in layers,0.01,0.0
"def fromstring(cls, input): <TAB> productions = [] <TAB> for linenum, line in enumerate(input.split(""\n"")): <TAB> <TAB> line = line.strip() <TAB> <TAB> if line.startswith(""#"") or line == """": <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> productions += _read_dependency_production(line) <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> raise ValueError(""Unable to parse line %s: %s"" % (linenum, line)) <TAB> if len(productions) == 0: <TAB> <TAB> raise ValueError(""No productions found!"") <TAB> return DependencyGrammar(productions)",true,"if line . startswith ( ""#"" ) or line == """" :","if line . startswith ( ""#"" ) or line == """" :",1.0,0.0
"def repl(m, base_path, rel_path=None): <TAB> if m.group(""comments""): <TAB> <TAB> tag = m.group(""comments"") <TAB> else: <TAB> <TAB> tag = m.group(""open"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tag += RE_TAG_LINK_ATTR.sub( <TAB> <TAB> <TAB> <TAB> lambda m2: repl_absolute(m2, base_path), m.group(""attr"") <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> tag += RE_TAG_LINK_ATTR.sub( <TAB> <TAB> <TAB> <TAB> lambda m2: repl_relative(m2, base_path, rel_path), m.group(""attr"") <TAB> <TAB> <TAB> ) <TAB> <TAB> tag += m.group(""close"") <TAB> return tag",true,if rel_path is None :,if rel_path is None :,0.75,0.0
"def encode(path): <TAB> if isinstance(path, str_cls): <TAB> <TAB> try: <TAB> <TAB> <TAB> path = path.encode(fs_encoding, ""strict"") <TAB> <TAB> except UnicodeEncodeError: <TAB> <TAB> <TAB> if not platform.is_linux(): <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> path = path.encode(fs_fallback_encoding, ""strict"") <TAB> return path",true,if not platform . is_linux ( ) :,if not platform . is_linux ( ) :,0.75,0.0
"def __iter__(self): <TAB> base_iterator = super(ProcessIterable, self).__iter__() <TAB> if getattr(self.queryset, ""_coerced"", False): <TAB> <TAB> for process in base_iterator: <TAB> <TAB> <TAB> if isinstance(process, self.queryset.model): <TAB> <TAB> <TAB> <TAB> process = coerce_to_related_instance( <TAB> <TAB> <TAB> <TAB> <TAB> process, process.flow_class.process_class <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> yield process <TAB> else: <TAB> <TAB> for process in base_iterator: <TAB> <TAB> <TAB> yield process",true,"if isinstance ( process , self . queryset . model ) :","if isinstance ( process , self . queryset . model ) :",0.75,0.0
"def footnotes_under(n: Element) -> Iterator[nodes.footnote]: <TAB> if isinstance(n, nodes.footnote): <TAB> <TAB> yield n <TAB> else: <TAB> <TAB> for c in n.children: <TAB> <TAB> <TAB> if isinstance(c, addnodes.start_of_file): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> elif isinstance(c, nodes.Element): <TAB> <TAB> <TAB> <TAB> yield from footnotes_under(c)",true,"if isinstance ( c , addnodes . start_of_file ) :","if isinstance ( c , addnodes . start_of_file ) :",0.75,0.0
"def _process_submissions(self) -> None: <TAB> """"""Process all submissions which have not been processed yet."""""" <TAB> while self._to_be_processed: <TAB> <TAB> job = self._to_be_processed[0] <TAB> <TAB> job.process()  # trigger computation <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> heapq.heappush( <TAB> <TAB> <TAB> <TAB> self._steady_priority_queue, <TAB> <TAB> <TAB> <TAB> OrderedJobs(job.release_time, self._order, job), <TAB> <TAB> <TAB> ) <TAB> <TAB> self._to_be_processed.popleft()  # remove right after it is added to the heap queue <TAB> <TAB> self._order += 1",false,if not self . batch_mode :,if job . release_time is not None :,0.02,0.0
"def valid_localparts(strip_delimiters=False): <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS.split(""\n""): <TAB> <TAB> # strip line, skip over empty lines <TAB> <TAB> line = line.strip() <TAB> <TAB> if line == """": <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over comments or empty lines <TAB> <TAB> match = COMMENT.match(line) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over localparts with delimiters <TAB> <TAB> if strip_delimiters: <TAB> <TAB> <TAB> if "","" in line or "";"" in line: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield line",false,if match :,if match is None :,0.1,0.0
"def _get_payload_hash(self, method, data=None): <TAB> if method in (""POST"", ""PUT""): <TAB> <TAB> if data: <TAB> <TAB> <TAB> if hasattr(data, ""next"") or hasattr(data, ""__next__""): <TAB> <TAB> <TAB> <TAB> # File upload; don't try to read the entire payload <TAB> <TAB> <TAB> <TAB> return UNSIGNED_PAYLOAD <TAB> <TAB> <TAB> return _hash(data) <TAB> <TAB> else: <TAB> <TAB> <TAB> return UNSIGNED_PAYLOAD <TAB> else: <TAB> <TAB> return _hash("""")",true,"if hasattr ( data , ""next"" ) or hasattr ( data , ""__next__"" ) :","if hasattr ( data , ""next"" ) or hasattr ( data , ""__next__"" ) :",1.0,0.0
"def get_download_info(self): <TAB> try: <TAB> <TAB> download_info = self.api.get_download_info(self.game) <TAB> <TAB> result = True <TAB> except NoDownloadLinkFound as e: <TAB> <TAB> print(e) <TAB> <TAB> if Config.get(""current_download"") == self.game.id: <TAB> <TAB> <TAB> Config.unset(""current_download"") <TAB> <TAB> GLib.idle_add( <TAB> <TAB> <TAB> self.parent.parent.show_error, <TAB> <TAB> <TAB> _(""Download error""), <TAB> <TAB> <TAB> _( <TAB> <TAB> <TAB> <TAB> ""There was an error when trying to fetch the download link!\n{}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> e <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ), <TAB> <TAB> ) <TAB> <TAB> download_info = False <TAB> <TAB> result = False <TAB> return result, download_info",true,"if Config . get ( ""current_download"" ) == self . game . id :","if Config . get ( ""current_download"" ) == self . game . id :",0.75,0.0
"def find_id(self, doc_id): <TAB> self._lock.acquire() <TAB> try: <TAB> <TAB> doc = self._docs.get(doc_id) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> doc = copy.deepcopy(doc) <TAB> <TAB> <TAB> doc[""id""] = doc_id <TAB> <TAB> <TAB> return doc <TAB> finally: <TAB> <TAB> self._lock.release()",true,if doc :,if doc :,0.53,0.0
"def assign_art(self, session, task): <TAB> """"""Place the discovered art in the filesystem."""""" <TAB> if task in self.art_candidates: <TAB> <TAB> candidate = self.art_candidates.pop(task) <TAB> <TAB> self._set_art(task.album, candidate, not self.src_removed) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> task.prune(candidate.path)",false,if self . src_removed :,if task . prune :,0.29,0.0
"def _replace_named(self, named, replace_scalar): <TAB> for item in named: <TAB> <TAB> for name, value in self._get_replaced_named(item, replace_scalar): <TAB> <TAB> <TAB> if not is_string(name): <TAB> <TAB> <TAB> <TAB> raise DataError(""Argument names must be strings."") <TAB> <TAB> <TAB> yield name, value",true,if not is_string ( name ) :,if not is_string ( name ) :,0.75,0.0
"def qtTypeIdent(conn, *args): <TAB> # We're not using the conn object at the moment, but - we will <TAB> # modify the <TAB> # logic to use the server version specific keywords later. <TAB> res = None <TAB> value = None <TAB> for val in args: <TAB> <TAB> # DataType doesn't have len function then convert it to string <TAB> <TAB> if not hasattr(val, ""__len__""): <TAB> <TAB> <TAB> val = str(val) <TAB> <TAB> if len(val) == 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> value = val <TAB> <TAB> if Driver.needsQuoting(val, True): <TAB> <TAB> <TAB> value = value.replace('""', '""""') <TAB> <TAB> <TAB> value = '""' + value + '""' <TAB> <TAB> res = ((res and res + ""."") or """") + value <TAB> return res",true,"if Driver . needsQuoting ( val , True ) :","if Driver . needsQuoting ( val , True ) :",0.75,0.0
"def _update_tileable_and_chunk_shape(self, tileable_graph, chunk_result, failed_ops): <TAB> for n in tileable_graph: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> tiled_n = get_tiled(n) <TAB> <TAB> if has_unknown_shape(tiled_n): <TAB> <TAB> <TAB> if any(c.key not in chunk_result for c in tiled_n.chunks): <TAB> <TAB> <TAB> <TAB> # some of the chunks has been fused <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_nsplits = self.get_tileable_nsplits(n, chunk_result=chunk_result) <TAB> <TAB> <TAB> for node in (n, tiled_n): <TAB> <TAB> <TAB> <TAB> node._update_shape(tuple(sum(nsplit) for nsplit in new_nsplits)) <TAB> <TAB> <TAB> tiled_n._nsplits = new_nsplits",false,if n . op in failed_ops :,if n in failed_ops :,0.11,0.0
"def _read_filter(self, data): <TAB> if data: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.inner_sha.update(data) <TAB> <TAB> if self.expected_inner_md5sum: <TAB> <TAB> <TAB> self.inner_md5.update(data) <TAB> return data",false,if self . expected_inner_sha256 :,if self . expected_inner_sha :,0.39,0.0
"def find_previous_editable(self, *args): <TAB> if self.editw == 0: <TAB> <TAB> if self._active_page > 0: <TAB> <TAB> <TAB> self.switch_page(self._active_page - 1) <TAB> if not self.editw == 0: <TAB> <TAB> # remember that xrange does not return the 'last' value, <TAB> <TAB> # so go to -1, not 0! (fence post error in reverse) <TAB> <TAB> for n in range(self.editw - 1, -1, -1): <TAB> <TAB> <TAB> if self._widgets__[n].editable and not self._widgets__[n].hidden: <TAB> <TAB> <TAB> <TAB> self.editw = n <TAB> <TAB> <TAB> <TAB> break",true,if self . _widgets__ [ n ] . editable and not self . _widgets__ [ n ] . hidden :,if self . _widgets__ [ n ] . editable and not self . _widgets__ [ n ] . hidden :,1.0,0.0
"def _get_event_for_message(self, message_id): <TAB> with self.event_lock: <TAB> <TAB> if message_id not in self._events: <TAB> <TAB> <TAB> raise RuntimeError( <TAB> <TAB> <TAB> <TAB> ""Event for message[{}] should have been created before accessing"".format( <TAB> <TAB> <TAB> <TAB> <TAB> message_id <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> return self._events[message_id]",true,if message_id not in self . _events :,if message_id not in self . _events :,0.75,0.0
"def _get_deepest(self, t): <TAB> if isinstance(t, list): <TAB> <TAB> if len(t) == 1: <TAB> <TAB> <TAB> return t[0] <TAB> <TAB> else: <TAB> <TAB> <TAB> for part in t: <TAB> <TAB> <TAB> <TAB> res = self._get_deepest(part) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return res <TAB> <TAB> <TAB> return None <TAB> return None",false,if res :,if res is not None :,0.09,0.0
"def _get_notify(self, action_node): <TAB> if action_node.name not in self._skip_notify_tasks: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> task_notify = NotificationsHelper.to_model(action_node.notify) <TAB> <TAB> <TAB> return task_notify <TAB> <TAB> elif self._chain_notify: <TAB> <TAB> <TAB> return self._chain_notify <TAB> return None",true,if action_node . notify :,if action_node . notify :,0.75,0.0
"def __init__(self, centered=None, shape_params=()): <TAB> assert centered is None or isinstance(centered, (float, torch.Tensor)) <TAB> assert isinstance(shape_params, (tuple, list)) <TAB> assert all(isinstance(name, str) for name in shape_params) <TAB> if is_validation_enabled(): <TAB> <TAB> if isinstance(centered, float): <TAB> <TAB> <TAB> assert 0 <= centered and centered <= 1 <TAB> <TAB> elif isinstance(centered, torch.Tensor): <TAB> <TAB> <TAB> assert (0 <= centered).all() <TAB> <TAB> <TAB> assert (centered <= 1).all() <TAB> <TAB> else: <TAB> <TAB> <TAB> assert centered is None <TAB> self.centered = centered <TAB> self.shape_params = shape_params",false,"elif isinstance ( centered , torch . Tensor ) :","if isinstance ( centered , float ) :",0.16,0.0
"def collect(self): <TAB> for nickname in self.squid_hosts.keys(): <TAB> <TAB> squid_host = self.squid_hosts[nickname] <TAB> <TAB> fulldata = self._getData(squid_host[""host""], squid_host[""port""]) <TAB> <TAB> if fulldata is not None: <TAB> <TAB> <TAB> fulldata = fulldata.splitlines() <TAB> <TAB> <TAB> for data in fulldata: <TAB> <TAB> <TAB> <TAB> matches = self.stat_pattern.match(data) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self.publish_counter( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""%s.%s"" % (nickname, matches.group(1)), float(matches.group(2)) <TAB> <TAB> <TAB> <TAB> <TAB> )",true,if matches :,if matches :,0.53,0.0
"def test_len(self): <TAB> eq = self.assertEqual <TAB> eq(base64MIME.base64_len(""hello""), len(base64MIME.encode(""hello"", eol=""""))) <TAB> for size in range(15): <TAB> <TAB> if size == 0: <TAB> <TAB> <TAB> bsize = 0 <TAB> <TAB> elif size <= 3: <TAB> <TAB> <TAB> bsize = 4 <TAB> <TAB> elif size <= 6: <TAB> <TAB> <TAB> bsize = 8 <TAB> <TAB> elif size <= 9: <TAB> <TAB> <TAB> bsize = 12 <TAB> <TAB> elif size <= 12: <TAB> <TAB> <TAB> bsize = 16 <TAB> <TAB> else: <TAB> <TAB> <TAB> bsize = 20 <TAB> <TAB> eq(base64MIME.base64_len(""x"" * size), bsize)",false,elif size <= 9 :,elif size <= 6 :,0.39,0.0
"def wait_for_initial_conf(self, timeout=1.0): <TAB> logger.info(""Waiting for initial configuration"") <TAB> cur_timeout = timeout <TAB> # Arbiter do not already set our have_conf param <TAB> while not self.new_conf and not self.interrupted: <TAB> <TAB> elapsed, _, _ = self.handleRequests(cur_timeout) <TAB> <TAB> if elapsed: <TAB> <TAB> <TAB> cur_timeout -= elapsed <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> cur_timeout = timeout <TAB> <TAB> sys.stdout.write(""."") <TAB> <TAB> sys.stdout.flush()",false,if cur_timeout > 0 :,if cur_timeout <= 0 :,0.33,0.0
"def __init__(self, querylist=None): <TAB> self.query_id = -1 <TAB> if querylist is None: <TAB> <TAB> self.querylist = [] <TAB> else: <TAB> <TAB> self.querylist = querylist <TAB> <TAB> for query in self.querylist: <TAB> <TAB> <TAB> if self.query_id == -1: <TAB> <TAB> <TAB> <TAB> self.query_id = query.query_id <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise ValueError(""query in list must be same query_id"")",false,if self . query_id != query . query_id :,if query . query_id != self . query_id :,0.65,0.0
"def candidates() -> Generator[""Symbol"", None, None]: <TAB> s = self <TAB> if Symbol.debug_lookup: <TAB> <TAB> Symbol.debug_print(""searching in self:"") <TAB> <TAB> print(s.to_string(Symbol.debug_indent + 1), end="""") <TAB> while True: <TAB> <TAB> if matchSelf: <TAB> <TAB> <TAB> yield s <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield from s.children_recurse_anon <TAB> <TAB> else: <TAB> <TAB> <TAB> yield from s._children <TAB> <TAB> if s.siblingAbove is None: <TAB> <TAB> <TAB> break <TAB> <TAB> s = s.siblingAbove <TAB> <TAB> if Symbol.debug_lookup: <TAB> <TAB> <TAB> Symbol.debug_print(""searching in sibling:"") <TAB> <TAB> <TAB> print(s.to_string(Symbol.debug_indent + 1), end="""")",false,if recurseInAnon :,if matchAnon :,0.32,0.0
"def get_default_params(problem_type: str, penalty: str): <TAB> # TODO: get seed from seeds provider <TAB> if problem_type == REGRESSION: <TAB> <TAB> default_params = {""C"": None, ""random_state"": 0, ""fit_intercept"": True} <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> default_params[""solver""] = ""auto"" <TAB> else: <TAB> <TAB> default_params = { <TAB> <TAB> <TAB> ""C"": None, <TAB> <TAB> <TAB> ""random_state"": 0, <TAB> <TAB> <TAB> ""solver"": _get_solver(problem_type), <TAB> <TAB> <TAB> ""n_jobs"": -1, <TAB> <TAB> <TAB> ""fit_intercept"": True, <TAB> <TAB> } <TAB> model_params = list(default_params.keys()) <TAB> return model_params, default_params",false,if penalty == L2 :,"if penalty == ""auto"" :",0.14,0.0
"def _UploadDirectory(local_dir: str, gcs_bucket: storage.Bucket, gcs_dir: str): <TAB> """"""Upload the contents of a local directory to a GCS Bucket."""""" <TAB> for file_name in os.listdir(local_dir): <TAB> <TAB> path = os.path.join(local_dir, file_name) <TAB> <TAB> if not os.path.isfile(path): <TAB> <TAB> <TAB> logging.info(""Skipping %s as it's not a file."", path) <TAB> <TAB> <TAB> continue <TAB> <TAB> logging.info(""Uploading: %s"", path) <TAB> <TAB> gcs_blob = gcs_bucket.blob(f""{gcs_dir}/{file_name}"") <TAB> <TAB> gcs_blob.upload_from_filename(path)",true,if not os . path . isfile ( path ) :,if not os . path . isfile ( path ) :,1.0,0.0
"def decode_query_ids(self, trans, conditional): <TAB> if conditional.operator == ""and"": <TAB> <TAB> self.decode_query_ids(trans, conditional.left) <TAB> <TAB> self.decode_query_ids(trans, conditional.right) <TAB> else: <TAB> <TAB> left_base = conditional.left.split(""."")[0] <TAB> <TAB> if left_base in self.FIELDS: <TAB> <TAB> <TAB> field = self.FIELDS[left_base] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> conditional.right = trans.security.decode_id(conditional.right)",false,if field . id_decode :,if field . id == conditional . right :,0.19,0.0
"def data_dir(self) -> Path: <TAB> try: <TAB> <TAB> from appdirs import user_data_dir <TAB> except ImportError: <TAB> <TAB> # linux <TAB> <TAB> path = Path.home() / "".local"" / ""share"" <TAB> <TAB> if path.exists(): <TAB> <TAB> <TAB> return path / ""dephell"" <TAB> <TAB> # mac os <TAB> <TAB> path = Path.home() / ""Library"" / ""Application Support"" <TAB> <TAB> if path.exists(): <TAB> <TAB> <TAB> return path / ""dephell"" <TAB> <TAB> self.pip_main([""install"", ""appdirs""]) <TAB> <TAB> from appdirs import user_data_dir <TAB> return Path(user_data_dir(""dephell""))",true,if path . exists ( ) :,if path . exists ( ) :,0.75,0.0
"def setGameCard(self, isGameCard=False): <TAB> if isGameCard: <TAB> <TAB> targetValue = 1 <TAB> else: <TAB> <TAB> targetValue = 0 <TAB> for nca in self: <TAB> <TAB> if isinstance(nca, Nca): <TAB> <TAB> <TAB> if nca.header.getIsGameCard() == targetValue: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> Print.info(""writing isGameCard for %s, %d"" % (str(nca._path), targetValue)) <TAB> <TAB> <TAB> nca.header.setIsGameCard(targetValue)",false,if nca . header . getIsGameCard ( ) == targetValue :,"if isinstance ( nca , Nca ) :",0.01,0.0
"def check_apns_certificate(ss): <TAB> mode = ""start"" <TAB> for s in ss.split(""\n""): <TAB> <TAB> if mode == ""start"": <TAB> <TAB> <TAB> if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s: <TAB> <TAB> <TAB> <TAB> mode = ""key"" <TAB> <TAB> elif mode == ""key"": <TAB> <TAB> <TAB> if ""END RSA PRIVATE KEY"" in s or ""END PRIVATE KEY"" in s: <TAB> <TAB> <TAB> <TAB> mode = ""end"" <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> elif s.startswith(""Proc-Type"") and ""ENCRYPTED"" in s: <TAB> <TAB> <TAB> <TAB> raise ImproperlyConfigured( <TAB> <TAB> <TAB> <TAB> <TAB> ""Encrypted APNS private keys are not supported"" <TAB> <TAB> <TAB> <TAB> ) <TAB> if mode != ""end"": <TAB> <TAB> raise ImproperlyConfigured(""The APNS certificate doesn't contain a private key"")",false,"elif mode == ""key"" :","elif s . startswith ( ""Proc-Type"" ) and ""ENCRYPTED"" in s :",0.15,0.0
"def register_aggregate_groups(conn, *groups): <TAB> seen = set() <TAB> for group in groups: <TAB> <TAB> klasses = AGGREGATE_COLLECTION[group] <TAB> <TAB> for klass in klasses: <TAB> <TAB> <TAB> name = getattr(klass, ""name"", klass.__name__) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> seen.add(name) <TAB> <TAB> <TAB> <TAB> conn.create_aggregate(name, -1, klass)",true,if name not in seen :,if name not in seen :,0.75,0.0
"def _impl(inputs, input_types): <TAB> data = inputs[0] <TAB> axis = None <TAB> keepdims = False <TAB> if len(inputs) > 2:  # default, torch have only data, axis=None, keepdims=False <TAB> <TAB> if isinstance(inputs[1], int): <TAB> <TAB> <TAB> axis = int(inputs[1]) <TAB> <TAB> elif _is_int_seq(inputs[1]): <TAB> <TAB> <TAB> axis = inputs[1] <TAB> <TAB> else: <TAB> <TAB> <TAB> axis = list(_infer_shape(inputs[1])) <TAB> <TAB> keepdims = bool(inputs[2]) <TAB> return get_relay_op(name)(data, axis=axis, keepdims=keepdims)",false,elif _is_int_seq ( inputs [ 1 ] ) :,"if isinstance ( inputs [ 1 ] , int ) :",0.27,0.0
"def walks_generator(): <TAB> if filelist is not None: <TAB> <TAB> bucket = [] <TAB> <TAB> for filename in filelist: <TAB> <TAB> <TAB> with io.open(filename) as inf: <TAB> <TAB> <TAB> <TAB> for line in inf: <TAB> <TAB> <TAB> <TAB> <TAB> walk = [int(x) for x in line.strip(""\n"").split("" "")] <TAB> <TAB> <TAB> <TAB> <TAB> bucket.append(walk) <TAB> <TAB> <TAB> <TAB> <TAB> if len(bucket) == batch_size: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield bucket <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> bucket = [] <TAB> <TAB> if len(bucket): <TAB> <TAB> <TAB> yield bucket <TAB> else: <TAB> <TAB> for _ in range(epoch): <TAB> <TAB> <TAB> for nodes in graph.node_batch_iter(batch_size): <TAB> <TAB> <TAB> <TAB> walks = graph.random_walk(nodes, walk_len) <TAB> <TAB> <TAB> <TAB> yield walks",true,if len ( bucket ) :,if len ( bucket ) :,0.75,0.0
"def _calculate_runtimes(states): <TAB> results = {""runtime"": 0.00, ""num_failed_states"": 0, ""num_passed_states"": 0} <TAB> for state, resultset in states.items(): <TAB> <TAB> if isinstance(resultset, dict) and ""duration"" in resultset: <TAB> <TAB> <TAB> # Count the pass vs failures <TAB> <TAB> <TAB> if resultset[""result""]: <TAB> <TAB> <TAB> <TAB> results[""num_passed_states""] += 1 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> results[""num_failed_states""] += 1 <TAB> <TAB> <TAB> # Count durations <TAB> <TAB> <TAB> results[""runtime""] += resultset[""duration""] <TAB> log.debug(""Parsed state metrics: {}"".format(results)) <TAB> return results",false,"if isinstance ( resultset , dict ) and ""duration"" in resultset :","if resultset [ ""result"" ] :",0.01,0.0
"def _replicator_primary_device() -> snt_replicator.Replicator: <TAB> # NOTE: The explicit device list is required since currently Replicator <TAB> # only considers CPU and GPU devices. This means on TPU by default we only <TAB> # mirror on the local CPU. <TAB> for device_type in (""TPU"", ""GPU"", ""CPU""): <TAB> <TAB> devices = tf.config.experimental.list_logical_devices(device_type=device_type) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> devices = [d.name for d in devices] <TAB> <TAB> <TAB> logging.info(""Replicating over %s"", devices) <TAB> <TAB> <TAB> return snt_replicator.Replicator(devices=devices) <TAB> assert False, ""No TPU/GPU or CPU found""",true,if devices :,if devices :,0.53,0.0
"def get_tag_values(self, event): <TAB> http = event.interfaces.get(""sentry.interfaces.Http"") <TAB> if not http: <TAB> <TAB> return [] <TAB> if not http.headers: <TAB> <TAB> return [] <TAB> headers = http.headers <TAB> # XXX: transitional support for workers <TAB> if isinstance(headers, dict): <TAB> <TAB> headers = headers.items() <TAB> output = [] <TAB> for key, value in headers: <TAB> <TAB> if key != ""User-Agent"": <TAB> <TAB> <TAB> continue <TAB> <TAB> ua = Parse(value) <TAB> <TAB> if not ua: <TAB> <TAB> <TAB> continue <TAB> <TAB> result = self.get_tag_from_ua(ua) <TAB> <TAB> if result: <TAB> <TAB> <TAB> output.append(result) <TAB> return output",true,"if key != ""User-Agent"" :","if key != ""User-Agent"" :",0.75,0.0
"def general(metadata, value): <TAB> if metadata.get(""commands"") and value: <TAB> <TAB> if not metadata.get(""nargs""): <TAB> <TAB> <TAB> v = quote(value) <TAB> <TAB> else: <TAB> <TAB> <TAB> v = value <TAB> <TAB> return u""{0} {1}"".format(metadata[""commands""][0], v) <TAB> else: <TAB> <TAB> if not value: <TAB> <TAB> <TAB> return None <TAB> <TAB> elif not metadata.get(""nargs""): <TAB> <TAB> <TAB> return quote(value) <TAB> <TAB> else: <TAB> <TAB> <TAB> return value",false,"if not metadata . get ( ""nargs"" ) :","elif not metadata . get ( ""nargs"" ) :",0.41,0.0
"def _actions_read(self, c): <TAB> self.action_input.handle_read(c) <TAB> if c in [curses.KEY_ENTER, util.KEY_ENTER2]: <TAB> <TAB> # take action <TAB> <TAB> if self.action_input.selected_index == 0:  # Cancel <TAB> <TAB> <TAB> self.back_to_parent() <TAB> <TAB> elif self.action_input.selected_index == 1:  # Apply <TAB> <TAB> <TAB> self._apply_prefs() <TAB> <TAB> <TAB> client.core.get_config().addCallback(self._update_preferences) <TAB> <TAB> elif self.action_input.selected_index == 2:  # OK <TAB> <TAB> <TAB> self._apply_prefs() <TAB> <TAB> <TAB> self.back_to_parent()",false,elif self . action_input . selected_index == 2 :,elif self . action_input . selected_index == 1 :,0.88,0.0
def logic(): <TAB> if reset == 1: <TAB> <TAB> lfsr.next = 1 <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # lfsr.next[24:1] = lfsr[23:0] <TAB> <TAB> <TAB> lfsr.next = lfsr << 1 <TAB> <TAB> <TAB> lfsr.next[0] = lfsr[23] ^ lfsr[22] ^ lfsr[21] ^ lfsr[16],false,if enable :,if reset == 0 :,0.05,0.0
"def action_delete(self, request, attachments): <TAB> deleted_attachments = [] <TAB> desynced_posts = [] <TAB> for attachment in attachments: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> deleted_attachments.append(attachment.pk) <TAB> <TAB> <TAB> desynced_posts.append(attachment.post_id) <TAB> if desynced_posts: <TAB> <TAB> with transaction.atomic(): <TAB> <TAB> <TAB> for post in Post.objects.filter(id__in=desynced_posts): <TAB> <TAB> <TAB> <TAB> self.delete_from_cache(post, deleted_attachments) <TAB> for attachment in attachments: <TAB> <TAB> attachment.delete() <TAB> message = _(""Selected attachments have been deleted."") <TAB> messages.success(request, message)",false,if attachment . post :,if attachment . post_id :,0.39,0.0
"def __getitem__(self, index): <TAB> if self._check(): <TAB> <TAB> if isinstance(index, int): <TAB> <TAB> <TAB> if index < 0 or index >= len(self.features): <TAB> <TAB> <TAB> <TAB> raise IndexError(index) <TAB> <TAB> <TAB> if self.features[index] is None: <TAB> <TAB> <TAB> <TAB> feature = self.device.feature_request(FEATURE.FEATURE_SET, 0x10, index) <TAB> <TAB> <TAB> <TAB> if feature: <TAB> <TAB> <TAB> <TAB> <TAB> (feature,) = _unpack(""!H"", feature[:2]) <TAB> <TAB> <TAB> <TAB> <TAB> self.features[index] = FEATURE[feature] <TAB> <TAB> <TAB> return self.features[index] <TAB> <TAB> elif isinstance(index, slice): <TAB> <TAB> <TAB> indices = index.indices(len(self.features)) <TAB> <TAB> <TAB> return [self.__getitem__(i) for i in range(*indices)]",false,"elif isinstance ( index , slice ) :","if isinstance ( index , int ) :",0.21,0.0
"def _skip_start(self): <TAB> start, stop = self.start, self.stop <TAB> for chunk in self.app_iter: <TAB> <TAB> self._pos += len(chunk) <TAB> <TAB> if self._pos < start: <TAB> <TAB> <TAB> continue <TAB> <TAB> elif self._pos == start: <TAB> <TAB> <TAB> return b"""" <TAB> <TAB> else: <TAB> <TAB> <TAB> chunk = chunk[start - self._pos :] <TAB> <TAB> <TAB> if stop is not None and self._pos > stop: <TAB> <TAB> <TAB> <TAB> chunk = chunk[: stop - self._pos] <TAB> <TAB> <TAB> <TAB> assert len(chunk) == stop - start <TAB> <TAB> <TAB> return chunk <TAB> else: <TAB> <TAB> raise StopIteration()",false,if self . _pos < start :,elif self . _pos == start :,0.1,0.0
"def get_files(d): <TAB> f = [] <TAB> for root, dirs, files in os.walk(d): <TAB> <TAB> for name in files: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if ""qemux86copy-"" in root or ""qemux86-"" in root: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if ""do_build"" not in name and ""do_populate_sdk"" not in name: <TAB> <TAB> <TAB> <TAB> f.append(os.path.join(root, name)) <TAB> return f",false,"if ""meta-environment"" in root or ""cross-canadian"" in root :","if ""build"" in root and ""build_sdk"" not in root :",0.32,0.0
"def _load_windows_store_certs(self, storename, purpose): <TAB> certs = bytearray() <TAB> try: <TAB> <TAB> for cert, encoding, trust in enum_certificates(storename): <TAB> <TAB> <TAB> # CA certs are never PKCS#7 encoded <TAB> <TAB> <TAB> if encoding == ""x509_asn"": <TAB> <TAB> <TAB> <TAB> if trust is True or purpose.oid in trust: <TAB> <TAB> <TAB> <TAB> <TAB> certs.extend(cert) <TAB> except PermissionError: <TAB> <TAB> warnings.warn(""unable to enumerate Windows certificate store"") <TAB> if certs: <TAB> <TAB> self.load_verify_locations(cadata=certs) <TAB> return certs",true,"if encoding == ""x509_asn"" :","if encoding == ""x509_asn"" :",0.75,0.0
"def test_tokenizer_identifier_with_correct_config(self): <TAB> for tokenizer_class in [BertTokenizer, BertTokenizerFast, AutoTokenizer]: <TAB> <TAB> tokenizer = tokenizer_class.from_pretrained(""wietsedv/bert-base-dutch-cased"") <TAB> <TAB> self.assertIsInstance(tokenizer, (BertTokenizer, BertTokenizerFast)) <TAB> <TAB> if isinstance(tokenizer, BertTokenizer): <TAB> <TAB> <TAB> self.assertEqual(tokenizer.basic_tokenizer.do_lower_case, False) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.assertEqual(tokenizer.do_lower_case, False) <TAB> <TAB> self.assertEqual(tokenizer.model_max_length, 512)",true,"if isinstance ( tokenizer , BertTokenizer ) :","if isinstance ( tokenizer , BertTokenizer ) :",0.75,0.0
"def run(self): <TAB> global WAITING_BEFORE_START <TAB> time.sleep(WAITING_BEFORE_START) <TAB> while self.keep_alive: <TAB> <TAB> path_id, module, resolve = self.queue_receive.get() <TAB> <TAB> if path_id is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> self.lock.acquire() <TAB> <TAB> self.modules[path_id] = module <TAB> <TAB> self.lock.release() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> resolution = self._resolve_with_other_modules(resolve) <TAB> <TAB> <TAB> self._relations[path_id] = [] <TAB> <TAB> <TAB> for package in resolution: <TAB> <TAB> <TAB> <TAB> self._relations[path_id].append(resolution[package]) <TAB> <TAB> <TAB> self.queue_send.put((path_id, module, False, resolution))",false,if resolve :,if resolve is not None :,0.09,0.0
"def __new__(mcs, name, bases, attrs): <TAB> include_profile = include_trace = include_garbage = True <TAB> bases = list(bases) <TAB> if name == ""SaltLoggingClass"": <TAB> <TAB> for base in bases: <TAB> <TAB> <TAB> if hasattr(base, ""trace""): <TAB> <TAB> <TAB> <TAB> include_trace = False <TAB> <TAB> <TAB> if hasattr(base, ""garbage""): <TAB> <TAB> <TAB> <TAB> include_garbage = False <TAB> if include_profile: <TAB> <TAB> bases.append(LoggingProfileMixin) <TAB> if include_trace: <TAB> <TAB> bases.append(LoggingTraceMixin) <TAB> if include_garbage: <TAB> <TAB> bases.append(LoggingGarbageMixin) <TAB> return super(LoggingMixinMeta, mcs).__new__(mcs, name, tuple(bases), attrs)",false,"if hasattr ( base , ""garbage"" ) :","if hasattr ( base , ""trace"" ) :",0.55,0.0
"def __str__(self, prefix="""", printElemNumber=0): <TAB> res = """" <TAB> if self.has_owner_: <TAB> <TAB> res += prefix + (""owner: %s\n"" % self.DebugFormatString(self.owner_)) <TAB> cnt = 0 <TAB> for e in self.entries_: <TAB> <TAB> elm = """" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> elm = ""(%d)"" % cnt <TAB> <TAB> res += prefix + (""entries%s <\n"" % elm) <TAB> <TAB> res += e.__str__(prefix + ""  "", printElemNumber) <TAB> <TAB> res += prefix + "">\n"" <TAB> <TAB> cnt += 1 <TAB> return res",true,if printElemNumber :,if printElemNumber :,0.53,0.0
"def parse_tag(self): <TAB> buf = [] <TAB> escaped = False <TAB> for c in self.get_next_chars(): <TAB> <TAB> if escaped: <TAB> <TAB> <TAB> buf.append(c) <TAB> <TAB> elif c == ""\\"": <TAB> <TAB> <TAB> escaped = True <TAB> <TAB> elif c == "">"": <TAB> <TAB> <TAB> return """".join(buf) <TAB> <TAB> else: <TAB> <TAB> <TAB> buf.append(c) <TAB> raise Exception(""Unclosed tag "" + """".join(buf))",true,"elif c == "">"" :","elif c == "">"" :",1.0,0.0
"def get_batches(train_nodes, train_labels, batch_size=64, shuffle=True): <TAB> if shuffle: <TAB> <TAB> random.shuffle(train_nodes) <TAB> total = train_nodes.shape[0] <TAB> for i in range(0, total, batch_size): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> cur_nodes = train_nodes[i : i + batch_size] <TAB> <TAB> <TAB> cur_labels = train_labels[cur_nodes] <TAB> <TAB> <TAB> yield cur_nodes, cur_labels",false,if i + batch_size <= total :,if i + batch_size < total :,0.25,0.0
"def _get_all_info_lines(data): <TAB> infos = [] <TAB> for row in data: <TAB> <TAB> splitrow = row.split() <TAB> <TAB> if len(splitrow) > 0: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> infos.append("" "".join(splitrow[1:])) <TAB> return infos",false,"if splitrow [ 0 ] == ""INFO:"" :","if splitrow [ 0 ] == ""info"" and ""info"" in splitrow :",0.35,0.0
"def _validate_client_public_key(self, username, key_data): <TAB> """"""Validate a client public key for the specified user"""""" <TAB> try: <TAB> <TAB> key = decode_ssh_public_key(key_data) <TAB> except KeyImportError: <TAB> <TAB> return None <TAB> options = None <TAB> if self._client_keys: <TAB> <TAB> options = self._client_keys.validate(key, self._peer_addr) <TAB> if options is None: <TAB> <TAB> result = self._owner.validate_public_key(username, key) <TAB> <TAB> if asyncio.iscoroutine(result): <TAB> <TAB> <TAB> result = yield from result <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> options = {} <TAB> self._key_options = options <TAB> return key",true,if not result :,if not result :,0.75,0.0
"def attach_related_versions(addons, addon_dict=None): <TAB> if addon_dict is None: <TAB> <TAB> addon_dict = {addon.id: addon for addon in addons} <TAB> all_ids = set(filter(None, (addon._current_version_id for addon in addons))) <TAB> versions = list(Version.objects.filter(id__in=all_ids).order_by()) <TAB> for version in versions: <TAB> <TAB> try: <TAB> <TAB> <TAB> addon = addon_dict[version.addon_id] <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> log.info(""Version %s has an invalid add-on id."" % version.id) <TAB> <TAB> <TAB> continue <TAB> <TAB> if addon._current_version_id == version.id: <TAB> <TAB> <TAB> addon._current_version = version <TAB> <TAB> version.addon = addon",true,if addon . _current_version_id == version . id :,if addon . _current_version_id == version . id :,0.75,0.0
"def move_view(obj, evt): <TAB> position = obj.GetCurrentCursorPosition() <TAB> for other_axis, axis_number in self._axis_names.iteritems(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> ipw3d = getattr(self, ""ipw_3d_%s"" % other_axis) <TAB> <TAB> ipw3d.ipw.slice_position = position[axis_number]",false,if other_axis == axis_name :,if axis_number not in position :,0.03,0.0
"def func_wrapper(*args, **kwargs): <TAB> warnings.simplefilter(""always"", DeprecationWarning)  # turn off filter <TAB> for old, new in arg_mapping.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> warnings.warn( <TAB> <TAB> <TAB> <TAB> f""Keyword argument '{old}' has been "" <TAB> <TAB> <TAB> <TAB> f""deprecated in favour of '{new}'. "" <TAB> <TAB> <TAB> <TAB> f""'{old}' will be removed in a future version."", <TAB> <TAB> <TAB> <TAB> category=DeprecationWarning, <TAB> <TAB> <TAB> <TAB> stacklevel=2, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> val = kwargs.pop(old) <TAB> <TAB> <TAB> kwargs[new] = val <TAB> # reset filter <TAB> warnings.simplefilter(""default"", DeprecationWarning) <TAB> return func(*args, **kwargs)",true,if old in kwargs :,if old in kwargs :,0.75,0.0
"def inner_connection_checker(self, *args, **kwargs): <TAB> LOG.debug(""in _connection_checker"") <TAB> for attempts in range(5): <TAB> <TAB> try: <TAB> <TAB> <TAB> return func(self, *args, **kwargs) <TAB> <TAB> except exception.VolumeBackendAPIException as e: <TAB> <TAB> <TAB> pattern = re.compile(r"".*Session id expired$"") <TAB> <TAB> <TAB> matches = pattern.match(six.text_type(e)) <TAB> <TAB> <TAB> if matches: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> LOG.debug(""Session might have expired."" "" Trying to relogin"") <TAB> <TAB> <TAB> <TAB> <TAB> self._login() <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> LOG.error(""Re-throwing Exception %s"", e) <TAB> <TAB> <TAB> raise",false,if attempts < 4 :,if attempts == 0 :,0.31,0.0
"def set(self, pcount): <TAB> """"""Set channel prefetch_count setting."""""" <TAB> if pcount != self.prev: <TAB> <TAB> new_value = pcount <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> logger.warning( <TAB> <TAB> <TAB> <TAB> ""QoS: Disabled: prefetch_count exceeds %r"", PREFETCH_COUNT_MAX <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> new_value = 0 <TAB> <TAB> logger.debug(""basic.qos: prefetch_count->%s"", new_value) <TAB> <TAB> self.callback(prefetch_count=new_value) <TAB> <TAB> self.prev = pcount <TAB> return pcount",false,if pcount > PREFETCH_COUNT_MAX :,if new_value > PREFETCH_COUNT_MAX :,0.39,0.0
"def _build_gcs_object_key(self, key): <TAB> if self.platform_specific_separator: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> gcs_object_key = os.path.join( <TAB> <TAB> <TAB> <TAB> self.prefix, self._convert_key_to_filepath(key) <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> gcs_object_key = self._convert_key_to_filepath(key) <TAB> else: <TAB> <TAB> if self.prefix: <TAB> <TAB> <TAB> gcs_object_key = ""/"".join((self.prefix, self._convert_key_to_filepath(key))) <TAB> <TAB> else: <TAB> <TAB> <TAB> gcs_object_key = self._convert_key_to_filepath(key) <TAB> return gcs_object_key",true,if self . prefix :,if self . prefix :,0.75,0.0
"def number_operators(self, a, b, skip=[]): <TAB> dict = {""a"": a, ""b"": b} <TAB> for name, expr in self.binops.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> name = ""__%s__"" % name <TAB> <TAB> <TAB> if hasattr(a, name): <TAB> <TAB> <TAB> <TAB> res = eval(expr, dict) <TAB> <TAB> <TAB> <TAB> self.binop_test(a, b, res, expr, name) <TAB> for name, expr in self.unops.items(): <TAB> <TAB> if name not in skip: <TAB> <TAB> <TAB> name = ""__%s__"" % name <TAB> <TAB> <TAB> if hasattr(a, name): <TAB> <TAB> <TAB> <TAB> res = eval(expr, dict) <TAB> <TAB> <TAB> <TAB> self.unop_test(a, res, expr, name)",true,if name not in skip :,if name not in skip :,0.75,0.0
def isCurveMonotonic(set_): <TAB> for i in range(len(set_) - 1): <TAB> <TAB> # ==== added by zli ======= <TAB> <TAB> if set_[i][0] >= set_[i + 1][0]: <TAB> <TAB> <TAB> return False <TAB> <TAB> # ==== added by zli ======= <TAB> <TAB> # ==== added by zli ======= <TAB> <TAB> # if set_[i][1] > set_[i + 1][1]: <TAB> <TAB> if set_[i][1] >= set_[i + 1][1]: <TAB> <TAB> <TAB> # ==== added by zli ======= <TAB> <TAB> <TAB> return False <TAB> return True,true,if set_ [ i ] [ 0 ] >= set_ [ i + 1 ] [ 0 ] :,if set_ [ i ] [ 0 ] >= set_ [ i + 1 ] [ 0 ] :,1.0,0.0
"def show_topics(): <TAB> """"""prints all available miscellaneous help topics."""""" <TAB> print(_stash.text_color(""Miscellaneous Topics:"", ""yellow"")) <TAB> for pp in PAGEPATHS: <TAB> <TAB> if not os.path.isdir(pp): <TAB> <TAB> <TAB> continue <TAB> <TAB> content = os.listdir(pp) <TAB> <TAB> for pn in content: <TAB> <TAB> <TAB> if ""."" in pn: <TAB> <TAB> <TAB> <TAB> name = pn[: pn.index(""."")] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> name = pn <TAB> <TAB> <TAB> print(name)",true,if not os . path . isdir ( pp ) :,if not os . path . isdir ( pp ) :,0.75,0.0
"def test_send_error(self): <TAB> allow_transfer_encoding_codes = (205, 304) <TAB> for code in (101, 102, 204, 205, 304): <TAB> <TAB> self.con.request(""SEND_ERROR"", ""/{}"".format(code)) <TAB> <TAB> res = self.con.getresponse() <TAB> <TAB> self.assertEqual(code, res.status) <TAB> <TAB> self.assertEqual(None, res.getheader(""Content-Length"")) <TAB> <TAB> self.assertEqual(None, res.getheader(""Content-Type"")) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.assertEqual(None, res.getheader(""Transfer-Encoding"")) <TAB> <TAB> data = res.read() <TAB> <TAB> self.assertEqual(b"""", data)",false,if code not in allow_transfer_encoding_codes :,if allow_transfer_encoding_codes :,0.05,0.0
"def _length_hint(obj): <TAB> """"""Returns the length hint of an object."""""" <TAB> try: <TAB> <TAB> return len(obj) <TAB> except (AttributeError, TypeError): <TAB> <TAB> try: <TAB> <TAB> <TAB> get_hint = type(obj).__length_hint__ <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> return None <TAB> <TAB> try: <TAB> <TAB> <TAB> hint = get_hint(obj) <TAB> <TAB> except TypeError: <TAB> <TAB> <TAB> return None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> return hint",false,"if hint is NotImplemented or not isinstance ( hint , int_types ) or hint < 0 :",if hint is None :,0.16,0.0
"def _rmtree(self, path): <TAB> # Essentially a stripped down version of shutil.rmtree.  We can't <TAB> # use globals because they may be None'ed out at shutdown. <TAB> for name in self._listdir(path): <TAB> <TAB> fullname = self._path_join(path, name) <TAB> <TAB> try: <TAB> <TAB> <TAB> isdir = self._isdir(fullname) <TAB> <TAB> except self._os_error: <TAB> <TAB> <TAB> isdir = False <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._rmtree(fullname) <TAB> <TAB> else: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> self._remove(fullname) <TAB> <TAB> <TAB> except self._os_error: <TAB> <TAB> <TAB> <TAB> pass <TAB> try: <TAB> <TAB> self._rmdir(path) <TAB> except self._os_error: <TAB> <TAB> pass",true,if isdir :,if isdir :,0.53,0.0
"def get_sources(self, sources=None): <TAB> """"""Returns all sources from this provider."""""" <TAB> self._load() <TAB> if sources is None: <TAB> <TAB> sources = list(self.data.keys()) <TAB> elif not isinstance(sources, (list, tuple)): <TAB> <TAB> sources = [sources] <TAB> for source in sources: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise KeyError( <TAB> <TAB> <TAB> <TAB> ""Invalid data key: {}. Valid keys are: {}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> source, "", "".join(str(k) for k in self.data) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return {k: self.data[k] for k in sources}",true,if source not in self . data :,if source not in self . data :,0.75,0.0
"def do_shorts( <TAB> opts: List[Tuple[str, str]], optstring: str, shortopts: str, args: List[str] ) -> Tuple[List[Tuple[str, str]], List[str]]: <TAB> while optstring != """": <TAB> <TAB> opt, optstring = optstring[0], optstring[1:] <TAB> <TAB> if short_has_arg(opt, shortopts): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if not args: <TAB> <TAB> <TAB> <TAB> <TAB> raise GetoptError(""option -%s requires argument"" % opt, opt) <TAB> <TAB> <TAB> <TAB> optstring, args = args[0], args[1:] <TAB> <TAB> <TAB> optarg, optstring = optstring, """" <TAB> <TAB> else: <TAB> <TAB> <TAB> optarg = """" <TAB> <TAB> opts.append((""-"" + opt, optarg)) <TAB> return opts, args",true,"if optstring == """" :","if optstring == """" :",0.75,0.0
"def _sanitize_dict(self, config_dict, allow_val_change=None, ignore_keys: set = None): <TAB> sanitized = {} <TAB> for k, v in six.iteritems(config_dict): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> k, v = self._sanitize(k, v, allow_val_change) <TAB> <TAB> sanitized[k] = v <TAB> return sanitized",false,if ignore_keys and k in ignore_keys :,if k in ignore_keys :,0.23,0.0
def x(data): <TAB> count = 0 <TAB> while count < 10: <TAB> <TAB> data.start_example(SOME_LABEL) <TAB> <TAB> b = data.draw_bits(1) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> count += 1 <TAB> <TAB> data.stop_example(discard=not b) <TAB> data.mark_interesting(),true,if b :,if b :,0.53,0.0
"def prompt_for_resume(config): <TAB> logger = logging.getLogger(""changeme"") <TAB> logger.error( <TAB> <TAB> ""A previous scan was interrupted. Type R to resume or F to start a fresh scan"" <TAB> ) <TAB> answer = """" <TAB> while not (answer == ""R"" or answer == ""F""): <TAB> <TAB> prompt = ""(R/F)> "" <TAB> <TAB> answer = """" <TAB> <TAB> try: <TAB> <TAB> <TAB> answer = raw_input(prompt) <TAB> <TAB> except NameError: <TAB> <TAB> <TAB> answer = input(prompt) <TAB> <TAB> if answer.upper() == ""F"": <TAB> <TAB> <TAB> logger.debug(""Forcing a fresh scan"") <TAB> <TAB> elif answer.upper() == ""R"": <TAB> <TAB> <TAB> logger.debug(""Resuming previous scan"") <TAB> <TAB> <TAB> config.resume = True <TAB> return config.resume",false,"elif answer . upper ( ) == ""R"" :","if answer . upper ( ) == ""F"" :",0.31,0.0
"def _evaluate_local_single(self, iterator): <TAB> for batch in iterator: <TAB> <TAB> in_arrays = convert._call_converter(self.converter, batch, self.device) <TAB> <TAB> with function.no_backprop_mode(): <TAB> <TAB> <TAB> if isinstance(in_arrays, tuple): <TAB> <TAB> <TAB> <TAB> results = self.calc_local(*in_arrays) <TAB> <TAB> <TAB> elif isinstance(in_arrays, dict): <TAB> <TAB> <TAB> <TAB> results = self.calc_local(**in_arrays) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> results = self.calc_local(in_arrays) <TAB> <TAB> if self._progress_hook: <TAB> <TAB> <TAB> self._progress_hook(batch) <TAB> <TAB> yield results",true,"if isinstance ( in_arrays , tuple ) :","if isinstance ( in_arrays , tuple ) :",0.75,0.0
"def _send_until_done(self, data): <TAB> while True: <TAB> <TAB> try: <TAB> <TAB> <TAB> return self.connection.send(data) <TAB> <TAB> except OpenSSL.SSL.WantWriteError: <TAB> <TAB> <TAB> if not util.wait_for_write(self.socket, self.socket.gettimeout()): <TAB> <TAB> <TAB> <TAB> raise timeout() <TAB> <TAB> <TAB> continue <TAB> <TAB> except OpenSSL.SSL.SysCallError as e: <TAB> <TAB> <TAB> raise SocketError(str(e))",true,"if not util . wait_for_write ( self . socket , self . socket . gettimeout ( ) ) :","if not util . wait_for_write ( self . socket , self . socket . gettimeout ( ) ) :",0.75,0.0
"def _read_jtl_chunk(self, jtl): <TAB> data = jtl.read(1024 * 1024 * 10) <TAB> if data: <TAB> <TAB> parts = data.rsplit(""\n"", 1) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ready_chunk = self.buffer + parts[0] + ""\n"" <TAB> <TAB> <TAB> self.buffer = parts[1] <TAB> <TAB> <TAB> df = string_to_df(ready_chunk) <TAB> <TAB> <TAB> self.stat_queue.put(df) <TAB> <TAB> <TAB> return df <TAB> <TAB> else: <TAB> <TAB> <TAB> self.buffer += parts[0] <TAB> else: <TAB> <TAB> if self.jmeter_finished: <TAB> <TAB> <TAB> self.agg_finished = True <TAB> <TAB> jtl.readline() <TAB> return None",true,if len ( parts ) > 1 :,if len ( parts ) > 1 :,0.75,0.0
"def __new__(mcl, classname, bases, dictionary): <TAB> slots = list(dictionary.get(""__slots__"", [])) <TAB> for getter_name in [key for key in dictionary if key.startswith(""get_"")]: <TAB> <TAB> name = getter_name <TAB> <TAB> slots.append(""__"" + name) <TAB> <TAB> getter = dictionary.pop(getter_name) <TAB> <TAB> setter = dictionary.get(setter_name, None) <TAB> <TAB> if setter is not None and isinstance(setter, collections.Callable): <TAB> <TAB> <TAB> del dictionary[setter_name] <TAB> <TAB> dictionary[name] = property(getter.setter) <TAB> <TAB> dictionary[""__slots__""] = tuple(slots) <TAB> <TAB> return super().__new__(mcl, classname, bases, dictionary)",true,"if setter is not None and isinstance ( setter , collections . Callable ) :","if setter is not None and isinstance ( setter , collections . Callable ) :",0.75,0.0
"def tex_coords(self): <TAB> """"""Array of texture coordinate data."""""" <TAB> if ""multi_tex_coords"" not in self.domain.attribute_names: <TAB> <TAB> if self._tex_coords_cache_version != self.domain._version: <TAB> <TAB> <TAB> domain = self.domain <TAB> <TAB> <TAB> attribute = domain.attribute_names[""tex_coords""] <TAB> <TAB> <TAB> self._tex_coords_cache = attribute.get_region( <TAB> <TAB> <TAB> <TAB> attribute.buffer, self.start, self.count <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self._tex_coords_cache_version = domain._version <TAB> <TAB> region = self._tex_coords_cache <TAB> <TAB> region.invalidate() <TAB> <TAB> return region.array <TAB> else: <TAB> <TAB> return None",true,if self . _tex_coords_cache_version != self . domain . _version :,if self . _tex_coords_cache_version != self . domain . _version :,1.0,0.0
"def index(self, sub, start=0): <TAB> """"""Returns the index of the closing bracket"""""" <TAB> br = ""([{<""["")]}>"".index(sub)] <TAB> count = 0 <TAB> for i in range(start, len(self.string)): <TAB> <TAB> char = self.string[i] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> count += 1 <TAB> <TAB> elif char == sub: <TAB> <TAB> <TAB> if count > 0: <TAB> <TAB> <TAB> <TAB> count -= 1 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return i <TAB> err = ""Closing bracket {!r} missing in string {!r}"".format( <TAB> <TAB> sub, """".join(self.original) <TAB> ) <TAB> raise ParseError(err)",false,if char == br :,if char in br :,0.14,0.0
"def test_createFile(self): <TAB> text = ""This is a test!"" <TAB> path = tempfile.mktemp() <TAB> try: <TAB> <TAB> koDoc = self._koDocFromPath(path, load=False) <TAB> <TAB> koDoc.buffer = text <TAB> <TAB> koDoc.save(0) <TAB> <TAB> del koDoc <TAB> <TAB> koDoc2 = self._koDocFromPath(path) <TAB> <TAB> assert koDoc2.buffer == text <TAB> finally: <TAB> <TAB> if os.path.exists(path): <TAB> <TAB> <TAB> os.unlink(path)  # clean up",true,if os . path . exists ( path ) :,if os . path . exists ( path ) :,1.0,0.0
"def __editScopeHasEdit(self, attributeHistory): <TAB> with attributeHistory.context: <TAB> <TAB> tweak = GafferScene.EditScopeAlgo.acquireParameterEdit( <TAB> <TAB> <TAB> attributeHistory.scene.node(), <TAB> <TAB> <TAB> attributeHistory.context[""scene:path""], <TAB> <TAB> <TAB> attributeHistory.attributeName, <TAB> <TAB> <TAB> IECoreScene.ShaderNetwork.Parameter("""", self.__parameter), <TAB> <TAB> <TAB> createIfNecessary=False, <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> return tweak[""enabled""].getValue()",true,if tweak is None :,if tweak is None :,0.75,0.0
"def mail_migrator(app, schema_editor): <TAB> Event_SettingsStore = app.get_model(""pretixbase"", ""Event_SettingsStore"") <TAB> for ss in Event_SettingsStore.objects.filter( <TAB> <TAB> key__in=[ <TAB> <TAB> <TAB> ""mail_text_order_approved"", <TAB> <TAB> <TAB> ""mail_text_order_placed"", <TAB> <TAB> <TAB> ""mail_text_order_placed_require_approval"", <TAB> <TAB> ] <TAB> ): <TAB> <TAB> chgd = ss.value.replace(""{date}"", ""{expire_date}"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ss.value = chgd <TAB> <TAB> <TAB> ss.save() <TAB> <TAB> <TAB> cache.delete(""hierarkey_{}_{}"".format(""event"", ss.object_id))",false,if chgd != ss . value :,if chgd :,0.04,0.0
"def __get_limits(self): <TAB> dimension = len(self.__tree.get_root().data) <TAB> nodes = self.__get_all_nodes() <TAB> max, min = [float(""-inf"")] * dimension, [float(""+inf"")] * dimension <TAB> for node in nodes: <TAB> <TAB> for d in range(dimension): <TAB> <TAB> <TAB> if max[d] < node.data[d]: <TAB> <TAB> <TAB> <TAB> max[d] = node.data[d] <TAB> <TAB> <TAB> if min[d] > node.data[d]: <TAB> <TAB> <TAB> <TAB> min[d] = node.data[d] <TAB> return min, max",true,if min [ d ] > node . data [ d ] :,if min [ d ] > node . data [ d ] :,1.0,0.0
"def get_complete_position(self, context: UserContext) -> int: <TAB> # Check member prefix pattern. <TAB> for prefix_pattern in convert2list( <TAB> <TAB> self.get_filetype_var(context[""filetype""], ""prefix_patterns"") <TAB> ): <TAB> <TAB> m = re.search(self._object_pattern + prefix_pattern + r""\w*$"", context[""input""]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> self._prefix = re.sub(r""\w*$"", """", m.group(0)) <TAB> <TAB> m = re.search(r""\w*$"", context[""input""]) <TAB> <TAB> if m: <TAB> <TAB> <TAB> return m.start() <TAB> return -1",false,"if m is None or prefix_pattern == """" :",if not m :,0.02,0.0
"def _stderr_supports_color(): <TAB> try: <TAB> <TAB> if hasattr(sys.stderr, ""isatty"") and sys.stderr.isatty(): <TAB> <TAB> <TAB> if curses: <TAB> <TAB> <TAB> <TAB> curses.setupterm() <TAB> <TAB> <TAB> <TAB> if curses.tigetnum(""colors"") > 0: <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> elif colorama: <TAB> <TAB> <TAB> <TAB> if sys.stderr is getattr( <TAB> <TAB> <TAB> <TAB> <TAB> colorama.initialise, ""wrapped_stderr"", object() <TAB> <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> except Exception: <TAB> <TAB> # Very broad exception handling because it's always better to <TAB> <TAB> # fall back to non-colored logs than to break at startup. <TAB> <TAB> pass <TAB> return False",false,elif colorama :,"if curses . tigetnum ( ""colors"" ) > 0 :",0.03,0.0
"def setLabelColumnWidth(self, panel, width): <TAB> for child in panel.GetChildren(): <TAB> <TAB> if isinstance(child, wx.lib.stattext.GenStaticText): <TAB> <TAB> <TAB> size = child.GetSize() <TAB> <TAB> <TAB> size[0] = width <TAB> <TAB> <TAB> child.SetBestSize(size)",true,"if isinstance ( child , wx . lib . stattext . GenStaticText ) :","if isinstance ( child , wx . lib . stattext . GenStaticText ) :",0.75,0.0
"def update(self, other): <TAB> if other.M is None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.items.update(other.items) <TAB> <TAB> else: <TAB> <TAB> <TAB> for i in other.items: <TAB> <TAB> <TAB> <TAB> self.add(i) <TAB> <TAB> return <TAB> if self.M is None: <TAB> <TAB> self.convert() <TAB> self.M = array.array(""B"", list(map(max, list(zip(self.M, other.M)))))",false,if self . M is None :,if self . items is not None :,0.25,0.0
"def on_end_epoch(self, state): <TAB> if self.write_epoch_metrics: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.writer.add_text( <TAB> <TAB> <TAB> <TAB> ""epoch"", <TAB> <TAB> <TAB> <TAB> ""<h4>Epoch {}</h4>"".format(state[torchbearer.EPOCH]) <TAB> <TAB> <TAB> <TAB> + self.table_formatter(str(state[torchbearer.METRICS])), <TAB> <TAB> <TAB> <TAB> 1, <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.writer.add_text( <TAB> <TAB> <TAB> <TAB> ""epoch"", <TAB> <TAB> <TAB> <TAB> self.table_formatter(str(state[torchbearer.METRICS])), <TAB> <TAB> <TAB> <TAB> state[torchbearer.EPOCH], <TAB> <TAB> <TAB> )",false,if self . visdom :,if self . use_epoch_metrics :,0.39,0.0
"def is_listening_for_message(conversation_id: Text, endpoint: EndpointConfig) -> bool: <TAB> """"""Check if the conversation is in need for a user message."""""" <TAB> tracker = await retrieve_tracker(endpoint, conversation_id, EventVerbosity.APPLIED) <TAB> for i, e in enumerate(reversed(tracker.get(""events"", []))): <TAB> <TAB> if e.get(""event"") == UserUttered.type_name: <TAB> <TAB> <TAB> return False <TAB> <TAB> elif e.get(""event"") == ActionExecuted.type_name: <TAB> <TAB> <TAB> return e.get(""name"") == ACTION_LISTEN_NAME <TAB> return False",false,"if e . get ( ""event"" ) == UserUttered . type_name :","elif e . get ( ""event"" ) == ActionExecuted . type_name :",0.36,0.0
"def filter_ports(self, dpid, in_port, nw_id, allow_nw_id_external=None): <TAB> assert nw_id != self.nw_id_unknown <TAB> ret = [] <TAB> for port in self.get_ports(dpid): <TAB> <TAB> nw_id_ = port.network_id <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if nw_id_ == nw_id: <TAB> <TAB> <TAB> ret.append(port.port_no) <TAB> <TAB> elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external: <TAB> <TAB> <TAB> ret.append(port.port_no) <TAB> return ret",false,if port . port_no == in_port :,if in_port :,0.04,0.0
"def next_month(billing_cycle_anchor: datetime, dt: datetime) -> datetime: <TAB> estimated_months = round((dt - billing_cycle_anchor).days * 12.0 / 365) <TAB> for months in range(max(estimated_months - 1, 0), estimated_months + 2): <TAB> <TAB> proposed_next_month = add_months(billing_cycle_anchor, months) <TAB> <TAB> if 20 < (proposed_next_month - dt).days < 40: <TAB> <TAB> <TAB> return proposed_next_month <TAB> raise AssertionError( <TAB> <TAB> ""Something wrong in next_month calculation with "" <TAB> <TAB> f""billing_cycle_anchor: {billing_cycle_anchor}, dt: {dt}"" <TAB> )",true,if 20 < ( proposed_next_month - dt ) . days < 40 :,if 20 < ( proposed_next_month - dt ) . days < 40 :,0.75,0.0
"def wait_complete(self): <TAB> """"""Wait for futures complete done."""""" <TAB> for future in concurrent.futures.as_completed(self._futures.keys()): <TAB> <TAB> try: <TAB> <TAB> <TAB> error = future.exception() <TAB> <TAB> except concurrent.futures.CancelledError: <TAB> <TAB> <TAB> break <TAB> <TAB> name = self._futures[future] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> err_msg = 'Extracting ""{0}"", got: {1}'.format(name, error) <TAB> <TAB> <TAB> logger.error(err_msg)",false,if error is not None :,if error :,0.05,0.0
"def _accept_with(cls, orm, target): <TAB> if target is orm.mapper: <TAB> <TAB> return mapperlib.Mapper <TAB> elif isinstance(target, type): <TAB> <TAB> if issubclass(target, mapperlib.Mapper): <TAB> <TAB> <TAB> return target <TAB> <TAB> else: <TAB> <TAB> <TAB> mapper = _mapper_or_none(target) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return mapper <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return _MapperEventsHold(target) <TAB> else: <TAB> <TAB> return target",false,if mapper is not None :,if mapper :,0.05,0.0
"def gvariant_args(args: List[Any]) -> str: <TAB> """"""Convert args into gvariant."""""" <TAB> gvariant = """" <TAB> for arg in args: <TAB> <TAB> if isinstance(arg, bool): <TAB> <TAB> <TAB> gvariant += "" {}"".format(str(arg).lower()) <TAB> <TAB> elif isinstance(arg, (int, float)): <TAB> <TAB> <TAB> gvariant += f"" {arg}"" <TAB> <TAB> elif isinstance(arg, str): <TAB> <TAB> <TAB> gvariant += f' ""{arg}""' <TAB> <TAB> else: <TAB> <TAB> <TAB> gvariant += f"" {arg!s}"" <TAB> return gvariant.lstrip()",false,"if isinstance ( arg , bool ) :","elif isinstance ( arg , str ) :",0.2,0.0
"def _list_cases(suite): <TAB> for test in suite: <TAB> <TAB> if isinstance(test, unittest.TestSuite): <TAB> <TAB> <TAB> _list_cases(test) <TAB> <TAB> elif isinstance(test, unittest.TestCase): <TAB> <TAB> <TAB> if support.match_test(test): <TAB> <TAB> <TAB> <TAB> print(test.id())",false,"elif isinstance ( test , unittest . TestCase ) :",if support . match_test ( test ) :,0.03,0.0
def get_and_set_all_disambiguation(self): <TAB> all_disambiguations = [] <TAB> for page in self.pages: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> all_disambiguations.extend(page.relations.disambiguation_links_norm) <TAB> <TAB> if page.relations.disambiguation_links is not None: <TAB> <TAB> <TAB> all_disambiguations.extend(page.relations.disambiguation_links) <TAB> return set(all_disambiguations),true,if page . relations . disambiguation_links_norm is not None :,if page . relations . disambiguation_links_norm is not None :,0.75,0.0
"def test_decode_invalid(self): <TAB> testcases = [ <TAB> <TAB> (b""xn--w&"", ""strict"", UnicodeError()), <TAB> <TAB> (b""xn--w&"", ""ignore"", ""xn-""), <TAB> ] <TAB> for puny, errors, expected in testcases: <TAB> <TAB> with self.subTest(puny=puny, errors=errors): <TAB> <TAB> <TAB> if isinstance(expected, Exception): <TAB> <TAB> <TAB> <TAB> self.assertRaises(UnicodeError, puny.decode, ""punycode"", errors) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.assertEqual(puny.decode(""punycode"", errors), expected)",true,"if isinstance ( expected , Exception ) :","if isinstance ( expected , Exception ) :",0.75,0.0
"def find_globs(walker, patterns, matches): <TAB> for root, dirs, files in walker: <TAB> <TAB> for d in dirs: <TAB> <TAB> <TAB> d = join(root, d) <TAB> <TAB> <TAB> for pattern in patterns: <TAB> <TAB> <TAB> <TAB> for p in Path(d).glob(pattern): <TAB> <TAB> <TAB> <TAB> <TAB> matches.add(str(p)) <TAB> <TAB> sub_files = set() <TAB> <TAB> for p in matches: <TAB> <TAB> <TAB> if root.startswith(p): <TAB> <TAB> <TAB> <TAB> for f in files: <TAB> <TAB> <TAB> <TAB> <TAB> sub_files.add(join(root, f)) <TAB> <TAB> matches.update(sub_files)",true,if root . startswith ( p ) :,if root . startswith ( p ) :,0.75,0.0
"def parse_stack_trace(self, it, line): <TAB> """"""Iterate over lines and parse stack traces."""""" <TAB> events = [] <TAB> stack_traces = [] <TAB> while self.stack_trace_re.match(line): <TAB> <TAB> event = self.parse_stack_trace_line(line) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> events.append(event) <TAB> <TAB> stack_traces.append(line) <TAB> <TAB> line = get_next(it) <TAB> events.reverse() <TAB> return stack_traces, events, line",true,if event :,if event :,0.53,0.0
"def process(self): <TAB> """"""Do processing necessary, storing result in feature."""""" <TAB> summation = 0  # count of all <TAB> histo = self.data[""flat.notes.quarterLengthHistogram""] <TAB> if not histo: <TAB> <TAB> raise NativeFeatureException(""input lacks notes"") <TAB> maxKey = 0  # max found for any one key <TAB> for key in histo: <TAB> <TAB> # all defined keys should be greater than zero, but just in case <TAB> <TAB> if histo[key] > 0: <TAB> <TAB> <TAB> summation += histo[key] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> maxKey = histo[key] <TAB> self.feature.vector[0] = maxKey / summation",false,if histo [ key ] >= maxKey :,if maxKey > histo [ key ] :,0.26,0.0
"def load_resource(name): <TAB> """"""return file contents for files within the package root folder"""""" <TAB> try: <TAB> <TAB> if is_ST3(): <TAB> <TAB> <TAB> return sublime.load_resource(""Packages/Markdown Preview/{0}"".format(name)) <TAB> <TAB> else: <TAB> <TAB> <TAB> filename = os.path.join( <TAB> <TAB> <TAB> <TAB> sublime.packages_path(), INSTALLED_DIRECTORY, os.path.normpath(name) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return load_utf8(filename) <TAB> except: <TAB> <TAB> print(""Error while load_resource('%s')"" % name) <TAB> <TAB> traceback.print_exc() <TAB> <TAB> return """"",true,if is_ST3 ( ) :,if is_ST3 ( ) :,0.75,0.0
"def get_password(self, service, repo_url): <TAB> if self.is_unlocked: <TAB> <TAB> asyncio.set_event_loop(asyncio.new_event_loop()) <TAB> <TAB> collection = secretstorage.get_default_collection(self.connection) <TAB> <TAB> attributes = {""application"": ""Vorta"", ""service"": service, ""repo_url"": repo_url} <TAB> <TAB> items = list(collection.search_items(attributes)) <TAB> <TAB> logger.debug(""Found %i passwords matching repo URL."", len(items)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return items[0].get_secret().decode(""utf-8"") <TAB> return None",false,if len ( items ) > 0 :,if len ( items ) == 1 :,0.52,0.0
"def get_files(d): <TAB> res = [] <TAB> for p in glob.glob(os.path.join(d, ""*"")): <TAB> <TAB> if not p: <TAB> <TAB> <TAB> continue <TAB> <TAB> (pth, fname) = os.path.split(p) <TAB> <TAB> if fname == ""output"": <TAB> <TAB> <TAB> continue <TAB> <TAB> if fname == ""PureMVC_Python_1_0"": <TAB> <TAB> <TAB> continue <TAB> <TAB> if fname[-4:] == "".pyc"":  # ehmm.. no. <TAB> <TAB> <TAB> continue <TAB> <TAB> if os.path.isdir(p): <TAB> <TAB> <TAB> get_dir(p) <TAB> <TAB> else: <TAB> <TAB> <TAB> res.append(p) <TAB> return res",false,if os . path . isdir ( p ) :,"if fname [ - 4 : ] == "".pyc"" :",0.01,0.0
"def test_nic_names(self): <TAB> p = subprocess.Popen([""ipconfig"", ""/all""], stdout=subprocess.PIPE) <TAB> out = p.communicate()[0] <TAB> if PY3: <TAB> <TAB> out = str(out, sys.stdout.encoding) <TAB> nics = psutil.net_io_counters(pernic=True).keys() <TAB> for nic in nics: <TAB> <TAB> if ""pseudo-interface"" in nic.replace("" "", ""-"").lower(): <TAB> <TAB> <TAB> continue <TAB> <TAB> if nic not in out: <TAB> <TAB> <TAB> self.fail(""%r nic wasn't found in 'ipconfig /all' output"" % nic)",true,"if ""pseudo-interface"" in nic . replace ( "" "" , ""-"" ) . lower ( ) :","if ""pseudo-interface"" in nic . replace ( "" "" , ""-"" ) . lower ( ) :",0.75,0.0
"def vexop_to_simop(op, extended=True, fp=True): <TAB> res = operations.get(op) <TAB> if res is None and extended: <TAB> <TAB> attrs = op_attrs(op) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise UnsupportedIROpError(""Operation not implemented"") <TAB> <TAB> res = SimIROp(op, **attrs) <TAB> if res is None: <TAB> <TAB> raise UnsupportedIROpError(""Operation not implemented"") <TAB> if res._float and not fp: <TAB> <TAB> raise UnsupportedIROpError(""Floating point support disabled"") <TAB> return res",true,if attrs is None :,if attrs is None :,0.75,0.0
"def rule_builder_add_value(self, value, screenshot_name=None): <TAB> rule_builder = self.components.rule_builder <TAB> rule_builder.menu_button_column.wait_for_and_click() <TAB> with self.rule_builder_rule_editor(""add-column-value"") as editor_element: <TAB> <TAB> filter_input = editor_element.find_element_by_css_selector(""input[type='text']"") <TAB> <TAB> filter_input.clear() <TAB> <TAB> filter_input.send_keys(value) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.screenshot(screenshot_name)",true,if screenshot_name :,if screenshot_name :,0.53,0.0
"def make_open_socket(self): <TAB> s = socket.socket() <TAB> try: <TAB> <TAB> s.bind(DEFAULT_BIND_ADDR_TUPLE) <TAB> <TAB> if WIN or greentest.LINUX: <TAB> <TAB> <TAB> # Windows and linux (with psutil) doesn't show as open until <TAB> <TAB> <TAB> # we call listen (linux with lsof accepts either) <TAB> <TAB> <TAB> s.listen(1) <TAB> <TAB> self.assert_open(s, s.fileno()) <TAB> except: <TAB> <TAB> s.close() <TAB> <TAB> s = None <TAB> <TAB> raise <TAB> return s",true,if WIN or greentest . LINUX :,if WIN or greentest . LINUX :,0.75,0.0
"def handle_ray_task_error(e): <TAB> for s in e.traceback_str.split(""\n"")[::-1]: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> raise getattr(builtins, s.split("":"")[0])("""".join(s.split("":"")[1:])) <TAB> <TAB> <TAB> except AttributeError as att_err: <TAB> <TAB> <TAB> <TAB> if ""module"" in str(att_err) and builtins.__name__ in str(att_err): <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> raise att_err <TAB> raise e",false,"if ""Error"" in s or ""Exception"" in s :","if "":"" in s :",0.07,0.0
"def compare_multiple_events(i, expected_results, actual_results): <TAB> events_in_a_row = [] <TAB> j = i <TAB> while j < len(expected_results) and isinstance( <TAB> <TAB> actual_results[j], actual_results[i].__class__ <TAB> ): <TAB> <TAB> events_in_a_row.append(actual_results[j]) <TAB> <TAB> j += 1 <TAB> message = """" <TAB> for event in events_in_a_row: <TAB> <TAB> for k in range(i, j): <TAB> <TAB> <TAB> passed, message = compare_events(expected_results[k], event) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> expected_results[k] = None <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> return i, False, message <TAB> return j, True, """"",true,if passed :,if passed :,0.53,0.0
"def ListSubscriptions(self, params): <TAB> queryreturn = sqlQuery(""""""SELECT label, address, enabled FROM subscriptions"""""") <TAB> data = '{""subscriptions"":[' <TAB> for row in queryreturn: <TAB> <TAB> label, address, enabled = row <TAB> <TAB> label = shared.fixPotentiallyInvalidUTF8Data(label) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> data += "","" <TAB> <TAB> data += json.dumps( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> ""label"": label.encode(""base64""), <TAB> <TAB> <TAB> <TAB> ""address"": address, <TAB> <TAB> <TAB> <TAB> ""enabled"": enabled == 1, <TAB> <TAB> <TAB> }, <TAB> <TAB> <TAB> indent=4, <TAB> <TAB> <TAB> separators=("","", "": ""), <TAB> <TAB> ) <TAB> data += ""]}"" <TAB> return data",false,if len ( data ) > 20 :,if len ( data ) > 100 :,0.61,0.0
"def compile(self, args): <TAB> compiled_args = {} <TAB> for key, value in six.iteritems(args): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> compiled_args[key] = str(value) <TAB> <TAB> else: <TAB> <TAB> <TAB> compiled_args[key] = sjson_dumps(value) <TAB> return self._minified_code % compiled_args",false,if key in self . clean_args :,if type ( value ) is dict :,0.02,0.0
"def insert(self, pack_id, data): <TAB> if (pack_id not in self.queue) and pack_id > self.begin_id: <TAB> <TAB> self.queue[pack_id] = PacketInfo(data) <TAB> <TAB> if self.end_id == pack_id: <TAB> <TAB> <TAB> self.end_id = pack_id + 1 <TAB> <TAB> elif self.end_id < pack_id: <TAB> <TAB> <TAB> eid = self.end_id <TAB> <TAB> <TAB> while eid < pack_id: <TAB> <TAB> <TAB> <TAB> self.miss_queue.add(eid) <TAB> <TAB> <TAB> <TAB> eid += 1 <TAB> <TAB> <TAB> self.end_id = pack_id + 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> self.miss_queue.remove(pack_id)",true,elif self . end_id < pack_id :,elif self . end_id < pack_id :,0.75,0.0
"def _target_generator(self): <TAB> # since we do not have predictions yet, so we ignore sampling here <TAB> if self._internal_target_generator is None: <TAB> <TAB> if self._anchors_none: <TAB> <TAB> <TAB> return None <TAB> <TAB> from ....model_zoo.ssd.target import SSDTargetGenerator <TAB> <TAB> self._internal_target_generator = SSDTargetGenerator( <TAB> <TAB> <TAB> iou_thresh=self._iou_thresh, <TAB> <TAB> <TAB> stds=self._box_norm, <TAB> <TAB> <TAB> negative_mining_ratio=-1, <TAB> <TAB> <TAB> **self._kwargs <TAB> <TAB> ) <TAB> <TAB> return self._internal_target_generator <TAB> else: <TAB> <TAB> return self._internal_target_generator",true,if self . _anchors_none :,if self . _anchors_none :,0.75,0.0
"def test_heapsort(self): <TAB> # Exercise everything with repeated heapsort checks <TAB> for trial in range(100): <TAB> <TAB> size = random.randrange(50) <TAB> <TAB> data = [random.randrange(25) for i in range(size)] <TAB> <TAB><IF-STMT>  # Half of the time, use heapify <TAB> <TAB> <TAB> heap = data[:] <TAB> <TAB> <TAB> self.module.heapify(heap) <TAB> <TAB> else:  # The rest of the time, use heappush <TAB> <TAB> <TAB> heap = [] <TAB> <TAB> <TAB> for item in data: <TAB> <TAB> <TAB> <TAB> self.module.heappush(heap, item) <TAB> <TAB> heap_sorted = [self.module.heappop(heap) for i in range(size)] <TAB> <TAB> self.assertEqual(heap_sorted, sorted(data))",false,if trial & 1 :,if trial == 1 :,0.33,0.0
"def wait(self, timeout=None): <TAB> if self.returncode is None: <TAB> <TAB> if timeout is None: <TAB> <TAB> <TAB> msecs = _subprocess.INFINITE <TAB> <TAB> else: <TAB> <TAB> <TAB> msecs = max(0, int(timeout * 1000 + 0.5)) <TAB> <TAB> res = _subprocess.WaitForSingleObject(int(self._handle), msecs) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> code = _subprocess.GetExitCodeProcess(self._handle) <TAB> <TAB> <TAB> if code == TERMINATE: <TAB> <TAB> <TAB> <TAB> code = -signal.SIGTERM <TAB> <TAB> <TAB> self.returncode = code <TAB> return self.returncode",false,if res == _subprocess . WAIT_OBJECT_0 :,if res :,0.04,0.0
"def _on_change(self): <TAB> changed = False <TAB> self.save() <TAB> for key, value in self.data.items(): <TAB> <TAB> if isinstance(value, bool): <TAB> <TAB> <TAB> if value: <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if isinstance(value, int): <TAB> <TAB> <TAB> if value != 1: <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> elif value is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> elif len(value) != 0: <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> break <TAB> self._reset_button.disabled = not changed",false,elif value is None :,elif len ( value ) != 0 :,0.15,0.0
"def isnotsurplus(self, item: T) -> bool: <TAB> if not self.matchers: <TAB> <TAB> if self.mismatch_description: <TAB> <TAB> <TAB> self.mismatch_description.append_text( <TAB> <TAB> <TAB> <TAB> ""not matched: "" <TAB> <TAB> <TAB> ).append_description_of(item) <TAB> <TAB> return False <TAB> return True",true,if self . mismatch_description :,if self . mismatch_description :,0.75,0.0
"def resolve_env_secrets(config, environ): <TAB> """"""Create copy that recursively replaces {""$env"": ""NAME""} with values from environ"""""" <TAB> if isinstance(config, dict): <TAB> <TAB> if list(config.keys()) == [""$env""]: <TAB> <TAB> <TAB> return environ.get(list(config.values())[0]) <TAB> <TAB> elif list(config.keys()) == [""$file""]: <TAB> <TAB> <TAB> return open(list(config.values())[0]).read() <TAB> <TAB> else: <TAB> <TAB> <TAB> return { <TAB> <TAB> <TAB> <TAB> key: resolve_env_secrets(value, environ) <TAB> <TAB> <TAB> <TAB> for key, value in config.items() <TAB> <TAB> <TAB> } <TAB> elif isinstance(config, list): <TAB> <TAB> return [resolve_env_secrets(value, environ) for value in config] <TAB> else: <TAB> <TAB> return config",true,"if list ( config . keys ( ) ) == [ ""$env"" ] :","if list ( config . keys ( ) ) == [ ""$env"" ] :",0.75,0.0
"def __open__(filename, *args, **kwargs): <TAB> if os.path.isfile(filename): <TAB> <TAB> return __realopen__(filename, *args, **kwargs) <TAB> if not os.path.isabs(filename): <TAB> <TAB> datafilename = __papplet__.dataPath(filename) <TAB> <TAB> if os.path.isfile(datafilename): <TAB> <TAB> <TAB> return __realopen__(datafilename, *args, **kwargs) <TAB> <TAB> sketchfilename = __papplet__.sketchPath(filename) <TAB> if os.path.isfile(sketchfilename): <TAB> <TAB> return __realopen__(sketchfilename, *args, **kwargs) <TAB> # Fail naturally <TAB> return __realopen__(filename, *args, **kwargs)",true,if os . path . isfile ( datafilename ) :,if os . path . isfile ( datafilename ) :,0.75,0.0
def run(self): <TAB> while not self.completed: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> time.sleep(self.period) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._completed.wait(self.period) <TAB> <TAB> self.counter += 1 <TAB> <TAB> try: <TAB> <TAB> <TAB> self.callback(self.counter) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> self.stop() <TAB> <TAB> if self.timeout is not None: <TAB> <TAB> <TAB> dt = time.time() - self._start_time <TAB> <TAB> <TAB> if dt > self.timeout: <TAB> <TAB> <TAB> <TAB> self.stop() <TAB> <TAB> if self.counter == self.count: <TAB> <TAB> <TAB> self.stop(),false,if self . block :,if self . timeout is None :,0.2,0.0
"def remove(self, path, config=None, error_on_path=False, defaults=None): <TAB> if not path: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise NoSuchSettingsPath() <TAB> <TAB> return <TAB> if config is not None or defaults is not None: <TAB> <TAB> if config is None: <TAB> <TAB> <TAB> config = self._config <TAB> <TAB> if defaults is None: <TAB> <TAB> <TAB> defaults = dict(self._map.parents) <TAB> <TAB> chain = HierarchicalChainMap(config, defaults) <TAB> else: <TAB> <TAB> chain = self._map <TAB> try: <TAB> <TAB> chain.del_by_path(path) <TAB> <TAB> self._mark_dirty() <TAB> except KeyError: <TAB> <TAB> if error_on_path: <TAB> <TAB> <TAB> raise NoSuchSettingsPath() <TAB> <TAB> pass",true,if error_on_path :,if error_on_path :,0.53,0.0
"def structured_dot_grad(sparse_A, dense_B, ga): <TAB> if sparse_A.type.format in (""csc"", ""csr""): <TAB> <TAB> if sparse_A.type.format == ""csc"": <TAB> <TAB> <TAB> sdgcsx = sdg_csc <TAB> <TAB> <TAB> CSx = CSC <TAB> <TAB> else: <TAB> <TAB> <TAB> sdgcsx = sdg_csr <TAB> <TAB> <TAB> CSx = CSR <TAB> <TAB> g_A_data = sdgcsx(csm_indices(sparse_A), csm_indptr(sparse_A), dense_B, ga) <TAB> <TAB> return CSx( <TAB> <TAB> <TAB> g_A_data, csm_indices(sparse_A), csm_indptr(sparse_A), csm_shape(sparse_A) <TAB> <TAB> ) <TAB> else: <TAB> <TAB> raise NotImplementedError()",true,"if sparse_A . type . format == ""csc"" :","if sparse_A . type . format == ""csc"" :",0.75,0.0
"def step_async(self, actions): <TAB> listify = True <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> listify = False <TAB> except TypeError: <TAB> <TAB> pass <TAB> if not listify: <TAB> <TAB> self.actions = actions <TAB> else: <TAB> <TAB> assert ( <TAB> <TAB> <TAB> self.num_envs == 1 <TAB> <TAB> ), f""actions {actions} is either not a list or has a wrong size - cannot match to {self.num_envs} environments"" <TAB> <TAB> self.actions = [actions]",false,if len ( actions ) == self . num_envs :,if len ( actions ) == 0 :,0.38,0.0
"def tempFailureRetry(func, *args, **kwargs): <TAB> while True: <TAB> <TAB> try: <TAB> <TAB> <TAB> return func(*args, **kwargs) <TAB> <TAB> except (os.error, IOError) as ex: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise",true,if ex . errno == errno . EINTR :,if ex . errno == errno . EINTR :,1.0,0.0
"def test_learning_always_changes_generation(chars, order): <TAB> learner = LStar(lambda s: len(s) == 1 and s[0] in chars) <TAB> for c in order: <TAB> <TAB> prev = learner.generation <TAB> <TAB> s = bytes([c]) <TAB> <TAB> if learner.dfa.matches(s) != learner.member(s): <TAB> <TAB> <TAB> learner.learn(s) <TAB> <TAB> <TAB> assert learner.generation > prev",true,if learner . dfa . matches ( s ) != learner . member ( s ) :,if learner . dfa . matches ( s ) != learner . member ( s ) :,1.0,0.0
"def test_costs_5D_noisy_names(signal_bkps_5D_noisy, cost_name): <TAB> signal, bkps = signal_bkps_5D_noisy <TAB> cost = cost_factory(cost_name) <TAB> cost.fit(signal) <TAB> cost.error(0, 100) <TAB> cost.error(100, signal.shape[0]) <TAB> cost.error(10, 50) <TAB> cost.sum_of_costs(bkps) <TAB> with pytest.raises(NotEnoughPoints): <TAB> <TAB> if cost_name == ""cosine"": <TAB> <TAB> <TAB> cost.min_size = 4 <TAB> <TAB> <TAB> cost.error(1, 2) <TAB> <TAB> else: <TAB> <TAB> <TAB> cost.error(1, 2)",true,"if cost_name == ""cosine"" :","if cost_name == ""cosine"" :",0.75,0.0
"def remove_empty_dirs(dirname): <TAB> logger.debug(""remove_empty_dirs '%s'"" % (dirname)) <TAB> try: <TAB> <TAB> if not isinstance(dirname, str): <TAB> <TAB> <TAB> dirname = dirname.encode(""utf-8"") <TAB> <TAB> os.removedirs(dirname) <TAB> <TAB> logger.debug(""remove_empty_dirs '%s' done"" % (dirname)) <TAB> except OSError as exc:  # Python >2.5 <TAB> <TAB> if exc.errno == errno.ENOTEMPTY: <TAB> <TAB> <TAB> logger.debug(""remove_empty_dirs '%s' not empty"" % (dirname)) <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> raise <TAB> except Exception as e: <TAB> <TAB> logger.exception(e) <TAB> <TAB> logger.error(""remove_empty_dirs exception: "" + dirname) <TAB> <TAB> raise e",true,"if not isinstance ( dirname , str ) :","if not isinstance ( dirname , str ) :",0.75,0.0
"def get_unique_attribute(self, name: str): <TAB> feat = None <TAB> for f in self.features: <TAB> <TAB> if self._return_feature(f) and hasattr(f, name): <TAB> <TAB> <TAB> if feat is not None: <TAB> <TAB> <TAB> <TAB> raise RuntimeError(""The attribute was not unique."") <TAB> <TAB> <TAB> feat = f <TAB> if feat is None: <TAB> <TAB> raise RuntimeError(""The attribute did not exist"") <TAB> return getattr(feat, name)",true,"if self . _return_feature ( f ) and hasattr ( f , name ) :","if self . _return_feature ( f ) and hasattr ( f , name ) :",1.0,0.0
"def get_allocated_address( <TAB> self, config: ActorPoolConfig, allocated: allocated_type ) -> str: <TAB> addresses = config.get_external_addresses(label=self.label) <TAB> for addr in addresses: <TAB> <TAB> occupied = False <TAB> <TAB> for strategy, _ in allocated.get(addr, dict()).values(): <TAB> <TAB> <TAB> if strategy == self: <TAB> <TAB> <TAB> <TAB> occupied = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return addr <TAB> raise NoIdleSlot( <TAB> <TAB> f""No idle slot for creating actor "" f""with label {self.label}, mark {self.mark}"" <TAB> )",false,if not occupied :,if occupied :,0.1,0.0
"def __deepcopy__(self, memo): <TAB> cls = self.__class__ <TAB> result = cls.__new__(cls) <TAB> memo[id(self)] = result <TAB> for key, value in self.__dict__.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> setattr(result, key, copy.copy(value)) <TAB> <TAB> else: <TAB> <TAB> <TAB> setattr(result, key, copy.deepcopy(value, memo)) <TAB> return result",false,if key in cls . dynamic_methods :,if type ( value ) is dict :,0.02,0.0
"def restore_forward(model): <TAB> for child in model.children(): <TAB> <TAB> # leaf node <TAB> <TAB> if is_leaf(child) and hasattr(child, ""old_forward""): <TAB> <TAB> <TAB> child.forward = child.old_forward <TAB> <TAB> <TAB> child.old_forward = None <TAB> <TAB> else: <TAB> <TAB> <TAB> restore_forward(child)",true,"if is_leaf ( child ) and hasattr ( child , ""old_forward"" ) :","if is_leaf ( child ) and hasattr ( child , ""old_forward"" ) :",1.0,0.0
"def add(self, obj, allow_duplicates=False): <TAB> if allow_duplicates or obj not in self._constants: <TAB> <TAB> self._constant_pool.append(obj) <TAB> <TAB> self._constants[obj] = len(self) <TAB> <TAB> if obj.__class__ in (Double, Long): <TAB> <TAB> <TAB> self._constant_pool.append(None)",true,"if obj . __class__ in ( Double , Long ) :","if obj . __class__ in ( Double , Long ) :",0.75,0.0
"def find_file_copyright_notices(fname): <TAB> ret = set() <TAB> f = open(fname) <TAB> lines = f.readlines() <TAB> for l in lines[:80]:  # hmmm, assume copyright to be in first 80 lines <TAB> <TAB> idx = l.lower().find(""copyright"") <TAB> <TAB> if idx < 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> copyright = l[idx + 9 :].strip() <TAB> <TAB> if not copyright: <TAB> <TAB> <TAB> continue <TAB> <TAB> copyright = sanitise(copyright) <TAB> <TAB> # hmm, do a quick check to see if there's a year, <TAB> <TAB> # if not, skip it <TAB> <TAB> if not copyright.find(""200"") >= 0 and not copyright.find(""199"") >= 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> ret.add(copyright) <TAB> return ret",true,"if not copyright . find ( ""200"" ) >= 0 and not copyright . find ( ""199"" ) >= 0 :","if not copyright . find ( ""200"" ) >= 0 and not copyright . find ( ""199"" ) >= 0 :",1.0,0.0
"def callback(lexer, match, context): <TAB> text = match.group() <TAB> extra = """" <TAB> if start: <TAB> <TAB> context.next_indent = len(text) <TAB> <TAB> if context.next_indent < context.indent: <TAB> <TAB> <TAB> while context.next_indent < context.indent: <TAB> <TAB> <TAB> <TAB> context.indent = context.indent_stack.pop() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> extra = text[context.indent :] <TAB> <TAB> <TAB> <TAB> text = text[: context.indent] <TAB> else: <TAB> <TAB> context.next_indent += len(text) <TAB> if text: <TAB> <TAB> yield match.start(), TokenClass, text <TAB> if extra: <TAB> <TAB> yield match.start() + len(text), TokenClass.Error, extra <TAB> context.pos = match.end()",false,if context . next_indent > context . indent :,if context . next_indent < context . indent :,0.36,0.0
"def queries(self): <TAB> if DEV: <TAB> <TAB> cmd = ShellCommand(""docker"", ""ps"", ""-qf"", ""name=%s"" % self.path.k8s) <TAB> <TAB> if not cmd.check(f""docker check for {self.path.k8s}""): <TAB> <TAB> <TAB> if not cmd.stdout.strip(): <TAB> <TAB> <TAB> <TAB> log_cmd = ShellCommand( <TAB> <TAB> <TAB> <TAB> <TAB> ""docker"", ""logs"", self.path.k8s, stderr=subprocess.STDOUT <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> if log_cmd.check(f""docker logs for {self.path.k8s}""): <TAB> <TAB> <TAB> <TAB> <TAB> print(cmd.stdout) <TAB> <TAB> <TAB> <TAB> pytest.exit(f""container failed to start for {self.path.k8s}"") <TAB> return ()",true,"if log_cmd . check ( f""docker logs for {self.path.k8s}"" ) :","if log_cmd . check ( f""docker logs for {self.path.k8s}"" ) :",0.75,0.0
"def nodes(self): <TAB> if not self._nodes: <TAB> <TAB> nodes = self.cluster_group.instances() <TAB> <TAB> self._nodes = [] <TAB> <TAB> master = self.master_node <TAB> <TAB> nodeid = 1 <TAB> <TAB> for node in nodes: <TAB> <TAB> <TAB> if node.state not in [""pending"", ""running""]: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self._nodes.insert(0, master) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self._nodes.append(Node(node, self.key_location, ""node%.3d"" % nodeid)) <TAB> <TAB> <TAB> nodeid += 1 <TAB> else: <TAB> <TAB> for node in self._nodes: <TAB> <TAB> <TAB> log.debug(""refreshing instance %s"" % node.id) <TAB> <TAB> <TAB> node.update() <TAB> return self._nodes",false,if node . id == master . id :,if master :,0.01,0.0
"def match(cls, agent_name, guid, uri, media=None): <TAB> # Retrieve `Agent` for provided `guid` <TAB> agent = Agents.get(agent_name) <TAB> if agent is None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # First occurrence of unsupported agent <TAB> <TAB> <TAB> log.warn(""Unsupported metadata agent: %s"" % agent_name) <TAB> <TAB> <TAB> # Mark unsupported agent as ""seen"" <TAB> <TAB> <TAB> unsupported_agents[agent_name] = True <TAB> <TAB> <TAB> return False <TAB> <TAB> # Duplicate occurrence of unsupported agent <TAB> <TAB> log.warn( <TAB> <TAB> <TAB> ""Unsupported metadata agent: %s"" % agent_name, extra={""duplicate"": True} <TAB> <TAB> ) <TAB> <TAB> return False <TAB> # Fill `guid` with details from agent <TAB> return agent.fill(guid, uri, media)",true,if agent_name not in unsupported_agents :,if agent_name not in unsupported_agents :,0.75,0.0
"def __createRandom(plug): <TAB> node = plug.node() <TAB> parentNode = node.ancestor(Gaffer.Node) <TAB> with Gaffer.UndoScope(node.scriptNode()): <TAB> <TAB> randomNode = Gaffer.Random() <TAB> <TAB> parentNode.addChild(randomNode) <TAB> <TAB> if isinstance(plug, (Gaffer.FloatPlug, Gaffer.IntPlug)): <TAB> <TAB> <TAB> plug.setInput(randomNode[""outFloat""]) <TAB> <TAB> elif isinstance(plug, Gaffer.Color3fPlug): <TAB> <TAB> <TAB> plug.setInput(randomNode[""outColor""]) <TAB> GafferUI.NodeEditor.acquire(randomNode)",true,"elif isinstance ( plug , Gaffer . Color3fPlug ) :","elif isinstance ( plug , Gaffer . Color3fPlug ) :",0.75,0.0
"def post_arrow(self, arr: pa.Table, graph_type: str, opts: str = """"): <TAB> dataset_id = self.dataset_id <TAB> tok = self.token <TAB> sub_path = f""api/v2/upload/datasets/{dataset_id}/{graph_type}/arrow"" <TAB> try: <TAB> <TAB> resp = self.post_arrow_generic(sub_path, tok, arr, opts) <TAB> <TAB> out = resp.json() <TAB> <TAB> if not (""success"" in out) or not out[""success""]: <TAB> <TAB> <TAB> raise Exception(""No success indicator in server response"") <TAB> <TAB> return out <TAB> except Exception as e: <TAB> <TAB> logger.error(""Failed to post arrow to %s"", sub_path, exc_info=True) <TAB> <TAB> raise e",true,"if not ( ""success"" in out ) or not out [ ""success"" ] :","if not ( ""success"" in out ) or not out [ ""success"" ] :",1.0,0.0
"def dict_to_XML(tag, dictionary, **kwargs): <TAB> """"""Return XML element converting dicts recursively."""""" <TAB> elem = Element(tag, **kwargs) <TAB> for key, val in dictionary.items(): <TAB> <TAB> if tag == ""layers"": <TAB> <TAB> <TAB> child = dict_to_XML(""layer"", val, name=key) <TAB> <TAB> elif isinstance(val, MutableMapping): <TAB> <TAB> <TAB> child = dict_to_XML(key, val) <TAB> <TAB> else: <TAB> <TAB> <TAB> if tag == ""config"": <TAB> <TAB> <TAB> <TAB> child = Element(""variable"", name=key) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> child = Element(key) <TAB> <TAB> <TAB> child.text = str(val) <TAB> <TAB> elem.append(child) <TAB> return elem",true,"if tag == ""layers"" :","if tag == ""layers"" :",0.75,0.0
"def apply_incpaths_ml(self): <TAB> inc_lst = self.includes.split() <TAB> lst = self.incpaths_lst <TAB> for dir in inc_lst: <TAB> <TAB> node = self.path.find_dir(dir) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> error(""node not found: "" + str(dir)) <TAB> <TAB> <TAB> continue <TAB> <TAB> if not node in lst: <TAB> <TAB> <TAB> lst.append(node) <TAB> <TAB> self.bld_incpaths_lst.append(node)",true,if not node :,if not node :,0.75,0.0
"def _table_reprfunc(self, row, col, val): <TAB> if self._table.column_names[col].endswith(""Size""): <TAB> <TAB> if isinstance(val, compat.string_types): <TAB> <TAB> <TAB> return ""  %s"" % val <TAB> <TAB> elif val < 1024 ** 2: <TAB> <TAB> <TAB> return ""  %.1f KB"" % (val / 1024.0 ** 1) <TAB> <TAB> elif val < 1024 ** 3: <TAB> <TAB> <TAB> return ""  %.1f MB"" % (val / 1024.0 ** 2) <TAB> <TAB> else: <TAB> <TAB> <TAB> return ""  %.1f GB"" % (val / 1024.0 ** 3) <TAB> if col in (0, """"): <TAB> <TAB> return str(val) <TAB> else: <TAB> <TAB> return ""  %s"" % val",true,elif val < 1024 ** 3 :,elif val < 1024 ** 3 :,0.75,0.0
"def _cache_mem(curr_out, prev_mem, mem_len, reuse_len=None): <TAB> """"""cache hidden states into memory."""""" <TAB> if mem_len is None or mem_len == 0: <TAB> <TAB> return None <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> curr_out = curr_out[:reuse_len] <TAB> <TAB> if prev_mem is None: <TAB> <TAB> <TAB> new_mem = curr_out[-mem_len:] <TAB> <TAB> else: <TAB> <TAB> <TAB> new_mem = tf.concat([prev_mem, curr_out], 0)[-mem_len:] <TAB> new_mem.stop_gradient = True <TAB> return new_mem",false,if reuse_len is not None and reuse_len > 0 :,if reuse_len is not None :,0.39,0.0
"def GROUP_CONCAT(builder, distinct, expr, sep=None): <TAB> assert distinct in (None, True, False) <TAB> result = distinct and ""GROUP_CONCAT(DISTINCT "" or ""GROUP_CONCAT("", builder(expr) <TAB> if sep is not None: <TAB> <TAB> if builder.provider.dialect == ""MySQL"": <TAB> <TAB> <TAB> result = result, "" SEPARATOR "", builder(sep) <TAB> <TAB> else: <TAB> <TAB> <TAB> result = result, "", "", builder(sep) <TAB> return result, "")""",true,"if builder . provider . dialect == ""MySQL"" :","if builder . provider . dialect == ""MySQL"" :",0.75,0.0
"def __init__(self, *args, **kwargs): <TAB> super().__init__(*args, **kwargs) <TAB> self.custom_fields = [] <TAB> self.obj_type = ContentType.objects.get_for_model(self.model) <TAB> # Add all applicable CustomFields to the form <TAB> custom_fields = CustomField.objects.filter(content_types=self.obj_type) <TAB> for cf in custom_fields: <TAB> <TAB> # Annotate non-required custom fields as nullable <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.nullable_fields.append(cf.name) <TAB> <TAB> self.fields[cf.name] = cf.to_form_field( <TAB> <TAB> <TAB> set_initial=False, enforce_required=False <TAB> <TAB> ) <TAB> <TAB> # Annotate this as a custom field <TAB> <TAB> self.custom_fields.append(cf.name)",false,if not cf . required :,if cf . required :,0.28,0.0
"def is_child_of(self, item_hash, possible_child_hash): <TAB> if self.get_last(item_hash) != self.get_last(possible_child_hash): <TAB> <TAB> return None <TAB> while True: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> if possible_child_hash not in self.items: <TAB> <TAB> <TAB> return False <TAB> <TAB> possible_child_hash = self.items[possible_child_hash].previous_hash",false,if possible_child_hash == item_hash :,if item_hash == possible_child_hash :,0.29,0.0
"def validate(self): <TAB> self.assertEqual(len(self.inputs), len(self.outputs)) <TAB> for batch_in, batch_out in zip(self.inputs, self.outputs): <TAB> <TAB> self.assertEqual(len(batch_in), len(batch_out)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.validate_unordered_batch(batch_in, batch_out) <TAB> <TAB> else: <TAB> <TAB> <TAB> for in_data, out_data in zip(batch_in, batch_out): <TAB> <TAB> <TAB> <TAB> self.assertEqual(in_data.shape, out_data.shape) <TAB> <TAB> <TAB> <TAB> if not self.use_parallel_executor: <TAB> <TAB> <TAB> <TAB> <TAB> self.assertTrue((in_data == out_data).all())",false,if self . use_parallel_executor and not self . use_double_buffer :,if self . use_unordered_batch :,0.09,0.0
"def add_cells(self, cells): <TAB> for cell in cells: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> id = len(self.cell_id_map) <TAB> <TAB> <TAB> self.cell_id_map[cell] = id <TAB> <TAB> <TAB> self.id_cell_map[id] = cell",true,if cell not in self . cell_id_map :,if cell not in self . cell_id_map :,0.75,0.0
"def _verify_out(marker="">>""): <TAB> if shared: <TAB> <TAB> self.assertIn(""libapp_lib.dylib"", self.client.out) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.assertIn(""libapp_lib.a"", self.client.out) <TAB> <TAB> else:  # Incremental build not the same msg <TAB> <TAB> <TAB> self.assertIn(""Built target app_lib"", self.client.out) <TAB> out = str(self.client.out).splitlines() <TAB> for k, v in vals.items(): <TAB> <TAB> self.assertIn(""%s %s: %s"" % (marker, k, v), out)",false,"if marker == "">>"" :",if shared :,0.04,0.0
"def Visit_expr(self, node):  # pylint: disable=invalid-name <TAB> # expr ::= xor_expr ('|' xor_expr)* <TAB> for child in node.children: <TAB> <TAB> self.Visit(child) <TAB> <TAB> if isinstance(child, pytree.Leaf) and child.value == ""|"": <TAB> <TAB> <TAB> _AppendTokenSubtype(child, format_token.Subtype.BINARY_OPERATOR)",true,"if isinstance ( child , pytree . Leaf ) and child . value == ""|"" :","if isinstance ( child , pytree . Leaf ) and child . value == ""|"" :",1.0,0.0
"def fill_members(self): <TAB> if self._get_retrieve(): <TAB> <TAB> after = self.after.id if self.after else None <TAB> <TAB> data = await self.get_members(self.guild.id, self.retrieve, after) <TAB> <TAB> if not data: <TAB> <TAB> <TAB> # no data, terminate <TAB> <TAB> <TAB> return <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.limit = 0  # terminate loop <TAB> <TAB> self.after = Object(id=int(data[-1][""user""][""id""])) <TAB> <TAB> for element in reversed(data): <TAB> <TAB> <TAB> await self.members.put(self.create_member(element))",false,if len ( data ) < 1000 :,if len ( data ) < self . limit :,0.41,0.0
"def assert_warns(expected): <TAB> with warnings.catch_warnings(record=True) as w: <TAB> <TAB> warnings.simplefilter(""always"") <TAB> <TAB> yield <TAB> # Python 2 does not raise warnings multiple times from the same stack <TAB> # frame. <TAB> if sys.version_info >= (3, 0): <TAB> <TAB> if not any(isinstance(m.message, expected) for m in w): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> exc_name = expected.__name__ <TAB> <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> <TAB> exc_name = str(expected) <TAB> <TAB> <TAB> raise AssertionError(""%s not triggerred"" % exc_name)",true,"if not any ( isinstance ( m . message , expected ) for m in w ) :","if not any ( isinstance ( m . message , expected ) for m in w ) :",1.0,0.0
"def __init__(self, measures): <TAB> """"""Constructs a ContingencyMeasures given a NgramAssocMeasures class"""""" <TAB> self.__class__.__name__ = ""Contingency"" + measures.__class__.__name__ <TAB> for k in dir(measures): <TAB> <TAB> if k.startswith(""__""): <TAB> <TAB> <TAB> continue <TAB> <TAB> v = getattr(measures, k) <TAB> <TAB> if not k.startswith(""_""): <TAB> <TAB> <TAB> v = self._make_contingency_fn(measures, v) <TAB> <TAB> setattr(self, k, v)",true,"if k . startswith ( ""__"" ) :","if k . startswith ( ""__"" ) :",0.75,0.0
"def _omit_keywords(self, context): <TAB> omitted_kws = 0 <TAB> for event, elem in context: <TAB> <TAB> # Teardowns aren't omitted to allow checking suite teardown status. <TAB> <TAB> omit = elem.tag == ""kw"" and elem.get(""type"") != ""teardown"" <TAB> <TAB> start = event == ""start"" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> omitted_kws += 1 <TAB> <TAB> if not omitted_kws: <TAB> <TAB> <TAB> yield event, elem <TAB> <TAB> elif not start: <TAB> <TAB> <TAB> elem.clear() <TAB> <TAB> if omit and not start: <TAB> <TAB> <TAB> omitted_kws -= 1",true,if omit and start :,if omit and start :,0.75,0.0
"def read_block(buffer, i): <TAB> offset = i * BLOCK_LENGTH % config.CAPTURE_BUFFER <TAB> while True: <TAB> <TAB> if buffer[offset] == BLOCK_MARKER.END: <TAB> <TAB> <TAB> return None <TAB> <TAB> while buffer[offset] == BLOCK_MARKER.WRITE: <TAB> <TAB> <TAB> time.sleep(SHORT_SENSOR_SLEEP_TIME) <TAB> <TAB> buffer[offset] = BLOCK_MARKER.READ <TAB> <TAB> buffer.seek(offset + 1) <TAB> <TAB> length = struct.unpack(""=H"", buffer.read(2))[0] <TAB> <TAB> retval = buffer.read(length) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> buffer[offset] = BLOCK_MARKER.NOP <TAB> return retval",false,if buffer [ offset ] == BLOCK_MARKER . READ :,if retval == BLOCK_MARKER . NOP :,0.12,0.0
def _start(self): <TAB> try: <TAB> <TAB> instance_info = self._get_instance_info() <TAB> <TAB> if not instance_info.is_running(): <TAB> <TAB> <TAB> self._multipass_cmd.start(instance_name=self.instance_name) <TAB> except errors.ProviderInfoError as instance_error: <TAB> <TAB> # Until we have proper multipass error codes to know if this <TAB> <TAB> # was a communication error we should keep this error tracking <TAB> <TAB> # and generation here. <TAB> <TAB> raise errors.ProviderInstanceNotFoundError( <TAB> <TAB> <TAB> instance_name=self.instance_name <TAB> <TAB> ) from instance_error,true,if not instance_info . is_running ( ) :,if not instance_info . is_running ( ) :,0.75,0.0
"def _river_driver(self): <TAB> if self._cached_river_driver: <TAB> <TAB> return self._cached_river_driver <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._cached_river_driver = MsSqlDriver( <TAB> <TAB> <TAB> <TAB> self.workflow, self.wokflow_object_class, self.field_name <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._cached_river_driver = OrmDriver( <TAB> <TAB> <TAB> <TAB> self.workflow, self.wokflow_object_class, self.field_name <TAB> <TAB> <TAB> ) <TAB> <TAB> return self._cached_river_driver",false,if app_config . IS_MSSQL :,if self . is_sql :,0.29,0.0
"def __LazyMap__(self, attr): <TAB> try: <TAB> <TAB> if self._LazyAddAttr_(attr): <TAB> <TAB> <TAB> debug_attr_print( <TAB> <TAB> <TAB> <TAB> ""%s.__LazyMap__(%s) added something"" % (self._username_, attr) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return 1 <TAB> except AttributeError: <TAB> <TAB> return 0",true,if self . _LazyAddAttr_ ( attr ) :,if self . _LazyAddAttr_ ( attr ) :,0.75,0.0
"def prepare(self, data=None, user=None): <TAB> """"""Prepare activation for execution."""""" <TAB> super(ManagedStartViewActivation, self).prepare.original() <TAB> self.task.owner = user <TAB> management_form_class = self.get_management_form_class() <TAB> self.management_form = management_form_class(data=data, instance=self.task) <TAB> if data: <TAB> <TAB> if not self.management_form.is_valid(): <TAB> <TAB> <TAB> raise FlowRuntimeError( <TAB> <TAB> <TAB> <TAB> ""Activation metadata is broken {}"".format(self.management_form.errors) <TAB> <TAB> <TAB> ) <TAB> <TAB> self.task = self.management_form.save(commit=False)",true,if not self . management_form . is_valid ( ) :,if not self . management_form . is_valid ( ) :,0.75,0.0
"def PreprocessConditionalStatement(self, IfList, ReplacedLine): <TAB> while self: <TAB> <TAB> if self.__Token: <TAB> <TAB> <TAB> x = 1 <TAB> <TAB> elif not IfList: <TAB> <TAB> <TAB> if self <= 2: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionSizeGuid = 3 <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> RegionLayoutLine = 5 <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionLayoutLine = self.CurrentLineNumber <TAB> return 1",false,if not RegionSizeGuid :,if self <= 3 :,0.04,0.0
"def _get_completion(self, document): <TAB> try: <TAB> <TAB> completion_header = document.xpath(""//div[@id='complete_day']"")[0] <TAB> <TAB> completion_message = completion_header.getchildren()[0] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif ""day_complete_message"" in completion_message.classes: <TAB> <TAB> <TAB> return True <TAB> except IndexError: <TAB> <TAB> return False  # Who knows, probably not my diary.",false,"if ""day_incomplete_message"" in completion_message . classes :","if ""completion_message"" in completion_message . classes :",0.57,0.0
"def run(self): <TAB> DISPATCH_SYNC = components.interfaces.nsIEventTarget.DISPATCH_SYNC <TAB> try: <TAB> <TAB> if self._stopped: <TAB> <TAB> <TAB> return <TAB> <TAB> for match in findlib2.find_all_matches(self.regex, self.text): <TAB> <TAB> <TAB> if self._stopped: <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> self.target.dispatch(lambda: self.callback(match), DISPATCH_SYNC) <TAB> <TAB> <TAB> if self._stopped: <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> self.target.dispatch(lambda: self.callback(None), DISPATCH_SYNC) <TAB> finally: <TAB> <TAB> self.callback = None <TAB> <TAB> self.target = None",true,if self . _stopped :,if self . _stopped :,0.75,0.0
"def to_key(literal_or_identifier): <TAB> """"""returns string representation of this object"""""" <TAB> if literal_or_identifier[""type""] == ""Identifier"": <TAB> <TAB> return literal_or_identifier[""name""] <TAB> elif literal_or_identifier[""type""] == ""Literal"": <TAB> <TAB> k = literal_or_identifier[""value""] <TAB> <TAB> if isinstance(k, float): <TAB> <TAB> <TAB> return unicode(float_repr(k)) <TAB> <TAB> elif ""regex"" in literal_or_identifier: <TAB> <TAB> <TAB> return compose_regex(k) <TAB> <TAB> elif isinstance(k, bool): <TAB> <TAB> <TAB> return ""true"" if k else ""false"" <TAB> <TAB> elif k is None: <TAB> <TAB> <TAB> return ""null"" <TAB> <TAB> else: <TAB> <TAB> <TAB> return unicode(k)",false,"elif ""regex"" in literal_or_identifier :",elif k is None :,0.03,0.0
"def process_image_pre_creation(sender, instance: Image, **kwargs): <TAB> # FIXME(winkidney): May have issue on determining if it <TAB> #  is created or not <TAB> if instance.pk is not None: <TAB> <TAB> return <TAB> for plugin in _plugin_instances: <TAB> <TAB> process_fn = getattr(plugin, ""process_image_pre_creation"", None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> process_fn( <TAB> <TAB> <TAB> <TAB> django_settings=settings, <TAB> <TAB> <TAB> <TAB> image_instance=instance, <TAB> <TAB> <TAB> ) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> logging.exception( <TAB> <TAB> <TAB> <TAB> ""Error occurs while trying to access plugin's pin_pre_save "" <TAB> <TAB> <TAB> <TAB> ""for plugin %s"" % plugin <TAB> <TAB> <TAB> )",true,if process_fn is None :,if process_fn is None :,0.75,0.0
"def check_screenshots(self): <TAB> # If we arrive here, there have not been any failures yet <TAB> if self.interactive: <TAB> <TAB> self._commit_screenshots() <TAB> else: <TAB> <TAB> if self._has_reference_screenshots(): <TAB> <TAB> <TAB> self._validate_screenshots() <TAB> <TAB> <TAB> # Always commit the screenshots here. They can be used for the next test run. <TAB> <TAB> <TAB> # If reference screenshots were already present and there was a mismatch, it should <TAB> <TAB> <TAB> # have failed above. <TAB> <TAB> <TAB> self._commit_screenshots() <TAB> <TAB> elif self.allow_missing_screenshots: <TAB> <TAB> <TAB> warnings.warn(""No committed reference screenshots available. Ignoring."") <TAB> <TAB> else: <TAB> <TAB> <TAB> self.fail( <TAB> <TAB> <TAB> <TAB> ""No committed reference screenshots available. Run interactive first."" <TAB> <TAB> <TAB> )",true,if self . _has_reference_screenshots ( ) :,if self . _has_reference_screenshots ( ) :,0.75,0.0
"def on_task_abort(self, task, config): <TAB> if ""abort"" in config: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> log.debug(""sending abort notification"") <TAB> <TAB> self.send_notification( <TAB> <TAB> <TAB> config[""abort""][""title""], <TAB> <TAB> <TAB> config[""abort""][""message""], <TAB> <TAB> <TAB> config[""abort""][""via""], <TAB> <TAB> <TAB> template_renderer=task.render, <TAB> <TAB> )",false,if task . silent_abort :,if task . status_code == 404 :,0.12,0.0
"def block_users(self, user_ids): <TAB> broken_items = [] <TAB> self.logger.info(""Going to block %d users."" % len(user_ids)) <TAB> for user_id in tqdm(user_ids): <TAB> <TAB> if not self.block(user_id): <TAB> <TAB> <TAB> self.error_delay() <TAB> <TAB> <TAB> broken_items = user_ids[user_ids.index(user_id) :] <TAB> <TAB> <TAB> break <TAB> self.logger.info(""DONE: Total blocked %d users."" % self.total[""blocks""]) <TAB> return broken_items",true,if not self . block ( user_id ) :,if not self . block ( user_id ) :,0.75,0.0
"def find_widget_by_id(self, id, parent=None): <TAB> """"""Recursively searches for widget with specified ID"""""" <TAB> if parent == None: <TAB> <TAB> if id in self: <TAB> <TAB> <TAB> return self[id]  # Do things fast if possible <TAB> <TAB> parent = self[""editor""] <TAB> for c in parent.get_children(): <TAB> <TAB> if hasattr(c, ""get_id""): <TAB> <TAB> <TAB> if c.get_id() == id: <TAB> <TAB> <TAB> <TAB> return c <TAB> <TAB> if isinstance(c, Gtk.Container): <TAB> <TAB> <TAB> r = self.find_widget_by_id(id, c) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return r <TAB> return None",false,if not r is None :,if r :,0.03,0.0
"def addClasses(self, name): <TAB> # Result: void - None <TAB> # In: name: string <TAB> for n in name.split(): <TAB> <TAB> try: <TAB> <TAB> <TAB> k, method = n.split(""."") <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> k = n <TAB> <TAB> <TAB> method = None <TAB> <TAB> self.classes[k] = 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.methods.setdefault(k, {})[method] = 1",true,if method is not None :,if method is not None :,0.75,0.0
"def Read(self, lex_mode): <TAB> while True: <TAB> <TAB> t = self._Read(lex_mode) <TAB> <TAB> self.was_line_cont = t.id == Id.Ignored_LineCont <TAB> <TAB> # TODO: Change to ALL IGNORED types, once you have SPACE_TOK.  This means <TAB> <TAB> # we don't have to handle them in the VS_1/VS_2/etc. states. <TAB> <TAB> if t.id != Id.Ignored_LineCont: <TAB> <TAB> <TAB> break <TAB> # log('Read() Returning %s', t) <TAB> return t",true,if t . id != Id . Ignored_LineCont :,if t . id != Id . Ignored_LineCont :,0.75,0.0
"def _dir_guildfile(dir, ctx): <TAB> from guild import guildfile <TAB> try: <TAB> <TAB> return guildfile.for_dir(dir) <TAB> except guildfile.NoModels: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> help_suffix = "" or '%s' for help"" % click_util.cmd_help(ctx) <TAB> <TAB> else: <TAB> <TAB> <TAB> help_suffix = """" <TAB> <TAB> cli.error( <TAB> <TAB> <TAB> ""%s does not contain a Guild file (guild.yml)\n"" <TAB> <TAB> <TAB> ""Try specifying a project path or package name%s."" <TAB> <TAB> <TAB> % (cwd_desc(dir), help_suffix) <TAB> <TAB> ) <TAB> except guildfile.GuildfileError as e: <TAB> <TAB> cli.error(str(e))",true,if ctx :,if ctx :,0.53,0.0
"def check_response(self, response): <TAB> """"""Specialized version of check_response()."""""" <TAB> for line in response: <TAB> <TAB> # Skip blank lines: <TAB> <TAB> if not line.strip(): <TAB> <TAB> <TAB> continue <TAB> <TAB> if line.startswith(b""OK""): <TAB> <TAB> <TAB> return <TAB> <TAB> elif line.startswith(b""Benutzer/Passwort Fehler""): <TAB> <TAB> <TAB> raise BadLogin(line) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise FailedPost(""Server returned '%s'"" % six.ensure_text(line))",true,"if line . startswith ( b""OK"" ) :","if line . startswith ( b""OK"" ) :",0.75,0.0
"def ParseResponses( <TAB> self, <TAB> knowledge_base: rdf_client.KnowledgeBase, <TAB> responses: Iterable[rdfvalue.RDFValue], ) -> Iterator[rdf_client.User]: <TAB> for response in responses: <TAB> <TAB> if not isinstance(response, rdf_client_fs.StatEntry): <TAB> <TAB> <TAB> raise TypeError(f""Unexpected response type: `{type(response)}`"") <TAB> <TAB> # TODO: `st_mode` has to be an `int`, not `StatMode`. <TAB> <TAB> if stat.S_ISDIR(int(response.st_mode)): <TAB> <TAB> <TAB> homedir = response.pathspec.path <TAB> <TAB> <TAB> username = os.path.basename(homedir) <TAB> <TAB> <TAB> if username not in self._ignore_users: <TAB> <TAB> <TAB> <TAB> yield rdf_client.User(username=username, homedir=homedir)",true,if stat . S_ISDIR ( int ( response . st_mode ) ) :,if stat . S_ISDIR ( int ( response . st_mode ) ) :,0.75,0.0
"def __call__(self, x, uttid=None): <TAB> if self.utt2spk is not None: <TAB> <TAB> spk = self.utt2spk[uttid] <TAB> else: <TAB> <TAB> spk = uttid <TAB> if not self.reverse: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> x = np.add(x, self.bias[spk]) <TAB> <TAB> if self.norm_vars: <TAB> <TAB> <TAB> x = np.multiply(x, self.scale[spk]) <TAB> else: <TAB> <TAB> if self.norm_vars: <TAB> <TAB> <TAB> x = np.divide(x, self.scale[spk]) <TAB> <TAB> if self.norm_means: <TAB> <TAB> <TAB> x = np.subtract(x, self.bias[spk]) <TAB> return x",true,if self . norm_means :,if self . norm_means :,0.75,0.0
"def hasFixtures(self, ctx_callback=None): <TAB> context = self.context <TAB> if context is None: <TAB> <TAB> return False <TAB> if self.implementsAnyFixture(context, ctx_callback=ctx_callback): <TAB> <TAB> return True <TAB> # My context doesn't have any, but its ancestors might <TAB> factory = self.factory <TAB> if factory: <TAB> <TAB> ancestors = factory.context.get(self, []) <TAB> <TAB> for ancestor in ancestors: <TAB> <TAB> <TAB> if self.implementsAnyFixture(ancestor, ctx_callback=ctx_callback): <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",true,"if self . implementsAnyFixture ( ancestor , ctx_callback = ctx_callback ) :","if self . implementsAnyFixture ( ancestor , ctx_callback = ctx_callback ) :",1.0,0.0
def UpdateControlState(self): <TAB> active = self.demoModules.GetActiveID() <TAB> # Update the radio/restore buttons <TAB> for moduleID in self.radioButtons: <TAB> <TAB> btn = self.radioButtons[moduleID] <TAB> <TAB> if moduleID == active: <TAB> <TAB> <TAB> btn.SetValue(True) <TAB> <TAB> else: <TAB> <TAB> <TAB> btn.SetValue(False) <TAB> <TAB> if self.demoModules.Exists(moduleID): <TAB> <TAB> <TAB> btn.Enable(True) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.btnRestore.Enable(True) <TAB> <TAB> else: <TAB> <TAB> <TAB> btn.Enable(False) <TAB> <TAB> <TAB> if moduleID == modModified: <TAB> <TAB> <TAB> <TAB> self.btnRestore.Enable(False),false,if moduleID == modModified :,if moduleID == active :,0.39,0.0
"def ignore_proxy_host(self): <TAB> """"""Check if self.host is in the $no_proxy ignore list."""""" <TAB> if urllib.proxy_bypass(self.host): <TAB> <TAB> return True <TAB> no_proxy = os.environ.get(""no_proxy"") <TAB> if no_proxy: <TAB> <TAB> entries = [parse_host_port(x) for x in no_proxy.split("","")] <TAB> <TAB> for host, port in entries: <TAB> <TAB> <TAB> if host.lower() == self.host and port == self.port: <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",true,if host . lower ( ) == self . host and port == self . port :,if host . lower ( ) == self . host and port == self . port :,1.0,0.0
"def run(self, _): <TAB> view = self.view <TAB> if not view.settings().get(""terminus_view""): <TAB> <TAB> return <TAB> terminal = Terminal.from_id(view.id()) <TAB> if terminal: <TAB> <TAB> terminal.close() <TAB> <TAB> panel_name = terminal.panel_name <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> window = panel_window(view) <TAB> <TAB> <TAB> if window: <TAB> <TAB> <TAB> <TAB> window.destroy_output_panel(panel_name) <TAB> <TAB> else: <TAB> <TAB> <TAB> view.close()",true,if panel_name :,if panel_name :,0.53,0.0
"def get_docname_for_node(self, node: Node) -> str: <TAB> while node: <TAB> <TAB> if isinstance(node, nodes.document): <TAB> <TAB> <TAB> return self.env.path2doc(node[""source""]) <TAB> <TAB> elif isinstance(node, addnodes.start_of_file): <TAB> <TAB> <TAB> return node[""docname""] <TAB> <TAB> else: <TAB> <TAB> <TAB> node = node.parent <TAB> return None  # never reached here. only for type hinting",false,"if isinstance ( node , nodes . document ) :","elif isinstance ( node , addnodes . start_of_file ) :",0.16,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB> if tt == 10: <TAB> <TAB> <TAB> self.add_version(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 0 :,if tt == 0 :,0.75,0.0
"def _maybe_female(self, path_elements, female, strict): <TAB> if female: <TAB> <TAB> if self.has_gender_differences: <TAB> <TAB> <TAB> elements = path_elements + [""female""] <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> return self._get_file(elements, "".png"", strict=strict) <TAB> <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> elif strict: <TAB> <TAB> <TAB> raise ValueError(""Pokemon %s has no gender differences"" % self.species_id) <TAB> return self._get_file(path_elements, "".png"", strict=strict)",false,if strict :,if not self . raise_on_bad_gender_differences :,0.17,0.0
"def OnKeyUp(self, event): <TAB> if self._properties.modifiable: <TAB> <TAB> if event.GetKeyCode() == wx.WXK_ESCAPE: <TAB> <TAB> <TAB> self._cancel_editing() <TAB> <TAB> elif event.GetKeyCode() == wx.WXK_RETURN: <TAB> <TAB> <TAB> self._update_value() <TAB> <TAB> elif event.GetKeyCode() == wx.WXK_DELETE: <TAB> <TAB> <TAB> self.SetValue("""") <TAB> if event.GetKeyCode() != wx.WXK_RETURN: <TAB> <TAB> # Don't send skip event if enter key is pressed <TAB> <TAB> # On some platforms this event is sent too late and causes crash <TAB> <TAB> event.Skip()",false,elif event . GetKeyCode ( ) == wx . WXK_DELETE :,elif event . GetKeyCode ( ) == wx . WXK_RETURN :,0.65,0.0
"def sync_up_to_new_location(self, worker_ip): <TAB> if worker_ip != self.worker_ip: <TAB> <TAB> logger.debug(""Setting new worker IP to %s"", worker_ip) <TAB> <TAB> self.set_worker_ip(worker_ip) <TAB> <TAB> self.reset() <TAB> <TAB> if not self.sync_up(): <TAB> <TAB> <TAB> logger.warning(""Sync up to new location skipped. This should not occur."") <TAB> else: <TAB> <TAB> logger.warning(""Sync attempted to same IP %s."", worker_ip)",true,if not self . sync_up ( ) :,if not self . sync_up ( ) :,0.75,0.0
"def _get_download_link(self, url, download_type=""torrent""): <TAB> links = { <TAB> <TAB> ""torrent"": """", <TAB> <TAB> ""magnet"": """", <TAB> } <TAB> try: <TAB> <TAB> data = self.session.get(url).text <TAB> <TAB> with bs4_parser(data) as html: <TAB> <TAB> <TAB> downloads = html.find(""div"", {""class"": ""download""}) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> for download in downloads.findAll(""a""): <TAB> <TAB> <TAB> <TAB> <TAB> link = download[""href""] <TAB> <TAB> <TAB> <TAB> <TAB> if link.startswith(""magnet""): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> links[""magnet""] = link <TAB> <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> links[""torrent""] = urljoin(self.urls[""base_url""], link) <TAB> except Exception: <TAB> <TAB> pass <TAB> return links[download_type]",true,if downloads :,if downloads :,0.53,0.0
"def force_ipv4(self, *args): <TAB> """"""only ipv4 localhost in /etc/hosts"""""" <TAB> logg.debug(""checking /etc/hosts for '::1 localhost'"") <TAB> lines = [] <TAB> for line in open(self.etc_hosts()): <TAB> <TAB> if ""::1"" in line: <TAB> <TAB> <TAB> newline = re.sub(""\\slocalhost\\s"", "" "", line) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> logg.info(""/etc/hosts: '%s' => '%s'"", line.rstrip(), newline.rstrip()) <TAB> <TAB> <TAB> <TAB> line = newline <TAB> <TAB> lines.append(line) <TAB> f = open(self.etc_hosts(), ""w"") <TAB> for line in lines: <TAB> <TAB> f.write(line) <TAB> f.close()",false,if line != newline :,if line :,0.07,0.0
"def prepare(self): <TAB> # Maybe the brok is a old daemon one or was already prepared <TAB> # if so, the data is already ok <TAB> if hasattr(self, ""prepared"") and not self.prepared: <TAB> <TAB> self.data = SafeUnpickler.loads(self.data) <TAB> <TAB> if hasattr(self, ""instance_id""): <TAB> <TAB> <TAB> self.data[""instance_id""] = self.instance_id <TAB> self.prepared = True",true,"if hasattr ( self , ""instance_id"" ) :","if hasattr ( self , ""instance_id"" ) :",0.75,0.0
"def _test_compute_q0(self): <TAB> # Stub code to search a logq space and figure out logq0 by eyeballing <TAB> # results. This code does not run with the tests. Remove underscore to run. <TAB> sigma = 15 <TAB> order = 250 <TAB> logqs = np.arange(-290, -270, 1) <TAB> count = 0 <TAB> for logq in logqs: <TAB> <TAB> count += 1 <TAB> <TAB> sys.stdout.write( <TAB> <TAB> <TAB> ""\t%0.5g: %0.10g"" % (logq, pate.rdp_gaussian(logq, sigma, order)) <TAB> <TAB> ) <TAB> <TAB> sys.stdout.flush() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print("""")",false,if count % 5 == 0 :,if count % 100 == 0 :,0.39,0.0
"def valid_fieldnames(fieldnames): <TAB> """"""check if fieldnames are valid"""""" <TAB> for fieldname in fieldnames: <TAB> <TAB> if fieldname in canonical_field_names and fieldname == ""source"": <TAB> <TAB> <TAB> return True <TAB> <TAB> elif fieldname in fieldname_map and fieldname_map[fieldname] == ""source"": <TAB> <TAB> <TAB> return True <TAB> return False",false,"if fieldname in canonical_field_names and fieldname == ""source"" :","elif fieldname in fieldname_map and fieldname_map [ fieldname ] == ""source"" :",0.22,0.0
"def ns_provide(self, id_): <TAB> global controllers, layouts <TAB> if id_ == ""_leo_viewrendered"": <TAB> <TAB> c = self.c <TAB> <TAB> vr = controllers.get(c.hash()) or ViewRenderedController(c) <TAB> <TAB> h = c.hash() <TAB> <TAB> controllers[h] = vr <TAB> <TAB> if not layouts.get(h): <TAB> <TAB> <TAB> layouts[h] = c.db.get(""viewrendered_default_layouts"", (None, None)) <TAB> <TAB> # return ViewRenderedController(self.c) <TAB> <TAB> return vr",true,if not layouts . get ( h ) :,if not layouts . get ( h ) :,0.75,0.0
"def remove(self, path, config=None, error_on_path=False, defaults=None): <TAB> if not path: <TAB> <TAB> if error_on_path: <TAB> <TAB> <TAB> raise NoSuchSettingsPath() <TAB> <TAB> return <TAB> if config is not None or defaults is not None: <TAB> <TAB> if config is None: <TAB> <TAB> <TAB> config = self._config <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> defaults = dict(self._map.parents) <TAB> <TAB> chain = HierarchicalChainMap(config, defaults) <TAB> else: <TAB> <TAB> chain = self._map <TAB> try: <TAB> <TAB> chain.del_by_path(path) <TAB> <TAB> self._mark_dirty() <TAB> except KeyError: <TAB> <TAB> if error_on_path: <TAB> <TAB> <TAB> raise NoSuchSettingsPath() <TAB> <TAB> pass",true,if defaults is None :,if defaults is None :,0.75,0.0
"def _mongo_query_and(self, queries): <TAB> if len(queries) == 1: <TAB> <TAB> return queries[0] <TAB> query = {} <TAB> for q in queries: <TAB> <TAB> for k, v in q.items(): <TAB> <TAB> <TAB> if k not in query: <TAB> <TAB> <TAB> <TAB> query[k] = {} <TAB> <TAB> <TAB> if isinstance(v, list): <TAB> <TAB> <TAB> <TAB> # TODO check exists of k in query, may be it should be update <TAB> <TAB> <TAB> <TAB> query[k] = v <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> query[k].update(v) <TAB> return query",true,"if isinstance ( v , list ) :","if isinstance ( v , list ) :",0.75,0.0
"def write(self, data): <TAB> self.size -= len(data) <TAB> passon = None <TAB> if self.size > 0: <TAB> <TAB> self.data.append(data) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> data, passon = data[: self.size], data[self.size :] <TAB> <TAB> else: <TAB> <TAB> <TAB> passon = b"""" <TAB> <TAB> if data: <TAB> <TAB> <TAB> self.data.append(data) <TAB> return passon",false,if self . size :,if self . size > 0 :,0.29,0.0
"def updateVar(name, data, mode=None): <TAB> if mode: <TAB> <TAB> if mode == ""append"": <TAB> <TAB> <TAB> core.config.globalVariables[name].append(data) <TAB> <TAB> elif mode == ""add"": <TAB> <TAB> <TAB> core.config.globalVariables[name].add(data) <TAB> else: <TAB> <TAB> core.config.globalVariables[name] = data",true,"elif mode == ""add"" :","elif mode == ""add"" :",1.0,0.0
"def vi_pos_back_short(line, index=0, count=1): <TAB> line = vi_list(line) <TAB> try: <TAB> <TAB> for i in range(count): <TAB> <TAB> <TAB> index -= 1 <TAB> <TAB> <TAB> while vi_is_space(line[index]): <TAB> <TAB> <TAB> <TAB> index -= 1 <TAB> <TAB> <TAB> in_word = vi_is_word(line[index]) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> while vi_is_word(line[index]): <TAB> <TAB> <TAB> <TAB> <TAB> index -= 1 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> while not vi_is_word_or_space(line[index]): <TAB> <TAB> <TAB> <TAB> <TAB> index -= 1 <TAB> <TAB> return index + 1 <TAB> except IndexError: <TAB> <TAB> return 0",true,if in_word :,if in_word :,0.53,0.0
"def _truncate_to_length(generator, len_map=None): <TAB> for example in generator: <TAB> <TAB> example = list(example) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for key, max_len in len_map.items(): <TAB> <TAB> <TAB> <TAB> example_len = example[key].shape <TAB> <TAB> <TAB> <TAB> if example_len > max_len: <TAB> <TAB> <TAB> <TAB> <TAB> example[key] = np.resize(example[key], max_len) <TAB> <TAB> yield tuple(example)",true,if len_map is not None :,if len_map is not None :,0.75,0.0
"def decorate(f): <TAB> # call-signature of f is exposed via __wrapped__. <TAB> # we want it to mimic Obj.__init__ <TAB> f.__wrapped__ = Obj.__init__ <TAB> f._uses_signature = Obj <TAB> # Supplement the docstring of f with information from Obj <TAB> if Obj.__doc__: <TAB> <TAB> doclines = Obj.__doc__.splitlines() <TAB> <TAB> if f.__doc__: <TAB> <TAB> <TAB> doc = f.__doc__ + ""\n"".join(doclines[1:]) <TAB> <TAB> else: <TAB> <TAB> <TAB> doc = ""\n"".join(doclines) <TAB> <TAB> try: <TAB> <TAB> <TAB> f.__doc__ = doc <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> # __doc__ is not modifiable for classes in Python < 3.3 <TAB> <TAB> <TAB> pass <TAB> return f",true,if f . __doc__ :,if f . __doc__ :,0.75,0.0
"def IncrementErrorCount(self, category): <TAB> """"""Bumps the module's error statistic."""""" <TAB> self.error_count += 1 <TAB> if self.counting in (""toplevel"", ""detailed""): <TAB> <TAB> if self.counting != ""detailed"": <TAB> <TAB> <TAB> category = category.split(""/"")[0] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.errors_by_category[category] = 0 <TAB> <TAB> self.errors_by_category[category] += 1",true,if category not in self . errors_by_category :,if category not in self . errors_by_category :,0.75,0.0
"def _delete_fields(self, data): <TAB> data = self._del( <TAB> <TAB> data, [""speaker_ids"", ""track_id"", ""microlocation_id"", ""session_type_id""] <TAB> ) <TAB> # convert datetime fields <TAB> for _ in [""start_time_tz"", ""end_time_tz""]: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> data[_] = SESSION_POST[_[0:-3]].from_str(data[_]) <TAB> <TAB> <TAB> data[_[0:-3]] = data.pop(_) <TAB> return data",true,if _ in data :,if _ in data :,0.75,0.0
"def get_strings_of_set(word, char_set, threshold=20): <TAB> count = 0 <TAB> letters = """" <TAB> strings = [] <TAB> for char in word: <TAB> <TAB> if char in char_set: <TAB> <TAB> <TAB> letters += char <TAB> <TAB> <TAB> count += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> strings.append(letters) <TAB> <TAB> <TAB> letters = """" <TAB> <TAB> <TAB> count = 0 <TAB> if count > threshold: <TAB> <TAB> strings.append(letters) <TAB> return strings",true,if count > threshold :,if count > threshold :,0.75,0.0
"def _ArgumentListHasDictionaryEntry(self, token): <TAB> """"""Check if the function argument list has a dictionary as an arg."""""" <TAB> if _IsArgumentToFunction(token): <TAB> <TAB> while token: <TAB> <TAB> <TAB> if token.value == ""{"": <TAB> <TAB> <TAB> <TAB> length = token.matching_bracket.total_length - token.total_length <TAB> <TAB> <TAB> <TAB> return length + self.stack[-2].indent > self.column_limit <TAB> <TAB> <TAB> if token.ClosesScope(): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if token.OpensScope(): <TAB> <TAB> <TAB> <TAB> token = token.matching_bracket <TAB> <TAB> <TAB> token = token.next_token <TAB> return False",false,if token . ClosesScope ( ) :,"if token . value == ""{"" :",0.09,0.0
"def check_apns_certificate(ss): <TAB> mode = ""start"" <TAB> for s in ss.split(""\n""): <TAB> <TAB> if mode == ""start"": <TAB> <TAB> <TAB> if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s: <TAB> <TAB> <TAB> <TAB> mode = ""key"" <TAB> <TAB> elif mode == ""key"": <TAB> <TAB> <TAB> if ""END RSA PRIVATE KEY"" in s or ""END PRIVATE KEY"" in s: <TAB> <TAB> <TAB> <TAB> mode = ""end"" <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> elif s.startswith(""Proc-Type"") and ""ENCRYPTED"" in s: <TAB> <TAB> <TAB> <TAB> raise ImproperlyConfigured( <TAB> <TAB> <TAB> <TAB> <TAB> ""Encrypted APNS private keys are not supported"" <TAB> <TAB> <TAB> <TAB> ) <TAB> if mode != ""end"": <TAB> <TAB> raise ImproperlyConfigured(""The APNS certificate doesn't contain a private key"")",true,"elif s . startswith ( ""Proc-Type"" ) and ""ENCRYPTED"" in s :","elif s . startswith ( ""Proc-Type"" ) and ""ENCRYPTED"" in s :",1.0,0.0
"def main(self): <TAB> self.model.clear() <TAB> self.callman.unregister_all() <TAB> active_handle = self.get_active(""Person"") <TAB> if active_handle: <TAB> <TAB> active = self.dbstate.db.get_person_from_handle(active_handle) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.callman.register_obj(active) <TAB> <TAB> <TAB> self.display_citations(active) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.set_has_data(False) <TAB> else: <TAB> <TAB> self.set_has_data(False)",true,if active :,if active :,0.53,0.0
"def _validate(self) -> None: <TAB> # Paren validation and such <TAB> super(Tuple, self)._validate() <TAB> if len(self.elements) == 0: <TAB> <TAB><IF-STMT>  # assumes len(lpar) == len(rpar), via superclass <TAB> <TAB> <TAB> raise CSTValidationError( <TAB> <TAB> <TAB> <TAB> ""A zero-length tuple must be wrapped in parentheses."" <TAB> <TAB> <TAB> )",false,if len ( self . lpar ) == 0 :,if len ( self . elements ) == 0 :,0.58,0.0
"def _session_from_arg(self, session_obj, lock_type=None): <TAB> if not isinstance(session_obj, self.ISession): <TAB> <TAB> vm = self._machine_from_arg(session_obj) <TAB> <TAB> lock_type = lock_type or self.LockType.null <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return vm.create_session(lock_type) <TAB> <TAB> return None <TAB> return session_obj",true,if vm :,if vm :,0.53,0.0
"def _decorator(cls): <TAB> for name, meth in inspect.getmembers(cls, inspect.isroutine): <TAB> <TAB> if name not in cls.__dict__: <TAB> <TAB> <TAB> continue <TAB> <TAB> if name != ""__init__"": <TAB> <TAB> <TAB> if not private and name.startswith(""_""): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> if name in butnot: <TAB> <TAB> <TAB> continue <TAB> <TAB> setattr(cls, name, decorator(meth)) <TAB> return cls",true,"if name != ""__init__"" :","if name != ""__init__"" :",0.75,0.0
"def pdb(message=""""): <TAB> """"""Fall into pdb."""""" <TAB> import pdb  # Required: we have just defined pdb as a function! <TAB> if app and not app.useIpython: <TAB> <TAB> # from leo.core.leoQt import QtCore <TAB> <TAB> # This is more portable. <TAB> <TAB> try: <TAB> <TAB> <TAB> import PyQt5.QtCore as QtCore <TAB> <TAB> except ImportError: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> import PyQt4.QtCore as QtCore <TAB> <TAB> <TAB> except ImportError: <TAB> <TAB> <TAB> <TAB> QtCore = None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # pylint: disable=no-member <TAB> <TAB> <TAB> QtCore.pyqtRemoveInputHook() <TAB> if message: <TAB> <TAB> print(message) <TAB> pdb.set_trace()",true,if QtCore :,if QtCore :,0.53,0.0
"def get_s3_bucket_locations(buckets, self_log=False): <TAB> """"""return (bucket_name, prefix) for all s3 logging targets"""""" <TAB> for b in buckets: <TAB> <TAB> if b.get(""Logging""): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if b[""Name""] != b[""Logging""][""TargetBucket""]: <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield (b[""Logging""][""TargetBucket""], b[""Logging""][""TargetPrefix""]) <TAB> <TAB> if not self_log and b[""Name""].startswith(""cf-templates-""): <TAB> <TAB> <TAB> yield (b[""Name""], """")",false,if self_log :,"if ""Logging"" in b :",0.05,0.0
"def prepare_fields(self): <TAB> # See clean() <TAB> for k, v in self.fields.items(): <TAB> <TAB> v._required = v.required <TAB> <TAB> v.required = False <TAB> <TAB> v.widget.is_required = False <TAB> <TAB> if isinstance(v, I18nFormField): <TAB> <TAB> <TAB> v._required = v.one_required <TAB> <TAB> <TAB> v.one_required = False <TAB> <TAB> <TAB> v.widget.enabled_locales = self.locales",true,"if isinstance ( v , I18nFormField ) :","if isinstance ( v , I18nFormField ) :",0.75,0.0
"def __pack__(self): <TAB> new_values = [] <TAB> for i in xrange(len(self.__unpacked_data_elms__)): <TAB> <TAB> for key in self.__keys__[i]: <TAB> <TAB> <TAB> new_val = getattr(self, key) <TAB> <TAB> <TAB> old_val = self.__unpacked_data_elms__[i] <TAB> <TAB> <TAB> # In the case of Unions, when the first changed value <TAB> <TAB> <TAB> # is picked the loop is exited <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> new_values.append(new_val) <TAB> return struct.pack(self.__format__, *new_values)",true,if new_val != old_val :,if new_val != old_val :,0.75,0.0
"def run(self): <TAB> pwd_found = [] <TAB> if constant.user_dpapi and constant.user_dpapi.unlocked: <TAB> <TAB> main_vault_directory = os.path.join( <TAB> <TAB> <TAB> constant.profile[""APPDATA""], u"".."", u""Local"", u""Microsoft"", u""Vault"" <TAB> <TAB> ) <TAB> <TAB> if os.path.exists(main_vault_directory): <TAB> <TAB> <TAB> for vault_directory in os.listdir(main_vault_directory): <TAB> <TAB> <TAB> <TAB> cred = constant.user_dpapi.decrypt_vault( <TAB> <TAB> <TAB> <TAB> <TAB> os.path.join(main_vault_directory, vault_directory) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> if cred: <TAB> <TAB> <TAB> <TAB> <TAB> pwd_found.append(cred) <TAB> return pwd_found",true,if os . path . exists ( main_vault_directory ) :,if os . path . exists ( main_vault_directory ) :,0.75,0.0
"def on_revision_plugin_revision_pre_save(**kwargs): <TAB> instance = kwargs[""instance""] <TAB> if kwargs.get(""created"", False): <TAB> <TAB> update_previous_revision = ( <TAB> <TAB> <TAB> not instance.previous_revision <TAB> <TAB> <TAB> and instance.plugin <TAB> <TAB> <TAB> and instance.plugin.current_revision <TAB> <TAB> <TAB> and instance.plugin.current_revision != instance <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> instance.previous_revision = instance.plugin.current_revision <TAB> if not instance.revision_number: <TAB> <TAB> try: <TAB> <TAB> <TAB> previous_revision = instance.plugin.revision_set.latest() <TAB> <TAB> <TAB> instance.revision_number = previous_revision.revision_number + 1 <TAB> <TAB> except RevisionPluginRevision.DoesNotExist: <TAB> <TAB> <TAB> instance.revision_number = 1",true,if update_previous_revision :,if update_previous_revision :,0.53,0.0
"def __setattr__(self, name, value): <TAB> super().__setattr__(name, value) <TAB> field = self._fields.get(name) <TAB> if field: <TAB> <TAB> self.check_field_type(field, value) <TAB> <TAB> if name in self.__ast_frozen_fields__: <TAB> <TAB> <TAB> raise TypeError(f""cannot set immutable {name} on {self!r}"")",true,if name in self . __ast_frozen_fields__ :,if name in self . __ast_frozen_fields__ :,0.75,0.0
"def _check_for_req_data(data): <TAB> required_args = [""columns""] <TAB> for arg in required_args: <TAB> <TAB> if arg not in data or (isinstance(data[arg], list) and len(data[arg]) < 1): <TAB> <TAB> <TAB> return True, make_json_response( <TAB> <TAB> <TAB> <TAB> status=400, <TAB> <TAB> <TAB> <TAB> success=0, <TAB> <TAB> <TAB> <TAB> errormsg=gettext(""Could not find required parameter ({})."").format(arg), <TAB> <TAB> <TAB> ) <TAB> return False, """"",true,"if arg not in data or ( isinstance ( data [ arg ] , list ) and len ( data [ arg ] ) < 1 ) :","if arg not in data or ( isinstance ( data [ arg ] , list ) and len ( data [ arg ] ) < 1 ) :",1.0,0.0
"def train_dict(self, triples): <TAB> """"""Train a dict lemmatizer given training (word, pos, lemma) triples."""""" <TAB> # accumulate counter <TAB> ctr = Counter() <TAB> ctr.update([(p[0], p[1], p[2]) for p in triples]) <TAB> # find the most frequent mappings <TAB> for p, _ in ctr.most_common(): <TAB> <TAB> w, pos, l = p <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.composite_dict[(w, pos)] = l <TAB> <TAB> if w not in self.word_dict: <TAB> <TAB> <TAB> self.word_dict[w] = l <TAB> return",false,"if ( w , pos ) not in self . composite_dict :","if ( w , pos ) in self . composite_dict :",0.43,0.0
"def render(type_, obj, context): <TAB> if type_ == ""foreign_key"": <TAB> <TAB> return None <TAB> if type_ == ""column"": <TAB> <TAB> if obj.name == ""y"": <TAB> <TAB> <TAB> return None <TAB> <TAB> elif obj.name == ""q"": <TAB> <TAB> <TAB> return False <TAB> <TAB> else: <TAB> <TAB> <TAB> return ""col(%s)"" % obj.name <TAB> if type_ == ""type"" and isinstance(obj, MySpecialType): <TAB> <TAB> context.imports.add(""from mypackage import MySpecialType"") <TAB> <TAB> return ""MySpecialType()"" <TAB> return ""render:%s"" % type_",true,"elif obj . name == ""q"" :","elif obj . name == ""q"" :",1.0,0.0
"def test_knows_when_stepping_back_possible(self): <TAB> iterator = bidirectional_iterator.BidirectionalIterator([0, 1, 2, 3]) <TAB> commands = [0, 1, 0, 0, 1, 1, 0, 0, 0, 0] <TAB> command_count = 0 <TAB> results = [] <TAB> for _ in iterator: <TAB> <TAB> if commands[command_count]: <TAB> <TAB> <TAB> iterator.step_back_on_next_iteration() <TAB> <TAB> results.append(iterator.can_step_back()) <TAB> <TAB> command_count += 1 <TAB> assert results == [False, True, False, True, True, True, False, True, True, True]",true,if commands [ command_count ] :,if commands [ command_count ] :,0.75,0.0
"def flask_debug_true(context): <TAB> if context.is_module_imported_like(""flask""): <TAB> <TAB> if context.call_function_name_qual.endswith("".run""): <TAB> <TAB> <TAB> if context.check_call_arg_value(""debug"", ""True""): <TAB> <TAB> <TAB> <TAB> return bandit.Issue( <TAB> <TAB> <TAB> <TAB> <TAB> severity=bandit.HIGH, <TAB> <TAB> <TAB> <TAB> <TAB> confidence=bandit.MEDIUM, <TAB> <TAB> <TAB> <TAB> <TAB> text=""A Flask app appears to be run with debug=True, "" <TAB> <TAB> <TAB> <TAB> <TAB> ""which exposes the Werkzeug debugger and allows "" <TAB> <TAB> <TAB> <TAB> <TAB> ""the execution of arbitrary code."", <TAB> <TAB> <TAB> <TAB> <TAB> lineno=context.get_lineno_for_call_arg(""debug""), <TAB> <TAB> <TAB> <TAB> )",true,"if context . check_call_arg_value ( ""debug"" , ""True"" ) :","if context . check_call_arg_value ( ""debug"" , ""True"" ) :",0.75,0.0
"def __exit__(self, exc_type, exc_val, exc_tb): <TAB> if self._should_meta_profile: <TAB> <TAB> end_time = timezone.now() <TAB> <TAB> exception_raised = exc_type is not None <TAB> <TAB> if exception_raised: <TAB> <TAB> <TAB> Logger.error( <TAB> <TAB> <TAB> <TAB> ""Exception when performing meta profiling, dumping trace below"" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> traceback.print_exception(exc_type, exc_val, exc_tb) <TAB> <TAB> request = getattr(DataCollector().local, ""request"", None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> curr = request.meta_time or 0 <TAB> <TAB> <TAB> request.meta_time = curr + _time_taken(self.start_time, end_time)",true,if request :,if request :,0.53,0.0
"def get_job_offer(ja_list): <TAB> ja_joff_map = {} <TAB> offers = frappe.get_all( <TAB> <TAB> ""Job Offer"", <TAB> <TAB> filters=[[""job_applicant"", ""IN"", ja_list]], <TAB> <TAB> fields=[""name"", ""job_applicant"", ""status"", ""offer_date"", ""designation""], <TAB> ) <TAB> for offer in offers: <TAB> <TAB> if offer.job_applicant not in ja_joff_map.keys(): <TAB> <TAB> <TAB> ja_joff_map[offer.job_applicant] = [offer] <TAB> <TAB> else: <TAB> <TAB> <TAB> ja_joff_map[offer.job_applicant].append(offer) <TAB> return ja_joff_map",true,if offer . job_applicant not in ja_joff_map . keys ( ) :,if offer . job_applicant not in ja_joff_map . keys ( ) :,0.75,0.0
"def _get_deepest(self, t): <TAB> if isinstance(t, list): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return t[0] <TAB> <TAB> else: <TAB> <TAB> <TAB> for part in t: <TAB> <TAB> <TAB> <TAB> res = self._get_deepest(part) <TAB> <TAB> <TAB> <TAB> if res: <TAB> <TAB> <TAB> <TAB> <TAB> return res <TAB> <TAB> <TAB> return None <TAB> return None",true,if len ( t ) == 1 :,if len ( t ) == 1 :,0.75,0.0
"def test_main(self): <TAB> root = os.path.dirname(mutagen.__path__[0]) <TAB> skip = [os.path.join(root, ""docs""), os.path.join(root, ""venv"")] <TAB> for dirpath, dirnames, filenames in os.walk(root): <TAB> <TAB> if any((dirpath.startswith(s + os.sep) or s == dirpath) for s in skip): <TAB> <TAB> <TAB> continue <TAB> <TAB> for filename in filenames: <TAB> <TAB> <TAB> if filename.endswith("".py""): <TAB> <TAB> <TAB> <TAB> path = os.path.join(dirpath, filename) <TAB> <TAB> <TAB> <TAB> self._check_encoding(path)",true,if any ( ( dirpath . startswith ( s + os . sep ) or s == dirpath ) for s in skip ) :,if any ( ( dirpath . startswith ( s + os . sep ) or s == dirpath ) for s in skip ) :,1.0,0.0
"def xview(self, mode=None, value=None, units=None): <TAB> if type(value) == str: <TAB> <TAB> value = float(value) <TAB> if mode is None: <TAB> <TAB> return self.hsb.get() <TAB> elif mode == ""moveto"": <TAB> <TAB> frameWidth = self.innerframe.winfo_reqwidth() <TAB> <TAB> self._startX = value * float(frameWidth) <TAB> else:  # mode == 'scroll' <TAB> <TAB> clipperWidth = self._clipper.winfo_width() <TAB> <TAB> if units == ""units"": <TAB> <TAB> <TAB> jump = int(clipperWidth * self._jfraction) <TAB> <TAB> else: <TAB> <TAB> <TAB> jump = clipperWidth <TAB> <TAB> self._startX = self._startX + value * jump <TAB> self.reposition()",true,"if units == ""units"" :","if units == ""units"" :",0.75,0.0
"def test_training_script_with_max_history_set(tmpdir): <TAB> train_dialogue_model( <TAB> <TAB> DEFAULT_DOMAIN_PATH, <TAB> <TAB> DEFAULT_STORIES_FILE, <TAB> <TAB> tmpdir.strpath, <TAB> <TAB> interpreter=RegexInterpreter(), <TAB> <TAB> policy_config=""data/test_config/max_hist_config.yml"", <TAB> <TAB> kwargs={}, <TAB> ) <TAB> agent = Agent.load(tmpdir.strpath) <TAB> for policy in agent.policy_ensemble.policies: <TAB> <TAB> if hasattr(policy.featurizer, ""max_history""): <TAB> <TAB> <TAB> if type(policy) == FormPolicy: <TAB> <TAB> <TAB> <TAB> assert policy.featurizer.max_history == 2 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> assert policy.featurizer.max_history == 5",true,"if hasattr ( policy . featurizer , ""max_history"" ) :","if hasattr ( policy . featurizer , ""max_history"" ) :",0.75,0.0
"def generate_auto_complete(self, base, iterable_var): <TAB> sugg = [] <TAB> for entry in iterable_var: <TAB> <TAB> compare_entry = entry <TAB> <TAB> compare_base = base <TAB> <TAB> if self.settings.get(IGNORE_CASE_SETTING): <TAB> <TAB> <TAB> compare_entry = compare_entry.lower() <TAB> <TAB> <TAB> compare_base = compare_base.lower() <TAB> <TAB> if self.compare_entries(compare_entry, compare_base): <TAB> <TAB> <TAB> if entry not in sugg: <TAB> <TAB> <TAB> <TAB> sugg.append(entry) <TAB> return sugg",false,if self . settings . get ( IGNORE_CASE_SETTING ) :,"if self . compare_entries ( compare_entry , compare_base ) :",0.07,0.0
"def marker_expr(remaining): <TAB> if remaining and remaining[0] == ""("": <TAB> <TAB> result, remaining = marker(remaining[1:].lstrip()) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise SyntaxError(""unterminated parenthesis: %s"" % remaining) <TAB> <TAB> remaining = remaining[1:].lstrip() <TAB> else: <TAB> <TAB> lhs, remaining = marker_var(remaining) <TAB> <TAB> while remaining: <TAB> <TAB> <TAB> m = MARKER_OP.match(remaining) <TAB> <TAB> <TAB> if not m: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> op = m.groups()[0] <TAB> <TAB> <TAB> remaining = remaining[m.end() :] <TAB> <TAB> <TAB> rhs, remaining = marker_var(remaining) <TAB> <TAB> <TAB> lhs = {""op"": op, ""lhs"": lhs, ""rhs"": rhs} <TAB> <TAB> result = lhs <TAB> return result, remaining",false,"if remaining [ 0 ] != "")"" :",if not result :,0.02,0.0
"def __repr__(self): <TAB> """"""Dump the class data in the format of a .netrc file."""""" <TAB> rep = """" <TAB> for host in self.hosts.keys(): <TAB> <TAB> attrs = self.hosts[host] <TAB> <TAB> rep = rep + ""machine "" + host + ""\n\tlogin "" + repr(attrs[0]) + ""\n"" <TAB> <TAB> if attrs[1]: <TAB> <TAB> <TAB> rep = rep + ""account "" + repr(attrs[1]) <TAB> <TAB> rep = rep + ""\tpassword "" + repr(attrs[2]) + ""\n"" <TAB> for macro in self.macros.keys(): <TAB> <TAB> rep = rep + ""macdef "" + macro + ""\n"" <TAB> <TAB> for line in self.macros[macro]: <TAB> <TAB> <TAB> rep = rep + line <TAB> <TAB> rep = rep + ""\n"" <TAB> return rep",true,if attrs [ 1 ] :,if attrs [ 1 ] :,0.75,0.0
"def _parse_policies(self, policies_yaml): <TAB> for item in policies_yaml: <TAB> <TAB> id_ = required_key(item, ""id"") <TAB> <TAB> controls_ids = required_key(item, ""controls"") <TAB> <TAB> if not isinstance(controls_ids, list): <TAB> <TAB> <TAB> if controls_ids != ""all"": <TAB> <TAB> <TAB> <TAB> msg = ""Policy {id_} contains invalid controls list {controls}."".format( <TAB> <TAB> <TAB> <TAB> <TAB> id_=id_, controls=str(controls_ids) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> raise ValueError(msg) <TAB> <TAB> self.policies[id_] = controls_ids",true,"if not isinstance ( controls_ids , list ) :","if not isinstance ( controls_ids , list ) :",0.75,0.0
"def __set__(self, obj, value):  # noqa <TAB> if ( <TAB> <TAB> value is not None <TAB> <TAB> and self.field._currency_field.null <TAB> <TAB> and not isinstance(value, MONEY_CLASSES + (Decimal,)) <TAB> ): <TAB> <TAB> # For nullable fields we need either both NULL amount and currency or both NOT NULL <TAB> <TAB> raise ValueError(""Missing currency value"") <TAB> if isinstance(value, BaseExpression): <TAB> <TAB> if isinstance(value, Value): <TAB> <TAB> <TAB> value = self.prepare_value(obj, value.value) <TAB> <TAB> elif not isinstance(value, Func): <TAB> <TAB> <TAB> validate_money_expression(obj, value) <TAB> <TAB> <TAB> prepare_expression(value) <TAB> else: <TAB> <TAB> value = self.prepare_value(obj, value) <TAB> obj.__dict__[self.field.name] = value",true,"if isinstance ( value , Value ) :","if isinstance ( value , Value ) :",0.75,0.0
"def Children(self): <TAB> """"""Returns a list of all of this object's owned (strong) children."""""" <TAB> children = [] <TAB> for property, attributes in self._schema.iteritems(): <TAB> <TAB> (is_list, property_type, is_strong) = attributes[0:3] <TAB> <TAB> if is_strong and property in self._properties: <TAB> <TAB> <TAB> if not is_list: <TAB> <TAB> <TAB> <TAB> children.append(self._properties[property]) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> children.extend(self._properties[property]) <TAB> return children",true,if is_strong and property in self . _properties :,if is_strong and property in self . _properties :,0.75,0.0
"def next_item(self, direction): <TAB> """"""Selects next menu item, based on self._direction"""""" <TAB> start, i = -1, 0 <TAB> try: <TAB> <TAB> start = self.items.index(self._selected) <TAB> <TAB> i = start + direction <TAB> except: <TAB> <TAB> pass <TAB> while True: <TAB> <TAB> if i == start: <TAB> <TAB> <TAB> # Cannot find valid menu item <TAB> <TAB> <TAB> self.select(start) <TAB> <TAB> <TAB> break <TAB> <TAB> if i >= len(self.items): <TAB> <TAB> <TAB> i = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> if i < 0: <TAB> <TAB> <TAB> i = len(self.items) - 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> if self.select(i): <TAB> <TAB> <TAB> break <TAB> <TAB> i += direction <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> start = 0",false,if start < 0 :,if i == start :,0.04,0.0
"def setup_displace(self): <TAB> self.displace_mod = None <TAB> self.displace_strength = 0.020 <TAB> for mod in self.obj.modifiers: <TAB> <TAB> if mod.type == ""DISPLACE"": <TAB> <TAB> <TAB> self.displace_mod = mod <TAB> <TAB> <TAB> self.displace_strength = mod.strength <TAB> if not self.displace_mod: <TAB> <TAB> bpy.ops.object.modifier_add(type=""DISPLACE"") <TAB> <TAB> self.displace_mod = self.obj.modifiers[-1] <TAB> <TAB> self.displace_mod.show_expanded = False <TAB> <TAB> self.displace_mod.strength = self.displace_strength <TAB> <TAB> self.displace_mod.show_render = False <TAB> <TAB> self.displace_mod.show_viewport = False",true,"if mod . type == ""DISPLACE"" :","if mod . type == ""DISPLACE"" :",0.75,0.0
"def set_json_body(cls, request_builder): <TAB> old_body = request_builder.info.pop(""data"", {}) <TAB> if isinstance(old_body, abc.Mapping): <TAB> <TAB> body = request_builder.info.setdefault(""json"", {}) <TAB> <TAB> for path in old_body: <TAB> <TAB> <TAB> if isinstance(path, tuple): <TAB> <TAB> <TAB> <TAB> cls._sequence_path_resolver(path, old_body[path], body) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> body[path] = old_body[path] <TAB> else: <TAB> <TAB> request_builder.info.setdefault(""json"", old_body)",true,"if isinstance ( path , tuple ) :","if isinstance ( path , tuple ) :",0.75,0.0
"def build(opt): <TAB> dpath = os.path.join(opt[""datapath""], ""DBLL"") <TAB> version = None <TAB> if not build_data.built(dpath, version_string=version): <TAB> <TAB> print(""[building data: "" + dpath + ""]"") <TAB> <TAB> if build_data.built(dpath): <TAB> <TAB> <TAB> # An older version exists, so remove these outdated files. <TAB> <TAB> <TAB> build_data.remove_dir(dpath) <TAB> <TAB> build_data.make_dir(dpath) <TAB> <TAB> # Download the data. <TAB> <TAB> for downloadable_file in RESOURCES: <TAB> <TAB> <TAB> downloadable_file.download_file(dpath) <TAB> <TAB> # Mark the data as built. <TAB> <TAB> build_data.mark_done(dpath, version_string=version)",true,if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,0.75,0.0
"def test_prefix_lm(self): <TAB> num_tries = 100 <TAB> original = ""This is a long test with lots of words to see if it works ok."" <TAB> dataset = tf.data.Dataset.from_tensor_slices({""text"": [original] * num_tries}) <TAB> dataset = prep.prefix_lm(dataset) <TAB> for data in test_utils.dataset_as_text(dataset): <TAB> <TAB> inputs = data[""inputs""].replace(""prefix: "", """") <TAB> <TAB> targets = data[""targets""] <TAB> <TAB> reconstructed = """".join(inputs) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> reconstructed += "" "" <TAB> <TAB> reconstructed += """".join(targets) <TAB> <TAB> self.assertEqual(reconstructed, original)",false,if inputs :,if targets :,0.32,0.0
"def leading_whitespace(self, inputstring): <TAB> """"""Get leading whitespace."""""" <TAB> leading_ws = [] <TAB> for i, c in enumerate(inputstring): <TAB> <TAB> if c in legal_indent_chars: <TAB> <TAB> <TAB> leading_ws.append(c) <TAB> <TAB> else: <TAB> <TAB> <TAB> break <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.indchar = c <TAB> <TAB> elif c != self.indchar: <TAB> <TAB> <TAB> self.strict_err_or_warn(""found mixing of tabs and spaces"", inputstring, i) <TAB> return """".join(leading_ws)",false,if self . indchar is None :,if i == 0 :,0.02,0.0
"def __init__(self, text): <TAB> self.mappings = {} <TAB> self.attributes = collections.defaultdict(set) <TAB> for stanza in _ParseTextProperties(text): <TAB> <TAB> processor_id, single_values, multiple_values = self._ParseStanza(stanza) <TAB> <TAB> if processor_id is None:  # can be 0 <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> logging.warn(""Processor id %s seen twice in %s"", processor_id, text) <TAB> <TAB> <TAB> continue <TAB> <TAB> self.mappings[processor_id] = single_values <TAB> <TAB> for key, value in multiple_values.items(): <TAB> <TAB> <TAB> self.attributes[key].add(value)",true,if processor_id in self . mappings :,if processor_id in self . mappings :,0.75,0.0
"def __iter__(self): <TAB> for chunk in self.source: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.wait_counter = 0 <TAB> <TAB> <TAB> yield chunk <TAB> <TAB> elif self.wait_counter < self.wait_cntr_max: <TAB> <TAB> <TAB> self.wait_counter += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> logger.warning( <TAB> <TAB> <TAB> <TAB> ""Data poller has been receiving no data for {} seconds.\n"" <TAB> <TAB> <TAB> <TAB> ""Closing data poller"".format(self.wait_cntr_max * self.poll_period) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> break <TAB> <TAB> time.sleep(self.poll_period)",false,if chunk is not None :,if self . wait_counter == self . wait_cntr_max :,0.02,0.0
"def download(self, prefetch=False): <TAB> while self.running: <TAB> <TAB> try: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> (path, start, end) = self.prefetch_queue.get( <TAB> <TAB> <TAB> <TAB> <TAB> True, 1 <TAB> <TAB> <TAB> <TAB> )  # 1 second time-out <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> (path, start, end) = self.download_queue.get( <TAB> <TAB> <TAB> <TAB> <TAB> True, 1 <TAB> <TAB> <TAB> <TAB> )  # 1 second time-out <TAB> <TAB> <TAB> self.download_data(path, start, end) <TAB> <TAB> <TAB> if prefetch: <TAB> <TAB> <TAB> <TAB> self.prefetch_queue.task_done() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.download_queue.task_done() <TAB> <TAB> except Queue.Empty: <TAB> <TAB> <TAB> pass",true,if prefetch :,if prefetch :,0.53,0.0
"def process_messages(self, found_files, messages): <TAB> for message in messages: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> message.to_absolute_path(self.config.workdir) <TAB> <TAB> else: <TAB> <TAB> <TAB> message.to_relative_path(self.config.workdir) <TAB> if self.config.blending: <TAB> <TAB> messages = blender.blend(messages) <TAB> filepaths = found_files.iter_module_paths(abspath=False) <TAB> return postfilter.filter_messages(filepaths, self.config.workdir, messages)",false,if self . config . absolute_paths :,if self . config . absolute :,0.57,0.0
"def set_indentation_params(self, ispythonsource, guess=1): <TAB> if guess and ispythonsource: <TAB> <TAB> i = self.guess_indent() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.indentwidth = i <TAB> <TAB> if self.indentwidth != self.tabwidth: <TAB> <TAB> <TAB> self.usetabs = 0 <TAB> self.editwin.set_tabwidth(self.tabwidth)",false,if 2 <= i <= 8 :,if i :,0.02,0.0
"def to_tree(self, tagname=None, value=None, namespace=None): <TAB> namespace = getattr(self, ""namespace"", namespace) <TAB> if value is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tagname = ""{%s}%s"" % (namespace, tagname) <TAB> <TAB> el = Element(tagname) <TAB> <TAB> el.text = safe_string(value) <TAB> <TAB> return el",true,if namespace is not None :,if namespace is not None :,0.75,0.0
"def execute(self, argv: List) -> bool: <TAB> if not argv: <TAB> <TAB> print(""ERROR: You must give at least one module to download."") <TAB> <TAB> return False <TAB> for _arg in argv: <TAB> <TAB> result = module_server.search_module(_arg) <TAB> <TAB> CacheUpdater(""hub_download"", _arg).start() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> url = result[0][""url""] <TAB> <TAB> <TAB> with log.ProgressBar(""Download {}"".format(url)) as bar: <TAB> <TAB> <TAB> <TAB> for file, ds, ts in utils.download_with_progress(url): <TAB> <TAB> <TAB> <TAB> <TAB> bar.update(float(ds) / ts) <TAB> <TAB> else: <TAB> <TAB> <TAB> print(""ERROR: Could not find a HubModule named {}"".format(_arg)) <TAB> return True",true,if result :,if result :,0.53,0.0
"def visit_type_type(self, t: TypeType) -> ProperType: <TAB> if isinstance(self.s, TypeType): <TAB> <TAB> typ = self.meet(t.item, self.s.item) <TAB> <TAB> if not isinstance(typ, NoneType): <TAB> <TAB> <TAB> typ = TypeType.make_normalized(typ, line=t.line) <TAB> <TAB> return typ <TAB> elif isinstance(self.s, Instance) and self.s.type.fullname == ""builtins.type"": <TAB> <TAB> return t <TAB> elif isinstance(self.s, CallableType): <TAB> <TAB> return self.meet(t, self.s) <TAB> else: <TAB> <TAB> return self.default(self.s)",true,"if not isinstance ( typ , NoneType ) :","if not isinstance ( typ , NoneType ) :",0.75,0.0
"def run(self, paths=[]): <TAB> items = [] <TAB> for item in SideBarSelection(paths).getSelectedItems(): <TAB> <TAB> items.append(item.name()) <TAB> if len(items) > 0: <TAB> <TAB> sublime.set_clipboard(""\n"".join(items)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> sublime.status_message(""Items copied"") <TAB> <TAB> else: <TAB> <TAB> <TAB> sublime.status_message(""Item copied"")",true,if len ( items ) > 1 :,if len ( items ) > 1 :,0.75,0.0
"def get_icon(self): <TAB> if self.icon is not None: <TAB> <TAB> # Load it from an absolute filename <TAB> <TAB> if os.path.exists(self.icon): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> return GdkPixbuf.Pixbuf.new_from_file_at_size(self.icon, 24, 24) <TAB> <TAB> <TAB> except GObject.GError as ge: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> # Load it from the current icon theme <TAB> <TAB> (icon_name, extension) = os.path.splitext(os.path.basename(self.icon)) <TAB> <TAB> theme = Gtk.IconTheme() <TAB> <TAB> if theme.has_icon(icon_name): <TAB> <TAB> <TAB> return theme.load_icon(icon_name, 24, 0)",true,if os . path . exists ( self . icon ) :,if os . path . exists ( self . icon ) :,0.75,0.0
"def setup_logger(): <TAB> """"""Set up logger and add stdout handler"""""" <TAB> logging.setLoggerClass(IPDLogger) <TAB> logger = logging.getLogger(""icloudpd"") <TAB> has_stdout_handler = False <TAB> for handler in logger.handlers: <TAB> <TAB> if handler.name == ""stdoutLogger"": <TAB> <TAB> <TAB> has_stdout_handler = True <TAB> if not has_stdout_handler: <TAB> <TAB> formatter = logging.Formatter( <TAB> <TAB> <TAB> fmt=""%(asctime)s %(levelname)-8s %(message)s"", datefmt=""%Y-%m-%d %H:%M:%S"" <TAB> <TAB> ) <TAB> <TAB> stdout_handler = logging.StreamHandler(stream=sys.stdout) <TAB> <TAB> stdout_handler.setFormatter(formatter) <TAB> <TAB> stdout_handler.name = ""stdoutLogger"" <TAB> <TAB> logger.addHandler(stdout_handler) <TAB> return logger",true,"if handler . name == ""stdoutLogger"" :","if handler . name == ""stdoutLogger"" :",0.75,0.0
"def process_extra_fields(self): <TAB> if self.instance.pk is not None: <TAB> <TAB> if self.cleaned_data.get(""initialize"", None): <TAB> <TAB> <TAB> self.instance.initialize() <TAB> <TAB> if self.cleaned_data.get(""update"", None) or not self.instance.stores.count(): <TAB> <TAB> <TAB> self.instance.update_from_templates()",true,"if self . cleaned_data . get ( ""update"" , None ) or not self . instance . stores . count ( ) :","if self . cleaned_data . get ( ""update"" , None ) or not self . instance . stores . count ( ) :",1.0,0.0
"def testFunctions(self): <TAB> from zim.formats.wiki import match_url, is_url <TAB> for input, input_is_url, tail in self.examples: <TAB> <TAB> if input_is_url: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.assertEqual(match_url(input), input[: -len(tail)]) <TAB> <TAB> <TAB> <TAB> self.assertFalse(is_url(input)) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.assertEqual(match_url(input), input) <TAB> <TAB> <TAB> <TAB> self.assertTrue(is_url(input)) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.assertEqual(match_url(input), None) <TAB> <TAB> <TAB> self.assertFalse(is_url(input))",true,if tail :,if tail :,0.53,0.0
"def _SetUser(self, users): <TAB> for user in users.items(): <TAB> <TAB> username = user[0] <TAB> <TAB> settings = user[1] <TAB> <TAB> room = settings[""room""][""name""] if ""room"" in settings else None <TAB> <TAB> file_ = settings[""file""] if ""file"" in settings else None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if ""joined"" in settings[""event""]: <TAB> <TAB> <TAB> <TAB> self._client.userlist.addUser(username, room, file_) <TAB> <TAB> <TAB> elif ""left"" in settings[""event""]: <TAB> <TAB> <TAB> <TAB> self._client.removeUser(username) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._client.userlist.modUser(username, room, file_)",false,"if ""event"" in settings :",if file_ :,0.04,0.0
"def restoreTerminals(self, state): <TAB> for name in list(self.terminals.keys()): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.removeTerminal(name) <TAB> for name, opts in state.items(): <TAB> <TAB> if name in self.terminals: <TAB> <TAB> <TAB> term = self[name] <TAB> <TAB> <TAB> term.setOpts(**opts) <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> opts = strDict(opts) <TAB> <TAB> <TAB> self.addTerminal(name, **opts) <TAB> <TAB> except: <TAB> <TAB> <TAB> printExc(""Error restoring terminal %s (%s):"" % (str(name), str(opts)))",false,if name not in state :,if name in self :,0.15,0.0
"def htmlify(path, text): <TAB> fname = os.path.basename(path) <TAB> if any((fnmatch.fnmatchcase(fname, p) for p in _patterns)): <TAB> <TAB> # Get file_id, skip if not in database <TAB> <TAB> sql = ""SELECT files.id FROM files WHERE path = ? LIMIT 1"" <TAB> <TAB> row = _conn.execute(sql, (path,)).fetchone() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ClangHtmlifier(_tree, _conn, path, text, row[0]) <TAB> return None",true,if row :,if row :,0.53,0.0
"def autoformat_filter_conv2d(fsize, in_depth, out_depth): <TAB> if isinstance(fsize, int): <TAB> <TAB> return [fsize, fsize, in_depth, out_depth] <TAB> elif isinstance(fsize, (tuple, list, tf.TensorShape)): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return [fsize[0], fsize[1], in_depth, out_depth] <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> ""filter length error: "" <TAB> <TAB> <TAB> <TAB> + str(len(fsize)) <TAB> <TAB> <TAB> <TAB> + "", only a length of 2 is supported."" <TAB> <TAB> <TAB> ) <TAB> else: <TAB> <TAB> raise Exception(""filter format error: "" + str(type(fsize)))",true,if len ( fsize ) == 2 :,if len ( fsize ) == 2 :,0.75,0.0
"def _rle_encode(string): <TAB> new = b"""" <TAB> count = 0 <TAB> for cur in string: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> count += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> if count: <TAB> <TAB> <TAB> <TAB> new += b""\0"" + bytes([count]) <TAB> <TAB> <TAB> <TAB> count = 0 <TAB> <TAB> <TAB> new += bytes([cur]) <TAB> return new",false,if not cur :,"if cur == b"""" :",0.05,0.0
"def is_clean(self): <TAB> acceptable_statuses = {""external"", ""unversioned""} <TAB> root = self._capture_output(""status"", ""--quiet"") <TAB> for elem in root.findall(""./target/entry""): <TAB> <TAB> status = elem.find(""./wc-status"") <TAB> <TAB> if status.get(""item"", None) in acceptable_statuses: <TAB> <TAB> <TAB> continue <TAB> <TAB> log.debug(""Path %s is %s"", elem.get(""path""), status.get(""item"")) <TAB> <TAB> return False <TAB> return True",true,"if status . get ( ""item"" , None ) in acceptable_statuses :","if status . get ( ""item"" , None ) in acceptable_statuses :",0.75,0.0
"def process(self, body, message): <TAB> try: <TAB> <TAB> if not isinstance(body, self._handler.message_type): <TAB> <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> <TAB> 'Received an unexpected type ""%s"" for payload.' % type(body) <TAB> <TAB> <TAB> ) <TAB> <TAB> response = self._handler.pre_ack_process(body) <TAB> <TAB> self._dispatcher.dispatch(self._process_message, response) <TAB> except: <TAB> <TAB> LOG.exception(""%s failed to process message: %s"", self.__class__.__name__, body) <TAB> finally: <TAB> <TAB> # At this point we will always ack a message. <TAB> <TAB> message.ack()",true,"if not isinstance ( body , self . _handler . message_type ) :","if not isinstance ( body , self . _handler . message_type ) :",0.75,0.0
"def page_file(self, page): <TAB> try: <TAB> <TAB> page = self.notebook.get_page(page) <TAB> <TAB> if hasattr(page, ""source"") and isinstance(page.source, File): <TAB> <TAB> <TAB> return page.source <TAB> <TAB> else: <TAB> <TAB> <TAB> return None <TAB> except PageNotFoundError: <TAB> <TAB> return None",true,"if hasattr ( page , ""source"" ) and isinstance ( page . source , File ) :","if hasattr ( page , ""source"" ) and isinstance ( page . source , File ) :",1.0,0.0
"def _optimize(self, solutions): <TAB> best_a = None <TAB> best_silhouette = None <TAB> best_k = None <TAB> for a, silhouette, k in solutions(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> pass <TAB> <TAB> elif silhouette <= best_silhouette: <TAB> <TAB> <TAB> break <TAB> <TAB> best_silhouette = silhouette <TAB> <TAB> best_a = a <TAB> <TAB> best_k = k <TAB> return best_a, best_silhouette, best_k",false,if best_silhouette is None :,if a == best_a :,0.03,0.0
"def _cancel_tasks_for_partitions(self, to_cancel_partitions): <TAB> # type: (Iterable[str]) -> None <TAB> with self._lock: <TAB> <TAB> _LOGGER.debug( <TAB> <TAB> <TAB> ""EventProcessor %r tries to cancel partitions %r"", <TAB> <TAB> <TAB> self._id, <TAB> <TAB> <TAB> to_cancel_partitions, <TAB> <TAB> ) <TAB> <TAB> for partition_id in to_cancel_partitions: <TAB> <TAB> <TAB> if partition_id in self._consumers: <TAB> <TAB> <TAB> <TAB> self._consumers[partition_id].stop = True <TAB> <TAB> <TAB> <TAB> _LOGGER.info( <TAB> <TAB> <TAB> <TAB> <TAB> ""EventProcessor %r has cancelled partition %r"", <TAB> <TAB> <TAB> <TAB> <TAB> self._id, <TAB> <TAB> <TAB> <TAB> <TAB> partition_id, <TAB> <TAB> <TAB> <TAB> )",true,if partition_id in self . _consumers :,if partition_id in self . _consumers :,0.75,0.0
"def get_intersect_all(self, refine=False): <TAB> result = None <TAB> for source, parts in self._per_source.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result = parts <TAB> <TAB> else: <TAB> <TAB> <TAB> result.intersection_update(parts) <TAB> if not result: <TAB> <TAB> return None <TAB> elif len(result) == 1: <TAB> <TAB> return list(result)[0].item <TAB> else: <TAB> <TAB> solids = [p.item for p in result] <TAB> <TAB> solid = solids[0].fuse(solids[1:]) <TAB> <TAB> if refine: <TAB> <TAB> <TAB> solid = solid.removeSplitter() <TAB> <TAB> return solid",false,if result is None :,if source is None :,0.39,0.0
"def geli_detach(self, pool, clear=False): <TAB> failed = 0 <TAB> for ed in self.middleware.call_sync( <TAB> <TAB> ""datastore.query"", <TAB> <TAB> ""storage.encrypteddisk"", <TAB> <TAB> [(""encrypted_volume"", ""="", pool[""id""])], <TAB> ): <TAB> <TAB> dev = ed[""encrypted_provider""] <TAB> <TAB> try: <TAB> <TAB> <TAB> self.geli_detach_single(dev) <TAB> <TAB> except Exception as ee: <TAB> <TAB> <TAB> self.logger.warn(str(ee)) <TAB> <TAB> <TAB> failed += 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> self.geli_clear(dev) <TAB> <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> <TAB> self.logger.warn(""Failed to clear %s: %s"", dev, e) <TAB> return failed",true,if clear :,if clear :,0.53,0.0
def compute_lengths(batch_sizes): <TAB> tmp_batch_sizes = np.copy(batch_sizes) <TAB> lengths = [] <TAB> while True: <TAB> <TAB> c = np.count_nonzero(tmp_batch_sizes > 0) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> lengths.append(c) <TAB> <TAB> tmp_batch_sizes = np.array([b - 1 for b in tmp_batch_sizes]) <TAB> return np.array(lengths),true,if c == 0 :,if c == 0 :,0.75,0.0
"def _render_raw_list(bytes_items): <TAB> flatten_items = [] <TAB> for item in bytes_items: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> flatten_items.append(b"""") <TAB> <TAB> elif isinstance(item, bytes): <TAB> <TAB> <TAB> flatten_items.append(item) <TAB> <TAB> elif isinstance(item, int): <TAB> <TAB> <TAB> flatten_items.append(str(item).encode()) <TAB> <TAB> elif isinstance(item, list): <TAB> <TAB> <TAB> flatten_items.append(_render_raw_list(item)) <TAB> return b""\n"".join(flatten_items)",true,if item is None :,if item is None :,0.75,0.0
"def update(self, new_config): <TAB> jsonschema.validate(new_config, self.schema) <TAB> config = {} <TAB> for k, v in new_config.items(): <TAB> <TAB> if k in self.schema.get(""secret"", []) and v == SECRET_PLACEHOLDER: <TAB> <TAB> <TAB> config[k] = self[k] <TAB> <TAB> else: <TAB> <TAB> <TAB> config[k] = v <TAB> self._config = config <TAB> self.changed()",true,"if k in self . schema . get ( ""secret"" , [ ] ) and v == SECRET_PLACEHOLDER :","if k in self . schema . get ( ""secret"" , [ ] ) and v == SECRET_PLACEHOLDER :",1.0,0.0
"def _encode_numpy(values, uniques=None, encode=False, check_unknown=True): <TAB> # only used in _encode below, see docstring there for details <TAB> if uniques is None: <TAB> <TAB> if encode: <TAB> <TAB> <TAB> uniques, encoded = np.unique(values, return_inverse=True) <TAB> <TAB> <TAB> return uniques, encoded <TAB> <TAB> else: <TAB> <TAB> <TAB> # unique sorts <TAB> <TAB> <TAB> return np.unique(values) <TAB> if encode: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> diff = _encode_check_unknown(values, uniques) <TAB> <TAB> <TAB> if diff: <TAB> <TAB> <TAB> <TAB> raise ValueError(""y contains previously unseen labels: %s"" % str(diff)) <TAB> <TAB> encoded = np.searchsorted(uniques, values) <TAB> <TAB> return uniques, encoded <TAB> else: <TAB> <TAB> return uniques",true,if check_unknown :,if check_unknown :,0.53,0.0
"def restore_dtype_and_merge(arr, input_dtype): <TAB> if isinstance(arr, list): <TAB> <TAB> arr = [restore_dtype_and_merge(arr_i, input_dtype) for arr_i in arr] <TAB> <TAB> shapes = [arr_i.shape for arr_i in arr] <TAB> <TAB> if len(set(shapes)) == 1: <TAB> <TAB> <TAB> arr = np.array(arr) <TAB> if ia.is_np_array(arr): <TAB> <TAB> arr = iadt.restore_dtypes_(arr, input_dtype) <TAB> return arr",false,if len ( set ( shapes ) ) == 1 :,if ia . is_np_array ( arr ) :,0.05,0.0
"def proc_minute(d): <TAB> if expanded[0][0] != ""*"": <TAB> <TAB> diff_min = nearest_diff_method(d.minute, expanded[0], 60) <TAB> <TAB> if diff_min is not None and diff_min != 0: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> d += relativedelta(minutes=diff_min, second=59) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> d += relativedelta(minutes=diff_min, second=0) <TAB> <TAB> <TAB> return True, d <TAB> return False, d",false,if is_prev :,"if expanded [ 0 ] == ""*"" :",0.04,0.0
"def _populate_tree(self, element, d): <TAB> """"""Populates an etree with attributes & elements, given a dict."""""" <TAB> for k, v in d.iteritems(): <TAB> <TAB> if isinstance(v, dict): <TAB> <TAB> <TAB> self._populate_dict(element, k, v) <TAB> <TAB> elif isinstance(v, list): <TAB> <TAB> <TAB> self._populate_list(element, k, v) <TAB> <TAB> elif isinstance(v, bool): <TAB> <TAB> <TAB> self._populate_bool(element, k, v) <TAB> <TAB> elif isinstance(v, basestring): <TAB> <TAB> <TAB> self._populate_str(element, k, v) <TAB> <TAB> elif type(v) in [int, float, long, complex]: <TAB> <TAB> <TAB> self._populate_number(element, k, v)",false,"if isinstance ( v , dict ) :","elif isinstance ( v , basestring ) :",0.2,0.0
"def __createItemAttribute(self, item, function, preload): <TAB> """"""Create the new widget, add it, and remove the old one"""""" <TAB> try: <TAB> <TAB> self.__stack.addWidget(function(item, preload)) <TAB> <TAB> # Remove the widget <TAB> <TAB> if self.__stack.count() > 1: <TAB> <TAB> <TAB> oldWidget = self.__stack.widget(0) <TAB> <TAB> <TAB> self.__stack.removeWidget(oldWidget) <TAB> <TAB> <TAB> oldWidget.setParent(QtWidgets.QWidget()) <TAB> except Exception as e: <TAB> <TAB> list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",true,if self . __stack . count ( ) > 1 :,if self . __stack . count ( ) > 1 :,0.75,0.0
"def download_main( <TAB> download, download_playlist, urls, playlist, output_dir, merge, info_only ): <TAB> for url in urls: <TAB> <TAB> if url.startswith(""https://""): <TAB> <TAB> <TAB> url = url[8:] <TAB> <TAB> if not url.startswith(""http://""): <TAB> <TAB> <TAB> url = ""http://"" + url <TAB> <TAB> if playlist: <TAB> <TAB> <TAB> download_playlist( <TAB> <TAB> <TAB> <TAB> url, output_dir=output_dir, merge=merge, info_only=info_only <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> download(url, output_dir=output_dir, merge=merge, info_only=info_only)",true,"if url . startswith ( ""https://"" ) :","if url . startswith ( ""https://"" ) :",0.75,0.0
"def add_enc_zero(obj, enc_zero): <TAB> if isinstance(obj, np.ndarray): <TAB> <TAB> return obj + enc_zero <TAB> elif isinstance(obj, Iterable): <TAB> <TAB> return type(obj)( <TAB> <TAB> <TAB> EncryptModeCalculator.add_enc_zero(o, enc_zero) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> else o + enc_zero <TAB> <TAB> <TAB> for o in obj <TAB> <TAB> ) <TAB> else: <TAB> <TAB> return obj + enc_zero",false,"if isinstance ( o , Iterable )",if o,0.02,0.0
"def ensemble(self, pairs, other_preds): <TAB> """"""Ensemble the dict with statistical model predictions."""""" <TAB> lemmas = [] <TAB> assert len(pairs) == len(other_preds) <TAB> for p, pred in zip(pairs, other_preds): <TAB> <TAB> w, pos = p <TAB> <TAB> if (w, pos) in self.composite_dict: <TAB> <TAB> <TAB> lemma = self.composite_dict[(w, pos)] <TAB> <TAB> elif w in self.word_dict: <TAB> <TAB> <TAB> lemma = self.word_dict[w] <TAB> <TAB> else: <TAB> <TAB> <TAB> lemma = pred <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> lemma = w <TAB> <TAB> lemmas.append(lemma) <TAB> return lemmas",true,if lemma is None :,if lemma is None :,0.75,0.0
"def replace_to_6hex(color): <TAB> """"""Validate and replace 3hex colors to 6hex ones."""""" <TAB> if match(r""^#(?:[0-9a-fA-F]{3}){1,2}$"", color): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> color = ""#{0}{0}{1}{1}{2}{2}"".format(color[1], color[2], color[3]) <TAB> <TAB> return color <TAB> else: <TAB> <TAB> exit(_(""Invalid color {}"").format(color))",false,if len ( color ) == 4 :,if len ( color ) == 3 :,0.61,0.0
"def computeMachineName(self): <TAB> """"""Return the name of the current machine, i.e, HOSTNAME."""""" <TAB> # This is prepended to leoSettings.leo or myLeoSettings.leo <TAB> # to give the machine-specific setting name. <TAB> # How can this be worth doing?? <TAB> try: <TAB> <TAB> import os <TAB> <TAB> name = os.getenv(""HOSTNAME"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> name = os.getenv(""COMPUTERNAME"") <TAB> <TAB> if not name: <TAB> <TAB> <TAB> import socket <TAB> <TAB> <TAB> name = socket.gethostname() <TAB> except Exception: <TAB> <TAB> name = """" <TAB> return name",true,if not name :,if not name :,0.75,0.0
"def _git_dirty_working_directory(q, include_untracked): <TAB> try: <TAB> <TAB> cmd = [""git"", ""status"", ""--porcelain""] <TAB> <TAB> if include_untracked: <TAB> <TAB> <TAB> cmd += [""--untracked-files=normal""] <TAB> <TAB> else: <TAB> <TAB> <TAB> cmd += [""--untracked-files=no""] <TAB> <TAB> status = _run_git_cmd(cmd) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> q.put(bool(status)) <TAB> <TAB> else: <TAB> <TAB> <TAB> q.put(None) <TAB> except (subprocess.CalledProcessError, OSError, FileNotFoundError): <TAB> <TAB> q.put(None)",false,if status is not None :,if status :,0.05,0.0
"def runAndWaitWork(server, work): <TAB> work.touch() <TAB> thr = threading.Thread(target=workThread, args=(server, work)) <TAB> thr.setDaemon(True) <TAB> thr.start() <TAB> # Wait around for done or timeout <TAB> while True: <TAB> <TAB> if work.isTimedOut(): <TAB> <TAB> <TAB> break <TAB> <TAB> # If the thread is done, lets get out. <TAB> <TAB> if not thr.isAlive(): <TAB> <TAB> <TAB> break <TAB> <TAB> # If our parent, or some thread closes stdin, <TAB> <TAB> # time to pack up and go. <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> time.sleep(2)",false,if sys . stdin . closed :,if work . parent is None :,0.09,0.0
"def read(self, count=True, timeout=None, ignore_non_errors=True, ignore_timeouts=True): <TAB> try: <TAB> <TAB> return self._read(count, timeout) <TAB> except usb.USBError as e: <TAB> <TAB> if DEBUG_COMM: <TAB> <TAB> <TAB> log.info( <TAB> <TAB> <TAB> <TAB> ""read: e.errno=%s e.strerror=%s e.message=%s repr=%s"" <TAB> <TAB> <TAB> <TAB> % (e.errno, e.strerror, e.message, repr(e)) <TAB> <TAB> <TAB> ) <TAB> <TAB> if ignore_timeouts and is_timeout(e): <TAB> <TAB> <TAB> return [] <TAB> <TAB> if ignore_non_errors and is_noerr(e): <TAB> <TAB> <TAB> return [] <TAB> <TAB> raise",true,if ignore_non_errors and is_noerr ( e ) :,if ignore_non_errors and is_noerr ( e ) :,0.75,0.0
"def PrintHeader(self):  # print the header array <TAB> if self.draw == False: <TAB> <TAB> return <TAB> for val in self.parent.header: <TAB> <TAB> self.SetPrintFont(val[""Font""]) <TAB> <TAB> header_indent = val[""Indent""] * self.pwidth <TAB> <TAB> text = val[""Text""] <TAB> <TAB> htype = val[""Type""] <TAB> <TAB> if htype == ""Date"": <TAB> <TAB> <TAB> addtext = self.GetDate() <TAB> <TAB> elif htype == ""Date & Time"": <TAB> <TAB> <TAB> addtext = self.GetDateTime() <TAB> <TAB> else: <TAB> <TAB> <TAB> addtext = """" <TAB> <TAB> self.OutTextPageWidth( <TAB> <TAB> <TAB> text + addtext, self.pheader_margin, val[""Align""], header_indent, True <TAB> <TAB> )",false,"if htype == ""Date"" :","elif htype == ""Date & Time"" :",0.05,0.0
"def get_intersect_all(self, refine=False): <TAB> result = None <TAB> for source, parts in self._per_source.items(): <TAB> <TAB> if result is None: <TAB> <TAB> <TAB> result = parts <TAB> <TAB> else: <TAB> <TAB> <TAB> result.intersection_update(parts) <TAB> if not result: <TAB> <TAB> return None <TAB> elif len(result) == 1: <TAB> <TAB> return list(result)[0].item <TAB> else: <TAB> <TAB> solids = [p.item for p in result] <TAB> <TAB> solid = solids[0].fuse(solids[1:]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> solid = solid.removeSplitter() <TAB> <TAB> return solid",true,if refine :,if refine :,0.53,0.0
"def captured_updateNode(self, context): <TAB> if not self.updating_name_from_pointer: <TAB> <TAB> font_datablock = self.get_bpy_data_from_name(self.fontname, bpy.data.fonts) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.font_pointer = font_datablock <TAB> <TAB> <TAB> updateNode(self, context)",true,if font_datablock :,if font_datablock :,0.53,0.0
"def __add__(self, other): <TAB> if isinstance(other, Vector2): <TAB> <TAB> # Vector + Vector -> Vector <TAB> <TAB> # Vector + Point -> Point <TAB> <TAB> # Point + Point -> Vector <TAB> <TAB> if self.__class__ is other.__class__: <TAB> <TAB> <TAB> _class = Vector2 <TAB> <TAB> else: <TAB> <TAB> <TAB> _class = Point2 <TAB> <TAB> return _class(self.x + other.x, self.y + other.y) <TAB> else: <TAB> <TAB> assert hasattr(other, ""__len__"") and len(other) == 2 <TAB> <TAB> return Vector2(self.x + other[0], self.y + other[1])",true,if self . __class__ is other . __class__ :,if self . __class__ is other . __class__ :,0.75,0.0
"def _flatten_settings_from_form(self, settings, form, form_values): <TAB> """"""Take a nested dict and return a flat dict of setting values."""""" <TAB> setting_values = {} <TAB> for field in form.c: <TAB> <TAB> if isinstance(field, _ContainerMixin): <TAB> <TAB> <TAB> setting_values.update( <TAB> <TAB> <TAB> <TAB> self._flatten_settings_from_form( <TAB> <TAB> <TAB> <TAB> <TAB> settings, field, form_values[field._name] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> elif field._name in settings: <TAB> <TAB> <TAB> setting_values[field._name] = form_values[field._name] <TAB> return setting_values",false,"if isinstance ( field , _ContainerMixin ) :",elif field . _name in settings :,0.02,0.0
"def add_include_dirs(self, args): <TAB> ids = [] <TAB> for a in args: <TAB> <TAB> # FIXME same hack, forcibly unpack from holder. <TAB> <TAB> if hasattr(a, ""includedirs""): <TAB> <TAB> <TAB> a = a.includedirs <TAB> <TAB> if not isinstance(a, IncludeDirs): <TAB> <TAB> <TAB> raise InvalidArguments( <TAB> <TAB> <TAB> <TAB> ""Include directory to be added is not an include directory object."" <TAB> <TAB> <TAB> ) <TAB> <TAB> ids.append(a) <TAB> self.include_dirs += ids",false,"if not isinstance ( a , IncludeDirs ) :","if hasattr ( a , ""includedirs"" ) :",0.08,0.0
"def _clip_array(array, config): <TAB> if ""threshold"" in config.keys(): <TAB> <TAB> threshold = config[""threshold""] <TAB> else: <TAB> <TAB> abs_array = np.max(np.abs(array)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return array <TAB> <TAB> threshold = np.percentile(np.abs(array), 99.99) <TAB> return np.clip(array, -threshold, threshold)",false,if abs_array < 1.0 :,if abs_array < 0.0 :,0.39,0.0
def dfs(v: str) -> Iterator[Set[str]]: <TAB> index[v] = len(stack) <TAB> stack.append(v) <TAB> boundaries.append(index[v]) <TAB> for w in edges[v]: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield from dfs(w) <TAB> <TAB> elif w not in identified: <TAB> <TAB> <TAB> while index[w] < boundaries[-1]: <TAB> <TAB> <TAB> <TAB> boundaries.pop() <TAB> if boundaries[-1] == index[v]: <TAB> <TAB> boundaries.pop() <TAB> <TAB> scc = set(stack[index[v] :]) <TAB> <TAB> del stack[index[v] :] <TAB> <TAB> identified.update(scc) <TAB> <TAB> yield scc,false,if w not in index :,if w in boundaries :,0.05,0.0
"def create_balancer( <TAB> self, name, members, protocol=""http"", port=80, algorithm=DEFAULT_ALGORITHM ): <TAB> balancer = self.ex_create_balancer_nowait(name, members, protocol, port, algorithm) <TAB> timeout = 60 * 20 <TAB> waittime = 0 <TAB> interval = 2 * 15 <TAB> if balancer.id is not None: <TAB> <TAB> return balancer <TAB> else: <TAB> <TAB> while waittime < timeout: <TAB> <TAB> <TAB> balancers = self.list_balancers() <TAB> <TAB> <TAB> for i in balancers: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return i <TAB> <TAB> <TAB> waittime += interval <TAB> <TAB> <TAB> time.sleep(interval) <TAB> raise Exception(""Failed to get id"")",false,if i . name == balancer . name and i . id is not None :,if i . id is not None :,0.27,0.0
"def handle(self, scope: Scope, receive: Receive, send: Send) -> None: <TAB> if self.methods and scope[""method""] not in self.methods: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise HTTPException(status_code=405) <TAB> <TAB> else: <TAB> <TAB> <TAB> response = PlainTextResponse(""Method Not Allowed"", status_code=405) <TAB> <TAB> await response(scope, receive, send) <TAB> else: <TAB> <TAB> await self.app(scope, receive, send)",false,"if ""app"" in scope :",if receive . status != 200 :,0.03,0.0
"def convert(data): <TAB> result = [] <TAB> for d in data: <TAB> <TAB> # noinspection PyCompatibility <TAB> <TAB> if isinstance(d, tuple) and len(d) == 2: <TAB> <TAB> <TAB> result.append((d[0], None, d[1])) <TAB> <TAB> elif isinstance(d, basestring): <TAB> <TAB> <TAB> result.append(d) <TAB> return result",true,"elif isinstance ( d , basestring ) :","elif isinstance ( d , basestring ) :",0.75,0.0
"def register_adapters(): <TAB> global adapters_registered <TAB> if adapters_registered is True: <TAB> <TAB> return <TAB> try: <TAB> <TAB> import pkg_resources <TAB> <TAB> packageDir = pkg_resources.resource_filename(""pyamf"", ""adapters"") <TAB> except: <TAB> <TAB> packageDir = os.path.dirname(__file__) <TAB> for f in glob.glob(os.path.join(packageDir, ""*.py"")): <TAB> <TAB> mod = os.path.basename(f).split(os.path.extsep, 1)[0] <TAB> <TAB> if mod == ""__init__"" or not mod.startswith(""_""): <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> register_adapter(mod[1:].replace(""_"", "".""), PackageImporter(mod)) <TAB> <TAB> except ImportError: <TAB> <TAB> <TAB> pass <TAB> adapters_registered = True",true,"if mod == ""__init__"" or not mod . startswith ( ""_"" ) :","if mod == ""__init__"" or not mod . startswith ( ""_"" ) :",1.0,0.0
"def load_modules( <TAB> to_load, load, attr, modules_dict, excluded_aliases, loading_message=None ): <TAB> if loading_message: <TAB> <TAB> print(loading_message) <TAB> for name in to_load: <TAB> <TAB> module = load(name) <TAB> <TAB> if module is None or not hasattr(module, attr): <TAB> <TAB> <TAB> continue <TAB> <TAB> cls = getattr(module, attr) <TAB> <TAB> if hasattr(cls, ""initialize"") and not cls.initialize(): <TAB> <TAB> <TAB> continue <TAB> <TAB> if hasattr(module, ""aliases""): <TAB> <TAB> <TAB> for alias in module.aliases(): <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> modules_dict[alias] = module <TAB> <TAB> else: <TAB> <TAB> <TAB> modules_dict[name] = module <TAB> if loading_message: <TAB> <TAB> print()",true,if alias not in excluded_aliases :,if alias not in excluded_aliases :,0.75,0.0
"def clean_items(event, items, variations): <TAB> for item in items: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValidationError(_(""One or more items do not belong to this event."")) <TAB> <TAB> if item.has_variations: <TAB> <TAB> <TAB> if not any(var.item == item for var in variations): <TAB> <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> <TAB> _( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""One or more items has variations but none of these are in the variations list."" <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> )",false,if event != item . event :,if event not in item :,0.04,0.0
"def __get_file_by_num(self, num, file_list, idx=0): <TAB> for element in file_list: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return element <TAB> <TAB> if element[3] and element[4]: <TAB> <TAB> <TAB> i = self.__get_file_by_num(num, element[3], idx + 1) <TAB> <TAB> <TAB> if not isinstance(i, int): <TAB> <TAB> <TAB> <TAB> return i <TAB> <TAB> <TAB> idx = i <TAB> <TAB> else: <TAB> <TAB> <TAB> idx += 1 <TAB> return idx",false,if idx == num :,if idx == 0 :,0.14,0.0
"def check(chip, xeddb, chipdb): <TAB> all_inst = [] <TAB> undoc = [] <TAB> for inst in xeddb.recs: <TAB> <TAB> if inst.isa_set in chipdb[chip]: <TAB> <TAB> <TAB> if inst.undocumented: <TAB> <TAB> <TAB> <TAB> undoc.append(inst) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> all_inst.append(inst) <TAB> return (all_inst, undoc)",true,if inst . isa_set in chipdb [ chip ] :,if inst . isa_set in chipdb [ chip ] :,0.75,0.0
"def get_all_topic_src_files(self): <TAB> """"""Retrieves the file paths of all the topics in directory"""""" <TAB> topic_full_paths = [] <TAB> topic_names = os.listdir(self.topic_dir) <TAB> for topic_name in topic_names: <TAB> <TAB> # Do not try to load hidden files. <TAB> <TAB> if not topic_name.startswith("".""): <TAB> <TAB> <TAB> topic_full_path = os.path.join(self.topic_dir, topic_name) <TAB> <TAB> <TAB> # Ignore the JSON Index as it is stored with topic files. <TAB> <TAB> <TAB> if topic_full_path != self.index_file: <TAB> <TAB> <TAB> <TAB> topic_full_paths.append(topic_full_path) <TAB> return topic_full_paths",true,"if not topic_name . startswith ( ""."" ) :","if not topic_name . startswith ( ""."" ) :",0.75,0.0
"def _get_element(dom_msi, tag_name, name=None, id_=None): <TAB> """"""Get a xml element defined on Product."""""" <TAB> product = dom_msi.getElementsByTagName(""Product"")[0] <TAB> elements = product.getElementsByTagName(tag_name) <TAB> for element in elements: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> element.getAttribute(""Name"") == name <TAB> <TAB> <TAB> <TAB> and element.getAttribute(""Id"") == id_ <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> return element <TAB> <TAB> elif id_: <TAB> <TAB> <TAB> if element.getAttribute(""Id"") == id_: <TAB> <TAB> <TAB> <TAB> return element",false,if name and id_ :,if name :,0.07,0.0
"def __init__(self, *models): <TAB> super().__init__() <TAB> self.models = ModuleList(models) <TAB> for m in models: <TAB> <TAB> if not hasattr(m, ""likelihood""): <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""IndependentModelList currently only supports models that have a likelihood (e.g. ExactGPs)"" <TAB> <TAB> <TAB> ) <TAB> self.likelihood = LikelihoodList(*[m.likelihood for m in models])",true,"if not hasattr ( m , ""likelihood"" ) :","if not hasattr ( m , ""likelihood"" ) :",0.75,0.0
"def _sniff(filename, oxlitype): <TAB> try: <TAB> <TAB> with open(filename, ""rb"") as fileobj: <TAB> <TAB> <TAB> header = fileobj.read(4) <TAB> <TAB> <TAB> if header == b""OXLI"": <TAB> <TAB> <TAB> <TAB> fileobj.read(1)  # skip the version number <TAB> <TAB> <TAB> <TAB> ftype = fileobj.read(1) <TAB> <TAB> <TAB> <TAB> if binascii.hexlify(ftype) == oxlitype: <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> return False <TAB> except OSError: <TAB> <TAB> return False",true,"if header == b""OXLI"" :","if header == b""OXLI"" :",0.75,0.0
"def convert_port_bindings(port_bindings): <TAB> result = {} <TAB> for k, v in six.iteritems(port_bindings): <TAB> <TAB> key = str(k) <TAB> <TAB> if ""/"" not in key: <TAB> <TAB> <TAB> key += ""/tcp"" <TAB> <TAB> if isinstance(v, list): <TAB> <TAB> <TAB> result[key] = [_convert_port_binding(binding) for binding in v] <TAB> <TAB> else: <TAB> <TAB> <TAB> result[key] = [_convert_port_binding(v)] <TAB> return result",true,"if isinstance ( v , list ) :","if isinstance ( v , list ) :",0.75,0.0
"def input_data(self): <TAB> gen = self.config.generator <TAB> # don't try running the generator if we specify an output file explicitly, <TAB> # otherwise generator may segfault and we end up returning the output file anyway <TAB> if gen and (not self.config[""out""] or not self.config[""in""]): <TAB> <TAB> if self._generated is None: <TAB> <TAB> <TAB> self._run_generator(gen, args=self.config.generator_args) <TAB> <TAB> if self._generated[0]: <TAB> <TAB> <TAB> return self._generated[0] <TAB> # in file is optional <TAB> return ( <TAB> <TAB> self._normalize(self.problem.problem_data[self.config[""in""]]) <TAB> <TAB> if self.config[""in""] <TAB> <TAB> else b"""" <TAB> )",false,if self . _generated is None :,if self . _generated [ 0 ] :,0.2,0.0
"def __new__(cls, *tasks, **kwargs): <TAB> # This forces `chain(X, Y, Z)` to work the same way as `X | Y | Z` <TAB> if not kwargs and tasks: <TAB> <TAB> if len(tasks) != 1 or is_list(tasks[0]): <TAB> <TAB> <TAB> tasks = tasks[0] if len(tasks) == 1 else tasks <TAB> <TAB> <TAB> return reduce(operator.or_, tasks) <TAB> return super(chain, cls).__new__(cls, *tasks, **kwargs)",true,if len ( tasks ) != 1 or is_list ( tasks [ 0 ] ) :,if len ( tasks ) != 1 or is_list ( tasks [ 0 ] ) :,1.0,0.0
"def get_file_sources(): <TAB> global _file_sources <TAB> if _file_sources is None: <TAB> <TAB> from galaxy.files import ConfiguredFileSources <TAB> <TAB> file_sources = None <TAB> <TAB> if os.path.exists(""file_sources.json""): <TAB> <TAB> <TAB> file_sources_as_dict = None <TAB> <TAB> <TAB> with open(""file_sources.json"", ""r"") as f: <TAB> <TAB> <TAB> <TAB> file_sources_as_dict = json.load(f) <TAB> <TAB> <TAB> if file_sources_as_dict is not None: <TAB> <TAB> <TAB> <TAB> file_sources = ConfiguredFileSources.from_dict(file_sources_as_dict) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ConfiguredFileSources.from_dict([]) <TAB> <TAB> _file_sources = file_sources <TAB> return _file_sources",true,if file_sources is None :,if file_sources is None :,0.75,0.0
"def InitializeColours(self): <TAB> """"""Initializes the 16 custom colours in :class:`CustomPanel`."""""" <TAB> curr = self._colourData.GetColour() <TAB> self._colourSelection = -1 <TAB> for i in range(16): <TAB> <TAB> c = self._colourData.GetCustomColour(i) <TAB> <TAB> if c.IsOk(): <TAB> <TAB> <TAB> self._customColours[i] = self._colourData.GetCustomColour(i) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._customColours[i] = wx.WHITE <TAB> <TAB> if c == curr: <TAB> <TAB> <TAB> self._colourSelection = i",true,if c . IsOk ( ) :,if c . IsOk ( ) :,0.75,0.0
"def convert_obj_into_marshallable(self, obj): <TAB> if isinstance(obj, self.marshalable_types): <TAB> <TAB> return obj <TAB> if isinstance(obj, array.array): <TAB> <TAB> if obj.typecode == ""c"": <TAB> <TAB> <TAB> return obj.tostring() <TAB> <TAB> if obj.typecode == ""u"": <TAB> <TAB> <TAB> return obj.tounicode() <TAB> <TAB> return obj.tolist() <TAB> return self.class_to_dict(obj)",false,"if obj . typecode == ""u"" :","if obj . typecode == ""c"" :",0.57,0.0
"def run(self): <TAB> self.run_command(""egg_info"") <TAB> from glob import glob <TAB> for pattern in self.match: <TAB> <TAB> pattern = self.distribution.get_name() + ""*"" + pattern <TAB> <TAB> files = glob(os.path.join(self.dist_dir, pattern)) <TAB> <TAB> files = [(os.path.getmtime(f), f) for f in files] <TAB> <TAB> files.sort() <TAB> <TAB> files.reverse() <TAB> <TAB> log.info(""%d file(s) matching %s"", len(files), pattern) <TAB> <TAB> files = files[self.keep :] <TAB> <TAB> for (t, f) in files: <TAB> <TAB> <TAB> log.info(""Deleting %s"", f) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> os.unlink(f)",false,if not self . dry_run :,if t :,0.11,0.0
"def render_token_list(self, tokens): <TAB> result = [] <TAB> vars = [] <TAB> for token in tokens: <TAB> <TAB> if token.token_type == TOKEN_TEXT: <TAB> <TAB> <TAB> result.append(token.contents.replace(""%"", ""%%"")) <TAB> <TAB> elif token.token_type == TOKEN_VAR: <TAB> <TAB> <TAB> result.append(""%%(%s)s"" % token.contents) <TAB> <TAB> <TAB> vars.append(token.contents) <TAB> return """".join(result), vars",true,elif token . token_type == TOKEN_VAR :,elif token . token_type == TOKEN_VAR :,1.0,0.0
"def _handle_raise(self, values, is_NAs, origins): <TAB> for is_NA, origin in zip(is_NAs, origins): <TAB> <TAB> if np.any(is_NA): <TAB> <TAB> <TAB> msg = ( <TAB> <TAB> <TAB> <TAB> ""Missing values detected. If you want rows with missing "" <TAB> <TAB> <TAB> <TAB> ""values to be automatically deleted in a list-wise "" <TAB> <TAB> <TAB> <TAB> ""manner (not recommended), please set dropna=True in "" <TAB> <TAB> <TAB> <TAB> ""the Bambi Model initialization."" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> raise PatsyError(msg, origin) <TAB> return values",true,if np . any ( is_NA ) :,if np . any ( is_NA ) :,0.75,0.0
"def add_node_data(node_array, ntwk): <TAB> node_ntwk = nx.Graph() <TAB> newdata = {} <TAB> for idx, data in ntwk.nodes(data=True): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> newdata[""value""] = node_array[int(idx) - 1] <TAB> <TAB> <TAB> data.update(newdata) <TAB> <TAB> <TAB> node_ntwk.add_node(int(idx), **data) <TAB> return node_ntwk",false,if not int ( idx ) == 0 :,if int ( idx ) > 0 :,0.31,0.0
"def safe_parse_date(date_hdr): <TAB> """"""Parse a Date: or Received: header into a unix timestamp."""""" <TAB> try: <TAB> <TAB> if "";"" in date_hdr: <TAB> <TAB> <TAB> date_hdr = date_hdr.split("";"")[-1].strip() <TAB> <TAB> msg_ts = long(rfc822.mktime_tz(rfc822.parsedate_tz(date_hdr))) <TAB> <TAB> if (msg_ts > (time.time() + 24 * 3600)) or (msg_ts < 1): <TAB> <TAB> <TAB> return None <TAB> <TAB> else: <TAB> <TAB> <TAB> return msg_ts <TAB> except (ValueError, TypeError, OverflowError): <TAB> <TAB> return None",true,if ( msg_ts > ( time . time ( ) + 24 * 3600 ) ) or ( msg_ts < 1 ) :,if ( msg_ts > ( time . time ( ) + 24 * 3600 ) ) or ( msg_ts < 1 ) :,1.0,0.0
"def _route_db(self, model, **hints): <TAB> chosen_db = None <TAB> for router in self.routers: <TAB> <TAB> try: <TAB> <TAB> <TAB> method = getattr(router, action) <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> # If the router doesn't have a method, skip to the next one. <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> chosen_db = method(model, **hints) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return chosen_db <TAB> try: <TAB> <TAB> return hints[""instance""]._state.db or DEFAULT_DB_ALIAS <TAB> except KeyError: <TAB> <TAB> return DEFAULT_DB_ALIAS",true,if chosen_db :,if chosen_db :,0.53,0.0
"def get_keys(struct, ignore_first_level=False): <TAB> res = [] <TAB> if isinstance(struct, dict): <TAB> <TAB> if not ignore_first_level: <TAB> <TAB> <TAB> keys = [x.split(""("")[0] for x in struct.keys()] <TAB> <TAB> <TAB> res.extend(keys) <TAB> <TAB> for key in struct: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> logging.debug(""Ignored: %s: %s"", key, struct[key]) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> res.extend(get_keys(struct[key], key in IGNORED_FIRST_LEVEL)) <TAB> elif isinstance(struct, list): <TAB> <TAB> for item in struct: <TAB> <TAB> <TAB> res.extend(get_keys(item)) <TAB> return res",false,if key in IGNORED_KEYS :,if key in IGNORED_FIRST_LEVEL :,0.39,0.0
"def launch_app(self, fs_id): <TAB> if fs_id in self.app_infos: <TAB> <TAB> row = self.get_row_by_fsid(fs_id) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> app_info = self.app_infos[fs_id] <TAB> <TAB> filepath = os.path.join(row[SAVEDIR_COL], row[SAVENAME_COL]) <TAB> <TAB> gfile = Gio.File.new_for_path(filepath) <TAB> <TAB> app_info.launch( <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> gfile, <TAB> <TAB> <TAB> ], <TAB> <TAB> <TAB> None, <TAB> <TAB> ) <TAB> <TAB> self.app_infos.pop(fs_id, None)",false,if not row :,if row is None :,0.05,0.0
"def create_skipfile(files_changed, skipfile): <TAB> # File is likely to contain some garbage values at start, <TAB> # only the corresponding json should be parsed. <TAB> json_pattern = re.compile(r""^\{.*\}"") <TAB> for line in files_changed.readlines(): <TAB> <TAB> if re.match(json_pattern, line): <TAB> <TAB> <TAB> for filename in json.loads(line): <TAB> <TAB> <TAB> <TAB> if ""/COMMIT_MSG"" in filename: <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> skipfile.write(""+*/%s\n"" % filename) <TAB> skipfile.write(""-*\n"")",true,"if re . match ( json_pattern , line ) :","if re . match ( json_pattern , line ) :",0.75,0.0
"def zscore(self, client, request, N): <TAB> check_input(request, N != 2) <TAB> key = request[1] <TAB> db = client.db <TAB> value = db.get(key) <TAB> if value is None: <TAB> <TAB> client.reply_bulk(None) <TAB> elif not isinstance(value, self.zset_type): <TAB> <TAB> client.reply_wrongtype() <TAB> else: <TAB> <TAB> score = value.score(request[2], None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> score = str(score).encode(""utf-8"") <TAB> <TAB> client.reply_bulk(score)",true,if score is not None :,if score is not None :,0.75,0.0
"def _list_cases(suite): <TAB> for test in suite: <TAB> <TAB> if isinstance(test, unittest.TestSuite): <TAB> <TAB> <TAB> _list_cases(test) <TAB> <TAB> elif isinstance(test, unittest.TestCase): <TAB> <TAB> <TAB> if support.match_test(test): <TAB> <TAB> <TAB> <TAB> print(test.id())",true,if support . match_test ( test ) :,if support . match_test ( test ) :,0.75,0.0
"def Run(self): <TAB> """"""The main run method of the client."""""" <TAB> for thread in self._threads.values(): <TAB> <TAB> thread.start() <TAB> logging.info(START_STRING) <TAB> while True: <TAB> <TAB> dead_threads = [tn for (tn, t) in self._threads.items() if not t.isAlive()] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise FatalError( <TAB> <TAB> <TAB> <TAB> ""These threads are dead: %r. Shutting down..."" % dead_threads <TAB> <TAB> <TAB> ) <TAB> <TAB> time.sleep(10)",true,if dead_threads :,if dead_threads :,0.53,0.0
"def _slice_queryset(queryset, order_by, per_page, start): <TAB> page_len = int(per_page) + 1 <TAB> if start: <TAB> <TAB> if order_by.startswith(""-""): <TAB> <TAB> <TAB> filter_name = ""%s__lte"" % order_by[1:] <TAB> <TAB> else: <TAB> <TAB> <TAB> filter_name = ""%s__gte"" % order_by <TAB> <TAB> return queryset.filter(**{filter_name: start})[:page_len] <TAB> return queryset[:page_len]",true,"if order_by . startswith ( ""-"" ) :","if order_by . startswith ( ""-"" ) :",0.75,0.0
"def compute_timer_precision(timer): <TAB> precision = None <TAB> points = 0 <TAB> timeout = timeout_timer() + 1.0 <TAB> previous = timer() <TAB> while timeout_timer() < timeout or points < 5: <TAB> <TAB> for _ in XRANGE(10): <TAB> <TAB> <TAB> t1 = timer() <TAB> <TAB> <TAB> t2 = timer() <TAB> <TAB> <TAB> dt = t2 - t1 <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> dt = t2 - previous <TAB> <TAB> <TAB> if dt <= 0.0: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> if precision is not None: <TAB> <TAB> <TAB> precision = min(precision, dt) <TAB> <TAB> else: <TAB> <TAB> <TAB> precision = dt <TAB> <TAB> points += 1 <TAB> <TAB> previous = timer() <TAB> return precision",false,if 0 < dt :,if dt <= 0.0 :,0.04,0.0
"def findWorkingDir(): <TAB> frozen = getattr(sys, ""frozen"", """") <TAB> if not frozen: <TAB> <TAB> path = os.path.dirname(__file__) <TAB> elif frozen in (""dll"", ""console_exe"", ""windows_exe"", ""macosx_app""): <TAB> <TAB> path = os.path.dirname( <TAB> <TAB> <TAB> os.path.dirname(os.path.dirname(os.path.dirname(__file__))) <TAB> <TAB> ) <TAB> elif frozen:  # needed for PyInstaller <TAB> <TAB> if getattr(sys, ""_MEIPASS"", """") is not None: <TAB> <TAB> <TAB> path = getattr(sys, ""_MEIPASS"", """")  # --onefile <TAB> <TAB> else: <TAB> <TAB> <TAB> path = os.path.dirname(sys.executable)  # --onedir <TAB> else: <TAB> <TAB> path = """" <TAB> return path",true,"if getattr ( sys , ""_MEIPASS"" , """" ) is not None :","if getattr ( sys , ""_MEIPASS"" , """" ) is not None :",0.75,0.0
"def CreateDataType(vmodlName, wsdlName, parent, version, props): <TAB> with _lazyLock: <TAB> <TAB> dic = [vmodlName, wsdlName, parent, version, props] <TAB> <TAB> names = vmodlName.split(""."") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> vmodlName = ""."".join(name[0].lower() + name[1:] for name in names) <TAB> <TAB> _AddToDependencyMap(names) <TAB> <TAB> typeNs = GetWsdlNamespace(version) <TAB> <TAB> _dataDefMap[vmodlName] = dic <TAB> <TAB> _wsdlDefMap[(typeNs, wsdlName)] = dic <TAB> <TAB> _wsdlTypeMapNSs.add(typeNs)",false,if _allowCapitalizedNames :,if len ( names ) > 1 :,0.04,0.0
"def ParseResponses( <TAB> self, <TAB> knowledge_base: rdf_client.KnowledgeBase, <TAB> responses: Iterable[rdfvalue.RDFValue], ) -> Iterator[rdf_client.User]: <TAB> for response in responses: <TAB> <TAB> if not isinstance(response, rdf_client_fs.StatEntry): <TAB> <TAB> <TAB> raise TypeError(f""Unexpected response type: `{type(response)}`"") <TAB> <TAB> # TODO: `st_mode` has to be an `int`, not `StatMode`. <TAB> <TAB> if stat.S_ISDIR(int(response.st_mode)): <TAB> <TAB> <TAB> homedir = response.pathspec.path <TAB> <TAB> <TAB> username = os.path.basename(homedir) <TAB> <TAB> <TAB> if username not in self._ignore_users: <TAB> <TAB> <TAB> <TAB> yield rdf_client.User(username=username, homedir=homedir)",false,if username not in self . _ignore_users :,if stat . S_ISDIR ( int ( response . st_mode ) ) :,0.02,0.0
"def process_question(qtxt): <TAB> question = """" <TAB> skip = False <TAB> for letter in qtxt: <TAB> <TAB> if letter == ""<"": <TAB> <TAB> <TAB> skip = True <TAB> <TAB> if letter == "">"": <TAB> <TAB> <TAB> skip = False <TAB> <TAB> if skip: <TAB> <TAB> <TAB> continue <TAB> <TAB> if letter.isalnum() or letter == "" "": <TAB> <TAB> <TAB> if letter == "" "": <TAB> <TAB> <TAB> <TAB> letter = ""_"" <TAB> <TAB> <TAB> question += letter.lower() <TAB> return question",true,"if letter . isalnum ( ) or letter == "" "" :","if letter . isalnum ( ) or letter == "" "" :",1.0,0.0
"def process_all(self, lines, times=1): <TAB> gap = False <TAB> for _ in range(times): <TAB> <TAB> for line in lines: <TAB> <TAB> <TAB> if gap: <TAB> <TAB> <TAB> <TAB> self.write("""") <TAB> <TAB> <TAB> self.process(line) <TAB> <TAB> <TAB> if not is_command(line): <TAB> <TAB> <TAB> <TAB> gap = True <TAB> return 0",true,if not is_command ( line ) :,if not is_command ( line ) :,0.75,0.0
"def _get(self, domain): <TAB> with self.lock: <TAB> <TAB> try: <TAB> <TAB> <TAB> record = self.cache[domain] <TAB> <TAB> <TAB> time_now = time.time() <TAB> <TAB> <TAB> if time_now - record[""update""] > self.ttl: <TAB> <TAB> <TAB> <TAB> record = None <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> record = None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> record = {""r"": ""unknown"", ""dns"": {}, ""g"": 1, ""query_count"": 0} <TAB> <TAB> # self.cache[domain] = record <TAB> <TAB> return record",true,if not record :,if not record :,0.75,0.0
"def gen_constant_folding(cw): <TAB> types = [""Int32"", ""Double"", ""BigInteger"", ""Complex""] <TAB> for cur_type in types: <TAB> <TAB> cw.enter_block(""if (constLeft.Value.GetType() == typeof(%s))"" % (cur_type,)) <TAB> <TAB> cw.enter_block(""switch (_op)"") <TAB> <TAB> for op in ops: <TAB> <TAB> <TAB> gen = getattr(op, ""genConstantFolding"", None) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> gen(cw, cur_type) <TAB> <TAB> cw.exit_block() <TAB> <TAB> cw.exit_block()",true,if gen is not None :,if gen is not None :,0.75,0.0
"def unreferenced_dummy(self): <TAB> for g, base in zip(self.evgroups, self.evbases): <TAB> <TAB> for ind, j in enumerate(g): <TAB> <TAB> <TAB> if not self.indexobj[base + ind]: <TAB> <TAB> <TAB> <TAB> debug_print( <TAB> <TAB> <TAB> <TAB> <TAB> ""replacing unreferenced %d %s with dummy"" % ((base + ind), g[ind]) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> g[ind] = ""dummy"" <TAB> <TAB> <TAB> <TAB> self.evnum[base + ind] = ""dummy""",true,if not self . indexobj [ base + ind ] :,if not self . indexobj [ base + ind ] :,0.75,0.0
"def handle_signature(self, sig: str, signode: desc_signature) -> Tuple[str, str]: <TAB> for cls in self.__class__.__mro__: <TAB> <TAB> if cls.__name__ != ""DirectiveAdapter"": <TAB> <TAB> <TAB> warnings.warn( <TAB> <TAB> <TAB> <TAB> ""PyDecoratorMixin is deprecated. "" <TAB> <TAB> <TAB> <TAB> ""Please check the implementation of %s"" % cls, <TAB> <TAB> <TAB> <TAB> RemovedInSphinx50Warning, <TAB> <TAB> <TAB> <TAB> stacklevel=2, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> break <TAB> else: <TAB> <TAB> warnings.warn( <TAB> <TAB> <TAB> ""PyDecoratorMixin is deprecated"", RemovedInSphinx50Warning, stacklevel=2 <TAB> <TAB> ) <TAB> ret = super().handle_signature(sig, signode)  # type: ignore <TAB> signode.insert(0, addnodes.desc_addname(""@"", ""@"")) <TAB> return ret",true,"if cls . __name__ != ""DirectiveAdapter"" :","if cls . __name__ != ""DirectiveAdapter"" :",0.75,0.0
"def _iter_lines(path=path, response=response, max_next=options.http_max_next): <TAB> path.responses = [] <TAB> n = 0 <TAB> while response: <TAB> <TAB> path.responses.append(response) <TAB> <TAB> yield from response.iter_lines(decode_unicode=True) <TAB> <TAB> src = response.links.get(""next"", {}).get(""url"", None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> n += 1 <TAB> <TAB> if n > max_next: <TAB> <TAB> <TAB> vd.warning(f""stopping at max {max_next} pages"") <TAB> <TAB> <TAB> break <TAB> <TAB> vd.status(f""fetching next page from {src}"") <TAB> <TAB> response = requests.get(src, stream=True)",true,if not src :,if not src :,0.75,0.0
"def ordered_indices(self): <TAB> with data_utils.numpy_seed(self.seed, self.epoch): <TAB> <TAB> # Used to store the order of indices of each dataset to use <TAB> <TAB> indices = [ <TAB> <TAB> <TAB> np.random.permutation(len(dataset)) for dataset in self.datasets.values() <TAB> <TAB> ] <TAB> <TAB> # Keep track of which samples we've  used for each dataset <TAB> <TAB> counters = [0 for _ in self.datasets] <TAB> <TAB> sampled_indices = [ <TAB> <TAB> <TAB> self._sample(indices, counters) for _ in range(self.total_num_instances) <TAB> <TAB> ] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> sampled_indices.sort(key=lambda i: self.num_tokens(i)) <TAB> <TAB> return np.array(sampled_indices, dtype=np.int64)",true,if self . sort_indices :,if self . sort_indices :,0.75,0.0
"def _build_columns(self): <TAB> self.columns = [Column() for col in self.keys] <TAB> for row in self: <TAB> <TAB> for (col_idx, col_val) in enumerate(row): <TAB> <TAB> <TAB> col = self.columns[col_idx] <TAB> <TAB> <TAB> col.append(col_val) <TAB> <TAB> <TAB> if (col_val is not None) and (not is_quantity(col_val)): <TAB> <TAB> <TAB> <TAB> col.is_quantity = False <TAB> for (idx, key_name) in enumerate(self.keys): <TAB> <TAB> self.columns[idx].name = key_name <TAB> self.x = Column() <TAB> self.ys = []",true,if ( col_val is not None ) and ( not is_quantity ( col_val ) ) :,if ( col_val is not None ) and ( not is_quantity ( col_val ) ) :,1.0,0.0
"def tearDown(self): <TAB> subprocess_list = self.subprocess_list <TAB> processes = subprocess_list.processes <TAB> self.schedule.reset() <TAB> del self.schedule <TAB> for proc in processes: <TAB> <TAB> if proc.is_alive(): <TAB> <TAB> <TAB> terminate_process(proc.pid, kill_children=True, slow_stop=True) <TAB> subprocess_list.cleanup() <TAB> processes = subprocess_list.processes <TAB> if processes: <TAB> <TAB> for proc in processes: <TAB> <TAB> <TAB> if proc.is_alive(): <TAB> <TAB> <TAB> <TAB> terminate_process(proc.pid, kill_children=True, slow_stop=False) <TAB> <TAB> subprocess_list.cleanup() <TAB> processes = subprocess_list.processes <TAB> if processes: <TAB> <TAB> log.warning(""Processes left running: %s"", processes)",true,if proc . is_alive ( ) :,if proc . is_alive ( ) :,0.75,0.0
"def colorNetwork(cls, network, nodesInNetwork, nodeByID=None): <TAB> for node in nodesInNetwork: <TAB> <TAB> node.use_custom_color = True <TAB> <TAB> neededCopies = sum(socket.execution.neededCopies for socket in node.outputs) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> color = (0.7, 0.9, 0.7) <TAB> <TAB> else: <TAB> <TAB> <TAB> color = (1.0, 0.3, 0.3) <TAB> <TAB> node.color = color",false,if neededCopies == 0 :,if neededCopies > network . maxCopies :,0.05,0.0
"def _init_warmup_scheduler(self, optimizer, states): <TAB> updates_so_far = states.get(""number_training_updates"", 0) <TAB> if self.warmup_updates > 0 and ( <TAB> <TAB> updates_so_far <= self.warmup_updates or self.hard_reset <TAB> ): <TAB> <TAB> self.warmup_scheduler = optim.lr_scheduler.LambdaLR(optimizer, self._warmup_lr) <TAB> <TAB> if states.get(""warmup_scheduler""): <TAB> <TAB> <TAB> self.warmup_scheduler.load_state_dict(states[""warmup_scheduler""]) <TAB> else: <TAB> <TAB> self.warmup_scheduler = None",true,"if states . get ( ""warmup_scheduler"" ) :","if states . get ( ""warmup_scheduler"" ) :",0.75,0.0
"def inner(self, *iargs, **ikwargs): <TAB> try: <TAB> <TAB> return getattr(super(VEXResilienceMixin, self), func)(*iargs, **ikwargs) <TAB> except excs as e: <TAB> <TAB> for exc, handler in zip(excs, handlers): <TAB> <TAB> <TAB> if isinstance(e, exc): <TAB> <TAB> <TAB> <TAB> v = getattr(self, handler)(*iargs, **ikwargs) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> <TAB> return v <TAB> <TAB> assert False, ""this should be unreachable if Python is working correctly""",false,if v is raiseme :,if v is None :,0.39,0.0
"def unwrap_envelope(self, data, many): <TAB> if many: <TAB> <TAB> if data[""items""]: <TAB> <TAB> <TAB> if isinstance(data, InstrumentedList) or isinstance(data, list): <TAB> <TAB> <TAB> <TAB> self.context[""total""] = len(data) <TAB> <TAB> <TAB> <TAB> return data <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.context[""total""] = data[""total""] <TAB> <TAB> else: <TAB> <TAB> <TAB> self.context[""total""] = 0 <TAB> <TAB> <TAB> data = {""items"": []} <TAB> <TAB> return data[""items""] <TAB> return data",true,"if isinstance ( data , InstrumentedList ) or isinstance ( data , list ) :","if isinstance ( data , InstrumentedList ) or isinstance ( data , list ) :",1.0,0.0
"def __subclasscheck__(self, cls): <TAB> if self.__origin__ is not None: <TAB> <TAB> if sys._getframe(1).f_globals[""__name__""] not in [""abc"", ""functools""]: <TAB> <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> <TAB> ""Parameterized generics cannot be used with class "" ""or instance checks"" <TAB> <TAB> <TAB> ) <TAB> <TAB> return False <TAB> if self is Generic: <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> ""Class %r cannot be used with class "" ""or instance checks"" % self <TAB> <TAB> ) <TAB> return super().__subclasscheck__(cls)",true,"if sys . _getframe ( 1 ) . f_globals [ ""__name__"" ] not in [ ""abc"" , ""functools"" ] :","if sys . _getframe ( 1 ) . f_globals [ ""__name__"" ] not in [ ""abc"" , ""functools"" ] :",0.75,0.0
"def __init__(self, pyversions, coverage_service): <TAB> build_matrix = """" <TAB> for version in pyversions: <TAB> <TAB> build_matrix += ""\n <TAB>{},"".format( <TAB> <TAB> <TAB> version <TAB> <TAB> <TAB> if version.startswith(""pypy"") <TAB> <TAB> <TAB> else ""py{}"".format("""".join(version.split("".""))) <TAB> <TAB> ) <TAB> coverage_package = """" <TAB> if coverage_service: <TAB> <TAB> coverage_package += ""\n <TAB>{}"".format(coverage_service.package) <TAB> coverage_package += ""\n"" <TAB> super(Tox, self).__init__( <TAB> <TAB> ""tox.ini"", <TAB> <TAB> TEMPLATE.format(build_matrix=build_matrix, coverage_package=coverage_package), <TAB> )",true,"if version . startswith ( ""pypy"" )","if version . startswith ( ""pypy"" )",0.75,0.0
"def _get_app(self, body=None): <TAB> app = self._app <TAB> if app is None: <TAB> <TAB> try: <TAB> <TAB> <TAB> tasks = self.tasks.tasks  # is a group <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> tasks = self.tasks <TAB> <TAB> if len(tasks): <TAB> <TAB> <TAB> app = tasks[0]._app <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> app = body._app <TAB> return app if app is not None else current_app",false,if app is None and body is not None :,if body is not None :,0.43,0.0
"def logic(): <TAB> for v in [True, False, None, 0, True, None, None, 1]: <TAB> <TAB> yield clk.posedge <TAB> <TAB> xd.next = v <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yd.next = zd.next = None <TAB> <TAB> elif v: <TAB> <TAB> <TAB> yd.next = zd.next = 11 <TAB> <TAB> else: <TAB> <TAB> <TAB> yd.next = zd.next = 0",false,if v is None :,if v :,0.07,0.0
"def run(self): <TAB> eid = self.start_episode() <TAB> obs = self.env.reset() <TAB> while True: <TAB> <TAB> if random.random() < self.off_pol_frac: <TAB> <TAB> <TAB> action = self.env.action_space.sample() <TAB> <TAB> <TAB> self.log_action(eid, obs, action) <TAB> <TAB> else: <TAB> <TAB> <TAB> action = self.get_action(eid, obs) <TAB> <TAB> obs, reward, done, info = self.env.step(action) <TAB> <TAB> self.log_returns(eid, reward, info=info) <TAB> <TAB> if done: <TAB> <TAB> <TAB> self.end_episode(eid, obs) <TAB> <TAB> <TAB> obs = self.env.reset() <TAB> <TAB> <TAB> eid = self.start_episode()",true,if random . random ( ) < self . off_pol_frac :,if random . random ( ) < self . off_pol_frac :,1.0,0.0
"def tearDown(self): <TAB> os.chdir(self.orig_working_dir) <TAB> sys.argv = self.orig_argv <TAB> sys.stdout = self.orig_stdout <TAB> sys.stderr = self.orig_stderr <TAB> for dirname in [""lv_LV"", ""ja_JP""]: <TAB> <TAB> locale_dir = os.path.join(self.datadir, ""project"", ""i18n"", dirname) <TAB> <TAB> if os.path.isdir(locale_dir): <TAB> <TAB> <TAB> shutil.rmtree(locale_dir)",true,if os . path . isdir ( locale_dir ) :,if os . path . isdir ( locale_dir ) :,0.75,0.0
"def sentry_set_scope(process_context, entity, project, email=None, url=None): <TAB> # Using GLOBAL_HUB means these tags will persist between threads. <TAB> # Normally there is one hub per thread. <TAB> with sentry_sdk.hub.GLOBAL_HUB.configure_scope() as scope: <TAB> <TAB> scope.set_tag(""process_context"", process_context) <TAB> <TAB> scope.set_tag(""entity"", entity) <TAB> <TAB> scope.set_tag(""project"", project) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> scope.user = {""email"": email} <TAB> <TAB> if url: <TAB> <TAB> <TAB> scope.set_tag(""url"", url)",true,if email :,if email :,0.53,0.0
"def getDataMax(self): <TAB> result = -Double.MAX_VALUE <TAB> nCurves = self.chart.getNCurves() <TAB> for i in range(nCurves): <TAB> <TAB> c = self.getSystemCurve(i) <TAB> <TAB> if not c.isVisible(): <TAB> <TAB> <TAB> continue <TAB> <TAB> if c.getYAxis() == Y_AXIS: <TAB> <TAB> <TAB> nPoints = c.getNPoints() <TAB> <TAB> <TAB> for j in range(nPoints): <TAB> <TAB> <TAB> <TAB> result = self.maxIgnoreNaNAndMaxValue(result, c.getPoint(j).getY()) <TAB> if result == -Double.MAX_VALUE: <TAB> <TAB> return Double.NaN <TAB> return result",false,if not c . isVisible ( ) :,if c . getYAxis ( ) == Y_AXIS :,0.04,0.0
"def handle_starttag(self, tag, attrs): <TAB> if tag == ""link"" and (""rel"", ""icon"") in attrs or (""rel"", ""shortcut icon"") in attrs: <TAB> <TAB> href = None <TAB> <TAB> icon_type = None <TAB> <TAB> for attr, value in attrs: <TAB> <TAB> <TAB> if attr == ""href"": <TAB> <TAB> <TAB> <TAB> href = value <TAB> <TAB> <TAB> elif attr == ""type"": <TAB> <TAB> <TAB> <TAB> icon_type = value <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> mimetype = extension_to_mimetype(href.rpartition(""."")[2]) <TAB> <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> icon_type = mimetype <TAB> <TAB> <TAB> if icon_type: <TAB> <TAB> <TAB> <TAB> self.icons.append((href, icon_type))",true,if href :,if href :,0.53,0.0
"def get_version(version_file=STATIC_VERSION_FILE): <TAB> version_info = get_static_version_info(version_file) <TAB> version = version_info[""version""] <TAB> if version == ""__use_git__"": <TAB> <TAB> version = get_version_from_git() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> version = get_version_from_git_archive(version_info) <TAB> <TAB> if not version: <TAB> <TAB> <TAB> version = Version(""unknown"", None, None) <TAB> <TAB> return pep440_format(version) <TAB> else: <TAB> <TAB> return version",true,if not version :,if not version :,0.75,0.0
"def _Sleep(self, seconds): <TAB> if threading.current_thread() is not self._worker_thread: <TAB> <TAB> return self._original_sleep(seconds) <TAB> self._time += seconds <TAB> self._budget -= seconds <TAB> while self._budget < 0: <TAB> <TAB> self._worker_thread_turn.clear() <TAB> <TAB> self._owner_thread_turn.set() <TAB> <TAB> self._worker_thread_turn.wait() <TAB> <TAB> if self._worker_thread_done: <TAB> <TAB> <TAB> raise FakeTimeline._WorkerThreadExit()",true,if self . _worker_thread_done :,if self . _worker_thread_done :,0.75,0.0
"def validate_attributes(self): <TAB> if not (self.has_variants or self.variant_of): <TAB> <TAB> return <TAB> if not self.variant_based_on: <TAB> <TAB> self.variant_based_on = ""Item Attribute"" <TAB> if self.variant_based_on == ""Item Attribute"": <TAB> <TAB> attributes = [] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> frappe.throw(_(""Attribute table is mandatory"")) <TAB> <TAB> for d in self.attributes: <TAB> <TAB> <TAB> if d.attribute in attributes: <TAB> <TAB> <TAB> <TAB> frappe.throw( <TAB> <TAB> <TAB> <TAB> <TAB> _( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""Attribute {0} selected multiple times in Attributes Table"" <TAB> <TAB> <TAB> <TAB> <TAB> ).format(d.attribute) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> attributes.append(d.attribute)",true,if not self . attributes :,if not self . attributes :,0.75,0.0
"def check_digest_auth(user, passwd): <TAB> """"""Check user authentication using HTTP Digest auth"""""" <TAB> if request.headers.get(""Authorization""): <TAB> <TAB> credentails = parse_authorization_header(request.headers.get(""Authorization"")) <TAB> <TAB> if not credentails: <TAB> <TAB> <TAB> return <TAB> <TAB> response_hash = response( <TAB> <TAB> <TAB> credentails, <TAB> <TAB> <TAB> passwd, <TAB> <TAB> <TAB> dict( <TAB> <TAB> <TAB> <TAB> uri=request.script_root + request.path, <TAB> <TAB> <TAB> <TAB> body=request.data, <TAB> <TAB> <TAB> <TAB> method=request.method, <TAB> <TAB> <TAB> ), <TAB> <TAB> ) <TAB> <TAB> if credentails.get(""response"") == response_hash: <TAB> <TAB> <TAB> return True <TAB> return False",true,"if credentails . get ( ""response"" ) == response_hash :","if credentails . get ( ""response"" ) == response_hash :",0.75,0.0
"def _get_index_type(return_index_type, ctx): <TAB> if return_index_type is None:  # pragma: no cover <TAB> <TAB> if ctx.running_mode == RunningMode.local: <TAB> <TAB> <TAB> return_index_type = ""object"" <TAB> <TAB> elif ctx.running_mode == RunningMode.local_cluster: <TAB> <TAB> <TAB> return_index_type = ""filename"" <TAB> <TAB> else: <TAB> <TAB> <TAB> return_index_type = ""bytes"" <TAB> return return_index_type",true,elif ctx . running_mode == RunningMode . local_cluster :,elif ctx . running_mode == RunningMode . local_cluster :,0.75,0.0
"def iter_event_handlers( <TAB> self, <TAB> resource: resources_.Resource, <TAB> event: bodies.RawEvent, ) -> Iterator[handlers.ResourceWatchingHandler]: <TAB> warnings.warn( <TAB> <TAB> ""SimpleRegistry.iter_event_handlers() is deprecated; use "" <TAB> <TAB> ""ResourceWatchingRegistry.iter_handlers()."", <TAB> <TAB> DeprecationWarning, <TAB> ) <TAB> cause = _create_watching_cause(resource, event) <TAB> for handler in self._handlers: <TAB> <TAB> if not isinstance(handler, handlers.ResourceWatchingHandler): <TAB> <TAB> <TAB> pass <TAB> <TAB> elif registries.match(handler=handler, cause=cause, ignore_fields=True): <TAB> <TAB> <TAB> yield handler",true,"elif registries . match ( handler = handler , cause = cause , ignore_fields = True ) :","elif registries . match ( handler = handler , cause = cause , ignore_fields = True ) :",1.0,0.0
"def subprocess_post_check( <TAB> completed_process: subprocess.CompletedProcess, raise_error: bool = True ) -> None: <TAB> if completed_process.returncode: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(completed_process.stdout, file=sys.stdout, end="""") <TAB> <TAB> if completed_process.stderr is not None: <TAB> <TAB> <TAB> print(completed_process.stderr, file=sys.stderr, end="""") <TAB> <TAB> if raise_error: <TAB> <TAB> <TAB> raise PipxError( <TAB> <TAB> <TAB> <TAB> f""{' '.join([str(x) for x in completed_process.args])!r} failed"" <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> logger.info(f""{' '.join(completed_process.args)!r} failed"")",true,if completed_process . stdout is not None :,if completed_process . stdout is not None :,0.75,0.0
"def __pow__(self, power): <TAB> if power == 1: <TAB> <TAB> return self <TAB> if power == -1: <TAB> <TAB> # HACK: break cycle <TAB> <TAB> from cirq.devices import line_qubit <TAB> <TAB> decomposed = protocols.decompose_once_with_qubits( <TAB> <TAB> <TAB> self, qubits=line_qubit.LineQid.for_gate(self), default=None <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return NotImplemented <TAB> <TAB> inverse_decomposed = protocols.inverse(decomposed, None) <TAB> <TAB> if inverse_decomposed is None: <TAB> <TAB> <TAB> return NotImplemented <TAB> <TAB> return _InverseCompositeGate(self) <TAB> return NotImplemented",true,if decomposed is None :,if decomposed is None :,0.75,0.0
"def tearDown(self): <TAB> """"""Close the application after tests"""""" <TAB> # set it back to it's old position so not to annoy users :-) <TAB> self.old_pos = self.dlg.rectangle <TAB> # close the application <TAB> self.dlg.menu_select(""File->Exit"") <TAB> try: <TAB> <TAB> if self.app.UntitledNotepad[""Do&n't Save""].exists(): <TAB> <TAB> <TAB> self.app.UntitledNotepad[""Do&n't Save""].click() <TAB> <TAB> <TAB> self.app.UntitledNotepad.wait_not(""visible"") <TAB> except Exception: <TAB> <TAB> pass <TAB> finally: <TAB> <TAB> self.app.kill()",true,"if self . app . UntitledNotepad [ ""Do&n't Save"" ] . exists ( ) :","if self . app . UntitledNotepad [ ""Do&n't Save"" ] . exists ( ) :",0.75,0.0
"def terminate_subprocess(proc, timeout=0.1, log=None): <TAB> if proc.poll() is None: <TAB> <TAB> if log: <TAB> <TAB> <TAB> log.info(""Sending SIGTERM to %r"", proc) <TAB> <TAB> proc.terminate() <TAB> <TAB> timeout_time = time.time() + timeout <TAB> <TAB> while proc.poll() is None and time.time() < timeout_time: <TAB> <TAB> <TAB> time.sleep(0.02) <TAB> <TAB> if proc.poll() is None: <TAB> <TAB> <TAB> if log: <TAB> <TAB> <TAB> <TAB> log.info(""Sending SIGKILL to %r"", proc) <TAB> <TAB> <TAB> proc.kill() <TAB> return proc.returncode",true,if proc . poll ( ) is None :,if proc . poll ( ) is None :,0.75,0.0
"def validate(self, detection, expectation): <TAB> config = SigmaConfiguration() <TAB> self.basic_rule[""detection""] = detection <TAB> with patch(""yaml.safe_load_all"", return_value=[self.basic_rule]): <TAB> <TAB> parser = SigmaCollectionParser(""any sigma io"", config, None) <TAB> <TAB> backend = SQLiteBackend(config, self.table) <TAB> <TAB> assert len(parser.parsers) == 1 <TAB> <TAB> for p in parser.parsers: <TAB> <TAB> <TAB> if isinstance(expectation, str): <TAB> <TAB> <TAB> <TAB> self.assertEqual(expectation, backend.generate(p)) <TAB> <TAB> <TAB> elif isinstance(expectation, Exception): <TAB> <TAB> <TAB> <TAB> self.assertRaises(type(expectation), backend.generate, p)",false,"if isinstance ( expectation , str ) :","elif isinstance ( expectation , Exception ) :",0.2,0.0
"def makelist(d): <TAB> """"""Convert d into a list if all the keys of d are integers."""""" <TAB> if isinstance(d, dict): <TAB> <TAB> if all(isint(k) for k in d): <TAB> <TAB> <TAB> return [makelist(d[k]) for k in sorted(d, key=int)] <TAB> <TAB> else: <TAB> <TAB> <TAB> return web.storage((k, makelist(v)) for k, v in d.items()) <TAB> else: <TAB> <TAB> return d",false,if all ( isint ( k ) for k in d ) :,if all ( isinstance ( k ) for k in d ) :,0.88,0.0
"def __share_local_dir(self, lpath, rpath, fast): <TAB> result = const.ENoError <TAB> for walk in self.__walk_normal_file(lpath): <TAB> <TAB> (dirpath, dirnames, filenames) = walk <TAB> <TAB> for filename in filenames: <TAB> <TAB> <TAB> rpart = os.path.relpath(dirpath, lpath) <TAB> <TAB> <TAB> if rpart == ""."": <TAB> <TAB> <TAB> <TAB> rpart = """" <TAB> <TAB> <TAB> subr = self.__share_local_file( <TAB> <TAB> <TAB> <TAB> joinpath(dirpath, filename), <TAB> <TAB> <TAB> <TAB> posixpath.join(rpath, rpart, filename), <TAB> <TAB> <TAB> <TAB> fast, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if subr != const.ENoError: <TAB> <TAB> <TAB> <TAB> result = subr <TAB> return result",true,if subr != const . ENoError :,if subr != const . ENoError :,0.75,0.0
"def _targets(self, sigmaparser): <TAB> # build list of matching target mappings <TAB> targets = set() <TAB> for condfield in self.conditions: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> rulefieldvalues = sigmaparser.values[condfield] <TAB> <TAB> <TAB> for condvalue in self.conditions[condfield]: <TAB> <TAB> <TAB> <TAB> if condvalue in rulefieldvalues: <TAB> <TAB> <TAB> <TAB> <TAB> targets.update(self.conditions[condfield][condvalue]) <TAB> return targets",true,if condfield in sigmaparser . values :,if condfield in sigmaparser . values :,0.75,0.0
"def _wrapped_view(request, *args, **kwargs): <TAB> # based on authority/decorators.py <TAB> user = request.user <TAB> if user.is_authenticated(): <TAB> <TAB> obj = _resolve_lookup(obj_lookup, kwargs) <TAB> <TAB> perm_obj = _resolve_lookup(perm_obj_lookup, kwargs) <TAB> <TAB> granted = access.has_perm_or_owns(user, perm, obj, perm_obj, owner_attr) <TAB> <TAB> if granted or user.has_perm(perm): <TAB> <TAB> <TAB> return view_func(request, *args, **kwargs) <TAB> # In all other cases, permission denied <TAB> return HttpResponseForbidden()",true,if granted or user . has_perm ( perm ) :,if granted or user . has_perm ( perm ) :,0.75,0.0
"def assert_parts_cleaned(self, earlier_parts, current_parts, expected_parts, hint): <TAB> cleaned_parts = [] <TAB> for earlier in earlier_parts: <TAB> <TAB> earlier_part = earlier[""part""] <TAB> <TAB> earlier_step = earlier[""step""] <TAB> <TAB> found = False <TAB> <TAB> for current in current_parts: <TAB> <TAB> <TAB> if earlier_part == current[""part""] and earlier_step == current[""step""]: <TAB> <TAB> <TAB> <TAB> found = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if not found: <TAB> <TAB> <TAB> cleaned_parts.append(dict(part=earlier_part, step=earlier_step)) <TAB> self.assertThat(cleaned_parts, HasLength(len(expected_parts)), hint) <TAB> for expected in expected_parts: <TAB> <TAB> self.assertThat(cleaned_parts, Contains(expected), hint)",true,"if earlier_part == current [ ""part"" ] and earlier_step == current [ ""step"" ] :","if earlier_part == current [ ""part"" ] and earlier_step == current [ ""step"" ] :",1.0,0.0
"def show_image(self, wnd_name, img): <TAB> if wnd_name in self.named_windows: <TAB> <TAB> if self.named_windows[wnd_name] == 0: <TAB> <TAB> <TAB> self.named_windows[wnd_name] = 1 <TAB> <TAB> <TAB> self.on_create_window(wnd_name) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.capture_mouse(wnd_name) <TAB> <TAB> self.on_show_image(wnd_name, img) <TAB> else: <TAB> <TAB> print(""show_image: named_window "", wnd_name, "" not found."")",false,if wnd_name in self . capture_mouse_windows :,if self . named_windows [ wnd_name ] == 1 :,0.04,0.0
"def readlines(self, hint=None): <TAB> # Again, allow hint but ignore <TAB> body = self._get_body() <TAB> rest = body[self.position :] <TAB> self.position = len(body) <TAB> result = [] <TAB> while 1: <TAB> <TAB> next = rest.find(""\r\n"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result.append(rest) <TAB> <TAB> <TAB> break <TAB> <TAB> result.append(rest[: next + 2]) <TAB> <TAB> rest = rest[next + 2 :] <TAB> return result",true,if next == - 1 :,if next == - 1 :,0.75,0.0
"def __lt__(self, other): <TAB> olen = len(other) <TAB> for i in range(olen): <TAB> <TAB> try: <TAB> <TAB> <TAB> c = self[i] < other[i] <TAB> <TAB> except IndexError: <TAB> <TAB> <TAB> # self must be shorter <TAB> <TAB> <TAB> return True <TAB> <TAB> if c: <TAB> <TAB> <TAB> return c <TAB> <TAB> elif other[i] < self[i]: <TAB> <TAB> <TAB> return False <TAB> return len(self) < olen",true,elif other [ i ] < self [ i ] :,elif other [ i ] < self [ i ] :,0.75,0.0
"def social_user(backend, uid, user=None, *args, **kwargs): <TAB> provider = backend.name <TAB> social = backend.strategy.storage.user.get_social_auth(provider, uid) <TAB> if social: <TAB> <TAB> if user and social.user != user: <TAB> <TAB> <TAB> msg = ""This account is already in use."" <TAB> <TAB> <TAB> raise AuthAlreadyAssociated(backend, msg) <TAB> <TAB> elif not user: <TAB> <TAB> <TAB> user = social.user <TAB> return { <TAB> <TAB> ""social"": social, <TAB> <TAB> ""user"": user, <TAB> <TAB> ""is_new"": user is None, <TAB> <TAB> ""new_association"": social is None, <TAB> }",true,elif not user :,elif not user :,0.74,0.0
"def markUVs(self, indices=None): <TAB> if isinstance(indices, tuple): <TAB> <TAB> indices = indices[0] <TAB> ntexco = len(self.texco) <TAB> if indices is None: <TAB> <TAB> self.utexc = True <TAB> else: <TAB> <TAB> if self.utexc is False: <TAB> <TAB> <TAB> self.utexc = np.zeros(ntexco, dtype=bool) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.utexc[indices] = True",false,if self . utexc is not True :,if indices is not None :,0.16,0.0
"def destination(self, type, name, arglist): <TAB> classname = ""ResFunction"" <TAB> listname = ""functions"" <TAB> if arglist: <TAB> <TAB> t, n, m = arglist[0] <TAB> <TAB> if t == ""Handle"" and m == ""InMode"": <TAB> <TAB> <TAB> classname = ""ResMethod"" <TAB> <TAB> <TAB> listname = ""resmethods"" <TAB> return classname, listname",true,"if t == ""Handle"" and m == ""InMode"" :","if t == ""Handle"" and m == ""InMode"" :",1.0,0.0
"def select(self, regions, register): <TAB> self.view.sel().clear() <TAB> to_store = [] <TAB> for r in regions: <TAB> <TAB> self.view.sel().add(r) <TAB> <TAB> if register: <TAB> <TAB> <TAB> to_store.append(self.view.substr(self.view.full_line(r))) <TAB> if register: <TAB> <TAB> text = """".join(to_store) <TAB> <TAB> if not text.endswith(""\n""): <TAB> <TAB> <TAB> text = text + ""\n"" <TAB> <TAB> state = State(self.view) <TAB> <TAB> state.registers[register] = [text]",true,"if not text . endswith ( ""\n"" ) :","if not text . endswith ( ""\n"" ) :",0.75,0.0
"def _skip_start(self): <TAB> start, stop = self.start, self.stop <TAB> for chunk in self.app_iter: <TAB> <TAB> self._pos += len(chunk) <TAB> <TAB> if self._pos < start: <TAB> <TAB> <TAB> continue <TAB> <TAB> elif self._pos == start: <TAB> <TAB> <TAB> return b"""" <TAB> <TAB> else: <TAB> <TAB> <TAB> chunk = chunk[start - self._pos :] <TAB> <TAB> <TAB> if stop is not None and self._pos > stop: <TAB> <TAB> <TAB> <TAB> chunk = chunk[: stop - self._pos] <TAB> <TAB> <TAB> <TAB> assert len(chunk) == stop - start <TAB> <TAB> <TAB> return chunk <TAB> else: <TAB> <TAB> raise StopIteration()",true,elif self . _pos == start :,elif self . _pos == start :,1.0,0.0
"def start(self): <TAB> self.on_config_change() <TAB> self.start_config_watch() <TAB> try: <TAB> <TAB> if self.config[""MITMf""][""DNS""][""tcp""].lower() == ""on"": <TAB> <TAB> <TAB> self.startTCP() <TAB> <TAB> else: <TAB> <TAB> <TAB> self.startUDP() <TAB> except socket.error as e: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> shutdown( <TAB> <TAB> <TAB> <TAB> ""\n[DNS] Unable to start DNS server on port {}: port already in use"".format( <TAB> <TAB> <TAB> <TAB> <TAB> self.config[""MITMf""][""DNS""][""port""] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> )",false,"if ""Address already in use"" in e :",if e . args [ 0 ] == errno . EADDRINUSE :,0.02,0.0
"def ignore(self, other): <TAB> if isinstance(other, Suppress): <TAB> <TAB> if other not in self.ignoreExprs: <TAB> <TAB> <TAB> super(ParseElementEnhance, self).ignore(other) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.expr.ignore(self.ignoreExprs[-1]) <TAB> else: <TAB> <TAB> super(ParseElementEnhance, self).ignore(other) <TAB> <TAB> if self.expr is not None: <TAB> <TAB> <TAB> self.expr.ignore(self.ignoreExprs[-1]) <TAB> return self",true,if self . expr is not None :,if self . expr is not None :,0.75,0.0
"def test_relative_deploy_path_override(): <TAB> s = Site(TEST_SITE_ROOT) <TAB> s.load() <TAB> res = s.content.resource_from_relative_path( <TAB> <TAB> ""blog/2010/december/merry-christmas.html"" <TAB> ) <TAB> res.relative_deploy_path = ""blog/2010/december/happy-holidays.html"" <TAB> for page in s.content.walk_resources(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> assert page.relative_deploy_path == ""blog/2010/december/happy-holidays.html"" <TAB> <TAB> else: <TAB> <TAB> <TAB> assert page.relative_deploy_path == Folder(page.relative_path)",false,if res . source_file == page . source_file :,if page . is_linked :,0.09,0.0
"def _parser(cls, buf): <TAB> tlvs = [] <TAB> while buf: <TAB> <TAB> tlv_type = LLDPBasicTLV.get_type(buf) <TAB> <TAB> tlv = cls._tlv_parsers[tlv_type](buf) <TAB> <TAB> tlvs.append(tlv) <TAB> <TAB> offset = LLDP_TLV_SIZE + tlv.len <TAB> <TAB> buf = buf[offset:] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> assert len(buf) > 0 <TAB> lldp_pkt = cls(tlvs) <TAB> assert lldp_pkt._tlvs_len_valid() <TAB> assert lldp_pkt._tlvs_valid() <TAB> return lldp_pkt, None, buf",false,if tlv . tlv_type == LLDP_TLV_END :,if len ( buf ) == 0 :,0.02,0.0
"def _do_pull(self, repo, pull_kwargs, silent, ignore_pull_failures): <TAB> try: <TAB> <TAB> output = self.client.pull(repo, **pull_kwargs) <TAB> <TAB> if silent: <TAB> <TAB> <TAB> with open(os.devnull, ""w"") as devnull: <TAB> <TAB> <TAB> <TAB> yield from stream_output(output, devnull) <TAB> <TAB> else: <TAB> <TAB> <TAB> yield from stream_output(output, sys.stdout) <TAB> except (StreamOutputError, NotFound) as e: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise <TAB> <TAB> else: <TAB> <TAB> <TAB> log.error(str(e))",false,if not ignore_pull_failures :,if ignore_pull_failures :,0.1,0.0
"def _collect_bytecode(ordered_code): <TAB> bytecode_blocks = [] <TAB> stack = [ordered_code] <TAB> while stack: <TAB> <TAB> code = stack.pop() <TAB> <TAB> bytecode_blocks.append(code.co_code) <TAB> <TAB> for const in code.co_consts: <TAB> <TAB> <TAB> if isinstance(const, blocks.OrderedCode): <TAB> <TAB> <TAB> <TAB> stack.append(const) <TAB> return bytecode_blocks",true,"if isinstance ( const , blocks . OrderedCode ) :","if isinstance ( const , blocks . OrderedCode ) :",0.75,0.0
"def displayhook(value): <TAB> if value is None: <TAB> <TAB> return <TAB> builtins = modules[""builtins""] <TAB> # Set '_' to None to avoid recursion <TAB> builtins._ = None <TAB> text = repr(value) <TAB> try: <TAB> <TAB> local_stdout = stdout <TAB> except NameError as e: <TAB> <TAB> raise RuntimeError(""lost sys.stdout"") from e <TAB> try: <TAB> <TAB> local_stdout.write(text) <TAB> except UnicodeEncodeError: <TAB> <TAB> bytes = text.encode(local_stdout.encoding, ""backslashreplace"") <TAB> <TAB> if hasattr(local_stdout, ""buffer""): <TAB> <TAB> <TAB> local_stdout.buffer.write(bytes) <TAB> <TAB> else: <TAB> <TAB> <TAB> text = bytes.decode(local_stdout.encoding, ""strict"") <TAB> <TAB> <TAB> local_stdout.write(text) <TAB> local_stdout.write(""\n"") <TAB> builtins._ = value",true,"if hasattr ( local_stdout , ""buffer"" ) :","if hasattr ( local_stdout , ""buffer"" ) :",0.75,0.0
"def _analyze(self): <TAB> lines = open(self.log_path, ""r"").readlines() <TAB> prev_line = None <TAB> for line in lines: <TAB> <TAB> if line.startswith(""ERROR:"") and prev_line and prev_line.startswith(""=""): <TAB> <TAB> <TAB> self.errors.append(line[len(""ERROR:"") :].strip()) <TAB> <TAB> elif line.startswith(""FAIL:"") and prev_line and prev_line.startswith(""=""): <TAB> <TAB> <TAB> self.failures.append(line[len(""FAIL:"") :].strip()) <TAB> <TAB> prev_line = line",true,"elif line . startswith ( ""FAIL:"" ) and prev_line and prev_line . startswith ( ""="" ) :","elif line . startswith ( ""FAIL:"" ) and prev_line and prev_line . startswith ( ""="" ) :",1.0,0.0
"def _flush(self): <TAB> if self._data: <TAB> <TAB> if self._last is not None: <TAB> <TAB> <TAB> text = """".join(self._data) <TAB> <TAB> <TAB> if self._tail: <TAB> <TAB> <TAB> <TAB> assert self._last.tail is None, ""internal error (tail)"" <TAB> <TAB> <TAB> <TAB> self._last.tail = text <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> assert self._last.text is None, ""internal error (text)"" <TAB> <TAB> <TAB> <TAB> self._last.text = text <TAB> <TAB> self._data = []",true,if self . _tail :,if self . _tail :,0.75,0.0
"def write(self, chunk): <TAB> consumer = self._current_consumer <TAB> server_side = consumer.server_side <TAB> if server_side: <TAB> <TAB> server_side.data_received(chunk) <TAB> else: <TAB> <TAB> consumer.message += chunk <TAB> <TAB> assert consumer.in_parser.execute(chunk, len(chunk)) == len(chunk) <TAB> <TAB> if consumer.in_parser.is_message_complete(): <TAB> <TAB> <TAB> consumer.finished()",true,if consumer . in_parser . is_message_complete ( ) :,if consumer . in_parser . is_message_complete ( ) :,0.75,0.0
"def _api_change_cat(name, output, kwargs): <TAB> """"""API: accepts output, value(=nzo_id), value2(=category)"""""" <TAB> value = kwargs.get(""value"") <TAB> value2 = kwargs.get(""value2"") <TAB> if value and value2: <TAB> <TAB> nzo_id = value <TAB> <TAB> cat = value2 <TAB> <TAB> if cat == ""None"": <TAB> <TAB> <TAB> cat = None <TAB> <TAB> result = sabnzbd.NzbQueue.change_cat(nzo_id, cat) <TAB> <TAB> return report(output, keyword=""status"", data=bool(result > 0)) <TAB> else: <TAB> <TAB> return report(output, _MSG_NO_VALUE)",true,"if cat == ""None"" :","if cat == ""None"" :",0.75,0.0
"def get_allocated_address( <TAB> self, config: ActorPoolConfig, allocated: allocated_type ) -> str: <TAB> addresses = config.get_external_addresses(label=self.label) <TAB> for addr in addresses: <TAB> <TAB> occupied = False <TAB> <TAB> for strategy, _ in allocated.get(addr, dict()).values(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> occupied = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if not occupied: <TAB> <TAB> <TAB> return addr <TAB> raise NoIdleSlot( <TAB> <TAB> f""No idle slot for creating actor "" f""with label {self.label}, mark {self.mark}"" <TAB> )",false,if strategy == self :,if strategy == self . strategy :,0.29,0.0
"def schedule_logger(job_id=None, delete=False): <TAB> if not job_id: <TAB> <TAB> return getLogger(""fate_flow_schedule"") <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> with LoggerFactory.lock: <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> for key in LoggerFactory.schedule_logger_dict.keys(): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if job_id in key: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> del LoggerFactory.schedule_logger_dict[key] <TAB> <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> return True <TAB> <TAB> key = job_id + ""schedule"" <TAB> <TAB> if key in LoggerFactory.schedule_logger_dict: <TAB> <TAB> <TAB> return LoggerFactory.schedule_logger_dict[key] <TAB> <TAB> return LoggerFactory.get_schedule_logger(job_id)",true,if delete :,if delete :,0.53,0.0
"def quick_load(tool_file, async_load=True): <TAB> try: <TAB> <TAB> tool = self.load_tool(tool_file, tool_cache_data_dir) <TAB> <TAB> self.__add_tool(tool, load_panel_dict, elems) <TAB> <TAB> # Always load the tool into the integrated_panel_dict, or it will not be included in the integrated_tool_panel.xml file. <TAB> <TAB> key = ""tool_%s"" % str(tool.id) <TAB> <TAB> integrated_elems[key] = tool <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._load_tool_panel() <TAB> <TAB> <TAB> self._save_integrated_tool_panel() <TAB> <TAB> return tool.id <TAB> except Exception: <TAB> <TAB> log.exception(""Failed to load potential tool %s."", tool_file) <TAB> <TAB> return None",true,if async_load :,if async_load :,0.53,0.0
"def _get_default_ordering(self): <TAB> try: <TAB> <TAB> ordering = super(DocumentChangeList, self)._get_default_ordering() <TAB> except AttributeError: <TAB> <TAB> ordering = [] <TAB> <TAB> if self.model_admin.ordering: <TAB> <TAB> <TAB> ordering = self.model_admin.ordering <TAB> <TAB> elif self.lookup_opts.ordering: <TAB> <TAB> <TAB> ordering = self.lookup_opts.ordering <TAB> return ordering",true,elif self . lookup_opts . ordering :,elif self . lookup_opts . ordering :,0.75,0.0
"def names(self, persistent=None): <TAB> u = set() <TAB> result = [] <TAB> for s in [ <TAB> <TAB> self.__storage(None), <TAB> <TAB> self.__storage(self.__category), <TAB> ]: <TAB> <TAB> for b in s: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if b.name.startswith(""__""): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if b.name not in u: <TAB> <TAB> <TAB> <TAB> result.append(b.name) <TAB> <TAB> <TAB> <TAB> u.add(b.name) <TAB> return result",false,if persistent is not None and b . persistent != persistent :,if b . persistent and persistent is not None :,0.33,0.0
"def common_check_get_messages_query( <TAB> self, query_params: Dict[str, object], expected: str ) -> None: <TAB> user_profile = self.example_user(""hamlet"") <TAB> request = POSTRequestMock(query_params, user_profile) <TAB> with queries_captured() as queries: <TAB> <TAB> get_messages_backend(request, user_profile) <TAB> for query in queries: <TAB> <TAB> if ""/* get_messages */"" in query[""sql""]: <TAB> <TAB> <TAB> sql = str(query[""sql""]).replace("" /* get_messages */"", """") <TAB> <TAB> <TAB> self.assertEqual(sql, expected) <TAB> <TAB> <TAB> return <TAB> raise AssertionError(""get_messages query not found"")",true,"if ""/* get_messages */"" in query [ ""sql"" ] :","if ""/* get_messages */"" in query [ ""sql"" ] :",0.75,0.0
"def _activate_only_current_top_active(): <TAB> for i in range(0, len(current_sequence().tracks) - 1): <TAB> <TAB> if i == current_sequence().get_first_active_track().id: <TAB> <TAB> <TAB> current_sequence().tracks[i].active = True <TAB> <TAB> else: <TAB> <TAB> <TAB> current_sequence().tracks[i].active = False <TAB> gui.tline_column.widget.queue_draw()",true,if i == current_sequence ( ) . get_first_active_track ( ) . id :,if i == current_sequence ( ) . get_first_active_track ( ) . id :,0.75,0.0
"def http_wrapper(self, url, postdata={}): <TAB> try: <TAB> <TAB> if postdata != {}: <TAB> <TAB> <TAB> f = urllib.urlopen(url, postdata) <TAB> <TAB> else: <TAB> <TAB> <TAB> f = urllib.urlopen(url) <TAB> <TAB> response = f.read() <TAB> except: <TAB> <TAB> import traceback <TAB> <TAB> import logging, sys <TAB> <TAB> cla, exc, tb = sys.exc_info() <TAB> <TAB> logging.error(url) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> logging.error(""with post data"") <TAB> <TAB> else: <TAB> <TAB> <TAB> logging.error(""without post data"") <TAB> <TAB> logging.error(exc.args) <TAB> <TAB> logging.error(traceback.format_tb(tb)) <TAB> <TAB> response = """" <TAB> return response",false,if postdata :,if exc . args [ 0 ] == 404 :,0.04,0.0
"def frequent_thread_switches(): <TAB> """"""Make concurrency bugs more likely to manifest."""""" <TAB> interval = None <TAB> if not sys.platform.startswith(""java""): <TAB> <TAB> if hasattr(sys, ""getswitchinterval""): <TAB> <TAB> <TAB> interval = sys.getswitchinterval() <TAB> <TAB> <TAB> sys.setswitchinterval(1e-6) <TAB> <TAB> else: <TAB> <TAB> <TAB> interval = sys.getcheckinterval() <TAB> <TAB> <TAB> sys.setcheckinterval(1) <TAB> try: <TAB> <TAB> yield <TAB> finally: <TAB> <TAB> if not sys.platform.startswith(""java""): <TAB> <TAB> <TAB> if hasattr(sys, ""setswitchinterval""): <TAB> <TAB> <TAB> <TAB> sys.setswitchinterval(interval) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> sys.setcheckinterval(interval)",false,"if not sys . platform . startswith ( ""java"" ) :","if hasattr ( sys , ""setswitchinterval"" ) :",0.03,0.0
"def iter_filters(filters, block_end=False): <TAB> queue = deque(filters) <TAB> while queue: <TAB> <TAB> f = queue.popleft() <TAB> <TAB> if f is not None and f.type in (""or"", ""and"", ""not""): <TAB> <TAB> <TAB> if block_end: <TAB> <TAB> <TAB> <TAB> queue.appendleft(None) <TAB> <TAB> <TAB> for gf in f.filters: <TAB> <TAB> <TAB> <TAB> queue.appendleft(gf) <TAB> <TAB> yield f",true,"if f is not None and f . type in ( ""or"" , ""and"" , ""not"" ) :","if f is not None and f . type in ( ""or"" , ""and"" , ""not"" ) :",1.0,0.0
"def smartsplit(code): <TAB> """"""Split `code` at "" symbol, only if it is not escaped."""""" <TAB> strings = [] <TAB> pos = 0 <TAB> while pos < len(code): <TAB> <TAB> if code[pos] == '""': <TAB> <TAB> <TAB> word = """"  # new word <TAB> <TAB> <TAB> pos += 1 <TAB> <TAB> <TAB> while pos < len(code): <TAB> <TAB> <TAB> <TAB> if code[pos] == '""': <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> if code[pos] == ""\\"": <TAB> <TAB> <TAB> <TAB> <TAB> word += ""\\"" <TAB> <TAB> <TAB> <TAB> <TAB> pos += 1 <TAB> <TAB> <TAB> <TAB> word += code[pos] <TAB> <TAB> <TAB> <TAB> pos += 1 <TAB> <TAB> <TAB> strings.append('""%s""' % word) <TAB> <TAB> pos += 1 <TAB> return strings",true,"if code [ pos ] == '""' :","if code [ pos ] == '""' :",0.75,0.0
"def get_folder_content(cls, name): <TAB> """"""Return (folders, files) for the given folder in the root dir."""""" <TAB> folders = set() <TAB> files = set() <TAB> for path in cls.LAYOUT: <TAB> <TAB> if not path.startswith(name + ""/""): <TAB> <TAB> <TAB> continue <TAB> <TAB> parts = path.split(""/"") <TAB> <TAB> if len(parts) == 2: <TAB> <TAB> <TAB> files.add(parts[1]) <TAB> <TAB> else: <TAB> <TAB> <TAB> folders.add(parts[1]) <TAB> folders = list(folders) <TAB> folders.sort() <TAB> files = list(files) <TAB> files.sort() <TAB> return (folders, files)",true,"if not path . startswith ( name + ""/"" ) :","if not path . startswith ( name + ""/"" ) :",0.75,0.0
"def array_for(self, i): <TAB> if 0 <= i < self._cnt: <TAB> <TAB> if i >= self.tailoff(): <TAB> <TAB> <TAB> return self._tail <TAB> <TAB> node = self._root <TAB> <TAB> level = self._shift <TAB> <TAB> while level > 0: <TAB> <TAB> <TAB> assert isinstance(node, Node) <TAB> <TAB> <TAB> node = node._array[(i >> level) & 0x01F] <TAB> <TAB> <TAB> level -= 5 <TAB> <TAB> assert isinstance(node, Node) <TAB> <TAB> return node._array <TAB> affirm(False, u""Index out of Range"")",true,if i >= self . tailoff ( ) :,if i >= self . tailoff ( ) :,0.75,0.0
"def __or__(self, other) -> ""MultiVector"": <TAB> r""""""``self | other``, the inner product :math:`M \cdot N`"""""" <TAB> other, mv = self._checkOther(other) <TAB> if mv: <TAB> <TAB> newValue = self.layout.imt_func(self.value, other.value) <TAB> else: <TAB> <TAB> if isinstance(other, np.ndarray): <TAB> <TAB> <TAB> obj = self.__array__() <TAB> <TAB> <TAB> return obj | other <TAB> <TAB> # l * M = M * l = 0 for scalar l <TAB> <TAB> return self._newMV(dtype=np.result_type(self.value.dtype, other)) <TAB> return self._newMV(newValue)",true,"if isinstance ( other , np . ndarray ) :","if isinstance ( other , np . ndarray ) :",0.75,0.0
"def parse_bzr_stats(status): <TAB> stats = RepoStats() <TAB> statustype = ""changed"" <TAB> for statusline in status: <TAB> <TAB> if statusline[:2] == ""  "": <TAB> <TAB> <TAB> setattr(stats, statustype, getattr(stats, statustype) + 1) <TAB> <TAB> elif statusline == ""added:"": <TAB> <TAB> <TAB> statustype = ""staged"" <TAB> <TAB> elif statusline == ""unknown:"": <TAB> <TAB> <TAB> statustype = ""new"" <TAB> <TAB> else:  # removed, missing, renamed, modified or kind changed <TAB> <TAB> <TAB> statustype = ""changed"" <TAB> return stats",false,"elif statusline == ""added:"" :","elif statusline == ""unknown:"" :",0.64,0.0
"def write(self, timestamps, actualValues, predictedValues, predictionStep=1): <TAB> assert len(timestamps) == len(actualValues) == len(predictedValues) <TAB> for index in range(len(self.names)): <TAB> <TAB> timestamp = timestamps[index] <TAB> <TAB> actual = actualValues[index] <TAB> <TAB> prediction = predictedValues[index] <TAB> <TAB> writer = self.outputWriters[index] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> outputRow = [timestamp, actual, prediction] <TAB> <TAB> <TAB> writer.writerow(outputRow) <TAB> <TAB> <TAB> self.lineCounts[index] += 1",false,if timestamp is not None :,if writer is not None :,0.52,0.0
"def clean(self): <TAB> """"""Delete old files in ""tmp""."""""" <TAB> now = time.time() <TAB> for entry in os.listdir(os.path.join(self._path, ""tmp"")): <TAB> <TAB> path = os.path.join(self._path, ""tmp"", entry) <TAB> <TAB><IF-STMT>  # 60 * 60 * 36 <TAB> <TAB> <TAB> os.remove(path)",false,if now - os . path . getatime ( path ) > 129600 :,if now - path > 60 * 60 :,0.04,0.0
"def _get_info(self, path): <TAB> info = OrderedDict() <TAB> if not self._is_mac() or self._has_xcode_tools(): <TAB> <TAB> stdout = None <TAB> <TAB> try: <TAB> <TAB> <TAB> stdout, stderr = Popen( <TAB> <TAB> <TAB> <TAB> [self._find_binary(), ""info"", os.path.realpath(path)], <TAB> <TAB> <TAB> <TAB> stdout=PIPE, <TAB> <TAB> <TAB> <TAB> stderr=PIPE, <TAB> <TAB> <TAB> ).communicate() <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> for line in stdout.splitlines(): <TAB> <TAB> <TAB> <TAB> <TAB> line = u(line).split("": "", 1) <TAB> <TAB> <TAB> <TAB> <TAB> if len(line) == 2: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> info[line[0]] = line[1] <TAB> return info",true,if stdout :,if stdout :,0.53,0.0
"def add(meta_list, info_list=None): <TAB> if not info_list: <TAB> <TAB> info_list = meta_list <TAB> if not isinstance(meta_list, (list, tuple)): <TAB> <TAB> meta_list = (meta_list,) <TAB> if not isinstance(info_list, (list, tuple)): <TAB> <TAB> info_list = (info_list,) <TAB> for info_f in info_list: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for meta_f in meta_list: <TAB> <TAB> <TAB> <TAB> metadata[meta_f] = info[info_f] <TAB> <TAB> <TAB> break",false,if info . get ( info_f ) is not None :,if info_f not in metadata :,0.1,0.0
"def _compute_log_r(model_trace, guide_trace): <TAB> log_r = MultiFrameTensor() <TAB> stacks = get_plate_stacks(model_trace) <TAB> for name, model_site in model_trace.nodes.items(): <TAB> <TAB> if model_site[""type""] == ""sample"": <TAB> <TAB> <TAB> log_r_term = model_site[""log_prob""] <TAB> <TAB> <TAB> if not model_site[""is_observed""]: <TAB> <TAB> <TAB> <TAB> log_r_term = log_r_term - guide_trace.nodes[name][""log_prob""] <TAB> <TAB> <TAB> log_r.add((stacks[name], log_r_term.detach())) <TAB> return log_r",true,"if model_site [ ""type"" ] == ""sample"" :","if model_site [ ""type"" ] == ""sample"" :",0.75,0.0
"def pickline(file, key, casefold=1): <TAB> try: <TAB> <TAB> f = open(file, ""r"") <TAB> except IOError: <TAB> <TAB> return None <TAB> pat = re.escape(key) + "":"" <TAB> prog = re.compile(pat, casefold and re.IGNORECASE) <TAB> while 1: <TAB> <TAB> line = f.readline() <TAB> <TAB> if not line: <TAB> <TAB> <TAB> break <TAB> <TAB> if prog.match(line): <TAB> <TAB> <TAB> text = line[len(key) + 1 :] <TAB> <TAB> <TAB> while 1: <TAB> <TAB> <TAB> <TAB> line = f.readline() <TAB> <TAB> <TAB> <TAB> if not line or not line[0].isspace(): <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> text = text + line <TAB> <TAB> <TAB> return text.strip() <TAB> return None",false,if not line or not line [ 0 ] . isspace ( ) :,if prog . match ( line ) :,0.02,0.0
"def build_iterator(data, infinite=True): <TAB> """"""Build the iterator for inputs."""""" <TAB> index = 0 <TAB> size = len(data[0]) <TAB> while True: <TAB> <TAB> if index + batch_size > size: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> index = 0 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> yield data[0][index : index + batch_size], data[1][index : index + batch_size] <TAB> <TAB> index += batch_size",true,if infinite :,if infinite :,0.53,0.0
"def checkall(g, bg, dst_nodes, include_dst_in_src=True): <TAB> for etype in g.etypes: <TAB> <TAB> ntype = g.to_canonical_etype(etype)[2] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> check(g, bg, ntype, etype, dst_nodes[ntype], include_dst_in_src) <TAB> <TAB> else: <TAB> <TAB> <TAB> check(g, bg, ntype, etype, None, include_dst_in_src)",false,if dst_nodes is not None and ntype in dst_nodes :,if ntype in dst_nodes :,0.31,0.0
"def minimalBases(classes): <TAB> """"""Reduce a list of base classes to its ordered minimum equivalent"""""" <TAB> if not __python3:  # pragma: no cover <TAB> <TAB> classes = [c for c in classes if c is not ClassType] <TAB> candidates = [] <TAB> for m in classes: <TAB> <TAB> for n in classes: <TAB> <TAB> <TAB> if issubclass(n, m) and m is not n: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> # m has no subclasses in 'classes' <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> candidates.remove(m)  # ensure that we're later in the list <TAB> <TAB> <TAB> candidates.append(m) <TAB> return candidates",true,if m in candidates :,if m in candidates :,0.75,0.0
"def __keep_songs_enable(self, enabled): <TAB> config.set(""memory"", ""queue_keep_songs"", enabled) <TAB> if enabled: <TAB> <TAB> self.queue.set_first_column_type(CurrentColumn) <TAB> else: <TAB> <TAB> for col in self.queue.get_columns(): <TAB> <TAB> <TAB> # Remove the CurrentColum if it exists <TAB> <TAB> <TAB> if isinstance(col, CurrentColumn): <TAB> <TAB> <TAB> <TAB> self.queue.set_first_column_type(None) <TAB> <TAB> <TAB> <TAB> break",true,"if isinstance ( col , CurrentColumn ) :","if isinstance ( col , CurrentColumn ) :",0.75,0.0
"def outlineView_heightOfRowByItem_(self, tree, item) -> float: <TAB> default_row_height = self.rowHeight <TAB> if item is self: <TAB> <TAB> return default_row_height <TAB> heights = [default_row_height] <TAB> for column in self.tableColumns: <TAB> <TAB> value = getattr(item.attrs[""node""], str(column.identifier)) <TAB> <TAB> if isinstance(value, toga.Widget): <TAB> <TAB> <TAB> # if the cell value is a widget, use its height <TAB> <TAB> <TAB> heights.append(value._impl.native.intrinsicContentSize().height) <TAB> return max(heights)",true,"if isinstance ( value , toga . Widget ) :","if isinstance ( value , toga . Widget ) :",0.75,0.0
"def condition(self): <TAB> if self.__condition is None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # Avoid an extra indirection in the common case of only one condition. <TAB> <TAB> <TAB> self.__condition = self.flat_conditions[0] <TAB> <TAB> elif len(self.flat_conditions) == 0: <TAB> <TAB> <TAB> # Possible, if unlikely, due to filter predicate rewriting <TAB> <TAB> <TAB> self.__condition = lambda _: True <TAB> <TAB> else: <TAB> <TAB> <TAB> self.__condition = lambda x: all(cond(x) for cond in self.flat_conditions) <TAB> return self.__condition",true,if len ( self . flat_conditions ) == 1 :,if len ( self . flat_conditions ) == 1 :,0.75,0.0
"def _find_delimiter(f, block_size=2 ** 16): <TAB> delimiter = b""\n"" <TAB> if f.tell() == 0: <TAB> <TAB> return 0 <TAB> while True: <TAB> <TAB> b = f.read(block_size) <TAB> <TAB> if not b: <TAB> <TAB> <TAB> return f.tell() <TAB> <TAB> elif delimiter in b: <TAB> <TAB> <TAB> return f.tell() - len(b) + b.index(delimiter) + 1",true,elif delimiter in b :,elif delimiter in b :,0.75,0.0
"def serialize(self, name=None): <TAB> data = super(SimpleText, self).serialize(name) <TAB> data[""contentType""] = self.contentType <TAB> data[""content""] = self.content <TAB> if self.width: <TAB> <TAB> if self.width not in [100, 50, 33, 25]: <TAB> <TAB> <TAB> raise InvalidWidthException(self.width) <TAB> <TAB> data[""inputOptions""] = {} <TAB> <TAB> data[""width""] = self.width <TAB> return data",true,"if self . width not in [ 100 , 50 , 33 , 25 ] :","if self . width not in [ 100 , 50 , 33 , 25 ] :",0.75,0.0
"def inference(self): <TAB> self.attention_weight_dim = self.input_dims[0][-1] <TAB> if self.keep_dim: <TAB> <TAB> self.output_dim = copy.deepcopy(self.input_dims[0]) <TAB> else: <TAB> <TAB> self.output_dim = [] <TAB> <TAB> for idx, dim in enumerate(self.input_dims[0]): <TAB> <TAB> <TAB> if idx != len(self.input_dims[0]) - 2: <TAB> <TAB> <TAB> <TAB> self.output_dim.append(dim) <TAB> super( <TAB> <TAB> LinearAttentionConf, self <TAB> ).inference()  # PUT THIS LINE AT THE END OF inference()",true,if idx != len ( self . input_dims [ 0 ] ) - 2 :,if idx != len ( self . input_dims [ 0 ] ) - 2 :,0.75,0.0
"def __delete_hook(self, rpc): <TAB> try: <TAB> <TAB> rpc.check_success() <TAB> except apiproxy_errors.Error: <TAB> <TAB> return None <TAB> result = [] <TAB> for status in rpc.response.delete_status_list(): <TAB> <TAB> if status == MemcacheDeleteResponse.DELETED: <TAB> <TAB> <TAB> result.append(DELETE_SUCCESSFUL) <TAB> <TAB> elif status == MemcacheDeleteResponse.NOT_FOUND: <TAB> <TAB> <TAB> result.append(DELETE_ITEM_MISSING) <TAB> <TAB> else: <TAB> <TAB> <TAB> result.append(DELETE_NETWORK_FAILURE) <TAB> return result",true,elif status == MemcacheDeleteResponse . NOT_FOUND :,elif status == MemcacheDeleteResponse . NOT_FOUND :,0.75,0.0
def identify_page_at_cursor(self): <TAB> for region in self.view.sel(): <TAB> <TAB> text_on_cursor = None <TAB> <TAB> pos = region.begin() <TAB> <TAB> scope_region = self.view.extract_scope(pos) <TAB> <TAB> if not scope_region.empty(): <TAB> <TAB> <TAB> text_on_cursor = self.view.substr(scope_region) <TAB> <TAB> <TAB> return text_on_cursor.strip(string.punctuation) <TAB> return None,true,if not scope_region . empty ( ) :,if not scope_region . empty ( ) :,0.75,0.0
"def from_elem(cls, parent, when_elem): <TAB> """"""Loads the proper when by attributes of elem"""""" <TAB> when_value = when_elem.get(""value"", None) <TAB><IF-STMT> <TAB> <TAB> return ValueToolOutputActionConditionalWhen(parent, when_elem, when_value) <TAB> else: <TAB> <TAB> when_value = when_elem.get(""datatype_isinstance"", None) <TAB> <TAB> if when_value is not None: <TAB> <TAB> <TAB> return DatatypeIsInstanceToolOutputActionConditionalWhen( <TAB> <TAB> <TAB> <TAB> parent, when_elem, when_value <TAB> <TAB> <TAB> ) <TAB> raise TypeError(""When type not implemented"")",true,if when_value is not None :,if when_value is not None :,0.75,0.0
"def test_insert_entity_empty_string_rk( <TAB> self, tables_cosmos_account_name, tables_primary_cosmos_account_key ): <TAB> # Arrange <TAB> await self._set_up(tables_cosmos_account_name, tables_primary_cosmos_account_key) <TAB> try: <TAB> <TAB> entity = {""PartitionKey"": ""pk"", ""RowKey"": """"} <TAB> <TAB> # Act <TAB> <TAB> with pytest.raises(HttpResponseError): <TAB> <TAB> <TAB> await self.table.create_entity(entity=entity) <TAB> <TAB> <TAB> # Assert <TAB> <TAB> #  assert resp is None <TAB> finally: <TAB> <TAB> await self._tear_down() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> sleep(SLEEP_DELAY)",false,if self . is_live :,if self . timeout is None :,0.2,0.0
"def provider_uris(self): <TAB> login_urls = {} <TAB> continue_url = self.request.get(""continue_url"") <TAB> for provider in self.provider_info: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> login_url = self.uri_for( <TAB> <TAB> <TAB> <TAB> ""social-login"", provider_name=provider, continue_url=continue_url <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> login_url = self.uri_for(""social-login"", provider_name=provider) <TAB> <TAB> login_urls[provider] = login_url <TAB> return login_urls",true,if continue_url :,if continue_url :,0.53,0.0
"def expand_extensions(existing): <TAB> for name in extension_names: <TAB> <TAB> ext = ( <TAB> <TAB> <TAB> im(""lizard_ext.lizard"" + name.lower()).LizardExtension() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> else name <TAB> <TAB> ) <TAB> <TAB> existing.insert( <TAB> <TAB> <TAB> len(existing) if not hasattr(ext, ""ordering_index"") else ext.ordering_index, <TAB> <TAB> <TAB> ext, <TAB> <TAB> ) <TAB> return existing",false,"if isinstance ( name , str )",if name in existing,0.02,0.0
"def wrapper(self, *args, **kwargs): <TAB> if not self.request.path.endswith(""/""): <TAB> <TAB> if self.request.method in (""GET"", ""HEAD""): <TAB> <TAB> <TAB> uri = self.request.path + ""/"" <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> uri += ""?"" + self.request.query <TAB> <TAB> <TAB> self.redirect(uri, permanent=True) <TAB> <TAB> <TAB> return <TAB> <TAB> raise HTTPError(404) <TAB> return method(self, *args, **kwargs)",true,if self . request . query :,if self . request . query :,0.75,0.0
"def subword_map_by_joiner(subwords, marker=SubwordMarker.JOINER): <TAB> """"""Return word id for each subword token (annotate by joiner)."""""" <TAB> flags = [0] * len(subwords) <TAB> for i, tok in enumerate(subwords): <TAB> <TAB> if tok.endswith(marker): <TAB> <TAB> <TAB> flags[i] = 1 <TAB> <TAB> if tok.startswith(marker): <TAB> <TAB> <TAB> assert i >= 1 and flags[i - 1] != 1, ""Sentence `{}` not correct!"".format( <TAB> <TAB> <TAB> <TAB> "" "".join(subwords) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> flags[i - 1] = 1 <TAB> marker_acc = list(accumulate([0] + flags[:-1])) <TAB> word_group = [(i - maker_sofar) for i, maker_sofar in enumerate(marker_acc)] <TAB> return word_group",false,if tok . endswith ( marker ) :,if tok . startswith ( marker ) :,0.5,0.0
"def next_item(self, direction): <TAB> """"""Selects next menu item, based on self._direction"""""" <TAB> start, i = -1, 0 <TAB> try: <TAB> <TAB> start = self.items.index(self._selected) <TAB> <TAB> i = start + direction <TAB> except: <TAB> <TAB> pass <TAB> while True: <TAB> <TAB> if i == start: <TAB> <TAB> <TAB> # Cannot find valid menu item <TAB> <TAB> <TAB> self.select(start) <TAB> <TAB> <TAB> break <TAB> <TAB> if i >= len(self.items): <TAB> <TAB> <TAB> i = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> if i < 0: <TAB> <TAB> <TAB> i = len(self.items) - 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> if self.select(i): <TAB> <TAB> <TAB> break <TAB> <TAB> i += direction <TAB> <TAB> if start < 0: <TAB> <TAB> <TAB> start = 0",true,if self . select ( i ) :,if self . select ( i ) :,0.75,0.0
"def get_config(cls): <TAB> # FIXME: Replace this as soon as we have a config module <TAB> config = {} <TAB> # Try to get iflytek_yuyin config from config <TAB> profile_path = dingdangpath.config(""profile.yml"") <TAB> if os.path.exists(profile_path): <TAB> <TAB> with open(profile_path, ""r"") as f: <TAB> <TAB> <TAB> profile = yaml.safe_load(f) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if ""vid"" in profile[""iflytek_yuyin""]: <TAB> <TAB> <TAB> <TAB> <TAB> config[""vid""] = profile[""iflytek_yuyin""][""vid""] <TAB> return config",true,"if ""iflytek_yuyin"" in profile :","if ""iflytek_yuyin"" in profile :",0.75,0.0
"def get_signed_in_user(test_case): <TAB> playback = not (test_case.is_live or test_case.in_recording) <TAB> if playback: <TAB> <TAB> return MOCKED_USER_NAME <TAB> else: <TAB> <TAB> account_info = test_case.cmd(""account show"").get_output_in_json() <TAB> <TAB> if account_info[""user""][""type""] != ""servicePrincipal"": <TAB> <TAB> <TAB> return account_info[""user""][""name""] <TAB> return None",true,"if account_info [ ""user"" ] [ ""type"" ] != ""servicePrincipal"" :","if account_info [ ""user"" ] [ ""type"" ] != ""servicePrincipal"" :",0.75,0.0
"def rename_project(self, project, new_name): <TAB> """"""Rename project, update the related projects if necessary"""""" <TAB> old_name = project.name <TAB> for proj in self.projects: <TAB> <TAB> relproj = proj.get_related_projects() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> relproj[relproj.index(old_name)] = new_name <TAB> <TAB> <TAB> proj.set_related_projects(relproj) <TAB> project.rename(new_name) <TAB> self.save()",true,if old_name in relproj :,if old_name in relproj :,0.75,0.0
"def test_call_extern_c_fn(self): <TAB> global memcmp <TAB> memcmp = cffi_support.ExternCFunction( <TAB> <TAB> ""memcmp"", <TAB> <TAB> (""int memcmp ( const uint8_t * ptr1, "" ""const uint8_t * ptr2, size_t num )""), <TAB> ) <TAB> @udf(BooleanVal(FunctionContext, StringVal, StringVal)) <TAB> def fn(context, a, b): <TAB> <TAB> if a.is_null != b.is_null: <TAB> <TAB> <TAB> return False <TAB> <TAB> if a is None: <TAB> <TAB> <TAB> return True <TAB> <TAB> if len(a) != b.len: <TAB> <TAB> <TAB> return False <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> return memcmp(a.ptr, b.ptr, a.len) == 0",true,if a . ptr == b . ptr :,if a . ptr == b . ptr :,1.0,0.0
"def parse_variable(self): <TAB> begin = self._pos <TAB> while True: <TAB> <TAB> ch = self.read() <TAB> <TAB> if ch == ""%"": <TAB> <TAB> <TAB> return ScriptVariable(self._text[begin : self._pos - 1]) <TAB> <TAB> elif ch is None: <TAB> <TAB> <TAB> self.__raise_eof() <TAB> <TAB> elif not isidentif(ch) and ch != "":"": <TAB> <TAB> <TAB> self.__raise_char(ch)",false,"if ch == ""%"" :",elif ch is None :,0.03,0.0
"def h_file(self): <TAB> filename = self.abspath() <TAB> st = os.stat(filename) <TAB> cache = self.ctx.hashes_md5_tstamp <TAB> if filename in cache and cache[filename][0] == st.st_mtime: <TAB> <TAB> return cache[filename][1] <TAB> if STRONGEST: <TAB> <TAB> ret = Utils.h_file(filename) <TAB> else: <TAB> <TAB> if stat.S_ISDIR(st[stat.ST_MODE]): <TAB> <TAB> <TAB> raise IOError(""Not a file"") <TAB> <TAB> ret = Utils.md5(str((st.st_mtime, st.st_size)).encode()).digest() <TAB> cache[filename] = (st.st_mtime, ret) <TAB> return ret",true,if stat . S_ISDIR ( st [ stat . ST_MODE ] ) :,if stat . S_ISDIR ( st [ stat . ST_MODE ] ) :,1.0,0.0
"def add_widgets(self, *widgets_or_spacings): <TAB> """"""Add widgets/spacing to dialog vertical layout"""""" <TAB> layout = self.layout() <TAB> for widget_or_spacing in widgets_or_spacings: <TAB> <TAB> if isinstance(widget_or_spacing, int): <TAB> <TAB> <TAB> layout.addSpacing(widget_or_spacing) <TAB> <TAB> else: <TAB> <TAB> <TAB> layout.addWidget(widget_or_spacing)",true,"if isinstance ( widget_or_spacing , int ) :","if isinstance ( widget_or_spacing , int ) :",0.75,0.0
"def _str_index(self): <TAB> idx = self[""index""] <TAB> out = [] <TAB> if len(idx) == 0: <TAB> <TAB> return out <TAB> out += ["".. index:: %s"" % idx.get(""default"", """")] <TAB> for section, references in idx.iteritems(): <TAB> <TAB> if section == ""default"": <TAB> <TAB> <TAB> continue <TAB> <TAB> elif section == ""refguide"": <TAB> <TAB> <TAB> out += [""   single: %s"" % ("", "".join(references))] <TAB> <TAB> else: <TAB> <TAB> <TAB> out += [""   %s: %s"" % (section, "","".join(references))] <TAB> return out",false,"if section == ""default"" :","elif section == ""refguide"" :",0.06,0.0
"def dictify_CPPDEFINES(env): <TAB> cppdefines = env.get(""CPPDEFINES"", {}) <TAB> if cppdefines is None: <TAB> <TAB> return {} <TAB> if SCons.Util.is_Sequence(cppdefines): <TAB> <TAB> result = {} <TAB> <TAB> for c in cppdefines: <TAB> <TAB> <TAB> if SCons.Util.is_Sequence(c): <TAB> <TAB> <TAB> <TAB> result[c[0]] = c[1] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> result[c] = None <TAB> <TAB> return result <TAB> if not SCons.Util.is_Dict(cppdefines): <TAB> <TAB> return {cppdefines: None} <TAB> return cppdefines",true,if SCons . Util . is_Sequence ( c ) :,if SCons . Util . is_Sequence ( c ) :,0.75,0.0
"def decoder(s): <TAB> r = [] <TAB> decode = [] <TAB> for c in s: <TAB> <TAB> if c == ""&"" and not decode: <TAB> <TAB> <TAB> decode.append(""&"") <TAB> <TAB> elif c == ""-"" and decode: <TAB> <TAB> <TAB> if len(decode) == 1: <TAB> <TAB> <TAB> <TAB> r.append(""&"") <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> r.append(modified_unbase64("""".join(decode[1:]))) <TAB> <TAB> <TAB> decode = [] <TAB> <TAB> elif decode: <TAB> <TAB> <TAB> decode.append(c) <TAB> <TAB> else: <TAB> <TAB> <TAB> r.append(c) <TAB> if decode: <TAB> <TAB> r.append(modified_unbase64("""".join(decode[1:]))) <TAB> bin_str = """".join(r) <TAB> return (bin_str, len(s))",false,elif decode :,"elif c == ""-"" and decode :",0.2,0.0
"def optimize(self, graph: Graph): <TAB> MAX_TEXTURE_SIZE = config.WEBGL_MAX_TEXTURE_SIZE <TAB> flag_changed = False <TAB> for v in traverse.listup_variables(graph): <TAB> <TAB> if not Placeholder.check_resolved(v.size): <TAB> <TAB> <TAB> continue <TAB> <TAB> height, width = TextureShape.get(v) <TAB> <TAB> if height <= MAX_TEXTURE_SIZE and width <= MAX_TEXTURE_SIZE: <TAB> <TAB> <TAB> continue <TAB> <TAB> if not v.has_attribute(SplitTarget): <TAB> <TAB> <TAB> flag_changed = True <TAB> <TAB> <TAB> v.attributes.add(SplitTarget()) <TAB> return graph, flag_changed",true,if not Placeholder . check_resolved ( v . size ) :,if not Placeholder . check_resolved ( v . size ) :,0.75,0.0
"def one_gpr_reg_one_mem_scalable(ii): <TAB> n, r = 0, 0 <TAB> for op in _gen_opnds(ii): <TAB> <TAB> if op_agen(op) or (op_mem(op) and op.oc2 in [""v""]): <TAB> <TAB> <TAB> n += 1 <TAB> <TAB> elif op_gprv(op): <TAB> <TAB> <TAB> r += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> return False <TAB> return n == 1 and r == 1",true,elif op_gprv ( op ) :,elif op_gprv ( op ) :,0.75,0.0
"def get_genome_dir(gid, galaxy_dir, data): <TAB> """"""Return standard location of genome directories."""""" <TAB> if galaxy_dir: <TAB> <TAB> refs = genome.get_refs(gid, None, galaxy_dir, data) <TAB> <TAB> seq_file = tz.get_in([""fasta"", ""base""], refs) <TAB> <TAB> if seq_file and os.path.exists(seq_file): <TAB> <TAB> <TAB> return os.path.dirname(os.path.dirname(seq_file)) <TAB> else: <TAB> <TAB> gdirs = glob.glob(os.path.join(_get_data_dir(), ""genomes"", ""*"", gid)) <TAB> <TAB> if len(gdirs) == 1 and os.path.exists(gdirs[0]): <TAB> <TAB> <TAB> return gdirs[0]",false,if len ( gdirs ) == 1 and os . path . exists ( gdirs [ 0 ] ) :,if seq_file and os . path . exists ( seq_file ) :,0.22,0.0
"def __modules(self): <TAB> raw_output = self.__module_avail_output().decode(""utf-8"") <TAB> for line in StringIO(raw_output): <TAB> <TAB> line = line and line.strip() <TAB> <TAB> if not line or line.startswith(""-""): <TAB> <TAB> <TAB> continue <TAB> <TAB> line_modules = line.split() <TAB> <TAB> for module in line_modules: <TAB> <TAB> <TAB> if module.endswith(self.default_indicator): <TAB> <TAB> <TAB> <TAB> module = module[0 : -len(self.default_indicator)].strip() <TAB> <TAB> <TAB> module_parts = module.split(""/"") <TAB> <TAB> <TAB> module_version = None <TAB> <TAB> <TAB> if len(module_parts) == 2: <TAB> <TAB> <TAB> <TAB> module_version = module_parts[1] <TAB> <TAB> <TAB> module_name = module_parts[0] <TAB> <TAB> <TAB> yield module_name, module_version",true,if module . endswith ( self . default_indicator ) :,if module . endswith ( self . default_indicator ) :,0.75,0.0
"def save(self): <TAB> updates = self.cinder_obj_get_changes() <TAB> if updates: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> metadata = updates.pop(""metadata"", None) <TAB> <TAB> <TAB> self.metadata = db.backup_metadata_update( <TAB> <TAB> <TAB> <TAB> self._context, self.id, metadata, True <TAB> <TAB> <TAB> ) <TAB> <TAB> updates.pop(""parent"", None) <TAB> <TAB> db.backup_update(self._context, self.id, updates) <TAB> self.obj_reset_changes()",true,"if ""metadata"" in updates :","if ""metadata"" in updates :",0.75,0.0
"def test_set_tag(association_obj, sagemaker_session): <TAB> tag = {""Key"": ""foo"", ""Value"": ""bar""} <TAB> association_obj.set_tag(tag) <TAB> while True: <TAB> <TAB> actual_tags = sagemaker_session.sagemaker_client.list_tags( <TAB> <TAB> <TAB> ResourceArn=association_obj.source_arn <TAB> <TAB> )[""Tags""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> time.sleep(5) <TAB> # When sagemaker-client-config endpoint-url is passed as argument to hit some endpoints, <TAB> # length of actual tags will be greater than 1 <TAB> assert len(actual_tags) > 0 <TAB> assert actual_tags[0] == tag",true,if actual_tags :,if actual_tags :,0.53,0.0
"def test_error_stream(environ, start_response): <TAB> writer = start_response(""200 OK"", []) <TAB> wsgi_errors = environ[""wsgi.errors""] <TAB> error_msg = None <TAB> for method in [ <TAB> <TAB> ""flush"", <TAB> <TAB> ""write"", <TAB> <TAB> ""writelines"", <TAB> ]: <TAB> <TAB> if not hasattr(wsgi_errors, method): <TAB> <TAB> <TAB> error_msg = ""wsgi.errors has no '%s' attr"" % method <TAB> <TAB> if not error_msg and not callable(getattr(wsgi_errors, method)): <TAB> <TAB> <TAB> error_msg = ""wsgi.errors.%s attr is not callable"" % method <TAB> <TAB> if error_msg: <TAB> <TAB> <TAB> break <TAB> return_msg = error_msg or ""success"" <TAB> writer(return_msg) <TAB> return []",false,"if not error_msg and not callable ( getattr ( wsgi_errors , method ) ) :","if not hasattr ( wsgi_errors , method ) :",0.15,0.0
"def current_dict(cursor_offset, line): <TAB> """"""If in dictionary completion, return the dict that should be used"""""" <TAB> for m in current_dict_re.finditer(line): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return LinePart(m.start(1), m.end(1), m.group(1)) <TAB> return None",false,if m . start ( 2 ) <= cursor_offset and m . end ( 2 ) >= cursor_offset :,if m . start ( 1 ) <= cursor_offset and m . end ( 1 ) >= cursor_offset :,0.85,0.0
"def show_file_browser(self): <TAB> """"""Show/hide the file browser."""""" <TAB> if self.show_file_browser_action.isChecked(): <TAB> <TAB> sizes = self.panel.sizes() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> sizes[0] = sum(sizes) // 4 <TAB> <TAB> <TAB> self.panel.setSizes(sizes) <TAB> <TAB> self.file_browser.show() <TAB> else: <TAB> <TAB> self.file_browser.hide()",false,if sizes [ 0 ] == 0 :,if len ( sizes ) > 4 :,0.02,0.0
"def run(self, paths=[]): <TAB> items = [] <TAB> for item in SideBarSelection(paths).getSelectedItems(): <TAB> <TAB> items.append(item.nameEncoded()) <TAB> if len(items) > 0: <TAB> <TAB> sublime.set_clipboard(""\n"".join(items)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> sublime.status_message(""Items copied"") <TAB> <TAB> else: <TAB> <TAB> <TAB> sublime.status_message(""Item copied"")",true,if len ( items ) > 1 :,if len ( items ) > 1 :,0.75,0.0
"def prepend(self, value): <TAB> """"""prepend value to nodes"""""" <TAB> root, root_text = self._get_root(value) <TAB> for i, tag in enumerate(self): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tag.text = """" <TAB> <TAB> if len(root) > 0: <TAB> <TAB> <TAB> root[-1].tail = tag.text <TAB> <TAB> <TAB> tag.text = root_text <TAB> <TAB> else: <TAB> <TAB> <TAB> tag.text = root_text + tag.text <TAB> <TAB> if i > 0: <TAB> <TAB> <TAB> root = deepcopy(list(root)) <TAB> <TAB> tag[:0] = root <TAB> <TAB> root = tag[: len(root)] <TAB> return self",false,if not tag . text :,if tag . text is None :,0.1,0.0
"def getLabel(self, address=None): <TAB> if address is None: <TAB> <TAB> address = self.address <TAB> label = address <TAB> if shared.config.has_section(address): <TAB> <TAB> label = shared.config.get(address, ""label"") <TAB> queryreturn = sqlQuery(""""""select label from addressbook where address=?"""""", address) <TAB> if queryreturn != []: <TAB> <TAB> for row in queryreturn: <TAB> <TAB> <TAB> (label,) = row <TAB> else: <TAB> <TAB> queryreturn = sqlQuery( <TAB> <TAB> <TAB> """"""select label from subscriptions where address=?"""""", address <TAB> <TAB> ) <TAB> <TAB> if queryreturn != []: <TAB> <TAB> <TAB> for row in queryreturn: <TAB> <TAB> <TAB> <TAB> (label,) = row <TAB> return label",false,if queryreturn != [ ] :,if shared . config . has_section ( address ) :,0.02,0.0
"def _parse(self, engine): <TAB> """"""Parse the layer."""""" <TAB> if isinstance(self.args, dict): <TAB> <TAB> if ""axis"" in self.args: <TAB> <TAB> <TAB> self.axis = engine.evaluate(self.args[""axis""], recursive=True) <TAB> <TAB> <TAB> if not isinstance(self.axis, int): <TAB> <TAB> <TAB> <TAB> raise ParsingError('""axis"" must be an integer.') <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.momentum = engine.evaluate(self.args[""momentum""], recursive=True) <TAB> <TAB> <TAB> if not isinstance(self.momentum, (int, float)): <TAB> <TAB> <TAB> <TAB> raise ParsingError('""momentum"" must be numeric.')",true,"if ""momentum"" in self . args :","if ""momentum"" in self . args :",0.75,0.0
"def urlquote(*args, **kwargs): <TAB> new_kwargs = dict(kwargs) <TAB> if not PY3: <TAB> <TAB> new_kwargs = dict(kwargs) <TAB> <TAB> if ""encoding"" in new_kwargs: <TAB> <TAB> <TAB> del new_kwargs[""encoding""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> del new_kwargs[""errors""] <TAB> return quote(*args, **new_kwargs)",false,"if ""errors"" in kwargs :","if ""errors"" in new_kwargs :",0.39,0.0
"def setNextFormPrevious(self, backup=STARTING_FORM): <TAB> try: <TAB> <TAB> if self._THISFORM.FORM_NAME == self._FORM_VISIT_LIST[-1]: <TAB> <TAB> <TAB> self._FORM_VISIT_LIST.pop()  # Remove the current form. if it is at the end of the list <TAB> <TAB> if self._THISFORM.FORM_NAME == self.NEXT_ACTIVE_FORM: <TAB> <TAB> <TAB> # take no action if it looks as if someone has already set the next form. <TAB> <TAB> <TAB> self.setNextForm( <TAB> <TAB> <TAB> <TAB> self._FORM_VISIT_LIST.pop() <TAB> <TAB> <TAB> )  # Switch to the previous form if one exists <TAB> except IndexError: <TAB> <TAB> self.setNextForm(backup)",false,if self . _THISFORM . FORM_NAME == self . NEXT_ACTIVE_FORM :,if self . _THISFORM . FORM_NAME == self . _FORM_VISIT_LIST [ - 1 ] :,0.69,0.0
"def iter_chars_to_words(self, chars): <TAB> current_word = [] <TAB> for char in chars: <TAB> <TAB> if not self.keep_blank_chars and char[""text""].isspace(): <TAB> <TAB> <TAB> if current_word: <TAB> <TAB> <TAB> <TAB> yield current_word <TAB> <TAB> <TAB> <TAB> current_word = [] <TAB> <TAB> elif current_word and self.char_begins_new_word(current_word, char): <TAB> <TAB> <TAB> yield current_word <TAB> <TAB> <TAB> current_word = [char] <TAB> <TAB> else: <TAB> <TAB> <TAB> current_word.append(char) <TAB> if current_word: <TAB> <TAB> yield current_word",true,"elif current_word and self . char_begins_new_word ( current_word , char ) :","elif current_word and self . char_begins_new_word ( current_word , char ) :",1.0,0.0
"def get(self): <TAB> """"""return a secret by name"""""" <TAB> results = self._get(""secrets"", self.name) <TAB> results[""decoded""] = {} <TAB> results[""exists""] = False <TAB> if results[""returncode""] == 0 and results[""results""][0]: <TAB> <TAB> results[""exists""] = True <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if ""data"" in results[""results""][0]: <TAB> <TAB> <TAB> <TAB> for sname, value in results[""results""][0][""data""].items(): <TAB> <TAB> <TAB> <TAB> <TAB> results[""decoded""][sname] = base64.b64decode(value) <TAB> if results[""returncode""] != 0 and '""%s"" not found' % self.name in results[""stderr""]: <TAB> <TAB> results[""returncode""] = 0 <TAB> return results",false,if self . decode :,"if ""results"" in results :",0.03,0.0
"def insert_use(self, edit): <TAB> if self.is_first_use(): <TAB> <TAB> for location in [r""^\s*namespace\s+[\w\\]+[;{]"", r""<\?php""]: <TAB> <TAB> <TAB> inserted = self.insert_first_use(location, edit) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> else: <TAB> <TAB> self.insert_use_among_others(edit)",true,if inserted :,if inserted :,0.53,0.0
"def _new_rsa_key(spec): <TAB> if ""name"" not in spec: <TAB> <TAB> if ""/"" in spec[""key""]: <TAB> <TAB> <TAB> (head, tail) = os.path.split(spec[""key""]) <TAB> <TAB> <TAB> spec[""path""] = head <TAB> <TAB> <TAB> spec[""name""] = tail <TAB> <TAB> else: <TAB> <TAB> <TAB> spec[""name""] = spec[""key""] <TAB> return rsa_init(spec)",true,"if ""/"" in spec [ ""key"" ] :","if ""/"" in spec [ ""key"" ] :",0.75,0.0
"def mimeData(self, indexes): <TAB> if len(indexes) == 1: <TAB> <TAB> index = indexes[0] <TAB> <TAB> model = song = index.data(Qt.UserRole) <TAB> <TAB> if index.column() == Column.album: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> model = song.album <TAB> <TAB> <TAB> except (ProviderIOError, Exception): <TAB> <TAB> <TAB> <TAB> model = None <TAB> <TAB> return ModelMimeData(model)",true,if index . column ( ) == Column . album :,if index . column ( ) == Column . album :,0.75,0.0
"def get(self, url, **kwargs): <TAB> app, url = self._prepare_call(url, kwargs) <TAB> if app: <TAB> <TAB> if url.endswith(""ping"") and self._first_ping: <TAB> <TAB> <TAB> self._first_ping = False <TAB> <TAB> <TAB> return EmptyCapabilitiesResponse() <TAB> <TAB> elif ""Hello0"" in url and ""1.2.1"" in url and ""v1"" in url: <TAB> <TAB> <TAB> return ErrorApiResponse() <TAB> <TAB> else: <TAB> <TAB> <TAB> response = app.get(url, **kwargs) <TAB> <TAB> <TAB> return TestingResponse(response) <TAB> else: <TAB> <TAB> return requests.get(url, **kwargs)",true,"elif ""Hello0"" in url and ""1.2.1"" in url and ""v1"" in url :","elif ""Hello0"" in url and ""1.2.1"" in url and ""v1"" in url :",1.0,0.0
"def handle_noargs(self, **options): <TAB> self.style = color_style() <TAB> print(""Running Django's own validation:"") <TAB> self.validate(display_num_errors=True) <TAB> for model in loading.get_models(): <TAB> <TAB> if hasattr(model, ""_create_content_base""): <TAB> <TAB> <TAB> self.validate_base_model(model) <TAB> <TAB> if hasattr(model, ""_feincms_content_models""): <TAB> <TAB> <TAB> self.validate_content_type(model)",false,"if hasattr ( model , ""_feincms_content_models"" ) :","if hasattr ( model , ""_create_content_base"" ) :",0.55,0.0
"def test_rules_widget(self): <TAB> subreddit = self.reddit.subreddit(pytest.placeholders.test_subreddit) <TAB> widgets = subreddit.widgets <TAB> with self.use_cassette(""TestSubredditWidgets.fetch_widgets""): <TAB> <TAB> rules = None <TAB> <TAB> for widget in widgets.sidebar: <TAB> <TAB> <TAB> if isinstance(widget, RulesWidget): <TAB> <TAB> <TAB> <TAB> rules = widget <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> assert isinstance(rules, RulesWidget) <TAB> <TAB> assert rules == rules <TAB> <TAB> assert rules.id == rules <TAB> <TAB> assert rules.display <TAB> <TAB> assert len(rules) > 0 <TAB> <TAB> assert subreddit == rules.subreddit",true,"if isinstance ( widget , RulesWidget ) :","if isinstance ( widget , RulesWidget ) :",0.75,0.0
"def __init__(self, exception): <TAB> message = str(exception) <TAB> with contextlib.suppress(IndexError): <TAB> <TAB> underlying_exception = exception.args[0] <TAB> <TAB> if isinstance(underlying_exception, urllib3.exceptions.MaxRetryError): <TAB> <TAB> <TAB> message = ( <TAB> <TAB> <TAB> <TAB> ""maximum retries exceeded trying to reach the store.\n"" <TAB> <TAB> <TAB> <TAB> ""Check your network connection, and check the store "" <TAB> <TAB> <TAB> <TAB> ""status at {}"".format(_STORE_STATUS_URL) <TAB> <TAB> <TAB> ) <TAB> super().__init__(message=message)",true,"if isinstance ( underlying_exception , urllib3 . exceptions . MaxRetryError ) :","if isinstance ( underlying_exception , urllib3 . exceptions . MaxRetryError ) :",0.75,0.0
"def wrapped(self, request): <TAB> try: <TAB> <TAB> return self._finished <TAB> except AttributeError: <TAB> <TAB> if self.node_ids: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> log.debug( <TAB> <TAB> <TAB> <TAB> <TAB> ""%s is still going to be used, not terminating it. "" <TAB> <TAB> <TAB> <TAB> <TAB> ""Still in use on:\n%s"", <TAB> <TAB> <TAB> <TAB> <TAB> self, <TAB> <TAB> <TAB> <TAB> <TAB> pprint.pformat(list(self.node_ids)), <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> log.debug(""Finish called on %s"", self) <TAB> <TAB> try: <TAB> <TAB> <TAB> return func(request) <TAB> <TAB> finally: <TAB> <TAB> <TAB> self._finished = True",false,if not request . session . shouldfail and not request . session . shouldstop :,if self . node_ids :,0.03,0.0
"def get_min_vertical_scroll() -> int: <TAB> # Make sure that the cursor line is not below the bottom. <TAB> # (Calculate how many lines can be shown between the cursor and the .) <TAB> used_height = 0 <TAB> prev_lineno = ui_content.cursor_position.y <TAB> for lineno in range(ui_content.cursor_position.y, -1, -1): <TAB> <TAB> used_height += get_line_height(lineno) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return prev_lineno <TAB> <TAB> else: <TAB> <TAB> <TAB> prev_lineno = lineno <TAB> return 0",false,if used_height > height - scroll_offsets_bottom :,if used_height > scroll_height :,0.16,0.0
"def cookies(self): <TAB> # strip cookie_suffix from all cookies in the request, return result <TAB> cookies = flask.Request.cookies.__get__(self) <TAB> result = {} <TAB> desuffixed = {} <TAB> for key, value in cookies.items(): <TAB> <TAB> if key.endswith(self.cookie_suffix): <TAB> <TAB> <TAB> desuffixed[key[: -len(self.cookie_suffix)]] = value <TAB> <TAB> else: <TAB> <TAB> <TAB> result[key] = value <TAB> result.update(desuffixed) <TAB> return result",true,if key . endswith ( self . cookie_suffix ) :,if key . endswith ( self . cookie_suffix ) :,0.75,0.0
"def update_vars(state1, state2): <TAB> ops = [] <TAB> for name in state1._fields: <TAB> <TAB> state1_vs = getattr(state1, name) <TAB> <TAB> if isinstance(state1_vs, list): <TAB> <TAB> <TAB> ops += [ <TAB> <TAB> <TAB> <TAB> tf.assign(_v1, _v2) <TAB> <TAB> <TAB> <TAB> for _v1, _v2 in zip(state1_vs, getattr(state2, name)) <TAB> <TAB> <TAB> ] <TAB> <TAB> else: <TAB> <TAB> <TAB> ops += [tf.assign(state1_vs, getattr(state2, name))] <TAB> return tf.group(*ops)",true,"if isinstance ( state1_vs , list ) :","if isinstance ( state1_vs , list ) :",0.75,0.0
"def manifest(self): <TAB> """"""The current manifest dictionary."""""" <TAB> if self.reload: <TAB> <TAB> if not self.exists(self.manifest_path): <TAB> <TAB> <TAB> return {} <TAB> <TAB> mtime = self.getmtime(self.manifest_path) <TAB> <TAB> if self._mtime is None or mtime > self._mtime: <TAB> <TAB> <TAB> self._manifest = self.get_manifest() <TAB> <TAB> <TAB> self._mtime = mtime <TAB> return self._manifest",false,if not self . exists ( self . manifest_path ) :,if self . _mtime is None or mtime > self . _mtime :,0.09,0.0
"def csvtitle(self): <TAB> if isinstance(self.name, six.string_types): <TAB> <TAB> return '""' + self.name + '""' + char[""sep""] * (len(self.nick) - 1) <TAB> else: <TAB> <TAB> ret = """" <TAB> <TAB> for i, name in enumerate(self.name): <TAB> <TAB> <TAB> ret = ret + '""' + name + '""' + char[""sep""] * (len(self.nick) - 1) <TAB> <TAB> <TAB> if i + 1 != len(self.name): <TAB> <TAB> <TAB> <TAB> ret = ret + char[""sep""] <TAB> <TAB> return ret",true,if i + 1 != len ( self . name ) :,if i + 1 != len ( self . name ) :,0.75,0.0
"def cache_dst(self): <TAB> final_dst = None <TAB> final_linenb = None <TAB> for linenb, assignblk in enumerate(self): <TAB> <TAB> for dst, src in viewitems(assignblk): <TAB> <TAB> <TAB> if dst.is_id(""IRDst""): <TAB> <TAB> <TAB> <TAB> if final_dst is not None: <TAB> <TAB> <TAB> <TAB> <TAB> raise ValueError(""Multiple destinations!"") <TAB> <TAB> <TAB> <TAB> final_dst = src <TAB> <TAB> <TAB> <TAB> final_linenb = linenb <TAB> self._dst = final_dst <TAB> self._dst_linenb = final_linenb <TAB> return final_dst",true,"if dst . is_id ( ""IRDst"" ) :","if dst . is_id ( ""IRDst"" ) :",0.75,0.0
"def _ProcessName(self, name, dependencies): <TAB> """"""Retrieve a module name from a node name."""""" <TAB> module_name, dot, base_name = name.rpartition(""."") <TAB> if dot: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if module_name in dependencies: <TAB> <TAB> <TAB> <TAB> dependencies[module_name].add(base_name) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> dependencies[module_name] = {base_name} <TAB> <TAB> else: <TAB> <TAB> <TAB> # If we have a relative import that did not get qualified (usually due <TAB> <TAB> <TAB> # to an empty package_name), don't insert module_name='' into the <TAB> <TAB> <TAB> # dependencies; we get a better error message if we filter it out here <TAB> <TAB> <TAB> # and fail later on. <TAB> <TAB> <TAB> logging.warning(""Empty package name: %s"", name)",false,if module_name :,if base_name :,0.32,0.0
"def get_aa_from_codonre(re_aa): <TAB> aas = [] <TAB> m = 0 <TAB> for i in re_aa: <TAB> <TAB> if i == ""["": <TAB> <TAB> <TAB> m = -1 <TAB> <TAB> <TAB> aas.append("""") <TAB> <TAB> elif i == ""]"": <TAB> <TAB> <TAB> m = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> elif m == -1: <TAB> <TAB> <TAB> aas[-1] = aas[-1] + i <TAB> <TAB> elif m == 0: <TAB> <TAB> <TAB> aas.append(i) <TAB> return aas",false,elif m == 0 :,elif m == - 1 :,0.44,0.0
"def logic(): <TAB> count = intbv(0, min=0, max=MAXVAL + 1) <TAB> while True: <TAB> <TAB> yield clock.posedge, reset.posedge <TAB> <TAB> if reset == 1: <TAB> <TAB> <TAB> count[:] = 0 <TAB> <TAB> else: <TAB> <TAB> <TAB> flag.next = 0 <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> flag.next = 1 <TAB> <TAB> <TAB> <TAB> count[:] = 0 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> count += 1",false,if count == MAXVAL :,if reset == 0 :,0.04,0.0
"def _history_define_metric( <TAB> self, hkey: str ) -> Optional[wandb_internal_pb2.MetricRecord]: <TAB> """"""check for hkey match in glob metrics, return defined metric."""""" <TAB> # Dont define metric for internal metrics <TAB> if hkey.startswith(""_""): <TAB> <TAB> return None <TAB> for k, mglob in six.iteritems(self._metric_globs): <TAB> <TAB> if k.endswith(""*""): <TAB> <TAB> <TAB> if hkey.startswith(k[:-1]): <TAB> <TAB> <TAB> <TAB> m = wandb_internal_pb2.MetricRecord() <TAB> <TAB> <TAB> <TAB> m.CopyFrom(mglob) <TAB> <TAB> <TAB> <TAB> m.ClearField(""glob_name"") <TAB> <TAB> <TAB> <TAB> m.name = hkey <TAB> <TAB> <TAB> <TAB> return m <TAB> return None",false,if hkey . startswith ( k [ : - 1 ] ) :,"if k . endswith ( ""*"" ) :",0.02,0.0
"def optimize_models(args, use_cuda, models): <TAB> """"""Optimize ensemble for generation"""""" <TAB> for model in models: <TAB> <TAB> model.make_generation_fast_( <TAB> <TAB> <TAB> beamable_mm_beam_size=None if args.no_beamable_mm else args.beam, <TAB> <TAB> <TAB> need_attn=args.print_alignment, <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> model.half() <TAB> <TAB> if use_cuda: <TAB> <TAB> <TAB> model.cuda()",false,if args . fp16 :,if args . half :,0.39,0.0
"def _Dynamic_Rollback(self, transaction, transaction_response): <TAB> txid = transaction.handle() <TAB> self.__local_tx_lock.acquire() <TAB> try: <TAB> <TAB> if txid not in self.__transactions: <TAB> <TAB> <TAB> raise apiproxy_errors.ApplicationError( <TAB> <TAB> <TAB> <TAB> datastore_pb.Error.BAD_REQUEST, ""Transaction %d not found."" % (txid,) <TAB> <TAB> <TAB> ) <TAB> <TAB> txdata = self.__transactions[txid] <TAB> <TAB> assert ( <TAB> <TAB> <TAB> txdata.thread_id == thread.get_ident() <TAB> <TAB> ), ""Transactions are single-threaded."" <TAB> <TAB> del self.__transactions[txid] <TAB> finally: <TAB> <TAB> self.__local_tx_lock.release()",true,if txid not in self . __transactions :,if txid not in self . __transactions :,0.75,0.0
"def get_job_dirs(path): <TAB> regex = re.compile(""[1-9][0-9]*-"") <TAB> jobdirs = [] <TAB> for d in os.listdir(path): <TAB> <TAB> # skip directories not matching the job result dir pattern <TAB> <TAB> if not regex.match(d): <TAB> <TAB> <TAB> continue <TAB> <TAB> d = os.path.join(options.resultsdir, d) <TAB> <TAB> if os.path.isdir(d) and not os.path.exists(os.path.join(d, PUBLISH_FLAGFILE)): <TAB> <TAB> <TAB> jobdirs.append(d) <TAB> return jobdirs",false,if not regex . match ( d ) :,"if os . path . isdir ( d ) and not os . path . exists ( os . path . join ( d , PUBLISH_FLAGFILE ) ) :",0.05,0.0
"def traverse(node, functions=[]): <TAB> if hasattr(node, ""grad_fn""): <TAB> <TAB> node = node.grad_fn <TAB> if hasattr(node, ""variable""): <TAB> <TAB> node = graph.nodes_by_id.get(id(node.variable)) <TAB> <TAB> if node: <TAB> <TAB> <TAB> node.functions = list(functions) <TAB> <TAB> <TAB> del functions[:] <TAB> if hasattr(node, ""next_functions""): <TAB> <TAB> functions.append(type(node).__name__) <TAB> <TAB> for f in node.next_functions: <TAB> <TAB> <TAB> if f[0]: <TAB> <TAB> <TAB> <TAB> functions.append(type(f[0]).__name__) <TAB> <TAB> <TAB> <TAB> traverse(f[0], functions) <TAB> if hasattr(node, ""saved_tensors""): <TAB> <TAB> for t in node.saved_tensors: <TAB> <TAB> <TAB> traverse(t)",true,if f [ 0 ] :,if f [ 0 ] :,0.75,0.0
"def get_all_snap_points(self, forts): <TAB> points = [] <TAB> radius = Constants.MAX_DISTANCE_FORT_IS_REACHABLE <TAB> for i in range(0, len(forts)): <TAB> <TAB> for j in range(i + 1, len(forts)): <TAB> <TAB> <TAB> c1, c2 = self.get_enclosing_circles(forts[i], forts[j], radius) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> points.append((c1, c2, forts[i], forts[j])) <TAB> return points",false,if c1 and c2 :,if c1 != c2 :,0.08,0.0
"def doDir(elem): <TAB> for child in elem.childNodes: <TAB> <TAB> if not isinstance(child, minidom.Element): <TAB> <TAB> <TAB> continue <TAB> <TAB> if child.tagName == ""Directory"": <TAB> <TAB> <TAB> doDir(child) <TAB> <TAB> elif child.tagName == ""Component"": <TAB> <TAB> <TAB> for grandchild in child.childNodes: <TAB> <TAB> <TAB> <TAB> if not isinstance(grandchild, minidom.Element): <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> if grandchild.tagName != ""File"": <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> files.add(grandchild.getAttribute(""Source"").replace(os.sep, ""/""))",false,"if not isinstance ( grandchild , minidom . Element ) :","if grandchild . tagName != ""File"" :",0.01,0.0
"def computeLeadingWhitespaceWidth(s, tab_width): <TAB> w = 0 <TAB> for ch in s: <TAB> <TAB> if ch == "" "": <TAB> <TAB> <TAB> w += 1 <TAB> <TAB> elif ch == ""\t"": <TAB> <TAB> <TAB> w += abs(tab_width) - (w % abs(tab_width)) <TAB> <TAB> else: <TAB> <TAB> <TAB> break <TAB> return w",true,"elif ch == ""\t"" :","elif ch == ""\t"" :",1.0,0.0
"def test_avg_group_by(self): <TAB> ret = ( <TAB> <TAB> await Book.annotate(avg=Avg(""rating"")) <TAB> <TAB> .group_by(""author_id"") <TAB> <TAB> .values(""author_id"", ""avg"") <TAB> ) <TAB> for item in ret: <TAB> <TAB> author_id = item.get(""author_id"") <TAB> <TAB> avg = item.get(""avg"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.assertEqual(avg, 4.5) <TAB> <TAB> elif author_id == self.a2.pk: <TAB> <TAB> <TAB> self.assertEqual(avg, 2.0)",true,if author_id == self . a1 . pk :,if author_id == self . a1 . pk :,0.75,0.0
"def open_session(self, app, request): <TAB> sid = request.cookies.get(app.session_cookie_name) <TAB> if sid: <TAB> <TAB> stored_session = self.cls.objects(sid=sid).first() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> expiration = stored_session.expiration <TAB> <TAB> <TAB> if not expiration.tzinfo: <TAB> <TAB> <TAB> <TAB> expiration = expiration.replace(tzinfo=utc) <TAB> <TAB> <TAB> if expiration > datetime.datetime.utcnow().replace(tzinfo=utc): <TAB> <TAB> <TAB> <TAB> return MongoEngineSession( <TAB> <TAB> <TAB> <TAB> <TAB> initial=stored_session.data, sid=stored_session.sid <TAB> <TAB> <TAB> <TAB> ) <TAB> return MongoEngineSession(sid=str(uuid.uuid4()))",true,if stored_session :,if stored_session :,0.53,0.0
"def one_line_description(self): <TAB> MAX_LINE_LENGTH = 120 <TAB> desc = util.remove_html_tags(self.description or """") <TAB> desc = re.sub(""\s+"", "" "", desc).strip() <TAB> if not desc: <TAB> <TAB> return _(""No description available"") <TAB> else: <TAB> <TAB> # Decode the description to avoid gPodder bug 1277 <TAB> <TAB> desc = util.convert_bytes(desc).strip() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return desc[:MAX_LINE_LENGTH] + ""..."" <TAB> <TAB> else: <TAB> <TAB> <TAB> return desc",true,if len ( desc ) > MAX_LINE_LENGTH :,if len ( desc ) > MAX_LINE_LENGTH :,0.75,0.0
"def setInnerHTML(self, html): <TAB> log.HTMLClassifier.classify( <TAB> <TAB> log.ThugLogging.url if log.ThugOpts.local else log.last_url, html <TAB> ) <TAB> self.tag.clear() <TAB> for node in bs4.BeautifulSoup(html, ""html.parser"").contents: <TAB> <TAB> self.tag.append(node) <TAB> <TAB> name = getattr(node, ""name"", None) <TAB> <TAB> if name is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> handler = getattr(log.DFT, ""handle_%s"" % (name,), None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> handler(node)",false,if handler :,if handler is not None :,0.09,0.0
def get_supported_period_type_map(cls): <TAB> if cls.supported_period_map is None: <TAB> <TAB> cls.supported_period_map = {} <TAB> <TAB> cls.supported_period_map.update(cls.period_type_map) <TAB> <TAB> try: <TAB> <TAB> <TAB> from dateutil import relativedelta <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> cls.supported_period_map.update(cls.optional_period_type_map) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> pass <TAB> return cls.supported_period_map,false,if relativedelta is not None :,if relativedelta . now ( ) < cls . optional_period_type_map :,0.04,0.0
"def _compare_single_run(self, compares_done): <TAB> try: <TAB> <TAB> compare_id, redo = self.in_queue.get( <TAB> <TAB> <TAB> timeout=float(self.config[""ExpertSettings""][""block_delay""]) <TAB> <TAB> ) <TAB> except Empty: <TAB> <TAB> pass <TAB> else: <TAB> <TAB> if self._decide_whether_to_process(compare_id, redo, compares_done): <TAB> <TAB> <TAB> if redo: <TAB> <TAB> <TAB> <TAB> self.db_interface.delete_old_compare_result(compare_id) <TAB> <TAB> <TAB> compares_done.add(compare_id) <TAB> <TAB> <TAB> self._process_compare(compare_id) <TAB> <TAB> <TAB> if self.callback: <TAB> <TAB> <TAB> <TAB> self.callback()",true,"if self . _decide_whether_to_process ( compare_id , redo , compares_done ) :","if self . _decide_whether_to_process ( compare_id , redo , compares_done ) :",0.75,0.0
"def _get_field_actual(cant_be_number, raw_string, field_names): <TAB> for line in raw_string.splitlines(): <TAB> <TAB> for field_name in field_names: <TAB> <TAB> <TAB> field_name = field_name.lower() <TAB> <TAB> <TAB> if "":"" in line: <TAB> <TAB> <TAB> <TAB> left, right = line.split("":"", 1) <TAB> <TAB> <TAB> <TAB> left = left.strip().lower() <TAB> <TAB> <TAB> <TAB> right = right.strip() <TAB> <TAB> <TAB> <TAB> if left == field_name and len(right) > 0: <TAB> <TAB> <TAB> <TAB> <TAB> if cant_be_number: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if not right.isdigit(): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return right <TAB> <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return right <TAB> return None",true,if not right . isdigit ( ) :,if not right . isdigit ( ) :,0.75,0.0
"def _p_basicstr_content(s, content=_basicstr_re): <TAB> res = [] <TAB> while True: <TAB> <TAB> res.append(s.expect_re(content).group(0)) <TAB> <TAB> if not s.consume(""\\""): <TAB> <TAB> <TAB> break <TAB> <TAB> if s.consume_re(_newline_esc_re): <TAB> <TAB> <TAB> pass <TAB> <TAB> elif s.consume_re(_short_uni_re) or s.consume_re(_long_uni_re): <TAB> <TAB> <TAB> res.append(_chr(int(s.last().group(1), 16))) <TAB> <TAB> else: <TAB> <TAB> <TAB> s.expect_re(_escapes_re) <TAB> <TAB> <TAB> res.append(_escapes[s.last().group(0)]) <TAB> return """".join(res)",true,if s . consume_re ( _newline_esc_re ) :,if s . consume_re ( _newline_esc_re ) :,0.75,0.0
"def removedir(self, path): <TAB> # type: (Text) -> None <TAB> _path = self.validatepath(path) <TAB> if _path == ""/"": <TAB> <TAB> raise errors.RemoveRootError() <TAB> with ftp_errors(self, path): <TAB> <TAB> try: <TAB> <TAB> <TAB> self.ftp.rmd(_encode(_path, self.ftp.encoding)) <TAB> <TAB> except error_perm as error: <TAB> <TAB> <TAB> code, _ = _parse_ftp_error(error) <TAB> <TAB> <TAB> if code == ""550"": <TAB> <TAB> <TAB> <TAB> if self.isfile(path): <TAB> <TAB> <TAB> <TAB> <TAB> raise errors.DirectoryExpected(path) <TAB> <TAB> <TAB> <TAB> if not self.isempty(path): <TAB> <TAB> <TAB> <TAB> <TAB> raise errors.DirectoryNotEmpty(path) <TAB> <TAB> <TAB> raise  # pragma: no cover",false,if not self . isempty ( path ) :,"if code == ""550"" :",0.02,0.0
"def _normalize_store_path(self, resource_store): <TAB> if resource_store[""type""] == ""filesystem"": <TAB> <TAB> if not os.path.isabs(resource_store[""base_directory""]): <TAB> <TAB> <TAB> resource_store[""base_directory""] = os.path.join( <TAB> <TAB> <TAB> <TAB> self.root_directory, resource_store[""base_directory""] <TAB> <TAB> <TAB> ) <TAB> return resource_store",true,"if not os . path . isabs ( resource_store [ ""base_directory"" ] ) :","if not os . path . isabs ( resource_store [ ""base_directory"" ] ) :",0.75,0.0
"def _apply_nested(name, val, nested): <TAB> parts = name.split(""."") <TAB> cur = nested <TAB> for i in range(0, len(parts) - 1): <TAB> <TAB> cur = cur.setdefault(parts[i], {}) <TAB> <TAB> if not isinstance(cur, dict): <TAB> <TAB> <TAB> conflicts_with = ""."".join(parts[0 : i + 1]) <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""%r cannot be nested: conflicts with {%r: %s}"" <TAB> <TAB> <TAB> <TAB> % (name, conflicts_with, cur) <TAB> <TAB> <TAB> ) <TAB> cur[parts[-1]] = val",true,"if not isinstance ( cur , dict ) :","if not isinstance ( cur , dict ) :",0.75,0.0
"def build_packages(targeted_packages, distribution_directory, is_dev_build=False): <TAB> # run the build and distribution <TAB> for package_root in targeted_packages: <TAB> <TAB> service_hierarchy = os.path.join(os.path.basename(package_root)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> verify_update_package_requirement(package_root) <TAB> <TAB> print(""Generating Package Using Python {}"".format(sys.version)) <TAB> <TAB> run_check_call( <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> sys.executable, <TAB> <TAB> <TAB> <TAB> build_packing_script_location, <TAB> <TAB> <TAB> <TAB> ""--dest"", <TAB> <TAB> <TAB> <TAB> os.path.join(distribution_directory, service_hierarchy), <TAB> <TAB> <TAB> <TAB> package_root, <TAB> <TAB> <TAB> ], <TAB> <TAB> <TAB> root_dir, <TAB> <TAB> )",true,if is_dev_build :,if is_dev_build :,0.53,0.0
"def resolve_root_node_address(self, root_node): <TAB> if ""["" in root_node: <TAB> <TAB> name, numbers = root_node.split(""["", maxsplit=1) <TAB> <TAB> number = numbers.split("","", maxsplit=1)[0] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> number = number.split(""-"")[0] <TAB> <TAB> number = re.sub(""[^0-9]"", """", number) <TAB> <TAB> root_node = name + number <TAB> return root_node",true,"if ""-"" in number :","if ""-"" in number :",0.75,0.0
"def _map_args(maps: dict, **kwargs): <TAB> # maps: key=old name, value= new name <TAB> output = {} <TAB> for name, val in kwargs.items(): <TAB> <TAB> if name in maps: <TAB> <TAB> <TAB> assert isinstance(maps[name], str) <TAB> <TAB> <TAB> output.update({maps[name]: val}) <TAB> <TAB> else: <TAB> <TAB> <TAB> output.update({name: val}) <TAB> for keys in maps.keys(): <TAB> <TAB> if keys not in output.keys(): <TAB> <TAB> <TAB> pass <TAB> return output",true,if keys not in output . keys ( ) :,if keys not in output . keys ( ) :,0.75,0.0
"def next_item(self, direction): <TAB> """"""Selects next menu item, based on self._direction"""""" <TAB> start, i = -1, 0 <TAB> try: <TAB> <TAB> start = self.items.index(self._selected) <TAB> <TAB> i = start + direction <TAB> except: <TAB> <TAB> pass <TAB> while True: <TAB> <TAB> if i == start: <TAB> <TAB> <TAB> # Cannot find valid menu item <TAB> <TAB> <TAB> self.select(start) <TAB> <TAB> <TAB> break <TAB> <TAB> if i >= len(self.items): <TAB> <TAB> <TAB> i = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> if i < 0: <TAB> <TAB> <TAB> i = len(self.items) - 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> if self.select(i): <TAB> <TAB> <TAB> break <TAB> <TAB> i += direction <TAB> <TAB> if start < 0: <TAB> <TAB> <TAB> start = 0",false,if i >= len ( self . items ) :,if self . select ( i ) :,0.04,0.0
"def detect_reentrancy(self, contract): <TAB> for function in contract.functions_and_modifiers_declared: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if self.KEY in function.context: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self._explore(function.entry_point, []) <TAB> <TAB> <TAB> function.context[self.KEY] = True",false,if function . is_implemented :,if function . contract_type == contract . contract_type :,0.19,0.0
"def load_model(self): <TAB> if not os.path.exists(self.get_filename(absolute=True)): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return {}, {} <TAB> <TAB> error( <TAB> <TAB> <TAB> ""Model file with pre-trained convolution layers not found. Download it here..."", <TAB> <TAB> <TAB> ""https://github.com/alexjc/neural-enhance/releases/download/v%s/%s"" <TAB> <TAB> <TAB> % (__version__, self.get_filename()), <TAB> <TAB> ) <TAB> print(""  - Loaded file `{}` with trained model."".format(self.get_filename())) <TAB> return pickle.load(bz2.open(self.get_filename(), ""rb""))",false,if args . train :,if self . layers is None :,0.11,0.0
"def get_nonexisting_check_definition_extends(definition, indexed_oval_defs): <TAB> # TODO: handle multiple levels of referrals. <TAB> # OVAL checks that go beyond one level of extend_definition won't be properly identified <TAB> for extdefinition in definition.findall("".//{%s}extend_definition"" % oval_ns): <TAB> <TAB> # Verify each extend_definition in the definition <TAB> <TAB> extdefinitionref = extdefinition.get(""definition_ref"") <TAB> <TAB> # Search the OVAL tree for a definition with the referred ID <TAB> <TAB> referreddefinition = indexed_oval_defs.get(extdefinitionref) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # There is no oval satisfying the extend_definition referal <TAB> <TAB> <TAB> return extdefinitionref <TAB> return None",true,if referreddefinition is None :,if referreddefinition is None :,0.75,0.0
"def pause(self): <TAB> if self.is_playing: <TAB> <TAB> self.state = MusicPlayerState.PAUSED <TAB> <TAB> if self._current_player: <TAB> <TAB> <TAB> self._current_player.pause() <TAB> <TAB> self.emit(""pause"", player=self, entry=self.current_entry) <TAB> <TAB> return <TAB> elif self.is_paused: <TAB> <TAB> return <TAB> raise ValueError(""Cannot pause a MusicPlayer in state %s"" % self.state)",true,if self . _current_player :,if self . _current_player :,0.75,0.0
"def setNextFormPrevious(self, backup=STARTING_FORM): <TAB> try: <TAB> <TAB> if self._THISFORM.FORM_NAME == self._FORM_VISIT_LIST[-1]: <TAB> <TAB> <TAB> self._FORM_VISIT_LIST.pop()  # Remove the current form. if it is at the end of the list <TAB> <TAB> if self._THISFORM.FORM_NAME == self.NEXT_ACTIVE_FORM: <TAB> <TAB> <TAB> # take no action if it looks as if someone has already set the next form. <TAB> <TAB> <TAB> self.setNextForm( <TAB> <TAB> <TAB> <TAB> self._FORM_VISIT_LIST.pop() <TAB> <TAB> <TAB> )  # Switch to the previous form if one exists <TAB> except IndexError: <TAB> <TAB> self.setNextForm(backup)",true,if self . _THISFORM . FORM_NAME == self . _FORM_VISIT_LIST [ - 1 ] :,if self . _THISFORM . FORM_NAME == self . _FORM_VISIT_LIST [ - 1 ] :,1.0,0.0
"def get_expr_referrers(schema: s_schema.Schema, obj: so.Object) -> Dict[so.Object, str]: <TAB> """"""Return schema referrers with refs in expressions."""""" <TAB> refs = schema.get_referrers_ex(obj) <TAB> result = {} <TAB> for (mcls, fn), referrers in refs.items(): <TAB> <TAB> field = mcls.get_field(fn) <TAB> <TAB> if issubclass(field.type, (Expression, ExpressionList)): <TAB> <TAB> <TAB> result.update({ref: fn for ref in referrers}) <TAB> return result",true,"if issubclass ( field . type , ( Expression , ExpressionList ) ) :","if issubclass ( field . type , ( Expression , ExpressionList ) ) :",0.75,0.0
"def _fields_to_index(cls): <TAB> fields = [] <TAB> for field in cls._meta.sorted_fields: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> requires_index = any( <TAB> <TAB> <TAB> (field.index, field.unique, isinstance(field, ForeignKeyField)) <TAB> <TAB> ) <TAB> <TAB> if requires_index: <TAB> <TAB> <TAB> fields.append(field) <TAB> return fields",false,if field . primary_key :,if field . index is None :,0.2,0.0
"def ident_values(self): <TAB> value = self._ident_values <TAB> if value is False: <TAB> <TAB> value = None <TAB> <TAB> # XXX: how will this interact with orig_prefix ? <TAB> <TAB> # <TAB>  not exposing attrs for now if orig_prefix is set. <TAB> <TAB> if not self.orig_prefix: <TAB> <TAB> <TAB> wrapped = self.wrapped <TAB> <TAB> <TAB> idents = getattr(wrapped, ""ident_values"", None) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> value = [self._wrap_hash(ident) for ident in idents] <TAB> <TAB> <TAB> ##else: <TAB> <TAB> <TAB> ## <TAB>ident = self.ident <TAB> <TAB> <TAB> ## <TAB>if ident is not None: <TAB> <TAB> <TAB> ## <TAB> <TAB>value = [ident] <TAB> <TAB> self._ident_values = value <TAB> return value",false,if idents :,if idents is not None :,0.09,0.0
"def apply_incpaths_ml(self): <TAB> inc_lst = self.includes.split() <TAB> lst = self.incpaths_lst <TAB> for dir in inc_lst: <TAB> <TAB> node = self.path.find_dir(dir) <TAB> <TAB> if not node: <TAB> <TAB> <TAB> error(""node not found: "" + str(dir)) <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> lst.append(node) <TAB> <TAB> self.bld_incpaths_lst.append(node)",false,if not node in lst :,if node not in lst :,0.37,0.0
"def application_openFiles_(self, nsapp, filenames): <TAB> # logging.info('[osx] file open') <TAB> # logging.info('[osx] file : %s' % (filenames)) <TAB> for filename in filenames: <TAB> <TAB> logging.info(""[osx] receiving from macOS : %s"", filename) <TAB> <TAB> if os.path.exists(filename): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> sabnzbd.add_nzbfile(filename, keep=True)",false,if sabnzbd . filesystem . get_ext ( filename ) in VALID_ARCHIVES + VALID_NZB_FILES :,if nsapp == nsapp :,0.01,0.0
"def check(self, xp, nout): <TAB> input = xp.asarray(self.x).astype(numpy.float32) <TAB> with warnings.catch_warnings(): <TAB> <TAB> if self.ignore_warning: <TAB> <TAB> <TAB> warnings.simplefilter(""ignore"", self.ignore_warning) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.check_positive(xp, self.func, input, self.eps, nout) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.check_negative(xp, self.func, input, self.eps, nout)",false,if self . result :,if self . positive :,0.39,0.0
"def _set_scheme(url, newscheme): <TAB> scheme = _get_scheme(url) <TAB> newscheme = newscheme or """" <TAB> newseparator = "":"" if newscheme in COLON_SEPARATED_SCHEMES else ""://"" <TAB> if scheme == """":  # Protocol relative URL. <TAB> <TAB> url = ""%s:%s"" % (newscheme, url) <TAB> elif scheme is None and url:  # No scheme. <TAB> <TAB> url = """".join([newscheme, newseparator, url]) <TAB> elif scheme:  # Existing scheme. <TAB> <TAB> remainder = url[len(scheme) :] <TAB> <TAB> if remainder.startswith(""://""): <TAB> <TAB> <TAB> remainder = remainder[3:] <TAB> <TAB> elif remainder.startswith("":""): <TAB> <TAB> <TAB> remainder = remainder[1:] <TAB> <TAB> url = """".join([newscheme, newseparator, remainder]) <TAB> return url",false,"if remainder . startswith ( ""://"" ) :","elif remainder . startswith ( "":"" ) :",0.2,0.0
"def parquet(tables, data_directory, ignore_missing_dependency, **params): <TAB> try: <TAB> <TAB> import pyarrow as pa  # noqa: F401 <TAB> <TAB> import pyarrow.parquet as pq  # noqa: F401 <TAB> except ImportError: <TAB> <TAB> msg = ""PyArrow dependency is missing"" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> logger.warning(""Ignored: %s"", msg) <TAB> <TAB> <TAB> return 0 <TAB> <TAB> else: <TAB> <TAB> <TAB> raise click.ClickException(msg) <TAB> data_directory = Path(data_directory) <TAB> for table, df in read_tables(tables, data_directory): <TAB> <TAB> arrow_table = pa.Table.from_pandas(df) <TAB> <TAB> target_path = data_directory / ""{}.parquet"".format(table) <TAB> <TAB> pq.write_table(arrow_table, str(target_path))",true,if ignore_missing_dependency :,if ignore_missing_dependency :,0.53,0.0
"def h2i(self, pkt, s): <TAB> t = () <TAB> if type(s) is str: <TAB> <TAB> t = time.strptime(s) <TAB> <TAB> t = t[:2] + t[2:-3] <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> y, m, d, h, min, sec, rest, rest, rest = time.gmtime(time.time()) <TAB> <TAB> <TAB> t = (y, m, d, h, min, sec) <TAB> <TAB> else: <TAB> <TAB> <TAB> t = s <TAB> return t",false,if not s :,if type ( s ) is datetime :,0.04,0.0
"def filter_episodes(self, batch, cross_entropy): <TAB> """"""Filter the episodes for the cross_entropy method"""""" <TAB> accumulated_reward = [sum(rewards) for rewards in batch[""rewards""]] <TAB> percentile = cross_entropy * 100 <TAB> reward_bound = np.percentile(accumulated_reward, percentile) <TAB> # we save the batch with reward above the bound <TAB> result = {k: [] for k in self.data_keys} <TAB> episode_kept = 0 <TAB> for i in range(len(accumulated_reward)): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for k in self.data_keys: <TAB> <TAB> <TAB> <TAB> result[k].append(batch[k][i]) <TAB> <TAB> <TAB> episode_kept += 1 <TAB> return result",false,if accumulated_reward [ i ] >= reward_bound :,if reward_bound > episode_kept :,0.02,0.0
"def _readenv(var, msg): <TAB> match = _ENV_VAR_PAT.match(var) <TAB> if match and match.groups(): <TAB> <TAB> envvar = match.groups()[0] <TAB> <TAB> if envvar in os.environ: <TAB> <TAB> <TAB> value = os.environ[envvar] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> value = value.decode(""utf8"") <TAB> <TAB> <TAB> return value <TAB> <TAB> else: <TAB> <TAB> <TAB> raise InvalidConfigException( <TAB> <TAB> <TAB> <TAB> ""{} - environment variable '{}' not set"".format(msg, var) <TAB> <TAB> <TAB> ) <TAB> else: <TAB> <TAB> raise InvalidConfigException( <TAB> <TAB> <TAB> ""{} - environment variable name '{}' does not match pattern '{}'"".format( <TAB> <TAB> <TAB> <TAB> msg, var, _ENV_VAR_PAT_STR <TAB> <TAB> <TAB> ) <TAB> <TAB> )",true,if six . PY2 :,if six . PY2 :,0.75,0.0
"def _allocate_nbd(self): <TAB> if not os.path.exists(""/sys/block/nbd0""): <TAB> <TAB> self.error = _(""nbd unavailable: module not loaded"") <TAB> <TAB> return None <TAB> while True: <TAB> <TAB> if not self._DEVICES: <TAB> <TAB> <TAB> # really want to log this info, not raise <TAB> <TAB> <TAB> self.error = _(""No free nbd devices"") <TAB> <TAB> <TAB> return None <TAB> <TAB> device = self._DEVICES.pop() <TAB> <TAB> if not os.path.exists(""/sys/block/%s/pid"" % os.path.basename(device)): <TAB> <TAB> <TAB> break <TAB> return device",true,"if not os . path . exists ( ""/sys/block/%s/pid"" % os . path . basename ( device ) ) :","if not os . path . exists ( ""/sys/block/%s/pid"" % os . path . basename ( device ) ) :",1.0,0.0
"def _expand_deps_java_generation(self): <TAB> """"""Ensure that all multilingual dependencies such as proto_library generate java code."""""" <TAB> queue = collections.deque(self.deps) <TAB> keys = set() <TAB> while queue: <TAB> <TAB> k = queue.popleft() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> keys.add(k) <TAB> <TAB> <TAB> dep = self.target_database[k] <TAB> <TAB> <TAB> if ""generate_java"" in dep.attr:  # Has this attribute <TAB> <TAB> <TAB> <TAB> dep.attr[""generate_java""] = True <TAB> <TAB> <TAB> <TAB> queue.extend(dep.deps)",true,if k not in keys :,if k not in keys :,0.75,0.0
"def load_syntax(syntax): <TAB> context = _create_scheme() or {} <TAB> partition_scanner = PartitionScanner(syntax.get(""partitions"", [])) <TAB> scanners = {} <TAB> for part_name, part_scanner in list(syntax.get(""scanner"", {}).items()): <TAB> <TAB> scanners[part_name] = Scanner(part_scanner) <TAB> formats = [] <TAB> for fname, fstyle in list(syntax.get(""formats"", {}).items()): <TAB> <TAB> if isinstance(fstyle, basestring): <TAB> <TAB> <TAB> if fstyle.startswith(""%("") and fstyle.endswith("")s""): <TAB> <TAB> <TAB> <TAB> key = fstyle[2:-2] <TAB> <TAB> <TAB> <TAB> fstyle = context[key] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> fstyle = fstyle % context <TAB> <TAB> formats.append((fname, fstyle)) <TAB> return partition_scanner, scanners, formats",false,"if fstyle . startswith ( ""%("" ) and fstyle . endswith ( "")s"" ) :","if isinstance ( fstyle , basestring ) :",0.02,0.0
"def rollback(self): <TAB> for operation, values in self.current_transaction_state[::-1]: <TAB> <TAB> if operation == ""insert"": <TAB> <TAB> <TAB> values.remove() <TAB> <TAB> elif operation == ""update"": <TAB> <TAB> <TAB> old_value, new_value = values <TAB> <TAB> <TAB> if new_value.full_filename != old_value.full_filename: <TAB> <TAB> <TAB> <TAB> os.unlink(new_value.full_filename) <TAB> <TAB> <TAB> old_value.write() <TAB> self._post_xact_cleanup()",true,"if operation == ""insert"" :","if operation == ""insert"" :",0.75,0.0
"def _buildOffsets(offsetDict, localeData, indexStart): <TAB> o = indexStart <TAB> for key in localeData: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for k in key.split(""|""): <TAB> <TAB> <TAB> <TAB> offsetDict[k] = o <TAB> <TAB> else: <TAB> <TAB> <TAB> offsetDict[key] = o <TAB> <TAB> o += 1",true,"if ""|"" in key :","if ""|"" in key :",0.75,0.0
"def _check_start_pipeline_execution_errors( <TAB> graphene_info, execution_params, execution_plan ): <TAB> if execution_params.step_keys: <TAB> <TAB> for step_key in execution_params.step_keys: <TAB> <TAB> <TAB> if not execution_plan.has_step(step_key): <TAB> <TAB> <TAB> <TAB> raise UserFacingGraphQLError( <TAB> <TAB> <TAB> <TAB> <TAB> graphene_info.schema.type_named(""InvalidStepError"")( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> invalid_step_key=step_key <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> )",true,if not execution_plan . has_step ( step_key ) :,if not execution_plan . has_step ( step_key ) :,0.75,0.0
"def __setattr__(self, option_name, option_value): <TAB> if option_name in self._options: <TAB> <TAB> # type checking <TAB> <TAB> sort = self.OPTIONS[self.arch.name][option_name][0] <TAB> <TAB> if sort is None or isinstance(option_value, sort): <TAB> <TAB> <TAB> self._options[option_name] = option_value <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> 'Value for option ""%s"" must be of type %s' % (option_name, sort) <TAB> <TAB> <TAB> ) <TAB> else: <TAB> <TAB> super(CFGArchOptions, self).__setattr__(option_name, option_value)",true,"if sort is None or isinstance ( option_value , sort ) :","if sort is None or isinstance ( option_value , sort ) :",0.75,0.0
"def value(self): <TAB> quote = False <TAB> if self.defects: <TAB> <TAB> quote = True <TAB> else: <TAB> <TAB> for x in self: <TAB> <TAB> <TAB> if x.token_type == ""quoted-string"": <TAB> <TAB> <TAB> <TAB> quote = True <TAB> if quote: <TAB> <TAB> pre = post = """" <TAB> <TAB> if self[0].token_type == ""cfws"" or self[0][0].token_type == ""cfws"": <TAB> <TAB> <TAB> pre = "" "" <TAB> <TAB> if self[-1].token_type == ""cfws"" or self[-1][-1].token_type == ""cfws"": <TAB> <TAB> <TAB> post = "" "" <TAB> <TAB> return pre + quote_string(self.display_name) + post <TAB> else: <TAB> <TAB> return super(DisplayName, self).value",false,"if x . token_type == ""quoted-string"" :","if self [ 0 ] . token_type == ""cfws"" or self [ 0 ] [ 0 ] . token_type == ""cfws"" :",0.06,0.0
"def __init__(self, patch_files, patch_directories): <TAB> files = [] <TAB> files_data = {} <TAB> for filename_data in patch_files: <TAB> <TAB> if isinstance(filename_data, list): <TAB> <TAB> <TAB> filename, data = filename_data <TAB> <TAB> else: <TAB> <TAB> <TAB> filename = filename_data <TAB> <TAB> <TAB> data = None <TAB> <TAB> if not filename.startswith(os.sep): <TAB> <TAB> <TAB> filename = ""{0}{1}"".format(FakeState.deploy_dir, filename) <TAB> <TAB> files.append(filename) <TAB> <TAB> if data: <TAB> <TAB> <TAB> files_data[filename] = data <TAB> self.files = files <TAB> self.files_data = files_data <TAB> self.directories = patch_directories",true,"if isinstance ( filename_data , list ) :","if isinstance ( filename_data , list ) :",0.75,0.0
"def _evaluateStack(s): <TAB> op = s.pop() <TAB> if op in ""+-*/@^"": <TAB> <TAB> op2 = _evaluateStack(s) <TAB> <TAB> op1 = _evaluateStack(s) <TAB> <TAB> result = opn[op](op1, op2) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(result) <TAB> <TAB> return result <TAB> else: <TAB> <TAB> return op",false,if debug_flag :,if DEBUG :,0.32,0.0
"def reconnect_user(self, user_id, host_id, server_id): <TAB> if host_id == settings.local.host_id: <TAB> <TAB> return <TAB> if server_id and self.server.id != server_id: <TAB> <TAB> return <TAB> for client in self.clients.find({""user_id"": user_id}): <TAB> <TAB> self.clients.update_id( <TAB> <TAB> <TAB> client[""id""], <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> ""ignore_routes"": True, <TAB> <TAB> <TAB> }, <TAB> <TAB> ) <TAB> <TAB> if len(client[""id""]) > 32: <TAB> <TAB> <TAB> self.instance.disconnect_wg(client[""id""]) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.instance_com.client_kill(client[""id""])",true,"if len ( client [ ""id"" ] ) > 32 :","if len ( client [ ""id"" ] ) > 32 :",0.75,0.0
"def _get_library(self, name, args): <TAB> library_database = self._library_manager.get_new_connection_to_library_database() <TAB> try: <TAB> <TAB> last_updated = library_database.get_library_last_updated(name, args) <TAB> <TAB> if last_updated: <TAB> <TAB> <TAB> if time.time() - last_updated > 10.0: <TAB> <TAB> <TAB> <TAB> self._library_manager.fetch_keywords( <TAB> <TAB> <TAB> <TAB> <TAB> name, args, self._libraries_need_refresh_listener <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return library_database.fetch_library_keywords(name, args) <TAB> <TAB> return self._library_manager.get_and_insert_keywords(name, args) <TAB> finally: <TAB> <TAB> library_database.close()",true,if time . time ( ) - last_updated > 10.0 :,if time . time ( ) - last_updated > 10.0 :,1.0,0.0
"def get_paths(self, path, commit): <TAB> """"""Return a generator of all filepaths under path at commit."""""" <TAB> _check_path_is_repo_relative(path) <TAB> git_path = _get_git_path(path) <TAB> tree = self.gl_repo.git_repo[commit.tree[git_path].id] <TAB> assert tree.type == pygit2.GIT_OBJ_TREE <TAB> for tree_entry in tree: <TAB> <TAB> tree_entry_path = os.path.join(path, tree_entry.name) <TAB> <TAB> if tree_entry.type == ""tree"": <TAB> <TAB> <TAB> for fp in self.get_paths(tree_entry_path, commit): <TAB> <TAB> <TAB> <TAB> yield fp <TAB> <TAB> else: <TAB> <TAB> <TAB> yield tree_entry_path",true,"if tree_entry . type == ""tree"" :","if tree_entry . type == ""tree"" :",0.75,0.0
"def scan_resource_conf(self, conf): <TAB> if ""properties"" in conf: <TAB> <TAB> if ""attributes"" in conf[""properties""]: <TAB> <TAB> <TAB> if ""exp"" in conf[""properties""][""attributes""]: <TAB> <TAB> <TAB> <TAB> if conf[""properties""][""attributes""][""exp""]: <TAB> <TAB> <TAB> <TAB> <TAB> return CheckResult.PASSED <TAB> return CheckResult.FAILED",true,"if ""exp"" in conf [ ""properties"" ] [ ""attributes"" ] :","if ""exp"" in conf [ ""properties"" ] [ ""attributes"" ] :",0.75,0.0
"def _set_parse_context(self, tag, tag_attrs): <TAB> # special case: script or style parse context <TAB> if not self._wb_parse_context: <TAB> <TAB> if tag == ""style"": <TAB> <TAB> <TAB> self._wb_parse_context = ""style"" <TAB> <TAB> elif tag == ""script"": <TAB> <TAB> <TAB> if self._allow_js_type(tag_attrs): <TAB> <TAB> <TAB> <TAB> self._wb_parse_context = ""script""",false,if self . _allow_js_type ( tag_attrs ) :,"if tag == ""style"" :",0.02,0.0
"def modified(self): <TAB> paths = set() <TAB> dictionary_list = [] <TAB> for op_list in self._operations: <TAB> <TAB> if not isinstance(op_list, list): <TAB> <TAB> <TAB> op_list = (op_list,) <TAB> <TAB> for item in chain(*op_list): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> dictionary = item.dictionary <TAB> <TAB> <TAB> if dictionary.path in paths: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> paths.add(dictionary.path) <TAB> <TAB> <TAB> dictionary_list.append(dictionary) <TAB> return dictionary_list",false,if item is None :,if item . dictionary is None :,0.2,0.0
def preorder(root): <TAB> res = [] <TAB> if not root: <TAB> <TAB> return res <TAB> stack = [] <TAB> stack.append(root) <TAB> while stack: <TAB> <TAB> root = stack.pop() <TAB> <TAB> res.append(root.val) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> stack.append(root.right) <TAB> <TAB> if root.left: <TAB> <TAB> <TAB> stack.append(root.left) <TAB> return res,true,if root . right :,if root . right :,0.75,0.0
"def create(exported_python_target): <TAB> if exported_python_target not in created: <TAB> <TAB> self.context.log.info( <TAB> <TAB> <TAB> ""Creating setup.py project for {}"".format(exported_python_target) <TAB> <TAB> ) <TAB> <TAB> subject = self.derived_by_original.get( <TAB> <TAB> <TAB> exported_python_target, exported_python_target <TAB> <TAB> ) <TAB> <TAB> setup_dir, dependencies = self.create_setup_py(subject, dist_dir) <TAB> <TAB> created[exported_python_target] = setup_dir <TAB> <TAB> if self._recursive: <TAB> <TAB> <TAB> for dep in dependencies: <TAB> <TAB> <TAB> <TAB> if is_exported_python_target(dep): <TAB> <TAB> <TAB> <TAB> <TAB> create(dep)",false,if is_exported_python_target ( dep ) :,if self . _recursive :,0.03,0.0
"def test_array_interface(self, data): <TAB> result = np.array(data) <TAB> np.testing.assert_array_equal(result[0], data[0]) <TAB> result = np.array(data, dtype=object) <TAB> expected = np.array(list(data), dtype=object) <TAB> for a1, a2 in zip(result, expected): <TAB> <TAB> if np.isscalar(a1): <TAB> <TAB> <TAB> assert np.isnan(a1) and np.isnan(a2) <TAB> <TAB> else: <TAB> <TAB> <TAB> tm.assert_numpy_array_equal(a2, a1)",true,if np . isscalar ( a1 ) :,if np . isscalar ( a1 ) :,0.75,0.0
"def valueChanged(plug): <TAB> changed = plug.getInput() is not None <TAB> if not changed and isinstance(plug, Gaffer.ValuePlug): <TAB> <TAB> if Gaffer.NodeAlgo.hasUserDefault(plug): <TAB> <TAB> <TAB> changed = not Gaffer.NodeAlgo.isSetToUserDefault(plug) <TAB> <TAB> else: <TAB> <TAB> <TAB> changed = not plug.isSetToDefault() <TAB> return changed",true,if Gaffer . NodeAlgo . hasUserDefault ( plug ) :,if Gaffer . NodeAlgo . hasUserDefault ( plug ) :,0.75,0.0
"def process_tag(hive_name, company, company_key, tag, default_arch): <TAB> with winreg.OpenKeyEx(company_key, tag) as tag_key: <TAB> <TAB> version = load_version_data(hive_name, company, tag, tag_key) <TAB> <TAB><IF-STMT>  # if failed to get version bail <TAB> <TAB> <TAB> major, minor, _ = version <TAB> <TAB> <TAB> arch = load_arch_data(hive_name, company, tag, tag_key, default_arch) <TAB> <TAB> <TAB> if arch is not None: <TAB> <TAB> <TAB> <TAB> exe_data = load_exe(hive_name, company, company_key, tag) <TAB> <TAB> <TAB> <TAB> if exe_data is not None: <TAB> <TAB> <TAB> <TAB> <TAB> exe, args = exe_data <TAB> <TAB> <TAB> <TAB> <TAB> return company, major, minor, arch, exe, args",true,if version is not None :,if version is not None :,0.75,0.0
"def __iter__(self): <TAB> for name, value in self.__class__.__dict__.items(): <TAB> <TAB> if isinstance(value, alias_flag_value): <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance(value, flag_value): <TAB> <TAB> <TAB> yield (name, self._has_flag(value.flag))",false,"if isinstance ( value , flag_value ) :","if isinstance ( value , alias_flag_value ) :",0.55,0.0
"def connect(self): <TAB> self.sock = sockssocket() <TAB> self.sock.setproxy(*proxy_args) <TAB> if type(self.timeout) in (int, float): <TAB> <TAB> self.sock.settimeout(self.timeout) <TAB> self.sock.connect((self.host, self.port)) <TAB> if isinstance(self, compat_http_client.HTTPSConnection): <TAB> <TAB> if hasattr(self, ""_context""):  # Python > 2.6 <TAB> <TAB> <TAB> self.sock = self._context.wrap_socket(self.sock, server_hostname=self.host) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.sock = ssl.wrap_socket(self.sock)",true,"if hasattr ( self , ""_context"" ) :","if hasattr ( self , ""_context"" ) :",0.75,0.0
"def frequent_thread_switches(): <TAB> """"""Make concurrency bugs more likely to manifest."""""" <TAB> interval = None <TAB> if not sys.platform.startswith(""java""): <TAB> <TAB> if hasattr(sys, ""getswitchinterval""): <TAB> <TAB> <TAB> interval = sys.getswitchinterval() <TAB> <TAB> <TAB> sys.setswitchinterval(1e-6) <TAB> <TAB> else: <TAB> <TAB> <TAB> interval = sys.getcheckinterval() <TAB> <TAB> <TAB> sys.setcheckinterval(1) <TAB> try: <TAB> <TAB> yield <TAB> finally: <TAB> <TAB> if not sys.platform.startswith(""java""): <TAB> <TAB> <TAB> if hasattr(sys, ""setswitchinterval""): <TAB> <TAB> <TAB> <TAB> sys.setswitchinterval(interval) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> sys.setcheckinterval(interval)",true,"if hasattr ( sys , ""setswitchinterval"" ) :","if hasattr ( sys , ""setswitchinterval"" ) :",0.75,0.0
"def vars(self): <TAB> ret = [] <TAB> if op.intlist: <TAB> <TAB> varlist = op.intlist <TAB> else: <TAB> <TAB> varlist = self.discover <TAB> <TAB> for name in varlist: <TAB> <TAB> <TAB> if name in (""0"", ""1"", ""2"", ""8"", ""CPU0"", ""ERR"", ""LOC"", ""MIS"", ""NMI""): <TAB> <TAB> <TAB> <TAB> varlist.remove(name) <TAB> <TAB> if not op.full and len(varlist) > 3: <TAB> <TAB> <TAB> varlist = varlist[-3:] <TAB> for name in varlist: <TAB> <TAB> if name in self.discover: <TAB> <TAB> <TAB> ret.append(name) <TAB> <TAB> elif name.lower() in self.intmap: <TAB> <TAB> <TAB> ret.append(self.intmap[name.lower()]) <TAB> return ret",true,elif name . lower ( ) in self . intmap :,elif name . lower ( ) in self . intmap :,0.75,0.0
"def deleteDuplicates(gadgets, callback=None): <TAB> toReturn = [] <TAB> inst = set() <TAB> count = 0 <TAB> added = False <TAB> len_gadgets = len(gadgets) <TAB> for i, gadget in enumerate(gadgets): <TAB> <TAB> inst.add(gadget._gadget) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> count = len(inst) <TAB> <TAB> <TAB> toReturn.append(gadget) <TAB> <TAB> <TAB> added = True <TAB> <TAB> if callback: <TAB> <TAB> <TAB> callback(gadget, added, float(i + 1) / (len_gadgets)) <TAB> <TAB> <TAB> added = False <TAB> return toReturn",false,if len ( inst ) > count :,if count == len_gadgets :,0.02,0.0
"def ident(self): <TAB> value = self._ident <TAB> if value is False: <TAB> <TAB> value = None <TAB> <TAB> # XXX: how will this interact with orig_prefix ? <TAB> <TAB> # <TAB>  not exposing attrs for now if orig_prefix is set. <TAB> <TAB> if not self.orig_prefix: <TAB> <TAB> <TAB> wrapped = self.wrapped <TAB> <TAB> <TAB> ident = getattr(wrapped, ""ident"", None) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> value = self._wrap_hash(ident) <TAB> <TAB> self._ident = value <TAB> return value",true,if ident is not None :,if ident is not None :,0.75,0.0
"def _flatten_settings_from_form(self, settings, form, form_values): <TAB> """"""Take a nested dict and return a flat dict of setting values."""""" <TAB> setting_values = {} <TAB> for field in form.c: <TAB> <TAB> if isinstance(field, _ContainerMixin): <TAB> <TAB> <TAB> setting_values.update( <TAB> <TAB> <TAB> <TAB> self._flatten_settings_from_form( <TAB> <TAB> <TAB> <TAB> <TAB> settings, field, form_values[field._name] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> elif field._name in settings: <TAB> <TAB> <TAB> setting_values[field._name] = form_values[field._name] <TAB> return setting_values",true,elif field . _name in settings :,elif field . _name in settings :,0.75,0.0
"def _decorator(cls): <TAB> for name, meth in inspect.getmembers(cls, inspect.isroutine): <TAB> <TAB> if name not in cls.__dict__: <TAB> <TAB> <TAB> continue <TAB> <TAB> if name != ""__init__"": <TAB> <TAB> <TAB> if not private and name.startswith(""_""): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> if name in butnot: <TAB> <TAB> <TAB> continue <TAB> <TAB> setattr(cls, name, decorator(meth)) <TAB> return cls",false,"if not private and name . startswith ( ""_"" ) :","if name != ""__init__"" :",0.01,0.0
"def _do_cmp(f1, f2): <TAB> bufsize = BUFSIZE <TAB> with open(f1, ""rb"") as fp1, open(f2, ""rb"") as fp2: <TAB> <TAB> while True: <TAB> <TAB> <TAB> b1 = fp1.read(bufsize) <TAB> <TAB> <TAB> b2 = fp2.read(bufsize) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> if not b1: <TAB> <TAB> <TAB> <TAB> return True",true,if b1 != b2 :,if b1 != b2 :,0.75,0.0
"def _memoized(*args): <TAB> now = time.time() <TAB> try: <TAB> <TAB> value, last_update = self.cache[args] <TAB> <TAB> age = now - last_update <TAB> <TAB> if self._call_count > self.ctl or age > self.ttl: <TAB> <TAB> <TAB> self._call_count = 0 <TAB> <TAB> <TAB> raise AttributeError <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._call_count += 1 <TAB> <TAB> return value <TAB> except (KeyError, AttributeError): <TAB> <TAB> value = func(*args) <TAB> <TAB> if value: <TAB> <TAB> <TAB> self.cache[args] = (value, now) <TAB> <TAB> return value <TAB> except TypeError: <TAB> <TAB> return func(*args)",false,if self . ctl :,if age < self . ttl :,0.14,0.0
"def check(self, hyperlinks: Dict[str, Hyperlink]) -> Generator[CheckResult, None, None]: <TAB> self.invoke_threads() <TAB> total_links = 0 <TAB> for hyperlink in hyperlinks.values(): <TAB> <TAB> if self.is_ignored_uri(hyperlink.uri): <TAB> <TAB> <TAB> yield CheckResult( <TAB> <TAB> <TAB> <TAB> hyperlink.uri, hyperlink.docname, hyperlink.lineno, ""ignored"", """", 0 <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.wqueue.put(CheckRequest(CHECK_IMMEDIATELY, hyperlink), False) <TAB> <TAB> <TAB> total_links += 1 <TAB> done = 0 <TAB> while done < total_links: <TAB> <TAB> yield self.rqueue.get() <TAB> <TAB> done += 1 <TAB> self.shutdown_threads()",true,if self . is_ignored_uri ( hyperlink . uri ) :,if self . is_ignored_uri ( hyperlink . uri ) :,0.75,0.0
"def remove_subscriber(self, topic, subscriber): <TAB> if subscriber in self.subscribers[topic]: <TAB> <TAB> if hasattr(subscriber, ""_pyroRelease""): <TAB> <TAB> <TAB> subscriber._pyroRelease() <TAB> <TAB> if hasattr(subscriber, ""_pyroUri""): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> proxy = self.proxy_cache[subscriber._pyroUri] <TAB> <TAB> <TAB> <TAB> proxy._pyroRelease() <TAB> <TAB> <TAB> <TAB> del self.proxy_cache[subscriber._pyroUri] <TAB> <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> self.subscribers[topic].discard(subscriber)",true,"if hasattr ( subscriber , ""_pyroRelease"" ) :","if hasattr ( subscriber , ""_pyroRelease"" ) :",0.75,0.0
"def delete_arc(collection, document, origin, target, type): <TAB> directory = collection <TAB> real_dir = real_directory(directory) <TAB> mods = ModificationTracker() <TAB> projectconf = ProjectConfiguration(real_dir) <TAB> document = path_join(real_dir, document) <TAB> with TextAnnotations(document) as ann_obj: <TAB> <TAB> # bail as quick as possible if read-only <TAB> <TAB> if ann_obj._read_only: <TAB> <TAB> <TAB> raise AnnotationsIsReadOnlyError(ann_obj.get_document()) <TAB> <TAB> _delete_arc_with_ann(origin, target, type, mods, ann_obj, projectconf) <TAB> <TAB> mods_json = mods.json_response() <TAB> <TAB> mods_json[""annotations""] = _json_from_ann(ann_obj) <TAB> <TAB> return mods_json",true,if ann_obj . _read_only :,if ann_obj . _read_only :,0.75,0.0
"def _select_from(self, parent_path, is_dir, exists, listdir): <TAB> if not is_dir(parent_path): <TAB> <TAB> return <TAB> with _cached(listdir) as listdir: <TAB> <TAB> yielded = set() <TAB> <TAB> try: <TAB> <TAB> <TAB> successor_select = self.successor._select_from <TAB> <TAB> <TAB> for starting_point in self._iterate_directories( <TAB> <TAB> <TAB> <TAB> parent_path, is_dir, listdir <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> for p in successor_select(starting_point, is_dir, exists, listdir): <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield p <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yielded.add(p) <TAB> <TAB> finally: <TAB> <TAB> <TAB> yielded.clear()",true,if p not in yielded :,if p not in yielded :,0.75,0.0
"def _fractional_part(self, n, expr, evaluation): <TAB> n_sympy = n.to_sympy() <TAB> if n_sympy.is_constant(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> positive_integer_part = ( <TAB> <TAB> <TAB> <TAB> Expression(""Floor"", n).evaluate(evaluation).to_python() <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> result = n - positive_integer_part <TAB> <TAB> else: <TAB> <TAB> <TAB> negative_integer_part = ( <TAB> <TAB> <TAB> <TAB> Expression(""Ceiling"", n).evaluate(evaluation).to_python() <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> result = n - negative_integer_part <TAB> else: <TAB> <TAB> return expr <TAB> return from_python(result)",false,if n_sympy >= 0 :,if self . is_floor :,0.03,0.0
"def check_bounds(geometry): <TAB> if isinstance(geometry[0], (list, tuple)): <TAB> <TAB> return list(map(check_bounds, geometry)) <TAB> else: <TAB> <TAB> if geometry[0] > 180 or geometry[0] < -180: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""Longitude is out of bounds, check your JSON format or data"" <TAB> <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""Latitude is out of bounds, check your JSON format or data"" <TAB> <TAB> <TAB> )",false,if geometry [ 1 ] > 90 or geometry [ 1 ] < - 90 :,if geometry [ 0 ] > 180 or geometry [ 0 ] < - 180 :,0.58,0.0
"def get_absolute_path(self, root, path): <TAB> # find the first absolute path that exists <TAB> self.root = self.roots[0] <TAB> for root in self.roots: <TAB> <TAB> abspath = os.path.abspath(os.path.join(root, path)) <TAB> <TAB> if os.path.exists(abspath): <TAB> <TAB> <TAB> self.root = root  # make sure all the other methods in the base class know how to find the file <TAB> <TAB> <TAB> break <TAB> return abspath",true,if os . path . exists ( abspath ) :,if os . path . exists ( abspath ) :,0.75,0.0
"def do_setflow(self, l=""""): <TAB> try: <TAB> <TAB> if not isinstance(l, str) or not len(l): <TAB> <TAB> <TAB> l = str(self.flow_slider.GetValue()) <TAB> <TAB> else: <TAB> <TAB> <TAB> l = l.lower() <TAB> <TAB> flow = int(l) <TAB> <TAB> if self.p.online: <TAB> <TAB> <TAB> self.p.send_now(""M221 S"" + l) <TAB> <TAB> <TAB> self.log(_(""Setting print flow factor to %d%%."") % flow) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.logError(_(""Printer is not online."")) <TAB> except Exception as x: <TAB> <TAB> self.logError(_(""You must enter a flow. (%s)"") % (repr(x),))",true,"if not isinstance ( l , str ) or not len ( l ) :","if not isinstance ( l , str ) or not len ( l ) :",1.0,0.0
"def sources(): <TAB> for d in os.listdir(base): <TAB> <TAB> # <TAB> <TAB>if d.startswith('talis'): <TAB> <TAB> # <TAB> <TAB> <TAB>continue <TAB> <TAB> if d.endswith(""old""): <TAB> <TAB> <TAB> continue <TAB> <TAB> if d == ""indcat"": <TAB> <TAB> <TAB> continue <TAB> <TAB> if not os.path.isdir(base + d): <TAB> <TAB> <TAB> continue <TAB> <TAB> yield d",false,"if d . endswith ( ""old"" ) :","if d == ""indcat"" :",0.04,0.0
"def create_accumulator(self) -> tf_metric_accumulators.TFCompilableMetricsAccumulator: <TAB> configs = zip(self._metric_configs, self._loss_configs) <TAB> padding_options = None <TAB> if self._eval_config is not None: <TAB> <TAB> model_spec = model_util.get_model_spec(self._eval_config, self._model_name) <TAB> <TAB> if model_spec is not None and model_spec.HasField(""padding_options""): <TAB> <TAB> <TAB> padding_options = model_spec.padding_options <TAB> return tf_metric_accumulators.TFCompilableMetricsAccumulator( <TAB> <TAB> padding_options, <TAB> <TAB> [len(m) + len(l) for m, l in configs], <TAB> <TAB> desired_batch_size=self._desired_batch_size, <TAB> )",true,"if model_spec is not None and model_spec . HasField ( ""padding_options"" ) :","if model_spec is not None and model_spec . HasField ( ""padding_options"" ) :",0.75,0.0
"def parseImpl(self, instring, loc, doActions=True): <TAB> try: <TAB> <TAB> loc, tokens = self.expr._parse(instring, loc, doActions, callPreParse=False) <TAB> except (ParseException, IndexError): <TAB> <TAB> if self.defaultValue is not self.__optionalNotMatched: <TAB> <TAB> <TAB> if self.expr.resultsName: <TAB> <TAB> <TAB> <TAB> tokens = ParseResults([self.defaultValue]) <TAB> <TAB> <TAB> <TAB> tokens[self.expr.resultsName] = self.defaultValue <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> tokens = [self.defaultValue] <TAB> <TAB> else: <TAB> <TAB> <TAB> tokens = [] <TAB> return loc, tokens",false,if self . defaultValue is not self . __optionalNotMatched :,if self . expr . resultsName :,0.1,0.0
"def handleConnection(self): <TAB> # connection handshake <TAB> try: <TAB> <TAB> if self.daemon._handshake(self.csock): <TAB> <TAB> <TAB> return True <TAB> <TAB> self.csock.close() <TAB> except: <TAB> <TAB> ex_t, ex_v, ex_tb = sys.exc_info() <TAB> <TAB> tb = util.formatTraceback(ex_t, ex_v, ex_tb) <TAB> <TAB> log.warning(""error during connect/handshake: %s; %s"", ex_v, ""\n"".join(tb)) <TAB> <TAB> self.csock.close() <TAB> return False",true,if self . daemon . _handshake ( self . csock ) :,if self . daemon . _handshake ( self . csock ) :,1.0,0.0
"def getProc(su, innerTarget): <TAB> if len(su) == 1:  # have a one element wedge <TAB> <TAB> proc = (""first"", ""last"") <TAB> else: <TAB> <TAB> if su.isFirst(innerTarget) and su.isLast(innerTarget): <TAB> <TAB> <TAB> proc = (""first"", ""last"")  # same element can be first and last <TAB> <TAB> elif su.isFirst(innerTarget): <TAB> <TAB> <TAB> proc = (""first"",) <TAB> <TAB> elif su.isLast(innerTarget): <TAB> <TAB> <TAB> proc = (""last"",) <TAB> <TAB> else: <TAB> <TAB> <TAB> proc = () <TAB> return proc",false,if su . isFirst ( innerTarget ) and su . isLast ( innerTarget ) :,elif su . isFirst ( innerTarget ) :,0.27,0.0
"def get_color_dtype(data, column_names): <TAB> has_color = all(column in data[""points""] for column in column_names) <TAB> if has_color: <TAB> <TAB> color_data_types = [ <TAB> <TAB> <TAB> data[""points""][column_name].dtype for column_name in column_names <TAB> <TAB> ] <TAB> <TAB> if len(set(color_data_types)) > 1: <TAB> <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> <TAB> f""Data types of color values are inconsistent: got {color_data_types}"" <TAB> <TAB> <TAB> ) <TAB> <TAB> color_data_type = color_data_types[0] <TAB> else: <TAB> <TAB> color_data_type = None <TAB> return color_data_type",true,if len ( set ( color_data_types ) ) > 1 :,if len ( set ( color_data_types ) ) > 1 :,0.75,0.0
"def close(self): <TAB> children = [] <TAB> for children_part, line_offset, last_line_offset_leaf in self.children_groups: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> _update_positions(children_part, line_offset, last_line_offset_leaf) <TAB> <TAB> <TAB> except _PositionUpdatingFinished: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> children += children_part <TAB> self.tree_node.children = children <TAB> # Reset the parents <TAB> for node in children: <TAB> <TAB> node.parent = self.tree_node",false,if line_offset != 0 :,if children_part :,0.04,0.0
"def get_multi(self, keys, index=None): <TAB> with self._lmdb.begin() as txn: <TAB> <TAB> result = [] <TAB> <TAB> for key in keys: <TAB> <TAB> <TAB> packed = txn.get(key.encode()) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> result.append((key, cbor.loads(packed))) <TAB> return result",false,if packed is not None :,if packed :,0.05,0.0
"def get_directory_info(prefix, pth, recursive): <TAB> res = [] <TAB> directory = os.listdir(pth) <TAB> directory.sort() <TAB> for p in directory: <TAB> <TAB> if p[0] != ""."": <TAB> <TAB> <TAB> subp = os.path.join(pth, p) <TAB> <TAB> <TAB> p = os.path.join(prefix, p) <TAB> <TAB> <TAB> if recursive and os.path.isdir(subp): <TAB> <TAB> <TAB> <TAB> res.append([p, get_directory_info(prefix, subp, 1)]) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> res.append([p, None]) <TAB> return res",true,if recursive and os . path . isdir ( subp ) :,if recursive and os . path . isdir ( subp ) :,0.75,0.0
"def __schedule(self, workflow_scheduler_id, workflow_scheduler): <TAB> invocation_ids = self.__active_invocation_ids(workflow_scheduler_id) <TAB> for invocation_id in invocation_ids: <TAB> <TAB> log.debug(""Attempting to schedule workflow invocation [%s]"", invocation_id) <TAB> <TAB> self.__attempt_schedule(invocation_id, workflow_scheduler) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return",false,if not self . monitor_running :,if not self . is_running :,0.52,0.0
"def write(self, data): <TAB> self.size -= len(data) <TAB> passon = None <TAB> if self.size > 0: <TAB> <TAB> self.data.append(data) <TAB> else: <TAB> <TAB> if self.size: <TAB> <TAB> <TAB> data, passon = data[: self.size], data[self.size :] <TAB> <TAB> else: <TAB> <TAB> <TAB> passon = b"""" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.data.append(data) <TAB> return passon",true,if data :,if data :,0.53,0.0
"def __getstate__(self): <TAB> try: <TAB> <TAB> store_func, load_func = self.store_function, self.load_function <TAB> <TAB> self.store_function, self.load_function = None, None <TAB> <TAB> # ignore analyses. we re-initialize analyses when restoring from pickling so that we do not lose any newly <TAB> <TAB> # added analyses classes <TAB> <TAB> d = dict( <TAB> <TAB> <TAB> (k, v) <TAB> <TAB> <TAB> for k, v in self.__dict__.items() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> not in { <TAB> <TAB> <TAB> <TAB> ""analyses"", <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> <TAB> return d <TAB> finally: <TAB> <TAB> self.store_function, self.load_function = store_func, load_func",true,if k,if k,0.41,0.0
"def mouse_down(self, event): <TAB> if event.button == 1: <TAB> <TAB> if self.scrolling: <TAB> <TAB> <TAB> p = event.local <TAB> <TAB> <TAB> if self.scroll_up_rect().collidepoint(p): <TAB> <TAB> <TAB> <TAB> self.scroll_up() <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> elif self.scroll_down_rect().collidepoint(p): <TAB> <TAB> <TAB> <TAB> self.scroll_down() <TAB> <TAB> <TAB> <TAB> return <TAB> if event.button == 4: <TAB> <TAB> self.scroll_up() <TAB> if event.button == 5: <TAB> <TAB> self.scroll_down() <TAB> GridView.mouse_down(self, event)",true,if self . scroll_up_rect ( ) . collidepoint ( p ) :,if self . scroll_up_rect ( ) . collidepoint ( p ) :,0.75,0.0
"def on_api_command(self, command, data): <TAB> if command == ""select"": <TAB> <TAB> if not Permissions.PLUGIN_ACTION_COMMAND_PROMPT_INTERACT.can(): <TAB> <TAB> <TAB> return flask.abort(403, ""Insufficient permissions"") <TAB> <TAB> if self._prompt is None: <TAB> <TAB> <TAB> return flask.abort(409, ""No active prompt"") <TAB> <TAB> choice = data[""choice""] <TAB> <TAB> if not isinstance(choice, int) or not self._prompt.validate_choice(choice): <TAB> <TAB> <TAB> return flask.abort( <TAB> <TAB> <TAB> <TAB> 400, ""{!r} is not a valid value for choice"".format(choice) <TAB> <TAB> <TAB> ) <TAB> <TAB> self._answer_prompt(choice)",false,"if not isinstance ( choice , int ) or not self . _prompt . validate_choice ( choice ) :",if self . _prompt is None :,0.05,0.0
"def register_predictors(self, model_data_arr): <TAB> for integration in self._get_integrations(): <TAB> <TAB> if integration.check_connection(): <TAB> <TAB> <TAB> integration.register_predictors(model_data_arr) <TAB> <TAB> else: <TAB> <TAB> <TAB> logger.warning( <TAB> <TAB> <TAB> <TAB> f""There is no connection to {integration.name}. predictor wouldn't be registred."" <TAB> <TAB> <TAB> )",true,if integration . check_connection ( ) :,if integration . check_connection ( ) :,0.75,0.0
"def _pack_shears(shearData): <TAB> shears = list() <TAB> vidxs = list() <TAB> for e_idx, entry in enumerate(shearData): <TAB> <TAB> # Should be 3 entries <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> shears.extend([float(""nan""), float(""nan"")]) <TAB> <TAB> <TAB> vidxs.extend([0, 0]) <TAB> <TAB> else: <TAB> <TAB> <TAB> vidx1, vidx2, shear1, shear2 = entry <TAB> <TAB> <TAB> shears.extend([shear1, shear2]) <TAB> <TAB> <TAB> vidxs.extend([vidx1, vidx2]) <TAB> return (np.asarray(shears, dtype=np.float32), np.asarray(vidxs, dtype=np.uint32))",false,if entry is None :,if e_idx == 3 :,0.03,0.0
"def aiter_cogs(cls) -> AsyncIterator[Tuple[str, str]]: <TAB> yield ""Core"", ""0"" <TAB> for _dir in data_manager.cog_data_path().iterdir(): <TAB> <TAB> fpath = _dir / ""settings.json"" <TAB> <TAB> if not fpath.exists(): <TAB> <TAB> <TAB> continue <TAB> <TAB> with fpath.open() as f: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> data = json.load(f) <TAB> <TAB> <TAB> except json.JSONDecodeError: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not isinstance(data, dict): <TAB> <TAB> <TAB> continue <TAB> <TAB> cog_name = _dir.stem <TAB> <TAB> for cog_id, inner in data.items(): <TAB> <TAB> <TAB> if not isinstance(inner, dict): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield cog_name, cog_id",false,"if not isinstance ( inner , dict ) :","if not isinstance ( data , dict ) :",0.55,0.0
"def subFeaName(m, newNames, state): <TAB> try: <TAB> <TAB> int(m[3], 16) <TAB> except: <TAB> <TAB> return m[0] <TAB> name = m[2] <TAB> if name in newNames: <TAB> <TAB> # print('sub %r => %r' % (m[0], m[1] + newNames[name] + m[4])) <TAB> <TAB> if name == ""uni0402"": <TAB> <TAB> <TAB> print(""sub %r => %r"" % (m[0], m[1] + newNames[name] + m[4])) <TAB> <TAB> state[""didChange""] = True <TAB> <TAB> return m[1] + newNames[name] + m[4] <TAB> return m[0]",true,"if name == ""uni0402"" :","if name == ""uni0402"" :",0.75,0.0
"def log_graph(self, model: LightningModule, input_array=None): <TAB> if self._log_graph: <TAB> <TAB> if input_array is None: <TAB> <TAB> <TAB> input_array = model.example_input_array <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> input_array = model._apply_batch_transfer_handler(input_array) <TAB> <TAB> <TAB> self.experiment.add_graph(model, input_array) <TAB> <TAB> else: <TAB> <TAB> <TAB> rank_zero_warn( <TAB> <TAB> <TAB> <TAB> ""Could not log computational graph since the"" <TAB> <TAB> <TAB> <TAB> "" `model.example_input_array` attribute is not set"" <TAB> <TAB> <TAB> <TAB> "" or `input_array` was not given"", <TAB> <TAB> <TAB> <TAB> UserWarning, <TAB> <TAB> <TAB> )",false,if input_array is not None :,if self . batch_transfer_handler is not None :,0.38,0.0
"def apply(self, db, person): <TAB> for family_handle in person.get_family_handle_list(): <TAB> <TAB> family = db.get_family_from_handle(family_handle) <TAB> <TAB> if family: <TAB> <TAB> <TAB> for event_ref in family.get_event_ref_list(): <TAB> <TAB> <TAB> <TAB> if event_ref: <TAB> <TAB> <TAB> <TAB> <TAB> event = db.get_event_from_handle(event_ref.ref) <TAB> <TAB> <TAB> <TAB> <TAB> if not event.get_place_handle(): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> <TAB> if not event.get_date_object(): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",true,if not event . get_place_handle ( ) :,if not event . get_place_handle ( ) :,0.75,0.0
"def format(m): <TAB> if m > 1000: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return (str(int(m / 1000)), ""km"") <TAB> <TAB> else: <TAB> <TAB> <TAB> return (str(round(m / 1000, 1)), ""km"") <TAB> return (str(m), ""m"")",false,if m % 1000 == 0 :,if m < 1 :,0.1,0.0
"def previous(self): <TAB> try: <TAB> <TAB> idx = _jump_list_index <TAB> <TAB> next_index = idx + 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> next_index = 100 <TAB> <TAB> next_index = min(len(_jump_list) - 1, next_index) <TAB> <TAB> _jump_list_index = next_index <TAB> <TAB> return _jump_list[next_index] <TAB> except (IndexError, KeyError) as e: <TAB> <TAB> return None",true,if next_index > 100 :,if next_index > 100 :,0.75,0.0
"def _validate_and_set_default_hyperparameters(self): <TAB> """"""Placeholder docstring"""""" <TAB> # Check if all the required hyperparameters are set. If there is a default value <TAB> # for one, set it. <TAB> for name, definition in self.hyperparameter_definitions.items(): <TAB> <TAB> if name not in self.hyperparam_dict: <TAB> <TAB> <TAB> spec = definition[""spec""] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.hyperparam_dict[name] = spec[""DefaultValue""] <TAB> <TAB> <TAB> elif ""IsRequired"" in spec and spec[""IsRequired""]: <TAB> <TAB> <TAB> <TAB> raise ValueError(""Required hyperparameter: %s is not set"" % name)",false,"if ""DefaultValue"" in spec :","if ""DefaultValue"" in spec and spec [ ""DefaultValue"" ] :",0.25,0.0
"def _actions_read(self, c): <TAB> self.action_input.handle_read(c) <TAB> if c in [curses.KEY_ENTER, util.KEY_ENTER2]: <TAB> <TAB> # take action <TAB> <TAB> if self.action_input.selected_index == 0:  # Cancel <TAB> <TAB> <TAB> self.back_to_parent() <TAB> <TAB> elif self.action_input.selected_index == 1:  # Apply <TAB> <TAB> <TAB> self._apply_prefs() <TAB> <TAB> <TAB> client.core.get_config().addCallback(self._update_preferences) <TAB> <TAB> elif self.action_input.selected_index == 2:  # OK <TAB> <TAB> <TAB> self._apply_prefs() <TAB> <TAB> <TAB> self.back_to_parent()",true,elif self . action_input . selected_index == 1 :,elif self . action_input . selected_index == 1 :,1.0,0.0
"def _split_anonymous_function(s): <TAB> # Regex is not sufficient to handle differences between anonymous <TAB> # functions and YAML encoded lists. We perform a sniff test to see <TAB> # if it might be an anonymous function and then confirm by <TAB> # decoding it as YAML and testing the result. <TAB> if s[:1] == ""["" and s[-1:] == ""]"" and "":"" in s: <TAB> <TAB> try: <TAB> <TAB> <TAB> l = yaml_util.decode_yaml(s) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> return None, s[1:-1] <TAB> <TAB> else: <TAB> <TAB> <TAB> if len(l) == 1 and isinstance(l[0], (six.string_types, int)): <TAB> <TAB> <TAB> <TAB> return None, s[1:-1] <TAB> return None",true,"if len ( l ) == 1 and isinstance ( l [ 0 ] , ( six . string_types , int ) ) :","if len ( l ) == 1 and isinstance ( l [ 0 ] , ( six . string_types , int ) ) :",1.0,0.0
"def test_source_address(self): <TAB> for addr, is_ipv6 in VALID_SOURCE_ADDRESSES: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> warnings.warn(""No IPv6 support: skipping."", NoIPv6Warning) <TAB> <TAB> <TAB> continue <TAB> <TAB> pool = HTTPConnectionPool( <TAB> <TAB> <TAB> self.host, self.port, source_address=addr, retries=False <TAB> <TAB> ) <TAB> <TAB> self.addCleanup(pool.close) <TAB> <TAB> r = pool.request(""GET"", ""/source_address"") <TAB> <TAB> self.assertEqual(r.data, b(addr[0]))",false,if is_ipv6 and not HAS_IPV6_AND_DNS :,if is_ipv6 :,0.05,0.0
"def vim_G(self): <TAB> """"""Put the cursor on the last character of the file."""""" <TAB> if self.is_text_wrapper(self.w): <TAB> <TAB> if self.state == ""visual"": <TAB> <TAB> <TAB> self.do(""end-of-buffer-extend-selection"") <TAB> <TAB> else: <TAB> <TAB> <TAB> self.do(""end-of-buffer"") <TAB> <TAB> self.done() <TAB> else: <TAB> <TAB> self.quit()",true,"if self . state == ""visual"" :","if self . state == ""visual"" :",0.75,0.0
"def backend_supported(module, manager, **kwargs): <TAB> if CollectionNodeModule.backend_supported(module, manager, **kwargs): <TAB> <TAB> if ""tid"" not in kwargs: <TAB> <TAB> <TAB> return True <TAB> <TAB> conn = manager.connection(did=kwargs[""did""]) <TAB> <TAB> template_path = ""partitions/sql/{0}/#{0}#{1}#"".format( <TAB> <TAB> <TAB> manager.server_type, manager.version <TAB> <TAB> ) <TAB> <TAB> SQL = render_template( <TAB> <TAB> <TAB> ""/"".join([template_path, ""backend_support.sql""]), tid=kwargs[""tid""] <TAB> <TAB> ) <TAB> <TAB> status, res = conn.execute_scalar(SQL) <TAB> <TAB> # check if any errors <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return internal_server_error(errormsg=res) <TAB> <TAB> return res",false,if not status :,if status != 200 :,0.05,0.0
"def _get_regex_config(self, data_asset_name: Optional[str] = None) -> dict: <TAB> regex_config: dict = copy.deepcopy(self._default_regex) <TAB> asset: Optional[Asset] = None <TAB> if data_asset_name: <TAB> <TAB> asset = self._get_asset(data_asset_name=data_asset_name) <TAB> if asset is not None: <TAB> <TAB> # Override the defaults <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> regex_config[""pattern""] = asset.pattern <TAB> <TAB> if asset.group_names: <TAB> <TAB> <TAB> regex_config[""group_names""] = asset.group_names <TAB> return regex_config",true,if asset . pattern :,if asset . pattern :,0.75,0.0
"def resolve(self, other): <TAB> if other == ANY_TYPE: <TAB> <TAB> return self <TAB> elif isinstance(other, ComplexType): <TAB> <TAB> f = self.first.resolve(other.first) <TAB> <TAB> s = self.second.resolve(other.second) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ComplexType(f, s) <TAB> <TAB> else: <TAB> <TAB> <TAB> return None <TAB> elif self == ANY_TYPE: <TAB> <TAB> return other <TAB> else: <TAB> <TAB> return None",false,if f and s :,if f != s :,0.08,0.0
"def collect_pages(app): <TAB> new_images = {} <TAB> for full_path, basename in app.builder.images.iteritems(): <TAB> <TAB> base, ext = os.path.splitext(full_path) <TAB> <TAB> retina_path = base + ""@2x"" + ext <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> new_images[retina_path] = app.env.images[retina_path][1] <TAB> app.builder.images.update(new_images) <TAB> return []",true,if retina_path in app . env . images :,if retina_path in app . env . images :,0.75,0.0
"def has_bad_headers(self): <TAB> headers = [self.sender, self.reply_to] + self.recipients <TAB> for header in headers: <TAB> <TAB> if _has_newline(header): <TAB> <TAB> <TAB> return True <TAB> if self.subject: <TAB> <TAB> if _has_newline(self.subject): <TAB> <TAB> <TAB> for linenum, line in enumerate(self.subject.split(""\r\n"")): <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if linenum > 0 and line[0] not in ""\t "": <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if _has_newline(line): <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if len(line.strip()) == 0: <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",false,if not line :,if len ( line ) == 0 :,0.04,0.0
"def reader(): <TAB> try: <TAB> <TAB> imgs = mp4_loader(video_path, seg_num, seglen, mode) <TAB> <TAB> if len(imgs) < 1: <TAB> <TAB> <TAB> logger.error( <TAB> <TAB> <TAB> <TAB> ""{} frame length {} less than 1."".format(video_path, len(imgs)) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> yield None, None <TAB> except: <TAB> <TAB> logger.error(""Error when loading {}"".format(mp4_path)) <TAB> <TAB> yield None, None <TAB> imgs_ret = imgs_transform( <TAB> <TAB> imgs, mode, seg_num, seglen, short_size, target_size, img_mean, img_std <TAB> ) <TAB> label_ret = video_path <TAB> yield imgs_ret, label_ret",true,if len ( imgs ) < 1 :,if len ( imgs ) < 1 :,0.75,0.0
"def translate_from_sortname(name, sortname): <TAB> """"""'Translate' the artist name by reversing the sortname."""""" <TAB> for c in name: <TAB> <TAB> ctg = unicodedata.category(c) <TAB> <TAB> if ctg[0] == ""L"" and unicodedata.name(c).find(""LATIN"") == -1: <TAB> <TAB> <TAB> for separator in ("" & "", ""; "", "" and "", "" vs. "", "" with "", "" y ""): <TAB> <TAB> <TAB> <TAB> if separator in sortname: <TAB> <TAB> <TAB> <TAB> <TAB> parts = sortname.split(separator) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> parts = [sortname] <TAB> <TAB> <TAB> <TAB> separator = """" <TAB> <TAB> <TAB> return separator.join(map(_reverse_sortname, parts)) <TAB> return name",true,"if ctg [ 0 ] == ""L"" and unicodedata . name ( c ) . find ( ""LATIN"" ) == - 1 :","if ctg [ 0 ] == ""L"" and unicodedata . name ( c ) . find ( ""LATIN"" ) == - 1 :",0.75,0.0
"def _to_local_path(path): <TAB> """"""Convert local path to SFTP path"""""" <TAB> if sys.platform == ""win32"":  # pragma: no cover <TAB> <TAB> path = os.fsdecode(path) <TAB> <TAB> if path[:1] == ""/"" and path[2:3] == "":"": <TAB> <TAB> <TAB> path = path[1:] <TAB> <TAB> path = path.replace(""/"", ""\\"") <TAB> return path",true,"if path [ : 1 ] == ""/"" and path [ 2 : 3 ] == "":"" :","if path [ : 1 ] == ""/"" and path [ 2 : 3 ] == "":"" :",1.0,0.0
"def __call__(self, text: str) -> str: <TAB> for t in self.cleaner_types: <TAB> <TAB> if t == ""tacotron"": <TAB> <TAB> <TAB> text = tacotron_cleaner.cleaners.custom_english_cleaners(text) <TAB> <TAB> elif t == ""jaconv"": <TAB> <TAB> <TAB> text = jaconv.normalize(text) <TAB> <TAB> elif t == ""vietnamese"": <TAB> <TAB> <TAB> if vietnamese_cleaners is None: <TAB> <TAB> <TAB> <TAB> raise RuntimeError(""Please install underthesea"") <TAB> <TAB> <TAB> text = vietnamese_cleaners.vietnamese_cleaner(text) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise RuntimeError(f""Not supported: type={t}"") <TAB> return text",true,"elif t == ""jaconv"" :","elif t == ""jaconv"" :",1.0,0.0
"def cb_syncthing_system_data(self, daemon, mem, cpu, d_failed, d_total): <TAB> if self.daemon.get_my_id() in self.devices: <TAB> <TAB> # Update my device display <TAB> <TAB> device = self.devices[self.daemon.get_my_id()] <TAB> <TAB> device[""ram""] = sizeof_fmt(mem) <TAB> <TAB> device[""cpu""] = ""%3.2f%%"" % (cpu) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> device[""announce""] = _(""disabled"") <TAB> <TAB> else: <TAB> <TAB> <TAB> device[""announce""] = ""%s/%s"" % (d_total - d_failed, d_total)",false,if d_total == 0 :,if d_failed == 0 :,0.39,0.0
"def update_kls(self, sampled_kls): <TAB> for i, kl in enumerate(sampled_kls): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.kl_coeff_val[i] *= 0.5 <TAB> <TAB> elif kl > 1.5 * self.kl_target: <TAB> <TAB> <TAB> self.kl_coeff_val[i] *= 2.0 <TAB> return self.kl_coeff_val",false,if kl < self . kl_target / 1.5 :,if kl < 0.5 * self . kl_target :,0.1,0.0
"def DeleteEmptyCols(self): <TAB> cols2delete = [] <TAB> for c in range(0, self.GetCols()): <TAB> <TAB> f = True <TAB> <TAB> for r in range(0, self.GetRows()): <TAB> <TAB> <TAB> if self.FindItemAtPosition((r, c)) is not None: <TAB> <TAB> <TAB> <TAB> f = False <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> cols2delete.append(c) <TAB> for i in range(0, len(cols2delete)): <TAB> <TAB> self.ShiftColsLeft(cols2delete[i] + 1) <TAB> <TAB> cols2delete = [x - 1 for x in cols2delete]",true,if f :,if f :,0.53,0.0
"def get_session(self): <TAB> if self._session is None: <TAB> <TAB> session = super(ChildResourceManager, self).get_session() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> session = session.get_session_for_resource(self.resource_type.resource) <TAB> <TAB> self._session = session <TAB> return self._session",false,if self . resource_type . resource != constants . RESOURCE_ACTIVE_DIRECTORY :,if self . resource_type :,0.17,0.0
"def _get_master_authorized_networks_config(self, raw_cluster): <TAB> if raw_cluster.get(""masterAuthorizedNetworksConfig""): <TAB> <TAB> config = raw_cluster.get(""masterAuthorizedNetworksConfig"") <TAB> <TAB> config[""includes_public_cidr""] = False <TAB> <TAB> for block in config[""cidrBlocks""]: <TAB> <TAB> <TAB> if block[""cidrBlock""] == ""0.0.0.0/0"": <TAB> <TAB> <TAB> <TAB> config[""includes_public_cidr""] = True <TAB> <TAB> return config <TAB> else: <TAB> <TAB> return {""enabled"": False, ""cidrBlocks"": [], ""includes_public_cidr"": False}",true,"if block [ ""cidrBlock"" ] == ""0.0.0.0/0"" :","if block [ ""cidrBlock"" ] == ""0.0.0.0/0"" :",0.75,0.0
"def scan_folder(folder): <TAB> scanned_files = [] <TAB> for root, dirs, files in os.walk(folder): <TAB> <TAB> dirs[:] = [d for d in dirs if d != ""__pycache__""] <TAB> <TAB> relative_path = os.path.relpath(root, folder) <TAB> <TAB> for f in files: <TAB> <TAB> <TAB> if f.endswith("".pyc""): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> relative_name = os.path.normpath(os.path.join(relative_path, f)).replace( <TAB> <TAB> <TAB> <TAB> ""\\"", ""/"" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> scanned_files.append(relative_name) <TAB> return sorted(scanned_files)",true,"if f . endswith ( "".pyc"" ) :","if f . endswith ( "".pyc"" ) :",0.75,0.0
"def read_progress(self): <TAB> while True: <TAB> <TAB> processed_file = self.queue.get() <TAB> <TAB> self.threading_completed.append(processed_file) <TAB> <TAB> total_number = len(self.file_list) <TAB> <TAB> completed_number = len(self.threading_completed) <TAB> <TAB> # Just for the record, this slows down book searching by about 20% <TAB> <TAB> if _progress_emitter:  # Skip update in reading mode <TAB> <TAB> <TAB> _progress_emitter.update_progress(completed_number * 100 // total_number) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break",false,if total_number == completed_number :,if completed_number == total_number :,0.29,0.0
"def next_instruction_is_function_or_class(lines): <TAB> """"""Is the first non-empty, non-commented line of the cell either a function or a class?"""""" <TAB> parser = StringParser(""python"") <TAB> for i, line in enumerate(lines): <TAB> <TAB> if parser.is_quoted(): <TAB> <TAB> <TAB> parser.read_line(line) <TAB> <TAB> <TAB> continue <TAB> <TAB> parser.read_line(line) <TAB> <TAB> if not line.strip():  # empty line <TAB> <TAB> <TAB> if i > 0 and not lines[i - 1].strip(): <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> continue <TAB> <TAB> if line.startswith(""def "") or line.startswith(""class ""): <TAB> <TAB> <TAB> return True <TAB> <TAB> if line.startswith((""#"", ""@"", "" "", "")"")): <TAB> <TAB> <TAB> continue <TAB> <TAB> return False <TAB> return False",false,if i > 0 and not lines [ i - 1 ] . strip ( ) :,"if line . startswith ( ( ""#"" , ""@"" , "" "" , "")"" ) ) :",0.02,0.0
"def __next__(self): <TAB> try: <TAB> <TAB> data = next(self.iter_loader) <TAB> except StopIteration: <TAB> <TAB> self._epoch += 1 <TAB> <TAB> if hasattr(self._dataloader.sampler, ""set_epoch""): <TAB> <TAB> <TAB> self._dataloader.sampler.set_epoch(self._epoch) <TAB> <TAB> self.iter_loader = iter(self._dataloader) <TAB> <TAB> data = next(self.iter_loader) <TAB> return data",true,"if hasattr ( self . _dataloader . sampler , ""set_epoch"" ) :","if hasattr ( self . _dataloader . sampler , ""set_epoch"" ) :",0.75,0.0
"def dgl_mp_batchify_fn(data): <TAB> if isinstance(data[0], tuple): <TAB> <TAB> data = zip(*data) <TAB> <TAB> return [dgl_mp_batchify_fn(i) for i in data] <TAB> for dt in data: <TAB> <TAB> if dt is not None: <TAB> <TAB> <TAB> if isinstance(dt, dgl.DGLGraph): <TAB> <TAB> <TAB> <TAB> return [d for d in data if isinstance(d, dgl.DGLGraph)] <TAB> <TAB> <TAB> elif isinstance(dt, nd.NDArray): <TAB> <TAB> <TAB> <TAB> pad = Pad(axis=(1, 2), num_shards=1, ret_length=False) <TAB> <TAB> <TAB> <TAB> data_list = [dt for dt in data if dt is not None] <TAB> <TAB> <TAB> <TAB> return pad(data_list)",true,"if isinstance ( dt , dgl . DGLGraph ) :","if isinstance ( dt , dgl . DGLGraph ) :",0.75,0.0
"def f(self, info): <TAB> for k in keys: <TAB> <TAB> if callable(k): <TAB> <TAB> <TAB> for k2 in list(info.keys()): <TAB> <TAB> <TAB> <TAB> if k(k2): <TAB> <TAB> <TAB> <TAB> <TAB> info.pop(k2) <TAB> <TAB> else: <TAB> <TAB> <TAB> info.pop(k, None)",true,if callable ( k ) :,if callable ( k ) :,0.75,0.0
"def create(path, binary=False): <TAB> for i in range(10): <TAB> <TAB> try: <TAB> <TAB> <TAB> os.makedirs(os.path.dirname(path), exist_ok=True) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return open(path, ""wb"") <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return open(path, ""w"", encoding=""utf-8"") <TAB> <TAB> <TAB> if i > 0: <TAB> <TAB> <TAB> <TAB> log(True, f""Created {path} at attempt {i + 1}"") <TAB> <TAB> except: <TAB> <TAB> <TAB> time.sleep(0.5) <TAB> else: <TAB> <TAB> raise Error(f""Failed to create {path}"")",true,if binary :,if binary :,0.53,0.0
"def validate_update(self, update_query): <TAB> structure = DotCollapsedDict(self.doc_class.structure) <TAB> for op, fields in update_query.iteritems(): <TAB> <TAB> for field in fields: <TAB> <TAB> <TAB> if op != ""$unset"" and op != ""$rename"": <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise UpdateQueryError( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""'%s' not found in %s's structure"" <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> % (field, self.doc_class.__name__) <TAB> <TAB> <TAB> <TAB> <TAB> )",true,if field not in structure :,if field not in structure :,0.75,0.0
"def check_enums_ATLAS_ISAEXT(lines): <TAB> for i, isaext in enumerate(ATLAS_ISAEXT): <TAB> <TAB> got = lines.pop(0).strip() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> expect = ""none: 1"" <TAB> <TAB> else: <TAB> <TAB> <TAB> expect = ""{0}: {1}"".format(isaext, 1 << i) <TAB> <TAB> if got != expect: <TAB> <TAB> <TAB> raise RuntimeError( <TAB> <TAB> <TAB> <TAB> ""ATLAS_ISAEXT mismatch at position "" <TAB> <TAB> <TAB> <TAB> + str(i) <TAB> <TAB> <TAB> <TAB> + "": got >>"" <TAB> <TAB> <TAB> <TAB> + got <TAB> <TAB> <TAB> <TAB> + ""<<, expected >>"" <TAB> <TAB> <TAB> <TAB> + expect <TAB> <TAB> <TAB> <TAB> + ""<<"" <TAB> <TAB> <TAB> )",false,if i == 0 :,"if isaext == """" :",0.04,0.0
"def _test_export_session_csv(self, test_session=None): <TAB> with self.app.test_request_context(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> test_session = SessionFactory() <TAB> <TAB> field_data = export_sessions_csv([test_session]) <TAB> <TAB> session_row = field_data[1] <TAB> <TAB> self.assertEqual(session_row[0], ""example (accepted)"") <TAB> <TAB> self.assertEqual(session_row[9], ""accepted"")",false,if not test_session :,if test_session is None :,0.05,0.0
"def get_report_to_platform(self, args, scan_reports): <TAB> if self.bc_api_key: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> repo_id = self.get_repository(args) <TAB> <TAB> <TAB> self.setup_bridgecrew_credentials( <TAB> <TAB> <TAB> <TAB> bc_api_key=self.bc_api_key, repo_id=repo_id <TAB> <TAB> <TAB> ) <TAB> <TAB> if self.is_integration_configured(): <TAB> <TAB> <TAB> self._upload_run(args, scan_reports)",false,if args . directory :,if self . bc_api_key != self . bc_api_key :,0.11,0.0
"def test_fvalue(self): <TAB> if not getattr(self, ""skip_f"", False): <TAB> <TAB> rtol = getattr(self, ""rtol"", 1e-10) <TAB> <TAB> assert_allclose(self.res1.fvalue, self.res2.F, rtol=rtol) <TAB> <TAB> if hasattr(self.res2, ""Fp""): <TAB> <TAB> <TAB> # only available with ivreg2 <TAB> <TAB> <TAB> assert_allclose(self.res1.f_pvalue, self.res2.Fp, rtol=rtol) <TAB> else: <TAB> <TAB> raise pytest.skip(""TODO: document why this test is skipped"")",true,"if hasattr ( self . res2 , ""Fp"" ) :","if hasattr ( self . res2 , ""Fp"" ) :",0.75,0.0
"def fix_repeating_arguments(self): <TAB> """"""Fix elements that should accumulate/increment values."""""" <TAB> either = [list(child.children) for child in transform(self).children] <TAB> for case in either: <TAB> <TAB> for e in [child for child in case if case.count(child) > 1]: <TAB> <TAB> <TAB> if type(e) is Argument or type(e) is Option and e.argcount: <TAB> <TAB> <TAB> <TAB> if e.value is None: <TAB> <TAB> <TAB> <TAB> <TAB> e.value = [] <TAB> <TAB> <TAB> <TAB> elif type(e.value) is not list: <TAB> <TAB> <TAB> <TAB> <TAB> e.value = e.value.split() <TAB> <TAB> <TAB> if type(e) is Command or type(e) is Option and e.argcount == 0: <TAB> <TAB> <TAB> <TAB> e.value = 0 <TAB> return self",true,elif type ( e . value ) is not list :,elif type ( e . value ) is not list :,0.75,0.0
"def touch(self): <TAB> if not self.exists(): <TAB> <TAB> try: <TAB> <TAB> <TAB> self.parent().touch() <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> pass <TAB> <TAB> node = self._fs.touch(self.pathnames, {}) <TAB> <TAB> if not node.isdir: <TAB> <TAB> <TAB> raise AssertionError(""Not a folder: %s"" % self.path) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.watcher.emit(""created"", self)",true,if self . watcher :,if self . watcher :,0.75,0.0
"def __init__(self, _inf=None, _tzinfos=None): <TAB> if _inf: <TAB> <TAB> self._tzinfos = _tzinfos <TAB> <TAB> self._utcoffset, self._dst, self._tzname = _inf <TAB> else: <TAB> <TAB> _tzinfos = {} <TAB> <TAB> self._tzinfos = _tzinfos <TAB> <TAB> self._utcoffset, self._dst, self._tzname = self._transition_info[0] <TAB> <TAB> _tzinfos[self._transition_info[0]] = self <TAB> <TAB> for inf in self._transition_info[1:]: <TAB> <TAB> <TAB> if not _tzinfos.has_key(inf): <TAB> <TAB> <TAB> <TAB> _tzinfos[inf] = self.__class__(inf, _tzinfos)",true,if not _tzinfos . has_key ( inf ) :,if not _tzinfos . has_key ( inf ) :,0.75,0.0
"def test_sample_output(): <TAB> comment = ""SAMPLE OUTPUT"" <TAB> skip_files = [""__init__.py""] <TAB> errors = [] <TAB> for _file in sorted(MODULE_PATH.iterdir()): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> with _file.open() as f: <TAB> <TAB> <TAB> <TAB> if comment not in f.read(): <TAB> <TAB> <TAB> <TAB> <TAB> errors.append((comment, _file)) <TAB> if errors: <TAB> <TAB> line = ""Missing sample error(s) detected!\n\n"" <TAB> <TAB> for error in errors: <TAB> <TAB> <TAB> line += ""`{}` is not in module `{}`\n"".format(*error) <TAB> <TAB> print(line[:-1]) <TAB> <TAB> assert False",false,"if _file . suffix == "".py"" and _file . name not in skip_files :",if _file . name not in skip_files :,0.27,0.0
"def http_get(url, target): <TAB> req = requests.get(url, stream=True) <TAB> content_length = req.headers.get(""Content-Length"") <TAB> total = int(content_length) if content_length is not None else None <TAB> progress = tqdm(unit=""B"", total=total) <TAB> with open(target, ""wb"") as target_file: <TAB> <TAB> for chunk in req.iter_content(chunk_size=1024): <TAB> <TAB> <TAB><IF-STMT>  # filter out keep-alive new chunks <TAB> <TAB> <TAB> <TAB> progress.update(len(chunk)) <TAB> <TAB> <TAB> <TAB> target_file.write(chunk) <TAB> progress.close()",true,if chunk :,if chunk :,0.53,0.0
"def _elements_to_datasets(self, elements, level=0): <TAB> for element in elements: <TAB> <TAB> extra_kwds = {""identifier_%d"" % level: element[""name""]} <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for inner_element in self._elements_to_datasets( <TAB> <TAB> <TAB> <TAB> element[""elements""], level=level + 1 <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> dataset = extra_kwds.copy() <TAB> <TAB> <TAB> <TAB> dataset.update(inner_element) <TAB> <TAB> <TAB> <TAB> yield dataset <TAB> <TAB> else: <TAB> <TAB> <TAB> dataset = extra_kwds <TAB> <TAB> <TAB> extra_kwds.update(element) <TAB> <TAB> <TAB> yield extra_kwds",true,"if ""elements"" in element :","if ""elements"" in element :",0.75,0.0
"def update_dict(a, b): <TAB> for key, value in b.items(): <TAB> <TAB> if value is None: <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> a[key] = value <TAB> <TAB> elif isinstance(a[key], dict) and isinstance(value, dict): <TAB> <TAB> <TAB> update_dict(a[key], value) <TAB> <TAB> elif isinstance(a[key], list): <TAB> <TAB> <TAB> a[key].append(value) <TAB> <TAB> else: <TAB> <TAB> <TAB> a[key] = [a[key], value]",true,if key not in a :,if key not in a :,0.75,0.0
"def scan(self, targets): <TAB> for target in targets: <TAB> <TAB> target.print_infos() <TAB> <TAB> if self.is_interesting(target): <TAB> <TAB> <TAB> self.target[""other""].append(target) <TAB> <TAB> <TAB> if self.match(target): <TAB> <TAB> <TAB> <TAB> return target <TAB> return None",true,if self . match ( target ) :,if self . match ( target ) :,0.75,0.0
"def printConnections(switches): <TAB> ""Compactly print connected nodes to each switch"" <TAB> for sw in switches: <TAB> <TAB> output(""%s: "" % sw) <TAB> <TAB> for intf in sw.intfList(): <TAB> <TAB> <TAB> link = intf.link <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> intf1, intf2 = link.intf1, link.intf2 <TAB> <TAB> <TAB> <TAB> remote = intf1 if intf1.node != sw else intf2 <TAB> <TAB> <TAB> <TAB> output(""%s(%s) "" % (remote.node, sw.ports[intf])) <TAB> <TAB> output(""\n"")",true,if link :,if link :,0.53,0.0
"def __cut(sentence): <TAB> global emit_P <TAB> prob, pos_list = viterbi(sentence, ""BMES"", start_P, trans_P, emit_P) <TAB> begin, nexti = 0, 0 <TAB> # print pos_list, sentence <TAB> for i, char in enumerate(sentence): <TAB> <TAB> pos = pos_list[i] <TAB> <TAB> if pos == ""B"": <TAB> <TAB> <TAB> begin = i <TAB> <TAB> elif pos == ""E"": <TAB> <TAB> <TAB> yield sentence[begin : i + 1] <TAB> <TAB> <TAB> nexti = i + 1 <TAB> <TAB> elif pos == ""S"": <TAB> <TAB> <TAB> yield char <TAB> <TAB> <TAB> nexti = i + 1 <TAB> if nexti < len(sentence): <TAB> <TAB> yield sentence[nexti:]",true,"elif pos == ""E"" :","elif pos == ""E"" :",1.0,0.0
"def check_files(self, paths=None): <TAB> """"""Run all checks on the paths."""""" <TAB> if paths is None: <TAB> <TAB> paths = self.paths <TAB> report = self.options.report <TAB> runner = self.runner <TAB> report.start() <TAB> try: <TAB> <TAB> for path in paths: <TAB> <TAB> <TAB> if os.path.isdir(path): <TAB> <TAB> <TAB> <TAB> self.input_dir(path) <TAB> <TAB> <TAB> elif not self.excluded(path): <TAB> <TAB> <TAB> <TAB> runner(path) <TAB> except KeyboardInterrupt: <TAB> <TAB> print(""... stopped"") <TAB> report.stop() <TAB> return report",true,if os . path . isdir ( path ) :,if os . path . isdir ( path ) :,1.0,0.0
"def verts_of_loop(edge_loop): <TAB> verts = [] <TAB> for e0, e1 in iter_pairs(edge_loop, False): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> v0 = e0.shared_vert(e1) <TAB> <TAB> <TAB> verts += [e0.other_vert(v0), v0] <TAB> <TAB> verts += [e1.other_vert(verts[-1])] <TAB> if len(verts) > 1 and verts[0] == verts[-1]: <TAB> <TAB> return verts[:-1] <TAB> return verts",false,if not verts :,if len ( e0 . shared_vert ) > 1 and e1 . shared_vert :,0.03,0.0
"def generator(self, data): <TAB> for task in data: <TAB> <TAB> # Do we scan everything or just /bin/bash instances? <TAB> <TAB> if not (self._config.SCAN_ALL or str(task.p_comm) == ""bash""): <TAB> <TAB> <TAB> continue <TAB> <TAB> for bucket in task.bash_hash_entries(): <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> 0, <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> int(task.p_pid), <TAB> <TAB> <TAB> <TAB> <TAB> str(task.p_comm), <TAB> <TAB> <TAB> <TAB> <TAB> int(bucket.times_found), <TAB> <TAB> <TAB> <TAB> <TAB> str(bucket.key), <TAB> <TAB> <TAB> <TAB> <TAB> str(bucket.data.path), <TAB> <TAB> <TAB> <TAB> ], <TAB> <TAB> <TAB> )",true,"if not ( self . _config . SCAN_ALL or str ( task . p_comm ) == ""bash"" ) :","if not ( self . _config . SCAN_ALL or str ( task . p_comm ) == ""bash"" ) :",0.75,0.0
"def __get_ratio(self): <TAB> """"""Return splitter ratio of the main splitter."""""" <TAB> c = self.c <TAB> free_layout = c.free_layout <TAB> if free_layout: <TAB> <TAB> w = free_layout.get_main_splitter() <TAB> <TAB> if w: <TAB> <TAB> <TAB> aList = w.sizes() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> n1, n2 = aList <TAB> <TAB> <TAB> <TAB> # 2017/06/07: guard against division by zero. <TAB> <TAB> <TAB> <TAB> ratio = 0.5 if n1 + n2 == 0 else float(n1) / float(n1 + n2) <TAB> <TAB> <TAB> <TAB> return ratio <TAB> return 0.5",false,if len ( aList ) == 2 :,if len ( aList ) > 0 :,0.52,0.0
"def geterrors(self): <TAB> """"""Get all error messages."""""" <TAB> notes = self.getnotes(origin=""translator"").split(""\n"") <TAB> errordict = {} <TAB> for note in notes: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> error = note.replace(""(pofilter) "", """") <TAB> <TAB> <TAB> errorname, errortext = error.split("": "", 1) <TAB> <TAB> <TAB> errordict[errorname] = errortext <TAB> return errordict",false,"if ""(pofilter) "" in note :","if "" (pofilter) "" in note :",0.5,0.0
"def rename_path(self, path, new_path): <TAB> logger.debug(""rename_path '%s' -> '%s'"" % (path, new_path)) <TAB> dirs = self.readdir(path) <TAB> for d in dirs: <TAB> <TAB> if d in [""."", ""..""]: <TAB> <TAB> <TAB> continue <TAB> <TAB> d_path = """".join([path, ""/"", d]) <TAB> <TAB> d_new_path = """".join([new_path, ""/"", d]) <TAB> <TAB> attr = self.getattr(d_path) <TAB> <TAB> if stat.S_ISDIR(attr[""st_mode""]): <TAB> <TAB> <TAB> self.rename_path(d_path, d_new_path) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.rename_item(d_path, d_new_path) <TAB> self.rename_item(path, new_path, dir=True)",true,"if stat . S_ISDIR ( attr [ ""st_mode"" ] ) :","if stat . S_ISDIR ( attr [ ""st_mode"" ] ) :",0.75,0.0
"def index(self, url_id: int) -> FlaskResponse:  # pylint: disable=no-self-use <TAB> url = db.session.query(models.Url).get(url_id) <TAB> if url and url.url: <TAB> <TAB> explore_url = ""//superset/explore/?"" <TAB> <TAB> if url.url.startswith(explore_url): <TAB> <TAB> <TAB> explore_url += f""r={url_id}"" <TAB> <TAB> <TAB> return redirect(explore_url[1:]) <TAB> <TAB> return redirect(url.url[1:]) <TAB> flash(""URL to nowhere..."", ""danger"") <TAB> return redirect(""/"")",true,if url . url . startswith ( explore_url ) :,if url . url . startswith ( explore_url ) :,1.0,0.0
"def testShortCircuit(self): <TAB> """"""Test that creation short-circuits to reuse existing references"""""" <TAB> sd = {} <TAB> for s in self.ss: <TAB> <TAB> sd[s] = 1 <TAB> for t in self.ts: <TAB> <TAB> if hasattr(t, ""x""): <TAB> <TAB> <TAB> self.assertTrue(sd.has_key(safeRef(t.x))) <TAB> <TAB> <TAB> self.assertTrue(safeRef(t.x) in sd) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.assertTrue(sd.has_key(safeRef(t))) <TAB> <TAB> <TAB> self.assertTrue(safeRef(t) in sd)",true,"if hasattr ( t , ""x"" ) :","if hasattr ( t , ""x"" ) :",0.75,0.0
"def wrapped(request, *args, **kwargs): <TAB> if not request.user.is_authenticated(): <TAB> <TAB> request.session[""_next""] = request.get_full_path() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> redirect_uri = reverse( <TAB> <TAB> <TAB> <TAB> ""sentry-auth-organization"", args=[kwargs[""organization_slug""]] <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> redirect_uri = get_login_url() <TAB> <TAB> return HttpResponseRedirect(redirect_uri) <TAB> return func(request, *args, **kwargs)",true,"if ""organization_slug"" in kwargs :","if ""organization_slug"" in kwargs :",0.75,0.0
"def read_info(reader, dump=None): <TAB> line_number_table_length = reader.read_u2() <TAB><IF-STMT> <TAB> <TAB> reader.debug( <TAB> <TAB> <TAB> "" <TAB>"" * dump, ""Line numbers (%s total):"" % line_number_table_length <TAB> <TAB> ) <TAB> line_numbers = [] <TAB> for i in range(0, line_number_table_length): <TAB> <TAB> start_pc = reader.read_u2() <TAB> <TAB> line_number = reader.read_u2() <TAB> <TAB> if dump is not None: <TAB> <TAB> <TAB> reader.debug("" <TAB>"" * (dump + 1), ""%s: %s"" % (start_pc, line_number)) <TAB> <TAB> line_numbers.append((start_pc, line_number)) <TAB> return LineNumberTable(line_numbers)",true,if dump is not None :,if dump is not None :,0.75,0.0
"def compute_timer_precision(timer): <TAB> precision = None <TAB> points = 0 <TAB> timeout = timeout_timer() + 1.0 <TAB> previous = timer() <TAB> while timeout_timer() < timeout or points < 5: <TAB> <TAB> for _ in XRANGE(10): <TAB> <TAB> <TAB> t1 = timer() <TAB> <TAB> <TAB> t2 = timer() <TAB> <TAB> <TAB> dt = t2 - t1 <TAB> <TAB> <TAB> if 0 < dt: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> dt = t2 - previous <TAB> <TAB> <TAB> if dt <= 0.0: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> precision = min(precision, dt) <TAB> <TAB> else: <TAB> <TAB> <TAB> precision = dt <TAB> <TAB> points += 1 <TAB> <TAB> previous = timer() <TAB> return precision",false,if precision is not None :,if precision :,0.05,0.0
def get_hi_lineno(self): <TAB> lineno = Node.get_hi_lineno(self) <TAB> if self.expr1 is None: <TAB> <TAB> pass <TAB> else: <TAB> <TAB> lineno = self.expr1.get_hi_lineno() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> lineno = self.expr2.get_hi_lineno() <TAB> <TAB> <TAB> if self.expr3 is None: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> lineno = self.expr3.get_hi_lineno() <TAB> return lineno,true,if self . expr2 is None :,if self . expr2 is None :,0.75,0.0
"def validate_cluster_resource_group(cmd, namespace): <TAB> if namespace.cluster_resource_group is not None: <TAB> <TAB> client = get_mgmt_service_client( <TAB> <TAB> <TAB> cmd.cli_ctx, ResourceType.MGMT_RESOURCE_RESOURCES <TAB> <TAB> ) <TAB> <TAB> if client.resource_groups.check_existence(namespace.cluster_resource_group): <TAB> <TAB> <TAB> raise InvalidArgumentValueError( <TAB> <TAB> <TAB> <TAB> ""Invalid --cluster-resource-group '%s': resource group must not exist."" <TAB> <TAB> <TAB> <TAB> % namespace.cluster_resource_group <TAB> <TAB> <TAB> )",true,if client . resource_groups . check_existence ( namespace . cluster_resource_group ) :,if client . resource_groups . check_existence ( namespace . cluster_resource_group ) :,0.75,0.0
"def find_word_bounds(self, text, index, allowed_chars): <TAB> right = left = index <TAB> done = False <TAB> while not done: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self.word_boundary_char(text[left - 1]): <TAB> <TAB> <TAB> left -= 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> done = True <TAB> done = False <TAB> while not done: <TAB> <TAB> if right == len(text): <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self.word_boundary_char(text[right]): <TAB> <TAB> <TAB> right += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> done = True <TAB> return left, right",false,if left == 0 :,if left == 0 and right in allowed_chars :,0.34,0.0
"def _check_good_input(self, X, y=None): <TAB> if isinstance(X, dict): <TAB> <TAB> lengths = [len(X1) for X1 in X.values()] <TAB> <TAB> if len(set(lengths)) > 1: <TAB> <TAB> <TAB> raise ValueError(""Not all values of X are of equal length."") <TAB> <TAB> x_len = lengths[0] <TAB> else: <TAB> <TAB> x_len = len(X) <TAB> if y is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError(""X and y are not of equal length."") <TAB> if self.regression and y is not None and y.ndim == 1: <TAB> <TAB> y = y.reshape(-1, 1) <TAB> return X, y",false,if len ( y ) != x_len :,if x_len != x_len :,0.08,0.0
"def _get_text_nodes(nodes, html_body): <TAB> text = [] <TAB> open_tags = 0 <TAB> for node in nodes: <TAB> <TAB> if isinstance(node, HtmlTag): <TAB> <TAB> <TAB> if node.tag_type == OPEN_TAG: <TAB> <TAB> <TAB> <TAB> open_tags += 1 <TAB> <TAB> <TAB> elif node.tag_type == CLOSE_TAG: <TAB> <TAB> <TAB> <TAB> open_tags -= 1 <TAB> <TAB> elif ( <TAB> <TAB> <TAB> isinstance(node, HtmlDataFragment) <TAB> <TAB> <TAB> and node.is_text_content <TAB> <TAB> <TAB> and open_tags == 0 <TAB> <TAB> ): <TAB> <TAB> <TAB> text.append(html_body[node.start : node.end]) <TAB> return text",true,elif node . tag_type == CLOSE_TAG :,elif node . tag_type == CLOSE_TAG :,1.0,0.0
"def _get_spyne_type(cls_name, k, v): <TAB> try: <TAB> <TAB> v = NATIVE_MAP.get(v, v) <TAB> except TypeError: <TAB> <TAB> return <TAB> try: <TAB> <TAB> subc = issubclass(v, ModelBase) or issubclass(v, SelfReference) <TAB> except: <TAB> <TAB> subc = False <TAB> if subc: <TAB> <TAB> if issubclass(v, Array) and len(v._type_info) != 1: <TAB> <TAB> <TAB> raise Exception(""Invalid Array definition in %s.%s."" % (cls_name, k)) <TAB> <TAB> elif issubclass(v, Point) and v.Attributes.dim is None: <TAB> <TAB> <TAB> raise Exception(""Please specify the number of dimensions"") <TAB> <TAB> return v",true,"elif issubclass ( v , Point ) and v . Attributes . dim is None :","elif issubclass ( v , Point ) and v . Attributes . dim is None :",1.0,0.0
"def customize(cls, **kwargs): <TAB> """"""return a class with some existing attributes customized"""""" <TAB> for name, value in kwargs.iteritems(): <TAB> <TAB> if name in [""cookie"", ""circuit"", ""upstream"", ""downstream"", ""stream""]: <TAB> <TAB> <TAB> raise TransportError( <TAB> <TAB> <TAB> <TAB> ""you cannot customize the protected attribute %s"" % name <TAB> <TAB> <TAB> ) <TAB> <TAB> if not hasattr(cls, name): <TAB> <TAB> <TAB> raise TransportError(""Transport has no attribute %s"" % name) <TAB> NewSubClass = type(""Customized_{}"".format(cls.__name__), (cls,), kwargs) <TAB> return NewSubClass",true,"if name in [ ""cookie"" , ""circuit"" , ""upstream"" , ""downstream"" , ""stream"" ] :","if name in [ ""cookie"" , ""circuit"" , ""upstream"" , ""downstream"" , ""stream"" ] :",0.75,0.0
"def test_UNrelativize(self): <TAB> import URIlib <TAB> relative = self.relative + self.full_relativize <TAB> for base, rel, fullpath, common in relative: <TAB> <TAB> URI = uriparse.UnRelativizeURL(base, rel) <TAB> <TAB> fullURI = URIlib.URIParser(URI) <TAB> <TAB> # We need to canonicalize the result from unrelativize <TAB> <TAB> # compared to the original full path we expect to see. <TAB> <TAB> if fullpath[-1] in (""/"", ""\\""): <TAB> <TAB> <TAB> fullpath = fullpath[:-1] <TAB> <TAB> self.failUnlessSamePath( <TAB> <TAB> <TAB> os.path.normcase(fullURI.path), os.path.normcase(fullpath) <TAB> <TAB> )",true,"if fullpath [ - 1 ] in ( ""/"" , ""\\"" ) :","if fullpath [ - 1 ] in ( ""/"" , ""\\"" ) :",0.75,0.0
"def get_release_info(file_path=RELEASE_FILE): <TAB> RELEASE_TYPE_REGEX = re.compile(r""^[Rr]elease [Tt]ype: (major|minor|patch)$"") <TAB> with open(file_path, ""r"") as f: <TAB> <TAB> line = f.readline() <TAB> <TAB> match = RELEASE_TYPE_REGEX.match(line) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print( <TAB> <TAB> <TAB> <TAB> ""The file RELEASE.md should start with `Release type` "" <TAB> <TAB> <TAB> <TAB> ""and specify one of the following values: major, minor or patch."" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> sys.exit(1) <TAB> <TAB> type_ = match.group(1) <TAB> <TAB> changelog = """".join([line for line in f.readlines()]).strip() <TAB> return type_, changelog",false,if not match :,if match is None :,0.05,0.0
"def _get_next_history_entry(self): <TAB> if self._history: <TAB> <TAB> hist_len = len(self._history) - 1 <TAB> <TAB> self.history_index = min(hist_len, self.history_index + 1) <TAB> <TAB> index = self.history_index <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.history_index += 1 <TAB> <TAB> return self._history[index] <TAB> return """"",false,if self . history_index == hist_len :,if index < hist_len :,0.04,0.0
"def star_op(self): <TAB> """"""Put a '*' op, with special cases for *args."""""" <TAB> val = ""*"" <TAB> if self.paren_level: <TAB> <TAB> i = len(self.code_list) - 1 <TAB> <TAB> if self.code_list[i].kind == ""blank"": <TAB> <TAB> <TAB> i -= 1 <TAB> <TAB> token = self.code_list[i] <TAB> <TAB> if token.kind == ""lt"": <TAB> <TAB> <TAB> self.op_no_blanks(val) <TAB> <TAB> elif token.value == "","": <TAB> <TAB> <TAB> self.blank() <TAB> <TAB> <TAB> self.add_token(""op-no-blanks"", val) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.op(val) <TAB> else: <TAB> <TAB> self.op(val)",true,"if token . kind == ""lt"" :","if token . kind == ""lt"" :",0.75,0.0
"def get_safe_settings(): <TAB> ""Returns a dictionary of the settings module, with sensitive settings blurred out."" <TAB> settings_dict = {} <TAB> for k in dir(settings): <TAB> <TAB> if k.isupper(): <TAB> <TAB> <TAB> if HIDDEN_SETTINGS.search(k): <TAB> <TAB> <TAB> <TAB> settings_dict[k] = ""********************"" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> settings_dict[k] = getattr(settings, k) <TAB> return settings_dict",true,if k . isupper ( ) :,if k . isupper ( ) :,0.75,0.0
"def nextEditable(self): <TAB> """"""Moves focus of the cursor to the next editable window"""""" <TAB> if self.currentEditable is None: <TAB> <TAB> if len(self._editableChildren): <TAB> <TAB> <TAB> self._currentEditableRef = self._editableChildren[0] <TAB> else: <TAB> <TAB> for ref in weakref.getweakrefs(self.currentEditable): <TAB> <TAB> <TAB> if ref in self._editableChildren: <TAB> <TAB> <TAB> <TAB> cei = self._editableChildren.index(ref) <TAB> <TAB> <TAB> <TAB> nei = cei + 1 <TAB> <TAB> <TAB> <TAB> if nei >= len(self._editableChildren): <TAB> <TAB> <TAB> <TAB> <TAB> nei = 0 <TAB> <TAB> <TAB> <TAB> self._currentEditableRef = self._editableChildren[nei] <TAB> return self.currentEditable",true,if ref in self . _editableChildren :,if ref in self . _editableChildren :,0.75,0.0
"def _handle_dependents_type(types, type_str, type_name, rel_name, row): <TAB> if types[type_str[0]] is None: <TAB> <TAB> if type_str[0] == ""i"": <TAB> <TAB> <TAB> type_name = ""index"" <TAB> <TAB> <TAB> rel_name = row[""indname""] + "" ON "" + rel_name <TAB> <TAB> elif type_str[0] == ""o"": <TAB> <TAB> <TAB> type_name = ""operator"" <TAB> <TAB> <TAB> rel_name = row[""relname""] <TAB> else: <TAB> <TAB> type_name = types[type_str[0]] <TAB> return type_name, rel_name",false,"if type_str [ 0 ] == ""i"" :","elif type_str [ 0 ] == ""o"" :",0.26,0.0
"def streamErrorHandler(self, conn, error): <TAB> name, text = ""error"", error.getData() <TAB> for tag in error.getChildren(): <TAB> <TAB> if tag.getNamespace() == NS_XMPP_STREAMS: <TAB> <TAB> <TAB> if tag.getName() == ""text"": <TAB> <TAB> <TAB> <TAB> text = tag.getData() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> name = tag.getName() <TAB> if name in stream_exceptions.keys(): <TAB> <TAB> exc = stream_exceptions[name] <TAB> else: <TAB> <TAB> exc = StreamError <TAB> raise exc((name, text))",true,if tag . getNamespace ( ) == NS_XMPP_STREAMS :,if tag . getNamespace ( ) == NS_XMPP_STREAMS :,0.75,0.0
"def _validate_names(self, settings: _SettingsType) -> None: <TAB> """"""Make sure all settings exist."""""" <TAB> unknown = [] <TAB> for name in settings: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> unknown.append(name) <TAB> if unknown: <TAB> <TAB> errors = [ <TAB> <TAB> <TAB> configexc.ConfigErrorDesc( <TAB> <TAB> <TAB> <TAB> ""While loading options"", ""Unknown option {}"".format(e) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> for e in sorted(unknown) <TAB> <TAB> ] <TAB> <TAB> raise configexc.ConfigFileErrors(""autoconfig.yml"", errors)",false,if name not in configdata . DATA :,if name not in self . DEFAULT_SETTINGS :,0.34,0.0
"def can_haz(self, target, credentials): <TAB> """"""Check whether key-values in target are present in credentials."""""" <TAB> # TODO(termie): handle ANDs, probably by providing a tuple instead of a <TAB> # <TAB> <TAB> <TAB>   string <TAB> for requirement in target: <TAB> <TAB> key, match = requirement.split("":"", 1) <TAB> <TAB> check = credentials.get(key) <TAB> <TAB> if check is None or isinstance(check, basestring): <TAB> <TAB> <TAB> check = [check] <TAB> <TAB> if match in check: <TAB> <TAB> <TAB> return True",true,"if check is None or isinstance ( check , basestring ) :","if check is None or isinstance ( check , basestring ) :",0.75,0.0
"def _recursive_fx_apply(input: dict, fx): <TAB> for k, v in input.items(): <TAB> <TAB> if isinstance(v, list): <TAB> <TAB> <TAB> v = torch.tensor(v) <TAB> <TAB> if isinstance(v, torch.Tensor): <TAB> <TAB> <TAB> v = fx(v.float()) <TAB> <TAB> <TAB> input[k] = v <TAB> <TAB> else: <TAB> <TAB> <TAB> _recursive_fx_apply(v, fx)",true,"if isinstance ( v , list ) :","if isinstance ( v , list ) :",0.75,0.0
"def get(self, url, **kwargs): <TAB> app, url = self._prepare_call(url, kwargs) <TAB> if app: <TAB> <TAB> if url.endswith(""ping"") and self._first_ping: <TAB> <TAB> <TAB> self._first_ping = False <TAB> <TAB> <TAB> return EmptyCapabilitiesResponse() <TAB> <TAB> elif ""Hello0"" in url and ""1.2.1"" in url and ""v1"" in url: <TAB> <TAB> <TAB> return ErrorApiResponse() <TAB> <TAB> else: <TAB> <TAB> <TAB> response = app.get(url, **kwargs) <TAB> <TAB> <TAB> return TestingResponse(response) <TAB> else: <TAB> <TAB> return requests.get(url, **kwargs)",false,"if url . endswith ( ""ping"" ) and self . _first_ping :","elif ""Hello0"" in url and ""1.2.1"" in url and ""v1"" in url :",0.01,0.0
"def server_thread_fn(): <TAB> server_ctx = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH) <TAB> server_ctx.load_cert_chain(""trio-test-1.pem"") <TAB> server = server_ctx.wrap_socket( <TAB> <TAB> server_sock, <TAB> <TAB> server_side=True, <TAB> <TAB> suppress_ragged_eofs=False, <TAB> ) <TAB> while True: <TAB> <TAB> data = server.recv(4096) <TAB> <TAB> print(""server got:"", data) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(""server waiting for client to finish everything"") <TAB> <TAB> <TAB> client_done.wait() <TAB> <TAB> <TAB> print(""server attempting to send back close-notify"") <TAB> <TAB> <TAB> server.unwrap() <TAB> <TAB> <TAB> print(""server ok"") <TAB> <TAB> <TAB> break <TAB> <TAB> server.sendall(data)",false,if not data :,if client_done :,0.05,0.0
"def find_hostnames(data): <TAB> # sends back an array of hostnames <TAB> hostnames = [] <TAB> for i in re.finditer(hostname_regex, data): <TAB> <TAB> h = string.lower(i.group(1)) <TAB> <TAB> tld = h.split(""."")[-1:][0] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> hostnames.append(h) <TAB> return hostnames",false,if tld in tlds :,if tld in hostnames :,0.39,0.0
"def Validate(self, win): <TAB> textCtrl = self.GetWindow() <TAB> text = textCtrl.GetValue().strip() <TAB> sChar = Character.getInstance() <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError(_t(""You must supply a name for the Character!"")) <TAB> <TAB> elif text in [x.name for x in sChar.getCharacterList()]: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> _t(""Character name already in use, please choose another."") <TAB> <TAB> <TAB> ) <TAB> <TAB> return True <TAB> except ValueError as e: <TAB> <TAB> pyfalog.error(e) <TAB> <TAB> wx.MessageBox(""{}"".format(e), _t(""Error"")) <TAB> <TAB> textCtrl.SetFocus() <TAB> <TAB> return False",false,if len ( text ) == 0 :,if not sChar :,0.02,0.0
def get_random_user_agent(agent_list=UA_CACHE): <TAB> if not len(agent_list): <TAB> <TAB> ua_file = file(UA_FILE) <TAB> <TAB> for line in ua_file: <TAB> <TAB> <TAB> line = line.strip() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> agent_list.append(line) <TAB> ua = random.choice(UA_CACHE) <TAB> return ua,true,if line :,if line :,0.53,0.0
"def _validate_action_like_for_prefixes(self, key): <TAB> for statement in self._statements: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if isinstance(statement[key], string_types): <TAB> <TAB> <TAB> <TAB> self._validate_action_prefix(statement[key]) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> for action in statement[key]: <TAB> <TAB> <TAB> <TAB> <TAB> self._validate_action_prefix(action)",true,if key in statement :,if key in statement :,0.75,0.0
"def predict(self, X): <TAB> if self.regression: <TAB> <TAB> return self.predict_proba(X) <TAB> else: <TAB> <TAB> y_pred = np.argmax(self.predict_proba(X), axis=1) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> y_pred = self.enc_.inverse_transform(y_pred) <TAB> <TAB> return y_pred",false,if self . use_label_encoder :,if self . enc_ :,0.39,0.0
"def _threaded_request_tracker(self, builder): <TAB> while True: <TAB> <TAB> event_type = self._read_q.get() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> payload = {""body"": b""""} <TAB> <TAB> request_id = builder.build_record(event_type, payload, """") <TAB> <TAB> self._write_q.put_nowait(request_id)",false,if event_type is False :,if event_type is None :,0.39,0.0
"def __call__(self, value): <TAB> try: <TAB> <TAB> super(EmailValidator, self).__call__(value) <TAB> except ValidationError as e: <TAB> <TAB> # Trivial case failed. Try for possible IDN domain-part <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> parts = value.split(""@"") <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> parts[-1] = parts[-1].encode(""idna"").decode(""ascii"") <TAB> <TAB> <TAB> except UnicodeError: <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> <TAB> super(EmailValidator, self).__call__(""@"".join(parts)) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise",false,"if value and ""@"" in value :","if ""@"" in value :",0.23,0.0
"def PreprocessConditionalStatement(self, IfList, ReplacedLine): <TAB> while self: <TAB> <TAB> if self.__Token: <TAB> <TAB> <TAB> x = 1 <TAB> <TAB> elif not IfList: <TAB> <TAB> <TAB> if self <= 2: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionSizeGuid = 3 <TAB> <TAB> <TAB> if not RegionSizeGuid: <TAB> <TAB> <TAB> <TAB> RegionLayoutLine = 5 <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionLayoutLine = self.CurrentLineNumber <TAB> return 1",false,elif not IfList :,if self . __Token :,0.03,0.0
"def _arg_with_type(self): <TAB> for t in self.d[""Args""]: <TAB> <TAB> m = re.search(""([A-Za-z0-9_-]+)\s{0,4}(\(.+\))\s{0,4}:"", t) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.args[m.group(1)] = m.group(2) <TAB> return self.args",true,if m :,if m :,0.53,0.0
"def get_palette_for_custom_classes(self, class_names, palette=None): <TAB> if self.label_map is not None: <TAB> <TAB> # return subset of palette <TAB> <TAB> palette = [] <TAB> <TAB> for old_id, new_id in sorted(self.label_map.items(), key=lambda x: x[1]): <TAB> <TAB> <TAB> if new_id != -1: <TAB> <TAB> <TAB> <TAB> palette.append(self.PALETTE[old_id]) <TAB> <TAB> palette = type(self.PALETTE)(palette) <TAB> elif palette is None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> palette = np.random.randint(0, 255, size=(len(class_names), 3)) <TAB> <TAB> else: <TAB> <TAB> <TAB> palette = self.PALETTE <TAB> return palette",false,if self . PALETTE is None :,if class_names :,0.02,0.0
"def Visit_star_expr(self, node):  # pylint: disable=invalid-name <TAB> # star_expr ::= '*' expr <TAB> for child in node.children: <TAB> <TAB> self.Visit(child) <TAB> <TAB> if isinstance(child, pytree.Leaf) and child.value == ""*"": <TAB> <TAB> <TAB> _AppendTokenSubtype(child, format_token.Subtype.UNARY_OPERATOR) <TAB> <TAB> <TAB> _AppendTokenSubtype(child, format_token.Subtype.VARARGS_STAR)",true,"if isinstance ( child , pytree . Leaf ) and child . value == ""*"" :","if isinstance ( child , pytree . Leaf ) and child . value == ""*"" :",1.0,0.0
"def create_if_compatible(cls, typ: Type, *, root: ""RootNode"") -> Optional[""Node""]: <TAB> if cls.compatible_types: <TAB> <TAB> target_type: Type = typ <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> target_type = getattr(typ, ""__origin__"", None) or typ <TAB> <TAB> if cls._issubclass(target_type, cls.compatible_types): <TAB> <TAB> <TAB> return cls(typ, root=root) <TAB> return None",false,if cls . use_origin :,if target_type is None :,0.03,0.0
"def grep_full_py_identifiers(tokens): <TAB> global pykeywords <TAB> tokens = list(tokens) <TAB> i = 0 <TAB> while i < len(tokens): <TAB> <TAB> tokentype, token = tokens[i] <TAB> <TAB> i += 1 <TAB> <TAB> if tokentype != ""id"": <TAB> <TAB> <TAB> continue <TAB> <TAB> while ( <TAB> <TAB> <TAB> i + 1 < len(tokens) <TAB> <TAB> <TAB> and tokens[i] == (""op"", ""."") <TAB> <TAB> <TAB> and tokens[i + 1][0] == ""id"" <TAB> <TAB> ): <TAB> <TAB> <TAB> token += ""."" + tokens[i + 1][1] <TAB> <TAB> <TAB> i += 2 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if token in pykeywords: <TAB> <TAB> <TAB> continue <TAB> <TAB> if token[0] in "".0123456789"": <TAB> <TAB> <TAB> continue <TAB> <TAB> yield token",false,"if token == """" :","if token == ""op"" and token == ""id"" :",0.19,0.0
"def create_config_filepath(cls, visibility=None): <TAB> if cls.is_local(visibility): <TAB> <TAB> # Local to this directory <TAB> <TAB> base_path = os.path.join(""."") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # Add it to the current ""./.polyaxon"" <TAB> <TAB> <TAB> base_path = os.path.join(base_path, "".polyaxon"") <TAB> <TAB> <TAB> cls._create_dir(base_path) <TAB> elif cls.CONFIG_PATH:  # Custom path <TAB> <TAB> pass <TAB> else:  # Handle both global and all cases <TAB> <TAB> base_path = polyaxon_user_path() <TAB> <TAB> cls._create_dir(base_path)",false,if cls . IS_POLYAXON_DIR :,if cls . CONFIG_PATH :,0.39,0.0
"def test_len(self): <TAB> eq = self.assertEqual <TAB> eq(base64MIME.base64_len(""hello""), len(base64MIME.encode(""hello"", eol=""""))) <TAB> for size in range(15): <TAB> <TAB> if size == 0: <TAB> <TAB> <TAB> bsize = 0 <TAB> <TAB> elif size <= 3: <TAB> <TAB> <TAB> bsize = 4 <TAB> <TAB> elif size <= 6: <TAB> <TAB> <TAB> bsize = 8 <TAB> <TAB> elif size <= 9: <TAB> <TAB> <TAB> bsize = 12 <TAB> <TAB> elif size <= 12: <TAB> <TAB> <TAB> bsize = 16 <TAB> <TAB> else: <TAB> <TAB> <TAB> bsize = 20 <TAB> <TAB> eq(base64MIME.base64_len(""x"" * size), bsize)",false,elif size <= 3 :,elif size <= 6 :,0.39,0.0
"def as_dict(path="""", version=""latest"", section=""meta-data""): <TAB> result = {} <TAB> dirs = dir(path, version, section) <TAB> if not dirs: <TAB> <TAB> return None <TAB> for item in dirs: <TAB> <TAB> if item.endswith(""/""): <TAB> <TAB> <TAB> records = as_dict(path + item, version, section) <TAB> <TAB> <TAB> if records: <TAB> <TAB> <TAB> <TAB> result[item[:-1]] = records <TAB> <TAB> elif is_dict.match(item): <TAB> <TAB> <TAB> idx, name = is_dict.match(item).groups() <TAB> <TAB> <TAB> records = as_dict(path + idx + ""/"", version, section) <TAB> <TAB> <TAB> if records: <TAB> <TAB> <TAB> <TAB> result[name] = records <TAB> <TAB> else: <TAB> <TAB> <TAB> result[item] = valueconv(get(path + item, version, section)) <TAB> return result",true,"if item . endswith ( ""/"" ) :","if item . endswith ( ""/"" ) :",0.75,0.0
"def api_read(self): <TAB> result = {} <TAB> files = [""my.cnf"", ""debian.cnf""] <TAB> directory_list = self.exec_payload(""mysql_config_directory"")[""directory""] <TAB> for _file in files: <TAB> <TAB> for directory in directory_list: <TAB> <TAB> <TAB> mysql_conf = directory + _file <TAB> <TAB> <TAB> content = self.shell.read(mysql_conf) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> result[mysql_conf] = content <TAB> return result",true,if content :,if content :,0.53,0.0
"def generate(self, count=100): <TAB> self.pre_generate() <TAB> counter = iter(range(count)) <TAB> created = 0 <TAB> while True: <TAB> <TAB> batch = list(islice(counter, self.batch_size)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> self.do_generate(batch, self.batch_size) <TAB> <TAB> from_size = created <TAB> <TAB> created += len(batch) <TAB> <TAB> print(""Generate %s: %s-%s"" % (self.resource, from_size, created)) <TAB> self.after_generate()",false,if not batch :,if len ( batch ) == 0 :,0.04,0.0
"def _normalize_fields(self, document, loader): <TAB> # type: (Dict[Text, Text], Loader) -> None <TAB> # Normalize fields which are prefixed or full URIn to vocabulary terms <TAB> for d in list(document.keys()): <TAB> <TAB> d2 = loader.expand_url(d, u"""", scoped_id=False, vocab_term=True) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> document[d2] = document[d] <TAB> <TAB> <TAB> del document[d]",false,if d != d2 :,if d2 in document :,0.04,0.0
"def load_cache(filename, get_key=mangle_key): <TAB> cache = {} <TAB> if not os.path.exists(filename): <TAB> <TAB> return cache <TAB> f = open(filename, ""rb"") <TAB> l = 0 <TAB> for line in f.readlines(): <TAB> <TAB> l += 1 <TAB> <TAB> fields = line.split(b"" "") <TAB> <TAB> if fields == None or not len(fields) == 2 or fields[0][0:1] != b"":"": <TAB> <TAB> <TAB> sys.stderr.write(""Invalid file format in [%s], line %d\n"" % (filename, l)) <TAB> <TAB> <TAB> continue <TAB> <TAB> # put key:value in cache, key without ^: <TAB> <TAB> cache[get_key(fields[0][1:])] = fields[1].split(b""\n"")[0] <TAB> f.close() <TAB> return cache",true,"if fields == None or not len ( fields ) == 2 or fields [ 0 ] [ 0 : 1 ] != b"":"" :","if fields == None or not len ( fields ) == 2 or fields [ 0 ] [ 0 : 1 ] != b"":"" :",1.0,0.0
"def __lshift__(self, other): <TAB> if not self.symbolic and type(other) is int: <TAB> <TAB> return RegisterOffset( <TAB> <TAB> <TAB> self._bits, self.reg, self._to_signed(self.offset << other) <TAB> <TAB> ) <TAB> else: <TAB> <TAB> if self.symbolic: <TAB> <TAB> <TAB> return RegisterOffset(self._bits, self.reg, self.offset << other) <TAB> <TAB> else: <TAB> <TAB> <TAB> return RegisterOffset( <TAB> <TAB> <TAB> <TAB> self._bits, <TAB> <TAB> <TAB> <TAB> self.reg, <TAB> <TAB> <TAB> <TAB> ArithmeticExpression( <TAB> <TAB> <TAB> <TAB> <TAB> ArithmeticExpression.LShift, <TAB> <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self.offset, <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> other, <TAB> <TAB> <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> )",true,if self . symbolic :,if self . symbolic :,0.75,0.0
"def SaveSettings(self, force=False): <TAB> if self.config is not None: <TAB> <TAB> frame.ShellFrameMixin.SaveSettings(self) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> frame.Frame.SaveSettings(self, self.config) <TAB> <TAB> <TAB> self.shell.SaveSettings(self.config)",false,if self . autoSaveSettings or force :,if force :,0.04,0.0
"def _parse_gene(element): <TAB> for genename_element in element: <TAB> <TAB> if ""type"" in genename_element.attrib: <TAB> <TAB> <TAB> ann_key = ""gene_%s_%s"" % ( <TAB> <TAB> <TAB> <TAB> genename_element.tag.replace(NS, """"), <TAB> <TAB> <TAB> <TAB> genename_element.attrib[""type""], <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if genename_element.attrib[""type""] == ""primary"": <TAB> <TAB> <TAB> <TAB> self.ParsedSeqRecord.annotations[ann_key] = genename_element.text <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> append_to_annotations(ann_key, genename_element.text)",true,"if genename_element . attrib [ ""type"" ] == ""primary"" :","if genename_element . attrib [ ""type"" ] == ""primary"" :",0.75,0.0
"def _write_pkg_file(self, file): <TAB> with TemporaryFile(mode=""w+"") as tmpfd: <TAB> <TAB> _write_pkg_file_orig(self, tmpfd) <TAB> <TAB> tmpfd.seek(0) <TAB> <TAB> for line in tmpfd: <TAB> <TAB> <TAB> if line.startswith(""Metadata-Version: ""): <TAB> <TAB> <TAB> <TAB> file.write(""Metadata-Version: 2.1\n"") <TAB> <TAB> <TAB> elif line.startswith(""Description: ""): <TAB> <TAB> <TAB> <TAB> file.write( <TAB> <TAB> <TAB> <TAB> <TAB> ""Description-Content-Type: %s; charset=UTF-8\n"" <TAB> <TAB> <TAB> <TAB> <TAB> % long_description_content_type <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> file.write(line) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> file.write(line)",false,"if line . startswith ( ""Metadata-Version: "" ) :","elif line . startswith ( ""Description: "" ) :",0.21,0.0
"def get(self): <TAB> """"""If a value/an exception is stored, return/raise it. Otherwise until switch() or throw() is called."""""" <TAB> if self._exception is not _NONE: <TAB> <TAB> if self._exception is None: <TAB> <TAB> <TAB> return self.value <TAB> <TAB> getcurrent().throw(*self._exception)  # pylint:disable=undefined-variable <TAB> else: <TAB> <TAB> if self.greenlet is not None: <TAB> <TAB> <TAB> raise ConcurrentObjectUseError( <TAB> <TAB> <TAB> <TAB> ""This Waiter is already used by %r"" % (self.greenlet,) <TAB> <TAB> <TAB> ) <TAB> <TAB> self.greenlet = getcurrent()  # pylint:disable=undefined-variable <TAB> <TAB> try: <TAB> <TAB> <TAB> return self.hub.switch() <TAB> <TAB> finally: <TAB> <TAB> <TAB> self.greenlet = None",true,if self . _exception is None :,if self . _exception is None :,0.75,0.0
"def connect(self, *args): <TAB> """"""connects to the dropbox. args[0] is the username."""""" <TAB> if len(args) != 1: <TAB> <TAB> return ""expected one argument!"" <TAB> try: <TAB> <TAB> dbci = get_dropbox_client(args[0], False, None, None) <TAB> except Exception as e: <TAB> <TAB> return e.message <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ""No Dropbox configured for '{u}'."".format(u=args[0]) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.client = dbci <TAB> <TAB> return True",false,if dbci is None :,if not dbci :,0.04,0.0
"def escape(text, newline=False): <TAB> """"""Escape special html characters."""""" <TAB> if isinstance(text, str): <TAB> <TAB> if ""&"" in text: <TAB> <TAB> <TAB> text = text.replace(""&"", ""&amp;"") <TAB> <TAB> if "">"" in text: <TAB> <TAB> <TAB> text = text.replace("">"", ""&gt;"") <TAB> <TAB> if ""<"" in text: <TAB> <TAB> <TAB> text = text.replace(""<"", ""&lt;"") <TAB> <TAB> if '""' in text: <TAB> <TAB> <TAB> text = text.replace('""', ""&quot;"") <TAB> <TAB> if ""'"" in text: <TAB> <TAB> <TAB> text = text.replace(""'"", ""&quot;"") <TAB> <TAB> if newline: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> text = text.replace(""\n"", ""<br>"") <TAB> return text",true,"if ""\n"" in text :","if ""\n"" in text :",0.75,0.0
"def t(ret): <TAB> with IPDB() as ipdb: <TAB> <TAB> with ipdb.eventqueue() as evq: <TAB> <TAB> <TAB> for msg in evq: <TAB> <TAB> <TAB> <TAB> if msg.get_attr(""IFLA_IFNAME"") == ""test1984"": <TAB> <TAB> <TAB> <TAB> <TAB> ret.append(msg) <TAB> <TAB> <TAB> <TAB> <TAB> return",true,"if msg . get_attr ( ""IFLA_IFNAME"" ) == ""test1984"" :","if msg . get_attr ( ""IFLA_IFNAME"" ) == ""test1984"" :",0.75,0.0
"def check_stmt(self, stmt): <TAB> if is_future(stmt): <TAB> <TAB> for name, asname in stmt.names: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.found[name] = 1 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise SyntaxError(""future feature %s is not defined"" % name) <TAB> <TAB> stmt.valid_future = 1 <TAB> <TAB> return 1 <TAB> return 0",false,if name in self . features :,if asname in self . supported_features :,0.34,0.0
"def process_pypi_option(option, option_str, option_value, parser): <TAB> if option_str.startswith(""--no""): <TAB> <TAB> setattr(parser.values, option.dest, []) <TAB> else: <TAB> <TAB> indexes = getattr(parser.values, option.dest, []) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> indexes.append(_PYPI) <TAB> <TAB> setattr(parser.values, option.dest, indexes)",false,if _PYPI not in indexes :,if _PYPI is not None :,0.3,0.0
"def modify_address(self, name, address, domain): <TAB> if not self.get_entries_by_name(name, domain): <TAB> <TAB> raise exception.NotFound <TAB> infile = open(self.filename, ""r"") <TAB> outfile = tempfile.NamedTemporaryFile(""w"", delete=False) <TAB> for line in infile: <TAB> <TAB> entry = self.parse_line(line) <TAB> <TAB> if entry and entry[""name""].lower() == self.qualify(name, domain).lower(): <TAB> <TAB> <TAB> outfile.write( <TAB> <TAB> <TAB> <TAB> ""%s   %s   %s\n"" % (address, self.qualify(name, domain), entry[""type""]) <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> outfile.write(line) <TAB> infile.close() <TAB> outfile.close() <TAB> shutil.move(outfile.name, self.filename)",true,"if entry and entry [ ""name"" ] . lower ( ) == self . qualify ( name , domain ) . lower ( ) :","if entry and entry [ ""name"" ] . lower ( ) == self . qualify ( name , domain ) . lower ( ) :",1.0,0.0
"def tms_to_quadkey(self, tms, google=False): <TAB> quadKey = """" <TAB> x, y, z = tms <TAB> # this algorithm works with google tiles, rather than tms, so convert <TAB> # to those first. <TAB> if not google: <TAB> <TAB> y = (2 ** z - 1) - y <TAB> for i in range(z, 0, -1): <TAB> <TAB> digit = 0 <TAB> <TAB> mask = 1 << (i - 1) <TAB> <TAB> if (x & mask) != 0: <TAB> <TAB> <TAB> digit += 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> digit += 2 <TAB> <TAB> quadKey += str(digit) <TAB> return quadKey",true,if ( y & mask ) != 0 :,if ( y & mask ) != 0 :,0.75,0.0
"def add_if_unique(self, issuer, use, keys): <TAB> if use in self.issuer_keys[issuer] and self.issuer_keys[issuer][use]: <TAB> <TAB> for typ, key in keys: <TAB> <TAB> <TAB> flag = 1 <TAB> <TAB> <TAB> for _typ, _key in self.issuer_keys[issuer][use]: <TAB> <TAB> <TAB> <TAB> if _typ == typ and key is _key: <TAB> <TAB> <TAB> <TAB> <TAB> flag = 0 <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.issuer_keys[issuer][use].append((typ, key)) <TAB> else: <TAB> <TAB> self.issuer_keys[issuer][use] = keys",true,if flag :,if flag :,0.53,0.0
"def scan_error(self): <TAB> ""A string describing why the last scan failed, or None if it didn't."" <TAB> self.acquire_lock() <TAB> try: <TAB> <TAB> if self._scan_error_cache is None: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> self._load_buf_data_once() <TAB> <TAB> <TAB> except NotFoundInDatabase: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> return self._scan_error_cache <TAB> finally: <TAB> <TAB> self.release_lock()",true,if self . _scan_error_cache is None :,if self . _scan_error_cache is None :,0.75,0.0
"def _query(self): <TAB> if self._mongo_query is None: <TAB> <TAB> self._mongo_query = self._query_obj.to_query(self._document) <TAB> <TAB> if self._cls_query: <TAB> <TAB> <TAB> if ""_cls"" in self._mongo_query: <TAB> <TAB> <TAB> <TAB> self._mongo_query = {""$and"": [self._cls_query, self._mongo_query]} <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self._mongo_query.update(self._cls_query) <TAB> return self._mongo_query",false,if self . _cls_query :,"if ""_cls"" in self . _mongo_query :",0.06,0.0
"def CountButtons(self): <TAB> """"""Returns the number of visible buttons in the docked pane."""""" <TAB> n = 0 <TAB> if self.HasCaption() or self.HasCaptionLeft(): <TAB> <TAB> if isinstance(wx.GetTopLevelParent(self.window), AuiFloatingFrame): <TAB> <TAB> <TAB> return 1 <TAB> <TAB> if self.HasCloseButton(): <TAB> <TAB> <TAB> n += 1 <TAB> <TAB> if self.HasMaximizeButton(): <TAB> <TAB> <TAB> n += 1 <TAB> <TAB> if self.HasMinimizeButton(): <TAB> <TAB> <TAB> n += 1 <TAB> <TAB> if self.HasPinButton(): <TAB> <TAB> <TAB> n += 1 <TAB> return n",false,if self . HasPinButton ( ) :,if self . HasCloseButton ( ) :,0.39,0.0
"def testBind(self): <TAB> try: <TAB> <TAB> with socket.socket(socket.PF_CAN, socket.SOCK_DGRAM, socket.CAN_J1939) as s: <TAB> <TAB> <TAB> addr = ( <TAB> <TAB> <TAB> <TAB> self.interface, <TAB> <TAB> <TAB> <TAB> socket.J1939_NO_NAME, <TAB> <TAB> <TAB> <TAB> socket.J1939_NO_PGN, <TAB> <TAB> <TAB> <TAB> socket.J1939_NO_ADDR, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> s.bind(addr) <TAB> <TAB> <TAB> self.assertEqual(s.getsockname(), addr) <TAB> except OSError as e: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.skipTest(""network interface `%s` does not exist"" % self.interface) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise",false,if e . errno == errno . ENODEV :,if e . errno == errno . EEXIST :,0.88,0.0
"def createFields(self): <TAB> while self.current_size < self.size: <TAB> <TAB> pos = self.stream.searchBytes( <TAB> <TAB> <TAB> ""\0\0\1"", self.current_size, self.current_size + 1024 * 1024 * 8 <TAB> <TAB> )  # seek forward by at most 1MB <TAB> <TAB> if pos is not None: <TAB> <TAB> <TAB> padsize = pos - self.current_size <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> yield PaddingBytes(self, ""pad[]"", padsize // 8) <TAB> <TAB> chunk = Chunk(self, ""chunk[]"") <TAB> <TAB> try: <TAB> <TAB> <TAB> # force chunk to be processed, so that CustomFragments are complete <TAB> <TAB> <TAB> chunk[""content/data""] <TAB> <TAB> except: <TAB> <TAB> <TAB> pass <TAB> <TAB> yield chunk",false,if padsize :,if padsize > 0 :,0.1,0.0
"def index_modulemd_files(repo_path): <TAB> merger = Modulemd.ModuleIndexMerger() <TAB> for fn in sorted(os.listdir(repo_path)): <TAB> <TAB> if not fn.endswith("".yaml""): <TAB> <TAB> <TAB> continue <TAB> <TAB> yaml_path = os.path.join(repo_path, fn) <TAB> <TAB> mmd = Modulemd.ModuleIndex() <TAB> <TAB> mmd.update_from_file(yaml_path, strict=True) <TAB> <TAB> merger.associate_index(mmd, 0) <TAB> return merger.resolve()",true,"if not fn . endswith ( "".yaml"" ) :","if not fn . endswith ( "".yaml"" ) :",0.75,0.0
"def set_visible(self, visible=True): <TAB> self._visible = visible <TAB> if self._nswindow is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # Not really sure why on_resize needs to be here, <TAB> <TAB> <TAB> # but it's what pyglet wants. <TAB> <TAB> <TAB> self.dispatch_event(""on_resize"", self._width, self._height) <TAB> <TAB> <TAB> self.dispatch_event(""on_show"") <TAB> <TAB> <TAB> self.dispatch_event(""on_expose"") <TAB> <TAB> <TAB> self._nswindow.makeKeyAndOrderFront_(None) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._nswindow.orderOut_(None)",true,if visible :,if visible :,0.53,0.0
"def __repr__(self): <TAB> if self._in_repr: <TAB> <TAB> return ""<recursion>"" <TAB> try: <TAB> <TAB> self._in_repr = True <TAB> <TAB> if self.is_computed(): <TAB> <TAB> <TAB> status = ""computed, "" <TAB> <TAB> <TAB> if self.error() is None: <TAB> <TAB> <TAB> <TAB> if self.value() is self: <TAB> <TAB> <TAB> <TAB> <TAB> status += ""= self"" <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> status += ""= "" + repr(self.value()) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> status += ""error = "" + repr(self.error()) <TAB> <TAB> else: <TAB> <TAB> <TAB> status = ""isn't computed"" <TAB> <TAB> return ""%s (%s)"" % (type(self), status) <TAB> finally: <TAB> <TAB> self._in_repr = False",false,if self . value ( ) is self :,if self . is_computed ( ) :,0.21,0.0
"def _individual_get(self, segment, index_type, index, strictdoc): <TAB> if index_type == ""val"": <TAB> <TAB> for key, value in segment.items(): <TAB> <TAB> <TAB> if key == index[0]: <TAB> <TAB> <TAB> <TAB> return value <TAB> <TAB> <TAB> if hasattr(key, ""text""): <TAB> <TAB> <TAB> <TAB> if key.text == index[0]: <TAB> <TAB> <TAB> <TAB> <TAB> return value <TAB> <TAB> raise Exception(""Invalid state"") <TAB> elif index_type == ""index"": <TAB> <TAB> return segment[index] <TAB> elif index_type == ""textslice"": <TAB> <TAB> return segment[index[0] : index[1]] <TAB> elif index_type == ""key"": <TAB> <TAB> return index[1] if strictdoc else index[0] <TAB> else: <TAB> <TAB> raise Exception(""Invalid state"")",false,"if hasattr ( key , ""text"" ) :",if key == index [ 0 ] :,0.02,0.0
"def _makeSafeAbsoluteURI(base, rel=None): <TAB> # bail if ACCEPTABLE_URI_SCHEMES is empty <TAB> if not ACCEPTABLE_URI_SCHEMES: <TAB> <TAB> return _urljoin(base, rel or u"""") <TAB> if not base: <TAB> <TAB> return rel or u"""" <TAB> if not rel: <TAB> <TAB> try: <TAB> <TAB> <TAB> scheme = urlparse.urlparse(base)[0] <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> return u"""" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return base <TAB> <TAB> return u"""" <TAB> uri = _urljoin(base, rel) <TAB> if uri.strip().split("":"", 1)[0] not in ACCEPTABLE_URI_SCHEMES: <TAB> <TAB> return u"""" <TAB> return uri",false,if not scheme or scheme in ACCEPTABLE_URI_SCHEMES :,if scheme in ACCEPTABLE_URI_SCHEMES :,0.34,0.0
"def _write_packet(self, packet): <TAB> # Immediately writes the given packet to the network. The caller must <TAB> # have the write lock acquired before calling this method. <TAB> try: <TAB> <TAB> for listener in self.early_outgoing_packet_listeners: <TAB> <TAB> <TAB> listener.call_packet(packet) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> packet.write(self.socket, self.options.compression_threshold) <TAB> <TAB> else: <TAB> <TAB> <TAB> packet.write(self.socket) <TAB> <TAB> for listener in self.outgoing_packet_listeners: <TAB> <TAB> <TAB> listener.call_packet(packet) <TAB> except IgnorePacket: <TAB> <TAB> pass",false,if self . options . compression_enabled :,if self . options . compression_threshold :,0.57,0.0
"def rangelist_to_set(rangelist): <TAB> result = set() <TAB> if not rangelist: <TAB> <TAB> return result <TAB> for x in rangelist.split("",""): <TAB> <TAB> if re.match(r""^(\d+)$"", x): <TAB> <TAB> <TAB> result.add(int(x)) <TAB> <TAB> <TAB> continue <TAB> <TAB> m = re.match(r""^(\d+)-(\d+)$"", x) <TAB> <TAB> if m: <TAB> <TAB> <TAB> start = int(m.group(1)) <TAB> <TAB> <TAB> end = int(m.group(2)) <TAB> <TAB> <TAB> result.update(set(range(start, end + 1))) <TAB> <TAB> <TAB> continue <TAB> <TAB> msg = ""Cannot understand data input: %s %s"" % (x, rangelist) <TAB> <TAB> raise ValueError(msg) <TAB> return result",true,"if re . match ( r""^(\d+)$"" , x ) :","if re . match ( r""^(\d+)$"" , x ) :",0.75,0.0
"def test_device_property_logfile_isinstance(self): <TAB> mock = MagicMock() <TAB> with patch(builtin_string + "".open"", mock): <TAB> <TAB> if sys.version > ""3"": <TAB> <TAB> <TAB> builtin_file = ""io.TextIOWrapper"" <TAB> <TAB> else: <TAB> <TAB> <TAB> builtin_file = builtin_string + "".file"" <TAB> <TAB> with patch(builtin_file, MagicMock): <TAB> <TAB> <TAB> handle = open(""filename"", ""r"") <TAB> <TAB> <TAB> self.dev.logfile = handle <TAB> <TAB> <TAB> self.assertEqual(self.dev.logfile, handle)",true,"if sys . version > ""3"" :","if sys . version > ""3"" :",0.75,0.0
"def _line_ranges(statements, lines): <TAB> """"""Produce a list of ranges for `format_lines`."""""" <TAB> statements = sorted(statements) <TAB> lines = sorted(lines) <TAB> pairs = [] <TAB> start = None <TAB> lidx = 0 <TAB> for stmt in statements: <TAB> <TAB> if lidx >= len(lines): <TAB> <TAB> <TAB> break <TAB> <TAB> if stmt == lines[lidx]: <TAB> <TAB> <TAB> lidx += 1 <TAB> <TAB> <TAB> if not start: <TAB> <TAB> <TAB> <TAB> start = stmt <TAB> <TAB> <TAB> end = stmt <TAB> <TAB> elif start: <TAB> <TAB> <TAB> pairs.append((start, end)) <TAB> <TAB> <TAB> start = None <TAB> if start: <TAB> <TAB> pairs.append((start, end)) <TAB> return pairs",false,elif start :,if stmt == lines [ lidx ] :,0.03,0.0
"def reset_parameters(self): <TAB> initialize = layers.get_initializer(self._hparams.initializer) <TAB> if initialize is not None: <TAB> <TAB> # Do not re-initialize LayerNorm modules. <TAB> <TAB> for name, param in self.named_parameters(): <TAB> <TAB> <TAB> if name.split(""."")[-1] == ""weight"" and ""layer_norm"" not in name: <TAB> <TAB> <TAB> <TAB> initialize(param)",true,"if name . split ( ""."" ) [ - 1 ] == ""weight"" and ""layer_norm"" not in name :","if name . split ( ""."" ) [ - 1 ] == ""weight"" and ""layer_norm"" not in name :",1.0,0.0
"def billing_invoice_show_validator(namespace): <TAB> from azure.cli.core.azclierror import ( <TAB> <TAB> RequiredArgumentMissingError, <TAB> <TAB> MutuallyExclusiveArgumentError, <TAB> ) <TAB> valid_combs = ( <TAB> <TAB> ""only --account-name, --name / --name / --name, --by-subscription is valid"" <TAB> ) <TAB> if namespace.account_name is not None: <TAB> <TAB> if namespace.by_subscription is not None: <TAB> <TAB> <TAB> raise MutuallyExclusiveArgumentError(valid_combs) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise RequiredArgumentMissingError(""--name is also required"") <TAB> if namespace.by_subscription is not None: <TAB> <TAB> if namespace.name is None: <TAB> <TAB> <TAB> raise RequiredArgumentMissingError(""--name is also required"")",true,if namespace . name is None :,if namespace . name is None :,0.75,0.0
"def DeleteDocuments(self, document_ids, response): <TAB> """"""Deletes documents for the given document_ids."""""" <TAB> for document_id in document_ids: <TAB> <TAB> if document_id in self._documents: <TAB> <TAB> <TAB> document = self._documents[document_id] <TAB> <TAB> <TAB> self._inverted_index.RemoveDocument(document) <TAB> <TAB> <TAB> del self._documents[document_id] <TAB> <TAB> delete_status = response.add_status() <TAB> <TAB> delete_status.set_code(search_service_pb.SearchServiceError.OK)",true,if document_id in self . _documents :,if document_id in self . _documents :,0.75,0.0
"def generate_new_element(items, prefix, numeric=False): <TAB> """"""Creates a random string with prefix, that is not in 'items' list."""""" <TAB> while True: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> candidate = prefix + generate_random_numeric(8) <TAB> <TAB> else: <TAB> <TAB> <TAB> candidate = prefix + generate_random_alphanumeric(8) <TAB> <TAB> if not candidate in items: <TAB> <TAB> <TAB> return candidate <TAB> <TAB> LOG.debug(""Random collision on %s"" % candidate)",true,if numeric :,if numeric :,0.53,0.0
"def generate_text_for_vocab(self, data_dir, tmp_dir): <TAB> for i, sample in enumerate( <TAB> <TAB> self.generate_samples(data_dir, tmp_dir, problem.DatasetSplit.TRAIN) <TAB> ): <TAB> <TAB> if self.has_inputs: <TAB> <TAB> <TAB> yield sample[""inputs""] <TAB> <TAB> yield sample[""targets""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break",false,if self . max_samples_for_vocab and ( i + 1 ) >= self . max_samples_for_vocab :,if i == 0 :,0.05,0.0
"def _get_ccp(config=None, config_path=None, saltenv=""base""): <TAB> """""" """""" <TAB> if config_path: <TAB> <TAB> config = __salt__[""cp.get_file_str""](config_path, saltenv=saltenv) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise SaltException(""{} is not available"".format(config_path)) <TAB> if isinstance(config, six.string_types): <TAB> <TAB> config = config.splitlines() <TAB> ccp = ciscoconfparse.CiscoConfParse(config) <TAB> return ccp",false,if config is False :,if not config :,0.04,0.0
"def rpush(key, *vals, **kwargs): <TAB> ttl = kwargs.get(""ttl"") <TAB> cap = kwargs.get(""cap"") <TAB> if not ttl and not cap: <TAB> <TAB> _client.rpush(key, *vals) <TAB> else: <TAB> <TAB> pipe = _client.pipeline() <TAB> <TAB> pipe.rpush(key, *vals) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> pipe.ltrim(key, 0, cap) <TAB> <TAB> if ttl: <TAB> <TAB> <TAB> pipe.expire(key, ttl) <TAB> <TAB> pipe.execute()",true,if cap :,if cap :,0.53,0.0
"def check_apns_certificate(ss): <TAB> mode = ""start"" <TAB> for s in ss.split(""\n""): <TAB> <TAB> if mode == ""start"": <TAB> <TAB> <TAB> if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s: <TAB> <TAB> <TAB> <TAB> mode = ""key"" <TAB> <TAB> elif mode == ""key"": <TAB> <TAB> <TAB> if ""END RSA PRIVATE KEY"" in s or ""END PRIVATE KEY"" in s: <TAB> <TAB> <TAB> <TAB> mode = ""end"" <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> elif s.startswith(""Proc-Type"") and ""ENCRYPTED"" in s: <TAB> <TAB> <TAB> <TAB> raise ImproperlyConfigured( <TAB> <TAB> <TAB> <TAB> <TAB> ""Encrypted APNS private keys are not supported"" <TAB> <TAB> <TAB> <TAB> ) <TAB> if mode != ""end"": <TAB> <TAB> raise ImproperlyConfigured(""The APNS certificate doesn't contain a private key"")",false,"if mode == ""start"" :","elif s . startswith ( ""Proc-Type"" ) and ""ENCRYPTED"" in s :",0.02,0.0
"def _add_communication_type(apps, schema_editor, communication_type): <TAB> Worker = apps.get_model(""orchestra"", ""Worker"") <TAB> CommunicationPreference = apps.get_model(""orchestra"", ""CommunicationPreference"") <TAB> for worker in Worker.objects.all(): <TAB> <TAB> ( <TAB> <TAB> <TAB> communication_preference, <TAB> <TAB> <TAB> created, <TAB> <TAB> ) = CommunicationPreference.objects.get_or_create( <TAB> <TAB> <TAB> worker=worker, communication_type=communication_type <TAB> <TAB> ) <TAB> <TAB> # By default set both Slack and Email notifications to True <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> communication_preference.methods.slack = True <TAB> <TAB> <TAB> communication_preference.methods.email = True <TAB> <TAB> communication_preference.save()",true,if created :,if created :,0.53,0.0
"def get_postgresql_driver_name(): <TAB> # pylint: disable=unused-variable <TAB> try: <TAB> <TAB> driver = os.getenv(""CODECHECKER_DB_DRIVER"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return driver <TAB> <TAB> try: <TAB> <TAB> <TAB> # pylint: disable=W0611 <TAB> <TAB> <TAB> import psycopg2 <TAB> <TAB> <TAB> return ""psycopg2"" <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> # pylint: disable=W0611 <TAB> <TAB> <TAB> import pg8000 <TAB> <TAB> <TAB> return ""pg8000"" <TAB> except Exception as ex: <TAB> <TAB> LOG.error(str(ex)) <TAB> <TAB> LOG.error(""Failed to import psycopg2 or pg8000 module."") <TAB> <TAB> raise",true,if driver :,if driver :,0.53,0.0
"def env_purge_doc(app: Sphinx, env: BuildEnvironment, docname: str) -> None: <TAB> modules = getattr(env, ""_viewcode_modules"", {}) <TAB> for modname, entry in list(modules.items()): <TAB> <TAB> if entry is False: <TAB> <TAB> <TAB> continue <TAB> <TAB> code, tags, used, refname = entry <TAB> <TAB> for fullname in list(used): <TAB> <TAB> <TAB> if used[fullname] == docname: <TAB> <TAB> <TAB> <TAB> used.pop(fullname) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> modules.pop(modname)",false,if len ( used ) == 0 :,if code == docname :,0.02,0.0
"def do_query(data, q): <TAB> ret = [] <TAB> if not q: <TAB> <TAB> return ret <TAB> qkey = q[0] <TAB> for key, value in iterate(data): <TAB> <TAB> if len(q) == 1: <TAB> <TAB> <TAB> if key == qkey: <TAB> <TAB> <TAB> <TAB> ret.append(value) <TAB> <TAB> <TAB> elif is_iterable(value): <TAB> <TAB> <TAB> <TAB> ret.extend(do_query(value, q)) <TAB> <TAB> else: <TAB> <TAB> <TAB> if not is_iterable(value): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if key == qkey: <TAB> <TAB> <TAB> <TAB> ret.extend(do_query(value, q[1:])) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> ret.extend(do_query(value, q)) <TAB> return ret",false,if not is_iterable ( value ) :,elif is_iterable ( value ) :,0.38,0.0
"def _get_bucket_for_key(self, key: bytes) -> Optional[_DBValueTuple]: <TAB> dbs: Iterable[PartitionDB] <TAB> try: <TAB> <TAB> partition = self._key_index[key] <TAB> <TAB> dbs = [PartitionDB(partition, self._dbs[partition])] <TAB> except KeyError: <TAB> <TAB> dbs = cast(Iterable[PartitionDB], self._dbs.items()) <TAB> for partition, db in dbs: <TAB> <TAB> if db.key_may_exist(key)[0]: <TAB> <TAB> <TAB> value = db.get(key) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self._key_index[key] = partition <TAB> <TAB> <TAB> <TAB> return _DBValueTuple(db, value) <TAB> return None",true,if value is not None :,if value is not None :,0.75,0.0
"def _clean(self): <TAB> logger.info(""Cleaning up..."") <TAB> if self._process is not None: <TAB> <TAB> if self._process.poll() is None: <TAB> <TAB> <TAB> for _ in range(3): <TAB> <TAB> <TAB> <TAB> self._process.terminate() <TAB> <TAB> <TAB> <TAB> time.sleep(0.5) <TAB> <TAB> <TAB> <TAB> if self._process.poll() is not None: <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self._process.kill() <TAB> <TAB> <TAB> <TAB> self._process.wait() <TAB> <TAB> <TAB> <TAB> logger.error(""KILLED"") <TAB> if os.path.exists(self._tmp_dir): <TAB> <TAB> shutil.rmtree(self._tmp_dir) <TAB> self._process = None <TAB> self._ws = None <TAB> logger.info(""Cleanup complete"")",false,if self . _process . poll ( ) is not None :,if self . _process . poll ( ) is None :,0.49,0.0
"def _calculate_runtimes(states): <TAB> results = {""runtime"": 0.00, ""num_failed_states"": 0, ""num_passed_states"": 0} <TAB> for state, resultset in states.items(): <TAB> <TAB> if isinstance(resultset, dict) and ""duration"" in resultset: <TAB> <TAB> <TAB> # Count the pass vs failures <TAB> <TAB> <TAB> if resultset[""result""]: <TAB> <TAB> <TAB> <TAB> results[""num_passed_states""] += 1 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> results[""num_failed_states""] += 1 <TAB> <TAB> <TAB> # Count durations <TAB> <TAB> <TAB> results[""runtime""] += resultset[""duration""] <TAB> log.debug(""Parsed state metrics: {}"".format(results)) <TAB> return results",true,"if resultset [ ""result"" ] :","if resultset [ ""result"" ] :",0.75,0.0
"def spaces_after(token, prev, next, min=-1, max=-1, min_desc=None, max_desc=None): <TAB> if next is not None and token.end_mark.line == next.start_mark.line: <TAB> <TAB> spaces = next.start_mark.pointer - token.end_mark.pointer <TAB> <TAB> if max != -1 and spaces > max: <TAB> <TAB> <TAB> return LintProblem( <TAB> <TAB> <TAB> <TAB> token.start_mark.line + 1, next.start_mark.column, max_desc <TAB> <TAB> <TAB> ) <TAB> <TAB> elif min != -1 and spaces < min: <TAB> <TAB> <TAB> return LintProblem( <TAB> <TAB> <TAB> <TAB> token.start_mark.line + 1, next.start_mark.column + 1, min_desc <TAB> <TAB> <TAB> )",true,elif min != - 1 and spaces < min :,elif min != - 1 and spaces < min :,1.0,0.0
"def getfileinfo(name): <TAB> finfo = FInfo() <TAB> with io.open(name, ""rb"") as fp: <TAB> <TAB> # Quick check for textfile <TAB> <TAB> data = fp.read(512) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> finfo.Type = ""TEXT"" <TAB> <TAB> fp.seek(0, 2) <TAB> <TAB> dsize = fp.tell() <TAB> dir, file = os.path.split(name) <TAB> file = file.replace("":"", ""-"", 1) <TAB> return file, finfo, dsize, 0",false,if 0 not in data :,"if ""text"" in data :",0.12,0.0
"def dict_to_XML(tag, dictionary, **kwargs): <TAB> """"""Return XML element converting dicts recursively."""""" <TAB> elem = Element(tag, **kwargs) <TAB> for key, val in dictionary.items(): <TAB> <TAB> if tag == ""layers"": <TAB> <TAB> <TAB> child = dict_to_XML(""layer"", val, name=key) <TAB> <TAB> elif isinstance(val, MutableMapping): <TAB> <TAB> <TAB> child = dict_to_XML(key, val) <TAB> <TAB> else: <TAB> <TAB> <TAB> if tag == ""config"": <TAB> <TAB> <TAB> <TAB> child = Element(""variable"", name=key) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> child = Element(key) <TAB> <TAB> <TAB> child.text = str(val) <TAB> <TAB> elem.append(child) <TAB> return elem",false,"elif isinstance ( val , MutableMapping ) :","if tag == ""layers"" :",0.01,0.0
"def _read_bytes(self, length): <TAB> buffer = b"""" <TAB> while length: <TAB> <TAB> chunk = self.request.recv(length) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> log.debug(""Connection closed"") <TAB> <TAB> <TAB> return False <TAB> <TAB> length -= len(chunk) <TAB> <TAB> buffer += chunk <TAB> return buffer",false,"if chunk == b"""" :",if not chunk :,0.04,0.0
"def rec_deps(services, container_by_name, cnt, init_service): <TAB> deps = cnt[""_deps""] <TAB> for dep in deps.copy(): <TAB> <TAB> dep_cnts = services.get(dep) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> dep_cnt = container_by_name.get(dep_cnts[0]) <TAB> <TAB> if dep_cnt: <TAB> <TAB> <TAB> # TODO: avoid creating loops, A->B->A <TAB> <TAB> <TAB> if init_service and init_service in dep_cnt[""_deps""]: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_deps = rec_deps(services, container_by_name, dep_cnt, init_service) <TAB> <TAB> <TAB> deps.update(new_deps) <TAB> return deps",true,if not dep_cnts :,if not dep_cnts :,0.75,0.0
"def fix_repeating_arguments(self): <TAB> """"""Fix elements that should accumulate/increment values."""""" <TAB> either = [list(child.children) for child in transform(self).children] <TAB> for case in either: <TAB> <TAB> for e in [child for child in case if case.count(child) > 1]: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if e.value is None: <TAB> <TAB> <TAB> <TAB> <TAB> e.value = [] <TAB> <TAB> <TAB> <TAB> elif type(e.value) is not list: <TAB> <TAB> <TAB> <TAB> <TAB> e.value = e.value.split() <TAB> <TAB> <TAB> if type(e) is Command or type(e) is Option and e.argcount == 0: <TAB> <TAB> <TAB> <TAB> e.value = 0 <TAB> return self",false,if type ( e ) is Argument or type ( e ) is Option and e . argcount :,if type ( e ) is Argument or type ( e ) is Option and e . argcount == 0 :,0.88,0.0
"def do_cli(manager, options): <TAB> header = [""Name"", ""Description""] <TAB> table_data = [header] <TAB> for filter_name, filter in get_filters(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> filter_doc = inspect.getdoc(filter) or """" <TAB> <TAB> table_data.append([filter_name, filter_doc]) <TAB> try: <TAB> <TAB> table = TerminalTable(options.table_type, table_data) <TAB> except TerminalTableError as e: <TAB> <TAB> console(""ERROR: %s"" % str(e)) <TAB> else: <TAB> <TAB> console(table.output)",false,if options . name and not options . name in filter_name :,if filter is None :,0.05,0.0
"def _do_cmp(f1, f2): <TAB> bufsize = BUFSIZE <TAB> with open(f1, ""rb"") as fp1, open(f2, ""rb"") as fp2: <TAB> <TAB> while True: <TAB> <TAB> <TAB> b1 = fp1.read(bufsize) <TAB> <TAB> <TAB> b2 = fp2.read(bufsize) <TAB> <TAB> <TAB> if b1 != b2: <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return True",false,if not b1 :,if b1 == b2 :,0.05,0.0
"def apply(self, db, person): <TAB> families = person.get_parent_family_handle_list() <TAB> if families == []: <TAB> <TAB> return True <TAB> for family_handle in person.get_parent_family_handle_list(): <TAB> <TAB> family = db.get_family_from_handle(family_handle) <TAB> <TAB> if family: <TAB> <TAB> <TAB> father_handle = family.get_father_handle() <TAB> <TAB> <TAB> mother_handle = family.get_mother_handle() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> if not mother_handle: <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",true,if not father_handle :,if not father_handle :,0.75,0.0
"def caesar_cipher(s, k): <TAB> result = """" <TAB> for char in s: <TAB> <TAB> n = ord(char) <TAB> <TAB> if 64 < n < 91: <TAB> <TAB> <TAB> n = ((n - 65 + k) % 26) + 65 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> n = ((n - 97 + k) % 26) + 97 <TAB> <TAB> result = result + chr(n) <TAB> return result",false,if 96 < n < 123 :,if 64 < n < 97 :,0.34,0.0
"def title_by_index(self, trans, index, context): <TAB> d_type = self.get_datatype(trans, context) <TAB> for i, (composite_name, composite_file) in enumerate(d_type.writable_files.items()): <TAB> <TAB> if i == index: <TAB> <TAB> <TAB> rval = composite_name <TAB> <TAB> <TAB> if composite_file.description: <TAB> <TAB> <TAB> <TAB> rval = ""{} ({})"".format(rval, composite_file.description) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> rval = ""%s [optional]"" % rval <TAB> <TAB> <TAB> return rval <TAB> if index < self.get_file_count(trans, context): <TAB> <TAB> return ""Extra primary file"" <TAB> return None",true,if composite_file . optional :,if composite_file . optional :,0.75,0.0
"def __str__(self): <TAB> t = "" <TAB>"" <TAB> if self._name != ""root"": <TAB> <TAB> r = f""{t * (self._level-1)}{self._name}:\n"" <TAB> else: <TAB> <TAB> r = """" <TAB> level = self._level <TAB> for i, (k, v) in enumerate(self._pointer.items()): <TAB> <TAB> if isinstance(v, Config): <TAB> <TAB> <TAB> r += f""{t * (self._level)}{v}\n"" <TAB> <TAB> <TAB> self._level += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> r += f""{t * (self._level)}{k}: {v} ({type(v).__name__})\n"" <TAB> <TAB> self._level = level <TAB> return r[:-1]",true,"if isinstance ( v , Config ) :","if isinstance ( v , Config ) :",0.75,0.0
"def __get_securitygroups(vm_): <TAB> vm_securitygroups = config.get_cloud_config_value( <TAB> <TAB> ""securitygroups"", vm_, __opts__, search_global=False <TAB> ) <TAB> if not vm_securitygroups: <TAB> <TAB> return [] <TAB> securitygroups = list_securitygroups() <TAB> for i in range(len(vm_securitygroups)): <TAB> <TAB> vm_securitygroups[i] = six.text_type(vm_securitygroups[i]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise SaltCloudNotFound( <TAB> <TAB> <TAB> <TAB> ""The specified securitygroups '{0}' could not be found."".format( <TAB> <TAB> <TAB> <TAB> <TAB> vm_securitygroups[i] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return vm_securitygroups",false,if vm_securitygroups [ i ] not in securitygroups :,if i not in securitygroups :,0.27,0.0
"def assert_walk_snapshot( <TAB> self, field, filespecs_or_globs, paths, ignore_patterns=None, prepare=None ): <TAB> with self.mk_project_tree(ignore_patterns=ignore_patterns) as project_tree: <TAB> <TAB> scheduler = self.mk_scheduler( <TAB> <TAB> <TAB> rules=create_fs_rules(), project_tree=project_tree <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> prepare(project_tree) <TAB> <TAB> result = self.execute(scheduler, Snapshot, self.specs(filespecs_or_globs))[0] <TAB> <TAB> self.assertEqual(sorted(getattr(result, field)), sorted(paths))",true,if prepare :,if prepare :,0.53,0.0
"def _parse_rowids(self, rowids): <TAB> xploded = [] <TAB> rowids = [x.strip() for x in rowids.split("","")] <TAB> for rowid in rowids: <TAB> <TAB> try: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> start = int(rowid.split(""-"")[0].strip()) <TAB> <TAB> <TAB> <TAB> end = int(rowid.split(""-"")[-1].strip()) <TAB> <TAB> <TAB> <TAB> xploded += range(start, end + 1) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> xploded.append(int(rowid)) <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> continue <TAB> return sorted(list(set(xploded)))",true,"if ""-"" in rowid :","if ""-"" in rowid :",0.75,0.0
"def ensemble(self, pairs, other_preds): <TAB> """"""Ensemble the dict with statistical model predictions."""""" <TAB> lemmas = [] <TAB> assert len(pairs) == len(other_preds) <TAB> for p, pred in zip(pairs, other_preds): <TAB> <TAB> w, pos = p <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> lemma = self.composite_dict[(w, pos)] <TAB> <TAB> elif w in self.word_dict: <TAB> <TAB> <TAB> lemma = self.word_dict[w] <TAB> <TAB> else: <TAB> <TAB> <TAB> lemma = pred <TAB> <TAB> if lemma is None: <TAB> <TAB> <TAB> lemma = w <TAB> <TAB> lemmas.append(lemma) <TAB> return lemmas",true,"if ( w , pos ) in self . composite_dict :","if ( w , pos ) in self . composite_dict :",0.75,0.0
"def selectionToChunks(self, remove=False, add=False): <TAB> box = self.selectionBox() <TAB> if box: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.selectedChunks = set(self.level.allChunks) <TAB> <TAB> <TAB> return <TAB> <TAB> selectedChunks = self.selectedChunks <TAB> <TAB> boxedChunks = set(box.chunkPositions) <TAB> <TAB> if boxedChunks.issubset(selectedChunks): <TAB> <TAB> <TAB> remove = True <TAB> <TAB> if remove and not add: <TAB> <TAB> <TAB> selectedChunks.difference_update(boxedChunks) <TAB> <TAB> else: <TAB> <TAB> <TAB> selectedChunks.update(boxedChunks) <TAB> self.selectionTool.selectNone()",false,if box == self . level . bounds :,if remove and add :,0.02,0.0
"def _ensure_max_size(cls, image, max_size, interpolation): <TAB> if max_size is not None: <TAB> <TAB> size = max(image.shape[0], image.shape[1]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> resize_factor = max_size / size <TAB> <TAB> <TAB> new_height = int(image.shape[0] * resize_factor) <TAB> <TAB> <TAB> new_width = int(image.shape[1] * resize_factor) <TAB> <TAB> <TAB> image = ia.imresize_single_image( <TAB> <TAB> <TAB> <TAB> image, (new_height, new_width), interpolation=interpolation <TAB> <TAB> <TAB> ) <TAB> return image",false,if size > max_size :,if size is not None :,0.06,0.0
"def _1_0_cloud_ips(self, method, url, body, headers): <TAB> if method == ""GET"": <TAB> <TAB> return self.test_response(httplib.OK, self.fixtures.load(""list_cloud_ips.json"")) <TAB> elif method == ""POST"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> body = json.loads(body) <TAB> <TAB> node = json.loads(self.fixtures.load(""create_cloud_ip.json"")) <TAB> <TAB> if ""reverse_dns"" in body: <TAB> <TAB> <TAB> node[""reverse_dns""] = body[""reverse_dns""] <TAB> <TAB> return self.test_response(httplib.ACCEPTED, json.dumps(node))",false,if body :,"if ""reverse_dns"" not in body :",0.09,0.0
"def get_formatted_stats(self): <TAB> """"""Get percentage or number of rar's done"""""" <TAB> if self.cur_setname and self.cur_setname in self.total_volumes: <TAB> <TAB> # This won't work on obfuscated posts <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ""%02d/%02d"" % (self.cur_volume, self.total_volumes[self.cur_setname]) <TAB> return self.cur_volume",false,if self . total_volumes [ self . cur_setname ] >= self . cur_volume and self . cur_volume :,if self . cur_volume in self . total_volumes :,0.12,0.0
"def wdayset(self, year, month, day): <TAB> # We need to handle cross-year weeks here. <TAB> dset = [None] * (self.yearlen + 7) <TAB> i = datetime.date(year, month, day).toordinal() - self.yearordinal <TAB> start = i <TAB> for j in range(7): <TAB> <TAB> dset[i] = i <TAB> <TAB> i += 1 <TAB> <TAB> # if (not (0 <= i < self.yearlen) or <TAB> <TAB> # <TAB>self.wdaymask[i] == self.rrule._wkst): <TAB> <TAB> # This will cross the year boundary, if necessary. <TAB> <TAB> if self.wdaymask[i] == self.rrule._wkst: <TAB> <TAB> <TAB> break <TAB> return dset, start, i",true,if self . wdaymask [ i ] == self . rrule . _wkst :,if self . wdaymask [ i ] == self . rrule . _wkst :,1.0,0.0
"def do_acquire_read_lock(self, wait=True): <TAB> self.condition.acquire() <TAB> try: <TAB> <TAB> # see if a synchronous operation is waiting to start <TAB> <TAB> # or is already running, in which case we wait (or just <TAB> <TAB> # give up and return) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> while self.current_sync_operation is not None: <TAB> <TAB> <TAB> <TAB> self.condition.wait() <TAB> <TAB> else: <TAB> <TAB> <TAB> if self.current_sync_operation is not None: <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> self.asynch += 1 <TAB> finally: <TAB> <TAB> self.condition.release() <TAB> if not wait: <TAB> <TAB> return True",true,if wait :,if wait :,0.53,0.0
"def _blend(x, y):  # pylint: disable=invalid-name <TAB> """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB> if isinstance(x, (dict, OrderedDict)): <TAB> <TAB> if not isinstance(y, (dict, OrderedDict)): <TAB> <TAB> <TAB> return y <TAB> <TAB> return _merge(x, y, recursion_func=_blend) <TAB> if isinstance(x, (list, tuple)): <TAB> <TAB> if not isinstance(y, (list, tuple)): <TAB> <TAB> <TAB> return y <TAB> <TAB> result = [_blend(*i) for i in zip(x, y)] <TAB> <TAB> if len(x) > len(y): <TAB> <TAB> <TAB> result += x[len(y) :] <TAB> <TAB> elif len(x) < len(y): <TAB> <TAB> <TAB> result += y[len(x) :] <TAB> <TAB> return result <TAB> return y",false,"if not isinstance ( y , ( dict , OrderedDict ) ) :",if len ( x ) > len ( y ) :,0.03,0.0
"def update_forum_nums_topic_post(modeladmin, request, queryset): <TAB> for forum in queryset: <TAB> <TAB> forum.num_topics = forum.count_nums_topic() <TAB> <TAB> forum.num_posts = forum.count_nums_post() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> forum.last_post = forum.topic_set.order_by(""-last_reply_on"")[0].last_post <TAB> <TAB> else: <TAB> <TAB> <TAB> forum.last_post = """" <TAB> <TAB> forum.save()",false,if forum . num_topics :,if forum . topic_set :,0.39,0.0
"def get_docname_for_node(self, node: Node) -> str: <TAB> while node: <TAB> <TAB> if isinstance(node, nodes.document): <TAB> <TAB> <TAB> return self.env.path2doc(node[""source""]) <TAB> <TAB> elif isinstance(node, addnodes.start_of_file): <TAB> <TAB> <TAB> return node[""docname""] <TAB> <TAB> else: <TAB> <TAB> <TAB> node = node.parent <TAB> return None  # never reached here. only for type hinting",true,"elif isinstance ( node , addnodes . start_of_file ) :","elif isinstance ( node , addnodes . start_of_file ) :",0.75,0.0
"def _selected_machines(self, virtual_machines): <TAB> selected_machines = [] <TAB> for machine in virtual_machines: <TAB> <TAB> if self._args.host and self._args.host == machine.name: <TAB> <TAB> <TAB> selected_machines.append(machine) <TAB> <TAB> if self.tags and self._tags_match(machine.tags, self.tags): <TAB> <TAB> <TAB> selected_machines.append(machine) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> selected_machines.append(machine) <TAB> return selected_machines",false,if self . locations and machine . location in self . locations :,if machine not in self . selected_machines :,0.12,0.0
"def transform_kwarg(self, name, value, split_single_char_options): <TAB> if len(name) == 1: <TAB> <TAB> if value is True: <TAB> <TAB> <TAB> return [""-%s"" % name] <TAB> <TAB> elif value not in (False, None): <TAB> <TAB> <TAB> if split_single_char_options: <TAB> <TAB> <TAB> <TAB> return [""-%s"" % name, ""%s"" % value] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return [""-%s%s"" % (name, value)] <TAB> else: <TAB> <TAB> if value is True: <TAB> <TAB> <TAB> return [""--%s"" % dashify(name)] <TAB> <TAB> elif value is not False and value is not None: <TAB> <TAB> <TAB> return [""--%s=%s"" % (dashify(name), value)] <TAB> return []",true,"elif value not in ( False , None ) :","elif value not in ( False , None ) :",0.75,0.0
"def indent(elem, level=0): <TAB> i = ""\n"" + level * ""  "" <TAB> if len(elem): <TAB> <TAB> if not elem.text or not elem.text.strip(): <TAB> <TAB> <TAB> elem.text = i + ""  "" <TAB> <TAB> if not elem.tail or not elem.tail.strip(): <TAB> <TAB> <TAB> elem.tail = i <TAB> <TAB> for elem in elem: <TAB> <TAB> <TAB> indent(elem, level + 1) <TAB> <TAB> if not elem.tail or not elem.tail.strip(): <TAB> <TAB> <TAB> elem.tail = i <TAB> else: <TAB> <TAB> if level and (not elem.tail or not elem.tail.strip()): <TAB> <TAB> <TAB> elem.tail = i",true,if level and ( not elem . tail or not elem . tail . strip ( ) ) :,if level and ( not elem . tail or not elem . tail . strip ( ) ) :,1.0,0.0
"def _run_instances_op(self, op, instance_ids, **kwargs): <TAB> while instance_ids: <TAB> <TAB> try: <TAB> <TAB> <TAB> return self.manager.retry(op, InstanceIds=instance_ids, **kwargs) <TAB> <TAB> except ClientError as e: <TAB> <TAB> <TAB> if e.response[""Error""][""Code""] == ""IncorrectInstanceState"": <TAB> <TAB> <TAB> <TAB> instance_ids.remove(extract_instance_id(e)) <TAB> <TAB> <TAB> raise",true,"if e . response [ ""Error"" ] [ ""Code"" ] == ""IncorrectInstanceState"" :","if e . response [ ""Error"" ] [ ""Code"" ] == ""IncorrectInstanceState"" :",0.75,0.0
"def runTest(self): <TAB> self.poco(text=""wait UI"").click() <TAB> bomb_count = 0 <TAB> while True: <TAB> <TAB> blue_fish = self.poco(""fish_emitter"").child(""blue"") <TAB> <TAB> yellow_fish = self.poco(""fish_emitter"").child(""yellow"") <TAB> <TAB> bomb = self.poco(""fish_emitter"").child(""bomb"") <TAB> <TAB> fish = self.poco.wait_for_any([blue_fish, yellow_fish, bomb]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> bomb_count += 1 <TAB> <TAB> <TAB> if bomb_count > 3: <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> else: <TAB> <TAB> <TAB> fish.click() <TAB> <TAB> time.sleep(2.5)",false,if fish is bomb :,if fish :,0.07,0.0
"def lineWidth(self, lw=None): <TAB> """"""Set/get width of mesh edges. Same as `lw()`."""""" <TAB> if lw is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.GetProperty().EdgeVisibilityOff() <TAB> <TAB> <TAB> self.GetProperty().SetRepresentationToSurface() <TAB> <TAB> <TAB> return self <TAB> <TAB> self.GetProperty().EdgeVisibilityOn() <TAB> <TAB> self.GetProperty().SetLineWidth(lw) <TAB> else: <TAB> <TAB> return self.GetProperty().GetLineWidth() <TAB> return self",true,if lw == 0 :,if lw == 0 :,0.75,0.0
"def _current_date_updater(doc, field_name, value): <TAB> if isinstance(doc, dict): <TAB> <TAB> if value == {""$type"": ""timestamp""}: <TAB> <TAB> <TAB> # TODO(juannyg): get_current_timestamp should also be using helpers utcnow, <TAB> <TAB> <TAB> # as it currently using time.time internally <TAB> <TAB> <TAB> doc[field_name] = helpers.get_current_timestamp() <TAB> <TAB> else: <TAB> <TAB> <TAB> doc[field_name] = mongomock.utcnow()",true,"if value == { ""$type"" : ""timestamp"" } :","if value == { ""$type"" : ""timestamp"" } :",0.75,0.0
"def fill_members(self): <TAB> if self._get_retrieve(): <TAB> <TAB> after = self.after.id if self.after else None <TAB> <TAB> data = await self.get_members(self.guild.id, self.retrieve, after) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # no data, terminate <TAB> <TAB> <TAB> return <TAB> <TAB> if len(data) < 1000: <TAB> <TAB> <TAB> self.limit = 0  # terminate loop <TAB> <TAB> self.after = Object(id=int(data[-1][""user""][""id""])) <TAB> <TAB> for element in reversed(data): <TAB> <TAB> <TAB> await self.members.put(self.create_member(element))",true,if not data :,if not data :,0.75,0.0
"def extract(self, page, start_index=0, end_index=None): <TAB> items = [] <TAB> for extractor in self.extractors: <TAB> <TAB> extracted = extractor.extract( <TAB> <TAB> <TAB> page, start_index, end_index, self.template.ignored_regions <TAB> <TAB> ) <TAB> <TAB> for item in arg_to_iter(extracted): <TAB> <TAB> <TAB> if item: <TAB> <TAB> <TAB> <TAB> if isinstance(item, (ItemProcessor, dict)): <TAB> <TAB> <TAB> <TAB> <TAB> item[u""_template""] = self.template.id <TAB> <TAB> <TAB> <TAB> items.append(item) <TAB> return items",true,"if isinstance ( item , ( ItemProcessor , dict ) ) :","if isinstance ( item , ( ItemProcessor , dict ) ) :",0.75,0.0
"def _get_node_type_specific_fields(self, node_id: str, fields_key: str) -> Any: <TAB> fields = self.config[fields_key] <TAB> node_tags = self.provider.node_tags(node_id) <TAB> if TAG_RAY_USER_NODE_TYPE in node_tags: <TAB> <TAB> node_type = node_tags[TAG_RAY_USER_NODE_TYPE] <TAB> <TAB> if node_type not in self.available_node_types: <TAB> <TAB> <TAB> raise ValueError(f""Unknown node type tag: {node_type}."") <TAB> <TAB> node_specific_config = self.available_node_types[node_type] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> fields = node_specific_config[fields_key] <TAB> return fields",true,if fields_key in node_specific_config :,if fields_key in node_specific_config :,0.75,0.0
"def _write_all(self, writer): <TAB> """"""Writes messages and insert comments here and there."""""" <TAB> # Note: we make no assumptions about the length of original_messages and original_comments <TAB> for msg, comment in zip_longest( <TAB> <TAB> self.original_messages, self.original_comments, fillvalue=None <TAB> ): <TAB> <TAB> # msg and comment might be None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(""writing comment: "", comment) <TAB> <TAB> <TAB> writer.log_event(comment)  # we already know that this method exists <TAB> <TAB> if msg is not None: <TAB> <TAB> <TAB> print(""writing message: "", msg) <TAB> <TAB> <TAB> writer(msg)",true,if comment is not None :,if comment is not None :,0.75,0.0
"def run_tests(): <TAB> # type: () -> None <TAB> x = 5 <TAB> with switch(x) as case: <TAB> <TAB> if case(0): <TAB> <TAB> <TAB> print(""zero"") <TAB> <TAB> <TAB> print(""zero"") <TAB> <TAB> elif case(1, 2): <TAB> <TAB> <TAB> print(""one or two"") <TAB> <TAB> elif case(3, 4): <TAB> <TAB> <TAB> print(""three or four"") <TAB> <TAB> else: <TAB> <TAB> <TAB> print(""default"") <TAB> <TAB> <TAB> print(""another"")",false,if case ( 0 ) :,"elif case ( 3 , 4 ) :",0.05,0.0
"def date_to_format(value, target_format): <TAB> """"""Convert date to specified format"""""" <TAB> if target_format == str: <TAB> <TAB> if isinstance(value, datetime.date): <TAB> <TAB> <TAB> ret = value.strftime(""%d/%m/%y"") <TAB> <TAB> elif isinstance(value, datetime.datetime): <TAB> <TAB> <TAB> ret = value.strftime(""%d/%m/%y"") <TAB> <TAB> elif isinstance(value, datetime.time): <TAB> <TAB> <TAB> ret = value.strftime(""%H:%M:%S"") <TAB> else: <TAB> <TAB> ret = value <TAB> return ret",false,"elif isinstance ( value , datetime . datetime ) :","elif isinstance ( value , datetime . time ) :",0.48,0.0
"def database_app(request): <TAB> if request.param == ""postgres_app"": <TAB> <TAB> if not which(""initdb""): <TAB> <TAB> <TAB> pytest.skip(""initdb must be on PATH for postgresql fixture"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> pytest.skip(""psycopg2 must be installed for postgresql fixture"") <TAB> if request.param == ""sqlite_rabbitmq_app"": <TAB> <TAB> if not os.environ.get(""GALAXY_TEST_AMQP_INTERNAL_CONNECTION""): <TAB> <TAB> <TAB> pytest.skip( <TAB> <TAB> <TAB> <TAB> ""rabbitmq tests will be skipped if GALAXY_TEST_AMQP_INTERNAL_CONNECTION env var is unset"" <TAB> <TAB> <TAB> ) <TAB> return request.getfixturevalue(request.param)",false,if not psycopg2 :,"if ""psycopg2"" in os . environ :",0.04,0.0
"def poll_ms(self, timeout=-1): <TAB> s = bytearray(self.evbuf) <TAB><IF-STMT> <TAB> <TAB> deadline = utime.ticks_add(utime.ticks_ms(), timeout) <TAB> while True: <TAB> <TAB> n = epoll_wait(self.epfd, s, 1, timeout) <TAB> <TAB> if not os.check_error(n): <TAB> <TAB> <TAB> break <TAB> <TAB> if timeout >= 0: <TAB> <TAB> <TAB> timeout = utime.ticks_diff(deadline, utime.ticks_ms()) <TAB> <TAB> <TAB> if timeout < 0: <TAB> <TAB> <TAB> <TAB> n = 0 <TAB> <TAB> <TAB> <TAB> break <TAB> res = [] <TAB> if n > 0: <TAB> <TAB> vals = struct.unpack(epoll_event, s) <TAB> <TAB> res.append((vals[1], vals[0])) <TAB> return res",true,if timeout >= 0 :,if timeout >= 0 :,0.75,0.0
"def get_all_active_plugins(self) -> List[BotPlugin]: <TAB> """"""This returns the list of plugins in the callback ordered defined from the config."""""" <TAB> all_plugins = [] <TAB> for name in self.plugins_callback_order: <TAB> <TAB> # None is a placeholder for any plugin not having a defined order <TAB> <TAB> if name is None: <TAB> <TAB> <TAB> all_plugins += [ <TAB> <TAB> <TAB> <TAB> plugin <TAB> <TAB> <TAB> <TAB> for name, plugin in self.plugins.items() <TAB> <TAB> <TAB> <TAB> if name not in self.plugins_callback_order and plugin.is_activated <TAB> <TAB> <TAB> ] <TAB> <TAB> else: <TAB> <TAB> <TAB> plugin = self.plugins[name] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> all_plugins.append(plugin) <TAB> return all_plugins",false,if plugin . is_activated :,if plugin is not None :,0.06,0.0
"def get_expected_sql(self): <TAB> sql_base_path = path.join(path.dirname(path.realpath(__file__)), ""sql"") <TAB> # Iterate the version mapping directories. <TAB> for version_mapping in get_version_mapping_directories(self.server[""type""]): <TAB> <TAB> if version_mapping[""number""] > self.server_information[""server_version""]: <TAB> <TAB> <TAB> continue <TAB> <TAB> complete_path = path.join(sql_base_path, version_mapping[""name""]) <TAB> <TAB> if not path.exists(complete_path): <TAB> <TAB> <TAB> continue <TAB> <TAB> break <TAB> data_sql = """" <TAB> with open(path.join(complete_path, ""test_sql_output.sql"")) as fp: <TAB> <TAB> data_sql = fp.read() <TAB> return data_sql",true,"if version_mapping [ ""number"" ] > self . server_information [ ""server_version"" ] :","if version_mapping [ ""number"" ] > self . server_information [ ""server_version"" ] :",0.75,0.0
"def _validate_headers(self, headers): <TAB> if headers is None: <TAB> <TAB> return headers <TAB> res = {} <TAB> for key, value in headers.items(): <TAB> <TAB> if isinstance(value, (int, float)): <TAB> <TAB> <TAB> value = str(value) <TAB> <TAB> if not isinstance(key, (bytes, str)) or not isinstance(value, (bytes, str)): <TAB> <TAB> <TAB> raise ScriptError( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> ""message"": ""headers must be a table"" <TAB> <TAB> <TAB> <TAB> <TAB> "" with strings as keys and values."" <TAB> <TAB> <TAB> <TAB> <TAB> ""Header: `{!r}:{!r}` is not valid"".format(key, value) <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> <TAB> res[key] = value <TAB> return res",false,"if not isinstance ( key , ( bytes , str ) ) or not isinstance ( value , ( bytes , str ) ) :","if isinstance ( value , ( int , float ) ) :",0.09,0.0
"def _get_literal_value(self, pyval): <TAB> if pyval == self.vm.lookup_builtin(""builtins.True""): <TAB> <TAB> return True <TAB> elif pyval == self.vm.lookup_builtin(""builtins.False""): <TAB> <TAB> return False <TAB> elif isinstance(pyval, str): <TAB> <TAB> prefix, value = parser_constants.STRING_RE.match(pyval).groups()[:2] <TAB> <TAB> value = value[1:-1]  # remove quotation marks <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> value = compat.bytestring(value) <TAB> <TAB> elif ""u"" in prefix and self.vm.PY2: <TAB> <TAB> <TAB> value = compat.UnicodeType(value) <TAB> <TAB> return value <TAB> else: <TAB> <TAB> return pyval",false,"if ""b"" in prefix and not self . vm . PY2 :","if ""s"" in prefix and self . vm . PY2 :",0.41,0.0
"def decode_query_ids(self, trans, conditional): <TAB> if conditional.operator == ""and"": <TAB> <TAB> self.decode_query_ids(trans, conditional.left) <TAB> <TAB> self.decode_query_ids(trans, conditional.right) <TAB> else: <TAB> <TAB> left_base = conditional.left.split(""."")[0] <TAB> <TAB> if left_base in self.FIELDS: <TAB> <TAB> <TAB> field = self.FIELDS[left_base] <TAB> <TAB> <TAB> if field.id_decode: <TAB> <TAB> <TAB> <TAB> conditional.right = trans.security.decode_id(conditional.right)",false,if left_base in self . FIELDS :,if field . id_decode :,0.11,0.0
"def testLastPhrases(self): <TAB> for day in (11, 12, 13, 14, 15, 16, 17): <TAB> <TAB> start = datetime.datetime(2012, 11, day, 9, 0, 0) <TAB> <TAB> (yr, mth, dy, _, _, _, wd, yd, isdst) = start.timetuple() <TAB> <TAB> n = 4 - wd <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> n -= 7 <TAB> <TAB> target = start + datetime.timedelta(days=n) <TAB> <TAB> self.assertExpectedResult( <TAB> <TAB> <TAB> self.cal.parse(""last friday"", start.timetuple()), <TAB> <TAB> <TAB> (target.timetuple(), 1), <TAB> <TAB> <TAB> dateOnly=True, <TAB> <TAB> )",false,if n >= 0 :,if n > 7 :,0.31,0.0
"def _convertNbCharsInNbBits(self, nbChars): <TAB> nbMinBit = None <TAB> nbMaxBit = None <TAB> if nbChars is not None: <TAB> <TAB> if isinstance(nbChars, int): <TAB> <TAB> <TAB> nbMinBit = nbChars * 8 <TAB> <TAB> <TAB> nbMaxBit = nbMinBit <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> nbMinBit = nbChars[0] * 8 <TAB> <TAB> <TAB> if nbChars[1] is not None: <TAB> <TAB> <TAB> <TAB> nbMaxBit = nbChars[1] * 8 <TAB> return (nbMinBit, nbMaxBit)",true,if nbChars [ 0 ] is not None :,if nbChars [ 0 ] is not None :,0.75,0.0
"def getpystone(): <TAB> # Start calculation <TAB> maxpystone = 0 <TAB> # Start with a short run, find the the pystone, and increase runtime until duration took > 0.1 second <TAB> for pyseed in [1000, 2000, 5000, 10000, 20000, 50000, 100000, 200000]: <TAB> <TAB> duration, pystonefloat = pystones(pyseed) <TAB> <TAB> maxpystone = max(maxpystone, int(pystonefloat)) <TAB> <TAB> # Stop when pystone() has been running for at least 0.1 second <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> return maxpystone",false,if duration > 0.1 :,if duration < 0.1 :,0.33,0.0
"def _append_to_io_queue(self, data, stream_name): <TAB> # Make sure ANSI CSI codes and object links are stored as separate events <TAB> # TODO: try to complete previously submitted incomplete code <TAB> parts = re.split(OUTPUT_SPLIT_REGEX, data) <TAB> for part in parts: <TAB> <TAB><IF-STMT>  # split may produce empty string in the beginning or start <TAB> <TAB> <TAB> # split the data so that very long lines separated <TAB> <TAB> <TAB> for block in re.split( <TAB> <TAB> <TAB> <TAB> ""(.{%d,})"" % (self._get_squeeze_threshold() + 1), part <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> if block: <TAB> <TAB> <TAB> <TAB> <TAB> self._queued_io_events.append((block, stream_name))",false,if part :,if not part :,0.11,0.0
"def qtTypeIdent(conn, *args): <TAB> # We're not using the conn object at the moment, but - we will <TAB> # modify the <TAB> # logic to use the server version specific keywords later. <TAB> res = None <TAB> value = None <TAB> for val in args: <TAB> <TAB> # DataType doesn't have len function then convert it to string <TAB> <TAB> if not hasattr(val, ""__len__""): <TAB> <TAB> <TAB> val = str(val) <TAB> <TAB> if len(val) == 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> value = val <TAB> <TAB> if Driver.needsQuoting(val, True): <TAB> <TAB> <TAB> value = value.replace('""', '""""') <TAB> <TAB> <TAB> value = '""' + value + '""' <TAB> <TAB> res = ((res and res + ""."") or """") + value <TAB> return res",false,"if not hasattr ( val , ""__len__"" ) :","if Driver . needsQuoting ( val , True ) :",0.07,0.0
"def SetVerbose(self, level): <TAB> """"""Sets the verbose level."""""" <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> level = int(level) <TAB> <TAB> if (level >= 0) and (level <= 3): <TAB> <TAB> <TAB> self._verbose = level <TAB> <TAB> <TAB> return <TAB> except ValueError: <TAB> <TAB> pass <TAB> self.Error(""Verbose level (%s) must be between 0 and 3 inclusive."" % level)",false,if type ( level ) != types . IntType :,if level is not None :,0.01,0.0
"def step(self) -> None: <TAB> """"""Performs a single optimization step."""""" <TAB> for group in self.param_groups: <TAB> <TAB> for p in group[""params""]: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> p.add_(p.grad, alpha=(-group[""lr""] * self.num_data)) <TAB> return None",true,if p . grad is None :,if p . grad is None :,0.75,0.0
"def fill(self, values): <TAB> if lupa.lua_type(values) != ""table"": <TAB> <TAB> raise ScriptError( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> ""argument"": ""values"", <TAB> <TAB> <TAB> <TAB> ""message"": ""element:fill values is not a table"", <TAB> <TAB> <TAB> <TAB> ""splash_method"": ""fill"", <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> # marking all tables as arrays by default <TAB> for key, value in values.items(): <TAB> <TAB> if lupa.lua_type(value) == ""table"": <TAB> <TAB> <TAB> _mark_table_as_array(self.lua, value) <TAB> values = self.lua.lua2python(values) <TAB> return self.element.fill(values)",true,"if lupa . lua_type ( value ) == ""table"" :","if lupa . lua_type ( value ) == ""table"" :",0.75,0.0
"def _gen_repr(self, buf): <TAB> print >> buf, "" <TAB>def __repr__(self):"" <TAB> if self.argnames: <TAB> <TAB> fmt = COMMA.join([""%s""] * self.nargs) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> fmt = ""(%s)"" % fmt <TAB> <TAB> vals = [""repr(self.%s)"" % name for name in self.argnames] <TAB> <TAB> vals = COMMA.join(vals) <TAB> <TAB> if self.nargs == 1: <TAB> <TAB> <TAB> vals = vals + "","" <TAB> <TAB> print >> buf, ' <TAB> <TAB>return ""%s(%s)"" %% (%s)' % (self.name, fmt, vals) <TAB> else: <TAB> <TAB> print >> buf, ' <TAB> <TAB>return ""%s()""' % self.name",false,"if ""("" in self . args :",if self . nargs == 1 :,0.04,0.0
"def render_observation(self): <TAB> x = self.read_head_position <TAB> label = ""Observation Grid <TAB>: "" <TAB> x_str = """" <TAB> for j in range(-1, self.rows + 1): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> x_str += "" "" * len(label) <TAB> <TAB> for i in range(-2, self.input_width + 2): <TAB> <TAB> <TAB> if i == x[0] and j == x[1]: <TAB> <TAB> <TAB> <TAB> x_str += colorize(self._get_str_obs((i, j)), ""green"", highlight=True) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> x_str += self._get_str_obs((i, j)) <TAB> <TAB> x_str += ""\n"" <TAB> x_str = label + x_str <TAB> return x_str",false,if j != - 1 :,if j != 0 :,0.12,0.0
"def get_module_comment(self, attrname: str) -> Optional[List[str]]: <TAB> try: <TAB> <TAB> analyzer = ModuleAnalyzer.for_module(self.modname) <TAB> <TAB> analyzer.analyze() <TAB> <TAB> key = ("""", attrname) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return list(analyzer.attr_docs[key]) <TAB> except PycodeError: <TAB> <TAB> pass <TAB> return None",true,if key in analyzer . attr_docs :,if key in analyzer . attr_docs :,0.75,0.0
"def tms_to_quadkey(self, tms, google=False): <TAB> quadKey = """" <TAB> x, y, z = tms <TAB> # this algorithm works with google tiles, rather than tms, so convert <TAB> # to those first. <TAB> if not google: <TAB> <TAB> y = (2 ** z - 1) - y <TAB> for i in range(z, 0, -1): <TAB> <TAB> digit = 0 <TAB> <TAB> mask = 1 << (i - 1) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> digit += 1 <TAB> <TAB> if (y & mask) != 0: <TAB> <TAB> <TAB> digit += 2 <TAB> <TAB> quadKey += str(digit) <TAB> return quadKey",true,if ( x & mask ) != 0 :,if ( x & mask ) != 0 :,0.75,0.0
"def test_enumerate(app): <TAB> async with new_stream(app) as stream: <TAB> <TAB> for i in range(100): <TAB> <TAB> <TAB> await stream.channel.deliver(message(key=i, value=i * 4)) <TAB> <TAB> async for i, value in stream.enumerate(): <TAB> <TAB> <TAB> current_event = stream.current_event <TAB> <TAB> <TAB> assert i == current_event.key <TAB> <TAB> <TAB> assert value == i * 4 <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> assert await channel_empty(stream.channel)",false,if i >= 99 :,if i == 100 :,0.31,0.0
"def print_messages(self): <TAB> output_reports = self.config.get_output_report() <TAB> for report in output_reports: <TAB> <TAB> output_format, output_files = report <TAB> <TAB> self.summary[""formatter""] = output_format <TAB> <TAB> formatter = FORMATTERS[output_format]( <TAB> <TAB> <TAB> self.summary, self.messages, self.config.profile <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.write_to(formatter, sys.stdout) <TAB> <TAB> for output_file in output_files: <TAB> <TAB> <TAB> with open(output_file, ""w+"") as target: <TAB> <TAB> <TAB> <TAB> self.write_to(formatter, target)",false,if not output_files :,if self . output_files :,0.08,0.0
"def eval_metrics(self): <TAB> for task in self.task_list: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return [ <TAB> <TAB> <TAB> <TAB> metrics.Metrics.ACC, <TAB> <TAB> <TAB> <TAB> metrics.Metrics.NEG_LOG_PERPLEXITY, <TAB> <TAB> <TAB> <TAB> metrics.Metrics.ROUGE_2_F, <TAB> <TAB> <TAB> <TAB> metrics.Metrics.ROUGE_L_F, <TAB> <TAB> <TAB> ] <TAB> return [ <TAB> <TAB> metrics.Metrics.ACC, <TAB> <TAB> metrics.Metrics.NEG_LOG_PERPLEXITY, <TAB> ]",false,"if ""summarize"" in task . name :",if task . is_run :,0.04,0.0
"def _getBuildRequestForBrdict(self, brdict): <TAB> # Turn a brdict into a BuildRequest into a brdict. This is useful <TAB> # for API like 'nextBuild', which operate on BuildRequest objects. <TAB> breq = self.breqCache.get(brdict[""buildrequestid""]) <TAB> if not breq: <TAB> <TAB> breq = yield BuildRequest.fromBrdict(self.master, brdict) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.breqCache[brdict[""buildrequestid""]] = breq <TAB> defer.returnValue(breq)",true,if breq :,if breq :,0.53,0.0
"def _stash_splitter(states): <TAB> keep, split = [], [] <TAB> if state_func is not None: <TAB> <TAB> for s in states: <TAB> <TAB> <TAB> ns = state_func(s) <TAB> <TAB> <TAB> if isinstance(ns, SimState): <TAB> <TAB> <TAB> <TAB> split.append(ns) <TAB> <TAB> <TAB> elif isinstance(ns, (list, tuple, set)): <TAB> <TAB> <TAB> <TAB> split.extend(ns) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> split.append(s) <TAB> if stash_func is not None: <TAB> <TAB> split = stash_func(states) <TAB> if to_stash is not stash: <TAB> <TAB> keep = states <TAB> return keep, split",false,"if isinstance ( ns , SimState ) :","elif isinstance ( ns , ( list , tuple , set ) ) :",0.15,0.0
"def sequence_to_text(sequence): <TAB> """"""Converts a sequence of IDs back to a string"""""" <TAB> result = """" <TAB> for symbol_id in sequence: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> s = _id_to_symbol[symbol_id] <TAB> <TAB> <TAB> # Enclose ARPAbet back in curly braces: <TAB> <TAB> <TAB> if len(s) > 1 and s[0] == ""@"": <TAB> <TAB> <TAB> <TAB> s = ""{%s}"" % s[1:] <TAB> <TAB> <TAB> result += s <TAB> return result.replace(""}{"", "" "")",true,if symbol_id in _id_to_symbol :,if symbol_id in _id_to_symbol :,0.75,0.0
"def get_code(self, fullname=None): <TAB> fullname = self._fix_name(fullname) <TAB> if self.code is None: <TAB> <TAB> mod_type = self.etc[2] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> source = self.get_source(fullname) <TAB> <TAB> <TAB> self.code = compile(source, self.filename, ""exec"") <TAB> <TAB> elif mod_type == imp.PY_COMPILED: <TAB> <TAB> <TAB> self._reopen() <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> self.code = read_code(self.file) <TAB> <TAB> <TAB> finally: <TAB> <TAB> <TAB> <TAB> self.file.close() <TAB> <TAB> elif mod_type == imp.PKG_DIRECTORY: <TAB> <TAB> <TAB> self.code = self._get_delegate().get_code() <TAB> return self.code",true,if mod_type == imp . PY_SOURCE :,if mod_type == imp . PY_SOURCE :,0.75,0.0
"def identwaf(self, findall=False): <TAB> detected = list() <TAB> try: <TAB> <TAB> self.attackres = self.performCheck(self.centralAttack) <TAB> except RequestBlocked: <TAB> <TAB> return detected <TAB> for wafvendor in self.checklist: <TAB> <TAB> self.log.info(""Checking for %s"" % wafvendor) <TAB> <TAB> if self.wafdetections[wafvendor](self): <TAB> <TAB> <TAB> detected.append(wafvendor) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> self.knowledge[""wafname""] = detected <TAB> return detected",false,if not findall :,if findall :,0.1,0.0
"def SessionId(self): <TAB> """"""Returns the Session ID of the process"""""" <TAB> if self.Session.is_valid(): <TAB> <TAB> process_space = self.get_process_address_space() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return obj.Object( <TAB> <TAB> <TAB> <TAB> ""_MM_SESSION_SPACE"", offset=self.Session, vm=process_space <TAB> <TAB> <TAB> ).SessionId <TAB> return obj.NoneObject(""Cannot find process session"")",true,if process_space :,if process_space :,0.53,0.0
"def _convert_java_pattern_to_python(pattern): <TAB> """"""Convert a replacement pattern from the Java-style `$5` to the Python-style `\\5`."""""" <TAB> s = list(pattern) <TAB> i = 0 <TAB> while i < len(s) - 1: <TAB> <TAB> c = s[i] <TAB> <TAB> if c == ""$"" and s[i + 1] in ""0123456789"": <TAB> <TAB> <TAB> s[i] = ""\\"" <TAB> <TAB> elif c == ""\\"" and s[i + 1] == ""$"": <TAB> <TAB> <TAB> s[i] = """" <TAB> <TAB> <TAB> i += 1 <TAB> <TAB> i += 1 <TAB> return pattern[:0].join(s)",true,"elif c == ""\\"" and s [ i + 1 ] == ""$"" :","elif c == ""\\"" and s [ i + 1 ] == ""$"" :",1.0,0.0
"def __init__(self, coverage): <TAB> self.coverage = coverage <TAB> self.config = self.coverage.config <TAB> self.source_paths = set() <TAB> if self.config.source: <TAB> <TAB> for src in self.config.source: <TAB> <TAB> <TAB> if os.path.exists(src): <TAB> <TAB> <TAB> <TAB> if not self.config.relative_files: <TAB> <TAB> <TAB> <TAB> <TAB> src = files.canonical_filename(src) <TAB> <TAB> <TAB> <TAB> self.source_paths.add(src) <TAB> self.packages = {} <TAB> self.xml_out = None",true,if os . path . exists ( src ) :,if os . path . exists ( src ) :,0.75,0.0
"def populate_vol_format(self): <TAB> rhel6_file_whitelist = [""raw"", ""qcow2"", ""qed""] <TAB> model = self.widget(""vol-format"").get_model() <TAB> model.clear() <TAB> formats = self.vol_class.formats <TAB> if hasattr(self.vol_class, ""create_formats""): <TAB> <TAB> formats = getattr(self.vol_class, ""create_formats"") <TAB> if self.vol_class == Storage.FileVolume and not self.conn.rhel6_defaults_caps(): <TAB> <TAB> newfmts = [] <TAB> <TAB> for f in rhel6_file_whitelist: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> newfmts.append(f) <TAB> <TAB> formats = newfmts <TAB> for f in formats: <TAB> <TAB> model.append([f, f])",false,if f in formats :,if f not in formats :,0.15,0.0
"def get_file_sources(): <TAB> global _file_sources <TAB> if _file_sources is None: <TAB> <TAB> from galaxy.files import ConfiguredFileSources <TAB> <TAB> file_sources = None <TAB> <TAB> if os.path.exists(""file_sources.json""): <TAB> <TAB> <TAB> file_sources_as_dict = None <TAB> <TAB> <TAB> with open(""file_sources.json"", ""r"") as f: <TAB> <TAB> <TAB> <TAB> file_sources_as_dict = json.load(f) <TAB> <TAB> <TAB> if file_sources_as_dict is not None: <TAB> <TAB> <TAB> <TAB> file_sources = ConfiguredFileSources.from_dict(file_sources_as_dict) <TAB> <TAB> if file_sources is None: <TAB> <TAB> <TAB> ConfiguredFileSources.from_dict([]) <TAB> <TAB> _file_sources = file_sources <TAB> return _file_sources",true,"if os . path . exists ( ""file_sources.json"" ) :","if os . path . exists ( ""file_sources.json"" ) :",0.75,0.0
"def _blend(x, y):  # pylint: disable=invalid-name <TAB> """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB> if isinstance(x, (dict, OrderedDict)): <TAB> <TAB> if not isinstance(y, (dict, OrderedDict)): <TAB> <TAB> <TAB> return y <TAB> <TAB> return _merge(x, y, recursion_func=_blend) <TAB> if isinstance(x, (list, tuple)): <TAB> <TAB> if not isinstance(y, (list, tuple)): <TAB> <TAB> <TAB> return y <TAB> <TAB> result = [_blend(*i) for i in zip(x, y)] <TAB> <TAB> if len(x) > len(y): <TAB> <TAB> <TAB> result += x[len(y) :] <TAB> <TAB> elif len(x) < len(y): <TAB> <TAB> <TAB> result += y[len(x) :] <TAB> <TAB> return result <TAB> return y",true,if len ( x ) > len ( y ) :,if len ( x ) > len ( y ) :,1.0,0.0
"def copy_dicts(dct): <TAB> if ""_remote_data"" in dct: <TAB> <TAB> dsindex = dct[""_remote_data""][""_content""].dsindex <TAB> <TAB> newdct = dct.copy() <TAB> <TAB> newdct[""_remote_data""] = {""_content"": dsindex} <TAB> <TAB> return list(newdct.items()) <TAB> elif ""_data"" in dct: <TAB> <TAB> newdct = dct.copy() <TAB> <TAB> newdata = copy_dicts(dct[""_data""]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> newdct[""_data""] = newdata <TAB> <TAB> return list(newdct.items()) <TAB> return None",true,if newdata :,if newdata :,0.53,0.0
"def _import_epic_activity(self, project_data, taiga_epic, epic, options): <TAB> offset = 0 <TAB> while True: <TAB> <TAB> activities = self._client.get( <TAB> <TAB> <TAB> ""/projects/{}/epics/{}/activity"".format( <TAB> <TAB> <TAB> <TAB> project_data[""id""], <TAB> <TAB> <TAB> <TAB> epic[""id""], <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> {""envelope"": ""true"", ""limit"": 300, ""offset"": offset}, <TAB> <TAB> ) <TAB> <TAB> offset += 300 <TAB> <TAB> for activity in activities[""data""]: <TAB> <TAB> <TAB> self._import_activity(taiga_epic, activity, options) <TAB> <TAB> if len(activities[""data""]) < 300: <TAB> <TAB> <TAB> break",true,"if len ( activities [ ""data"" ] ) < 300 :","if len ( activities [ ""data"" ] ) < 300 :",0.75,0.0
"def __get__(self, instance, instance_type=None): <TAB> if instance: <TAB> <TAB> if self.att_name not in instance._obj_cache: <TAB> <TAB> <TAB> rel_obj = self.get_obj(instance) <TAB> <TAB> <TAB> if rel_obj: <TAB> <TAB> <TAB> <TAB> instance._obj_cache[self.att_name] = rel_obj <TAB> <TAB> return instance._obj_cache.get(self.att_name) <TAB> return self",true,if self . att_name not in instance . _obj_cache :,if self . att_name not in instance . _obj_cache :,0.75,0.0
"def download_main( <TAB> download, download_playlist, urls, playlist, output_dir, merge, info_only ): <TAB> for url in urls: <TAB> <TAB> if url.startswith(""https://""): <TAB> <TAB> <TAB> url = url[8:] <TAB> <TAB> if not url.startswith(""http://""): <TAB> <TAB> <TAB> url = ""http://"" + url <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> download_playlist( <TAB> <TAB> <TAB> <TAB> url, output_dir=output_dir, merge=merge, info_only=info_only <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> download(url, output_dir=output_dir, merge=merge, info_only=info_only)",true,if playlist :,if playlist :,0.53,0.0
"def _mksubs(self): <TAB> self._subs = {} <TAB> commit_dir = CommitDir(self, "".commit"") <TAB> self._subs["".commit""] = commit_dir <TAB> tag_dir = TagDir(self, "".tag"") <TAB> self._subs["".tag""] = tag_dir <TAB> for (name, sha) in git.list_refs(): <TAB> <TAB> if name.startswith(""refs/heads/""): <TAB> <TAB> <TAB> name = name[11:] <TAB> <TAB> <TAB> date = git.rev_get_date(sha.encode(""hex"")) <TAB> <TAB> <TAB> n1 = BranchList(self, name, sha) <TAB> <TAB> <TAB> n1.ctime = n1.mtime = date <TAB> <TAB> <TAB> self._subs[name] = n1",true,"if name . startswith ( ""refs/heads/"" ) :","if name . startswith ( ""refs/heads/"" ) :",0.75,0.0
"def readAtOffset(self, offset, size, shortok=False): <TAB> ret = b"""" <TAB> self.fd.seek(offset) <TAB> while len(ret) != size: <TAB> <TAB> rlen = size - len(ret) <TAB> <TAB> x = self.fd.read(rlen) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if not shortok: <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> return ret <TAB> <TAB> ret += x <TAB> return ret",false,"if x == b"""" :",if not x :,0.04,0.0
"def remove_indent(self): <TAB> """"""Remove one tab-width of blanks from the previous token."""""" <TAB> w = abs(self.tab_width) <TAB> if self.result: <TAB> <TAB> s = self.result[-1] <TAB> <TAB> if s.isspace(): <TAB> <TAB> <TAB> self.result.pop() <TAB> <TAB> <TAB> s = s.replace(""\t"", "" "" * w) <TAB> <TAB> <TAB> if s.startswith(""\n""): <TAB> <TAB> <TAB> <TAB> s2 = s[1:] <TAB> <TAB> <TAB> <TAB> self.result.append(""\n"" + s2[:-w]) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.result.append(s[:-w])",false,if s . isspace ( ) :,"if s . startswith ( ""\n"" ) :",0.1,0.0
"def flush(self, *args, **kwargs): <TAB> with self._lock: <TAB> <TAB> self._last_updated = time.time() <TAB> <TAB> try: <TAB> <TAB> <TAB> if kwargs.get(""in_place"", False): <TAB> <TAB> <TAB> <TAB> self._locked_flush_without_tempfile() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> mailbox.mbox.flush(self, *args, **kwargs) <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> if ""_create_temporary"" in traceback.format_exc(): <TAB> <TAB> <TAB> <TAB> self._locked_flush_without_tempfile() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> self._last_updated = time.time()",false,"if ""_create_temporary"" in traceback . format_exc ( ) :","if kwargs . get ( ""in_place"" , False ) :",0.03,0.0
"def _collect_manual_intervention_nodes(pipeline_tree): <TAB> for act in pipeline_tree[""activities""].values(): <TAB> <TAB> if act[""type""] == ""SubProcess"": <TAB> <TAB> <TAB> _collect_manual_intervention_nodes(act[""pipeline""]) <TAB> <TAB> elif act[""component""][""code""] in MANUAL_INTERVENTION_COMP_CODES: <TAB> <TAB> <TAB> manual_intervention_nodes.add(act[""id""])",false,"if act [ ""type"" ] == ""SubProcess"" :","elif act [ ""component"" ] [ ""code"" ] in MANUAL_INTERVENTION_COMP_CODES :",0.03,0.0
"def banned(): <TAB> if request.endpoint == ""views.themes"": <TAB> <TAB> return <TAB> if authed(): <TAB> <TAB> user = get_current_user_attrs() <TAB> <TAB> team = get_current_team_attrs() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ( <TAB> <TAB> <TAB> <TAB> render_template( <TAB> <TAB> <TAB> <TAB> <TAB> ""errors/403.html"", error=""You have been banned from this CTF"" <TAB> <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> <TAB> 403, <TAB> <TAB> <TAB> ) <TAB> <TAB> if team and team.banned: <TAB> <TAB> <TAB> return ( <TAB> <TAB> <TAB> <TAB> render_template( <TAB> <TAB> <TAB> <TAB> <TAB> ""errors/403.html"", <TAB> <TAB> <TAB> <TAB> <TAB> error=""Your team has been banned from this CTF"", <TAB> <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> <TAB> 403, <TAB> <TAB> <TAB> )",true,if user and user . banned :,if user and user . banned :,0.75,0.0
"def remove(self, values): <TAB> if not isinstance(values, (list, tuple, set)): <TAB> <TAB> values = [values] <TAB> for v in values: <TAB> <TAB> v = str(v) <TAB> <TAB> if isinstance(self._definition, dict): <TAB> <TAB> <TAB> self._definition.pop(v, None) <TAB> <TAB> elif self._definition == ""ANY"": <TAB> <TAB> <TAB> if v == ""ANY"": <TAB> <TAB> <TAB> <TAB> self._definition = [] <TAB> <TAB> elif v in self._definition: <TAB> <TAB> <TAB> self._definition.remove(v) <TAB> if ( <TAB> <TAB> self._value is not None <TAB> <TAB> and self._value not in self._definition <TAB> <TAB> and self._not_any() <TAB> ): <TAB> <TAB> raise ConanException(bad_value_msg(self._name, self._value, self.values_range))",false,elif v in self . _definition :,"if isinstance ( self . _definition , dict ) :",0.07,0.0
"def save(self, learner, file_name): <TAB> """"""Save the model to location specified in file_name."""""" <TAB> with open(file_name, ""wb"") as f: <TAB> <TAB> if hasattr(learner, ""inference_cache_""): <TAB> <TAB> <TAB> # don't store the large inference cache! <TAB> <TAB> <TAB> learner.inference_cache_, tmp = (None, learner.inference_cache_) <TAB> <TAB> <TAB> pickle.dump(learner, f, -1) <TAB> <TAB> <TAB> learner.inference_cache_ = tmp <TAB> <TAB> else: <TAB> <TAB> <TAB> pickle.dump(learner, f, -1)",true,"if hasattr ( learner , ""inference_cache_"" ) :","if hasattr ( learner , ""inference_cache_"" ) :",0.75,0.0
"def __init__(self, exprs, savelist=False): <TAB> super(ParseExpression, self).__init__(savelist) <TAB> if isinstance(exprs, _generatorType): <TAB> <TAB> exprs = list(exprs) <TAB> if isinstance(exprs, basestring): <TAB> <TAB> self.exprs = [ParserElement._literalStringClass(exprs)] <TAB> elif isinstance(exprs, collections.Iterable): <TAB> <TAB> exprs = list(exprs) <TAB> <TAB> # if sequence of strings provided, wrap with Literal <TAB> <TAB> if all(isinstance(expr, basestring) for expr in exprs): <TAB> <TAB> <TAB> exprs = map(ParserElement._literalStringClass, exprs) <TAB> <TAB> self.exprs = list(exprs) <TAB> else: <TAB> <TAB> try: <TAB> <TAB> <TAB> self.exprs = list(exprs) <TAB> <TAB> except TypeError: <TAB> <TAB> <TAB> self.exprs = [exprs] <TAB> self.callPreparse = False",true,"if all ( isinstance ( expr , basestring ) for expr in exprs ) :","if all ( isinstance ( expr , basestring ) for expr in exprs ) :",1.0,0.0
"def find(self, back=False): <TAB> flags = 0 <TAB><IF-STMT> <TAB> <TAB> flags = QTextDocument.FindBackward <TAB> if self.csBox.isChecked(): <TAB> <TAB> flags = flags | QTextDocument.FindCaseSensitively <TAB> text = self.searchEdit.text() <TAB> if not self.findMain(text, flags): <TAB> <TAB> if text in self.editBoxes[self.ind].toPlainText(): <TAB> <TAB> <TAB> cursor = self.editBoxes[self.ind].textCursor() <TAB> <TAB> <TAB> if back: <TAB> <TAB> <TAB> <TAB> cursor.movePosition(QTextCursor.End) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> cursor.movePosition(QTextCursor.Start) <TAB> <TAB> <TAB> self.editBoxes[self.ind].setTextCursor(cursor) <TAB> <TAB> <TAB> self.findMain(text, flags)",true,if back :,if back :,0.53,0.0
"def _load_storage(self): <TAB> self._storage = {} <TAB> for row in self(""SELECT object, resource, amount FROM storage""): <TAB> <TAB> ownerid = int(row[0]) <TAB> <TAB> if ownerid in self._storage: <TAB> <TAB> <TAB> self._storage[ownerid].append(row[1:]) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._storage[ownerid] = [row[1:]]",true,if ownerid in self . _storage :,if ownerid in self . _storage :,0.75,0.0
"def parse_chunked(self, unreader): <TAB> (size, rest) = self.parse_chunk_size(unreader) <TAB> while size > 0: <TAB> <TAB> while size > len(rest): <TAB> <TAB> <TAB> size -= len(rest) <TAB> <TAB> <TAB> yield rest <TAB> <TAB> <TAB> rest = unreader.read() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise NoMoreData() <TAB> <TAB> yield rest[:size] <TAB> <TAB> # Remove \r\n after chunk <TAB> <TAB> rest = rest[size:] <TAB> <TAB> while len(rest) < 2: <TAB> <TAB> <TAB> rest += unreader.read() <TAB> <TAB> if rest[:2] != b""\r\n"": <TAB> <TAB> <TAB> raise ChunkMissingTerminator(rest[:2]) <TAB> <TAB> (size, rest) = self.parse_chunk_size(unreader, data=rest[2:])",true,if not rest :,if not rest :,0.75,0.0
"def _augment_batch_(self, batch, random_state, parents, hooks): <TAB> for column in batch.columns: <TAB> <TAB> if column.name in [""keypoints"", ""bounding_boxes"", ""polygons"", ""line_strings""]: <TAB> <TAB> <TAB> for i, cbaoi in enumerate(column.value): <TAB> <TAB> <TAB> <TAB> column.value[i] = cbaoi.clip_out_of_image_() <TAB> return batch",true,"if column . name in [ ""keypoints"" , ""bounding_boxes"" , ""polygons"" , ""line_strings"" ] :","if column . name in [ ""keypoints"" , ""bounding_boxes"" , ""polygons"" , ""line_strings"" ] :",0.75,0.0
"def to_nim(self): <TAB> if self.is_pointer == 2: <TAB> <TAB> s = ""cstringArray"" if self.type == ""GLchar"" else ""ptr pointer"" <TAB> else: <TAB> <TAB> s = self.type <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> default = ""ptr "" + s <TAB> <TAB> <TAB> s = self.NIM_POINTER_MAP.get(s, default) <TAB> return s",false,if self . is_pointer == 1 :,if s in self . NIM_POINTER_MAP :,0.04,0.0
"def find(self, path): <TAB> if os.path.isfile(path) or os.path.islink(path): <TAB> <TAB> self.num_files = self.num_files + 1 <TAB> <TAB> if self.match_function(path): <TAB> <TAB> <TAB> self.files.append(path) <TAB> elif os.path.isdir(path): <TAB> <TAB> for content in os.listdir(path): <TAB> <TAB> <TAB> file = os.path.join(path, content) <TAB> <TAB> <TAB> if os.path.isfile(file) or os.path.islink(file): <TAB> <TAB> <TAB> <TAB> self.num_files = self.num_files + 1 <TAB> <TAB> <TAB> <TAB> if self.match_function(file): <TAB> <TAB> <TAB> <TAB> <TAB> self.files.append(file) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.find(file)",false,if os . path . isfile ( file ) or os . path . islink ( file ) :,if self . match_function ( file ) :,0.1,0.0
"def remove(self, event): <TAB> try: <TAB> <TAB> self._events_current_sweep.remove(event) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> assert event.in_sweep == True <TAB> <TAB> <TAB> assert event.other.in_sweep == True <TAB> <TAB> <TAB> event.in_sweep = False <TAB> <TAB> <TAB> event.other.in_sweep = False <TAB> <TAB> return True <TAB> except KeyError: <TAB> <TAB> if USE_DEBUG: <TAB> <TAB> <TAB> assert event.in_sweep == False <TAB> <TAB> <TAB> assert event.other.in_sweep == False <TAB> <TAB> return False",true,if USE_DEBUG :,if USE_DEBUG :,0.53,0.0
"def update_metadata(self): <TAB> for attrname in dir(self): <TAB> <TAB> if attrname.startswith(""__""): <TAB> <TAB> <TAB> continue <TAB> <TAB> attrvalue = getattr(self, attrname, None) <TAB> <TAB> if attrvalue == 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> if attrname == ""salt_version"": <TAB> <TAB> <TAB> attrname = ""version"" <TAB> <TAB> if hasattr(self.metadata, ""set_{0}"".format(attrname)): <TAB> <TAB> <TAB> getattr(self.metadata, ""set_{0}"".format(attrname))(attrvalue) <TAB> <TAB> elif hasattr(self.metadata, attrname): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> setattr(self.metadata, attrname, attrvalue) <TAB> <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> <TAB> pass",false,"if attrname == ""salt_version"" :","if attrname . startswith ( ""__"" ) :",0.05,0.0
"def _init_auxiliary_head(self, auxiliary_head): <TAB> """"""Initialize ``auxiliary_head``"""""" <TAB> if auxiliary_head is not None: <TAB> <TAB> if isinstance(auxiliary_head, list): <TAB> <TAB> <TAB> self.auxiliary_head = nn.ModuleList() <TAB> <TAB> <TAB> for head_cfg in auxiliary_head: <TAB> <TAB> <TAB> <TAB> self.auxiliary_head.append(builder.build_head(head_cfg)) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.auxiliary_head = builder.build_head(auxiliary_head)",true,"if isinstance ( auxiliary_head , list ) :","if isinstance ( auxiliary_head , list ) :",0.75,0.0
"def _str_param_list(self, name): <TAB> out = [] <TAB> if self[name]: <TAB> <TAB> out += self._str_header(name) <TAB> <TAB> for param in self[name]: <TAB> <TAB> <TAB> parts = [] <TAB> <TAB> <TAB> if param.name: <TAB> <TAB> <TAB> <TAB> parts.append(param.name) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> parts.append(param.type) <TAB> <TAB> <TAB> out += ["" : "".join(parts)] <TAB> <TAB> <TAB> if param.desc and """".join(param.desc).strip(): <TAB> <TAB> <TAB> <TAB> out += self._str_indent(param.desc) <TAB> <TAB> out += [""""] <TAB> return out",true,if param . type :,if param . type :,0.75,0.0
"def _set_handler( <TAB> self, name, handle=None, obj=None, constructor_args=(), constructor_kwds={} ): <TAB> if handle is None: <TAB> <TAB> handle = obj is not None <TAB> if handle: <TAB> <TAB> handler_class = self.handler_classes[name] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> newhandler = handler_class(obj) <TAB> <TAB> else: <TAB> <TAB> <TAB> newhandler = handler_class(*constructor_args, **constructor_kwds) <TAB> else: <TAB> <TAB> newhandler = None <TAB> self._replace_handler(name, newhandler)",false,if obj is not None :,if obj :,0.05,0.0
"def _extract_subtitles(src): <TAB> subtitles = {} <TAB> for caption in try_get(src, lambda x: x[""captions""], list) or []: <TAB> <TAB> subtitle_url = url_or_none(caption.get(""uri"")) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> lang = caption.get(""language"", ""deu"") <TAB> <TAB> <TAB> subtitles.setdefault(lang, []).append( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> ""url"": subtitle_url, <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> return subtitles",true,if subtitle_url :,if subtitle_url :,0.53,0.0
"def get_keys(struct, ignore_first_level=False): <TAB> res = [] <TAB> if isinstance(struct, dict): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> keys = [x.split(""("")[0] for x in struct.keys()] <TAB> <TAB> <TAB> res.extend(keys) <TAB> <TAB> for key in struct: <TAB> <TAB> <TAB> if key in IGNORED_KEYS: <TAB> <TAB> <TAB> <TAB> logging.debug(""Ignored: %s: %s"", key, struct[key]) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> res.extend(get_keys(struct[key], key in IGNORED_FIRST_LEVEL)) <TAB> elif isinstance(struct, list): <TAB> <TAB> for item in struct: <TAB> <TAB> <TAB> res.extend(get_keys(item)) <TAB> return res",false,if not ignore_first_level :,if ignore_first_level :,0.1,0.0
"def create_dir(path): <TAB> curr_path = None <TAB> for p in path: <TAB> <TAB> if curr_path is None: <TAB> <TAB> <TAB> curr_path = os.path.abspath(p) <TAB> <TAB> else: <TAB> <TAB> <TAB> curr_path = os.path.join(curr_path, p) <TAB> <TAB> if not os.path.exists(curr_path): <TAB> <TAB> <TAB> os.mkdir(curr_path)",true,if not os . path . exists ( curr_path ) :,if not os . path . exists ( curr_path ) :,0.75,0.0
"def dataToDumpFile(dumpFile, data): <TAB> try: <TAB> <TAB> dumpFile.write(data) <TAB> <TAB> dumpFile.flush() <TAB> except IOError as ex: <TAB> <TAB> if ""No space left"" in getUnicode(ex): <TAB> <TAB> <TAB> errMsg = ""no space left on output device"" <TAB> <TAB> <TAB> logger.error(errMsg) <TAB> <TAB> elif ""Permission denied"" in getUnicode(ex): <TAB> <TAB> <TAB> errMsg = ""permission denied when flushing dump data"" <TAB> <TAB> <TAB> logger.error(errMsg) <TAB> <TAB> else: <TAB> <TAB> <TAB> errMsg = ( <TAB> <TAB> <TAB> <TAB> ""error occurred when writing dump data to file ('%s')"" % getUnicode(ex) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> logger.error(errMsg)",true,"elif ""Permission denied"" in getUnicode ( ex ) :","elif ""Permission denied"" in getUnicode ( ex ) :",0.75,0.0
"def elements(self, top): <TAB> res = [] <TAB> # try: <TAB> # <TAB> string = ""== %s (%s)"" % (self.name,self.__class__) <TAB> # except AttributeError: <TAB> # <TAB> string = ""== (%s)"" % (self.__class__,) <TAB> # print(string) <TAB> for part in self.parts: <TAB> <TAB> if isinstance(part, Element): <TAB> <TAB> <TAB> res.append(name_or_ref(part, top)) <TAB> <TAB> else: <TAB> <TAB> <TAB> if isinstance(part, Extension): <TAB> <TAB> <TAB> <TAB> res.append(part.base) <TAB> <TAB> <TAB> res.extend(part.elements(top)) <TAB> return res",true,"if isinstance ( part , Element ) :","if isinstance ( part , Element ) :",0.75,0.0
"def _parse_param_value(name, datatype, default): <TAB> if datatype == ""bool"": <TAB> <TAB> if default.lower() == ""true"": <TAB> <TAB> <TAB> return True <TAB> <TAB> elif default.lower() == ""false"": <TAB> <TAB> <TAB> return False <TAB> <TAB> else: <TAB> <TAB> <TAB> _s = ""{}: Invalid default value '{}' for bool parameter {}"" <TAB> <TAB> <TAB> raise SyntaxError(_s.format(self.name, default, p)) <TAB> elif datatype == ""int"": <TAB> <TAB> if type(default) == int: <TAB> <TAB> <TAB> return default <TAB> <TAB> else: <TAB> <TAB> <TAB> return int(default, 0) <TAB> elif datatype == ""real"": <TAB> <TAB> if type(default) == float: <TAB> <TAB> <TAB> return default <TAB> <TAB> else: <TAB> <TAB> <TAB> return float(default) <TAB> else: <TAB> <TAB> return str(default)",true,"elif default . lower ( ) == ""false"" :","elif default . lower ( ) == ""false"" :",0.75,0.0
"def dvmethod(c, dx, doAST=False): <TAB> for m in c.get_methods(): <TAB> <TAB> mx = dx.get_method(m) <TAB> <TAB> ms = DvMethod(mx) <TAB> <TAB> ms.process(doAST=doAST) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> assert ms.get_ast() is not None <TAB> <TAB> <TAB> assert isinstance(ms.get_ast(), dict) <TAB> <TAB> <TAB> assert ""body"" in ms.get_ast() <TAB> <TAB> else: <TAB> <TAB> <TAB> assert ms.get_source() is not None",true,if doAST :,if doAST :,0.53,0.0
"def _repr_pretty_(self, p, cycle): <TAB> if cycle: <TAB> <TAB> return ""{{...}"" <TAB> with p.group(2, ""{"", ""}""): <TAB> <TAB> p.breakable("""") <TAB> <TAB> for idx, key in enumerate(self._items): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> p.text("","") <TAB> <TAB> <TAB> <TAB> p.breakable() <TAB> <TAB> <TAB> value = self._items[key] <TAB> <TAB> <TAB> p.pretty(key) <TAB> <TAB> <TAB> p.text("": "") <TAB> <TAB> <TAB> if isinstance(value, bytes): <TAB> <TAB> <TAB> <TAB> value = trimmed_repr(value) <TAB> <TAB> <TAB> p.pretty(value) <TAB> <TAB> p.breakable("""")",true,if idx :,if idx :,0.53,0.0
"def remove_rating(self, songs, librarian): <TAB> count = len(songs) <TAB> if count > 1 and config.getboolean(""browsers"", ""rating_confirm_multiple""): <TAB> <TAB> parent = qltk.get_menu_item_top_parent(self) <TAB> <TAB> dialog = ConfirmRateMultipleDialog(parent, _(""_Remove Rating""), count, None) <TAB> <TAB> if dialog.run() != Gtk.ResponseType.YES: <TAB> <TAB> <TAB> return <TAB> reset = [] <TAB> for song in songs: <TAB> <TAB> if ""~#rating"" in song: <TAB> <TAB> <TAB> del song[""~#rating""] <TAB> <TAB> <TAB> reset.append(song) <TAB> librarian.changed(reset)",true,if dialog . run ( ) != Gtk . ResponseType . YES :,if dialog . run ( ) != Gtk . ResponseType . YES :,0.75,0.0
"def get_or_create_place(self, place_name): <TAB> ""Return the requested place object tuple-packed with a new indicator."" <TAB> LOG.debug(""get_or_create_place: looking for: %s"", place_name) <TAB> for place_handle in self.db.iter_place_handles(): <TAB> <TAB> place = self.db.get_place_from_handle(place_handle) <TAB> <TAB> place_title = place_displayer.display(self.db, place) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return (0, place) <TAB> place = Place() <TAB> place.set_title(place_name) <TAB> place.name = PlaceName(value=place_name) <TAB> self.db.add_place(place, self.trans) <TAB> return (1, place)",true,if place_title == place_name :,if place_title == place_name :,0.75,0.0
"def _skip_trivial(constraint_data): <TAB> if skip_trivial_constraints: <TAB> <TAB> if isinstance(constraint_data, LinearCanonicalRepn): <TAB> <TAB> <TAB> if constraint_data.variables is None: <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> else: <TAB> <TAB> <TAB> if constraint_data.body.polynomial_degree() == 0: <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",true,"if isinstance ( constraint_data , LinearCanonicalRepn ) :","if isinstance ( constraint_data , LinearCanonicalRepn ) :",0.75,0.0
"def get_other(self, data, items): <TAB> is_tuple = False <TAB> if type(data) == tuple: <TAB> <TAB> data = list(data) <TAB> <TAB> is_tuple = True <TAB> if type(data) == list: <TAB> <TAB> m_items = items.copy() <TAB> <TAB> for idx, item in enumerate(items): <TAB> <TAB> <TAB> if item < 0: <TAB> <TAB> <TAB> <TAB> m_items[idx] = len(data) - abs(item) <TAB> <TAB> for i in sorted(set(m_items), reverse=True): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> del data[i] <TAB> <TAB> if is_tuple: <TAB> <TAB> <TAB> return tuple(data) <TAB> <TAB> else: <TAB> <TAB> <TAB> return data <TAB> else: <TAB> <TAB> return None",false,if i < len ( data ) and i > - 1 :,if i in data :,0.02,0.0
"def test_case_insensitivity(self): <TAB> with support.EnvironmentVarGuard() as env: <TAB> <TAB> env.set(""PYTHONCASEOK"", ""1"") <TAB> <TAB> if b""PYTHONCASEOK"" not in _bootstrap._os.environ: <TAB> <TAB> <TAB> self.skipTest(""os.environ changes not reflected in "" ""_os.environ"") <TAB> <TAB> loader = self.find_module() <TAB> <TAB> self.assertTrue(hasattr(loader, ""load_module""))",true,"if b""PYTHONCASEOK"" not in _bootstrap . _os . environ :","if b""PYTHONCASEOK"" not in _bootstrap . _os . environ :",0.75,0.0
def field_spec(self): <TAB><IF-STMT> <TAB> <TAB> self.lazy_init_lock_.acquire() <TAB> <TAB> try: <TAB> <TAB> <TAB> if self.field_spec_ is None: <TAB> <TAB> <TAB> <TAB> self.field_spec_ = FieldSpec() <TAB> <TAB> finally: <TAB> <TAB> <TAB> self.lazy_init_lock_.release() <TAB> return self.field_spec_,true,if self . field_spec_ is None :,if self . field_spec_ is None :,0.75,0.0
"def reduce(self, f, init): <TAB> for x in range(self._idx, rt.count(self._w_array)): <TAB> <TAB> if rt.reduced_QMARK_(init): <TAB> <TAB> <TAB> return rt.deref(init) <TAB> <TAB> init = f.invoke([init, rt.nth(self._w_array, rt.wrap(x))]) <TAB> return init",true,if rt . reduced_QMARK_ ( init ) :,if rt . reduced_QMARK_ ( init ) :,0.75,0.0
"def _find(event: E) -> None: <TAB> # We first check values after the selected value, then all values. <TAB> values = list(self.values) <TAB> for value in values[self._selected_index + 1 :] + values: <TAB> <TAB> text = fragment_list_to_text(to_formatted_text(value[1])).lower() <TAB> <TAB> if text.startswith(event.data.lower()): <TAB> <TAB> <TAB> self._selected_index = self.values.index(value) <TAB> <TAB> <TAB> return",true,if text . startswith ( event . data . lower ( ) ) :,if text . startswith ( event . data . lower ( ) ) :,0.75,0.0
"def check_permissions(): <TAB> if platform_os() != ""Windows"": <TAB> <TAB> if getuid() == 0: <TAB> <TAB> <TAB> print(localization.lang_check_permissions[""permissions_granted""]) <TAB> <TAB> else: <TAB> <TAB> <TAB> print(localization.lang_check_permissions[""permissions_denied""]) <TAB> <TAB> <TAB> exit() <TAB> else: <TAB> <TAB> print(localization.lang_check_permissions[""windows_warning""]) <TAB> <TAB> exit()",true,if getuid ( ) == 0 :,if getuid ( ) == 0 :,0.75,0.0
"def _ProcessName(self, name, dependencies): <TAB> """"""Retrieve a module name from a node name."""""" <TAB> module_name, dot, base_name = name.rpartition(""."") <TAB> if dot: <TAB> <TAB> if module_name: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> dependencies[module_name].add(base_name) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> dependencies[module_name] = {base_name} <TAB> <TAB> else: <TAB> <TAB> <TAB> # If we have a relative import that did not get qualified (usually due <TAB> <TAB> <TAB> # to an empty package_name), don't insert module_name='' into the <TAB> <TAB> <TAB> # dependencies; we get a better error message if we filter it out here <TAB> <TAB> <TAB> # and fail later on. <TAB> <TAB> <TAB> logging.warning(""Empty package name: %s"", name)",true,if module_name in dependencies :,if module_name in dependencies :,0.75,0.0
"def _load_db(self): <TAB> try: <TAB> <TAB> with open(self.db) as db: <TAB> <TAB> <TAB> content = db.read(8) <TAB> <TAB> <TAB> db.seek(0) <TAB> <TAB> <TAB> if content == (""Salted__""): <TAB> <TAB> <TAB> <TAB> data = StringIO() <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self.encryptor.decrypt(db, data) <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> raise EncryptionError( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""Encrpyted credential storage: {}"".format(self.db) <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return json.loads(data.getvalue()) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return json.load(db) <TAB> except: <TAB> <TAB> return {""creds"": []}",true,if self . encryptor :,if self . encryptor :,0.75,0.0
"def _parse(self, stream, context): <TAB> obj = [] <TAB> try: <TAB> <TAB> context_for_subcon = context <TAB> <TAB> if self.subcon.conflags & self.FLAG_COPY_CONTEXT: <TAB> <TAB> <TAB> context_for_subcon = context.__copy__() <TAB> <TAB> while True: <TAB> <TAB> <TAB> subobj = self.subcon._parse(stream, context_for_subcon) <TAB> <TAB> <TAB> if self.predicate(subobj, context): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> obj.append(subobj) <TAB> except ConstructError as ex: <TAB> <TAB> raise ArrayError(""missing terminator"", ex) <TAB> return obj",true,"if self . predicate ( subobj , context ) :","if self . predicate ( subobj , context ) :",0.75,0.0
"def is_active_for_user(self, user): <TAB> is_active = super(AbstractUserFlag, self).is_active_for_user(user) <TAB> if is_active: <TAB> <TAB> return is_active <TAB> user_ids = self._get_user_ids() <TAB> if hasattr(user, ""pk"") and user.pk in user_ids: <TAB> <TAB> return True <TAB> if hasattr(user, ""groups""): <TAB> <TAB> group_ids = self._get_group_ids() <TAB> <TAB> if group_ids: <TAB> <TAB> <TAB> user_groups = set(user.groups.all().values_list(""pk"", flat=True)) <TAB> <TAB> <TAB> if group_ids.intersection(user_groups): <TAB> <TAB> <TAB> <TAB> return True <TAB> return None",true,if group_ids . intersection ( user_groups ) :,if group_ids . intersection ( user_groups ) :,0.75,0.0
"def lookup_member(self, member_name): <TAB> document_choices = self.choices or [] <TAB> for document_choice in document_choices: <TAB> <TAB> doc_and_subclasses = [document_choice] + document_choice.__subclasses__() <TAB> <TAB> for doc_type in doc_and_subclasses: <TAB> <TAB> <TAB> field = doc_type._fields.get(member_name) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return field",true,if field :,if field :,0.53,0.0
"def apply(self, db, person): <TAB> families = person.get_parent_family_handle_list() <TAB> if families == []: <TAB> <TAB> return True <TAB> for family_handle in person.get_parent_family_handle_list(): <TAB> <TAB> family = db.get_family_from_handle(family_handle) <TAB> <TAB> if family: <TAB> <TAB> <TAB> father_handle = family.get_father_handle() <TAB> <TAB> <TAB> mother_handle = family.get_mother_handle() <TAB> <TAB> <TAB> if not father_handle: <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",true,if not mother_handle :,if not mother_handle :,0.75,0.0
"def init_weights(self): <TAB> for m in self.modules(): <TAB> <TAB> if isinstance(m, nn.Linear): <TAB> <TAB> <TAB> normal_init(m, std=0.01) <TAB> <TAB> if isinstance(m, nn.Conv3d): <TAB> <TAB> <TAB> xavier_init(m, distribution=""uniform"") <TAB> <TAB> if isinstance(m, nn.BatchNorm3d): <TAB> <TAB> <TAB> constant_init(m, 1)",true,"if isinstance ( m , nn . BatchNorm3d ) :","if isinstance ( m , nn . BatchNorm3d ) :",0.75,0.0
"def _update_learning_params(self): <TAB> model = self.model <TAB> hparams = self.hparams <TAB> fd = self.runner.feed_dict <TAB> step_num = self.step_num <TAB> if hparams.model_type == ""resnet_tf"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> lrn_rate = hparams.mom_lrn <TAB> <TAB> elif step_num < 30000: <TAB> <TAB> <TAB> lrn_rate = hparams.mom_lrn / 10 <TAB> <TAB> elif step_num < 35000: <TAB> <TAB> <TAB> lrn_rate = hparams.mom_lrn / 100 <TAB> <TAB> else: <TAB> <TAB> <TAB> lrn_rate = hparams.mom_lrn / 1000 <TAB> <TAB> fd[model.lrn_rate] = lrn_rate",false,if step_num < hparams . lrn_step :,if step_num < 20000 :,0.09,0.0
"def token_producer(source): <TAB> token = source.read_uint8() <TAB> while token is not None: <TAB> <TAB> if is_push_data_token(token): <TAB> <TAB> <TAB> yield DataToken(read_data(token, source)) <TAB> <TAB> elif is_small_integer(token): <TAB> <TAB> <TAB> yield SmallIntegerToken(read_small_integer(token)) <TAB> <TAB> else: <TAB> <TAB> <TAB> yield Token(token) <TAB> <TAB> token = source.read_uint8()",true,elif is_small_integer ( token ) :,elif is_small_integer ( token ) :,0.75,0.0
"def user_info(oicsrv, userdb, sub, client_id="""", user_info_claims=None): <TAB> identity = userdb[sub] <TAB> if user_info_claims: <TAB> <TAB> result = {} <TAB> <TAB> for key, restr in user_info_claims[""claims""].items(): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> result[key] = identity[key] <TAB> <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> <TAB> if restr == {""essential"": True}: <TAB> <TAB> <TAB> <TAB> <TAB> raise Exception(""Missing property '%s'"" % key) <TAB> else: <TAB> <TAB> result = identity <TAB> return OpenIDSchema(**result)",true,"if restr == { ""essential"" : True } :","if restr == { ""essential"" : True } :",0.75,0.0
"def _helpSlot(self, *args): <TAB> help_text = ""Filters are applied to packets in both direction.\n\n"" <TAB> filter_nb = 0 <TAB> for filter in self._filters: <TAB> <TAB> help_text += ""{}: {}"".format(filter[""name""], filter[""description""]) <TAB> <TAB> filter_nb += 1 <TAB> <TAB> if len(self._filters) != filter_nb: <TAB> <TAB> <TAB> help_text += ""\n\n"" <TAB> QtWidgets.QMessageBox.information(self, ""Help for filters"", help_text)",true,if len ( self . _filters ) != filter_nb :,if len ( self . _filters ) != filter_nb :,0.75,0.0
"def find_user_theme(self, name: str) -> Theme: <TAB> """"""Find a theme named as *name* from latex_theme_path."""""" <TAB> for theme_path in self.theme_paths: <TAB> <TAB> config_path = path.join(theme_path, name, ""theme.conf"") <TAB> <TAB> if path.isfile(config_path): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> return UserTheme(name, config_path) <TAB> <TAB> <TAB> except ThemeError as exc: <TAB> <TAB> <TAB> <TAB> logger.warning(exc) <TAB> return None",true,if path . isfile ( config_path ) :,if path . isfile ( config_path ) :,0.75,0.0
"def decompress(self, value): <TAB> if value: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if value.country_code and value.national_number: <TAB> <TAB> <TAB> <TAB> return [ <TAB> <TAB> <TAB> <TAB> <TAB> ""+%d"" % value.country_code, <TAB> <TAB> <TAB> <TAB> <TAB> national_significant_number(value), <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> else: <TAB> <TAB> <TAB> return value.split(""."") <TAB> return [None, """"]",false,if type ( value ) == PhoneNumber :,"if ""."" in value :",0.02,0.0
"def update_prevdoc_status(self, flag): <TAB> for quotation in list(set([d.prevdoc_docname for d in self.get(""items"")])): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> doc = frappe.get_doc(""Quotation"", quotation) <TAB> <TAB> <TAB> if doc.docstatus == 2: <TAB> <TAB> <TAB> <TAB> frappe.throw(_(""Quotation {0} is cancelled"").format(quotation)) <TAB> <TAB> <TAB> doc.set_status(update=True) <TAB> <TAB> <TAB> doc.update_opportunity()",false,if quotation :,if flag :,0.32,0.0
"def map(item): <TAB> if item.deleted: <TAB> <TAB> return <TAB> exploration = exp_fetchers.get_exploration_from_model(item) <TAB> for state_name, state in exploration.states.items(): <TAB> <TAB> hints_length = len(state.interaction.hints) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> exp_and_state_key = ""%s %s"" % (item.id, state_name.encode(""utf-8"")) <TAB> <TAB> <TAB> yield (python_utils.UNICODE(hints_length), exp_and_state_key)",true,if hints_length > 0 :,if hints_length > 0 :,0.75,0.0
"def _selected_machines(self, virtual_machines): <TAB> selected_machines = [] <TAB> for machine in virtual_machines: <TAB> <TAB> if self._args.host and self._args.host == machine.name: <TAB> <TAB> <TAB> selected_machines.append(machine) <TAB> <TAB> if self.tags and self._tags_match(machine.tags, self.tags): <TAB> <TAB> <TAB> selected_machines.append(machine) <TAB> <TAB> if self.locations and machine.location in self.locations: <TAB> <TAB> <TAB> selected_machines.append(machine) <TAB> return selected_machines",true,"if self . tags and self . _tags_match ( machine . tags , self . tags ) :","if self . tags and self . _tags_match ( machine . tags , self . tags ) :",1.0,0.0
"def _ripple_trim_compositors_move(self, delta): <TAB> comp_ids = self.multi_data.moved_compositors_destroy_ids <TAB> tracks_compositors = _get_tracks_compositors_list() <TAB> track_moved = self.multi_data.track_affected <TAB> for i in range(1, len(current_sequence().tracks) - 1): <TAB> <TAB> if not track_moved[i - 1]: <TAB> <TAB> <TAB> continue <TAB> <TAB> track_comps = tracks_compositors[i - 1] <TAB> <TAB> for comp in track_comps: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> comp.move(delta)",false,if comp . destroy_id in comp_ids :,if comp . id in comp_ids :,0.39,0.0
"def stream_docker_log(log_stream): <TAB> async for line in log_stream: <TAB> <TAB> if ""stream"" in line and line[""stream""].strip(): <TAB> <TAB> <TAB> logger.debug(line[""stream""].strip()) <TAB> <TAB> elif ""status"" in line: <TAB> <TAB> <TAB> logger.debug(line[""status""].strip()) <TAB> <TAB> elif ""error"" in line: <TAB> <TAB> <TAB> logger.error(line[""error""].strip()) <TAB> <TAB> <TAB> raise DockerBuildError",false,"elif ""status"" in line :","elif ""error"" in line :",0.39,0.0
"def create_keyfile(self, keyfile, size=64, force=False): <TAB> if force or not os.path.exists(keyfile): <TAB> <TAB> keypath = os.path.dirname(keyfile) <TAB> <TAB> if not os.path.exists(keypath): <TAB> <TAB> <TAB> os.makedirs(keypath) <TAB> <TAB> subprocess.run( <TAB> <TAB> <TAB> [""dd"", ""if=/dev/random"", f""of={keyfile}"", f""bs={size}"", ""count=1""], <TAB> <TAB> <TAB> check=True, <TAB> <TAB> <TAB> stdout=subprocess.DEVNULL, <TAB> <TAB> <TAB> stderr=subprocess.DEVNULL, <TAB> <TAB> )",false,if not os . path . exists ( keypath ) :,if not os . path . exists ( keyfile ) :,0.62,0.0
"def calc(self, arg): <TAB> op = arg[""op""] <TAB> if op == ""C"": <TAB> <TAB> self.clear() <TAB> <TAB> return str(self.current) <TAB> num = decimal.Decimal(arg[""num""]) <TAB> if self.op: <TAB> <TAB> if self.op == ""+"": <TAB> <TAB> <TAB> self.current += num <TAB> <TAB> elif self.op == ""-"": <TAB> <TAB> <TAB> self.current -= num <TAB> <TAB> elif self.op == ""*"": <TAB> <TAB> <TAB> self.current *= num <TAB> <TAB> elif self.op == ""/"": <TAB> <TAB> <TAB> self.current /= num <TAB> <TAB> self.op = op <TAB> else: <TAB> <TAB> self.op = op <TAB> <TAB> self.current = num <TAB> res = str(self.current) <TAB> if op == ""="": <TAB> <TAB> self.clear() <TAB> return res",false,"elif self . op == ""*"" :","elif self . op == ""/"" :",0.82,0.0
"def chop(expr, delta=10.0 ** (-10.0)): <TAB> if isinstance(expr, Real): <TAB> <TAB> if -delta < expr.get_float_value() < delta: <TAB> <TAB> <TAB> return Integer(0) <TAB> elif isinstance(expr, Complex) and expr.is_inexact(): <TAB> <TAB> real, imag = expr.real, expr.imag <TAB> <TAB> if -delta < real.get_float_value() < delta: <TAB> <TAB> <TAB> real = Integer(0) <TAB> <TAB> if -delta < imag.get_float_value() < delta: <TAB> <TAB> <TAB> imag = Integer(0) <TAB> <TAB> return Complex(real, imag) <TAB> elif isinstance(expr, Expression): <TAB> <TAB> return Expression(chop(expr.head), *[chop(leaf) for leaf in expr.leaves]) <TAB> return expr",false,if - delta < real . get_float_value ( ) < delta :,if - delta < expr . get_float_value ( ) < delta :,0.87,0.0
"def get_file_sources(): <TAB> global _file_sources <TAB> if _file_sources is None: <TAB> <TAB> from galaxy.files import ConfiguredFileSources <TAB> <TAB> file_sources = None <TAB> <TAB> if os.path.exists(""file_sources.json""): <TAB> <TAB> <TAB> file_sources_as_dict = None <TAB> <TAB> <TAB> with open(""file_sources.json"", ""r"") as f: <TAB> <TAB> <TAB> <TAB> file_sources_as_dict = json.load(f) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> file_sources = ConfiguredFileSources.from_dict(file_sources_as_dict) <TAB> <TAB> if file_sources is None: <TAB> <TAB> <TAB> ConfiguredFileSources.from_dict([]) <TAB> <TAB> _file_sources = file_sources <TAB> return _file_sources",true,if file_sources_as_dict is not None :,if file_sources_as_dict is not None :,0.75,0.0
"def _get_sort_map(tags): <TAB> """"""See TAG_TO_SORT"""""" <TAB> tts = {} <TAB> for name, tag in tags.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if tag.user: <TAB> <TAB> <TAB> <TAB> tts[name] = ""%ssort"" % name <TAB> <TAB> <TAB> if tag.internal: <TAB> <TAB> <TAB> <TAB> tts[""~%s"" % name] = ""~%ssort"" % name <TAB> return tts",false,if tag . has_sort :,if tag . sort :,0.39,0.0
"def __init__(self, **kwargs): <TAB> if self.name is None: <TAB> <TAB> raise RuntimeError(""RenderPrimitive cannot be used directly"") <TAB> self.option_values = {} <TAB> for key, val in kwargs.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""primitive `{0}' has no option `{1}'"".format(self.name, key) <TAB> <TAB> <TAB> ) <TAB> <TAB> self.option_values[key] = val <TAB> # set up defaults <TAB> for name, (description, default) in self.options.items(): <TAB> <TAB> if not name in self.option_values: <TAB> <TAB> <TAB> self.option_values[name] = default",false,if not key in self . options :,if key not in self . options :,0.54,0.0
"def modify_bottle_params(self, output_stride=None): <TAB> if output_stride is not None and output_stride % 2 != 0: <TAB> <TAB> raise Exception(""output stride must to be even number"") <TAB> if output_stride is None: <TAB> <TAB> return <TAB> else: <TAB> <TAB> stride = 2 <TAB> <TAB> for i, _cfg in enumerate(self.cfg): <TAB> <TAB> <TAB> stride = stride * _cfg[-1] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> s = 1 <TAB> <TAB> <TAB> <TAB> self.cfg[i][-1] = s",true,if stride > output_stride :,if stride > output_stride :,0.75,0.0
"def do_query(data, q): <TAB> ret = [] <TAB> if not q: <TAB> <TAB> return ret <TAB> qkey = q[0] <TAB> for key, value in iterate(data): <TAB> <TAB> if len(q) == 1: <TAB> <TAB> <TAB> if key == qkey: <TAB> <TAB> <TAB> <TAB> ret.append(value) <TAB> <TAB> <TAB> elif is_iterable(value): <TAB> <TAB> <TAB> <TAB> ret.extend(do_query(value, q)) <TAB> <TAB> else: <TAB> <TAB> <TAB> if not is_iterable(value): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if key == qkey: <TAB> <TAB> <TAB> <TAB> ret.extend(do_query(value, q[1:])) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> ret.extend(do_query(value, q)) <TAB> return ret",true,elif is_iterable ( value ) :,elif is_iterable ( value ) :,0.75,0.0
"def make_shares(self, plaintext): <TAB> share_arrays = [] <TAB> for i, p in enumerate(plaintext): <TAB> <TAB> share_array = self.make_byte_shares(p) <TAB> <TAB> for sa in share_array: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> share_arrays.append(array.array(""H"")) <TAB> <TAB> <TAB> current_share_array = sa <TAB> <TAB> <TAB> current_share_array.append(sa) <TAB> return share_arrays",true,if i == 0 :,if i == 0 :,0.75,0.0
"def populate(self, item): <TAB> # log.message('populate: %s', item) <TAB> path = self.getItemPath(item) <TAB> # log.message('populate: path=%s', path) <TAB> value = self.getValue(path) <TAB> for name in sorted(value.__dict__.keys()): <TAB> <TAB> if name[:2] == ""__"" and name[-2:] == ""__"": <TAB> <TAB> <TAB> continue <TAB> <TAB> child = getattr(value, name, None) <TAB> <TAB> if hasattr(child, ""__dict__""): <TAB> <TAB> <TAB> item.addChild(name, True) <TAB> <TAB> else: <TAB> <TAB> <TAB> item.addChild(name, False)",false,"if name [ : 2 ] == ""__"" and name [ - 2 : ] == ""__"" :","if hasattr ( child , ""__dict__"" ) :",0.01,0.0
"def __repr__(self): <TAB> try: <TAB> <TAB> if self._semlock._is_mine(): <TAB> <TAB> <TAB> name = current_process().name <TAB> <TAB> <TAB> if threading.current_thread().name != ""MainThread"": <TAB> <TAB> <TAB> <TAB> name += ""|"" + threading.current_thread().name <TAB> <TAB> elif self._semlock._get_value() == 1: <TAB> <TAB> <TAB> name = ""None"" <TAB> <TAB> elif self._semlock._count() > 0: <TAB> <TAB> <TAB> name = ""SomeOtherThread"" <TAB> <TAB> else: <TAB> <TAB> <TAB> name = ""SomeOtherProcess"" <TAB> except Exception: <TAB> <TAB> name = ""unknown"" <TAB> return ""<Lock(owner=%s)>"" % name",false,"if threading . current_thread ( ) . name != ""MainThread"" :",if self . _semlock . _is_mine ( ) :,0.07,0.0
"def buffer(self, lines, scroll_end=True, scroll_if_editing=False): <TAB> ""Add data to be displayed in the buffer."" <TAB> self.values.extend(lines) <TAB> if scroll_end: <TAB> <TAB> if not self.editing: <TAB> <TAB> <TAB> self.start_display_at = len(self.values) - len(self._my_widgets) <TAB> <TAB> elif scroll_if_editing: <TAB> <TAB> <TAB> self.start_display_at = len(self.values) - len(self._my_widgets)",false,if not self . editing :,elif scroll_if_editing :,0.02,0.0
"def warehouses(self) -> tuple: <TAB> from ..repositories import WarehouseBaseRepo <TAB> repos = dict() <TAB> for dep in chain(self.dependencies, [self]): <TAB> <TAB> if dep.repo is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> if not isinstance(dep.repo, WarehouseBaseRepo): <TAB> <TAB> <TAB> continue <TAB> <TAB> for repo in dep.repo.repos: <TAB> <TAB> <TAB> if repo.from_config: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> repos[repo.name] = repo <TAB> return tuple(repos.values())",true,"if not isinstance ( dep . repo , WarehouseBaseRepo ) :","if not isinstance ( dep . repo , WarehouseBaseRepo ) :",0.75,0.0
"def _apply_flag_attrs(src_flag, dest_flag): <TAB> # Use a baseline flag def to get default values for empty data. <TAB> baseline_flag = FlagDef("""", {}, None) <TAB> for name in dir(src_flag): <TAB> <TAB> if name[:1] == ""_"": <TAB> <TAB> <TAB> continue <TAB> <TAB> dest_val = getattr(dest_flag, name, None) <TAB> <TAB> baseline_val = getattr(baseline_flag, name, None) <TAB> <TAB> if dest_val == baseline_val: <TAB> <TAB> <TAB> setattr(dest_flag, name, getattr(src_flag, name))",true,"if name [ : 1 ] == ""_"" :","if name [ : 1 ] == ""_"" :",0.75,0.0
"def out(parent, attr, indent=0): <TAB> val = getattr(parent, attr) <TAB> prefix = ""%s%s:"" % ("" "" * indent, attr.replace(""_"", ""-"")) <TAB> if val is None: <TAB> <TAB> cli.out(prefix) <TAB> else: <TAB> <TAB> if attr == ""choices"": <TAB> <TAB> <TAB> val = [flag_util.encode_flag_val(c.value) for c in val] <TAB> <TAB> cli.out(""%s %s"" % (prefix, flag_util.encode_flag_val(val)))",true,"if attr == ""choices"" :","if attr == ""choices"" :",0.75,0.0
"def add_cand_to_check(cands): <TAB> for cand in cands: <TAB> <TAB> x = cand.creator <TAB> <TAB> if x is None: <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # `len(fan_out)` is in order to avoid comparing `x` <TAB> <TAB> <TAB> heapq.heappush(cand_funcs, (-x.rank, len(fan_out), x)) <TAB> <TAB> fan_out[x] += 1",false,if x not in fan_out :,if x . rank != 0 :,0.05,0.0
"def task_tree_lines(task=None): <TAB> if task is None: <TAB> <TAB> task = current_root_task() <TAB> rendered_children = [] <TAB> nurseries = list(task.child_nurseries) <TAB> while nurseries: <TAB> <TAB> nursery = nurseries.pop() <TAB> <TAB> nursery_children = _rendered_nursery_children(nursery) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> nested = _render_subtree(""(nested nursery)"", rendered_children) <TAB> <TAB> <TAB> nursery_children.append(nested) <TAB> <TAB> rendered_children = nursery_children <TAB> return _render_subtree(task.name, rendered_children)",false,if rendered_children :,if nursery_children :,0.32,0.0
"def lock_workspace(build_dir): <TAB> _BUILDING_LOCK_FILE = "".blade.building.lock"" <TAB> lock_file_fd, ret_code = lock_file(os.path.join(build_dir, _BUILDING_LOCK_FILE)) <TAB> if lock_file_fd == -1: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> console.fatal(""There is already an active building in current workspace."") <TAB> <TAB> else: <TAB> <TAB> <TAB> console.fatal(""Lock exception, please try it later."") <TAB> return lock_file_fd",false,if ret_code == errno . EAGAIN :,if ret_code == 0 :,0.09,0.0
"def test_list(self): <TAB> self._create_locations() <TAB> response = self.client.get(self.geojson_boxedlocation_list_url) <TAB> self.assertEqual(response.status_code, 200) <TAB> self.assertEqual(len(response.data[""features""]), 2) <TAB> for feature in response.data[""features""]: <TAB> <TAB> self.assertIn(""bbox"", feature) <TAB> <TAB> fid = feature[""id""] <TAB> <TAB> if fid == 1: <TAB> <TAB> <TAB> self.assertEqual(feature[""bbox""], self.bl1.bbox_geometry.extent) <TAB> <TAB> elif fid == 2: <TAB> <TAB> <TAB> self.assertEqual(feature[""bbox""], self.bl2.bbox_geometry.extent) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.fail(""Unexpected id: {0}"".format(fid)) <TAB> BoxedLocation.objects.all().delete()",true,elif fid == 2 :,elif fid == 2 :,1.0,0.0
"def result(): <TAB> # ""global"" does not work here... <TAB> R, V = rays, virtual_rays <TAB> if V is not None: <TAB> <TAB> if normalize: <TAB> <TAB> <TAB> V = normalize_rays(V, lattice) <TAB> <TAB> if check: <TAB> <TAB> <TAB> R = PointCollection(V, lattice) <TAB> <TAB> <TAB> V = PointCollection(V, lattice) <TAB> <TAB> <TAB> d = lattice.dimension() <TAB> <TAB> <TAB> if len(V) != d - R.dim() or (R + V).dim() != d: <TAB> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> <TAB> ""virtual rays must be linearly "" <TAB> <TAB> <TAB> <TAB> <TAB> ""independent and with other rays span the ambient space."" <TAB> <TAB> <TAB> <TAB> ) <TAB> return RationalPolyhedralFan(cones, R, lattice, is_complete, V)",true,if len ( V ) != d - R . dim ( ) or ( R + V ) . dim ( ) != d :,if len ( V ) != d - R . dim ( ) or ( R + V ) . dim ( ) != d :,1.0,0.0
"def search_host(self, search_string): <TAB> results = [] <TAB> for host_entry in self.config_data: <TAB> <TAB> if host_entry.get(""type"") != ""entry"": <TAB> <TAB> <TAB> continue <TAB> <TAB> if host_entry.get(""host"") == ""*"": <TAB> <TAB> <TAB> continue <TAB> <TAB> searchable_information = host_entry.get(""host"") <TAB> <TAB> for key, value in six.iteritems(host_entry.get(""options"")): <TAB> <TAB> <TAB> if isinstance(value, list): <TAB> <TAB> <TAB> <TAB> value = "" "".join(value) <TAB> <TAB> <TAB> if isinstance(value, int): <TAB> <TAB> <TAB> <TAB> value = str(value) <TAB> <TAB> <TAB> searchable_information += "" "" + value <TAB> <TAB> if search_string in searchable_information: <TAB> <TAB> <TAB> results.append(host_entry) <TAB> return results",true,"if isinstance ( value , list ) :","if isinstance ( value , list ) :",0.75,0.0
"def test_async_iterator(app): <TAB> async with new_stream(app) as stream: <TAB> <TAB> for i in range(100): <TAB> <TAB> <TAB> await stream.channel.deliver(message(key=i, value=i)) <TAB> <TAB> received = 0 <TAB> <TAB> async for value in stream: <TAB> <TAB> <TAB> assert value == received <TAB> <TAB> <TAB> received += 1 <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> assert await channel_empty(stream.channel)",true,if received >= 100 :,if received >= 100 :,0.75,0.0
"def has_google_credentials(): <TAB> global _HAS_GOOGLE_CREDENTIALS <TAB> if _HAS_GOOGLE_CREDENTIALS is None: <TAB> <TAB> provider = Provider(""google"") <TAB> <TAB> if provider.get_access_key() is None or provider.get_secret_key() is None: <TAB> <TAB> <TAB> _HAS_GOOGLE_CREDENTIALS = False <TAB> <TAB> else: <TAB> <TAB> <TAB> _HAS_GOOGLE_CREDENTIALS = True <TAB> return _HAS_GOOGLE_CREDENTIALS",true,if provider . get_access_key ( ) is None or provider . get_secret_key ( ) is None :,if provider . get_access_key ( ) is None or provider . get_secret_key ( ) is None :,1.0,0.0
"def __cmp__(self, other): <TAB> if isinstance(other, date) or isinstance(other, datetime): <TAB> <TAB> a = self._d.getTime() <TAB> <TAB> b = other._d.getTime() <TAB> <TAB> if a < b: <TAB> <TAB> <TAB> return -1 <TAB> <TAB> elif a == b: <TAB> <TAB> <TAB> return 0 <TAB> else: <TAB> <TAB> raise TypeError(""expected date or datetime object"") <TAB> return 1",true,elif a == b :,elif a == b :,1.0,0.0
"def validate_weight(self, weight): <TAB> try: <TAB> <TAB> add_acl_to_obj(self.context[""user_acl""], self.category) <TAB> except AttributeError: <TAB> <TAB> return weight  # don't validate weight further if category failed <TAB> if weight > self.category.acl.get(""can_pin_threads"", 0): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> _( <TAB> <TAB> <TAB> <TAB> <TAB> ""You don't have permission to pin threads globally "" <TAB> <TAB> <TAB> <TAB> <TAB> ""in this category."" <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> _(""You don't have permission to pin threads in this category."") <TAB> <TAB> <TAB> ) <TAB> return weight",false,if weight == 2 :,if weight == 0 :,0.39,0.0
"def effective(line): <TAB> for b in line: <TAB> <TAB> if not b.cond: <TAB> <TAB> <TAB> return <TAB> <TAB> else: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> val = 5 <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> if b.ignore: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> b.ignore -= 1 <TAB> <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return (b, True) <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> return (b, False) <TAB> return",false,if val :,if val > 0 :,0.1,0.0
"def wheelEvent(self, event): <TAB> """"""Handle a wheel event."""""" <TAB> if QtCore.Qt.ControlModifier & event.modifiers(): <TAB> <TAB> d = {""c"": self.leo_c} <TAB> <TAB> if isQt5: <TAB> <TAB> <TAB> point = event.angleDelta() <TAB> <TAB> <TAB> delta = point.y() or point.x() <TAB> <TAB> else: <TAB> <TAB> <TAB> delta = event.delta() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> zoom_out(d) <TAB> <TAB> else: <TAB> <TAB> <TAB> zoom_in(d) <TAB> <TAB> event.accept() <TAB> <TAB> return <TAB> QtWidgets.QTextBrowser.wheelEvent(self, event)",true,if delta < 0 :,if delta < 0 :,0.75,0.0
"def test_evname_in_mp_events_testcases(): <TAB> ok = True <TAB> for evname in ins.mp_events: <TAB> <TAB> if evname == ""version"": <TAB> <TAB> <TAB> continue <TAB> <TAB> for i, args in enumerate(ins.mp_events[evname][""test_cases""]): <TAB> <TAB> <TAB> if evname != args[0]: <TAB> <TAB> <TAB> <TAB> msg = ""Error, for evname %s the testase #%d does not match evname"" <TAB> <TAB> <TAB> <TAB> print(msg % (evname, i)) <TAB> <TAB> <TAB> <TAB> ok = False <TAB> if ok: <TAB> <TAB> print(""test_evname_in_mp_events_testcases: passed"")",false,if evname != args [ 0 ] :,"if evname == ""version"" :",0.04,0.0
"def check_database(): <TAB> if len(EmailAddress.objects.all()) > 0: <TAB> <TAB> print( <TAB> <TAB> <TAB> ""Are you sure you want to wipe the existing development database and reseed it? (Y/N)"" <TAB> <TAB> ) <TAB> <TAB> if raw_input().lower() == ""y"": <TAB> <TAB> <TAB> destroy_database() <TAB> <TAB> else: <TAB> <TAB> <TAB> return False <TAB> else: <TAB> <TAB> return True",true,"if raw_input ( ) . lower ( ) == ""y"" :","if raw_input ( ) . lower ( ) == ""y"" :",0.75,0.0
"def _get_requested_databases(self): <TAB> """"""Returns a list of databases requested, not including ignored dbs"""""" <TAB> requested_databases = [] <TAB> if (self._requested_namespaces is not None) and (self._requested_namespaces != []): <TAB> <TAB> for requested_namespace in self._requested_namespaces: <TAB> <TAB> <TAB> if requested_namespace[0] is ""*"": <TAB> <TAB> <TAB> <TAB> return [] <TAB> <TAB> <TAB> elif requested_namespace[0] not in IGNORE_DBS: <TAB> <TAB> <TAB> <TAB> requested_databases.append(requested_namespace[0]) <TAB> return requested_databases",true,elif requested_namespace [ 0 ] not in IGNORE_DBS :,elif requested_namespace [ 0 ] not in IGNORE_DBS :,0.75,0.0
"def decorated(self, *args, **kwargs): <TAB> start_time = time.perf_counter() <TAB> stderr = """" <TAB> saved_exception = None <TAB> try: <TAB> <TAB> yield from fn(self, *args, **kwargs) <TAB> except GitSavvyError as e: <TAB> <TAB> stderr = e.stderr <TAB> <TAB> saved_exception = e <TAB> finally: <TAB> <TAB> end_time = time.perf_counter() <TAB> <TAB> util.debug.log_git(args, None, ""<SNIP>"", stderr, end_time - start_time) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise saved_exception from None",true,if saved_exception :,if saved_exception :,0.53,0.0
"def is_suppressed_warning( <TAB> type: str, subtype: str, suppress_warnings: List[str] ) -> bool: <TAB> """"""Check the warning is suppressed or not."""""" <TAB> if type is None: <TAB> <TAB> return False <TAB> for warning_type in suppress_warnings: <TAB> <TAB> if ""."" in warning_type: <TAB> <TAB> <TAB> target, subtarget = warning_type.split(""."", 1) <TAB> <TAB> else: <TAB> <TAB> <TAB> target, subtarget = warning_type, None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> subtype is None <TAB> <TAB> <TAB> <TAB> or subtarget is None <TAB> <TAB> <TAB> <TAB> or subtarget == subtype <TAB> <TAB> <TAB> <TAB> or subtarget == ""*"" <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",false,if target == type :,if target is None and subtarget is None :,0.05,0.0
"def talk(self, words): <TAB> if self.writeSentence(words) == 0: <TAB> <TAB> return <TAB> r = [] <TAB> while 1: <TAB> <TAB> i = self.readSentence() <TAB> <TAB> if len(i) == 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> reply = i[0] <TAB> <TAB> attrs = {} <TAB> <TAB> for w in i[1:]: <TAB> <TAB> <TAB> j = w.find(""="", 1) <TAB> <TAB> <TAB> if j == -1: <TAB> <TAB> <TAB> <TAB> attrs[w] = """" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> attrs[w[:j]] = w[j + 1 :] <TAB> <TAB> r.append((reply, attrs)) <TAB> <TAB> if reply == ""!done"": <TAB> <TAB> <TAB> return r",true,"if reply == ""!done"" :","if reply == ""!done"" :",0.75,0.0
"def encrypt(self, plaintext): <TAB> encrypted = [] <TAB> for p in _string_to_bytes(plaintext): <TAB> <TAB> if len(self._remaining_block) == 0: <TAB> <TAB> <TAB> self._remaining_block = self._aes.encrypt(self._last_precipherblock) <TAB> <TAB> <TAB> self._last_precipherblock = [] <TAB> <TAB> precipherbyte = self._remaining_block.pop(0) <TAB> <TAB> self._last_precipherblock.append(precipherbyte) <TAB> <TAB> cipherbyte = p ^ precipherbyte <TAB> <TAB> encrypted.append(cipherbyte) <TAB> return _bytes_to_string(encrypted)",true,if len ( self . _remaining_block ) == 0 :,if len ( self . _remaining_block ) == 0 :,0.75,0.0
"def find_symbol(self, r, globally=False): <TAB> query = self.view.substr(self.view.word(r)) <TAB> fname = self.view.file_name().replace(""\\"", ""/"") <TAB> locations = self.view.window().lookup_symbol_in_index(query) <TAB> if not locations: <TAB> <TAB> return <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> location = [hit[2] for hit in locations if fname.endswith(hit[1])][0] <TAB> <TAB> <TAB> return location[0] - 1, location[1] - 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> # TODO: There might be many symbols with the same name. <TAB> <TAB> <TAB> return locations[0] <TAB> except IndexError: <TAB> <TAB> return",false,if not globally :,if globally :,0.1,0.0
"def __getslice__(self, i, j): <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # handle the case where the right bound is unspecified <TAB> <TAB> <TAB> j = len(self) <TAB> <TAB> if i < 0 or j < 0: <TAB> <TAB> <TAB> raise dns.exception.FormError <TAB> <TAB> # If it's not an empty slice, access left and right bounds <TAB> <TAB> # to make sure they're valid <TAB> <TAB> if i != j: <TAB> <TAB> <TAB> super(WireData, self).__getitem__(i) <TAB> <TAB> <TAB> super(WireData, self).__getitem__(j - 1) <TAB> <TAB> return WireData(super(WireData, self).__getslice__(i, j)) <TAB> except IndexError: <TAB> <TAB> raise dns.exception.FormError",false,if j == sys . maxint :,if i == j :,0.03,0.0
"def main(): <TAB> r = redis.StrictRedis() <TAB> curr_memory = prev_memory = r.info()[""used_memory""] <TAB> while True: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print( <TAB> <TAB> <TAB> <TAB> ""Delta Memory : %d, Total Memory : %d"" <TAB> <TAB> <TAB> <TAB> % ((curr_memory - prev_memory), curr_memory) <TAB> <TAB> <TAB> ) <TAB> <TAB> time.sleep(1) <TAB> <TAB> prev_memory = curr_memory <TAB> <TAB> curr_memory = r.info()[""used_memory""]",false,if prev_memory != curr_memory :,if curr_memory - prev_memory > curr_memory :,0.14,0.0
"def _visit(self, func): <TAB> fname = func[0] <TAB> if fname in self._flags: <TAB> <TAB> if self._flags[fname] == 1: <TAB> <TAB> <TAB> logger.critical(""Fatal error! network ins not Dag."") <TAB> <TAB> <TAB> import sys <TAB> <TAB> <TAB> sys.exit(-1) <TAB> <TAB> else: <TAB> <TAB> <TAB> return <TAB> else: <TAB> <TAB> if fname not in self._flags: <TAB> <TAB> <TAB> self._flags[fname] = 1 <TAB> <TAB> for output in func[3]: <TAB> <TAB> <TAB> for f in self._orig: <TAB> <TAB> <TAB> <TAB> for input in f[2]: <TAB> <TAB> <TAB> <TAB> <TAB> if output == input: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self._visit(f) <TAB> self._flags[fname] = 2 <TAB> self._sorted.insert(0, func)",true,if fname not in self . _flags :,if fname not in self . _flags :,0.75,0.0
"def urls(self, version=None): <TAB> """"""Returns all URLS that are mapped to this interface"""""" <TAB> urls = [] <TAB> for _base_url, routes in self.api.http.routes.items(): <TAB> <TAB> for url, methods in routes.items(): <TAB> <TAB> <TAB> for _method, versions in methods.items(): <TAB> <TAB> <TAB> <TAB> for interface_version, interface in versions.items(): <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if not url in urls: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> urls.append( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> (""/v{0}"".format(version) if version else """") + url <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> return urls",false,if interface_version == version and interface == self :,if interface_version == _base_url :,0.06,0.0
"def _handle_data(self, text): <TAB> if self._translate: <TAB> <TAB> if not text.startswith(""gtk-""): <TAB> <TAB> <TAB> self._data.append(text) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._translate = False <TAB> <TAB> <TAB> self._data = [] <TAB> <TAB> <TAB> self._comments = []",true,"if not text . startswith ( ""gtk-"" ) :","if not text . startswith ( ""gtk-"" ) :",0.75,0.0
"def set_dir_modes(self, dirname, mode): <TAB> if not self.is_chmod_supported(): <TAB> <TAB> return <TAB> for dirpath, dirnames, fnames in os.walk(dirname): <TAB> <TAB> if os.path.islink(dirpath): <TAB> <TAB> <TAB> continue <TAB> <TAB> log.info(""changing mode of %s to %o"", dirpath, mode) <TAB> <TAB> if not self.dry_run: <TAB> <TAB> <TAB> os.chmod(dirpath, mode)",true,if os . path . islink ( dirpath ) :,if os . path . islink ( dirpath ) :,0.75,0.0
"def language(self): <TAB> if self.lang_data: <TAB> <TAB> lang_data = [s if s != ""None"" else None for s in self.lang_data] <TAB> <TAB> if lang_data[0]: <TAB> <TAB> <TAB> return Language(lang_data[0], country=lang_data[1], script=lang_data[2])",true,if lang_data [ 0 ] :,if lang_data [ 0 ] :,0.75,0.0
"def _addItemToLayout(self, sample, label): <TAB> col = self.layout.columnCount() <TAB> row = self.layout.rowCount() <TAB> if row: <TAB> <TAB> row -= 1 <TAB> nCol = self.columnCount * 2 <TAB> # FIRST ROW FULL <TAB> if col == nCol: <TAB> <TAB> for col in range(0, nCol, 2): <TAB> <TAB> <TAB> # FIND RIGHT COLUMN <TAB> <TAB> <TAB> if not self.layout.itemAt(row, col): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if col + 2 == nCol: <TAB> <TAB> <TAB> # MAKE NEW ROW <TAB> <TAB> <TAB> col = 0 <TAB> <TAB> <TAB> row += 1 <TAB> self.layout.addItem(sample, row, col) <TAB> self.layout.addItem(label, row, col + 1)",true,"if not self . layout . itemAt ( row , col ) :","if not self . layout . itemAt ( row , col ) :",0.75,0.0
"def align_comments(tlist): <TAB> tidx, token = tlist.token_next_by(i=sql.Comment) <TAB> while token: <TAB> <TAB> pidx, prev_ = tlist.token_prev(tidx) <TAB> <TAB> if isinstance(prev_, sql.TokenList): <TAB> <TAB> <TAB> tlist.group_tokens(sql.TokenList, pidx, tidx, extend=True) <TAB> <TAB> <TAB> tidx = pidx <TAB> <TAB> tidx, token = tlist.token_next_by(i=sql.Comment, idx=tidx)",true,"if isinstance ( prev_ , sql . TokenList ) :","if isinstance ( prev_ , sql . TokenList ) :",0.75,0.0
"def hook_GetVariable(ql, address, params): <TAB> if params[""VariableName""] in ql.env: <TAB> <TAB> var = ql.env[params[""VariableName""]] <TAB> <TAB> read_len = read_int64(ql, params[""DataSize""]) <TAB> <TAB> if params[""Attributes""] != 0: <TAB> <TAB> <TAB> write_int64(ql, params[""Attributes""], 0) <TAB> <TAB> write_int64(ql, params[""DataSize""], len(var)) <TAB> <TAB> if read_len < len(var): <TAB> <TAB> <TAB> return EFI_BUFFER_TOO_SMALL <TAB> <TAB> if params[""Data""] != 0: <TAB> <TAB> <TAB> ql.mem.write(params[""Data""], var) <TAB> <TAB> return EFI_SUCCESS <TAB> return EFI_NOT_FOUND",true,if read_len < len ( var ) :,if read_len < len ( var ) :,0.75,0.0
"def _PromptMySQL(self, config): <TAB> """"""Prompts the MySQL configuration, retrying if the configuration is invalid."""""" <TAB> while True: <TAB> <TAB> self._PromptMySQLOnce(config) <TAB> <TAB> if self._CheckMySQLConnection(): <TAB> <TAB> <TAB> print(""Successfully connected to MySQL with the given configuration."") <TAB> <TAB> <TAB> return <TAB> <TAB> else: <TAB> <TAB> <TAB> print(""Error: Could not connect to MySQL with the given configuration."") <TAB> <TAB> <TAB> retry = RetryBoolQuestion(""Do you want to retry MySQL configuration?"", True) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise ConfigInitError()",true,if not retry :,if not retry :,0.75,0.0
"def split_long_line_with_indent(line, max_per_line, indent): <TAB> """"""Split the `line` so that it doesn't go over `max_per_line` and adds `indent` to new lines."""""" <TAB> words = line.split("" "") <TAB> lines = [] <TAB> current_line = words[0] <TAB> for word in words[1:]: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> lines.append(current_line) <TAB> <TAB> <TAB> current_line = "" "" * indent + word <TAB> <TAB> else: <TAB> <TAB> <TAB> current_line = f""{current_line} {word}"" <TAB> lines.append(current_line) <TAB> return ""\n"".join(lines)",false,"if len ( f""{current_line} {word}"" ) > max_per_line :",if max_per_line and word not in lines :,0.02,0.0
"def gen_cli(docs_dir): <TAB> with open(os.path.join(docs_dir, ""CLI_template.md""), ""r"") as cli_temp_file: <TAB> <TAB> temp_lines = cli_temp_file.readlines() <TAB> lines = [] <TAB> for line in temp_lines: <TAB> <TAB> matched = re.match(r""{onnx-tf.*}"", line) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> command = matched.string.strip()[1:-1] <TAB> <TAB> <TAB> output = subprocess.check_output(command.split("" "")).decode(""UTF-8"") <TAB> <TAB> <TAB> lines.append(output) <TAB> <TAB> else: <TAB> <TAB> <TAB> lines.append(line) <TAB> with open(os.path.join(docs_dir, ""CLI.md""), ""w"") as cli_file: <TAB> <TAB> cli_file.writelines(lines)",true,if matched :,if matched :,0.53,0.0
"def read(self, size=None): <TAB> if size == 0: <TAB> <TAB> return """" <TAB> data = list() <TAB> while size is None or size > 0: <TAB> <TAB> line = self.readline(size or -1) <TAB> <TAB> if not line: <TAB> <TAB> <TAB> break <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> size -= len(line) <TAB> <TAB> data.append(line) <TAB> return """".join(data)",false,if size is not None :,if len ( line ) > size :,0.02,0.0
"def _get_format_and_pattern(file_path): <TAB> file_path = Path(file_path) <TAB> with file_path.open() as f: <TAB> <TAB> first_line = f.readline().strip() <TAB> <TAB> match = re.match(r""format *: *(.+)"", first_line) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ""gztar"", first_line, 1 <TAB> <TAB> return match.group(1), f.readline().strip(), 2",true,if match is None :,if match is None :,0.75,0.0
"def remove_old_snapshot(install_dir): <TAB> logging.info(""Removing any old files in {}"".format(install_dir)) <TAB> for file in glob.glob(""{}/*"".format(install_dir)): <TAB> <TAB> try: <TAB> <TAB> <TAB> if os.path.isfile(file): <TAB> <TAB> <TAB> <TAB> os.unlink(file) <TAB> <TAB> <TAB> elif os.path.isdir(file): <TAB> <TAB> <TAB> <TAB> shutil.rmtree(file) <TAB> <TAB> except Exception as error: <TAB> <TAB> <TAB> logging.error(""Error: {}"".format(error)) <TAB> <TAB> <TAB> sys.exit(1)",true,elif os . path . isdir ( file ) :,elif os . path . isdir ( file ) :,0.75,0.0
"def _test_forever(self, tests): <TAB> while True: <TAB> <TAB> for test_name in tests: <TAB> <TAB> <TAB> yield test_name <TAB> <TAB> <TAB> if self.bad: <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return",false,if self . ns . fail_env_changed and self . environment_changed :,if self . fail :,0.14,0.0
"def _swig_extract_dependency_files(self, src): <TAB> dep = [] <TAB> for line in open(src): <TAB> <TAB> if line.startswith(""#include"") or line.startswith(""%include""): <TAB> <TAB> <TAB> line = line.split("" "")[1].strip(""""""'""\r\n"""""") <TAB> <TAB> <TAB> if not (""<"" in line or line in dep): <TAB> <TAB> <TAB> <TAB> dep.append(line) <TAB> return [i for i in dep if os.path.exists(i)]",false,"if not ( ""<"" in line or line in dep ) :","if line . startswith ( ""#include"" ) or line . startswith ( ""%include"" ) :",0.28,0.0
"def update_service_key(kid, name=None, metadata=None): <TAB> try: <TAB> <TAB> with db_transaction(): <TAB> <TAB> <TAB> key = db_for_update(ServiceKey.select().where(ServiceKey.kid == kid)).get() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> key.name = name <TAB> <TAB> <TAB> if metadata is not None: <TAB> <TAB> <TAB> <TAB> key.metadata.update(metadata) <TAB> <TAB> <TAB> key.save() <TAB> except ServiceKey.DoesNotExist: <TAB> <TAB> raise ServiceKeyDoesNotExist",true,if name is not None :,if name is not None :,0.75,0.0
"def range(self, dimension, data_range=True, dimension_range=True): <TAB> if self.nodes and dimension in self.nodes.dimensions(): <TAB> <TAB> node_range = self.nodes.range(dimension, data_range, dimension_range) <TAB> <TAB> if self._edgepaths: <TAB> <TAB> <TAB> path_range = self._edgepaths.range(dimension, data_range, dimension_range) <TAB> <TAB> <TAB> return max_range([node_range, path_range]) <TAB> <TAB> return node_range <TAB> return super(Graph, self).range(dimension, data_range, dimension_range)",true,if self . _edgepaths :,if self . _edgepaths :,0.75,0.0
"def handler(chan, host, port): <TAB> sock = socket() <TAB> try: <TAB> <TAB> sock.connect((host, port)) <TAB> except Exception as e: <TAB> <TAB> if verbose == True: <TAB> <TAB> <TAB> print(e) <TAB> <TAB> return <TAB> while True: <TAB> <TAB> r, w, x = select.select([sock, chan], [], []) <TAB> <TAB> if sock in r: <TAB> <TAB> <TAB> data = sock.recv(1024) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> chan.send(data) <TAB> <TAB> if chan in r: <TAB> <TAB> <TAB> data = chan.recv(1024) <TAB> <TAB> <TAB> if len(data) == 0: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> sock.send(data) <TAB> chan.close() <TAB> sock.close()",true,if len ( data ) == 0 :,if len ( data ) == 0 :,0.75,0.0
"def output_layer(self, features, **kwargs): <TAB> """"""Project features to the vocabulary size."""""" <TAB> if self.adaptive_softmax is None: <TAB> <TAB> # project back to size of vocabulary <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return F.linear(features, self.embed_tokens.weight) <TAB> <TAB> else: <TAB> <TAB> <TAB> return F.linear(features, self.embed_out) <TAB> else: <TAB> <TAB> return features",false,if self . share_input_output_embed :,if self . embed_tokens . weight is not None :,0.18,0.0
"def generate(self, dest, vars): <TAB> util.ensure_dir(dest) <TAB> for relpath, src, template in self._file_templates: <TAB> <TAB> file_dest = os.path.join(dest, relpath) <TAB> <TAB> util.ensure_dir(os.path.dirname(file_dest)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> shutil.copyfile(src, file_dest) <TAB> <TAB> else: <TAB> <TAB> <TAB> _render_template(template, vars, file_dest)",false,if template is None :,if src :,0.04,0.0
"def _py_matching_callback(self, context, result, sender, device): <TAB> d = HIDDevice.get_device(c_void_p(device)) <TAB> if d not in self.devices: <TAB> <TAB> self.devices.add(d) <TAB> <TAB> for x in self.matching_observers: <TAB> <TAB> <TAB> if hasattr(x, ""device_discovered""): <TAB> <TAB> <TAB> <TAB> x.device_discovered(d)",true,"if hasattr ( x , ""device_discovered"" ) :","if hasattr ( x , ""device_discovered"" ) :",0.75,0.0
"def urlquote(*args, **kwargs): <TAB> new_kwargs = dict(kwargs) <TAB> if not PY3: <TAB> <TAB> new_kwargs = dict(kwargs) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> del new_kwargs[""encoding""] <TAB> <TAB> if ""errors"" in kwargs: <TAB> <TAB> <TAB> del new_kwargs[""errors""] <TAB> return quote(*args, **new_kwargs)",false,"if ""encoding"" in new_kwargs :","if ""encoding"" in kwargs :",0.39,0.0
"def Set(self, attr, value): <TAB> hook = getattr(self, ""_set_%s"" % attr, None) <TAB> if hook: <TAB> <TAB> # If there is a set hook we must use the context manager. <TAB> <TAB> if self._lock > 0: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""Can only update attribute %s using the context manager."" % attr <TAB> <TAB> <TAB> ) <TAB> <TAB> if attr not in self._pending_hooks: <TAB> <TAB> <TAB> self._pending_hooks.append(attr) <TAB> <TAB> self._pending_parameters[attr] = value <TAB> else: <TAB> <TAB> super(Configuration, self).Set(attr, value)",true,if self . _lock > 0 :,if self . _lock > 0 :,0.75,0.0
"def on_profiles_loaded(self, profiles): <TAB> cb = self.builder.get_object(""cbProfile"") <TAB> model = cb.get_model() <TAB> model.clear() <TAB> for f in profiles: <TAB> <TAB> name = f.get_basename() <TAB> <TAB> if name.endswith("".mod""): <TAB> <TAB> <TAB> continue <TAB> <TAB> if name.endswith("".sccprofile""): <TAB> <TAB> <TAB> name = name[0:-11] <TAB> <TAB> model.append((name, f, None)) <TAB> cb.set_active(0)",true,"if name . endswith ( "".sccprofile"" ) :","if name . endswith ( "".sccprofile"" ) :",0.75,0.0
"def get_eval_task(self, worker_id): <TAB> """"""Return next evaluation (task_id, Task) tuple"""""" <TAB> with self._lock: <TAB> <TAB> if not self._eval_todo: <TAB> <TAB> <TAB> return -1, None <TAB> <TAB> self._task_id += 1 <TAB> <TAB> task = self._eval_todo.pop() <TAB> <TAB> self._doing[self._task_id] = (worker_id, task, time.time()) <TAB> <TAB> return self._task_id, task",true,if not self . _eval_todo :,if not self . _eval_todo :,0.75,0.0
"def queries(self): <TAB> if DEV: <TAB> <TAB> cmd = ShellCommand(""docker"", ""ps"", ""-qf"", ""name=%s"" % self.path.k8s) <TAB> <TAB> if not cmd.check(f""docker check for {self.path.k8s}""): <TAB> <TAB> <TAB> if not cmd.stdout.strip(): <TAB> <TAB> <TAB> <TAB> log_cmd = ShellCommand( <TAB> <TAB> <TAB> <TAB> <TAB> ""docker"", ""logs"", self.path.k8s, stderr=subprocess.STDOUT <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> if log_cmd.check(f""docker logs for {self.path.k8s}""): <TAB> <TAB> <TAB> <TAB> <TAB> print(cmd.stdout) <TAB> <TAB> <TAB> <TAB> pytest.exit(f""container failed to start for {self.path.k8s}"") <TAB> return ()",false,"if not cmd . check ( f""docker check for {self.path.k8s}"" ) :","if log_cmd . check ( f""docker logs for {self.path.k8s}"" ) :",0.32,0.0
"def disjoined(data): <TAB> # create marginalized distributions and multiple them together <TAB> data_disjoined = None <TAB> dim = len(data.shape) <TAB> for d in range(dim): <TAB> <TAB> axes = list(range(dim)) <TAB> <TAB> axes.remove(d) <TAB> <TAB> data1d = multisum(data, axes) <TAB> <TAB> shape = [1 for k in range(dim)] <TAB> <TAB> shape[d] = len(data1d) <TAB> <TAB> data1d = data1d.reshape(tuple(shape)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> data_disjoined = data1d <TAB> <TAB> else: <TAB> <TAB> <TAB> data_disjoined = data_disjoined * data1d <TAB> return data_disjoined",false,if d == 0 :,if data_disjoined is None :,0.03,0.0
"def safe_repr(val): <TAB> try: <TAB> <TAB> if isinstance(val, dict): <TAB> <TAB> <TAB> # We special case dicts to have a sorted repr. This makes testing <TAB> <TAB> <TAB> # significantly easier <TAB> <TAB> <TAB> val = _obj_with_safe_repr(val) <TAB> <TAB> ret = repr(val) <TAB> <TAB> if six.PY2: <TAB> <TAB> <TAB> ret = ret.decode(""utf-8"") <TAB> except UnicodeEncodeError: <TAB> <TAB> ret = red(""a %r that cannot be represented"" % type(val)) <TAB> else: <TAB> <TAB> ret = green(ret) <TAB> return ret",true,"if isinstance ( val , dict ) :","if isinstance ( val , dict ) :",0.75,0.0
"def wrapper(*args, **kwargs): <TAB> resp = view_func(*args, **kwargs) <TAB> if isinstance(resp, dict): <TAB> <TAB> ctx_params = request.environ.get(""webrec.template_params"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> resp.update(ctx_params) <TAB> <TAB> template = self.jinja_env.jinja_env.get_or_select_template(template_name) <TAB> <TAB> return template.render(**resp) <TAB> else: <TAB> <TAB> return resp",true,if ctx_params :,if ctx_params :,0.53,0.0
"def post(self, request, *args, **kwargs): <TAB> contact_id = kwargs.get(""pk"") <TAB> self.object = get_object_or_404(Contact, id=contact_id) <TAB> if ( <TAB> <TAB> self.request.user.role != ""ADMIN"" <TAB> <TAB> and not self.request.user.is_superuser <TAB> <TAB> and self.request.user != self.object.created_by <TAB> ) or self.object.company != self.request.company: <TAB> <TAB> raise PermissionDenied <TAB> else: <TAB> <TAB> if self.object.address_id: <TAB> <TAB> <TAB> self.object.address.delete() <TAB> <TAB> self.object.delete() <TAB> <TAB> if self.request.is_ajax(): <TAB> <TAB> <TAB> return JsonResponse({""error"": False}) <TAB> <TAB> return redirect(""contacts:list"")",true,if self . request . is_ajax ( ) :,if self . request . is_ajax ( ) :,0.75,0.0
"def escape(text, newline=False): <TAB> """"""Escape special html characters."""""" <TAB> if isinstance(text, str): <TAB> <TAB> if ""&"" in text: <TAB> <TAB> <TAB> text = text.replace(""&"", ""&amp;"") <TAB> <TAB> if "">"" in text: <TAB> <TAB> <TAB> text = text.replace("">"", ""&gt;"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> text = text.replace(""<"", ""&lt;"") <TAB> <TAB> if '""' in text: <TAB> <TAB> <TAB> text = text.replace('""', ""&quot;"") <TAB> <TAB> if ""'"" in text: <TAB> <TAB> <TAB> text = text.replace(""'"", ""&quot;"") <TAB> <TAB> if newline: <TAB> <TAB> <TAB> if ""\n"" in text: <TAB> <TAB> <TAB> <TAB> text = text.replace(""\n"", ""<br>"") <TAB> return text",true,"if ""<"" in text :","if ""<"" in text :",0.75,0.0
"def everythingIsUnicode(d): <TAB> """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB> for k, v in d.iteritems(): <TAB> <TAB> if isinstance(v, dict) and k != ""headers"": <TAB> <TAB> <TAB> if not everythingIsUnicode(v): <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance(v, list): <TAB> <TAB> <TAB> for i in v: <TAB> <TAB> <TAB> <TAB> if isinstance(i, dict) and not everythingIsUnicode(i): <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <TAB> elif isinstance(i, _bytes): <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance(v, _bytes): <TAB> <TAB> <TAB> return False <TAB> return True",false,if not everythingIsUnicode ( v ) :,"if isinstance ( v , dict ) and k != ""headers"" :",0.03,0.0
"def fill(self): <TAB> try: <TAB> <TAB> while ( <TAB> <TAB> <TAB> not self.stopping.wait(self.sample_wait) <TAB> <TAB> <TAB> and len(self.queue) < self.queue.maxlen <TAB> <TAB> ): <TAB> <TAB> <TAB> self.queue.append(self.parent._read()) <TAB> <TAB> <TAB> if self.partial and isinstance(self.parent, EventsMixin): <TAB> <TAB> <TAB> <TAB> self.parent._fire_events() <TAB> <TAB> self.full.set() <TAB> <TAB> while not self.stopping.wait(self.sample_wait): <TAB> <TAB> <TAB> self.queue.append(self.parent._read()) <TAB> <TAB> <TAB> if isinstance(self.parent, EventsMixin): <TAB> <TAB> <TAB> <TAB> self.parent._fire_events() <TAB> except ReferenceError: <TAB> <TAB> # Parent is dead; time to die! <TAB> <TAB> pass",true,"if self . partial and isinstance ( self . parent , EventsMixin ) :","if self . partial and isinstance ( self . parent , EventsMixin ) :",0.75,0.0
"def _SetListviewTextItems(self, items): <TAB> self.listview.DeleteAllItems() <TAB> index = -1 <TAB> for item in items: <TAB> <TAB> index = self.listview.InsertItem(index + 1, item[0]) <TAB> <TAB> data = item[1] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> data = """" <TAB> <TAB> self.listview.SetItemText(index, 1, data)",false,if data is None :,"if data == """" :",0.06,0.0
"def process_request(self, request): <TAB> for old, new in self.names_name: <TAB> <TAB> request.uri = request.uri.replace(old, new) <TAB> <TAB> if is_text_payload(request) and request.body: <TAB> <TAB> <TAB> body = six.ensure_str(request.body) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> request.body = body.replace(old, new) <TAB> return request",false,if old in body :,if body :,0.07,0.0
"def serialize(cls, value, *args, **kwargs): <TAB> if value is None: <TAB> <TAB> return """" <TAB> value_as_string = six.text_type(value) <TAB> if SHOULD_NOT_USE_LOCALE: <TAB> <TAB> return value_as_string <TAB> else: <TAB> <TAB> grouping = kwargs.get(""grouping"", None) <TAB> <TAB> has_decimal_places = value_as_string.find(""."") != -1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> string_format = ""%d"" <TAB> <TAB> else: <TAB> <TAB> <TAB> decimal_places = len(value_as_string.split(""."")[1]) <TAB> <TAB> <TAB> string_format = ""%.{}f"".format(decimal_places) <TAB> <TAB> return locale.format(string_format, value, grouping=grouping)",false,if not has_decimal_places :,if has_decimal_places :,0.1,0.0
"def review_link(request, path_obj): <TAB> try: <TAB> <TAB> if path_obj.has_suggestions(): <TAB> <TAB> <TAB> if check_permission(""translate"", request): <TAB> <TAB> <TAB> <TAB> text = _(""Review Suggestions"") <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> text = _(""View Suggestions"") <TAB> <TAB> <TAB> return { <TAB> <TAB> <TAB> <TAB> ""href"": dispatch.translate( <TAB> <TAB> <TAB> <TAB> <TAB> request, path_obj.pootle_path, matchnames=[""hassuggestion""] <TAB> <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> <TAB> ""text"": text, <TAB> <TAB> <TAB> } <TAB> except IOError: <TAB> <TAB> pass",true,if path_obj . has_suggestions ( ) :,if path_obj . has_suggestions ( ) :,0.75,0.0
"def _migrate_key(self, key): <TAB> """"""migrate key from old .dat file"""""" <TAB> key_path = os.path.join(self.home_path, ""keys.dat"") <TAB> if os.path.exists(key_path): <TAB> <TAB> try: <TAB> <TAB> <TAB> key_data = json.loads(open(key_path, ""rb"").read()) <TAB> <TAB> <TAB> if key_data.get(key): <TAB> <TAB> <TAB> <TAB> self.add_key(key, key_data.get(key)) <TAB> <TAB> except: <TAB> <TAB> <TAB> self.error(f""Corrupt key file. Manual migration of '{key}' required."")",true,if key_data . get ( key ) :,if key_data . get ( key ) :,0.75,0.0
"def gather_callback_args(self, obj, callbacks): <TAB> session = sa.orm.object_session(obj) <TAB> for callback in callbacks: <TAB> <TAB> backref = callback.backref <TAB> <TAB> root_objs = getdotattr(obj, backref) if backref else obj <TAB> <TAB> if root_objs: <TAB> <TAB> <TAB> if not isinstance(root_objs, Iterable): <TAB> <TAB> <TAB> <TAB> root_objs = [root_objs] <TAB> <TAB> <TAB> with session.no_autoflush: <TAB> <TAB> <TAB> <TAB> for root_obj in root_objs: <TAB> <TAB> <TAB> <TAB> <TAB> if root_obj: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> args = self.get_callback_args(root_obj, callback) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if args: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield args",true,"if not isinstance ( root_objs , Iterable ) :","if not isinstance ( root_objs , Iterable ) :",0.75,0.0
"def GetDefFile(self, gyp_to_build_path): <TAB> """"""Returns the .def file from sources, if any.  Otherwise returns None."""""" <TAB> spec = self.spec <TAB> if spec[""type""] in (""shared_library"", ""loadable_module"", ""executable""): <TAB> <TAB> def_files = [s for s in spec.get(""sources"", []) if s.endswith("".def"")] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return gyp_to_build_path(def_files[0]) <TAB> <TAB> elif len(def_files) > 1: <TAB> <TAB> <TAB> raise Exception(""Multiple .def files"") <TAB> return None",true,if len ( def_files ) == 1 :,if len ( def_files ) == 1 :,0.75,0.0
"def _validate_gallery(images): <TAB> for image in images: <TAB> <TAB> image_path = image.get(""image_path"", """") <TAB> <TAB> if image_path: <TAB> <TAB> <TAB> if not isfile(image_path): <TAB> <TAB> <TAB> <TAB> raise TypeError(f""{image_path!r} is not a valid image path."") <TAB> <TAB> else: <TAB> <TAB> <TAB> raise TypeError(""'image_path' is required."") <TAB> <TAB> if not len(image.get(""caption"", """")) <= 180: <TAB> <TAB> <TAB> raise TypeError(""Caption must be 180 characters or less."")",true,"if not len ( image . get ( ""caption"" , """" ) ) <= 180 :","if not len ( image . get ( ""caption"" , """" ) ) <= 180 :",0.75,0.0
"def VType(self): <TAB> if ""DW_AT_type"" in self.attributes: <TAB> <TAB> target = self.types[self.type_id] <TAB> <TAB> target_type = target.VType() <TAB> <TAB> if not isinstance(target_type, list): <TAB> <TAB> <TAB> target_type = [target_type, None] <TAB> <TAB> return [""Pointer"", dict(target=target_type[0], target_args=target_type[1])] <TAB> return [""Pointer"", dict(target=""Void"")]",true,"if not isinstance ( target_type , list ) :","if not isinstance ( target_type , list ) :",0.75,0.0
"def addInPlace(self, value1, value2): <TAB> for group in value2: <TAB> <TAB> for key in value2[group]: <TAB> <TAB> <TAB> if key not in value1[group]: <TAB> <TAB> <TAB> <TAB> value1[group][key] = value2[group][key] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> value1[group][key] += value2[group][key] <TAB> return value1",true,if key not in value1 [ group ] :,if key not in value1 [ group ] :,0.75,0.0
"def _mongo_query_and(self, queries): <TAB> if len(queries) == 1: <TAB> <TAB> return queries[0] <TAB> query = {} <TAB> for q in queries: <TAB> <TAB> for k, v in q.items(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> query[k] = {} <TAB> <TAB> <TAB> if isinstance(v, list): <TAB> <TAB> <TAB> <TAB> # TODO check exists of k in query, may be it should be update <TAB> <TAB> <TAB> <TAB> query[k] = v <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> query[k].update(v) <TAB> return query",true,if k not in query :,if k not in query :,0.75,0.0
"def _handled_eventtype(self, eventtype, handler): <TAB> if eventtype not in known_events: <TAB> <TAB> log.error('The event ""%s"" is not known', eventtype) <TAB> <TAB> return False <TAB> if known_events[eventtype].__module__.startswith(""deluge.event""): <TAB> <TAB> if handler.__self__ is self: <TAB> <TAB> <TAB> return True <TAB> <TAB> log.error( <TAB> <TAB> <TAB> ""You cannot register custom notification providers "" <TAB> <TAB> <TAB> ""for built-in event types."" <TAB> <TAB> ) <TAB> <TAB> return False <TAB> return True",true,if handler . __self__ is self :,if handler . __self__ is self :,0.75,0.0
"def get_ax_arg(uri): <TAB> if not ax_ns: <TAB> <TAB> return u"""" <TAB> prefix = ""openid."" + ax_ns + "".type."" <TAB> ax_name = None <TAB> for name, values in self.request.arguments.iteritems(): <TAB> <TAB> if values[-1] == uri and name.startswith(prefix): <TAB> <TAB> <TAB> part = name[len(prefix) :] <TAB> <TAB> <TAB> ax_name = ""openid."" + ax_ns + "".value."" + part <TAB> <TAB> <TAB> break <TAB> if not ax_name: <TAB> <TAB> return u"""" <TAB> return self.get_argument(ax_name, u"""")",true,if values [ - 1 ] == uri and name . startswith ( prefix ) :,if values [ - 1 ] == uri and name . startswith ( prefix ) :,0.75,0.0
"def handle_starttag(self, tag, attrs): <TAB> if tag == ""base"": <TAB> <TAB> self.base_url = dict(attrs).get(""href"") <TAB> if self.scan_tag(tag): <TAB> <TAB> for attr, value in attrs: <TAB> <TAB> <TAB> if self.scan_attr(attr): <TAB> <TAB> <TAB> <TAB> if self.strip: <TAB> <TAB> <TAB> <TAB> <TAB> value = strip_html5_whitespace(value) <TAB> <TAB> <TAB> <TAB> url = self.process_attr(value) <TAB> <TAB> <TAB> <TAB> link = Link(url=url) <TAB> <TAB> <TAB> <TAB> self.links.append(link) <TAB> <TAB> <TAB> <TAB> self.current_link = link",true,if self . scan_attr ( attr ) :,if self . scan_attr ( attr ) :,0.75,0.0
"def test_long_steadystate_queue_popright(self): <TAB> for size in (0, 1, 2, 100, 1000): <TAB> <TAB> d = deque(reversed(range(size))) <TAB> <TAB> append, pop = d.appendleft, d.pop <TAB> <TAB> for i in range(size, BIG): <TAB> <TAB> <TAB> append(i) <TAB> <TAB> <TAB> x = pop() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.assertEqual(x, i - size) <TAB> <TAB> self.assertEqual(list(reversed(list(d))), list(range(BIG - size, BIG)))",false,if x != i - size :,if x is not None :,0.04,0.0
"def _update_read(self): <TAB> """"""Update state when there is read event"""""" <TAB> try: <TAB> <TAB> msg = bytes(self._sock.recv(4096)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.on_message(msg) <TAB> <TAB> <TAB> return True <TAB> <TAB> # normal close, remote is closed <TAB> <TAB> self.close() <TAB> except socket.error as err: <TAB> <TAB> if err.args[0] in (errno.EAGAIN, errno.EWOULDBLOCK): <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> self.on_error(err) <TAB> return False",true,if msg :,if msg :,0.53,0.0
"def prepend(self, value): <TAB> """"""prepend value to nodes"""""" <TAB> root, root_text = self._get_root(value) <TAB> for i, tag in enumerate(self): <TAB> <TAB> if not tag.text: <TAB> <TAB> <TAB> tag.text = """" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> root[-1].tail = tag.text <TAB> <TAB> <TAB> tag.text = root_text <TAB> <TAB> else: <TAB> <TAB> <TAB> tag.text = root_text + tag.text <TAB> <TAB> if i > 0: <TAB> <TAB> <TAB> root = deepcopy(list(root)) <TAB> <TAB> tag[:0] = root <TAB> <TAB> root = tag[: len(root)] <TAB> return self",false,if len ( root ) > 0 :,if i > 0 :,0.08,0.0
"def cmp(self, other): <TAB> v_is_ptr = not isinstance(self, CTypesGenericPrimitive) <TAB> w_is_ptr = isinstance(other, CTypesData) and not isinstance( <TAB> <TAB> other, CTypesGenericPrimitive <TAB> ) <TAB> if v_is_ptr and w_is_ptr: <TAB> <TAB> return cmpfunc(self._convert_to_address(None), other._convert_to_address(None)) <TAB> elif v_is_ptr or w_is_ptr: <TAB> <TAB> return NotImplemented <TAB> else: <TAB> <TAB> if isinstance(self, CTypesGenericPrimitive): <TAB> <TAB> <TAB> self = self._value <TAB> <TAB> if isinstance(other, CTypesGenericPrimitive): <TAB> <TAB> <TAB> other = other._value <TAB> <TAB> return cmpfunc(self, other)",false,"if isinstance ( other , CTypesGenericPrimitive ) :","if isinstance ( self , CTypesGenericPrimitive ) :",0.5,0.0
"def get_external_addresses(self, label=None) -> List[str]: <TAB> result = [] <TAB> for c in self._conf[""pools""].values(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if label == c[""label""]: <TAB> <TAB> <TAB> <TAB> result.append(c[""external_address""][0]) <TAB> <TAB> else: <TAB> <TAB> <TAB> result.append(c[""external_address""][0]) <TAB> return result",false,if label is not None :,"if ""external_address"" in c :",0.03,0.0
"def coerce_text(v): <TAB> if not isinstance(v, basestring_): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> attr = ""__unicode__"" <TAB> <TAB> else: <TAB> <TAB> <TAB> attr = ""__str__"" <TAB> <TAB> if hasattr(v, attr): <TAB> <TAB> <TAB> return unicode(v) <TAB> <TAB> else: <TAB> <TAB> <TAB> return bytes(v) <TAB> return v",false,if sys . version_info [ 0 ] < 3 :,if PY2 :,0.01,0.0
"def check_localhost(self): <TAB> """"""Warn if any socket_host is 'localhost'. See #711."""""" <TAB> for k, v in cherrypy.config.items(): <TAB> <TAB> if k == ""server.socket_host"" and v == ""localhost"": <TAB> <TAB> <TAB> warnings.warn( <TAB> <TAB> <TAB> <TAB> ""The use of 'localhost' as a socket host can "" <TAB> <TAB> <TAB> <TAB> ""cause problems on newer systems, since "" <TAB> <TAB> <TAB> <TAB> ""'localhost' can map to either an IPv4 or an "" <TAB> <TAB> <TAB> <TAB> ""IPv6 address. You should use '127.0.0.1' "" <TAB> <TAB> <TAB> <TAB> ""or '[::1]' instead."" <TAB> <TAB> <TAB> )",true,"if k == ""server.socket_host"" and v == ""localhost"" :","if k == ""server.socket_host"" and v == ""localhost"" :",1.0,0.0
"def add_songs(self, filenames, library): <TAB> changed = [] <TAB> for i in range(len(self)): <TAB> <TAB> if isinstance(self[i], str) and self._list[i] in filenames: <TAB> <TAB> <TAB> song = library[self._list[i]] <TAB> <TAB> <TAB> self._list[i] = song <TAB> <TAB> <TAB> changed.append(song) <TAB> if changed: <TAB> <TAB> self._emit_changed(changed, msg=""add"") <TAB> return bool(changed)",true,"if isinstance ( self [ i ] , str ) and self . _list [ i ] in filenames :","if isinstance ( self [ i ] , str ) and self . _list [ i ] in filenames :",1.0,0.0
"def _expand_deps_java_generation(self): <TAB> """"""Ensure that all multilingual dependencies such as proto_library generate java code."""""" <TAB> queue = collections.deque(self.deps) <TAB> keys = set() <TAB> while queue: <TAB> <TAB> k = queue.popleft() <TAB> <TAB> if k not in keys: <TAB> <TAB> <TAB> keys.add(k) <TAB> <TAB> <TAB> dep = self.target_database[k] <TAB> <TAB> <TAB><IF-STMT>  # Has this attribute <TAB> <TAB> <TAB> <TAB> dep.attr[""generate_java""] = True <TAB> <TAB> <TAB> <TAB> queue.extend(dep.deps)",false,"if ""generate_java"" in dep . attr :",if dep . attr :,0.23,0.0
"def get(self): <TAB> name = request.args.get(""filename"") <TAB> if name is not None: <TAB> <TAB> opts = dict() <TAB> <TAB> opts[""type""] = ""episode"" <TAB> <TAB> result = guessit(name, options=opts) <TAB> <TAB> res = dict() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> res[""episode""] = result[""episode""] <TAB> <TAB> else: <TAB> <TAB> <TAB> res[""episode""] = 0 <TAB> <TAB> if ""season"" in result: <TAB> <TAB> <TAB> res[""season""] = result[""season""] <TAB> <TAB> else: <TAB> <TAB> <TAB> res[""season""] = 0 <TAB> <TAB> if ""subtitle_language"" in result: <TAB> <TAB> <TAB> res[""subtitle_language""] = str(result[""subtitle_language""]) <TAB> <TAB> return jsonify(data=res) <TAB> else: <TAB> <TAB> return """", 400",true,"if ""episode"" in result :","if ""episode"" in result :",0.75,0.0
def _get_error_file(self) -> Optional[str]: <TAB> error_file = None <TAB> min_timestamp = sys.maxsize <TAB> for replicas in self.role_replicas.values(): <TAB> <TAB> for replica in replicas: <TAB> <TAB> <TAB> if not os.path.exists(replica.error_file): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> mtime = os.path.getmtime(replica.error_file) <TAB> <TAB> <TAB> if mtime < min_timestamp: <TAB> <TAB> <TAB> <TAB> min_timestamp = mtime <TAB> <TAB> <TAB> <TAB> error_file = replica.error_file <TAB> return error_file,true,if not os . path . exists ( replica . error_file ) :,if not os . path . exists ( replica . error_file ) :,0.75,0.0
"def findChapterNameForPosition(self, p): <TAB> """"""Return the name of a chapter containing p or None if p does not exist."""""" <TAB> cc, c = self, self.c <TAB> if not p or not c.positionExists(p): <TAB> <TAB> return None <TAB> for name in cc.chaptersDict: <TAB> <TAB> if name != ""main"": <TAB> <TAB> <TAB> theChapter = cc.chaptersDict.get(name) <TAB> <TAB> <TAB> if theChapter.positionIsInChapter(p): <TAB> <TAB> <TAB> <TAB> return name <TAB> return ""main""",false,"if name != ""main"" :",if theChapter . positionIsInChapter ( p ) :,0.03,0.0
"def remove_files(folder, file_extensions): <TAB> for f in os.listdir(folder): <TAB> <TAB> f_path = os.path.join(folder, f) <TAB> <TAB> if os.path.isfile(f_path): <TAB> <TAB> <TAB> extension = os.path.splitext(f_path)[1] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> os.remove(f_path)",true,if extension in file_extensions :,if extension in file_extensions :,0.75,0.0
"def execute_uncomment(self, event): <TAB> cursor = self._editor.GetCurrentPos() <TAB> line, pos = self._editor.GetCurLine() <TAB> spaces = "" "" * self._tab_size <TAB> comment = ""Comment"" + spaces <TAB> cpos = cursor - len(comment) <TAB> lenline = len(line) <TAB> if lenline > 0: <TAB> <TAB> idx = 0 <TAB> <TAB> while idx < lenline and line[idx] == "" "": <TAB> <TAB> <TAB> idx += 1 <TAB> <TAB> if (line[idx : len(comment) + idx]).lower() == comment.lower(): <TAB> <TAB> <TAB> self._editor.DeleteRange(cursor - pos + idx, len(comment)) <TAB> <TAB> <TAB> self._editor.SetCurrentPos(cpos) <TAB> <TAB> <TAB> self._editor.SetSelection(cpos, cpos) <TAB> <TAB> <TAB> self.store_position()",true,if ( line [ idx : len ( comment ) + idx ] ) . lower ( ) == comment . lower ( ) :,if ( line [ idx : len ( comment ) + idx ] ) . lower ( ) == comment . lower ( ) :,1.0,0.0
"def test_batch_kwarg_path_relative_dot_slash_is_modified_and_found_in_a_code_cell( <TAB> critical_suite_with_citations, empty_data_context ): <TAB> obs = SuiteEditNotebookRenderer.from_data_context(empty_data_context).render( <TAB> <TAB> critical_suite_with_citations, {""path"": ""./foo/data""} <TAB> ) <TAB> assert isinstance(obs, dict) <TAB> found_expected = False <TAB> for cell in obs[""cells""]: <TAB> <TAB> if cell[""cell_type""] == ""code"": <TAB> <TAB> <TAB> source_code = cell[""source""] <TAB> <TAB> <TAB> if 'batch_kwargs = {""path"": ""../.././foo/data""}' in source_code: <TAB> <TAB> <TAB> <TAB> found_expected = True <TAB> <TAB> <TAB> <TAB> break <TAB> assert found_expected",true,"if cell [ ""cell_type"" ] == ""code"" :","if cell [ ""cell_type"" ] == ""code"" :",0.75,0.0
"def _get_file(self): <TAB> if self._file is None: <TAB> <TAB> self._file = SpooledTemporaryFile( <TAB> <TAB> <TAB> max_size=self._storage.max_memory_size, <TAB> <TAB> <TAB> suffix="".S3Boto3StorageFile"", <TAB> <TAB> <TAB> dir=setting(""FILE_UPLOAD_TEMP_DIR""), <TAB> <TAB> ) <TAB> <TAB> if ""r"" in self._mode: <TAB> <TAB> <TAB> self._is_dirty = False <TAB> <TAB> <TAB> self.obj.download_fileobj(self._file) <TAB> <TAB> <TAB> self._file.seek(0) <TAB> <TAB> if self._storage.gzip and self.obj.content_encoding == ""gzip"": <TAB> <TAB> <TAB> self._file = GzipFile(mode=self._mode, fileobj=self._file, mtime=0.0) <TAB> return self._file",false,"if self . _storage . gzip and self . obj . content_encoding == ""gzip"" :","if ""r"" in self . _mode :",0.02,0.0
"def _parse_filters(f_strs): <TAB> filters = [] <TAB> if not f_strs: <TAB> <TAB> return filters <TAB> for f_str in f_strs: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> fname, fopts = f_str.split("":"", 1) <TAB> <TAB> <TAB> filters.append((fname, _parse_options([fopts]))) <TAB> <TAB> else: <TAB> <TAB> <TAB> filters.append((f_str, {})) <TAB> return filters",true,"if "":"" in f_str :","if "":"" in f_str :",0.75,0.0
"def update_completion(self): <TAB> """"""Update completion model with exist tags"""""" <TAB> orig_text = self.widget.text() <TAB> text = "", "".join(orig_text.replace("", "", "","").split("","")[:-1]) <TAB> tags = [] <TAB> for tag in self.tags_list: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if orig_text[-1] not in ("","", "" ""): <TAB> <TAB> <TAB> <TAB> tags.append(""%s,%s"" % (text, tag)) <TAB> <TAB> <TAB> tags.append(""%s, %s"" % (text, tag)) <TAB> <TAB> else: <TAB> <TAB> <TAB> tags.append(tag) <TAB> if tags != self.completer_model.stringList(): <TAB> <TAB> self.completer_model.setStringList(tags)",false,"if "","" in orig_text :",if tag in text :,0.04,0.0
"def _get_startup_packages(lib_path: Path, packages) -> Set[str]: <TAB> names = set() <TAB> for path in lib_path.iterdir(): <TAB> <TAB> name = path.name <TAB> <TAB> if name == ""__pycache__"": <TAB> <TAB> <TAB> continue <TAB> <TAB> if name.endswith("".py""): <TAB> <TAB> <TAB> names.add(name.split(""."")[0]) <TAB> <TAB> elif path.is_dir() and ""."" not in name: <TAB> <TAB> <TAB> names.add(name) <TAB> if packages: <TAB> <TAB> packages = {package.lower().replace(""-"", ""_"") for package in packages} <TAB> <TAB> if len(names & packages) == len(packages): <TAB> <TAB> <TAB> return packages <TAB> return names",false,"if name . endswith ( "".py"" ) :","if name == ""__pycache__"" :",0.04,0.0
"def get_cloud_credential(self): <TAB> """"""Return the credential which is directly tied to the inventory source type."""""" <TAB> credential = None <TAB> for cred in self.credentials.all(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if cred.kind == self.source.replace(""ec2"", ""aws""): <TAB> <TAB> <TAB> <TAB> credential = cred <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> # these need to be returned in the API credential field <TAB> <TAB> <TAB> if cred.credential_type.kind != ""vault"": <TAB> <TAB> <TAB> <TAB> credential = cred <TAB> <TAB> <TAB> <TAB> break <TAB> return credential",false,if self . source in CLOUD_PROVIDERS :,if cred . credential_type :,0.07,0.0
"def newickize(clade): <TAB> """"""Convert a node tree to a Newick tree string, recursively."""""" <TAB> label = clade.name or """" <TAB> if label: <TAB> <TAB> unquoted_label = re.match(token_dict[""unquoted node label""], label) <TAB> <TAB> if (not unquoted_label) or (unquoted_label.end() < len(label)): <TAB> <TAB> <TAB> label = ""'%s'"" % label.replace(""\\"", ""\\\\"").replace(""'"", ""\\'"") <TAB> if clade.is_terminal():  # terminal <TAB> <TAB> return label + make_info_string(clade, terminal=True) <TAB> else: <TAB> <TAB> subtrees = (newickize(sub) for sub in clade) <TAB> <TAB> return ""(%s)%s"" % ("","".join(subtrees), label + make_info_string(clade))",false,if ( not unquoted_label ) or ( unquoted_label . end ( ) < len ( label ) ) :,if clade . is_terminal ( ) :,0.06,0.0
"def __iter__(self): <TAB> for name, value in self._vars.store.data.items(): <TAB> <TAB> source = self._sources[name] <TAB> <TAB> prefix = self._get_prefix(value) <TAB> <TAB> name = u""{0}{{{1}}}"".format(prefix, name) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield ArgumentInfo(name, value) <TAB> <TAB> else: <TAB> <TAB> <TAB> yield VariableInfo(name, value, source)",false,if source == self . ARGUMENT_SOURCE :,if source is None :,0.04,0.0
"def filepath_enumerate(paths): <TAB> """"""Enumerate the file paths of all subfiles of the list of paths"""""" <TAB> out = [] <TAB> for path in paths: <TAB> <TAB> if os.path.isfile(path): <TAB> <TAB> <TAB> out.append(path) <TAB> <TAB> else: <TAB> <TAB> <TAB> for root, dirs, files in os.walk(path): <TAB> <TAB> <TAB> <TAB> for name in files: <TAB> <TAB> <TAB> <TAB> <TAB> out.append(os.path.normpath(os.path.join(root, name))) <TAB> return out",true,if os . path . isfile ( path ) :,if os . path . isfile ( path ) :,1.0,0.0
"def del_(self, key): <TAB> hash_ = self.hash(key) <TAB> node_ = self._table[hash_] <TAB> pre_node = None <TAB> while node_ is not None: <TAB> <TAB> if node_.key == key: <TAB> <TAB> <TAB> if pre_node is None: <TAB> <TAB> <TAB> <TAB> self._table[hash_] = node_.next <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> pre_node.next = node_.next <TAB> <TAB> <TAB> self._len -= 1 <TAB> <TAB> pre_node = node_ <TAB> <TAB> node_ = node_.next",true,if node_ . key == key :,if node_ . key == key :,1.0,0.0
"def _recurse(self, base_path, rel_source, rel_zip): <TAB> submodules_path = Path(base_path) / ""submodules"" <TAB> if not submodules_path.is_dir(): <TAB> <TAB> return <TAB> for submodule in submodules_path.iterdir(): <TAB> <TAB> source_path = submodule / rel_source <TAB> <TAB> if not source_path.is_dir(): <TAB> <TAB> <TAB> continue <TAB> <TAB> output_path = submodule / rel_zip <TAB> <TAB> self._build_lambdas(source_path, output_path) <TAB> <TAB> self._recurse(submodule, rel_source, rel_zip)",true,if not source_path . is_dir ( ) :,if not source_path . is_dir ( ) :,0.75,0.0
"def find_test_functions(collections): <TAB> if not isinstance(collections, list): <TAB> <TAB> collections = [collections] <TAB> functions = [] <TAB> for collection in collections: <TAB> <TAB> if not isinstance(collection, dict): <TAB> <TAB> <TAB> collection = vars(collection) <TAB> <TAB> keys = collection.keys() <TAB> <TAB> keys.sort() <TAB> <TAB> for key in keys: <TAB> <TAB> <TAB> value = collection[key] <TAB> <TAB> <TAB> if isinstance(value, types.FunctionType) and hasattr(value, ""unittest""): <TAB> <TAB> <TAB> <TAB> functions.append(value) <TAB> return functions",true,"if isinstance ( value , types . FunctionType ) and hasattr ( value , ""unittest"" ) :","if isinstance ( value , types . FunctionType ) and hasattr ( value , ""unittest"" ) :",1.0,0.0
"def __init__( <TAB> self, <TAB> classifier, <TAB> layer_name=None, <TAB> transpose=None, <TAB> distance=None, <TAB> copy_weights=True, ): <TAB> super().__init__() <TAB> self.copy_weights = copy_weights <TAB> ### set layer weights ### <TAB> if layer_name is not None: <TAB> <TAB> self.set_weights(getattr(classifier, layer_name)) <TAB> else: <TAB> <TAB> for x in self.possible_layer_names: <TAB> <TAB> <TAB> layer = getattr(classifier, x, None) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.set_weights(layer) <TAB> <TAB> <TAB> <TAB> break <TAB> ### set distance measure ### <TAB> self.distance = classifier.distance if distance is None else distance <TAB> self.transpose = transpose",true,if layer is not None :,if layer is not None :,0.75,0.0
def multi_dev_generator(self): <TAB> for data in self._data_loader(): <TAB> <TAB> if len(self._tail_data) < self._base_number: <TAB> <TAB> <TAB> self._tail_data += data <TAB> <TAB> if len(self._tail_data) == self._base_number: <TAB> <TAB> <TAB> yield self._tail_data <TAB> <TAB> <TAB> self._tail_data = [],true,if len ( self . _tail_data ) == self . _base_number :,if len ( self . _tail_data ) == self . _base_number :,1.0,0.0
"def Resolve(self, updater=None): <TAB> if len(self.Conflicts): <TAB> <TAB> for setting, edge in self.Conflicts: <TAB> <TAB> <TAB> answer = self.AskUser(self.Setting, setting) <TAB> <TAB> <TAB> if answer == Gtk.ResponseType.YES: <TAB> <TAB> <TAB> <TAB> value = setting.Value.split(""|"") <TAB> <TAB> <TAB> <TAB> value.remove(edge) <TAB> <TAB> <TAB> <TAB> setting.Value = ""|"".join(value) <TAB> <TAB> <TAB> <TAB> if updater: <TAB> <TAB> <TAB> <TAB> <TAB> updater.UpdateSetting(setting) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",false,if answer == Gtk . ResponseType . NO :,if answer != Gtk . ResponseType . NO :,0.58,0.0
"def _post_process_ttl(zone): <TAB> for name in zone: <TAB> <TAB> for record_type in zone[name]: <TAB> <TAB> <TAB> records = zone[name][record_type] <TAB> <TAB> <TAB> if isinstance(records, list): <TAB> <TAB> <TAB> <TAB> ttl = min([x[""ttl""] for x in records]) <TAB> <TAB> <TAB> <TAB> for record in records: <TAB> <TAB> <TAB> <TAB> <TAB> if record[""ttl""] != ttl: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> logger.warning( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""Using lowest TTL {} for the record set. Ignoring value {}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ttl, record[""ttl""] <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <TAB> record[""ttl""] = ttl",false,"if record [ ""ttl"" ] != ttl :","if isinstance ( records , list ) :",0.02,0.0
"def __init__(self, cmds, env, cleanup=[]): <TAB> self.handle = None <TAB> self.cmds = cmds <TAB> self.env = env <TAB> if cleanup: <TAB> <TAB> if callable(cleanup): <TAB> <TAB> <TAB> cleanup = [cleanup] <TAB> <TAB> else: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> cleanup = [c for c in cleanup if callable(c)] <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> cleanup = [] <TAB> self.cleanup = cleanup",true,if callable ( cleanup ) :,if callable ( cleanup ) :,0.75,0.0
"def _parse_data_of_birth(cls, data_of_birth_string): <TAB> if data_of_birth_string: <TAB> <TAB> format = ""%m/%d/%Y"" <TAB> <TAB> try: <TAB> <TAB> <TAB> parsed_date = datetime.datetime.strptime(data_of_birth_string, format) <TAB> <TAB> <TAB> return parsed_date <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> # Facebook sometimes provides a partial date format <TAB> <TAB> <TAB> # ie 04/07 (ignore those) <TAB> <TAB> <TAB> if data_of_birth_string.count(""/"") != 1: <TAB> <TAB> <TAB> <TAB> raise",true,"if data_of_birth_string . count ( ""/"" ) != 1 :","if data_of_birth_string . count ( ""/"" ) != 1 :",0.75,0.0
"def process_lib(vars_, coreval): <TAB> for d in vars_: <TAB> <TAB> var = d.upper() <TAB> <TAB> if var == ""QTCORE"": <TAB> <TAB> <TAB> continue <TAB> <TAB> value = env[""LIBPATH_"" + var] <TAB> <TAB> if value: <TAB> <TAB> <TAB> core = env[coreval] <TAB> <TAB> <TAB> accu = [] <TAB> <TAB> <TAB> for lib in value: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> accu.append(lib) <TAB> <TAB> <TAB> env[""LIBPATH_"" + var] = accu",false,if lib in core :,if lib == core :,0.08,0.0
"def throttle_status(server=None): <TAB> result = AmonStruct() <TAB> result.allow = False <TAB> last_check = server.get(""last_check"") <TAB> server_check_period = server.get(""check_every"", 60) <TAB> if last_check: <TAB> <TAB> period_since_last_check = unix_utc_now() - last_check <TAB> <TAB> # Add 15 seconds buffer, for statsd <TAB> <TAB> period_since_last_check = period_since_last_check + 15 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result.allow = True <TAB> else: <TAB> <TAB> result.allow = True  # Never checked <TAB> return result",true,if period_since_last_check >= server_check_period :,if period_since_last_check >= server_check_period :,0.75,0.0
"def fetch_scatter_outputs(self, task): <TAB> scatteroutputs = [] <TAB> for var in task[""body""]: <TAB> <TAB> # TODO variable support <TAB> <TAB> if var.startswith(""call""): <TAB> <TAB> <TAB> if ""outputs"" in self.tasks_dictionary[task[""body""][var][""task""]]: <TAB> <TAB> <TAB> <TAB> for output in self.tasks_dictionary[task[""body""][var][""task""]][ <TAB> <TAB> <TAB> <TAB> <TAB> ""outputs"" <TAB> <TAB> <TAB> <TAB> ]: <TAB> <TAB> <TAB> <TAB> <TAB> scatteroutputs.append( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> {""task"": task[""body""][var][""alias""], ""output"": output[0]} <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> return scatteroutputs",false,"if ""outputs"" in self . tasks_dictionary [ task [ ""body"" ] [ var ] [ ""task"" ] ] :","if var . startswith ( ""call"" ) :",0.01,0.0
"def _add_constant_node(self, source_node): <TAB> parent_ids = range(len(source_node.in_edges)) <TAB> for idx in parent_ids: <TAB> <TAB> parent_node = self.tf_graph.get_node(source_node.in_edges[idx]) <TAB> <TAB> if parent_node.type == ""Const"": <TAB> <TAB> <TAB> self._rename_Const(parent_node)",true,"if parent_node . type == ""Const"" :","if parent_node . type == ""Const"" :",0.75,0.0
"def enableCtrls(self): <TAB> # Check if each ctrl has a requirement or an incompatibility, <TAB> # look it up, and enable/disable if so <TAB> for data in self.storySettingsData: <TAB> <TAB> name = data[""name""] <TAB> <TAB> if name in self.ctrls: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> set = self.getSetting(data[""requires""]) <TAB> <TAB> <TAB> <TAB> for i in self.ctrls[name]: <TAB> <TAB> <TAB> <TAB> <TAB> i.Enable(set not in [""off"", ""false"", ""0""])",true,"if ""requires"" in data :","if ""requires"" in data :",0.75,0.0
"def update_realtime(self, stdout="""", stderr="""", delete=False): <TAB> wooey_cache = wooey_settings.WOOEY_REALTIME_CACHE <TAB> if delete == False and wooey_cache is None: <TAB> <TAB> self.stdout = stdout <TAB> <TAB> self.stderr = stderr <TAB> <TAB> self.save() <TAB> elif wooey_cache is not None: <TAB> <TAB> cache = django_cache[wooey_cache] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> cache.delete(self.get_realtime_key()) <TAB> <TAB> else: <TAB> <TAB> <TAB> cache.set( <TAB> <TAB> <TAB> <TAB> self.get_realtime_key(), <TAB> <TAB> <TAB> <TAB> json.dumps({""stdout"": stdout, ""stderr"": stderr}), <TAB> <TAB> <TAB> )",true,if delete :,if delete :,0.53,0.0
"def _check_for_batch_clashes(xs): <TAB> """"""Check that batch names do not overlap with sample names."""""" <TAB> names = set([x[""description""] for x in xs]) <TAB> dups = set([]) <TAB> for x in xs: <TAB> <TAB> batches = tz.get_in((""metadata"", ""batch""), x) <TAB> <TAB> if batches: <TAB> <TAB> <TAB> if not isinstance(batches, (list, tuple)): <TAB> <TAB> <TAB> <TAB> batches = [batches] <TAB> <TAB> <TAB> for batch in batches: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> dups.add(batch) <TAB> if len(dups) > 0: <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> ""Batch names must be unique from sample descriptions.\n"" <TAB> <TAB> <TAB> ""Clashing batch names: %s"" % sorted(list(dups)) <TAB> <TAB> )",false,if batch in names :,if batch not in names :,0.27,0.0
"def toggle(self, event=None): <TAB> if self.absolute: <TAB> <TAB> if self.save == self.split: <TAB> <TAB> <TAB> self.save = 100 <TAB> <TAB> if self.split > 20: <TAB> <TAB> <TAB> self.save = self.split <TAB> <TAB> <TAB> self.split = 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> self.split = self.save <TAB> else: <TAB> <TAB> if self.save == self.split: <TAB> <TAB> <TAB> self.save = 0.3 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.split = self.save <TAB> <TAB> elif self.split < 0.5: <TAB> <TAB> <TAB> self.split = self.min <TAB> <TAB> else: <TAB> <TAB> <TAB> self.split = self.max <TAB> self.placeChilds()",false,if self . split <= self . min or self . split >= self . max :,if self . split > 20 :,0.13,0.0
"def can_read(self): <TAB> if hasattr(self.file, ""__iter__""): <TAB> <TAB> iterator = iter(self.file) <TAB> <TAB> head = next(iterator, None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.repaired = [] <TAB> <TAB> <TAB> return True <TAB> <TAB> if isinstance(head, str): <TAB> <TAB> <TAB> self.repaired = itertools.chain([head], iterator) <TAB> <TAB> <TAB> return True <TAB> <TAB> else: <TAB> <TAB> <TAB> # We may have mangled a generator at this point, so just abort <TAB> <TAB> <TAB> raise IOSourceError( <TAB> <TAB> <TAB> <TAB> ""Could not open source: %r (mode: %r)"" <TAB> <TAB> <TAB> <TAB> % (self.file, self.options[""mode""]) <TAB> <TAB> <TAB> ) <TAB> return False",true,if head is None :,if head is None :,0.75,0.0
"def _print_message_content(self, peer, data): <TAB> inheaders = 1 <TAB> lines = data.splitlines() <TAB> for line in lines: <TAB> <TAB> # headers first <TAB> <TAB> if inheaders and not line: <TAB> <TAB> <TAB> peerheader = ""X-Peer: "" + peer[0] <TAB> <TAB> <TAB> if not isinstance(data, str): <TAB> <TAB> <TAB> <TAB> # decoded_data=false; make header match other binary output <TAB> <TAB> <TAB> <TAB> peerheader = repr(peerheader.encode(""utf-8"")) <TAB> <TAB> <TAB> print(peerheader) <TAB> <TAB> <TAB> inheaders = 0 <TAB> <TAB> if not isinstance(data, str): <TAB> <TAB> <TAB> # Avoid spurious 'str on bytes instance' warning. <TAB> <TAB> <TAB> line = repr(line) <TAB> <TAB> print(line)",true,"if not isinstance ( data , str ) :","if not isinstance ( data , str ) :",0.75,0.0
"def connect(self): <TAB> # Makes connection with MySQL server <TAB> try: <TAB> <TAB> if os.path.exists(""/etc/mysql/conf.d/my.cnf""): <TAB> <TAB> <TAB> connection = pymysql.connect(read_default_file=""/etc/mysql/conf.d/my.cnf"") <TAB> <TAB> else: <TAB> <TAB> <TAB> connection = pymysql.connect(read_default_file=""~/.my.cnf"") <TAB> <TAB> return connection <TAB> except ValueError as e: <TAB> <TAB> Log.debug(self, str(e)) <TAB> <TAB> raise MySQLConnectionError <TAB> except pymysql.err.InternalError as e: <TAB> <TAB> Log.debug(self, str(e)) <TAB> <TAB> raise MySQLConnectionError",true,"if os . path . exists ( ""/etc/mysql/conf.d/my.cnf"" ) :","if os . path . exists ( ""/etc/mysql/conf.d/my.cnf"" ) :",0.75,0.0
"def _copy_package_apps( <TAB> local_bin_dir: Path, app_paths: List[Path], suffix: str = """" ) -> None: <TAB> for src_unresolved in app_paths: <TAB> <TAB> src = src_unresolved.resolve() <TAB> <TAB> app = src.name <TAB> <TAB> dest = Path(local_bin_dir / add_suffix(app, suffix)) <TAB> <TAB> if not dest.parent.is_dir(): <TAB> <TAB> <TAB> mkdir(dest.parent) <TAB> <TAB> if dest.exists(): <TAB> <TAB> <TAB> logger.warning(f""{hazard}  Overwriting file {str(dest)} with {str(src)}"") <TAB> <TAB> <TAB> dest.unlink() <TAB> <TAB> if src.exists(): <TAB> <TAB> <TAB> shutil.copy(src, dest)",true,if src . exists ( ) :,if src . exists ( ) :,0.75,0.0
"def update(self, x, who=None, metadata=None): <TAB> self._retain_refs(metadata) <TAB> y = self._get_key(x) <TAB> if self.keep == ""last"": <TAB> <TAB> # remove key if already present so that emitted value <TAB> <TAB> # will reflect elements' actual relative ordering <TAB> <TAB> self._buffer.pop(y, None) <TAB> <TAB> self._metadata_buffer.pop(y, None) <TAB> <TAB> self._buffer[y] = x <TAB> <TAB> self._metadata_buffer[y] = metadata <TAB> else:  # self.keep == ""first"" <TAB> <TAB> if y not in self._buffer: <TAB> <TAB> <TAB> self._buffer[y] = x <TAB> <TAB> <TAB> self._metadata_buffer[y] = metadata <TAB> return self.last",true,if y not in self . _buffer :,if y not in self . _buffer :,0.75,0.0
"def resolve_credential_keys(m_keys, keys): <TAB> res = [] <TAB> for k in m_keys: <TAB> <TAB> if k[""c7n:match-type""] == ""credential"": <TAB> <TAB> <TAB> c_date = parse_date(k[""last_rotated""]) <TAB> <TAB> <TAB> for ak in keys: <TAB> <TAB> <TAB> <TAB> if c_date == ak[""CreateDate""]: <TAB> <TAB> <TAB> <TAB> <TAB> ak = dict(ak) <TAB> <TAB> <TAB> <TAB> <TAB> ak[""c7n:match-type""] = ""access"" <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> res.append(ak) <TAB> <TAB> elif k not in res: <TAB> <TAB> <TAB> res.append(k) <TAB> return res",false,if ak not in res :,if k in res :,0.12,0.0
"def _apply_flag_attrs(src_flag, dest_flag): <TAB> # Use a baseline flag def to get default values for empty data. <TAB> baseline_flag = FlagDef("""", {}, None) <TAB> for name in dir(src_flag): <TAB> <TAB> if name[:1] == ""_"": <TAB> <TAB> <TAB> continue <TAB> <TAB> dest_val = getattr(dest_flag, name, None) <TAB> <TAB> baseline_val = getattr(baseline_flag, name, None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> setattr(dest_flag, name, getattr(src_flag, name))",true,if dest_val == baseline_val :,if dest_val == baseline_val :,0.75,0.0
"def _ws_keep_reading(self): <TAB> import websockets.exceptions <TAB> while not self._reader_stopped: <TAB> <TAB> try: <TAB> <TAB> <TAB> data = await self._ws.recv() <TAB> <TAB> <TAB> if isinstance(data, str): <TAB> <TAB> <TAB> <TAB> data = data.encode(""UTF-8"") <TAB> <TAB> <TAB> if len(data) == 0: <TAB> <TAB> <TAB> <TAB> self._error = ""EOF"" <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> except websockets.exceptions.ConnectionClosedError: <TAB> <TAB> <TAB> # TODO: try to reconnect in case of Ctrl+D <TAB> <TAB> <TAB> self._error = ""EOF"" <TAB> <TAB> <TAB> break <TAB> <TAB> self.num_bytes_received += len(data) <TAB> <TAB> self._make_output_available(data, block=False)",true,"if isinstance ( data , str ) :","if isinstance ( data , str ) :",0.75,0.0
"def to_dict(self) -> Dict[str, Any]: <TAB> result = {} <TAB> for field_name in self.API_FIELDS: <TAB> <TAB> if field_name == ""id"": <TAB> <TAB> <TAB> result[""stream_id""] = self.id <TAB> <TAB> <TAB> continue <TAB> <TAB> elif field_name == ""date_created"": <TAB> <TAB> <TAB> result[""date_created""] = datetime_to_timestamp(self.date_created) <TAB> <TAB> <TAB> continue <TAB> <TAB> result[field_name] = getattr(self, field_name) <TAB> result[""is_announcement_only""] = ( <TAB> <TAB> self.stream_post_policy == Stream.STREAM_POST_POLICY_ADMINS <TAB> ) <TAB> return result",false,"if field_name == ""id"" :","elif field_name == ""date_created"" :",0.06,0.0
"def all_masks( <TAB> cls, <TAB> images, <TAB> run, <TAB> run_key, <TAB> step, ): <TAB> all_mask_groups = [] <TAB> for image in images: <TAB> <TAB> if image._masks: <TAB> <TAB> <TAB> mask_group = {} <TAB> <TAB> <TAB> for k in image._masks: <TAB> <TAB> <TAB> <TAB> mask = image._masks[k] <TAB> <TAB> <TAB> <TAB> mask_group[k] = mask.to_json(run) <TAB> <TAB> <TAB> all_mask_groups.append(mask_group) <TAB> <TAB> else: <TAB> <TAB> <TAB> all_mask_groups.append(None) <TAB> if all_mask_groups and not all(x is None for x in all_mask_groups): <TAB> <TAB> return all_mask_groups <TAB> else: <TAB> <TAB> return False",true,if image . _masks :,if image . _masks :,0.75,0.0
"def disconnect_all(listener): <TAB> """"""Disconnect from all signals"""""" <TAB> for emitter in listener._signal_data.emitters: <TAB> <TAB> for signal in emitter._signal_data.listeners: <TAB> <TAB> <TAB> emitter._signal_data.listeners[signal] = [ <TAB> <TAB> <TAB> <TAB> i <TAB> <TAB> <TAB> <TAB> for i in emitter._signal_data.listeners[signal] <TAB> <TAB> <TAB> <TAB> if getattr(i, ""__self__"", None) != listener <TAB> <TAB> <TAB> ]",true,"if getattr ( i , ""__self__"" , None ) != listener","if getattr ( i , ""__self__"" , None ) != listener",0.75,0.0
"def wait(self, timeout=None): <TAB> if self.returncode is None: <TAB> <TAB> if timeout is None: <TAB> <TAB> <TAB> msecs = _subprocess.INFINITE <TAB> <TAB> else: <TAB> <TAB> <TAB> msecs = max(0, int(timeout * 1000 + 0.5)) <TAB> <TAB> res = _subprocess.WaitForSingleObject(int(self._handle), msecs) <TAB> <TAB> if res == _subprocess.WAIT_OBJECT_0: <TAB> <TAB> <TAB> code = _subprocess.GetExitCodeProcess(self._handle) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> code = -signal.SIGTERM <TAB> <TAB> <TAB> self.returncode = code <TAB> return self.returncode",false,if code == TERMINATE :,if code == _subprocess . WAIT_SIGINT :,0.12,0.0
"def set_pbar_fraction(self, frac, progress, stage=None): <TAB> gtk.gdk.threads_enter() <TAB> try: <TAB> <TAB> self.is_pulsing = False <TAB> <TAB> self.set_stage_text(stage or _(""Processing..."")) <TAB> <TAB> self.pbar.set_text(progress) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> frac = 1.0 <TAB> <TAB> if frac < 0: <TAB> <TAB> <TAB> frac = 0 <TAB> <TAB> self.pbar.set_fraction(frac) <TAB> finally: <TAB> <TAB> gtk.gdk.threads_leave()",false,if frac > 1 :,if frac > 1.0 :,0.14,0.0
"def get_aa_from_codonre(re_aa): <TAB> aas = [] <TAB> m = 0 <TAB> for i in re_aa: <TAB> <TAB> if i == ""["": <TAB> <TAB> <TAB> m = -1 <TAB> <TAB> <TAB> aas.append("""") <TAB> <TAB> elif i == ""]"": <TAB> <TAB> <TAB> m = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> elif m == -1: <TAB> <TAB> <TAB> aas[-1] = aas[-1] + i <TAB> <TAB> elif m == 0: <TAB> <TAB> <TAB> aas.append(i) <TAB> return aas",false,"elif i == ""]"" :",elif m == - 1 :,0.34,0.0
"def link(token, base_url): <TAB> """"""Validation for ``link``."""""" <TAB> if get_keyword(token) == ""none"": <TAB> <TAB> return ""none"" <TAB> parsed_url = get_url(token, base_url) <TAB> if parsed_url: <TAB> <TAB> return parsed_url <TAB> function = parse_function(token) <TAB> if function: <TAB> <TAB> name, args = function <TAB> <TAB> prototype = (name, [a.type for a in args]) <TAB> <TAB> args = [getattr(a, ""value"", a) for a in args] <TAB> <TAB> if prototype == (""attr"", [""ident""]): <TAB> <TAB> <TAB> return (""attr()"", args[0])",true,"if prototype == ( ""attr"" , [ ""ident"" ] ) :","if prototype == ( ""attr"" , [ ""ident"" ] ) :",0.75,0.0
"def on_bt_search_clicked(self, widget): <TAB> if self.current_provider is None: <TAB> <TAB> return <TAB> query = self.en_query.get_text() <TAB> @self.obtain_podcasts_with <TAB> def load_data(): <TAB> <TAB> if self.current_provider.kind == directory.Provider.PROVIDER_SEARCH: <TAB> <TAB> <TAB> return self.current_provider.on_search(query) <TAB> <TAB> elif self.current_provider.kind == directory.Provider.PROVIDER_URL: <TAB> <TAB> <TAB> return self.current_provider.on_url(query) <TAB> <TAB> elif self.current_provider.kind == directory.Provider.PROVIDER_FILE: <TAB> <TAB> <TAB> return self.current_provider.on_file(query)",true,elif self . current_provider . kind == directory . Provider . PROVIDER_URL :,elif self . current_provider . kind == directory . Provider . PROVIDER_URL :,0.75,0.0
"def test_handle_single(self): <TAB> self.skipTest( <TAB> <TAB> ""Pops up windows and needs user input.. so disabled."" <TAB> <TAB> ""Still worth keeping whilst we don't have unit tests "" <TAB> <TAB> ""for all plugins."" <TAB> ) <TAB> # Ignored... <TAB> for id_, plugin in self.plugins.items(): <TAB> <TAB> if self.h.plugin_handle(plugin): <TAB> <TAB> <TAB> self.h.plugin_enable(plugin, None) <TAB> <TAB> <TAB> self.h.handle(id_, self.lib, self.parent, SONGS) <TAB> <TAB> <TAB> self.h.plugin_disable(plugin)",true,if self . h . plugin_handle ( plugin ) :,if self . h . plugin_handle ( plugin ) :,0.75,0.0
"def __repr__(self): <TAB> attrs = [] <TAB> for k in self._keydata: <TAB> <TAB> if k == ""p"": <TAB> <TAB> <TAB> attrs.append(""p(%d)"" % (self.size() + 1,)) <TAB> <TAB> elif hasattr(self, k): <TAB> <TAB> <TAB> attrs.append(k) <TAB> if self.has_private(): <TAB> <TAB> attrs.append(""private"") <TAB> # PY3K: This is meant to be text, do not change to bytes (data) <TAB> return ""<%s @0x%x %s>"" % (self.__class__.__name__, id(self), "","".join(attrs))",false,"if k == ""p"" :","elif hasattr ( self , k ) :",0.02,0.0
"def apply(self, node, code, required): <TAB> yield ""try:"" <TAB> yield from self.iterIndented(code) <TAB> yield "" <TAB>pass"" <TAB> yield ""except {}:"".format(self.exceptionString) <TAB> outputVariables = node.getOutputSocketVariables() <TAB> for i, s in enumerate(node.outputs): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if hasattr(s, ""getDefaultValueCode""): <TAB> <TAB> <TAB> <TAB> yield f"" <TAB>{outputVariables[s.identifier]} = {s.getDefaultValueCode()}"" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> yield f"" <TAB>{outputVariables[s.identifier]} = self.outputs[{i}].getDefaultValue()"" <TAB> yield "" <TAB>pass""",false,if s . identifier in required :,if s . identifier not in outputVariables :,0.36,0.0
"def __import__(name, globals=None, locals=None, fromlist=(), level=0): <TAB> module = orig___import__(name, globals, locals, fromlist, level) <TAB> if fromlist and module.__name__ in modules: <TAB> <TAB> if ""*"" in fromlist: <TAB> <TAB> <TAB> fromlist = list(fromlist) <TAB> <TAB> <TAB> fromlist.remove(""*"") <TAB> <TAB> <TAB> fromlist.extend(getattr(module, ""__all__"", [])) <TAB> <TAB> for x in fromlist: <TAB> <TAB> <TAB> if isinstance(getattr(module, x, None), types.ModuleType): <TAB> <TAB> <TAB> <TAB> from_name = ""{}.{}"".format(module.__name__, x) <TAB> <TAB> <TAB> <TAB> if from_name in modules: <TAB> <TAB> <TAB> <TAB> <TAB> importlib.import_module(from_name) <TAB> return module",true,"if isinstance ( getattr ( module , x , None ) , types . ModuleType ) :","if isinstance ( getattr ( module , x , None ) , types . ModuleType ) :",0.75,0.0
"def _consume_msg(self): <TAB> ws = self._ws <TAB> try: <TAB> <TAB> while True: <TAB> <TAB> <TAB> r = await ws.recv() <TAB> <TAB> <TAB> if isinstance(r, bytes): <TAB> <TAB> <TAB> <TAB> r = r.decode(""utf-8"") <TAB> <TAB> <TAB> msg = json.loads(r) <TAB> <TAB> <TAB> stream = msg.get(""stream"") <TAB> <TAB> <TAB> if stream is not None: <TAB> <TAB> <TAB> <TAB> await self._dispatch(stream, msg) <TAB> except websockets.WebSocketException as wse: <TAB> <TAB> logging.warn(wse) <TAB> <TAB> await self.close() <TAB> <TAB> asyncio.ensure_future(self._ensure_ws())",true,"if isinstance ( r , bytes ) :","if isinstance ( r , bytes ) :",0.75,0.0
"def add_source(self, source, name=None): <TAB> """"""Adds a new data source to an existing provider."""""" <TAB> if self.randomize: <TAB> <TAB> if not source.can_shuffle(): <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""Cannot add a non-shuffleable source to an "" <TAB> <TAB> <TAB> <TAB> ""already shuffled provider."" <TAB> <TAB> <TAB> ) <TAB> super().add_source(source, name=name) <TAB> if self.randomize is True: <TAB> <TAB> self._shuffle_len = self.entries",true,if not source . can_shuffle ( ) :,if not source . can_shuffle ( ) :,0.75,0.0
"def __str__(self): <TAB> buf = [""""] <TAB> if self.fileName: <TAB> <TAB> buf.append(self.fileName + "":"") <TAB> if self.line != -1: <TAB> <TAB> if not self.fileName: <TAB> <TAB> <TAB> buf.append(""line "") <TAB> <TAB> buf.append(str(self.line)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> buf.append("":"" + str(self.column)) <TAB> <TAB> buf.append("":"") <TAB> buf.append("" "") <TAB> return str("""").join(buf)",true,if self . column != - 1 :,if self . column != - 1 :,0.75,0.0
"def has_bad_headers(self): <TAB> headers = [self.sender, self.reply_to] + self.recipients <TAB> for header in headers: <TAB> <TAB> if _has_newline(header): <TAB> <TAB> <TAB> return True <TAB> if self.subject: <TAB> <TAB> if _has_newline(self.subject): <TAB> <TAB> <TAB> for linenum, line in enumerate(self.subject.split(""\r\n"")): <TAB> <TAB> <TAB> <TAB> if not line: <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if linenum > 0 and line[0] not in ""\t "": <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if _has_newline(line): <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if len(line.strip()) == 0: <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",false,if len ( line . strip ( ) ) == 0 :,"if linenum > 0 and line [ 0 ] not in ""\t"" :",0.01,0.0
"def scanHexEscape(self, prefix): <TAB> code = 0 <TAB> leng = 4 if (prefix == ""u"") else 2 <TAB> for i in xrange(leng): <TAB> <TAB> if self.index < self.length and isHexDigit(self.source[self.index]): <TAB> <TAB> <TAB> ch = self.source[self.index] <TAB> <TAB> <TAB> self.index += 1 <TAB> <TAB> <TAB> code = code * 16 + HEX_CONV[ch] <TAB> <TAB> else: <TAB> <TAB> <TAB> return """" <TAB> return unichr(code)",true,if self . index < self . length and isHexDigit ( self . source [ self . index ] ) :,if self . index < self . length and isHexDigit ( self . source [ self . index ] ) :,1.0,0.0
"def _get_table_info(self, table_name): <TAB> table_addr = self.addr_space.profile.get_symbol(table_name) <TAB> table_size = self._get_table_info_distorm() <TAB><IF-STMT> <TAB> <TAB> table_size = self._get_table_info_other(table_addr, table_name) <TAB> <TAB> if table_size == 0: <TAB> <TAB> <TAB> debug.error(""Unable to get system call table size"") <TAB> return [table_addr, table_size]",true,if table_size == 0 :,if table_size == 0 :,0.75,0.0
"def format_file_path(filepath): <TAB> """"""Formats a path as absolute and with the correct platform separator."""""" <TAB> try: <TAB> <TAB> is_windows_network_mount = WINDOWS_NETWORK_MOUNT_PATTERN.match(filepath) <TAB> <TAB> filepath = os.path.realpath(os.path.abspath(filepath)) <TAB> <TAB> filepath = re.sub(BACKSLASH_REPLACE_PATTERN, ""/"", filepath) <TAB> <TAB> is_windows_drive = WINDOWS_DRIVE_PATTERN.match(filepath) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> filepath = filepath.capitalize() <TAB> <TAB> if is_windows_network_mount: <TAB> <TAB> <TAB> # Add back a / to the front, since the previous modifications <TAB> <TAB> <TAB> # will have replaced any double slashes with single <TAB> <TAB> <TAB> filepath = ""/"" + filepath <TAB> except: <TAB> <TAB> pass <TAB> return filepath",true,if is_windows_drive :,if is_windows_drive :,0.53,0.0
"def _match(self, cre, s): <TAB> # Run compiled regular expression match method on 's'. <TAB> # Save result, return success. <TAB> self.mo = cre.match(s) <TAB> if __debug__: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._mesg(""\tmatched r'%r' => %r"" % (cre.pattern, self.mo.groups())) <TAB> return self.mo is not None",false,if self . mo is not None and self . debug >= 5 :,if self . mo :,0.11,0.0
"def reload_sanitize_allowlist(self, explicit=True): <TAB> self.sanitize_allowlist = [] <TAB> try: <TAB> <TAB> with open(self.sanitize_allowlist_file) as f: <TAB> <TAB> <TAB> for line in f.readlines(): <TAB> <TAB> <TAB> <TAB> if not line.startswith(""#""): <TAB> <TAB> <TAB> <TAB> <TAB> self.sanitize_allowlist.append(line.strip()) <TAB> except OSError: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> log.warning( <TAB> <TAB> <TAB> <TAB> ""Sanitize log file explicitly specified as '%s' but does not exist, continuing with no tools allowlisted."", <TAB> <TAB> <TAB> <TAB> self.sanitize_allowlist_file, <TAB> <TAB> <TAB> )",true,if explicit :,if explicit :,0.53,0.0
"def conj(self): <TAB> dtype = self.dtype <TAB> if issubclass(self.dtype.type, np.complexfloating): <TAB> <TAB> if not self.flags.forc: <TAB> <TAB> <TAB> raise RuntimeError( <TAB> <TAB> <TAB> <TAB> ""only contiguous arrays may "" ""be used as arguments to this operation"" <TAB> <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> order = ""F"" <TAB> <TAB> else: <TAB> <TAB> <TAB> order = ""C"" <TAB> <TAB> result = self._new_like_me(order=order) <TAB> <TAB> func = elementwise.get_conj_kernel(dtype) <TAB> <TAB> func.prepared_async_call( <TAB> <TAB> <TAB> self._grid, self._block, None, self.gpudata, result.gpudata, self.mem_size <TAB> <TAB> ) <TAB> <TAB> return result <TAB> else: <TAB> <TAB> return self",false,if self . flags . f_contiguous :,if self . flags . f :,0.57,0.0
"def scan_spec_conf(self, conf): <TAB> if ""metadata"" in conf: <TAB> <TAB> if ""annotations"" in conf[""metadata""] and conf[""metadata""].get(""annotations""): <TAB> <TAB> <TAB> for annotation in conf[""metadata""][""annotations""]: <TAB> <TAB> <TAB> <TAB> for key in annotation: <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""docker/default"" in annotation[key] <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> or ""runtime/default"" in annotation[key] <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return CheckResult.PASSED <TAB> return CheckResult.FAILED",false,"if ""seccomp.security.alpha.kubernetes.io/defaultProfileName"" in key :",if key in conf :,0.04,0.0
"def test_error_through_destructor(self): <TAB> # Test that the exception state is not modified by a destructor, <TAB> # even if close() fails. <TAB> rawio = self.CloseFailureIO() <TAB> with support.catch_unraisable_exception() as cm: <TAB> <TAB> with self.assertRaises(AttributeError): <TAB> <TAB> <TAB> self.tp(rawio).xyzzy <TAB> <TAB> if not IOBASE_EMITS_UNRAISABLE: <TAB> <TAB> <TAB> self.assertIsNone(cm.unraisable) <TAB> <TAB> elif cm.unraisable is not None: <TAB> <TAB> <TAB> self.assertEqual(cm.unraisable.exc_type, OSError)",true,elif cm . unraisable is not None :,elif cm . unraisable is not None :,0.75,0.0
"def _dumpf(frame): <TAB> if frame is None: <TAB> <TAB> return ""<None>"" <TAB> else: <TAB> <TAB> addn = ""(with trace!)"" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> addn = "" **No Trace Set **"" <TAB> <TAB> return ""Frame at %d, file %s, line: %d%s"" % ( <TAB> <TAB> <TAB> id(frame), <TAB> <TAB> <TAB> frame.f_code.co_filename, <TAB> <TAB> <TAB> frame.f_lineno, <TAB> <TAB> <TAB> addn, <TAB> <TAB> )",false,if frame . f_trace is None :,if not frame . f_code . co_filename :,0.04,0.0
"def containsBadbytes(self, value, bytecount=4): <TAB> for b in self.badbytes: <TAB> <TAB> tmp = value <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> b = ord(b) <TAB> <TAB> for i in range(bytecount): <TAB> <TAB> <TAB> if (tmp & 0xFF) == b: <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> tmp >>= 8 <TAB> return False",false,if type ( b ) == str :,if tmp & 0x80 :,0.02,0.0
"def _set_peer_statuses(self): <TAB> """"""Set peer statuses."""""" <TAB> cutoff = time.time() - STALE_SECS <TAB> for peer in self.peers: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> peer.status = PEER_BAD <TAB> <TAB> elif peer.last_good > cutoff: <TAB> <TAB> <TAB> peer.status = PEER_GOOD <TAB> <TAB> elif peer.last_good: <TAB> <TAB> <TAB> peer.status = PEER_STALE <TAB> <TAB> else: <TAB> <TAB> <TAB> peer.status = PEER_NEVER",false,if peer . bad :,if peer . last_good < cutoff :,0.2,0.0
"def afterTest(self, test): <TAB> try: <TAB> <TAB> # If the browser window is still open, close it now. <TAB> <TAB> self.driver.quit() <TAB> except AttributeError: <TAB> <TAB> pass <TAB> except Exception: <TAB> <TAB> pass <TAB> if self.options.headless: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> self.display.stop() <TAB> <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> pass",false,if self . headless_active :,if self . display :,0.39,0.0
"def _written_variables_in_proxy(self, contract): <TAB> variables = [] <TAB> if contract.is_upgradeable: <TAB> <TAB> variables_name_written_in_proxy = self._variable_written_in_proxy() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> variables_in_contract = [ <TAB> <TAB> <TAB> <TAB> contract.get_state_variable_from_name(v) <TAB> <TAB> <TAB> <TAB> for v in variables_name_written_in_proxy <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> variables_in_contract = [v for v in variables_in_contract if v] <TAB> <TAB> <TAB> variables += variables_in_contract <TAB> return list(set(variables))",true,if variables_name_written_in_proxy :,if variables_name_written_in_proxy :,0.53,0.0
"def _available_symbols(self, scoperef, expr): <TAB> cplns = [] <TAB> found_names = set() <TAB> while scoperef: <TAB> <TAB> elem = self._elem_from_scoperef(scoperef) <TAB> <TAB> for child in elem: <TAB> <TAB> <TAB> name = child.get(""name"", """") <TAB> <TAB> <TAB> if name.startswith(expr): <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> found_names.add(name) <TAB> <TAB> <TAB> <TAB> <TAB> ilk = child.get(""ilk"") or child.tag <TAB> <TAB> <TAB> <TAB> <TAB> cplns.append((ilk, name)) <TAB> <TAB> scoperef = self.parent_scoperef_from_scoperef(scoperef) <TAB> <TAB> if not scoperef: <TAB> <TAB> <TAB> break <TAB> return sorted(cplns, key=operator.itemgetter(1))",true,if name not in found_names :,if name not in found_names :,0.75,0.0
"def get_resource_public_actions(resource_class): <TAB> resource_class_members = inspect.getmembers(resource_class) <TAB> resource_methods = {} <TAB> for name, member in resource_class_members: <TAB> <TAB> if not name.startswith(""_""): <TAB> <TAB> <TAB> if not name[0].isupper(): <TAB> <TAB> <TAB> <TAB> if not name.startswith(""wait_until""): <TAB> <TAB> <TAB> <TAB> <TAB> if is_resource_action(member): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> resource_methods[name] = member <TAB> return resource_methods",false,if not name [ 0 ] . isupper ( ) :,if is_resource_action ( member ) :,0.02,0.0
def UpdateControlState(self): <TAB> active = self.demoModules.GetActiveID() <TAB> # Update the radio/restore buttons <TAB> for moduleID in self.radioButtons: <TAB> <TAB> btn = self.radioButtons[moduleID] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> btn.SetValue(True) <TAB> <TAB> else: <TAB> <TAB> <TAB> btn.SetValue(False) <TAB> <TAB> if self.demoModules.Exists(moduleID): <TAB> <TAB> <TAB> btn.Enable(True) <TAB> <TAB> <TAB> if moduleID == modModified: <TAB> <TAB> <TAB> <TAB> self.btnRestore.Enable(True) <TAB> <TAB> else: <TAB> <TAB> <TAB> btn.Enable(False) <TAB> <TAB> <TAB> if moduleID == modModified: <TAB> <TAB> <TAB> <TAB> self.btnRestore.Enable(False),true,if moduleID == active :,if moduleID == active :,0.75,0.0
"def test_controlcharacters(self): <TAB> for i in range(128): <TAB> <TAB> c = chr(i) <TAB> <TAB> testString = ""string containing %s"" % c <TAB> <TAB> if i >= 32 or c in ""\r\n\t"": <TAB> <TAB> <TAB> # \r, \n and \t are the only legal control chars in XML <TAB> <TAB> <TAB> data = plistlib.dumps(testString, fmt=plistlib.FMT_XML) <TAB> <TAB> <TAB> if c != ""\r"": <TAB> <TAB> <TAB> <TAB> self.assertEqual(plistlib.loads(data), testString) <TAB> <TAB> else: <TAB> <TAB> <TAB> with self.assertRaises(ValueError): <TAB> <TAB> <TAB> <TAB> plistlib.dumps(testString, fmt=plistlib.FMT_XML) <TAB> <TAB> plistlib.dumps(testString, fmt=plistlib.FMT_BINARY)",true,"if c != ""\r"" :","if c != ""\r"" :",0.75,0.0
"def remove_usernames(self, username: SLT[str]) -> None: <TAB> with self.__lock: <TAB> <TAB> if self._chat_ids: <TAB> <TAB> <TAB> raise RuntimeError( <TAB> <TAB> <TAB> <TAB> f""Can't set {self.username_name} in conjunction with (already set) "" <TAB> <TAB> <TAB> <TAB> f""{self.chat_id_name}s."" <TAB> <TAB> <TAB> ) <TAB> <TAB> parsed_username = self._parse_username(username) <TAB> <TAB> self._usernames -= parsed_username",true,if self . _chat_ids :,if self . _chat_ids :,0.75,0.0
"def get_size(self, shape_info): <TAB> # The size is the data, that have constant size. <TAB> state = np.random.RandomState().get_state() <TAB> size = 0 <TAB> for elem in state: <TAB> <TAB> if isinstance(elem, str): <TAB> <TAB> <TAB> size += len(elem) <TAB> <TAB> elif isinstance(elem, np.ndarray): <TAB> <TAB> <TAB> size += elem.size * elem.itemsize <TAB> <TAB> elif isinstance(elem, int): <TAB> <TAB> <TAB> size += np.dtype(""int"").itemsize <TAB> <TAB> elif isinstance(elem, float): <TAB> <TAB> <TAB> size += np.dtype(""float"").itemsize <TAB> <TAB> else: <TAB> <TAB> <TAB> raise NotImplementedError() <TAB> return size",false,"elif isinstance ( elem , int ) :","elif isinstance ( elem , np . ndarray ) :",0.35,0.0
"def before_step(self, step, feed_dict): <TAB> if step == 0: <TAB> <TAB> for _type, mem in self.memories.items(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.gan.session.run(tf.assign(mem[""var""], mem[""source""]))",true,"if ""var"" in mem and ""source"" in mem :","if ""var"" in mem and ""source"" in mem :",1.0,0.0
"def write(self, *bits): <TAB> for bit in bits: <TAB> <TAB> if not self.bytestream: <TAB> <TAB> <TAB> self.bytestream.append(0) <TAB> <TAB> byte = self.bytestream[self.bytenum] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if self.bytenum == len(self.bytestream) - 1: <TAB> <TAB> <TAB> <TAB> byte = 0 <TAB> <TAB> <TAB> <TAB> self.bytestream += bytes([byte]) <TAB> <TAB> <TAB> self.bytenum += 1 <TAB> <TAB> <TAB> self.bitnum = 0 <TAB> <TAB> mask = 2 ** self.bitnum <TAB> <TAB> if bit: <TAB> <TAB> <TAB> byte |= mask <TAB> <TAB> else: <TAB> <TAB> <TAB> byte &= ~mask <TAB> <TAB> self.bytestream[self.bytenum] = byte <TAB> <TAB> self.bitnum += 1",false,if self . bitnum == 8 :,if byte :,0.02,0.0
"def _validate_parameter_range(self, value_hp, parameter_range): <TAB> """"""Placeholder docstring"""""" <TAB> for ( <TAB> <TAB> parameter_range_key, <TAB> <TAB> parameter_range_value, <TAB> ) in parameter_range.__dict__.items(): <TAB> <TAB> if parameter_range_key == ""scaling_type"": <TAB> <TAB> <TAB> continue <TAB> <TAB> # Categorical ranges <TAB> <TAB> if isinstance(parameter_range_value, list): <TAB> <TAB> <TAB> for categorical_value in parameter_range_value: <TAB> <TAB> <TAB> <TAB> value_hp.validate(categorical_value) <TAB> <TAB> # Continuous, Integer ranges <TAB> <TAB> else: <TAB> <TAB> <TAB> value_hp.validate(parameter_range_value)",false,"if isinstance ( parameter_range_value , list ) :","if parameter_range_key == ""scaling_type"" :",0.02,0.0
"def _trackA(self, tracks): <TAB> try: <TAB> <TAB> track, start, end = self.featureA <TAB> <TAB> assert track in tracks <TAB> <TAB> return track <TAB> except TypeError: <TAB> <TAB> for track in tracks: <TAB> <TAB> <TAB> for feature_set in track.get_sets(): <TAB> <TAB> <TAB> <TAB> if hasattr(feature_set, ""features""): <TAB> <TAB> <TAB> <TAB> <TAB> if self.featureA in feature_set.features.values(): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return track <TAB> <TAB> return None",false,if self . featureA in feature_set . features . values ( ) :,"if hasattr ( feature_set , ""features"" ) :",0.02,0.0
"def walk(directory, path_so_far): <TAB> for name in sorted(os.listdir(directory)): <TAB> <TAB> if any(fnmatch(name, pattern) for pattern in basename_ignore): <TAB> <TAB> <TAB> continue <TAB> <TAB> path = path_so_far + ""/"" + name if path_so_far else name <TAB> <TAB> if any(fnmatch(path, pattern) for pattern in path_ignore): <TAB> <TAB> <TAB> continue <TAB> <TAB> full_name = os.path.join(directory, name) <TAB> <TAB> if os.path.isdir(full_name): <TAB> <TAB> <TAB> for file_path in walk(full_name, path): <TAB> <TAB> <TAB> <TAB> yield file_path <TAB> <TAB> elif os.path.isfile(full_name): <TAB> <TAB> <TAB> yield path",false,if os . path . isdir ( full_name ) :,"if any ( fnmatch ( name , pattern ) for pattern in basename_ignore ) :",0.02,0.0
"def _poll_ipc_requests(self) -> None: <TAB> try: <TAB> <TAB> if self._ipc_requests.empty(): <TAB> <TAB> <TAB> return <TAB> <TAB> while not self._ipc_requests.empty(): <TAB> <TAB> <TAB> args = self._ipc_requests.get() <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> for filename in args: <TAB> <TAB> <TAB> <TAB> <TAB> if os.path.isfile(filename): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self.get_editor_notebook().show_file(filename) <TAB> <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> <TAB> logger.exception(""Problem processing ipc request"", exc_info=e) <TAB> <TAB> self.become_active_window() <TAB> finally: <TAB> <TAB> self.after(50, self._poll_ipc_requests)",false,if self . _ipc_requests . empty ( ) :,if os . path . isfile ( filename ) :,0.08,0.0
"def test_read1(self): <TAB> self.test_write() <TAB> blocks = [] <TAB> nread = 0 <TAB> with gzip.GzipFile(self.filename, ""r"") as f: <TAB> <TAB> while True: <TAB> <TAB> <TAB> d = f.read1() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> blocks.append(d) <TAB> <TAB> <TAB> nread += len(d) <TAB> <TAB> <TAB> # Check that position was updated correctly (see issue10791). <TAB> <TAB> <TAB> self.assertEqual(f.tell(), nread) <TAB> self.assertEqual(b"""".join(blocks), data1 * 50)",true,if not d :,if not d :,0.75,0.0
"def _target_generator(self): <TAB> if self._internal_target_generator is None: <TAB> <TAB> if self._net_none: <TAB> <TAB> <TAB> return None <TAB> <TAB> from ....model_zoo.rcnn.rpn.rpn_target import RPNTargetGenerator <TAB> <TAB> self._internal_target_generator = RPNTargetGenerator( <TAB> <TAB> <TAB> num_sample=self._num_sample, <TAB> <TAB> <TAB> pos_iou_thresh=self._pos_iou_thresh, <TAB> <TAB> <TAB> neg_iou_thresh=self._neg_iou_thresh, <TAB> <TAB> <TAB> pos_ratio=self._pos_ratio, <TAB> <TAB> <TAB> stds=self._box_norm, <TAB> <TAB> <TAB> **self._kwargs <TAB> <TAB> ) <TAB> <TAB> return self._internal_target_generator <TAB> else: <TAB> <TAB> return self._internal_target_generator",true,if self . _net_none :,if self . _net_none :,0.75,0.0
"def time_left(self): <TAB> """"""Return how many seconds are left until the timeout expires"""""" <TAB> if self.is_non_blocking: <TAB> <TAB> return 0 <TAB> elif self.is_infinite: <TAB> <TAB> return None <TAB> else: <TAB> <TAB> delta = self.target_time - self.TIME() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # clock jumped, recalculate <TAB> <TAB> <TAB> self.target_time = self.TIME() + self.duration <TAB> <TAB> <TAB> return self.duration <TAB> <TAB> else: <TAB> <TAB> <TAB> return max(0, delta)",false,if delta > self . duration :,if delta < 0 :,0.04,0.0
"def _decorator(cls): <TAB> for name, meth in inspect.getmembers(cls, inspect.isroutine): <TAB> <TAB> if name not in cls.__dict__: <TAB> <TAB> <TAB> continue <TAB> <TAB> if name != ""__init__"": <TAB> <TAB> <TAB> if not private and name.startswith(""_""): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> setattr(cls, name, decorator(meth)) <TAB> return cls",false,if name in butnot :,if meth is None :,0.28,0.0
"def load_vocab(vocab_file: str) -> List: <TAB> """"""Loads a vocabulary file into a dictionary."""""" <TAB> vocab = collections.OrderedDict() <TAB> with io.open(vocab_file, ""r"", encoding=""UTF-8"") as file: <TAB> <TAB> for num, line in enumerate(file): <TAB> <TAB> <TAB> items = convert_to_unicode(line.strip()).split(""\t"") <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> token = items[0] <TAB> <TAB> <TAB> index = items[1] if len(items) == 2 else num <TAB> <TAB> <TAB> token = token.strip() <TAB> <TAB> <TAB> vocab[token] = int(index) <TAB> <TAB> return vocab",false,if len ( items ) > 2 :,if len ( items ) != 2 :,0.55,0.0
"def slice_fill(self, slice_): <TAB> ""Fills the slice with zeroes for the dimensions that have single elements and squeeze_dims true"" <TAB> if isinstance(self.indexes, int): <TAB> <TAB> new_slice_ = [0] <TAB> <TAB> offset = 0 <TAB> else: <TAB> <TAB> new_slice_ = [slice_[0]] <TAB> <TAB> offset = 1 <TAB> for i in range(1, len(self.nums)): <TAB> <TAB> if self.squeeze_dims[i]: <TAB> <TAB> <TAB> new_slice_.append(0) <TAB> <TAB> elif offset < len(slice_): <TAB> <TAB> <TAB> new_slice_.append(slice_[offset]) <TAB> <TAB> <TAB> offset += 1 <TAB> new_slice_ += slice_[offset:] <TAB> return new_slice_",true,if self . squeeze_dims [ i ] :,if self . squeeze_dims [ i ] :,0.75,0.0
"def check_update_function(url, folder, update_setter, version_setter, auto): <TAB> remote_version = urllib.urlopen(url).read() <TAB> if remote_version.isdigit(): <TAB> <TAB> local_version = get_local_timestamp(folder) <TAB> <TAB> if remote_version > local_version: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> update_setter.set_value(True) <TAB> <TAB> <TAB> version_setter.set_value(remote_version) <TAB> <TAB> <TAB> return True <TAB> <TAB> else: <TAB> <TAB> <TAB> return False <TAB> else: <TAB> <TAB> return False",true,if auto :,if auto :,0.53,0.0
"def iter_content(self, chunk_size_bytes): <TAB> while True: <TAB> <TAB> try: <TAB> <TAB> <TAB> data = self._fp.read(chunk_size_bytes) <TAB> <TAB> except IOError as e: <TAB> <TAB> <TAB> raise Fetcher.PermanentError( <TAB> <TAB> <TAB> <TAB> ""Problem reading chunk from {}: {}"".format(self._fp.name, e) <TAB> <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> yield data",true,if not data :,if not data :,0.75,0.0
"def gvariant_args(args: List[Any]) -> str: <TAB> """"""Convert args into gvariant."""""" <TAB> gvariant = """" <TAB> for arg in args: <TAB> <TAB> if isinstance(arg, bool): <TAB> <TAB> <TAB> gvariant += "" {}"".format(str(arg).lower()) <TAB> <TAB> elif isinstance(arg, (int, float)): <TAB> <TAB> <TAB> gvariant += f"" {arg}"" <TAB> <TAB> elif isinstance(arg, str): <TAB> <TAB> <TAB> gvariant += f' ""{arg}""' <TAB> <TAB> else: <TAB> <TAB> <TAB> gvariant += f"" {arg!s}"" <TAB> return gvariant.lstrip()",true,"elif isinstance ( arg , str ) :","elif isinstance ( arg , str ) :",0.75,0.0
"def _element_keywords(cls, backend, elements=None): <TAB> ""Returns a dictionary of element names to allowed keywords"" <TAB> if backend not in Store.loaded_backends(): <TAB> <TAB> return {} <TAB> mapping = {} <TAB> backend_options = Store.options(backend) <TAB> elements = elements if elements is not None else backend_options.keys() <TAB> for element in elements: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> element = element if isinstance(element, tuple) else (element,) <TAB> <TAB> element_keywords = [] <TAB> <TAB> options = backend_options[""."".join(element)] <TAB> <TAB> for group in Options._option_groups: <TAB> <TAB> <TAB> element_keywords.extend(options[group].allowed_keywords) <TAB> <TAB> mapping[element[0]] = element_keywords <TAB> return mapping",false,"if ""."" in element :",if element is None :,0.04,0.0
"def setup_parameter_node(self, param_node): <TAB> if param_node.bl_idname == ""SvNumberNode"": <TAB> <TAB> if self.use_prop or self.get_prop_name(): <TAB> <TAB> <TAB> value = self.sv_get()[0][0] <TAB> <TAB> <TAB> print(""V"", value) <TAB> <TAB> <TAB> if isinstance(value, int): <TAB> <TAB> <TAB> <TAB> param_node.selected_mode = ""int"" <TAB> <TAB> <TAB> <TAB> param_node.int_ = value <TAB> <TAB> <TAB> elif isinstance(value, float): <TAB> <TAB> <TAB> <TAB> param_node.selected_mode = ""float"" <TAB> <TAB> <TAB> <TAB> param_node.float_ = value",false,"if isinstance ( value , int ) :",if self . use_prop or self . get_prop_name ( ) :,0.03,0.0
"def _get_oshape(indices_shape, depth, axis): <TAB> oshape = [] <TAB> true_axis = len(indices_shape) if axis == -1 else axis <TAB> ndim = len(indices_shape) + 1 <TAB> indices_index = 0 <TAB> for i in range(0, ndim): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> oshape.append(depth) <TAB> <TAB> else: <TAB> <TAB> <TAB> oshape.append(indices_shape[indices_index]) <TAB> <TAB> <TAB> indices_index += 1 <TAB> return oshape",false,if i == true_axis :,if indices_index == 0 and true_axis :,0.06,0.0
"def check(self, value): <TAB> value = String.check(self, value) <TAB> if isinstance(value, str): <TAB> <TAB> value = value.upper() <TAB> <TAB> for prefix in (self.prefix, self.prefix.split(""_"", 1)[1]): <TAB> <TAB> <TAB> # e.g. PANGO_WEIGHT_BOLD --> BOLD but also WEIGHT_BOLD --> BOLD <TAB> <TAB> <TAB> if value.startswith(prefix): <TAB> <TAB> <TAB> <TAB> value = value[len(prefix) :] <TAB> <TAB> <TAB> value = value.lstrip(""_"") <TAB> <TAB> if hasattr(self.group, value): <TAB> <TAB> <TAB> return getattr(self.group, value) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""No such constant: %s_%s"" % (self.prefix, value)) <TAB> else: <TAB> <TAB> return value",true,if value . startswith ( prefix ) :,if value . startswith ( prefix ) :,0.75,0.0
"def shuffle_unison_inplace(list_of_lists, random_state=None): <TAB> if list_of_lists: <TAB> <TAB> assert all(len(l) == len(list_of_lists[0]) for l in list_of_lists) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> random_state.permutation(len(list_of_lists[0])) <TAB> <TAB> else: <TAB> <TAB> <TAB> p = np.random.permutation(len(list_of_lists[0])) <TAB> <TAB> return [l[p] for l in list_of_lists] <TAB> return None",false,if random_state is not None :,if random_state :,0.05,0.0
"def _load_module(self): <TAB> spec = self.default_module_spec <TAB> module_identifier = self.module_identifier <TAB> if module_identifier: <TAB> <TAB> impls = self.get_module_implementation_map() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ModuleNotFound( <TAB> <TAB> <TAB> <TAB> ""Invalid module identifier %r in %s"" <TAB> <TAB> <TAB> <TAB> % (module_identifier, force_ascii(repr(self))) <TAB> <TAB> <TAB> ) <TAB> <TAB> spec = impls[module_identifier] <TAB> cls = load( <TAB> <TAB> spec, context_explanation=""Loading module for %s"" % force_ascii(repr(self)) <TAB> ) <TAB> options = getattr(self, self.module_options_field, None) or {} <TAB> return cls(self, options)",true,if module_identifier not in impls :,if module_identifier not in impls :,0.75,0.0
"def get_data(self, state=None, request=None): <TAB> if self.load_in_memory: <TAB> <TAB> data, shapes = self._in_memory_get_data(state, request) <TAB> else: <TAB> <TAB> data, shapes = self._out_of_memory_get_data(state, request) <TAB> for i in range(len(data)): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if isinstance(request, numbers.Integral): <TAB> <TAB> <TAB> <TAB> data[i] = data[i].reshape(shapes[i]) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> for j in range(len(data[i])): <TAB> <TAB> <TAB> <TAB> <TAB> data[i][j] = data[i][j].reshape(shapes[i][j]) <TAB> return tuple(data)",false,if shapes [ i ] is not None :,if i in shapes :,0.02,0.0
"def resolve_credential_keys(m_keys, keys): <TAB> res = [] <TAB> for k in m_keys: <TAB> <TAB> if k[""c7n:match-type""] == ""credential"": <TAB> <TAB> <TAB> c_date = parse_date(k[""last_rotated""]) <TAB> <TAB> <TAB> for ak in keys: <TAB> <TAB> <TAB> <TAB> if c_date == ak[""CreateDate""]: <TAB> <TAB> <TAB> <TAB> <TAB> ak = dict(ak) <TAB> <TAB> <TAB> <TAB> <TAB> ak[""c7n:match-type""] = ""access"" <TAB> <TAB> <TAB> <TAB> <TAB> if ak not in res: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> res.append(ak) <TAB> <TAB> elif k not in res: <TAB> <TAB> <TAB> res.append(k) <TAB> return res",false,"if c_date == ak [ ""CreateDate"" ] :","if k [ ""c7n:match-type"" ] == ""credential"" :",0.08,0.0
"def _is_legacy_mode(self, node): <TAB> """"""Checks if the ``ast.Call`` node's keywords signal using legacy mode."""""" <TAB> script_mode = False <TAB> py_version = ""py2"" <TAB> for kw in node.keywords: <TAB> <TAB> if kw.arg == ""script_mode"": <TAB> <TAB> <TAB> script_mode = ( <TAB> <TAB> <TAB> <TAB> bool(kw.value.value) if isinstance(kw.value, ast.NameConstant) else True <TAB> <TAB> <TAB> ) <TAB> <TAB> if kw.arg == ""py_version"": <TAB> <TAB> <TAB> py_version = kw.value.s if isinstance(kw.value, ast.Str) else ""py3"" <TAB> return not (py_version.startswith(""py3"") or script_mode)",true,"if kw . arg == ""script_mode"" :","if kw . arg == ""script_mode"" :",0.75,0.0
"def get_upstream_statuses_events(self, upstream: Set) -> Dict[str, V1Statuses]: <TAB> statuses_by_refs = {u: [] for u in upstream} <TAB> events = self.events or []  # type: List[V1EventTrigger] <TAB> for e in events: <TAB> <TAB> entity_ref = contexts_refs.get_entity_ref(e.ref) <TAB> <TAB> if not entity_ref: <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> for kind in e.kinds: <TAB> <TAB> <TAB> status = V1EventKind.events_statuses_mapping.get(kind) <TAB> <TAB> <TAB> if status: <TAB> <TAB> <TAB> <TAB> statuses_by_refs[entity_ref].append(status) <TAB> return statuses_by_refs",false,if entity_ref not in statuses_by_refs :,if entity_ref in statuses_by_refs :,0.23,0.0
"def items(self): <TAB> dict = {} <TAB> for userdir in self.XDG_DIRS.keys(): <TAB> <TAB> prefix = self.get(userdir).strip('""').split(""/"")[0] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> path = ( <TAB> <TAB> <TAB> <TAB> os.getenv(""HOME"") <TAB> <TAB> <TAB> <TAB> + ""/"" <TAB> <TAB> <TAB> <TAB> + ""/"".join(self.get(userdir).strip('""').split(""/"")[1:]) <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> path = self.get(userdir).strip('""') <TAB> <TAB> dict[userdir] = path <TAB> return dict.items()",true,if prefix :,if prefix :,0.53,0.0
"def clean_objects(string, common_attributes): <TAB> """"""Return object and attribute lists"""""" <TAB> string = clean_string(string) <TAB> words = string.split() <TAB> if len(words) > 1: <TAB> <TAB> prefix_words_are_adj = True <TAB> <TAB> for att in words[:-1]: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> prefix_words_are_adj = False <TAB> <TAB> if prefix_words_are_adj: <TAB> <TAB> <TAB> return words[-1:], words[:-1] <TAB> <TAB> else: <TAB> <TAB> <TAB> return [string], [] <TAB> else: <TAB> <TAB> return [string], []",false,if att not in common_attributes :,if att in common_attributes :,0.23,0.0
"def extract_custom(extractor, *args, **kw): <TAB> for match in extractor(*args, **kw): <TAB> <TAB> msg = match[2] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> unused = ( <TAB> <TAB> <TAB> <TAB> ""<unused singular (hash=%s)>"" % md5(msg[1].encode(""utf8"")).hexdigest() <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> msg = (unused, msg[1], msg[2]) <TAB> <TAB> <TAB> match = (match[0], match[1], msg, match[3]) <TAB> <TAB> yield match",false,"if isinstance ( msg , tuple ) and msg [ 0 ] == """" :",if len ( msg ) > 1 :,0.02,0.0
"def test_convex_decomposition(self): <TAB> mesh = g.get_mesh(""quadknot.obj"") <TAB> engines = [(""vhacd"", g.trimesh.interfaces.vhacd.exists)] <TAB> for engine, exists in engines: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> g.log.warning(""skipping convex decomposition engine %s"", engine) <TAB> <TAB> <TAB> continue <TAB> <TAB> g.log.info(""Testing convex decomposition with engine %s"", engine) <TAB> <TAB> meshes = mesh.convex_decomposition(engine=engine) <TAB> <TAB> self.assertTrue(len(meshes) > 1) <TAB> <TAB> for m in meshes: <TAB> <TAB> <TAB> self.assertTrue(m.is_watertight) <TAB> <TAB> g.log.info(""convex decomposition succeeded with %s"", engine)",true,if not exists :,if not exists :,0.75,0.0
"def _to_string_infix(self, ostream, idx, verbose): <TAB> if verbose: <TAB> <TAB> ostream.write("" , "") <TAB> else: <TAB> <TAB> hasConst = not ( <TAB> <TAB> <TAB> self._const.__class__ in native_numeric_types and self._const == 0 <TAB> <TAB> ) <TAB> <TAB> if hasConst: <TAB> <TAB> <TAB> idx -= 1 <TAB> <TAB> _l = self._coef[id(self._args[idx])] <TAB> <TAB> _lt = _l.__class__ <TAB> <TAB> if _lt is _NegationExpression or (_lt in native_numeric_types and _l < 0): <TAB> <TAB> <TAB> ostream.write("" - "") <TAB> <TAB> else: <TAB> <TAB> <TAB> ostream.write("" + "")",true,if _lt is _NegationExpression or ( _lt in native_numeric_types and _l < 0 ) :,if _lt is _NegationExpression or ( _lt in native_numeric_types and _l < 0 ) :,0.75,0.0
"def get_other(self, data, items): <TAB> is_tuple = False <TAB> if type(data) == tuple: <TAB> <TAB> data = list(data) <TAB> <TAB> is_tuple = True <TAB> if type(data) == list: <TAB> <TAB> m_items = items.copy() <TAB> <TAB> for idx, item in enumerate(items): <TAB> <TAB> <TAB> if item < 0: <TAB> <TAB> <TAB> <TAB> m_items[idx] = len(data) - abs(item) <TAB> <TAB> for i in sorted(set(m_items), reverse=True): <TAB> <TAB> <TAB> if i < len(data) and i > -1: <TAB> <TAB> <TAB> <TAB> del data[i] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return tuple(data) <TAB> <TAB> else: <TAB> <TAB> <TAB> return data <TAB> else: <TAB> <TAB> return None",true,if is_tuple :,if is_tuple :,0.53,0.0
"def process_error(self, data): <TAB> if data.get(""error""): <TAB> <TAB> if ""denied"" in data[""error""] or ""cancelled"" in data[""error""]: <TAB> <TAB> <TAB> raise AuthCanceled(self, data.get(""error_description"", """")) <TAB> <TAB> raise AuthFailed(self, data.get(""error_description"") or data[""error""]) <TAB> elif ""denied"" in data: <TAB> <TAB> raise AuthCanceled(self, data[""denied""])",true,"if ""denied"" in data [ ""error"" ] or ""cancelled"" in data [ ""error"" ] :","if ""denied"" in data [ ""error"" ] or ""cancelled"" in data [ ""error"" ] :",1.0,0.0
"def tamper(payload, **kwargs): <TAB> junk_chars = ""!#$%&()*~+-_.,:;?@[/|\]^`"" <TAB> retval = """" <TAB> for i, char in enumerate(payload, start=1): <TAB> <TAB> amount = random.randint(10, 15) <TAB> <TAB> if char == "">"": <TAB> <TAB> <TAB> retval += "">"" <TAB> <TAB> <TAB> for _ in range(amount): <TAB> <TAB> <TAB> <TAB> retval += random.choice(junk_chars) <TAB> <TAB> elif char == ""<"": <TAB> <TAB> <TAB> retval += ""<"" <TAB> <TAB> <TAB> for _ in range(amount): <TAB> <TAB> <TAB> <TAB> retval += random.choice(junk_chars) <TAB> <TAB> elif char == "" "": <TAB> <TAB> <TAB> for _ in range(amount): <TAB> <TAB> <TAB> <TAB> retval += random.choice(junk_chars) <TAB> <TAB> else: <TAB> <TAB> <TAB> retval += char <TAB> return retval",false,"elif char == "" "" :","elif char == ""<"" :",0.62,0.0
"def retry_http_digest_auth(self, req, auth): <TAB> token, challenge = auth.split("" "", 1) <TAB> chal = parse_keqv_list(parse_http_list(challenge)) <TAB> auth = self.get_authorization(req, chal) <TAB> if auth: <TAB> <TAB> auth_val = ""Digest %s"" % auth <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> req.add_unredirected_header(self.auth_header, auth_val) <TAB> <TAB> resp = self.parent.open(req) <TAB> <TAB> return resp",true,"if req . headers . get ( self . auth_header , None ) == auth_val :","if req . headers . get ( self . auth_header , None ) == auth_val :",0.75,0.0
"def close(self): <TAB> self.selector.close() <TAB> if self.sock: <TAB> <TAB> sockname = None <TAB> <TAB> try: <TAB> <TAB> <TAB> sockname = self.sock.getsockname() <TAB> <TAB> except (socket.error, OSError): <TAB> <TAB> <TAB> pass <TAB> <TAB> self.sock.close() <TAB> <TAB> if type(sockname) is str: <TAB> <TAB> <TAB> # it was a Unix domain socket, remove it from the filesystem <TAB> <TAB> <TAB> if os.path.exists(sockname): <TAB> <TAB> <TAB> <TAB> os.remove(sockname) <TAB> self.sock = None",true,if os . path . exists ( sockname ) :,if os . path . exists ( sockname ) :,0.75,0.0
"def to_nurbs(self, curves): <TAB> result = [] <TAB> for i, c in enumerate(curves): <TAB> <TAB> nurbs = SvNurbsCurve.to_nurbs(c) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise Exception(f""Curve #{i} - {c} - can not be converted to NURBS!"") <TAB> <TAB> result.append(nurbs) <TAB> return result",true,if nurbs is None :,if nurbs is None :,0.75,0.0
"def handle_1_roomid_raffle(self, i): <TAB> if i[1] in [""handle_1_room_TV"", ""handle_1_room_captain""]: <TAB> <TAB> if await self.notify(""check_if_normal_room"", i[0], -1): <TAB> <TAB> <TAB> await self.notify(""post_watching_history"", i[0]) <TAB> <TAB> <TAB> await self.notify(i[1], i[0], i[2]) <TAB> else: <TAB> <TAB> print(""hhjjkskddrsfvsfdfvdfvvfdvdvdfdfffdfsvh"", i)",true,"if await self . notify ( ""check_if_normal_room"" , i [ 0 ] , - 1 ) :","if await self . notify ( ""check_if_normal_room"" , i [ 0 ] , - 1 ) :",0.75,0.0
"def init_ps_var_partition(self): <TAB> ps_vars = {} <TAB> for v in self._non_embed_vars.values(): <TAB> <TAB> if v.name not in self._var_to_ps: <TAB> <TAB> <TAB> self._var_to_ps[v.name] = string_to_id(v.name, self._ps_num) <TAB> <TAB> ps_id = self._var_to_ps[v.name] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ps_vars[ps_id] = [v] <TAB> <TAB> else: <TAB> <TAB> <TAB> ps_vars[ps_id].append(v) <TAB> self._ps_vars = ps_vars",true,if ps_id not in ps_vars :,if ps_id not in ps_vars :,0.75,0.0
"def get_files(d): <TAB> f = [] <TAB> for root, dirs, files in os.walk(d): <TAB> <TAB> for name in files: <TAB> <TAB> <TAB> if ""meta-environment"" in root or ""cross-canadian"" in root: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if ""qemux86copy-"" in root or ""qemux86-"" in root: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> f.append(os.path.join(root, name)) <TAB> return f",false,"if ""do_build"" not in name and ""do_populate_sdk"" not in name :",if name not in f :,0.21,0.0
"def setSelectedLabelState(self, p):  # selected, disabled <TAB> c = self.c <TAB> # g.trace(p,c.edit_widget(p)) <TAB> if p and c.edit_widget(p): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> g.trace(self.trace_n, c.edit_widget(p), p) <TAB> <TAB> <TAB> # g.trace(g.callers(6)) <TAB> <TAB> <TAB> self.trace_n += 1 <TAB> <TAB> self.setDisabledHeadlineColors(p)",false,if 0 :,if self . trace_n < self . trace_max_n :,0.04,0.0
"def filter_tasks(self, task_types=None, task_states=None, task_text=None): <TAB> tasks = self.api.tasks(self.id).get(""tasks"", {}) <TAB> if tasks and tasks.get(""task""): <TAB> <TAB> return [ <TAB> <TAB> <TAB> Task(self, task) <TAB> <TAB> <TAB> for task in tasks.get(""task"", []) <TAB> <TAB> <TAB> if (not task_types or task[""type""].lower() in task_types) <TAB> <TAB> <TAB> and (not task_states or task[""state""].lower() in task_states) <TAB> <TAB> <TAB> and (not task_text or task_text.lower() in str(task).lower()) <TAB> <TAB> ] <TAB> else: <TAB> <TAB> return []",true,"if ( not task_types or task [ ""type"" ] . lower ( ) in task_types )","if ( not task_types or task [ ""type"" ] . lower ( ) in task_types )",0.75,0.0
"def GenerateVector(self, hits, vector, level): <TAB> """"""Generate possible hit vectors which match the rules."""""" <TAB> for item in hits.get(level, []): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if item < vector[-1]: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if item > self.max_separation + vector[-1]: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> new_vector = vector + [item] <TAB> <TAB> if level + 1 == len(hits): <TAB> <TAB> <TAB> yield new_vector <TAB> <TAB> elif level + 1 < len(hits): <TAB> <TAB> <TAB> for result in self.GenerateVector(hits, new_vector, level + 1): <TAB> <TAB> <TAB> <TAB> yield result",true,if vector :,if vector :,0.53,0.0
def _transmit_from_storage(self) -> None: <TAB> for blob in self.storage.gets(): <TAB> <TAB> # give a few more seconds for blob lease operation <TAB> <TAB> # to reduce the chance of race (for perf consideration) <TAB> <TAB> if blob.lease(self._timeout + 5): <TAB> <TAB> <TAB> envelopes = [TelemetryItem(**x) for x in blob.get()] <TAB> <TAB> <TAB> result = self._transmit(list(envelopes)) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> blob.lease(1) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> blob.delete(),false,if result == ExportResult . FAILED_RETRYABLE :,if result :,0.04,0.0
"def load_dictionary(file): <TAB> oui = {} <TAB> with open(file, ""r"") as f: <TAB> <TAB> for line in f: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> data = line.split(""(hex)"") <TAB> <TAB> <TAB> <TAB> key = data[0].replace(""-"", "":"").lower().strip() <TAB> <TAB> <TAB> <TAB> company = data[1].strip() <TAB> <TAB> <TAB> <TAB> oui[key] = company <TAB> return oui",false,"if ""(hex)"" in line :","if ""hex"" in line :",0.39,0.0
"def _yield_minibatches_idx(self, rgen, n_batches, data_ary, shuffle=True): <TAB> indices = np.arange(data_ary.shape[0]) <TAB> if shuffle: <TAB> <TAB> indices = rgen.permutation(indices) <TAB> if n_batches > 1: <TAB> <TAB> remainder = data_ary.shape[0] % n_batches <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> minis = np.array_split(indices[:-remainder], n_batches) <TAB> <TAB> <TAB> minis[-1] = np.concatenate((minis[-1], indices[-remainder:]), axis=0) <TAB> <TAB> else: <TAB> <TAB> <TAB> minis = np.array_split(indices, n_batches) <TAB> else: <TAB> <TAB> minis = (indices,) <TAB> for idx_batch in minis: <TAB> <TAB> yield idx_batch",true,if remainder :,if remainder :,0.53,0.0
"def canonical_custom_headers(self, headers): <TAB> hoi = [] <TAB> custom_headers = {} <TAB> for key in headers: <TAB> <TAB> lk = key.lower() <TAB> <TAB> if headers[key] is not None: <TAB> <TAB> <TAB> if lk.startswith(""x-amz-""): <TAB> <TAB> <TAB> <TAB> custom_headers[lk] = "","".join(v.strip() for v in headers.get_all(key)) <TAB> sorted_header_keys = sorted(custom_headers.keys()) <TAB> for key in sorted_header_keys: <TAB> <TAB> hoi.append(""%s:%s"" % (key, custom_headers[key])) <TAB> return ""\n"".join(hoi)",true,"if lk . startswith ( ""x-amz-"" ) :","if lk . startswith ( ""x-amz-"" ) :",0.75,0.0
"def validate(self, data): <TAB> if not data.get(""reason""): <TAB> <TAB> # If reason is not provided, message is required and can not be <TAB> <TAB> # null or blank. <TAB> <TAB> message = data.get(""message"") <TAB> <TAB> if not message: <TAB> <TAB> <TAB> if ""message"" not in data: <TAB> <TAB> <TAB> <TAB> msg = serializers.Field.default_error_messages[""required""] <TAB> <TAB> <TAB> elif message is None: <TAB> <TAB> <TAB> <TAB> msg = serializers.Field.default_error_messages[""null""] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> msg = serializers.CharField.default_error_messages[""blank""] <TAB> <TAB> <TAB> raise serializers.ValidationError({""message"": [msg]}) <TAB> return data",true,elif message is None :,elif message is None :,0.75,0.0
def tearDown(self): <TAB> try: <TAB> <TAB> os.chdir(self.cwd) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> os.remove(self.pythonexe) <TAB> <TAB> test_support.rmtree(self.parent_dir) <TAB> finally: <TAB> <TAB> BaseTestCase.tearDown(self),false,if self . pythonexe != sys . executable :,if self . pythonexe :,0.23,0.0
"def update(self, value, label): <TAB> if self._disabled: <TAB> <TAB> return <TAB> try: <TAB> <TAB> self._progress.value = value <TAB> <TAB> self._label.value = label <TAB> <TAB> if not self._displayed: <TAB> <TAB> <TAB> self._displayed = True <TAB> <TAB> <TAB> display_widget(self._widget) <TAB> except Exception as e: <TAB> <TAB> self._disabled = True <TAB> <TAB> logger.exception(e) <TAB> <TAB> wandb.termwarn(""Unable to render progress bar, see the user log for details"")",true,if not self . _displayed :,if not self . _displayed :,0.75,0.0
"def GetBinaryOperationBinder(self, op): <TAB> with self._lock: <TAB> <TAB> if self._binaryOperationBinders.ContainsKey(op): <TAB> <TAB> <TAB> return self._binaryOperationBinders[op] <TAB> <TAB> b = runtime.SymplBinaryOperationBinder(op) <TAB> <TAB> self._binaryOperationBinders[op] = b <TAB> return b",true,if self . _binaryOperationBinders . ContainsKey ( op ) :,if self . _binaryOperationBinders . ContainsKey ( op ) :,0.75,0.0
"def apply(self, l, b, evaluation): <TAB> ""FromDigits[l_, b_]"" <TAB> if l.get_head_name() == ""System`List"": <TAB> <TAB> value = Integer(0) <TAB> <TAB> for leaf in l.leaves: <TAB> <TAB> <TAB> value = Expression(""Plus"", Expression(""Times"", value, b), leaf) <TAB> <TAB> return value <TAB> elif isinstance(l, String): <TAB> <TAB> value = FromDigits._parse_string(l.get_string_value(), b) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> evaluation.message(""FromDigits"", ""nlst"") <TAB> <TAB> else: <TAB> <TAB> <TAB> return value <TAB> else: <TAB> <TAB> evaluation.message(""FromDigits"", ""nlst"")",true,if value is None :,if value is None :,0.75,0.0
"def hsconn_sender(self): <TAB> while not self.stop_event.is_set(): <TAB> <TAB> try: <TAB> <TAB> <TAB> # Block, but timeout, so that we can exit the loop gracefully <TAB> <TAB> <TAB> request = self.send_queue.get(True, 6.0) <TAB> <TAB> <TAB> if self.socket is not None: <TAB> <TAB> <TAB> <TAB> # Socket got closed and set to None in another thread... <TAB> <TAB> <TAB> <TAB> self.socket.sendall(request) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.send_queue.task_done() <TAB> <TAB> except queue.Empty: <TAB> <TAB> <TAB> pass <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> self.stop_event.set()",false,if self . send_queue is not None :,if request is None :,0.08,0.0
"def check_expected(result, expected, contains=False): <TAB> if sys.version_info[0] >= 3: <TAB> <TAB> if isinstance(result, str): <TAB> <TAB> <TAB> result = result.encode(""ascii"") <TAB> <TAB> if isinstance(expected, str): <TAB> <TAB> <TAB> expected = expected.encode(""ascii"") <TAB> resultlines = result.splitlines() <TAB> expectedlines = expected.splitlines() <TAB> if len(resultlines) != len(expectedlines): <TAB> <TAB> return False <TAB> for rline, eline in zip(resultlines, expectedlines): <TAB> <TAB> if contains: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> else: <TAB> <TAB> <TAB> if not rline.endswith(eline): <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",false,if eline not in rline :,if rline != eline :,0.03,0.0
"def init_weights(self): <TAB> """"""Initialize model weights."""""" <TAB> for _, m in self.multi_deconv_layers.named_modules(): <TAB> <TAB> if isinstance(m, nn.ConvTranspose2d): <TAB> <TAB> <TAB> normal_init(m, std=0.001) <TAB> <TAB> elif isinstance(m, nn.BatchNorm2d): <TAB> <TAB> <TAB> constant_init(m, 1) <TAB> for m in self.multi_final_layers.modules(): <TAB> <TAB> if isinstance(m, nn.Conv2d): <TAB> <TAB> <TAB> normal_init(m, std=0.001, bias=0)",true,"if isinstance ( m , nn . ConvTranspose2d ) :","if isinstance ( m , nn . ConvTranspose2d ) :",0.75,0.0
"def filter_rel_attrs(field_name, **rel_attrs): <TAB> clean_dict = {} <TAB> for k, v in rel_attrs.items(): <TAB> <TAB> if k.startswith(field_name + ""__""): <TAB> <TAB> <TAB> splitted_key = k.split(""__"") <TAB> <TAB> <TAB> key = ""__"".join(splitted_key[1:]) <TAB> <TAB> <TAB> clean_dict[key] = v <TAB> <TAB> else: <TAB> <TAB> <TAB> clean_dict[k] = v <TAB> return clean_dict",true,"if k . startswith ( field_name + ""__"" ) :","if k . startswith ( field_name + ""__"" ) :",0.75,0.0
"def cancel(self): <TAB> with self._condition: <TAB> <TAB> if not self._cancelled and not self._final and self._previous_context_id: <TAB> <TAB> <TAB> self._squash( <TAB> <TAB> <TAB> <TAB> state_root=self._previous_state_hash, <TAB> <TAB> <TAB> <TAB> context_ids=[self._previous_context_id], <TAB> <TAB> <TAB> <TAB> persist=False, <TAB> <TAB> <TAB> <TAB> clean_up=True, <TAB> <TAB> <TAB> ) <TAB> <TAB> self._cancelled = True <TAB> <TAB> self._condition.notify_all()",true,if not self . _cancelled and not self . _final and self . _previous_context_id :,if not self . _cancelled and not self . _final and self . _previous_context_id :,1.0,0.0
"def _get_level(levels, level_ref): <TAB> if level_ref in levels: <TAB> <TAB> return levels.index(level_ref) <TAB> if isinstance(level_ref, six.integer_types): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> level_ref += len(levels) <TAB> <TAB> if not (0 <= level_ref < len(levels)): <TAB> <TAB> <TAB> raise PatsyError(""specified level %r is out of range"" % (level_ref,)) <TAB> <TAB> return level_ref <TAB> raise PatsyError(""specified level %r not found"" % (level_ref,))",true,if level_ref < 0 :,if level_ref < 0 :,0.75,0.0
"def parse_node(self, node, alias_map=None, conv=None): <TAB> sql, params, unknown = self._parse(node, alias_map, conv) <TAB> if unknown and conv and params: <TAB> <TAB> params = [conv.db_value(i) for i in params] <TAB> if isinstance(node, Node): <TAB> <TAB> if node._negated: <TAB> <TAB> <TAB> sql = ""NOT %s"" % sql <TAB> <TAB> if node._alias: <TAB> <TAB> <TAB> sql = "" "".join((sql, ""AS"", node._alias)) <TAB> <TAB> if node._ordering: <TAB> <TAB> <TAB> sql = "" "".join((sql, node._ordering)) <TAB> return sql, params",false,if node . _alias :,if node . _negated :,0.39,0.0
"def parse_object_id(_, values): <TAB> if values: <TAB> <TAB> for key in values: <TAB> <TAB> <TAB> if key.endswith(""_id""): <TAB> <TAB> <TAB> <TAB> val = values[key] <TAB> <TAB> <TAB> <TAB> if len(val) > 10: <TAB> <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> values[key] = utils.ObjectIdSilent(val) <TAB> <TAB> <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> values[key] = None",true,"if key . endswith ( ""_id"" ) :","if key . endswith ( ""_id"" ) :",0.75,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB> if tt == 10: <TAB> <TAB> <TAB> self.set_app_id(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 16: <TAB> <TAB> <TAB> self.set_max_rows(d.getVarInt32()) <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 0 :,if tt == 0 :,0.75,0.0
"def has_invalid_cce(yaml_file, product_yaml=None): <TAB> rule = yaml.open_and_macro_expand(yaml_file, product_yaml) <TAB> if ""identifiers"" in rule and rule[""identifiers""] is not None: <TAB> <TAB> for i_type, i_value in rule[""identifiers""].items(): <TAB> <TAB> <TAB> if i_type[0:3] == ""cce"": <TAB> <TAB> <TAB> <TAB> if not checks.is_cce_value_valid(""CCE-"" + str(i_value)): <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",true,"if i_type [ 0 : 3 ] == ""cce"" :","if i_type [ 0 : 3 ] == ""cce"" :",0.75,0.0
"def _generate_table(self, fromdesc, todesc, diffs): <TAB> if fromdesc or todesc: <TAB> <TAB> yield ( <TAB> <TAB> <TAB> simple_colorize(fromdesc, ""description""), <TAB> <TAB> <TAB> simple_colorize(todesc, ""description""), <TAB> <TAB> ) <TAB> for i, line in enumerate(diffs): <TAB> <TAB> if line is None: <TAB> <TAB> <TAB> # mdiff yields None on separator lines; skip the bogus ones <TAB> <TAB> <TAB> # generated for the first line <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> <TAB> simple_colorize(""---"", ""separator""), <TAB> <TAB> <TAB> <TAB> <TAB> simple_colorize(""---"", ""separator""), <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> yield line",false,if i > 0 :,if i == 0 :,0.33,0.0
"def _getPatternTemplate(pattern, key=None): <TAB> if key is None: <TAB> <TAB> key = pattern <TAB> <TAB> if ""%"" not in pattern: <TAB> <TAB> <TAB> key = pattern.upper() <TAB> template = DD_patternCache.get(key) <TAB> if not template: <TAB> <TAB> if key in (""EPOCH"", ""{^LN-BEG}EPOCH"", ""^EPOCH""): <TAB> <TAB> <TAB> template = DateEpoch(lineBeginOnly=(key != ""EPOCH"")) <TAB> <TAB> elif key in (""TAI64N"", ""{^LN-BEG}TAI64N"", ""^TAI64N""): <TAB> <TAB> <TAB> template = DateTai64n(wordBegin=(""start"" if key != ""TAI64N"" else False)) <TAB> <TAB> else: <TAB> <TAB> <TAB> template = DatePatternRegex(pattern) <TAB> DD_patternCache.set(key, template) <TAB> return template",false,"elif key in ( ""TAI64N"" , ""{^LN-BEG}TAI64N"" , ""^TAI64N"" ) :","if key in ( ""EPOCH"" , ""{^LN-BEG}EPOCH"" , ""^EPOCH"" ) :",0.06,0.0
"def ref_max_pooling_2d(x, kernel, stride, ignore_border, pad): <TAB> y = [] <TAB> for xx in x.reshape((-1,) + x.shape[-3:]): <TAB> <TAB> if xx.ndim == 2: <TAB> <TAB> <TAB> xx = xx[np.newaxis] <TAB> <TAB> y += [ <TAB> <TAB> <TAB> refs.pooling_2d(xx, ""max"", kernel, stride, pad, ignore_border)[np.newaxis] <TAB> <TAB> ] <TAB> y = np.vstack(y) <TAB> if x.ndim == 2: <TAB> <TAB> y = np.squeeze(y, 1) <TAB> return y.reshape(x.shape[:-3] + y.shape[1:])",true,if xx . ndim == 2 :,if xx . ndim == 2 :,0.75,0.0
"def show_topics(): <TAB> """"""prints all available miscellaneous help topics."""""" <TAB> print(_stash.text_color(""Miscellaneous Topics:"", ""yellow"")) <TAB> for pp in PAGEPATHS: <TAB> <TAB> if not os.path.isdir(pp): <TAB> <TAB> <TAB> continue <TAB> <TAB> content = os.listdir(pp) <TAB> <TAB> for pn in content: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> name = pn[: pn.index(""."")] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> name = pn <TAB> <TAB> <TAB> print(name)",true,"if ""."" in pn :","if ""."" in pn :",0.75,0.0
"def justify_toggle_auto(self, event=None): <TAB> c = self <TAB> if c.editCommands.autojustify == 0: <TAB> <TAB> c.editCommands.autojustify = abs(c.config.getInt(""autojustify"") or 0) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> g.es(""Autojustify on, @int autojustify == %s"" % c.editCommands.autojustify) <TAB> <TAB> else: <TAB> <TAB> <TAB> g.es(""Set @int autojustify in @settings"") <TAB> else: <TAB> <TAB> c.editCommands.autojustify = 0 <TAB> <TAB> g.es(""Autojustify off"")",true,if c . editCommands . autojustify :,if c . editCommands . autojustify :,0.75,0.0
"def render_token_list(self, tokens): <TAB> result = [] <TAB> vars = [] <TAB> for token in tokens: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result.append(token.contents.replace(""%"", ""%%"")) <TAB> <TAB> elif token.token_type == TOKEN_VAR: <TAB> <TAB> <TAB> result.append(""%%(%s)s"" % token.contents) <TAB> <TAB> <TAB> vars.append(token.contents) <TAB> return """".join(result), vars",false,if token . token_type == TOKEN_TEXT :,if token . token_type == TOKEN_CHAR :,0.57,0.0
"def get_target_dimensions(self): <TAB> width, height = self.engine.size <TAB> for operation in self.operations: <TAB> <TAB> if operation[""type""] == ""crop"": <TAB> <TAB> <TAB> width = operation[""right""] - operation[""left""] <TAB> <TAB> <TAB> height = operation[""bottom""] - operation[""top""] <TAB> <TAB> if operation[""type""] == ""resize"": <TAB> <TAB> <TAB> width = operation[""width""] <TAB> <TAB> <TAB> height = operation[""height""] <TAB> return (width, height)",false,"if operation [ ""type"" ] == ""resize"" :","if operation [ ""type"" ] == ""crop"" :",0.61,0.0
"def get_eval_matcher(self): <TAB> if isinstance(self.data[""match""], str): <TAB> <TAB> if self.data[""match""] == ""denied"": <TAB> <TAB> <TAB> values = [""explicitDeny"", ""implicitDeny""] <TAB> <TAB> else: <TAB> <TAB> <TAB> values = [""allowed""] <TAB> <TAB> vf = ValueFilter( <TAB> <TAB> <TAB> {""type"": ""value"", ""key"": ""EvalDecision"", ""value"": values, ""op"": ""in""} <TAB> <TAB> ) <TAB> else: <TAB> <TAB> vf = ValueFilter(self.data[""match""]) <TAB> vf.annotate = False <TAB> return vf",true,"if self . data [ ""match"" ] == ""denied"" :","if self . data [ ""match"" ] == ""denied"" :",0.75,0.0
"def test_training(self): <TAB> if not self.model_tester.is_training: <TAB> <TAB> return <TAB> config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common() <TAB> config.return_dict = True <TAB> for model_class in self.all_model_classes: <TAB> <TAB> if model_class in MODEL_MAPPING.values(): <TAB> <TAB> <TAB> continue <TAB> <TAB> model = model_class(config) <TAB> <TAB> model.to(torch_device) <TAB> <TAB> model.train() <TAB> <TAB> inputs = self._prepare_for_class(inputs_dict, model_class, return_labels=True) <TAB> <TAB> loss = model(**inputs).loss <TAB> <TAB> loss.backward()",true,if model_class in MODEL_MAPPING . values ( ) :,if model_class in MODEL_MAPPING . values ( ) :,0.75,0.0
"def prehook(self, emu, op, eip): <TAB> if op in self.badops: <TAB> <TAB> emu.stopEmu() <TAB> <TAB> raise v_exc.BadOpBytes(op.va) <TAB> if op.mnem in STOS: <TAB> <TAB> if self.arch == ""i386"": <TAB> <TAB> <TAB> reg = emu.getRegister(envi.archs.i386.REG_EDI) <TAB> <TAB> elif self.arch == ""amd64"": <TAB> <TAB> <TAB> reg = emu.getRegister(envi.archs.amd64.REG_RDI) <TAB> <TAB> if self.vw.isValidPointer(reg) and self.vw.getLocation(reg) is None: <TAB> <TAB> <TAB> self.vw.makePointer(reg, follow=True)",false,"if self . arch == ""i386"" :",if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None :,0.12,0.0
"def test_len(self): <TAB> eq = self.assertEqual <TAB> eq(base64mime.base64_len(""hello""), len(base64mime.encode(""hello"", eol=""""))) <TAB> for size in range(15): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> bsize = 0 <TAB> <TAB> elif size <= 3: <TAB> <TAB> <TAB> bsize = 4 <TAB> <TAB> elif size <= 6: <TAB> <TAB> <TAB> bsize = 8 <TAB> <TAB> elif size <= 9: <TAB> <TAB> <TAB> bsize = 12 <TAB> <TAB> elif size <= 12: <TAB> <TAB> <TAB> bsize = 16 <TAB> <TAB> else: <TAB> <TAB> <TAB> bsize = 20 <TAB> <TAB> eq(base64mime.base64_len(""x"" * size), bsize)",false,if size == 0 :,if size <= 1 :,0.31,0.0
"def __new__(cls, dependencies): <TAB> deps = check.list_param(dependencies, ""dependencies"", of_type=DependencyDefinition) <TAB> seen = {} <TAB> for dep in deps: <TAB> <TAB> key = dep.solid + "":"" + dep.output <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise DagsterInvalidDefinitionError( <TAB> <TAB> <TAB> <TAB> 'Duplicate dependencies on solid ""{dep.solid}"" output ""{dep.output}"" ' <TAB> <TAB> <TAB> <TAB> ""used in the same MultiDependencyDefinition."".format(dep=dep) <TAB> <TAB> <TAB> ) <TAB> <TAB> seen[key] = True <TAB> return super(MultiDependencyDefinition, cls).__new__(cls, deps)",true,if key in seen :,if key in seen :,0.75,0.0
"def get_explanation(self, spec): <TAB> """"""Expand an explanation."""""" <TAB> if spec: <TAB> <TAB> try: <TAB> <TAB> <TAB> a = self.dns_txt(spec) <TAB> <TAB> <TAB> if len(a) == 1: <TAB> <TAB> <TAB> <TAB> return str(self.expand(to_ascii(a[0]), stripdot=False)) <TAB> <TAB> except PermError: <TAB> <TAB> <TAB> # RFC4408 6.2/4 syntax errors cause exp= to be ignored <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise  # but report in harsh mode for record checking tools <TAB> <TAB> <TAB> pass <TAB> elif self.strict > 1: <TAB> <TAB> raise PermError(""Empty domain-spec on exp="") <TAB> # RFC4408 6.2/4 empty domain spec is ignored <TAB> # (unless you give precedence to the grammar). <TAB> return None",false,if self . strict > 1 :,if self . strict < 1 :,0.5,0.0
"def build(self): <TAB> if self.args.get(""sle_id""): <TAB> <TAB> self.process_sle_against_current_voucher() <TAB> else: <TAB> <TAB> entries_to_fix = self.get_future_entries_to_fix() <TAB> <TAB> i = 0 <TAB> <TAB> while i < len(entries_to_fix): <TAB> <TAB> <TAB> sle = entries_to_fix[i] <TAB> <TAB> <TAB> i += 1 <TAB> <TAB> <TAB> self.process_sle(sle) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.get_dependent_entries_to_fix(entries_to_fix, sle) <TAB> if self.exceptions: <TAB> <TAB> self.raise_exceptions() <TAB> self.update_bin()",false,if sle . dependant_sle_voucher_detail_no :,if self . depends_on_entries :,0.29,0.0
"def ValidateStopLatitude(self, problems): <TAB> if self.stop_lat is not None: <TAB> <TAB> value = self.stop_lat <TAB> <TAB> try: <TAB> <TAB> <TAB> if not isinstance(value, (float, int)): <TAB> <TAB> <TAB> <TAB> self.stop_lat = util.FloatStringToFloat(value, problems) <TAB> <TAB> except (ValueError, TypeError): <TAB> <TAB> <TAB> problems.InvalidValue(""stop_lat"", value) <TAB> <TAB> <TAB> del self.stop_lat <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> problems.InvalidValue(""stop_lat"", value)",false,if self . stop_lat > 90 or self . stop_lat < - 90 :,if self . stop_lat is None :,0.09,0.0
"def set(self, obj, **kwargs): <TAB> """"""Check for missing event functions and substitute these with"""""" <TAB> """"""the ignore method"""""" <TAB> ignore = getattr(self, ""ignore"") <TAB> for k, v in kwargs.iteritems(): <TAB> <TAB> setattr(self, k, getattr(obj, v)) <TAB> <TAB> if k in self.combinations: <TAB> <TAB> <TAB> for k1 in self.combinations[k]: <TAB> <TAB> <TAB> <TAB> if not hasattr(self, k1): <TAB> <TAB> <TAB> <TAB> <TAB> setattr(self, k1, ignore)",true,if k in self . combinations :,if k in self . combinations :,0.75,0.0
"def split(self, duration, include_remainder=True): <TAB> # Convert seconds to timedelta, if appropriate. <TAB> duration = _seconds_or_timedelta(duration) <TAB> if duration <= timedelta(seconds=0): <TAB> <TAB> raise ValueError(""cannot call split with a non-positive timedelta"") <TAB> start = self.start <TAB> while start < self.end: <TAB> <TAB> if start + duration <= self.end: <TAB> <TAB> <TAB> yield MayaInterval(start, start + duration) <TAB> <TAB> elif include_remainder: <TAB> <TAB> <TAB> yield MayaInterval(start, self.end) <TAB> <TAB> start += duration",true,elif include_remainder :,elif include_remainder :,0.51,0.0
"def get_first_field(layout, clz): <TAB> for layout_object in layout.fields: <TAB> <TAB> if issubclass(layout_object.__class__, clz): <TAB> <TAB> <TAB> return layout_object <TAB> <TAB> elif hasattr(layout_object, ""get_field_names""): <TAB> <TAB> <TAB> gf = get_first_field(layout_object, clz) <TAB> <TAB> <TAB> if gf: <TAB> <TAB> <TAB> <TAB> return gf",true,"elif hasattr ( layout_object , ""get_field_names"" ) :","elif hasattr ( layout_object , ""get_field_names"" ) :",0.75,0.0
"def _getPatternTemplate(pattern, key=None): <TAB> if key is None: <TAB> <TAB> key = pattern <TAB> <TAB> if ""%"" not in pattern: <TAB> <TAB> <TAB> key = pattern.upper() <TAB> template = DD_patternCache.get(key) <TAB> if not template: <TAB> <TAB> if key in (""EPOCH"", ""{^LN-BEG}EPOCH"", ""^EPOCH""): <TAB> <TAB> <TAB> template = DateEpoch(lineBeginOnly=(key != ""EPOCH"")) <TAB> <TAB> elif key in (""TAI64N"", ""{^LN-BEG}TAI64N"", ""^TAI64N""): <TAB> <TAB> <TAB> template = DateTai64n(wordBegin=(""start"" if key != ""TAI64N"" else False)) <TAB> <TAB> else: <TAB> <TAB> <TAB> template = DatePatternRegex(pattern) <TAB> DD_patternCache.set(key, template) <TAB> return template",true,"if key in ( ""EPOCH"" , ""{^LN-BEG}EPOCH"" , ""^EPOCH"" ) :","if key in ( ""EPOCH"" , ""{^LN-BEG}EPOCH"" , ""^EPOCH"" ) :",0.75,0.0
"def findOwningViewController(self, object): <TAB> while object: <TAB> <TAB> if self.isViewController(object): <TAB> <TAB> <TAB> description = fb.evaluateExpressionValue(object).GetObjectDescription() <TAB> <TAB> <TAB> print(""Found the owning view controller.\n{}"".format(description)) <TAB> <TAB> <TAB> cmd = 'echo {} | tr -d ""\n"" | pbcopy'.format(object) <TAB> <TAB> <TAB> os.system(cmd) <TAB> <TAB> <TAB> return <TAB> <TAB> else: <TAB> <TAB> <TAB> object = self.nextResponder(object) <TAB> print(""Could not find an owning view controller"")",true,if self . isViewController ( object ) :,if self . isViewController ( object ) :,0.75,0.0
"def __get_file_by_num(self, num, file_list, idx=0): <TAB> for element in file_list: <TAB> <TAB> if idx == num: <TAB> <TAB> <TAB> return element <TAB> <TAB> if element[3] and element[4]: <TAB> <TAB> <TAB> i = self.__get_file_by_num(num, element[3], idx + 1) <TAB> <TAB> <TAB> if not isinstance(i, int): <TAB> <TAB> <TAB> <TAB> return i <TAB> <TAB> <TAB> idx = i <TAB> <TAB> else: <TAB> <TAB> <TAB> idx += 1 <TAB> return idx",true,"if not isinstance ( i , int ) :","if not isinstance ( i , int ) :",0.75,0.0
"def promtool(**kwargs): <TAB> key = ""prometheus:promtool"" <TAB> try: <TAB> <TAB> path = pathlib.Path(util.setting(key)) <TAB> except TypeError: <TAB> <TAB> yield checks.Warning( <TAB> <TAB> <TAB> ""Missing setting for %s in %s "" % (key, settings.PROMGEN_CONFIG_FILE), <TAB> <TAB> <TAB> id=""promgen.W001"", <TAB> <TAB> ) <TAB> else: <TAB> <TAB> if not os.access(path, os.X_OK): <TAB> <TAB> <TAB> yield checks.Warning(""Unable to execute file %s"" % path, id=""promgen.W003"")",true,"if not os . access ( path , os . X_OK ) :","if not os . access ( path , os . X_OK ) :",1.0,0.0
"def parse_config(schema, config): <TAB> schemaparser = ConfigParser() <TAB> schemaparser.readfp(StringIO(schema)) <TAB> cfgparser = ConfigParser() <TAB> cfgparser.readfp(StringIO(config)) <TAB> result = {} <TAB> for section in cfgparser.sections(): <TAB> <TAB> result_section = {} <TAB> <TAB> schema = {} <TAB> <TAB> if section in schemaparser.sections(): <TAB> <TAB> <TAB> schema = dict(schemaparser.items(section)) <TAB> <TAB> for key, value in cfgparser.items(section): <TAB> <TAB> <TAB> converter = converters[schema.get(key, ""string"")] <TAB> <TAB> <TAB> result_section[key] = converter(value) <TAB> <TAB> result[section] = result_section <TAB> return result",true,if section in schemaparser . sections ( ) :,if section in schemaparser . sections ( ) :,0.75,0.0
"def validate_arguments(args): <TAB> if args.num_pss < 1: <TAB> <TAB> print(""Value error: must have ore than one parameter servers."") <TAB> <TAB> exit(1) <TAB> if not GPU_IDS: <TAB> <TAB> num_cpus = multiprocessing.cpu_count() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print( <TAB> <TAB> <TAB> <TAB> ""Value error: there are %s available CPUs but you are requiring %s."" <TAB> <TAB> <TAB> <TAB> % (num_cpus, args.cpu_trainers) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> exit(1) <TAB> if not os.path.isfile(args.file): <TAB> <TAB> print(""Value error: model trainning file does not exist"") <TAB> <TAB> exit(1)",false,if args . cpu_trainers > num_cpus :,if num_cpus > args . cpu_trainers :,0.1,0.0
"def infer_dataset_impl(path): <TAB> if IndexedRawTextDataset.exists(path): <TAB> <TAB> return ""raw"" <TAB> elif IndexedDataset.exists(path): <TAB> <TAB> with open(index_file_path(path), ""rb"") as f: <TAB> <TAB> <TAB> magic = f.read(8) <TAB> <TAB> <TAB> if magic == IndexedDataset._HDR_MAGIC: <TAB> <TAB> <TAB> <TAB> return ""cached"" <TAB> <TAB> <TAB> elif magic == MMapIndexedDataset.Index._HDR_MAGIC[:8]: <TAB> <TAB> <TAB> <TAB> return ""mmap"" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return None <TAB> elif FastaDataset.exists(path): <TAB> <TAB> return ""fasta"" <TAB> else: <TAB> <TAB> return None",true,elif magic == MMapIndexedDataset . Index . _HDR_MAGIC [ : 8 ] :,elif magic == MMapIndexedDataset . Index . _HDR_MAGIC [ : 8 ] :,1.0,0.0
"def _add_resource_group(obj): <TAB> if isinstance(obj, list): <TAB> <TAB> for array_item in obj: <TAB> <TAB> <TAB> _add_resource_group(array_item) <TAB> elif isinstance(obj, dict): <TAB> <TAB> try: <TAB> <TAB> <TAB> if ""resourcegroup"" not in [x.lower() for x in obj.keys()]: <TAB> <TAB> <TAB> <TAB> if obj[""id""]: <TAB> <TAB> <TAB> <TAB> <TAB> obj[""resourceGroup""] = _parse_id(obj[""id""])[""resource-group""] <TAB> <TAB> except (KeyError, IndexError, TypeError): <TAB> <TAB> <TAB> pass <TAB> <TAB> for item_key in obj: <TAB> <TAB> <TAB> if item_key != ""sourceVault"": <TAB> <TAB> <TAB> <TAB> _add_resource_group(obj[item_key])",false,"if obj [ ""id"" ] :","if item_key != ""sourceVault"" :",0.03,0.0
"def reformatBody(self, event=None): <TAB> """"""Reformat all paragraphs in the body."""""" <TAB> c, p = self, self.p <TAB> undoType = ""reformat-body"" <TAB> w = c.frame.body.wrapper <TAB> c.undoer.beforeChangeGroup(p, undoType) <TAB> w.setInsertPoint(0) <TAB> while 1: <TAB> <TAB> progress = w.getInsertPoint() <TAB> <TAB> c.reformatParagraph(event, undoType=undoType) <TAB> <TAB> ins = w.getInsertPoint() <TAB> <TAB> s = w.getAllText() <TAB> <TAB> w.setInsertPoint(ins) <TAB> <TAB> if ins <= progress or ins >= len(s): <TAB> <TAB> <TAB> break <TAB> c.undoer.afterChangeGroup(p, undoType)",true,if ins <= progress or ins >= len ( s ) :,if ins <= progress or ins >= len ( s ) :,1.0,0.0
"def make_sources(project: RootDependency) -> str: <TAB> content = [] <TAB> if project.readme: <TAB> <TAB> content.append(project.readme.path.name) <TAB> <TAB> if project.readme.markup != ""rst"": <TAB> <TAB> <TAB> content.append(project.readme.to_rst().path.name) <TAB> path = project.package.path <TAB> for fname in (""setup.cfg"", ""setup.py""): <TAB> <TAB> if (path / fname).exists(): <TAB> <TAB> <TAB> content.append(fname) <TAB> for package in chain(project.package.packages, project.package.data): <TAB> <TAB> for fpath in package: <TAB> <TAB> <TAB> fpath = fpath.relative_to(project.package.path) <TAB> <TAB> <TAB> content.append(""/"".join(fpath.parts)) <TAB> return ""\n"".join(content)",false,"if project . readme . markup != ""rst"" :",if ( path / fname ) . exists ( ) :,0.02,0.0
"def __init__(self, response): <TAB> error = ""{} {}"".format(response.status_code, response.reason) <TAB> extra = [] <TAB> try: <TAB> <TAB> response_json = response.json() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> error = "" "".join(error[""message""] for error in response_json[""error_list""]) <TAB> <TAB> <TAB> extra = [ <TAB> <TAB> <TAB> <TAB> error[""extra""] <TAB> <TAB> <TAB> <TAB> for error in response_json[""error_list""] <TAB> <TAB> <TAB> <TAB> if ""extra"" in error <TAB> <TAB> <TAB> ] <TAB> except JSONDecodeError: <TAB> <TAB> pass <TAB> super().__init__(response=response, error=error, extra=extra)",true,"if ""error_list"" in response_json :","if ""error_list"" in response_json :",0.75,0.0
"def handle_event(self, fileno=None, events=None): <TAB> if self._state == RUN: <TAB> <TAB> if self._it is None: <TAB> <TAB> <TAB> self._it = self._process_result(0)  # non-blocking <TAB> <TAB> try: <TAB> <TAB> <TAB> next(self._it) <TAB> <TAB> except (StopIteration, CoroStop): <TAB> <TAB> <TAB> self._it = None",true,if self . _it is None :,if self . _it is None :,0.75,0.0
"def find_query(self, needle, haystack): <TAB> try: <TAB> <TAB> import pinyin <TAB> <TAB> haystack_py = pinyin.get_initial(haystack, """") <TAB> <TAB> needle_len = len(needle) <TAB> <TAB> start = 0 <TAB> <TAB> result = [] <TAB> <TAB> while True: <TAB> <TAB> <TAB> found = haystack_py.find(needle, start) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> result.append((found, needle_len)) <TAB> <TAB> <TAB> start = found + needle_len <TAB> <TAB> return result <TAB> except: <TAB> <TAB> return None",false,if found < 0 :,if found == - 1 :,0.06,0.0
"def decorated_function(*args, **kwargs): <TAB> rv = f(*args, **kwargs) <TAB> if ""Last-Modified"" not in rv.headers: <TAB> <TAB> try: <TAB> <TAB> <TAB> result = date <TAB> <TAB> <TAB> if callable(result): <TAB> <TAB> <TAB> <TAB> result = result(rv) <TAB> <TAB> <TAB> if not isinstance(result, basestring): <TAB> <TAB> <TAB> <TAB> from werkzeug.http import http_date <TAB> <TAB> <TAB> <TAB> result = http_date(result) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> rv.headers[""Last-Modified""] = result <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> logging.getLogger(__name__).exception( <TAB> <TAB> <TAB> <TAB> ""Error while calculating the lastmodified value for response {!r}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> rv <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return rv",true,if result :,if result :,0.53,0.0
"def check_require(require_modules, require_lines): <TAB> for require_module in require_modules: <TAB> <TAB> st = try_import(require_module) <TAB> <TAB> if st == 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> elif st == 1: <TAB> <TAB> <TAB> print( <TAB> <TAB> <TAB> <TAB> ""installed {}: {}\n"".format( <TAB> <TAB> <TAB> <TAB> <TAB> require_module, require_lines[require_module] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> elif st == 2: <TAB> <TAB> <TAB> print( <TAB> <TAB> <TAB> <TAB> ""failed installed {}: {}\n"".format( <TAB> <TAB> <TAB> <TAB> <TAB> require_module, require_lines[require_module] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> )",false,elif st == 1 :,elif st == 2 :,0.64,0.0
"def bundle_directory(self, dirpath): <TAB> """"""Bundle all modules/packages in the given directory."""""" <TAB> dirpath = os.path.abspath(dirpath) <TAB> for nm in os.listdir(dirpath): <TAB> <TAB> nm = _u(nm) <TAB> <TAB> if nm.startswith("".""): <TAB> <TAB> <TAB> continue <TAB> <TAB> itempath = os.path.join(dirpath, nm) <TAB> <TAB> if os.path.isdir(itempath): <TAB> <TAB> <TAB> if os.path.exists(os.path.join(itempath, ""__init__.py"")): <TAB> <TAB> <TAB> <TAB> self.bundle_package(itempath) <TAB> <TAB> elif nm.endswith("".py""): <TAB> <TAB> <TAB> self.bundle_module(itempath)",false,"elif nm . endswith ( "".py"" ) :",if os . path . isdir ( itempath ) :,0.03,0.0
"def _find_root(): <TAB> test_dirs = [""Src"", ""Build"", ""Package"", ""Tests"", ""Util""] <TAB> root = os.getcwd() <TAB> test = all([os.path.exists(os.path.join(root, x)) for x in test_dirs]) <TAB> while not test: <TAB> <TAB> last_root = root <TAB> <TAB> root = os.path.dirname(root) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise Exception(""Root not found"") <TAB> <TAB> test = all([os.path.exists(os.path.join(root, x)) for x in test_dirs]) <TAB> return root",true,if root == last_root :,if root == last_root :,0.75,0.0
"def findMarkForUnitTestNodes(self): <TAB> """"""return the position of *all* non-ignored @mark-for-unit-test nodes."""""" <TAB> c = self.c <TAB> p, result, seen = c.rootPosition(), [], [] <TAB> while p: <TAB> <TAB> if p.v in seen: <TAB> <TAB> <TAB> p.moveToNodeAfterTree() <TAB> <TAB> else: <TAB> <TAB> <TAB> seen.append(p.v) <TAB> <TAB> <TAB> if g.match_word(p.h, 0, ""@ignore""): <TAB> <TAB> <TAB> <TAB> p.moveToNodeAfterTree() <TAB> <TAB> <TAB> elif p.h.startswith(""@mark-for-unit-tests""): <TAB> <TAB> <TAB> <TAB> result.append(p.copy()) <TAB> <TAB> <TAB> <TAB> p.moveToNodeAfterTree() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> p.moveToThreadNext() <TAB> return result",false,"elif p . h . startswith ( ""@mark-for-unit-tests"" ) :","if g . match_word ( p . h , 0 , ""@ignore"" ) :",0.06,0.0
"def startTagFrameset(self, token): <TAB> self.parser.parseError(""unexpected-start-tag"", {""name"": ""frameset""}) <TAB> if len(self.tree.openElements) == 1 or self.tree.openElements[1].name != ""body"": <TAB> <TAB> assert self.parser.innerHTML <TAB> elif not self.parser.framesetOK: <TAB> <TAB> pass <TAB> else: <TAB> <TAB> if self.tree.openElements[1].parent: <TAB> <TAB> <TAB> self.tree.openElements[1].parent.removeChild(self.tree.openElements[1]) <TAB> <TAB> while self.tree.openElements[-1].name != ""html"": <TAB> <TAB> <TAB> self.tree.openElements.pop() <TAB> <TAB> self.tree.insertElement(token) <TAB> <TAB> self.parser.phase = self.parser.phases[""inFrameset""]",true,if self . tree . openElements [ 1 ] . parent :,if self . tree . openElements [ 1 ] . parent :,0.75,0.0
"def try_split(self, split_text: List[str]): <TAB> ret = [] <TAB> for i in split_text: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> val = int(i, 2) <TAB> <TAB> if val > 255 or val < 0: <TAB> <TAB> <TAB> return None <TAB> <TAB> ret.append(val) <TAB> if len(ret) != 0: <TAB> <TAB> ret = bytes(ret) <TAB> <TAB> logger.debug(f""binary successful, returning {ret.__repr__()}"") <TAB> <TAB> return ret",false,if len ( i ) == 0 :,"if i == """" :",0.02,0.0
"def generator(self, data): <TAB> for sock in data: <TAB> <TAB> if not self._config.PHYSICAL_OFFSET: <TAB> <TAB> <TAB> offset = sock.obj_offset <TAB> <TAB> else: <TAB> <TAB> <TAB> offset = sock.obj_vm.vtop(sock.obj_offset) <TAB> <TAB> yield ( <TAB> <TAB> <TAB> 0, <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> Address(offset), <TAB> <TAB> <TAB> <TAB> int(sock.Pid), <TAB> <TAB> <TAB> <TAB> int(sock.LocalPort), <TAB> <TAB> <TAB> <TAB> int(sock.Protocol), <TAB> <TAB> <TAB> <TAB> str(protos.protos.get(sock.Protocol.v(), ""-"")), <TAB> <TAB> <TAB> <TAB> str(sock.LocalIpAddress), <TAB> <TAB> <TAB> <TAB> str(sock.CreateTime), <TAB> <TAB> <TAB> ], <TAB> <TAB> )",true,if not self . _config . PHYSICAL_OFFSET :,if not self . _config . PHYSICAL_OFFSET :,0.75,0.0
"def __init__(self, num_bits=4, always_apply=False, p=0.5): <TAB> super(Posterize, self).__init__(always_apply, p) <TAB> if isinstance(num_bits, (list, tuple)): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.num_bits = [to_tuple(i, 0) for i in num_bits] <TAB> <TAB> else: <TAB> <TAB> <TAB> self.num_bits = to_tuple(num_bits, 0) <TAB> else: <TAB> <TAB> self.num_bits = to_tuple(num_bits, num_bits)",false,if len ( num_bits ) == 3 :,if len ( num_bits ) == 2 :,0.61,0.0
"def tearDown(self): <TAB> """"""Just in case yn00 creates some junk files, do a clean-up."""""" <TAB> del_files = [self.out_file, ""2YN.dN"", ""2YN.dS"", ""2YN.t"", ""rst"", ""rst1"", ""rub""] <TAB> for filename in del_files: <TAB> <TAB> if os.path.exists(filename): <TAB> <TAB> <TAB> os.remove(filename) <TAB> if os.path.exists(self.working_dir): <TAB> <TAB> for filename in os.listdir(self.working_dir): <TAB> <TAB> <TAB> filepath = os.path.join(self.working_dir, filename) <TAB> <TAB> <TAB> os.remove(filepath) <TAB> <TAB> os.rmdir(self.working_dir)",true,if os . path . exists ( filename ) :,if os . path . exists ( filename ) :,0.75,0.0
"def reverse_search_history(self, searchfor, startpos=None): <TAB> if startpos is None: <TAB> <TAB> startpos = self.history_cursor <TAB> if _ignore_leading_spaces: <TAB> <TAB> res = [ <TAB> <TAB> <TAB> (idx, line.lstrip()) <TAB> <TAB> <TAB> for idx, line in enumerate(self.history[startpos:0:-1]) <TAB> <TAB> <TAB> if line.lstrip().startswith(searchfor.lstrip()) <TAB> <TAB> ] <TAB> else: <TAB> <TAB> res = [ <TAB> <TAB> <TAB> (idx, line) <TAB> <TAB> <TAB> for idx, line in enumerate(self.history[startpos:0:-1]) <TAB> <TAB> <TAB> if line.startswith(searchfor) <TAB> <TAB> ] <TAB> if res: <TAB> <TAB> self.history_cursor -= res[0][0] <TAB> <TAB> return res[0][1].get_line_text() <TAB> return """"",false,if line . lstrip ( ) . startswith ( searchfor . lstrip ( ) ),if line . startswith ( searchfor ),0.11,0.0
"def ComboBoxDroppedHeightTest(windows): <TAB> ""Check if each combobox height is the same as the reference"" <TAB> bugs = [] <TAB> for win in windows: <TAB> <TAB> if not win.ref: <TAB> <TAB> <TAB> continue <TAB> <TAB> if win.Class() != ""ComboBox"" or win.ref.Class() != ""ComboBox"": <TAB> <TAB> <TAB> continue <TAB> <TAB> if win.DroppedRect().height() != win.ref.DroppedRect().height(): <TAB> <TAB> <TAB> bugs.append( <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> win, <TAB> <TAB> <TAB> <TAB> <TAB> ], <TAB> <TAB> <TAB> <TAB> <TAB> {}, <TAB> <TAB> <TAB> <TAB> <TAB> testname, <TAB> <TAB> <TAB> <TAB> <TAB> 0, <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return bugs",true,"if win . Class ( ) != ""ComboBox"" or win . ref . Class ( ) != ""ComboBox"" :","if win . Class ( ) != ""ComboBox"" or win . ref . Class ( ) != ""ComboBox"" :",1.0,0.0
"def get_changed(self): <TAB> if self._is_expression(): <TAB> <TAB> result = self._get_node_text(self.ast) <TAB> <TAB> if result == self.source: <TAB> <TAB> <TAB> return None <TAB> <TAB> return result <TAB> else: <TAB> <TAB> collector = codeanalyze.ChangeCollector(self.source) <TAB> <TAB> last_end = -1 <TAB> <TAB> for match in self.matches: <TAB> <TAB> <TAB> start, end = match.get_region() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if not self._is_expression(): <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> last_end = end <TAB> <TAB> <TAB> replacement = self._get_matched_text(match) <TAB> <TAB> <TAB> collector.add_change(start, end, replacement) <TAB> <TAB> return collector.get_changed()",false,if start < last_end :,if end != last_end :,0.06,0.0
"def unpickle_from_file(file_path, gzip=False): <TAB> """"""Unpickle obj from file_path with gzipping."""""" <TAB> with tf.io.gfile.GFile(file_path, ""rb"") as f: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> obj = pickle.load(f) <TAB> <TAB> else: <TAB> <TAB> <TAB> with gzip_lib.GzipFile(fileobj=f, compresslevel=2) as gzipf: <TAB> <TAB> <TAB> <TAB> obj = pickle.load(gzipf) <TAB> return obj",false,if not gzip :,if gzip :,0.1,0.0
"def get_user_context(request, escape=False): <TAB> if isinstance(request, HttpRequest): <TAB> <TAB> user = getattr(request, ""user"", None) <TAB> <TAB> result = {""ip_address"": request.META[""REMOTE_ADDR""]} <TAB> <TAB> if user and user.is_authenticated(): <TAB> <TAB> <TAB> result.update( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> ""email"": user.email, <TAB> <TAB> <TAB> <TAB> <TAB> ""id"": user.id, <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> result[""name""] = user.name <TAB> else: <TAB> <TAB> result = {} <TAB> return mark_safe(json.dumps(result))",false,if user . name :,if escape :,0.04,0.0
"def get_item_address(self, item): <TAB> """"""Get an item's address as a collection of names"""""" <TAB> result = [] <TAB> while True: <TAB> <TAB> name = self.tree_ctrl.GetItemPyData(item) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> result.insert(0, name) <TAB> <TAB> <TAB> item = self.tree_ctrl.GetItemParent(item) <TAB> return result",true,if name is None :,if name is None :,0.75,0.0
"def closest_unseen(self, row1, col1, filter=None): <TAB> # find the closest unseen from this row/col <TAB> min_dist = maxint <TAB> closest_unseen = None <TAB> for row in range(self.height): <TAB> <TAB> for col in range(self.width): <TAB> <TAB> <TAB> if filter is None or (row, col) not in filter: <TAB> <TAB> <TAB> <TAB> if self.map[row][col] == UNSEEN: <TAB> <TAB> <TAB> <TAB> <TAB> dist = self.distance(row1, col1, row, col) <TAB> <TAB> <TAB> <TAB> <TAB> if dist < min_dist: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> min_dist = dist <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> closest_unseen = (row, col) <TAB> return closest_unseen",true,if self . map [ row ] [ col ] == UNSEEN :,if self . map [ row ] [ col ] == UNSEEN :,0.75,0.0
"def log_graph(self, model: LightningModule, input_array=None): <TAB> if self._log_graph: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> input_array = model.example_input_array <TAB> <TAB> if input_array is not None: <TAB> <TAB> <TAB> input_array = model._apply_batch_transfer_handler(input_array) <TAB> <TAB> <TAB> self.experiment.add_graph(model, input_array) <TAB> <TAB> else: <TAB> <TAB> <TAB> rank_zero_warn( <TAB> <TAB> <TAB> <TAB> ""Could not log computational graph since the"" <TAB> <TAB> <TAB> <TAB> "" `model.example_input_array` attribute is not set"" <TAB> <TAB> <TAB> <TAB> "" or `input_array` was not given"", <TAB> <TAB> <TAB> <TAB> UserWarning, <TAB> <TAB> <TAB> )",true,if input_array is None :,if input_array is None :,0.75,0.0
"def get_scene_exceptions_by_season(self, season=-1): <TAB> scene_exceptions = [] <TAB> for scene_exception in self.scene_exceptions: <TAB> <TAB> if not len(scene_exception) == 2: <TAB> <TAB> <TAB> continue <TAB> <TAB> scene_name, scene_season = scene_exception.split(""|"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> scene_exceptions.append(scene_name) <TAB> return scene_exceptions",true,if season == scene_season :,if season == scene_season :,0.75,0.0
def _clean_temp_files(): <TAB> for pattern in _temp_files: <TAB> <TAB> for path in glob.glob(pattern): <TAB> <TAB> <TAB> if os.path.islink(path) or os.path.isfile(path): <TAB> <TAB> <TAB> <TAB> os.remove(path) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> shutil.rmtree(path),true,if os . path . islink ( path ) or os . path . isfile ( path ) :,if os . path . islink ( path ) or os . path . isfile ( path ) :,1.0,0.0
"def wait_for_completion(self, job_id, offset, max_results, start_time, timeout): <TAB> """"""Wait for job completion and return the first page."""""" <TAB> while True: <TAB> <TAB> result = self.get_query_results( <TAB> <TAB> <TAB> job_id=job_id, page_token=None, start_index=offset, max_results=max_results <TAB> <TAB> ) <TAB> <TAB> if result[""jobComplete""]: <TAB> <TAB> <TAB> return result <TAB> <TAB> if (time.time() - start_time) > timeout: <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> ""Timeout: the query doesn't finish within %d seconds."" % timeout <TAB> <TAB> <TAB> ) <TAB> <TAB> time.sleep(1)",true,"if result [ ""jobComplete"" ] :","if result [ ""jobComplete"" ] :",0.75,0.0
"def get_data(self, element, ranges, style): <TAB><IF-STMT> <TAB> <TAB> groups = element.groupby(element.kdims).items() <TAB> else: <TAB> <TAB> groups = [(element.label, element)] <TAB> plots = [] <TAB> axis = ""x"" if self.invert_axes else ""y"" <TAB> for key, group in groups: <TAB> <TAB> if element.kdims: <TAB> <TAB> <TAB> label = "","".join([d.pprint_value(v) for d, v in zip(element.kdims, key)]) <TAB> <TAB> else: <TAB> <TAB> <TAB> label = key <TAB> <TAB> data = {axis: group.dimension_values(group.vdims[0]), ""name"": label} <TAB> <TAB> plots.append(data) <TAB> return plots",false,if element . kdims :,if self . invert_axes :,0.29,0.0
"def get_files(self, dirname): <TAB> if not self._data.has_key(dirname): <TAB> <TAB> self._create(dirname) <TAB> else: <TAB> <TAB> new_time = self._changed(dirname) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._update(dirname, new_time) <TAB> <TAB> <TAB> dcLog.debug(""==> "" + ""\t\n"".join(self._data[dirname][""flist""])) <TAB> return self._data[dirname][""flist""]",true,if new_time :,if new_time :,0.53,0.0
"def __init__(self, dir): <TAB> self.module_names = set() <TAB> for name in os.listdir(dir): <TAB> <TAB> if name.endswith("".py""): <TAB> <TAB> <TAB> self.module_names.add(name[:-3]) <TAB> <TAB> elif ""."" not in name: <TAB> <TAB> <TAB> self.module_names.add(name)",false,"if name . endswith ( "".py"" ) :","elif ""."" not in name :",0.02,0.0
"def logic(): <TAB> for i in range(100): <TAB> <TAB> yield clock.posedge, reset.negedge <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> count.next = 0 <TAB> <TAB> else: <TAB> <TAB> <TAB> if enable: <TAB> <TAB> <TAB> <TAB> count.next = (count + 1) % n <TAB> raise StopSimulation",true,if reset == ACTIVE_LOW :,if reset == ACTIVE_LOW :,0.75,0.0
"def sortkeypicker(keynames): <TAB> negate = set() <TAB> for i, k in enumerate(keynames): <TAB> <TAB> if k[:1] == ""-"": <TAB> <TAB> <TAB> keynames[i] = k[1:] <TAB> <TAB> <TAB> negate.add(k[1:]) <TAB> def getit(adict): <TAB> <TAB> composite = [adict[k] for k in keynames] <TAB> <TAB> for i, (k, v) in enumerate(zip(keynames, composite)): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> composite[i] = -v <TAB> <TAB> return composite <TAB> return getit",false,if k in negate :,if k not in negate :,0.15,0.0
"def show_image(self, wnd_name, img): <TAB> if wnd_name in self.named_windows: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.named_windows[wnd_name] = 1 <TAB> <TAB> <TAB> self.on_create_window(wnd_name) <TAB> <TAB> <TAB> if wnd_name in self.capture_mouse_windows: <TAB> <TAB> <TAB> <TAB> self.capture_mouse(wnd_name) <TAB> <TAB> self.on_show_image(wnd_name, img) <TAB> else: <TAB> <TAB> print(""show_image: named_window "", wnd_name, "" not found."")",false,if self . named_windows [ wnd_name ] == 0 :,if wnd_name not in self . named_windows :,0.06,0.0
"def check_action_permitted(self): <TAB> if ( <TAB> <TAB> self._action == ""sts:GetCallerIdentity"" <TAB> ):  # always allowed, even if there's an explicit Deny for it <TAB> <TAB> return True <TAB> policies = self._access_key.collect_policies() <TAB> permitted = False <TAB> for policy in policies: <TAB> <TAB> iam_policy = IAMPolicy(policy) <TAB> <TAB> permission_result = iam_policy.is_action_permitted(self._action) <TAB> <TAB> if permission_result == PermissionResult.DENIED: <TAB> <TAB> <TAB> self._raise_access_denied() <TAB> <TAB> elif permission_result == PermissionResult.PERMITTED: <TAB> <TAB> <TAB> permitted = True <TAB> if not permitted: <TAB> <TAB> self._raise_access_denied()",true,elif permission_result == PermissionResult . PERMITTED :,elif permission_result == PermissionResult . PERMITTED :,0.75,0.0
"def _limit_value(key, value, config): <TAB> if config[key].get(""upper_limit""): <TAB> <TAB> limit = config[key][""upper_limit""] <TAB> <TAB> # auto handle datetime <TAB> <TAB> if isinstance(value, datetime) and isinstance(limit, timedelta): <TAB> <TAB> <TAB> if config[key][""inverse""] is True: <TAB> <TAB> <TAB> <TAB> if (datetime.now() - limit) > value: <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime.now() - limit <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> if (datetime.now() + limit) < value: <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime.now() + limit <TAB> <TAB> elif value > limit: <TAB> <TAB> <TAB> value = limit <TAB> return value",false,if ( datetime . now ( ) - limit ) > value :,"if isinstance ( value , datetime ) and isinstance ( limit , timedelta ) :",0.01,0.0
"def replace_dataset_ids(path, key, value): <TAB> """"""Exchanges dataset_ids (HDA, LDA, HDCA, not Dataset) in input_values with dataset ids used in job."""""" <TAB> current_case = input_values <TAB> if key == ""id"": <TAB> <TAB> for i, p in enumerate(path): <TAB> <TAB> <TAB> if isinstance(current_case, (list, dict)): <TAB> <TAB> <TAB> <TAB> current_case = current_case[p] <TAB> <TAB> if src == current_case.get(""src""): <TAB> <TAB> <TAB> return key, translate_values.get(current_case[""id""], value) <TAB> return key, value",true,"if src == current_case . get ( ""src"" ) :","if src == current_case . get ( ""src"" ) :",0.75,0.0
"def load_ext(name, funcs): <TAB> ExtModule = namedtuple(""ExtModule"", funcs) <TAB> ext_list = [] <TAB> lib_root = os.path.dirname(os.path.dirname(os.path.realpath(__file__))) <TAB> for fun in funcs: <TAB> <TAB> if fun in [""nms"", ""softnms""]: <TAB> <TAB> <TAB> ext_list.append(extension.load(fun, name, lib_dir=lib_root).op) <TAB> <TAB> else: <TAB> <TAB> <TAB> ext_list.append(extension.load(fun, name, lib_dir=lib_root).op_) <TAB> return ExtModule(*ext_list)",true,"if fun in [ ""nms"" , ""softnms"" ] :","if fun in [ ""nms"" , ""softnms"" ] :",0.75,0.0
"def execute_action(self): <TAB> selected_actions = self.model_action.get_selected_results_with_index() <TAB> if selected_actions and self.args_for_action: <TAB> <TAB> for name, _, act_idx in selected_actions: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> action = self.actions[act_idx] <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> action.act([arg for arg, _, _ in self.args_for_action], self) <TAB> <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> <TAB> debug.log(""execute_action"", e)",true,if action :,if action :,0.53,0.0
"def __getattr__(self, attr): <TAB> proxy = self.__proxy <TAB> if proxy and hasattr(proxy, attr): <TAB> <TAB> return getattr(proxy, attr) <TAB> attrmap = self.__attrmap <TAB> if attr in attrmap: <TAB> <TAB> source = attrmap[attr] <TAB> <TAB> if callable(source): <TAB> <TAB> <TAB> value = source() <TAB> <TAB> else: <TAB> <TAB> <TAB> value = _import_object(source) <TAB> <TAB> setattr(self, attr, value) <TAB> <TAB> self.__log.debug(""loaded lazy attr %r: %r"", attr, value) <TAB> <TAB> return value <TAB> raise AttributeError(""'module' object has no attribute '%s'"" % (attr,))",true,if callable ( source ) :,if callable ( source ) :,0.75,0.0
"def forward(self, x): <TAB> # BxT -> BxCxT <TAB> x = x.unsqueeze(1) <TAB> for conv in self.conv_layers: <TAB> <TAB> residual = x <TAB> <TAB> x = conv(x) <TAB> <TAB> if self.skip_connections and x.size(1) == residual.size(1): <TAB> <TAB> <TAB> tsz = x.size(2) <TAB> <TAB> <TAB> r_tsz = residual.size(2) <TAB> <TAB> <TAB> residual = residual[..., :: r_tsz // tsz][..., :tsz] <TAB> <TAB> <TAB> x = (x + residual) * self.residual_scale <TAB> if self.log_compression: <TAB> <TAB> x = x.abs() <TAB> <TAB> x = x + 1 <TAB> <TAB> x = x.log() <TAB> return x",true,if self . skip_connections and x . size ( 1 ) == residual . size ( 1 ) :,if self . skip_connections and x . size ( 1 ) == residual . size ( 1 ) :,1.0,0.0
"def __Prefix_Step2a(self, token): <TAB> for prefix in self.__prefix_step2a: <TAB> <TAB> if token.startswith(prefix) and len(token) > 5: <TAB> <TAB> <TAB> token = token[len(prefix) :] <TAB> <TAB> <TAB> self.prefix_step2a_success = True <TAB> <TAB> <TAB> break <TAB> return token",true,if token . startswith ( prefix ) and len ( token ) > 5 :,if token . startswith ( prefix ) and len ( token ) > 5 :,1.0,0.0
"def is_valid(sample): <TAB> if sample is None: <TAB> <TAB> return False <TAB> if isinstance(sample, tuple): <TAB> <TAB> for s in sample: <TAB> <TAB> <TAB> if s is None: <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> elif isinstance(s, np.ndarray) and s.size == 0: <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> elif isinstance(s, collections.abc.Sequence) and len(s) == 0: <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",true,"elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 :","elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 :",0.75,0.0
"def get_all_comments(self, gallery_id, post_no, comment_cnt): <TAB> comment_page_cnt = (comment_cnt - 1) // self.options.comments_per_page + 1 <TAB> comments = [] <TAB> headers = {""X-Requested-With"": ""XMLHttpRequest""} <TAB> data = {""ci_t"": self._session.cookies[""ci_c""], ""id"": gallery_id, ""no"": post_no} <TAB> for i in range(comment_page_cnt): <TAB> <TAB> data[""comment_page""] = i + 1 <TAB> <TAB> response = self.request_comment(headers, data) <TAB> <TAB> batch = self.parse_comments(response.text) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> comments = batch + comments <TAB> return comments",true,if not batch :,if not batch :,0.75,0.0
def run_on_module(self): <TAB> try: <TAB> <TAB> self.module_base.disable(self.opts.module_spec) <TAB> except dnf.exceptions.MarkingErrors as e: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if e.no_match_group_specs or e.error_group_specs: <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> e.module_depsolv_errors <TAB> <TAB> <TAB> <TAB> and e.module_depsolv_errors[1] <TAB> <TAB> <TAB> <TAB> != libdnf.module.ModulePackageContainer.ModuleErrorType_ERROR_IN_DEFAULTS <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> logger.error(str(e)),false,if self . base . conf . strict :,if self . opts . strict :,0.2,0.0
"def find_field_notnull_differ(self, meta, table_description, table_name): <TAB> if not self.can_detect_notnull_differ: <TAB> <TAB> return <TAB> for field in all_local_fields(meta): <TAB> <TAB> attname = field.db_column or field.attname <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> null = self.get_field_db_nullable(field, table_name) <TAB> <TAB> if field.null != null: <TAB> <TAB> <TAB> action = field.null and ""DROP"" or ""SET"" <TAB> <TAB> <TAB> self.add_difference(""notnull-differ"", table_name, attname, action)",false,"if ( table_name , attname ) in self . new_db_fields :",if attname == table_description :,0.01,0.0
"def _change_moving_module(self, changes, dest): <TAB> if not self.source.is_folder(): <TAB> <TAB> pymodule = self.pycore.resource_to_pyobject(self.source) <TAB> <TAB> source = self.import_tools.relatives_to_absolutes(pymodule) <TAB> <TAB> pymodule = self.tools.new_pymodule(pymodule, source) <TAB> <TAB> source = self._change_occurrences_in_module(dest, pymodule) <TAB> <TAB> source = self.tools.new_source(pymodule, source) <TAB> <TAB> if source != self.source.read(): <TAB> <TAB> <TAB> changes.add_change(ChangeContents(self.source, source))",true,if source != self . source . read ( ) :,if source != self . source . read ( ) :,1.0,0.0
"def get(quality_name): <TAB> """"""Returns a quality object based on canonical quality name."""""" <TAB> found_components = {} <TAB> for part in quality_name.lower().split(): <TAB> <TAB> component = _registry.get(part) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError(""`%s` is not a valid quality string"" % part) <TAB> <TAB> if component.type in found_components: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""`%s` cannot be defined twice in a quality"" % component.type <TAB> <TAB> <TAB> ) <TAB> <TAB> found_components[component.type] = component <TAB> if not found_components: <TAB> <TAB> raise ValueError(""No quality specified"") <TAB> result = Quality() <TAB> for type, component in found_components.items(): <TAB> <TAB> setattr(result, type, component) <TAB> return result",true,if not component :,if not component :,0.75,0.0
def _unselected(self): <TAB> selected = self._selected <TAB> k = 0 <TAB> z = selected[k] <TAB> k += 1 <TAB> for i in range(self._n): <TAB> <TAB> if i == z: <TAB> <TAB> <TAB> if k < len(selected): <TAB> <TAB> <TAB> <TAB> z = selected[k] <TAB> <TAB> <TAB> <TAB> k += 1 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> z = -1 <TAB> <TAB> else: <TAB> <TAB> <TAB> yield i,true,if k < len ( selected ) :,if k < len ( selected ) :,0.75,0.0
"def render_headers(self) -> bytes: <TAB> if not hasattr(self, ""_headers""): <TAB> <TAB> parts = [ <TAB> <TAB> <TAB> b""Content-Disposition: form-data; "", <TAB> <TAB> <TAB> format_form_param(""name"", self.name), <TAB> <TAB> ] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> filename = format_form_param(""filename"", self.filename) <TAB> <TAB> <TAB> parts.extend([b""; "", filename]) <TAB> <TAB> if self.content_type is not None: <TAB> <TAB> <TAB> content_type = self.content_type.encode() <TAB> <TAB> <TAB> parts.extend([b""\r\nContent-Type: "", content_type]) <TAB> <TAB> parts.append(b""\r\n\r\n"") <TAB> <TAB> self._headers = b"""".join(parts) <TAB> return self._headers",false,if self . filename :,if self . filename is not None :,0.35,0.0
"def app_middleware(next, root, info, **kwargs): <TAB> app_auth_header = ""HTTP_AUTHORIZATION"" <TAB> prefix = ""bearer"" <TAB> request = info.context <TAB> if request.path == API_PATH: <TAB> <TAB> if not hasattr(request, ""app""): <TAB> <TAB> <TAB> request.app = None <TAB> <TAB> <TAB> auth = request.META.get(app_auth_header, """").split() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> auth_prefix, auth_token = auth <TAB> <TAB> <TAB> <TAB> if auth_prefix.lower() == prefix: <TAB> <TAB> <TAB> <TAB> <TAB> request.app = SimpleLazyObject(lambda: get_app(auth_token)) <TAB> return next(root, info, **kwargs)",false,if len ( auth ) == 2 :,if auth :,0.02,0.0
"def _shortest_hypernym_paths(self, simulate_root): <TAB> if self.offset == ""00000000"": <TAB> <TAB> return {self: 0} <TAB> queue = deque([(self, 0)]) <TAB> path = {} <TAB> while queue: <TAB> <TAB> s, depth = queue.popleft() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> path[s] = depth <TAB> <TAB> depth += 1 <TAB> <TAB> queue.extend((hyp, depth) for hyp in s._hypernyms()) <TAB> if simulate_root: <TAB> <TAB> root = Synset(self._wordnet_corpus_reader, None, self.pos(), ""00000000"", """") <TAB> <TAB> path[root] = max(path.values()) + 1 <TAB> return path",true,if s in path :,if s in path :,0.75,0.0
"def _populate_class_variables(): <TAB> lookup = {} <TAB> reverse_lookup = {} <TAB> characters_for_re = [] <TAB> for codepoint, name in list(codepoint2name.items()): <TAB> <TAB> character = chr(codepoint) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # There's no point in turning the quotation mark into <TAB> <TAB> <TAB> # &quot;, unless it happens within an attribute value, which <TAB> <TAB> <TAB> # is handled elsewhere. <TAB> <TAB> <TAB> characters_for_re.append(character) <TAB> <TAB> <TAB> lookup[character] = name <TAB> <TAB> # But we do want to turn &quot; into the quotation mark. <TAB> <TAB> reverse_lookup[name] = character <TAB> re_definition = ""[%s]"" % """".join(characters_for_re) <TAB> return lookup, reverse_lookup, re.compile(re_definition)",false,if codepoint != 34 :,if codepoint == 32 :,0.31,0.0
"def prepare_data_status(self, view: sublime.View, data: Dict[str, Any]) -> Any: <TAB> """"""Prepare the returned data for status"""""" <TAB> if ( <TAB> <TAB> data[""success""] <TAB> <TAB> and ""No docstring"" not in data[""doc""] <TAB> <TAB> and data[""doc""] != ""list\n"" <TAB> ): <TAB> <TAB> self.signature = data[""doc""] <TAB> <TAB> if self._signature_excluded(self.signature): <TAB> <TAB> <TAB> return <TAB> <TAB> try: <TAB> <TAB> <TAB> self.signature = self.signature.splitlines()[2] <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> return <TAB> <TAB> return self._show_status(view)",true,if self . _signature_excluded ( self . signature ) :,if self . _signature_excluded ( self . signature ) :,1.0,0.0
"def _setup_once_tables(cls): <TAB> if cls.run_define_tables == ""once"": <TAB> <TAB> cls.define_tables(cls.metadata) <TAB> <TAB> if cls.run_create_tables == ""once"": <TAB> <TAB> <TAB> cls.metadata.create_all(cls.bind) <TAB> <TAB> cls.tables.update(cls.metadata.tables)",true,"if cls . run_create_tables == ""once"" :","if cls . run_create_tables == ""once"" :",0.75,0.0
"def _send_recursive(self, files): <TAB> for base in files: <TAB> <TAB> if not os.path.isdir(base): <TAB> <TAB> <TAB> # filename mixed into the bunch <TAB> <TAB> <TAB> self._send_files([base]) <TAB> <TAB> <TAB> continue <TAB> <TAB> last_dir = asbytes(base) <TAB> <TAB> for root, dirs, fls in os.walk(base): <TAB> <TAB> <TAB> self._chdir(last_dir, asbytes(root)) <TAB> <TAB> <TAB> self._send_files([os.path.join(root, f) for f in fls]) <TAB> <TAB> <TAB> last_dir = asbytes(root) <TAB> <TAB> # back out of the directory <TAB> <TAB> for i in range(len(os.path.split(last_dir))): <TAB> <TAB> <TAB> self._send_popd()",true,if not os . path . isdir ( base ) :,if not os . path . isdir ( base ) :,0.75,0.0
"def __init__(self, *args, **kwargs): <TAB> super().__init__(*args, **kwargs) <TAB> # Automatically register models if required. <TAB> if not is_registered(self.model): <TAB> <TAB> inline_fields = () <TAB> <TAB> for inline in self.inlines: <TAB> <TAB> <TAB> inline_model, follow_field = self._reversion_introspect_inline_admin(inline) <TAB> <TAB> <TAB> if inline_model: <TAB> <TAB> <TAB> <TAB> self._reversion_autoregister(inline_model, ()) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> inline_fields += (follow_field,) <TAB> <TAB> self._reversion_autoregister(self.model, inline_fields)",true,if follow_field :,if follow_field :,0.53,0.0
"def dispatch_hook(key, hooks, hook_data, **kwargs): <TAB> """"""Dispatches a hook dictionary on a given piece of data."""""" <TAB> hooks = hooks or dict() <TAB> hooks = hooks.get(key) <TAB> if hooks: <TAB> <TAB> if hasattr(hooks, ""__call__""): <TAB> <TAB> <TAB> hooks = [hooks] <TAB> <TAB> for hook in hooks: <TAB> <TAB> <TAB> _hook_data = hook(hook_data, **kwargs) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> hook_data = _hook_data <TAB> return hook_data",false,if _hook_data is not None :,if _hook_data :,0.05,0.0
"def __call__(self, image, crop=True): <TAB> if isinstance(image, PTensor): <TAB> <TAB> return self.crop_to_output( <TAB> <TAB> <TAB> numpy_to_paddle(self(paddle_to_numpy(image), crop=False)) <TAB> <TAB> ) <TAB> else: <TAB> <TAB> warp = cv.warpAffine( <TAB> <TAB> <TAB> image, <TAB> <TAB> <TAB> self.transform_matrix, <TAB> <TAB> <TAB> image.shape[1::-1], <TAB> <TAB> <TAB> borderMode=cv.BORDER_REPLICATE, <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return self.crop_to_output(warp) <TAB> <TAB> else: <TAB> <TAB> <TAB> return warp",true,if crop :,if crop :,0.53,0.0
"def _analyze(self): <TAB> lines = open(self.log_path, ""r"").readlines() <TAB> prev_line = None <TAB> for line in lines: <TAB> <TAB> if line.startswith(""ERROR:"") and prev_line and prev_line.startswith(""=""): <TAB> <TAB> <TAB> self.errors.append(line[len(""ERROR:"") :].strip()) <TAB> <TAB> elif line.startswith(""FAIL:"") and prev_line and prev_line.startswith(""=""): <TAB> <TAB> <TAB> self.failures.append(line[len(""FAIL:"") :].strip()) <TAB> <TAB> prev_line = line",false,"if line . startswith ( ""ERROR:"" ) and prev_line and prev_line . startswith ( ""="" ) :","elif line . startswith ( ""FAIL:"" ) and prev_line and prev_line . startswith ( ""="" ) :",0.78,0.0
"def end(self, name): <TAB> self.soup.endData() <TAB> completed_tag = self.soup.tagStack[-1] <TAB> namespace, name = self._getNsTag(name) <TAB> nsprefix = None <TAB> if namespace is not None: <TAB> <TAB> for inverted_nsmap in reversed(self.nsmaps): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> nsprefix = inverted_nsmap[namespace] <TAB> <TAB> <TAB> <TAB> break <TAB> self.soup.handle_endtag(name, nsprefix) <TAB> if len(self.nsmaps) > 1: <TAB> <TAB> # This tag, or one of its parents, introduced a namespace <TAB> <TAB> # mapping, so pop it off the stack. <TAB> <TAB> self.nsmaps.pop()",false,if inverted_nsmap is not None and namespace in inverted_nsmap :,if namespace in inverted_nsmap :,0.31,0.0
"def _bind_parameters(operation, parameters): <TAB> # inspired by MySQL Python Connector (conversion.py) <TAB> string_parameters = {} <TAB> for (name, value) in parameters.iteritems(): <TAB> <TAB> if value is None: <TAB> <TAB> <TAB> string_parameters[name] = ""NULL"" <TAB> <TAB> elif isinstance(value, basestring): <TAB> <TAB> <TAB> string_parameters[name] = ""'"" + _escape(value) + ""'"" <TAB> <TAB> else: <TAB> <TAB> <TAB> string_parameters[name] = str(value) <TAB> return operation % string_parameters",true,"elif isinstance ( value , basestring ) :","elif isinstance ( value , basestring ) :",0.75,0.0
"def plugin_on_song_ended(self, song, skipped): <TAB> if song is not None: <TAB> <TAB> rating = song(""~#rating"") <TAB> <TAB> invrating = 1.0 - rating <TAB> <TAB> delta = min(rating, invrating) / 2.0 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> rating -= delta <TAB> <TAB> else: <TAB> <TAB> <TAB> rating += delta <TAB> <TAB> song[""~#rating""] = rating",true,if skipped :,if skipped :,0.53,0.0
"def on_activated_async(self, view): <TAB> if settings[""modified_lines_only""]: <TAB> <TAB> self.freeze_last_version(view) <TAB> if settings[""enabled""]: <TAB> <TAB> match_trailing_spaces(view) <TAB> <TAB> # continuously watch view for changes to the visible region <TAB> <TAB> if not view.id() in active_views: <TAB> <TAB> <TAB> # track <TAB> <TAB> <TAB> active_views[view.id()] = view.visible_region() <TAB> <TAB> <TAB> self.update_on_region_change(view)",true,if not view . id ( ) in active_views :,if not view . id ( ) in active_views :,0.75,0.0
"def _notin_text(term, text, verbose=False): <TAB> index = text.find(term) <TAB> head = text[:index] <TAB> tail = text[index + len(term) :] <TAB> correct_text = head + tail <TAB> diff = _diff_text(correct_text, text, verbose) <TAB> newdiff = [u(""%s is contained here:"") % py.io.saferepr(term, maxsize=42)] <TAB> for line in diff: <TAB> <TAB> if line.startswith(u(""Skipping"")): <TAB> <TAB> <TAB> continue <TAB> <TAB> if line.startswith(u(""- "")): <TAB> <TAB> <TAB> continue <TAB> <TAB> if line.startswith(u(""+ "")): <TAB> <TAB> <TAB> newdiff.append(u(""  "") + line[2:]) <TAB> <TAB> else: <TAB> <TAB> <TAB> newdiff.append(line) <TAB> return newdiff",false,"if line . startswith ( u ( ""Skipping"" ) ) :","if line . startswith ( u ( ""+"" ) ) :",0.6,0.0
"def delete_all(path): <TAB> ppath = os.getcwd() <TAB> os.chdir(path) <TAB> for fn in glob.glob(""*""): <TAB> <TAB> fn_full = os.path.join(path, fn) <TAB> <TAB> if os.path.isdir(fn): <TAB> <TAB> <TAB> delete_all(fn_full) <TAB> <TAB> elif fn.endswith("".png""): <TAB> <TAB> <TAB> os.remove(fn_full) <TAB> <TAB> elif fn.endswith("".md""): <TAB> <TAB> <TAB> os.remove(fn_full) <TAB> <TAB> elif DELETE_ALL_OLD: <TAB> <TAB> <TAB> os.remove(fn_full) <TAB> os.chdir(ppath) <TAB> os.rmdir(path)",false,"elif fn . endswith ( "".md"" ) :",elif delete_ALL_OLD :,0.01,0.0
"def reward(self): <TAB> """"""Returns a tuple of sum of raw and processed rewards."""""" <TAB> raw_rewards, processed_rewards = 0, 0 <TAB> for ts in self.time_steps: <TAB> <TAB> # NOTE: raw_reward and processed_reward are None for the first time-step. <TAB> <TAB> if ts.raw_reward is not None: <TAB> <TAB> <TAB> raw_rewards += ts.raw_reward <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> processed_rewards += ts.processed_reward <TAB> return raw_rewards, processed_rewards",true,if ts . processed_reward is not None :,if ts . processed_reward is not None :,0.75,0.0
"def formatmonthname(self, theyear, themonth, withyear=True): <TAB> with TimeEncoding(self.locale) as encoding: <TAB> <TAB> s = month_name[themonth] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> s = s.decode(encoding) <TAB> <TAB> if withyear: <TAB> <TAB> <TAB> s = ""%s %s"" % (s, theyear) <TAB> <TAB> return '<tr><th colspan=""7"" class=""month"">%s</th></tr>' % s",false,if encoding is not None :,if encoding :,0.05,0.0
"def check_digest_auth(user, passwd): <TAB> """"""Check user authentication using HTTP Digest auth"""""" <TAB> if request.headers.get(""Authorization""): <TAB> <TAB> credentails = parse_authorization_header(request.headers.get(""Authorization"")) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> response_hash = response( <TAB> <TAB> <TAB> credentails, <TAB> <TAB> <TAB> passwd, <TAB> <TAB> <TAB> dict( <TAB> <TAB> <TAB> <TAB> uri=request.script_root + request.path, <TAB> <TAB> <TAB> <TAB> body=request.data, <TAB> <TAB> <TAB> <TAB> method=request.method, <TAB> <TAB> <TAB> ), <TAB> <TAB> ) <TAB> <TAB> if credentails.get(""response"") == response_hash: <TAB> <TAB> <TAB> return True <TAB> return False",true,if not credentails :,if not credentails :,0.75,0.0
"def wrapped(self, request): <TAB> try: <TAB> <TAB> return self._finished <TAB> except AttributeError: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if not request.session.shouldfail and not request.session.shouldstop: <TAB> <TAB> <TAB> <TAB> log.debug( <TAB> <TAB> <TAB> <TAB> <TAB> ""%s is still going to be used, not terminating it. "" <TAB> <TAB> <TAB> <TAB> <TAB> ""Still in use on:\n%s"", <TAB> <TAB> <TAB> <TAB> <TAB> self, <TAB> <TAB> <TAB> <TAB> <TAB> pprint.pformat(list(self.node_ids)), <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> log.debug(""Finish called on %s"", self) <TAB> <TAB> try: <TAB> <TAB> <TAB> return func(request) <TAB> <TAB> finally: <TAB> <TAB> <TAB> self._finished = True",false,if self . node_ids :,if request . session :,0.29,0.0
"def run_tests(): <TAB> # type: () -> None <TAB> x = 5 <TAB> with switch(x) as case: <TAB> <TAB> if case(0): <TAB> <TAB> <TAB> print(""zero"") <TAB> <TAB> <TAB> print(""zero"") <TAB> <TAB> elif case(1, 2): <TAB> <TAB> <TAB> print(""one or two"") <TAB> <TAB> elif case(3, 4): <TAB> <TAB> <TAB> print(""three or four"") <TAB> <TAB> else: <TAB> <TAB> <TAB> print(""default"") <TAB> <TAB> <TAB> print(""another"")",true,"elif case ( 3 , 4 ) :","elif case ( 3 , 4 ) :",0.75,0.0
"def task_done(self): <TAB> with self._cond: <TAB> <TAB> if not self._unfinished_tasks.acquire(False): <TAB> <TAB> <TAB> raise ValueError(""task_done() called too many times"") <TAB> <TAB> if self._unfinished_tasks._semlock._is_zero(): <TAB> <TAB> <TAB> self._cond.notify_all()",false,if not self . _unfinished_tasks . acquire ( False ) :,if self . _unfinished_tasks . _semlock . _is_zero ( ) :,0.15,0.0
"def _set_uid(self, val): <TAB> if val is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.bus.log(""pwd module not available; ignoring uid."", level=30) <TAB> <TAB> <TAB> val = None <TAB> <TAB> elif isinstance(val, text_or_bytes): <TAB> <TAB> <TAB> val = pwd.getpwnam(val)[2] <TAB> self._uid = val",true,if pwd is None :,if pwd is None :,0.75,0.0
"def process_tag(hive_name, company, company_key, tag, default_arch): <TAB> with winreg.OpenKeyEx(company_key, tag) as tag_key: <TAB> <TAB> version = load_version_data(hive_name, company, tag, tag_key) <TAB> <TAB> if version is not None:  # if failed to get version bail <TAB> <TAB> <TAB> major, minor, _ = version <TAB> <TAB> <TAB> arch = load_arch_data(hive_name, company, tag, tag_key, default_arch) <TAB> <TAB> <TAB> if arch is not None: <TAB> <TAB> <TAB> <TAB> exe_data = load_exe(hive_name, company, company_key, tag) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> exe, args = exe_data <TAB> <TAB> <TAB> <TAB> <TAB> return company, major, minor, arch, exe, args",true,if exe_data is not None :,if exe_data is not None :,0.75,0.0
"def run(algs): <TAB> for alg in algs: <TAB> <TAB> vcs = alg.get(""variantcaller"") <TAB> <TAB> if vcs: <TAB> <TAB> <TAB> if isinstance(vcs, dict): <TAB> <TAB> <TAB> <TAB> vcs = reduce(operator.add, vcs.values()) <TAB> <TAB> <TAB> if not isinstance(vcs, (list, tuple)): <TAB> <TAB> <TAB> <TAB> vcs = [vcs] <TAB> <TAB> <TAB> return any(vc.startswith(prefix) for vc in vcs if vc)",false,"if not isinstance ( vcs , ( list , tuple ) ) :","if isinstance ( vcs , dict ) :",0.16,0.0
"def wrapper(self, *args, **kwargs): <TAB> if not self.request.path.endswith(""/""): <TAB> <TAB> if self.request.method in (""GET"", ""HEAD""): <TAB> <TAB> <TAB> uri = self.request.path + ""/"" <TAB> <TAB> <TAB> if self.request.query: <TAB> <TAB> <TAB> <TAB> uri += ""?"" + self.request.query <TAB> <TAB> <TAB> self.redirect(uri, permanent=True) <TAB> <TAB> <TAB> return <TAB> <TAB> raise HTTPError(404) <TAB> return method(self, *args, **kwargs)",true,"if self . request . method in ( ""GET"" , ""HEAD"" ) :","if self . request . method in ( ""GET"" , ""HEAD"" ) :",0.75,0.0
"def check_response(self, response): <TAB> """"""Specialized version of check_response()."""""" <TAB> for line in response: <TAB> <TAB> # Skip blank lines: <TAB> <TAB> if not line.strip(): <TAB> <TAB> <TAB> continue <TAB> <TAB> if line.startswith(b""OK""): <TAB> <TAB> <TAB> return <TAB> <TAB> elif line.startswith(b""Benutzer/Passwort Fehler""): <TAB> <TAB> <TAB> raise BadLogin(line) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise FailedPost(""Server returned '%s'"" % six.ensure_text(line))",false,if not line . strip ( ) :,"if line . startswith ( b""OK"" ) :",0.11,0.0
"def Walk(self, hMenu=None): <TAB> if not hMenu: <TAB> <TAB> hMenu = self.handle <TAB> n = user32.GetMenuItemCount(hMenu) <TAB> mi = MENUITEMINFO() <TAB> for i in range(n): <TAB> <TAB> mi.fMask = 2  #  MIIM_ID <TAB> <TAB> user32.GetMenuItemInfoA(hMenu, i, 1, byref(mi)) <TAB> <TAB> handle = user32.GetSubMenu(hMenu, i) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield handle, self.ListItems(handle) <TAB> <TAB> <TAB> for i in self.Walk(handle): <TAB> <TAB> <TAB> <TAB> yield i",true,if handle :,if handle :,0.53,0.0
"def setSelection(self, labels): <TAB> input = self.__validateInput(labels) <TAB> if len(input) == 0 and not self.__allowEmptySelection: <TAB> <TAB> return <TAB> if self.__allowMultipleSelection: <TAB> <TAB> self.__selectedLabels[:] = input <TAB> <TAB> self.__selectionChanged() <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError( <TAB> <TAB> <TAB> <TAB> ""Parameter must be single item or a list with one element."" <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.__selectedLabels[:] = input <TAB> <TAB> <TAB> self.__selectionChanged() <TAB> # Remove all selected labels that are not in the menu, emit signals if necessary and update the button. <TAB> self.__validateState()",false,if len ( input ) > 1 :,if len ( input ) != 1 :,0.55,0.0
"def _parse(self, engine): <TAB> """"""Parse the layer."""""" <TAB> if isinstance(self.args, dict): <TAB> <TAB> if ""axis"" in self.args: <TAB> <TAB> <TAB> self.axis = engine.evaluate(self.args[""axis""], recursive=True) <TAB> <TAB> <TAB> if not isinstance(self.axis, int): <TAB> <TAB> <TAB> <TAB> raise ParsingError('""axis"" must be an integer.') <TAB> <TAB> if ""momentum"" in self.args: <TAB> <TAB> <TAB> self.momentum = engine.evaluate(self.args[""momentum""], recursive=True) <TAB> <TAB> <TAB> if not isinstance(self.momentum, (int, float)): <TAB> <TAB> <TAB> <TAB> raise ParsingError('""momentum"" must be numeric.')",false,"if not isinstance ( self . momentum , ( int , float ) ) :","if not isinstance ( self . axis , int ) :",0.3,0.0
"def get_order(self, aBuf): <TAB> if not aBuf: <TAB> <TAB> return -1, 1 <TAB> # find out current char's byte length <TAB> first_char = wrap_ord(aBuf[0]) <TAB> if (0x81 <= first_char <= 0x9F) or (0xE0 <= first_char <= 0xFC): <TAB> <TAB> charLen = 2 <TAB> else: <TAB> <TAB> charLen = 1 <TAB> # return its order if it is hiragana <TAB> if len(aBuf) > 1: <TAB> <TAB> second_char = wrap_ord(aBuf[1]) <TAB> <TAB> if (first_char == 202) and (0x9F <= second_char <= 0xF1): <TAB> <TAB> <TAB> return second_char - 0x9F, charLen <TAB> return -1, charLen",true,if ( first_char == 202 ) and ( 0x9F <= second_char <= 0xF1 ) :,if ( first_char == 202 ) and ( 0x9F <= second_char <= 0xF1 ) :,0.75,0.0
"def saveSpecial(self, **kwargs): <TAB> for kw in SPECIAL_BOOL_LIST + SPECIAL_VALUE_LIST + SPECIAL_LIST_LIST: <TAB> <TAB> item = config.get_config(""misc"", kw) <TAB> <TAB> value = kwargs.get(kw) <TAB> <TAB> msg = item.set(value) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return badParameterResponse(msg) <TAB> config.save_config() <TAB> raise Raiser(self.__root)",true,if msg :,if msg :,0.53,0.0
"def sanitize_event_keys(kwargs, valid_keys): <TAB> # Sanity check: Don't honor keys that we don't recognize. <TAB> for key in list(kwargs.keys()): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> kwargs.pop(key) <TAB> # Truncate certain values over 1k <TAB> for key in [""play"", ""role"", ""task"", ""playbook""]: <TAB> <TAB> if isinstance(kwargs.get(""event_data"", {}).get(key), str): <TAB> <TAB> <TAB> if len(kwargs[""event_data""][key]) > 1024: <TAB> <TAB> <TAB> <TAB> kwargs[""event_data""][key] = Truncator(kwargs[""event_data""][key]).chars( <TAB> <TAB> <TAB> <TAB> <TAB> 1024 <TAB> <TAB> <TAB> <TAB> )",false,if key not in valid_keys :,if key in valid_keys :,0.23,0.0
"def toggleFactorReload(self, value=None): <TAB> self.serviceFittingOptions[""useGlobalForceReload""] = ( <TAB> <TAB> value <TAB> <TAB> if value is not None <TAB> <TAB> else not self.serviceFittingOptions[""useGlobalForceReload""] <TAB> ) <TAB> fitIDs = set() <TAB> for fit in set(self._loadedFits): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if fit.calculated: <TAB> <TAB> <TAB> fit.factorReload = self.serviceFittingOptions[""useGlobalForceReload""] <TAB> <TAB> <TAB> fit.clearFactorReloadDependentData() <TAB> <TAB> <TAB> fitIDs.add(fit.ID) <TAB> return fitIDs",true,if fit is None :,if fit is None :,0.75,0.0
"def closest_unseen(self, row1, col1, filter=None): <TAB> # find the closest unseen from this row/col <TAB> min_dist = maxint <TAB> closest_unseen = None <TAB> for row in range(self.height): <TAB> <TAB> for col in range(self.width): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if self.map[row][col] == UNSEEN: <TAB> <TAB> <TAB> <TAB> <TAB> dist = self.distance(row1, col1, row, col) <TAB> <TAB> <TAB> <TAB> <TAB> if dist < min_dist: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> min_dist = dist <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> closest_unseen = (row, col) <TAB> return closest_unseen",false,"if filter is None or ( row , col ) not in filter :","if filter is None or filter [ row , col ] == UNSEEN :",0.35,0.0
"def getAlphaClone(lookfor, eager=None): <TAB> if isinstance(lookfor, int): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> item = get_gamedata_session().query(AlphaClone).get(lookfor) <TAB> <TAB> else: <TAB> <TAB> <TAB> item = ( <TAB> <TAB> <TAB> <TAB> get_gamedata_session() <TAB> <TAB> <TAB> <TAB> .query(AlphaClone) <TAB> <TAB> <TAB> <TAB> .options(*processEager(eager)) <TAB> <TAB> <TAB> <TAB> .filter(AlphaClone.ID == lookfor) <TAB> <TAB> <TAB> <TAB> .first() <TAB> <TAB> <TAB> ) <TAB> else: <TAB> <TAB> raise TypeError(""Need integer as argument"") <TAB> return item",true,if eager is None :,if eager is None :,0.75,0.0
"def _rle_encode(string): <TAB> new = b"""" <TAB> count = 0 <TAB> for cur in string: <TAB> <TAB> if not cur: <TAB> <TAB> <TAB> count += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> new += b""\0"" + bytes([count]) <TAB> <TAB> <TAB> <TAB> count = 0 <TAB> <TAB> <TAB> new += bytes([cur]) <TAB> return new",true,if count :,if count :,0.53,0.0
def result_iterator(): <TAB> try: <TAB> <TAB> for future in fs: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> yield future.result() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> yield future.result(end_time - time.time()) <TAB> finally: <TAB> <TAB> for future in fs: <TAB> <TAB> <TAB> future.cancel(),false,if timeout is None :,if end_time is None :,0.39,0.0
"def _individual_get(self, segment, index_type, index, strictdoc): <TAB> if index_type == ""val"": <TAB> <TAB> for key, value in segment.items(): <TAB> <TAB> <TAB> if key == index[0]: <TAB> <TAB> <TAB> <TAB> return value <TAB> <TAB> <TAB> if hasattr(key, ""text""): <TAB> <TAB> <TAB> <TAB> if key.text == index[0]: <TAB> <TAB> <TAB> <TAB> <TAB> return value <TAB> <TAB> raise Exception(""Invalid state"") <TAB> elif index_type == ""index"": <TAB> <TAB> return segment[index] <TAB> elif index_type == ""textslice"": <TAB> <TAB> return segment[index[0] : index[1]] <TAB> elif index_type == ""key"": <TAB> <TAB> return index[1] if strictdoc else index[0] <TAB> else: <TAB> <TAB> raise Exception(""Invalid state"")",true,if key == index [ 0 ] :,if key == index [ 0 ] :,0.75,0.0
"def _reset_sequences(self, db_name): <TAB> conn = connections[db_name] <TAB> if conn.features.supports_sequence_reset: <TAB> <TAB> sql_list = conn.ops.sequence_reset_by_name_sql( <TAB> <TAB> <TAB> no_style(), conn.introspection.sequence_list() <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> cursor = conn.cursor() <TAB> <TAB> <TAB> <TAB> for sql in sql_list: <TAB> <TAB> <TAB> <TAB> <TAB> cursor.execute(sql) <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> transaction.rollback_unless_managed(using=db_name) <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> transaction.commit_unless_managed(using=db_name)",true,if sql_list :,if sql_list :,0.53,0.0
"def translate_to_statements(self, statements, conditional_write_vars): <TAB> lines = [] <TAB> for stmt in statements: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.temporary_vars.add((stmt.var, stmt.dtype)) <TAB> <TAB> line = self.translate_statement(stmt) <TAB> <TAB> if stmt.var in conditional_write_vars: <TAB> <TAB> <TAB> subs = {} <TAB> <TAB> <TAB> condvar = conditional_write_vars[stmt.var] <TAB> <TAB> <TAB> lines.append(""if %s:"" % condvar) <TAB> <TAB> <TAB> lines.append(indent(line)) <TAB> <TAB> else: <TAB> <TAB> <TAB> lines.append(line) <TAB> return lines",false,"if stmt . op == "":="" and not stmt . var in self . variables :",if stmt . var not in self . temporary_vars :,0.19,0.0
"def _bytecode_filenames(self, py_filenames): <TAB> bytecode_files = [] <TAB> for py_file in py_filenames: <TAB> <TAB> # Since build_py handles package data installation, the <TAB> <TAB> # list of outputs can contain more than just .py files. <TAB> <TAB> # Make sure we only report bytecode for the .py files. <TAB> <TAB> ext = os.path.splitext(os.path.normcase(py_file))[1] <TAB> <TAB> if ext != PYTHON_SOURCE_EXTENSION: <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> bytecode_files.append(py_file + ""c"") <TAB> <TAB> if self.optimize > 0: <TAB> <TAB> <TAB> bytecode_files.append(py_file + ""o"") <TAB> return bytecode_files",false,if self . compile :,if self . optimize > 0 :,0.12,0.0
"def logic(): <TAB> for i in range(100): <TAB> <TAB> yield clock.posedge, reset.negedge <TAB> <TAB> if reset == ACTIVE_LOW: <TAB> <TAB> <TAB> count.next = 0 <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> count.next = (count + 1) % n <TAB> raise StopSimulation",false,if enable :,if reset == ACTIVE_HIGH :,0.05,0.0
"def _is_subnet_of(a, b): <TAB> try: <TAB> <TAB> # Always false if one is v4 and the other is v6. <TAB> <TAB> if a._version != b._version: <TAB> <TAB> <TAB> raise TypeError(""%s and %s are not of the same version"" % (a, b)) <TAB> <TAB> return ( <TAB> <TAB> <TAB> b.network_address <= a.network_address <TAB> <TAB> <TAB> and b.broadcast_address >= a.broadcast_address <TAB> <TAB> ) <TAB> except AttributeError: <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> ""Unable to test subnet containment "" ""between %s and %s"" % (a, b) <TAB> <TAB> )",true,if a . _version != b . _version :,if a . _version != b . _version :,1.0,0.0
"def _filter_paths(basename, path, is_dir, exclude): <TAB> """""".gitignore style file filtering."""""" <TAB> for item in exclude: <TAB> <TAB> # Items ending in '/' apply only to directories. <TAB> <TAB> if item.endswith(""/"") and not is_dir: <TAB> <TAB> <TAB> continue <TAB> <TAB> # Items starting with '/' apply to the whole path. <TAB> <TAB> # In any other cases just the basename is used. <TAB> <TAB> match = path if item.startswith(""/"") else basename <TAB> <TAB> if fnmatch.fnmatch(match, item.strip(""/"")): <TAB> <TAB> <TAB> return True <TAB> return False",true,"if fnmatch . fnmatch ( match , item . strip ( ""/"" ) ) :","if fnmatch . fnmatch ( match , item . strip ( ""/"" ) ) :",1.0,0.0
"def __recv_null(self): <TAB> """"""Receive a null byte."""""" <TAB> while 1: <TAB> <TAB> c = self.sock.recv(1) <TAB> <TAB> if c == """": <TAB> <TAB> <TAB> self.close() <TAB> <TAB> <TAB> raise EOFError(""Socket Closed"") <TAB> <TAB> if c == ""\0"": <TAB> <TAB> <TAB> return",true,"if c == ""\0"" :","if c == ""\0"" :",0.75,0.0
"def onMessage(self, payload, isBinary): <TAB> if isBinary: <TAB> <TAB> self.result = ""Expected text message with payload, but got binary."" <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.result = ( <TAB> <TAB> <TAB> <TAB> ""Expected text message with payload of length %d, but got %d."" <TAB> <TAB> <TAB> <TAB> % (self.DATALEN, len(payload)) <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> ## FIXME : check actual content <TAB> <TAB> <TAB> ## <TAB> <TAB> <TAB> self.behavior = Case.OK <TAB> <TAB> <TAB> self.result = ""Received text message of length %d."" % len(payload) <TAB> self.p.createWirelog = True <TAB> self.p.sendClose(self.p.CLOSE_STATUS_CODE_NORMAL)",false,if len ( payload ) != self . DATALEN :,if self . DATALEN != 0 :,0.06,0.0
"def rename_path(self, path, new_path): <TAB> logger.debug(""rename_path '%s' -> '%s'"" % (path, new_path)) <TAB> dirs = self.readdir(path) <TAB> for d in dirs: <TAB> <TAB> if d in [""."", ""..""]: <TAB> <TAB> <TAB> continue <TAB> <TAB> d_path = """".join([path, ""/"", d]) <TAB> <TAB> d_new_path = """".join([new_path, ""/"", d]) <TAB> <TAB> attr = self.getattr(d_path) <TAB> <TAB> if stat.S_ISDIR(attr[""st_mode""]): <TAB> <TAB> <TAB> self.rename_path(d_path, d_new_path) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.rename_item(d_path, d_new_path) <TAB> self.rename_item(path, new_path, dir=True)",false,"if d in [ ""."" , "".."" ] :","if stat . S_ISDIR ( attr [ ""st_mode"" ] ) :",0.02,0.0
"def dir_box_click(self, double): <TAB> if double: <TAB> <TAB> name = self.list_box.get_selected_name() <TAB> <TAB> path = os.path.join(self.directory, name) <TAB> <TAB> suffix = os.path.splitext(name)[1] <TAB> <TAB> if suffix not in self.suffixes and os.path.isdir(path): <TAB> <TAB> <TAB> self.directory = path <TAB> <TAB> else: <TAB> <TAB> <TAB> self.double_click_file(name) <TAB> self.update()",true,if suffix not in self . suffixes and os . path . isdir ( path ) :,if suffix not in self . suffixes and os . path . isdir ( path ) :,1.0,0.0
"def __getattr__(self, key): <TAB> try: <TAB> <TAB> value = self.__parent.contents[key] <TAB> except KeyError: <TAB> <TAB> pass <TAB> else: <TAB> <TAB> if value is not None: <TAB> <TAB> <TAB> if isinstance(value, _ModuleMarker): <TAB> <TAB> <TAB> <TAB> return value.mod_ns <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> assert isinstance(value, _MultipleClassMarker) <TAB> <TAB> <TAB> <TAB> return value.attempt_get(self.__parent.path, key) <TAB> raise AttributeError( <TAB> <TAB> ""Module %r has no mapped classes "" <TAB> <TAB> ""registered under the name %r"" % (self.__parent.name, key) <TAB> )",true,"if isinstance ( value , _ModuleMarker ) :","if isinstance ( value , _ModuleMarker ) :",0.75,0.0
"def poll_thread(): <TAB> time.sleep(0.5) <TAB> if process.wait() and process_state: <TAB> <TAB> time.sleep(0.25) <TAB> <TAB> if not check_global_interrupt(): <TAB> <TAB> <TAB> stdout, stderr = process._communicate(None) <TAB> <TAB> <TAB> logger.error( <TAB> <TAB> <TAB> <TAB> ""Web server process exited unexpectedly"", <TAB> <TAB> <TAB> <TAB> ""app"", <TAB> <TAB> <TAB> <TAB> stdout=stdout, <TAB> <TAB> <TAB> <TAB> stderr=stderr, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> time.sleep(1) <TAB> <TAB> <TAB> restart_server(1)",true,if not check_global_interrupt ( ) :,if not check_global_interrupt ( ) :,0.75,0.0
"def apply_dateparser_timezone(utc_datetime, offset_or_timezone_abb): <TAB> for name, info in _tz_offsets: <TAB> <TAB> if info[""regex""].search("" %s"" % offset_or_timezone_abb): <TAB> <TAB> <TAB> tz = StaticTzInfo(name, info[""offset""]) <TAB> <TAB> <TAB> return utc_datetime.astimezone(tz)",false,"if info [ ""regex"" ] . search ( "" %s"" % offset_or_timezone_abb ) :","if info [ ""regex"" ] . search ( ""%s"" % offset_or_timezone_abb ) :",0.6,0.0
"def _load_wordlist(filename): <TAB> if filename is None: <TAB> <TAB> return {} <TAB> path = None <TAB> for dir in (CONFIG_DIR, ASSETS_DIR): <TAB> <TAB> path = os.path.realpath(os.path.join(dir, filename)) <TAB> <TAB> if os.path.exists(path): <TAB> <TAB> <TAB> break <TAB> words = {} <TAB> with open(path, encoding=""utf-8"") as f: <TAB> <TAB> pairs = [word.strip().rsplit("" "", 1) for word in f] <TAB> <TAB> pairs.sort(reverse=True, key=lambda x: int(x[1])) <TAB> <TAB> words = {p[0]: int(p[1]) for p in pairs} <TAB> return words",true,if os . path . exists ( path ) :,if os . path . exists ( path ) :,1.0,0.0
"def terminate_processes_matching_names(match_strings, kill=False): <TAB> """"""Terminates processes matching particular names (case sensitive)."""""" <TAB> if isinstance(match_strings, str): <TAB> <TAB> match_strings = [match_strings] <TAB> for process in psutil.process_iter(): <TAB> <TAB> try: <TAB> <TAB> <TAB> process_info = process.as_dict(attrs=[""name"", ""pid""]) <TAB> <TAB> <TAB> process_name = process_info[""name""] <TAB> <TAB> except (psutil.AccessDenied, psutil.NoSuchProcess, OSError): <TAB> <TAB> <TAB> continue <TAB> <TAB> if any(x == process_name for x in match_strings): <TAB> <TAB> <TAB> terminate_process(process_info[""pid""], kill)",true,if any ( x == process_name for x in match_strings ) :,if any ( x == process_name for x in match_strings ) :,1.0,0.0
"def has_scheme(self, inp): <TAB> if ""://"" in inp: <TAB> <TAB> return True <TAB> else: <TAB> <TAB> authority = inp.replace(""/"", ""#"").replace(""?"", ""#"").split(""#"")[0] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> _, host_or_port = authority.split("":"", 1) <TAB> <TAB> <TAB> # Assert it's not a port number <TAB> <TAB> <TAB> if re.match(r""^\d+$"", host_or_port): <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> else: <TAB> <TAB> <TAB> return False <TAB> return True",true,"if "":"" in authority :","if "":"" in authority :",0.75,0.0
"def close(self): <TAB> with BrowserContext._BROWSER_LOCK: <TAB> <TAB> BrowserContext._BROWSER_REFCNT -= 1 <TAB> <TAB> if BrowserContext._BROWSER_REFCNT == 0: <TAB> <TAB> <TAB> logger.info(""Destroying browser main loop"") <TAB> <TAB> <TAB> BrowserContext._BROWSER_LOOP.destroy() <TAB> <TAB> <TAB> BrowserContext._BROWSER_LOOP = None",true,if BrowserContext . _BROWSER_REFCNT == 0 :,if BrowserContext . _BROWSER_REFCNT == 0 :,0.75,0.0
"def _mock_get_merge_ticks(self, order_book_id_list, trading_date, last_dt=None): <TAB> for tick in self._ticks: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if ( <TAB> <TAB> <TAB> self.env.data_proxy.get_future_trading_date(tick.datetime).date() <TAB> <TAB> <TAB> != trading_date.date() <TAB> <TAB> ): <TAB> <TAB> <TAB> continue <TAB> <TAB> if last_dt and tick.datetime <= last_dt: <TAB> <TAB> <TAB> continue <TAB> <TAB> yield tick",false,if tick . order_book_id not in order_book_id_list :,if not tick . order_book_id_list or tick . order_book_id_list != order_book_id_list :,0.12,0.0
"def messageSourceStamps(self, source_stamps): <TAB> text = """" <TAB> for ss in source_stamps: <TAB> <TAB> source = """" <TAB> <TAB> if ss[""branch""]: <TAB> <TAB> <TAB> source += ""[branch %s] "" % ss[""branch""] <TAB> <TAB> if ss[""revision""]: <TAB> <TAB> <TAB> source += str(ss[""revision""]) <TAB> <TAB> else: <TAB> <TAB> <TAB> source += ""HEAD"" <TAB> <TAB> if ss[""patch""] is not None: <TAB> <TAB> <TAB> source += "" (plus patch)"" <TAB> <TAB> discriminator = """" <TAB> <TAB> if ss[""codebase""]: <TAB> <TAB> <TAB> discriminator = "" '%s'"" % ss[""codebase""] <TAB> <TAB> text += ""Build Source Stamp%s: %s\n"" % (discriminator, source) <TAB> return text",true,"if ss [ ""branch"" ] :","if ss [ ""branch"" ] :",0.75,0.0
"def test_open_read_bytes(self, sftp): <TAB> """"""Test reading bytes from a file"""""" <TAB> f = None <TAB> try: <TAB> <TAB> self._create_file(""file"", ""xxx"") <TAB> <TAB> f = yield from sftp.open(""file"", ""rb"") <TAB> <TAB> self.assertEqual((yield from f.read()), b""xxx"") <TAB> finally: <TAB> <TAB><IF-STMT>  # pragma: no branch <TAB> <TAB> <TAB> yield from f.close() <TAB> <TAB> remove(""file"")",true,if f :,if f :,0.53,0.0
"def handler(chan, host, port): <TAB> sock = socket() <TAB> try: <TAB> <TAB> sock.connect((host, port)) <TAB> except Exception as e: <TAB> <TAB> if verbose == True: <TAB> <TAB> <TAB> print(e) <TAB> <TAB> return <TAB> while True: <TAB> <TAB> r, w, x = select.select([sock, chan], [], []) <TAB> <TAB> if sock in r: <TAB> <TAB> <TAB> data = sock.recv(1024) <TAB> <TAB> <TAB> if len(data) == 0: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> chan.send(data) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> data = chan.recv(1024) <TAB> <TAB> <TAB> if len(data) == 0: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> sock.send(data) <TAB> chan.close() <TAB> sock.close()",false,if chan in r :,if w :,0.04,0.0
"def detect(get_page): <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS: <TAB> <TAB> page, headers, code = get_page(get=vector) <TAB> <TAB> retval = re.search(r""url\('/ks-waf-error\.png'\)"", page, re.I) is not None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> return retval",true,if retval :,if retval :,0.53,0.0
"def __init__(self, raw): <TAB> ticker_ticks = {} <TAB> for tick in raw[""results""]: <TAB> <TAB> if ticker_ticks.get(tick[""T""]): <TAB> <TAB> <TAB> ticker_ticks[tick[""T""]].append(tick) <TAB> <TAB> else: <TAB> <TAB> <TAB> ticker_ticks[tick[""T""]] = [tick] <TAB> super().__init__( <TAB> <TAB> {ticker: Aggsv2({""results"": ticks}) for ticker, ticks in ticker_ticks.items()} <TAB> )",true,"if ticker_ticks . get ( tick [ ""T"" ] ) :","if ticker_ticks . get ( tick [ ""T"" ] ) :",0.75,0.0
"def _makefiles(self, f): <TAB> if isinstance(f, dict): <TAB> <TAB> for k, v in list(f.items()): <TAB> <TAB> <TAB> if isinstance(v, list): <TAB> <TAB> <TAB> <TAB> self.makedir(dirname=k, content=v) <TAB> <TAB> <TAB> elif isinstance(v, str): <TAB> <TAB> <TAB> <TAB> self.make_file(filename=k, content=v) <TAB> <TAB> <TAB> else:  # pragma: nocover <TAB> <TAB> <TAB> <TAB> raise ValueError(""Unexpected:"", k, v) <TAB> elif isinstance(f, str): <TAB> <TAB> self._make_empty_file(f) <TAB> elif isinstance(f, list): <TAB> <TAB> self.make_list(f) <TAB> else:  # pragma: nocover <TAB> <TAB> raise ValueError(""Unknown type:"", f)",false,"if isinstance ( v , list ) :","elif isinstance ( v , str ) :",0.2,0.0
"def migrate_command_storage(apps, schema_editor): <TAB> model = apps.get_model(""terminal"", ""CommandStorage"") <TAB> init_storage_data(model) <TAB> setting = get_setting(apps, schema_editor, ""TERMINAL_COMMAND_STORAGE"") <TAB> if not setting: <TAB> <TAB> return <TAB> values = get_storage_data(setting) <TAB> for name, meta in values.items(): <TAB> <TAB> tp = meta.pop(""TYPE"") <TAB> <TAB> if not tp or name in [""default"", ""null""]: <TAB> <TAB> <TAB> continue <TAB> <TAB> model.objects.create(name=name, type=tp, meta=meta)",true,"if not tp or name in [ ""default"" , ""null"" ] :","if not tp or name in [ ""default"" , ""null"" ] :",0.75,0.0
"def build_vertices(self, ulines): <TAB> vertex_idx = 0 <TAB> vertices = collections.OrderedDict() <TAB> for line in ulines: <TAB> <TAB> for vt in line: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_vertex = (vt.u, vt.v, 0.0) <TAB> <TAB> <TAB> if new_vertex in vertices: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> vt.index = vertex_idx <TAB> <TAB> <TAB> vertex_idx += 1 <TAB> <TAB> <TAB> vertices[new_vertex] = 1 <TAB> return vertex_idx, list(vertices.keys())",false,if vt . replacement is not None :,if vt . index == vertex_idx :,0.08,0.0
"def get_quarantine_count(self): <TAB> """"""get obj/container/account quarantine counts"""""" <TAB> qcounts = {""objects"": 0, ""containers"": 0, ""accounts"": 0} <TAB> qdir = ""quarantined"" <TAB> for device in os.listdir(self.devices): <TAB> <TAB> for qtype in qcounts: <TAB> <TAB> <TAB> qtgt = os.path.join(self.devices, device, qdir, qtype) <TAB> <TAB> <TAB> if os.path.exists(qtgt): <TAB> <TAB> <TAB> <TAB> linkcount = os.lstat(qtgt).st_nlink <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> qcounts[qtype] += linkcount - 2 <TAB> return qcounts",true,if linkcount > 2 :,if linkcount > 2 :,0.75,0.0
"def _format_arg(self, name, trait_spec, value): <TAB> if name == ""mask_file"": <TAB> <TAB> return """" <TAB> if name == ""op_string"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if isdefined(self.inputs.mask_file): <TAB> <TAB> <TAB> <TAB> return self.inputs.op_string % self.inputs.mask_file <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise ValueError(""-k %s option in op_string requires mask_file"") <TAB> return super(ImageStats, self)._format_arg(name, trait_spec, value)",false,"if ""-k %s"" in self . inputs . op_string :",if self . inputs . mask_file :,0.15,0.0
"def _update_theme_style(self, *args): <TAB> self.line_color_normal = self.theme_cls.divider_color <TAB> if not any([self.error, self._text_len_error]): <TAB> <TAB> if not self.focus: <TAB> <TAB> <TAB> self._current_hint_text_color = self.theme_cls.disabled_hint_text_color <TAB> <TAB> <TAB> self._current_right_lbl_color = self.theme_cls.disabled_hint_text_color <TAB> <TAB> <TAB> if self.helper_text_mode == ""persistent"": <TAB> <TAB> <TAB> <TAB> self._current_error_color = self.theme_cls.disabled_hint_text_color",true,"if self . helper_text_mode == ""persistent"" :","if self . helper_text_mode == ""persistent"" :",0.75,0.0
"def createFields(self): <TAB> for item in self.format: <TAB> <TAB> if isinstance(item[-1], dict): <TAB> <TAB> <TAB> yield item[0](self, *item[1:-1], **item[-1]) <TAB> <TAB> else: <TAB> <TAB> <TAB> yield item[0](self, *item[1:])",true,"if isinstance ( item [ - 1 ] , dict ) :","if isinstance ( item [ - 1 ] , dict ) :",0.75,0.0
"def execute(self, statement, arguments=None): <TAB> while True: <TAB> <TAB> try: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.cursor.execute(statement, arguments) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.cursor.execute(statement) <TAB> <TAB> except sqlite3.OperationalError as ex: <TAB> <TAB> <TAB> if ""locked"" not in getSafeExString(ex): <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> else: <TAB> <TAB> <TAB> break <TAB> if statement.lstrip().upper().startswith(""SELECT""): <TAB> <TAB> return self.cursor.fetchall()",true,if arguments :,if arguments :,0.53,0.0
"def set_income_account_for_fixed_assets(self): <TAB> disposal_account = depreciation_cost_center = None <TAB> for d in self.get(""items""): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if not disposal_account: <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> disposal_account, <TAB> <TAB> <TAB> <TAB> <TAB> depreciation_cost_center, <TAB> <TAB> <TAB> <TAB> ) = get_disposal_account_and_cost_center(self.company) <TAB> <TAB> <TAB> d.income_account = disposal_account <TAB> <TAB> <TAB> if not d.cost_center: <TAB> <TAB> <TAB> <TAB> d.cost_center = depreciation_cost_center",false,if d . is_fixed_asset :,if d . income_account :,0.39,0.0
"def _convertNbCharsInNbBits(self, nbChars): <TAB> nbMinBit = None <TAB> nbMaxBit = None <TAB> if nbChars is not None: <TAB> <TAB> if isinstance(nbChars, int): <TAB> <TAB> <TAB> nbMinBit = nbChars * 8 <TAB> <TAB> <TAB> nbMaxBit = nbMinBit <TAB> <TAB> else: <TAB> <TAB> <TAB> if nbChars[0] is not None: <TAB> <TAB> <TAB> <TAB> nbMinBit = nbChars[0] * 8 <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> nbMaxBit = nbChars[1] * 8 <TAB> return (nbMinBit, nbMaxBit)",true,if nbChars [ 1 ] is not None :,if nbChars [ 1 ] is not None :,0.75,0.0
"def _get_service_full_name(self, name, help_command_table): <TAB> if help_command_table and name not in self._NON_SERVICE_COMMANDS: <TAB> <TAB> if name in self._HIGH_LEVEL_SERVICE_FULL_NAMES: <TAB> <TAB> <TAB> return self._HIGH_LEVEL_SERVICE_FULL_NAMES[name] <TAB> <TAB> service = help_command_table.get(name) <TAB> <TAB> if service: <TAB> <TAB> <TAB> return service.service_model.metadata[""serviceFullName""]",true,if name in self . _HIGH_LEVEL_SERVICE_FULL_NAMES :,if name in self . _HIGH_LEVEL_SERVICE_FULL_NAMES :,0.75,0.0
"def print_addresses(self): <TAB> p = 3 <TAB> tmp_str = ""["" <TAB> if self.get_len() >= 7:  # at least one complete IP address <TAB> <TAB> while 1: <TAB> <TAB> <TAB> if p + 1 == self.get_ptr(): <TAB> <TAB> <TAB> <TAB> tmp_str += ""#"" <TAB> <TAB> <TAB> tmp_str += self.get_ip_address(p) <TAB> <TAB> <TAB> p += 4 <TAB> <TAB> <TAB> if p >= self.get_len(): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> tmp_str += "", "" <TAB> tmp_str += ""] "" <TAB> if self.get_ptr() % 4:  # ptr field should be a multiple of 4 <TAB> <TAB> tmp_str += ""nonsense ptr field: %d "" % self.get_ptr() <TAB> return tmp_str",false,if p + 1 == self . get_ptr ( ) :,if p >= self . get_len ( ) :,0.15,0.0
"def run(self): <TAB> for _ in range(self.n): <TAB> <TAB> error = True <TAB> <TAB> try: <TAB> <TAB> <TAB> self.collection.insert_one({""test"": ""insert""}) <TAB> <TAB> <TAB> error = False <TAB> <TAB> except: <TAB> <TAB> <TAB> if not self.expect_exception: <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> assert error",false,if self . expect_exception :,if error :,0.04,0.0
"def create_composite_mounter_by_args(args): <TAB> """"""Creates a CompositeMounter by the images in given args."""""" <TAB> logging.info(""Mount images..."") <TAB> mounter = composite_mounter.CompositeMounter() <TAB> for partition in composite_mounter.SUPPORTED_PARTITIONS: <TAB> <TAB> image_source = vars(args)[partition] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> logging.info(""  %s=%s"", partition, image_source) <TAB> <TAB> <TAB> mounter.add_by_mount_target(partition, image_source) <TAB> if mounter.is_empty(): <TAB> <TAB> raise RuntimeError(""Must give at least one image source."") <TAB> return mounter",true,if image_source :,if image_source :,0.53,0.0
"def _get_containing_class(self, pyname): <TAB> if isinstance(pyname, pynames.DefinedName): <TAB> <TAB> scope = pyname.get_object().get_scope() <TAB> <TAB> parent = scope.parent <TAB> <TAB> if parent is not None and parent.get_kind() == ""Class"": <TAB> <TAB> <TAB> return parent.pyobject",true,"if parent is not None and parent . get_kind ( ) == ""Class"" :","if parent is not None and parent . get_kind ( ) == ""Class"" :",0.75,0.0
"def test_chunkcoding(self): <TAB> tstring_lines = [] <TAB> for b in self.tstring: <TAB> <TAB> lines = b.split(b""\n"") <TAB> <TAB> last = lines.pop() <TAB> <TAB> assert last == b"""" <TAB> <TAB> lines = [line + b""\n"" for line in lines] <TAB> <TAB> tstring_lines.append(lines) <TAB> for native, utf8 in zip(*tstring_lines): <TAB> <TAB> u = self.decode(native)[0] <TAB> <TAB> self.assertEqual(u, utf8.decode(""utf-8"")) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.assertEqual(native, self.encode(u)[0])",false,if self . roundtriptest :,if u :,0.04,0.0
"def set_default_variants(apps, schema_editor): <TAB> Product = apps.get_model(""product"", ""Product"") <TAB> for product in Product.objects.iterator(): <TAB> <TAB> first_variant = product.variants.first() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> product.default_variant = first_variant <TAB> <TAB> <TAB> product.save(update_fields=[""default_variant"", ""updated_at""])",true,if first_variant :,if first_variant :,0.53,0.0
"def json(self): <TAB> try: <TAB> <TAB> if self.is_json(): <TAB> <TAB> <TAB> raw_data = self.raw_data() <TAB> <TAB> <TAB> if not isinstance(raw_data, text_type): <TAB> <TAB> <TAB> <TAB> raw_data = raw_data.decode(""utf-8"") <TAB> <TAB> <TAB> return json.loads(raw_data) <TAB> except ValueError: <TAB> <TAB> pass",false,"if not isinstance ( raw_data , text_type ) :",if self . is_json ( ) :,0.03,0.0
"def clear_react(self, message: discord.Message, emoji: MutableMapping = None) -> None: <TAB> try: <TAB> <TAB> await message.clear_reactions() <TAB> except discord.Forbidden: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> with contextlib.suppress(discord.HTTPException): <TAB> <TAB> <TAB> async for key in AsyncIter(emoji.values(), delay=0.2): <TAB> <TAB> <TAB> <TAB> await message.remove_reaction(key, self.bot.user) <TAB> except discord.HTTPException: <TAB> <TAB> return",false,if not emoji :,if self . bot . user . is_authenticated :,0.03,0.0
"def check(self, value): <TAB> value = String.check(self, value) <TAB> if isinstance(value, str): <TAB> <TAB> value = value.upper() <TAB> <TAB> for prefix in (self.prefix, self.prefix.split(""_"", 1)[1]): <TAB> <TAB> <TAB> # e.g. PANGO_WEIGHT_BOLD --> BOLD but also WEIGHT_BOLD --> BOLD <TAB> <TAB> <TAB> if value.startswith(prefix): <TAB> <TAB> <TAB> <TAB> value = value[len(prefix) :] <TAB> <TAB> <TAB> value = value.lstrip(""_"") <TAB> <TAB> if hasattr(self.group, value): <TAB> <TAB> <TAB> return getattr(self.group, value) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""No such constant: %s_%s"" % (self.prefix, value)) <TAB> else: <TAB> <TAB> return value",false,"if hasattr ( self . group , value ) :",if value . startswith ( prefix ) :,0.03,0.0
"def value(self): <TAB> quote = False <TAB> if self.defects: <TAB> <TAB> quote = True <TAB> else: <TAB> <TAB> for x in self: <TAB> <TAB> <TAB> if x.token_type == ""quoted-string"": <TAB> <TAB> <TAB> <TAB> quote = True <TAB> if quote: <TAB> <TAB> pre = post = """" <TAB> <TAB> if self[0].token_type == ""cfws"" or self[0][0].token_type == ""cfws"": <TAB> <TAB> <TAB> pre = "" "" <TAB> <TAB> if self[-1].token_type == ""cfws"" or self[-1][-1].token_type == ""cfws"": <TAB> <TAB> <TAB> post = "" "" <TAB> <TAB> return pre + quote_string(self.display_name) + post <TAB> else: <TAB> <TAB> return super(DisplayName, self).value",false,"if self [ - 1 ] . token_type == ""cfws"" or self [ - 1 ] [ - 1 ] . token_type == ""cfws"" :","if self [ 0 ] . token_type == ""cfws"" or self [ 0 ] [ 0 ] . token_type == ""cfws"" :",0.63,0.0
"def get_drive(self, root_path="""", volume_guid_path=""""): <TAB> for drive in self.drives: <TAB> <TAB> if root_path: <TAB> <TAB> <TAB> config_root_path = drive.get(""root_path"") <TAB> <TAB> <TAB> if config_root_path and root_path == config_root_path: <TAB> <TAB> <TAB> <TAB> return drive <TAB> <TAB> elif volume_guid_path: <TAB> <TAB> <TAB> config_volume_guid_path = drive.get(""volume_guid_path"") <TAB> <TAB> <TAB> if config_volume_guid_path and config_volume_guid_path == volume_guid_path: <TAB> <TAB> <TAB> <TAB> return drive",true,elif volume_guid_path :,elif volume_guid_path :,0.51,0.0
"def parse_edges(self, pcb): <TAB> edges = [] <TAB> drawings = list(pcb.GetDrawings()) <TAB> bbox = None <TAB> for m in pcb.GetModules(): <TAB> <TAB> for g in m.GraphicalItems(): <TAB> <TAB> <TAB> drawings.append(g) <TAB> for d in drawings: <TAB> <TAB> if d.GetLayer() == pcbnew.Edge_Cuts: <TAB> <TAB> <TAB> parsed_drawing = self.parse_drawing(d) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> edges.append(parsed_drawing) <TAB> <TAB> <TAB> <TAB> if bbox is None: <TAB> <TAB> <TAB> <TAB> <TAB> bbox = d.GetBoundingBox() <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> bbox.Merge(d.GetBoundingBox()) <TAB> if bbox: <TAB> <TAB> bbox.Normalize() <TAB> return edges, bbox",true,if parsed_drawing :,if parsed_drawing :,0.53,0.0
"def to_key(literal_or_identifier): <TAB> """"""returns string representation of this object"""""" <TAB> if literal_or_identifier[""type""] == ""Identifier"": <TAB> <TAB> return literal_or_identifier[""name""] <TAB> elif literal_or_identifier[""type""] == ""Literal"": <TAB> <TAB> k = literal_or_identifier[""value""] <TAB> <TAB> if isinstance(k, float): <TAB> <TAB> <TAB> return unicode(float_repr(k)) <TAB> <TAB> elif ""regex"" in literal_or_identifier: <TAB> <TAB> <TAB> return compose_regex(k) <TAB> <TAB> elif isinstance(k, bool): <TAB> <TAB> <TAB> return ""true"" if k else ""false"" <TAB> <TAB> elif k is None: <TAB> <TAB> <TAB> return ""null"" <TAB> <TAB> else: <TAB> <TAB> <TAB> return unicode(k)",true,elif k is None :,elif k is None :,0.75,0.0
"def find_multiple_stats(stats, name, _found=None, _on_found=None): <TAB> if _found is None: <TAB> <TAB> _found = [] <TAB> for child_stats in stats: <TAB> <TAB> if child_stats.name == name: <TAB> <TAB> <TAB> _found.append(child_stats) <TAB> <TAB> <TAB> if callable(_on_found): <TAB> <TAB> <TAB> <TAB> _on_found(_found) <TAB> <TAB> find_multiple_stats(child_stats, name, _found) <TAB> return _found",true,if callable ( _on_found ) :,if callable ( _on_found ) :,0.75,0.0
"def _run_generated_code( <TAB> self, <TAB> code, <TAB> globs, <TAB> locs, <TAB> fails_under_py3k=True, ): <TAB> import warnings <TAB> from zope.interface._compat import PYTHON3 <TAB> with warnings.catch_warnings(record=True) as log: <TAB> <TAB> warnings.resetwarnings() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> exec(code, globs, locs) <TAB> <TAB> <TAB> self.assertEqual(len(log), 0)  # no longer warn <TAB> <TAB> <TAB> return True <TAB> <TAB> else: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> exec(code, globs, locs) <TAB> <TAB> <TAB> except TypeError: <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> if fails_under_py3k: <TAB> <TAB> <TAB> <TAB> <TAB> self.fail(""Didn't raise TypeError"")",false,if not PYTHON3 :,if PYTHON3 :,0.1,0.0
"def _get_node(self, node_id): <TAB> self.non_terminated_nodes({})  # Side effect: updates cache <TAB> with self.lock: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return self.cached_nodes[node_id] <TAB> <TAB> instance = ( <TAB> <TAB> <TAB> self.compute.instances() <TAB> <TAB> <TAB> .get( <TAB> <TAB> <TAB> <TAB> project=self.provider_config[""project_id""], <TAB> <TAB> <TAB> <TAB> zone=self.provider_config[""availability_zone""], <TAB> <TAB> <TAB> <TAB> instance=node_id, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> .execute() <TAB> <TAB> ) <TAB> <TAB> return instance",true,if node_id in self . cached_nodes :,if node_id in self . cached_nodes :,0.75,0.0
"def skip_to_close_match(self): <TAB> nestedCount = 1 <TAB> while 1: <TAB> <TAB> tok = self.tokenizer.get_next_token() <TAB> <TAB> ttype = tok[""style""] <TAB> <TAB> if ttype == SCE_PL_UNUSED: <TAB> <TAB> <TAB> return <TAB> <TAB> elif self.classifier.is_index_op(tok): <TAB> <TAB> <TAB> tval = tok[""text""] <TAB> <TAB> <TAB> if self.opHash.has_key(tval): <TAB> <TAB> <TAB> <TAB> if self.opHash[tval][1] == 1: <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount += 1 <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount -= 1 <TAB> <TAB> <TAB> <TAB> <TAB> if nestedCount <= 0: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break",false,if self . opHash . has_key ( tval ) :,if self . classifier . is_index_op ( tok ) :,0.32,0.0
"def _create_or_get_helper(self, infer_mode: Optional[bool] = None, **kwargs) -> Helper: <TAB> # Prefer creating a new helper when at least one kwarg is specified. <TAB> prefer_new = len(kwargs) > 0 <TAB> kwargs.update(infer_mode=infer_mode) <TAB> is_training = not infer_mode if infer_mode is not None else self.training <TAB> helper = self._train_helper if is_training else self._infer_helper <TAB> if prefer_new or helper is None: <TAB> <TAB> helper = self.create_helper(**kwargs) <TAB> <TAB> if is_training and self._train_helper is None: <TAB> <TAB> <TAB> self._train_helper = helper <TAB> <TAB> elif not is_training and self._infer_helper is None: <TAB> <TAB> <TAB> self._infer_helper = helper <TAB> return helper",true,elif not is_training and self . _infer_helper is None :,elif not is_training and self . _infer_helper is None :,0.75,0.0
"def get_ldset(self, ldsets): <TAB> ldset = None <TAB> if self._properties[""ldset_name""] == """": <TAB> <TAB> nldset = len(ldsets) <TAB> <TAB> if nldset == 0: <TAB> <TAB> <TAB> msg = _(""Logical Disk Set could not be found."") <TAB> <TAB> <TAB> raise exception.NotFound(msg) <TAB> <TAB> else: <TAB> <TAB> <TAB> ldset = None <TAB> else: <TAB> <TAB> if self._properties[""ldset_name""] not in ldsets: <TAB> <TAB> <TAB> msg = ( <TAB> <TAB> <TAB> <TAB> _(""Logical Disk Set `%s` could not be found."") <TAB> <TAB> <TAB> <TAB> % self._properties[""ldset_name""] <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> raise exception.NotFound(msg) <TAB> <TAB> ldset = ldsets[self._properties[""ldset_name""]] <TAB> return ldset",true,"if self . _properties [ ""ldset_name"" ] not in ldsets :","if self . _properties [ ""ldset_name"" ] not in ldsets :",0.75,0.0
"def calc_fractal_serial(q, maxiter): <TAB> # calculate z using pure python on a numpy array <TAB> # note that, unlike the other two implementations, <TAB> # the number of iterations per point is NOT constant <TAB> z = np.zeros(q.shape, complex) <TAB> output = np.resize( <TAB> <TAB> np.array( <TAB> <TAB> <TAB> 0, <TAB> <TAB> ), <TAB> <TAB> q.shape, <TAB> ) <TAB> for i in range(len(q)): <TAB> <TAB> for iter in range(maxiter): <TAB> <TAB> <TAB> z[i] = z[i] * z[i] + q[i] <TAB> <TAB> <TAB> if abs(z[i]) > 2.0: <TAB> <TAB> <TAB> <TAB> output[i] = iter <TAB> <TAB> <TAB> <TAB> break <TAB> return output",true,if abs ( z [ i ] ) > 2.0 :,if abs ( z [ i ] ) > 2.0 :,0.75,0.0
"def _verifySubs(self): <TAB> for inst in self.subs: <TAB> <TAB> if not isinstance(inst, (_Block, _Instantiator, Cosimulation)): <TAB> <TAB> <TAB> raise BlockError(_error.ArgType % (self.name,)) <TAB> <TAB> if isinstance(inst, (_Block, _Instantiator)): <TAB> <TAB> <TAB> if not inst.modctxt: <TAB> <TAB> <TAB> <TAB> raise BlockError(_error.InstanceError % (self.name, inst.callername))",false,"if isinstance ( inst , ( _Block , _Instantiator ) ) :","if isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) :",0.38,0.0
"def walks_generator(): <TAB> if filelist is not None: <TAB> <TAB> bucket = [] <TAB> <TAB> for filename in filelist: <TAB> <TAB> <TAB> with io.open(filename) as inf: <TAB> <TAB> <TAB> <TAB> for line in inf: <TAB> <TAB> <TAB> <TAB> <TAB> walk = [int(x) for x in line.strip(""\n"").split("" "")] <TAB> <TAB> <TAB> <TAB> <TAB> bucket.append(walk) <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield bucket <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> bucket = [] <TAB> <TAB> if len(bucket): <TAB> <TAB> <TAB> yield bucket <TAB> else: <TAB> <TAB> for _ in range(epoch): <TAB> <TAB> <TAB> for nodes in graph.node_batch_iter(batch_size): <TAB> <TAB> <TAB> <TAB> walks = graph.random_walk(nodes, walk_len) <TAB> <TAB> <TAB> <TAB> yield walks",true,if len ( bucket ) == batch_size :,if len ( bucket ) == batch_size :,0.75,0.0
"def _traverse(op): <TAB> if op in visited: <TAB> <TAB> return <TAB> visited.add(op) <TAB> if tag.is_injective(op.tag): <TAB> <TAB> if op not in s.outputs: <TAB> <TAB> <TAB> s[op].compute_inline() <TAB> <TAB> for tensor in op.input_tensors: <TAB> <TAB> <TAB> if isinstance(tensor.op, tvm.te.ComputeOp): <TAB> <TAB> <TAB> <TAB> _traverse(tensor.op) <TAB> callback(op)",true,"if isinstance ( tensor . op , tvm . te . ComputeOp ) :","if isinstance ( tensor . op , tvm . te . ComputeOp ) :",0.75,0.0
"def unwatch_run(self, run_id, handler): <TAB> with self._dict_lock: <TAB> <TAB> if run_id in self._run_id_dict: <TAB> <TAB> <TAB> self._handlers_dict[run_id] = [ <TAB> <TAB> <TAB> <TAB> (start_cursor, callback) <TAB> <TAB> <TAB> <TAB> for (start_cursor, callback) in self._handlers_dict[run_id] <TAB> <TAB> <TAB> <TAB> if callback != handler <TAB> <TAB> <TAB> ] <TAB> <TAB> if not self._handlers_dict[run_id]: <TAB> <TAB> <TAB> del self._handlers_dict[run_id] <TAB> <TAB> <TAB> run_id_dict = self._run_id_dict <TAB> <TAB> <TAB> del run_id_dict[run_id] <TAB> <TAB> <TAB> self._run_id_dict = run_id_dict",true,if run_id in self . _run_id_dict :,if run_id in self . _run_id_dict :,0.75,0.0
"def _PromptMySQL(self, config): <TAB> """"""Prompts the MySQL configuration, retrying if the configuration is invalid."""""" <TAB> while True: <TAB> <TAB> self._PromptMySQLOnce(config) <TAB> <TAB> if self._CheckMySQLConnection(): <TAB> <TAB> <TAB> print(""Successfully connected to MySQL with the given configuration."") <TAB> <TAB> <TAB> return <TAB> <TAB> else: <TAB> <TAB> <TAB> print(""Error: Could not connect to MySQL with the given configuration."") <TAB> <TAB> <TAB> retry = RetryBoolQuestion(""Do you want to retry MySQL configuration?"", True) <TAB> <TAB> <TAB> if not retry: <TAB> <TAB> <TAB> <TAB> raise ConfigInitError()",true,if self . _CheckMySQLConnection ( ) :,if self . _CheckMySQLConnection ( ) :,0.75,0.0
"def get_courses_without_topic(topic): <TAB> data = [] <TAB> for entry in frappe.db.get_all(""Course""): <TAB> <TAB> course = frappe.get_doc(""Course"", entry.name) <TAB> <TAB> topics = [t.topic for t in course.topics] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> data.append(course.name) <TAB> return data",false,if not topics or topic not in topics :,if topic in topics :,0.26,0.0
"def _error_handler(action, **keywords): <TAB> if keywords: <TAB> <TAB> file_type = keywords.get(""file_type"", None) <TAB> <TAB> if file_type: <TAB> <TAB> <TAB> raise exceptions.FileTypeNotSupported( <TAB> <TAB> <TAB> <TAB> constants.FILE_TYPE_NOT_SUPPORTED_FMT % (file_type, action) <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> keywords.pop(""on_demand"") <TAB> <TAB> <TAB> msg = ""Please check if there were typos in "" <TAB> <TAB> <TAB> msg += ""function parameters: %s. Otherwise "" <TAB> <TAB> <TAB> msg += ""unrecognized parameters were given."" <TAB> <TAB> <TAB> raise exceptions.UnknownParameters(msg % keywords) <TAB> else: <TAB> <TAB> raise exceptions.UnknownParameters(""No parameters found!"")",true,"if ""on_demand"" in keywords :","if ""on_demand"" in keywords :",0.75,0.0
"def select(self, regions, register): <TAB> self.view.sel().clear() <TAB> to_store = [] <TAB> for r in regions: <TAB> <TAB> self.view.sel().add(r) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> to_store.append(self.view.substr(self.view.full_line(r))) <TAB> if register: <TAB> <TAB> text = """".join(to_store) <TAB> <TAB> if not text.endswith(""\n""): <TAB> <TAB> <TAB> text = text + ""\n"" <TAB> <TAB> state = State(self.view) <TAB> <TAB> state.registers[register] = [text]",false,if register :,if r :,0.32,0.0
"def has_actor(self, message: HasActorMessage) -> ResultMessage: <TAB> actor_ref = message.actor_ref <TAB> # lookup allocated <TAB> for address, item in self._allocated_actors.items(): <TAB> <TAB> ref = create_actor_ref(address, actor_ref.uid) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ResultMessage(message.message_id, True, protocol=message.protocol) <TAB> return ResultMessage(message.message_id, False, protocol=message.protocol)",false,if ref in item :,if ref == message . message_id :,0.05,0.0
"def toggleMetaButton(self, event): <TAB> """"""Process clicks on toggle buttons"""""" <TAB> clickedBtn = event.EventObject <TAB> if wx.GetMouseState().GetModifiers() == wx.MOD_CONTROL: <TAB> <TAB> activeBtns = [btn for btn in self.metaButtons if btn.GetValue()] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> clickedBtn.setUserSelection(clickedBtn.GetValue()) <TAB> <TAB> <TAB> self.itemView.filterItemStore() <TAB> <TAB> else: <TAB> <TAB> <TAB> # Do 'nothing' if we're trying to turn last active button off <TAB> <TAB> <TAB> # Keep button in the same state <TAB> <TAB> <TAB> clickedBtn.setUserSelection(True) <TAB> else: <TAB> <TAB> for btn in self.metaButtons: <TAB> <TAB> <TAB> btn.setUserSelection(btn == clickedBtn) <TAB> <TAB> self.itemView.filterItemStore()",true,if activeBtns :,if activeBtns :,0.53,0.0
"def __init__(self, hub=None):  # pylint: disable=unused-argument <TAB> if resolver._resolver is None: <TAB> <TAB> _resolver = resolver._resolver = _DualResolver() <TAB> <TAB> if config.resolver_nameservers: <TAB> <TAB> <TAB> _resolver.network_resolver.nameservers[:] = config.resolver_nameservers <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> _resolver.network_resolver.lifetime = config.resolver_timeout <TAB> # Different hubs in different threads could be sharing the same <TAB> # resolver. <TAB> assert isinstance(resolver._resolver, _DualResolver) <TAB> self._resolver = resolver._resolver",true,if config . resolver_timeout :,if config . resolver_timeout :,0.75,0.0
"def sub_paragraph(self, li): <TAB> """"""Search for checkbox in sub-paragraph."""""" <TAB> found = False <TAB> if len(li): <TAB> <TAB> first = list(li)[0] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> m = RE_CHECKBOX.match(first.text) <TAB> <TAB> <TAB> if m is not None: <TAB> <TAB> <TAB> <TAB> first.text = self.markdown.htmlStash.store( <TAB> <TAB> <TAB> <TAB> <TAB> get_checkbox(m.group(""state"")), safe=True <TAB> <TAB> <TAB> <TAB> ) + m.group(""line"") <TAB> <TAB> <TAB> <TAB> found = True <TAB> return found",false,"if first . tag == ""p"" and first . text is not None :",if first . text :,0.05,0.0
"def _check_mswin_locale(locale): <TAB> msloc = None <TAB> try: <TAB> <TAB> msloc = _LOCALE_NAMES[locale[:5]][:2] <TAB> <TAB> locale = locale[:5] <TAB> except KeyError: <TAB> <TAB> try: <TAB> <TAB> <TAB> msloc = _LOCALE_NAMES[locale[:2]][:2] <TAB> <TAB> <TAB> locale = locale[:2] <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> # US English is the outlier, all other English locales want <TAB> <TAB> <TAB> # real English: <TAB> <TAB> <TAB> if locale[:2] == (""en"") and locale[:5] != ""en_US"": <TAB> <TAB> <TAB> <TAB> return (""en_GB"", ""1252"") <TAB> <TAB> <TAB> return (None, None) <TAB> return (locale, msloc)",true,"if locale [ : 2 ] == ( ""en"" ) and locale [ : 5 ] != ""en_US"" :","if locale [ : 2 ] == ( ""en"" ) and locale [ : 5 ] != ""en_US"" :",0.75,0.0
"def setLabel(self, s, protect=False): <TAB> """"""Set the label of the minibuffer."""""" <TAB> c, k, w = self.c, self, self.w <TAB> if w: <TAB> <TAB> # Support for the curses gui. <TAB> <TAB> if hasattr(g.app.gui, ""set_minibuffer_label""): <TAB> <TAB> <TAB> g.app.gui.set_minibuffer_label(c, s) <TAB> <TAB> w.setAllText(s) <TAB> <TAB> n = len(s) <TAB> <TAB> w.setSelectionRange(n, n, insert=n) <TAB> <TAB> if protect: <TAB> <TAB> <TAB> k.mb_prefix = s",true,"if hasattr ( g . app . gui , ""set_minibuffer_label"" ) :","if hasattr ( g . app . gui , ""set_minibuffer_label"" ) :",0.75,0.0
"def getProc(su, innerTarget): <TAB> if len(su) == 1:  # have a one element wedge <TAB> <TAB> proc = (""first"", ""last"") <TAB> else: <TAB> <TAB> if su.isFirst(innerTarget) and su.isLast(innerTarget): <TAB> <TAB> <TAB> proc = (""first"", ""last"")  # same element can be first and last <TAB> <TAB> elif su.isFirst(innerTarget): <TAB> <TAB> <TAB> proc = (""first"",) <TAB> <TAB> elif su.isLast(innerTarget): <TAB> <TAB> <TAB> proc = (""last"",) <TAB> <TAB> else: <TAB> <TAB> <TAB> proc = () <TAB> return proc",true,elif su . isFirst ( innerTarget ) :,elif su . isFirst ( innerTarget ) :,0.75,0.0
"def await_test_end(self): <TAB> iterations = 0 <TAB> while True: <TAB> <TAB> if iterations > 100: <TAB> <TAB> <TAB> self.log.debug(""Await: iteration limit reached"") <TAB> <TAB> <TAB> return <TAB> <TAB> status = self.master.get_status() <TAB> <TAB> if status.get(""status"") == ""ENDED"": <TAB> <TAB> <TAB> return <TAB> <TAB> iterations += 1 <TAB> <TAB> time.sleep(1.0)",true,"if status . get ( ""status"" ) == ""ENDED"" :","if status . get ( ""status"" ) == ""ENDED"" :",0.75,0.0
"def _handle_autocomplete_request_for_text(text): <TAB> if not hasattr(text, ""autocompleter""): <TAB> <TAB> if isinstance(text, (CodeViewText, ShellText)) and text.is_python_text(): <TAB> <TAB> <TAB> if isinstance(text, CodeViewText): <TAB> <TAB> <TAB> <TAB> text.autocompleter = Completer(text) <TAB> <TAB> <TAB> elif isinstance(text, ShellText): <TAB> <TAB> <TAB> <TAB> text.autocompleter = ShellCompleter(text) <TAB> <TAB> <TAB> text.bind(""<1>"", text.autocompleter.on_text_click) <TAB> <TAB> else: <TAB> <TAB> <TAB> return <TAB> text.autocompleter.handle_autocomplete_request()",false,"if isinstance ( text , CodeViewText ) :","if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) :",0.21,0.0
"def validate_party_details(self): <TAB> if self.party: <TAB> <TAB> if not frappe.db.exists(self.party_type, self.party): <TAB> <TAB> <TAB> frappe.throw(_(""Invalid {0}: {1}"").format(self.party_type, self.party)) <TAB> <TAB> if self.party_account and self.party_type in (""Customer"", ""Supplier""): <TAB> <TAB> <TAB> self.validate_account_type( <TAB> <TAB> <TAB> <TAB> self.party_account, [erpnext.get_party_account_type(self.party_type)] <TAB> <TAB> <TAB> )",false,"if not frappe . db . exists ( self . party_type , self . party ) :","if self . party_account and self . party_type in ( ""Customer"" , ""Supplier"" ) :",0.15,0.0
"def format(self, formatstr): <TAB> pieces = [] <TAB> for i, piece in enumerate(re_formatchars.split(force_text(formatstr))): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> pieces.append(force_text(getattr(self, piece)())) <TAB> <TAB> elif piece: <TAB> <TAB> <TAB> pieces.append(re_escaped.sub(r""\1"", piece)) <TAB> return """".join(pieces)",false,if i % 2 :,if i == 0 :,0.31,0.0
"def _convert_java_pattern_to_python(pattern): <TAB> """"""Convert a replacement pattern from the Java-style `$5` to the Python-style `\\5`."""""" <TAB> s = list(pattern) <TAB> i = 0 <TAB> while i < len(s) - 1: <TAB> <TAB> c = s[i] <TAB> <TAB> if c == ""$"" and s[i + 1] in ""0123456789"": <TAB> <TAB> <TAB> s[i] = ""\\"" <TAB> <TAB> elif c == ""\\"" and s[i + 1] == ""$"": <TAB> <TAB> <TAB> s[i] = """" <TAB> <TAB> <TAB> i += 1 <TAB> <TAB> i += 1 <TAB> return pattern[:0].join(s)",false,"if c == ""$"" and s [ i + 1 ] in ""0123456789"" :","elif c == ""\\"" and s [ i + 1 ] == ""$"" :",0.36,0.0
"def download(self, url, filename, **kwargs): <TAB> try: <TAB> <TAB> r = self.get(url, timeout=10, stream=True, **kwargs) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> with open(filename, ""wb"") as f: <TAB> <TAB> <TAB> for chunk in r.iter_content(chunk_size=1024): <TAB> <TAB> <TAB> <TAB> if chunk: <TAB> <TAB> <TAB> <TAB> <TAB> f.write(chunk) <TAB> <TAB> helpers.chmod_as_parent(filename) <TAB> except Exception as e: <TAB> <TAB> sickrage.app.log.debug( <TAB> <TAB> <TAB> ""Failed to download file from {} - ERROR: {}"".format(url, e) <TAB> <TAB> ) <TAB> <TAB> if os.path.exists(filename): <TAB> <TAB> <TAB> os.remove(filename) <TAB> <TAB> return False <TAB> return True",false,if r . status_code >= 400 :,if r is None :,0.04,0.0
"def run(self, paths=[]): <TAB> items = [] <TAB> for item in SideBarSelection(paths).getSelectedFilesWithExtension(""js""): <TAB> <TAB> items.append( <TAB> <TAB> <TAB> '<script type=""text/javascript"" src=""' <TAB> <TAB> <TAB> + item.pathAbsoluteFromProjectEncoded() <TAB> <TAB> <TAB> + '""></script>' <TAB> <TAB> ) <TAB> if len(items) > 0: <TAB> <TAB> sublime.set_clipboard(""\n"".join(items)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> sublime.status_message(""Items copied"") <TAB> <TAB> else: <TAB> <TAB> <TAB> sublime.status_message(""Item copied"")",true,if len ( items ) > 1 :,if len ( items ) > 1 :,0.75,0.0
"def work(self): <TAB> while True: <TAB> <TAB> timeout = self.timeout <TAB> <TAB> if idle.is_set(): <TAB> <TAB> <TAB> timeout = self.idle_timeout <TAB> <TAB> log.debug(""Wait for {}"".format(timeout)) <TAB> <TAB> fetch.wait(timeout) <TAB> <TAB> if shutting_down.is_set(): <TAB> <TAB> <TAB> log.info(""Stop fetch worker"") <TAB> <TAB> <TAB> break <TAB> <TAB> self.fetch()",false,if shutting_down . is_set ( ) :,if idle . is_set ( ) :,0.57,0.0
"def check_apns_certificate(ss): <TAB> mode = ""start"" <TAB> for s in ss.split(""\n""): <TAB> <TAB> if mode == ""start"": <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> mode = ""key"" <TAB> <TAB> elif mode == ""key"": <TAB> <TAB> <TAB> if ""END RSA PRIVATE KEY"" in s or ""END PRIVATE KEY"" in s: <TAB> <TAB> <TAB> <TAB> mode = ""end"" <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> elif s.startswith(""Proc-Type"") and ""ENCRYPTED"" in s: <TAB> <TAB> <TAB> <TAB> raise ImproperlyConfigured( <TAB> <TAB> <TAB> <TAB> <TAB> ""Encrypted APNS private keys are not supported"" <TAB> <TAB> <TAB> <TAB> ) <TAB> if mode != ""end"": <TAB> <TAB> raise ImproperlyConfigured(""The APNS certificate doesn't contain a private key"")",false,"if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s :","if ""key"" in s :",0.03,0.0
"def compare_lists(self, l1, l2, key): <TAB> l2_lookup = {o.get(key): o for o in l2} <TAB> for obj1 in l1: <TAB> <TAB> obj2 = l2_lookup.get(obj1.get(key)) <TAB> <TAB> for k in obj1: <TAB> <TAB> <TAB> if k not in ""id"" and obj1.get(k): <TAB> <TAB> <TAB> <TAB> self.assertEqual(obj1.get(k), obj2.get(k))",true,"if k not in ""id"" and obj1 . get ( k ) :","if k not in ""id"" and obj1 . get ( k ) :",1.0,0.0
"def before_get_object(self, view_kwargs): <TAB> if view_kwargs.get(""id"") is not None: <TAB> <TAB> try: <TAB> <TAB> <TAB> user_favourite_event = find_user_favourite_event_by_id( <TAB> <TAB> <TAB> <TAB> event_id=view_kwargs[""id""] <TAB> <TAB> <TAB> ) <TAB> <TAB> except NoResultFound: <TAB> <TAB> <TAB> raise ObjectNotFound( <TAB> <TAB> <TAB> <TAB> {""source"": ""/data/relationships/event""}, ""Object: not found"" <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> view_kwargs[""id""] = user_favourite_event.id <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> view_kwargs[""id""] = None",false,if user_favourite_event is not None :,if user_favourite_event :,0.05,0.0
"def close(self): <TAB> super().close() <TAB> if not sys.is_finalizing(): <TAB> <TAB> for sig in list(self._signal_handlers): <TAB> <TAB> <TAB> self.remove_signal_handler(sig) <TAB> else: <TAB> <TAB> if self._signal_handlers: <TAB> <TAB> <TAB> warnings.warn( <TAB> <TAB> <TAB> <TAB> f""Closing the loop {self!r} "" <TAB> <TAB> <TAB> <TAB> f""on interpreter shutdown "" <TAB> <TAB> <TAB> <TAB> f""stage, skipping signal handlers removal"", <TAB> <TAB> <TAB> <TAB> ResourceWarning, <TAB> <TAB> <TAB> <TAB> source=self, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self._signal_handlers.clear()",true,if self . _signal_handlers :,if self . _signal_handlers :,0.75,0.0
"def install_script(self, script, install_options=None): <TAB> try: <TAB> <TAB> fname = utils.do_script( <TAB> <TAB> <TAB> script, <TAB> <TAB> <TAB> python_exe=osp.join(self.target, ""python.exe""), <TAB> <TAB> <TAB> architecture=self.architecture, <TAB> <TAB> <TAB> verbose=self.verbose, <TAB> <TAB> <TAB> install_options=install_options, <TAB> <TAB> ) <TAB> except RuntimeError: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(""Failed!"") <TAB> <TAB> <TAB> raise",false,if not self . verbose :,if self . verbose :,0.28,0.0
"def GetRouterForUser(self, username): <TAB> """"""Returns a router corresponding to a given username."""""" <TAB> for index, router in enumerate(self.routers): <TAB> <TAB> router_id = str(index) <TAB> <TAB> if self.auth_manager.CheckPermissions(username, router_id): <TAB> <TAB> <TAB> logging.debug( <TAB> <TAB> <TAB> <TAB> ""Matched router %s to user %s"", router.__class__.__name__, username <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return router <TAB> logging.debug( <TAB> <TAB> ""No router ACL rule match for user %s. Using default "" ""router %s"", <TAB> <TAB> username, <TAB> <TAB> self.default_router.__class__.__name__, <TAB> ) <TAB> return self.default_router",true,"if self . auth_manager . CheckPermissions ( username , router_id ) :","if self . auth_manager . CheckPermissions ( username , router_id ) :",0.75,0.0
"def charset(self): <TAB> """"""The charset from the content type."""""" <TAB> header = self.environ.get(""CONTENT_TYPE"") <TAB> if header: <TAB> <TAB> ct, options = parse_options_header(header) <TAB> <TAB> charset = options.get(""charset"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if is_known_charset(charset): <TAB> <TAB> <TAB> <TAB> return charset <TAB> <TAB> <TAB> return self.unknown_charset(charset) <TAB> return self.default_charset",true,if charset :,if charset :,0.53,0.0
def isFinished(self): <TAB> # returns true if episode timesteps has reached episode length and resets the task <TAB> if self.count > self.epiLen: <TAB> <TAB> self.res() <TAB> <TAB> return True <TAB> else: <TAB> <TAB> if self.count == 1: <TAB> <TAB> <TAB> self.pertGlasPos(0) <TAB> <TAB> if self.count == self.epiLen / 2 + 1: <TAB> <TAB> <TAB> self.env.reset() <TAB> <TAB> <TAB> self.pertGlasPos(1) <TAB> <TAB> self.count += 1 <TAB> <TAB> return False,false,if self . count == self . epiLen / 2 + 1 :,if self . count == self . eipLen / 2 + 1 :,0.88,0.0
"def mtimes_of_files(dirnames: List[str], suffix: str) -> Iterator[float]: <TAB> for dirname in dirnames: <TAB> <TAB> for root, dirs, files in os.walk(dirname): <TAB> <TAB> <TAB> for sfile in files: <TAB> <TAB> <TAB> <TAB> if sfile.endswith(suffix): <TAB> <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield path.getmtime(path.join(root, sfile)) <TAB> <TAB> <TAB> <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> pass",true,if sfile . endswith ( suffix ) :,if sfile . endswith ( suffix ) :,0.75,0.0
"def get_all_hashes(self): <TAB> event_hashes = [] <TAB> sample_hashes = [] <TAB> for a in self.event.attributes: <TAB> <TAB> h = None <TAB> <TAB> if a.type in (""md5"", ""sha1"", ""sha256""): <TAB> <TAB> <TAB> h = a.value <TAB> <TAB> <TAB> event_hashes.append(h) <TAB> <TAB> elif a.type in (""filename|md5"", ""filename|sha1"", ""filename|sha256""): <TAB> <TAB> <TAB> h = a.value.split(""|"")[1] <TAB> <TAB> <TAB> event_hashes.append(h) <TAB> <TAB> elif a.type == ""malware-sample"": <TAB> <TAB> <TAB> h = a.value.split(""|"")[1] <TAB> <TAB> <TAB> sample_hashes.append(h) <TAB> return event_hashes, sample_hashes",true,"elif a . type == ""malware-sample"" :","elif a . type == ""malware-sample"" :",1.0,0.0
"def _validate(self, event): <TAB> if self.type is None: <TAB> <TAB> return <TAB> new = self.value <TAB> if not isinstance(new, self.type) and new is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.value = event.old <TAB> <TAB> types = repr(self.type) if isinstance(self.type, tuple) else self.type.__name__ <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> ""LiteralInput expected %s type but value %s "" <TAB> <TAB> <TAB> ""is of type %s."" % (types, new, type(new).__name__) <TAB> <TAB> )",false,if event :,if event . old is not None :,0.08,0.0
"def update_dict(a, b): <TAB> for key, value in b.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if key not in a: <TAB> <TAB> <TAB> a[key] = value <TAB> <TAB> elif isinstance(a[key], dict) and isinstance(value, dict): <TAB> <TAB> <TAB> update_dict(a[key], value) <TAB> <TAB> elif isinstance(a[key], list): <TAB> <TAB> <TAB> a[key].append(value) <TAB> <TAB> else: <TAB> <TAB> <TAB> a[key] = [a[key], value]",true,if value is None :,if value is None :,0.75,0.0
"def on_pre_save(self, view): <TAB> extOrClause = ""|"".join(s.get(""format_on_save_extensions"")) <TAB> extRegex = ""\\.("" + extOrClause + "")$"" <TAB> if s.get(""format_on_save"") and re.search(extRegex, view.file_name()): <TAB> <TAB> # only auto-format on save if there are no ""lint errors"" <TAB> <TAB> # here are some named regions from sublimelint see https://github.com/lunixbochs/sublimelint/tree/st3 <TAB> <TAB> lints_regions = [""lint-keyword-underline"", ""lint-keyword-outline""] <TAB> <TAB> for linter in lints_regions: <TAB> <TAB> <TAB> if len(view.get_regions(linter)): <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> view.run_command(""js_format"")",true,if len ( view . get_regions ( linter ) ) :,if len ( view . get_regions ( linter ) ) :,0.75,0.0
"def readMemory(self, va, size): <TAB> for mva, mmaxva, mmap, mbytes in self._map_defs: <TAB> <TAB> if mva <= va < mmaxva: <TAB> <TAB> <TAB> mva, msize, mperms, mfname = mmap <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise envi.SegmentationViolation(va) <TAB> <TAB> <TAB> offset = va - mva <TAB> <TAB> <TAB> return mbytes[offset : offset + size] <TAB> raise envi.SegmentationViolation(va)",false,if not mperms & MM_READ :,if mva >= va + size :,0.02,0.0
"def assertFilepathsEqual(self, p1, p2): <TAB> if sys.platform == ""win32"": <TAB> <TAB> if isinstance(p1, (list, tuple)): <TAB> <TAB> <TAB> p1 = [normcase(normpath(x)) for x in p1] <TAB> <TAB> <TAB> p2 = [normcase(normpath(x)) for x in p2] <TAB> <TAB> else: <TAB> <TAB> <TAB> assert isinstance(p1, (str, unicode)) <TAB> <TAB> <TAB> p1 = normcase(normpath(p1)) <TAB> <TAB> <TAB> p2 = normcase(normpath(p2)) <TAB> self.assertEqual(p1, p2)",true,"if isinstance ( p1 , ( list , tuple ) ) :","if isinstance ( p1 , ( list , tuple ) ) :",0.75,0.0
"def add_directory_csv_files(dir_path, paths=None): <TAB> if not paths: <TAB> <TAB> paths = [] <TAB> for p in listdir(dir_path): <TAB> <TAB> path = join(dir_path, p) <TAB> <TAB> if isdir(path): <TAB> <TAB> <TAB> # call recursively for each dir <TAB> <TAB> <TAB> paths = add_directory_csv_files(path, paths) <TAB> <TAB> elif isfile(path) and path.endswith("".csv""): <TAB> <TAB> <TAB> # add every file to the list <TAB> <TAB> <TAB> paths.append(path) <TAB> return paths",true,"elif isfile ( path ) and path . endswith ( "".csv"" ) :","elif isfile ( path ) and path . endswith ( "".csv"" ) :",0.75,0.0
"def _verifySubs(self): <TAB> for inst in self.subs: <TAB> <TAB> if not isinstance(inst, (_Block, _Instantiator, Cosimulation)): <TAB> <TAB> <TAB> raise BlockError(_error.ArgType % (self.name,)) <TAB> <TAB> if isinstance(inst, (_Block, _Instantiator)): <TAB> <TAB> <TAB> if not inst.modctxt: <TAB> <TAB> <TAB> <TAB> raise BlockError(_error.InstanceError % (self.name, inst.callername))",false,"if not isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) :","if isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) :",0.44,0.0
"def __annotations_bytes(self): <TAB> if self.annotations: <TAB> <TAB> a = [] <TAB> <TAB> for k, v in self.annotations.items(): <TAB> <TAB> <TAB> if len(k) != 4: <TAB> <TAB> <TAB> <TAB> raise errors.ProtocolError(""annotation key must be of length 4"") <TAB> <TAB> <TAB> if sys.version_info >= (3, 0): <TAB> <TAB> <TAB> <TAB> k = k.encode(""ASCII"") <TAB> <TAB> <TAB> a.append(struct.pack(""!4sH"", k, len(v))) <TAB> <TAB> <TAB> a.append(v) <TAB> <TAB> return b"""".join(a) <TAB> return b""""",true,"if sys . version_info >= ( 3 , 0 ) :","if sys . version_info >= ( 3 , 0 ) :",0.75,0.0
"def session(self, profile: str = ""default"", region: str = None) -> boto3.Session: <TAB> region = self._get_region(region, profile) <TAB> try: <TAB> <TAB> session = self._cache_lookup( <TAB> <TAB> <TAB> self._session_cache, <TAB> <TAB> <TAB> [profile, region], <TAB> <TAB> <TAB> self._boto3.Session, <TAB> <TAB> <TAB> [], <TAB> <TAB> <TAB> {""region_name"": region, ""profile_name"": profile}, <TAB> <TAB> ) <TAB> except ProfileNotFound: <TAB> <TAB> if profile != ""default"": <TAB> <TAB> <TAB> raise <TAB> <TAB> session = self._boto3.Session(region_name=region) <TAB> <TAB> self._cache_set(self._session_cache, [profile, region], session) <TAB> return session",true,"if profile != ""default"" :","if profile != ""default"" :",0.75,0.0
"def spans_score(gold_spans, system_spans): <TAB> correct, gi, si = 0, 0, 0 <TAB> while gi < len(gold_spans) and si < len(system_spans): <TAB> <TAB> if system_spans[si].start < gold_spans[gi].start: <TAB> <TAB> <TAB> si += 1 <TAB> <TAB> elif gold_spans[gi].start < system_spans[si].start: <TAB> <TAB> <TAB> gi += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> correct += gold_spans[gi].end == system_spans[si].end <TAB> <TAB> <TAB> si += 1 <TAB> <TAB> <TAB> gi += 1 <TAB> return Score(len(gold_spans), len(system_spans), correct)",true,elif gold_spans [ gi ] . start < system_spans [ si ] . start :,elif gold_spans [ gi ] . start < system_spans [ si ] . start :,1.0,0.0
"def to_api(tag, raw_value): <TAB> try: <TAB> <TAB> api_tag, converter = _QL_TO_SC[tag] if tag else (""q"", None) <TAB> except KeyError: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise self.error( <TAB> <TAB> <TAB> <TAB> ""Unsupported '%s' tag. Try: %s"" % (tag, "", "".join(SUPPORTED)) <TAB> <TAB> <TAB> ) <TAB> <TAB> return None, None <TAB> else: <TAB> <TAB> value = str(converter(raw_value) if converter else raw_value) <TAB> <TAB> return api_tag, value",false,if tag not in SUPPORTED :,if SUPPORTED :,0.05,0.0
"def unpack(self, buf): <TAB> dpkt.Packet.unpack(self, buf) <TAB> buf = buf[self.__hdr_len__ :] <TAB> # single-byte IE <TAB> if self.type & 0x80: <TAB> <TAB> self.len = 0 <TAB> <TAB> self.data = b"""" <TAB> # multi-byte IE <TAB> else: <TAB> <TAB> # special PER-encoded UUIE <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.len = struct.unpack("">H"", buf[:2])[0] <TAB> <TAB> <TAB> buf = buf[2:] <TAB> <TAB> # normal TLV-like IE <TAB> <TAB> else: <TAB> <TAB> <TAB> self.len = struct.unpack(""B"", buf[:1])[0] <TAB> <TAB> <TAB> buf = buf[1:] <TAB> <TAB> self.data = buf[: self.len]",false,if self . type == USER_TO_USER :,if self . type & 0x80 :,0.28,0.0
"def on_bt_search_clicked(self, widget): <TAB> if self.current_provider is None: <TAB> <TAB> return <TAB> query = self.en_query.get_text() <TAB> @self.obtain_podcasts_with <TAB> def load_data(): <TAB> <TAB> if self.current_provider.kind == directory.Provider.PROVIDER_SEARCH: <TAB> <TAB> <TAB> return self.current_provider.on_search(query) <TAB> <TAB> elif self.current_provider.kind == directory.Provider.PROVIDER_URL: <TAB> <TAB> <TAB> return self.current_provider.on_url(query) <TAB> <TAB> elif self.current_provider.kind == directory.Provider.PROVIDER_FILE: <TAB> <TAB> <TAB> return self.current_provider.on_file(query)",false,if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH :,elif self . current_provider . kind == directory . Provider . PROVIDER_URL :,0.45,0.0
"def _text(bitlist): <TAB> out = """" <TAB> for typ, text in bitlist: <TAB> <TAB> if not typ: <TAB> <TAB> <TAB> out += text <TAB> <TAB> elif typ == ""em"": <TAB> <TAB> <TAB> out += ""\\fI%s\\fR"" % text <TAB> <TAB> elif typ in [""strong"", ""code""]: <TAB> <TAB> <TAB> out += ""\\fB%s\\fR"" % text <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""unexpected tag %r inside text"" % (typ,)) <TAB> out = out.strip() <TAB> out = re.sub(re.compile(r""^\s+"", re.M), """", out) <TAB> return out",false,"elif typ == ""em"" :","elif typ in [ ""strong"" , ""code"" ] :",0.05,0.0
"def process(self, buckets): <TAB> with self.executor_factory(max_workers=3) as w: <TAB> <TAB> futures = {} <TAB> <TAB> results = [] <TAB> <TAB> for b in buckets: <TAB> <TAB> <TAB> futures[w.submit(self.process_bucket, b)] = b <TAB> <TAB> for f in as_completed(futures): <TAB> <TAB> <TAB> if f.exception(): <TAB> <TAB> <TAB> <TAB> b = futures[f] <TAB> <TAB> <TAB> <TAB> self.log.error( <TAB> <TAB> <TAB> <TAB> <TAB> ""error modifying bucket:%s\n%s"", b[""Name""], f.exception() <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> results += filter(None, [f.result()]) <TAB> <TAB> return results",true,if f . exception ( ) :,if f . exception ( ) :,0.75,0.0
"def check_settings(self): <TAB> if self.settings_dict[""TIME_ZONE""] is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ImproperlyConfigured( <TAB> <TAB> <TAB> <TAB> ""Connection '%s' cannot set TIME_ZONE because USE_TZ is "" <TAB> <TAB> <TAB> <TAB> ""False."" % self.alias <TAB> <TAB> <TAB> ) <TAB> <TAB> elif self.features.supports_timezones: <TAB> <TAB> <TAB> raise ImproperlyConfigured( <TAB> <TAB> <TAB> <TAB> ""Connection '%s' cannot set TIME_ZONE because its engine "" <TAB> <TAB> <TAB> <TAB> ""handles time zones conversions natively."" % self.alias <TAB> <TAB> <TAB> )",false,if not settings . USE_TZ :,if self . features . use_tz :,0.03,0.0
"def process_webhook_prop(namespace): <TAB> if not isinstance(namespace.webhook_properties, list): <TAB> <TAB> return <TAB> result = {} <TAB> for each in namespace.webhook_properties: <TAB> <TAB> if each: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> key, value = each.split(""="", 1) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> key, value = each, """" <TAB> <TAB> <TAB> result[key] = value <TAB> namespace.webhook_properties = result",true,"if ""="" in each :","if ""="" in each :",0.75,0.0
"def _expand_query_values(original_query_list): <TAB> query_list = [] <TAB> for key, value in original_query_list: <TAB> <TAB> if isinstance(value, basestring): <TAB> <TAB> <TAB> query_list.append((key, value)) <TAB> <TAB> else: <TAB> <TAB> <TAB> key_fmt = key + ""[%s]"" <TAB> <TAB> <TAB> value_list = _to_kv_list(value) <TAB> <TAB> <TAB> query_list.extend((key_fmt % k, v) for k, v in value_list) <TAB> return query_list",true,"if isinstance ( value , basestring ) :","if isinstance ( value , basestring ) :",0.75,0.0
"def tags(): <TAB> """"""Return a dictionary of all tags in the form {hash: [tag_names, ...]}."""""" <TAB> tags = {} <TAB> for (n, c) in list_refs(): <TAB> <TAB> if n.startswith(""refs/tags/""): <TAB> <TAB> <TAB> name = n[10:] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> tags[c] = [] <TAB> <TAB> <TAB> tags[c].append(name)  # more than one tag can point at 'c' <TAB> return tags",false,if not c in tags :,if c not in tags :,0.22,0.0
"def test_colorspiral(self): <TAB> """"""Set of 625 colours, with jitter, using get_colors()."""""" <TAB> boxedge = 20 <TAB> boxes_per_row = 25 <TAB> rows = 0 <TAB> for i, c in enumerate(get_colors(625)): <TAB> <TAB> self.c.setFillColor(c) <TAB> <TAB> x1 = boxedge * (i % boxes_per_row) <TAB> <TAB> y1 = rows * boxedge <TAB> <TAB> self.c.rect(x1, y1, boxedge, boxedge, fill=1, stroke=0) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> rows += 1 <TAB> self.finish()",false,if not ( i + 1 ) % boxes_per_row :,if i % boxes_per_row == 0 :,0.03,0.0
"def oldest_pending_update_in_days(): <TAB> """"""Return the datestamp of the oldest pending update"""""" <TAB> pendingupdatespath = os.path.join( <TAB> <TAB> prefs.pref(""ManagedInstallDir""), ""UpdateNotificationTracking.plist"" <TAB> ) <TAB> try: <TAB> <TAB> pending_updates = FoundationPlist.readPlist(pendingupdatespath) <TAB> except FoundationPlist.NSPropertyListSerializationException: <TAB> <TAB> return 0 <TAB> oldest_date = now = NSDate.date() <TAB> for category in pending_updates: <TAB> <TAB> for name in pending_updates[category]: <TAB> <TAB> <TAB> this_date = pending_updates[category][name] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> oldest_date = this_date <TAB> return now.timeIntervalSinceDate_(oldest_date) / (24 * 60 * 60)",false,if this_date < oldest_date :,if this_date > oldest_date :,0.08,0.0
"def _try_read_gpg(path): <TAB> path = os.path.expanduser(path) <TAB> cmd = _gpg_cmd() + [path] <TAB> log.debug(""gpg cmd: %s"", cmd) <TAB> try: <TAB> <TAB> p = subprocess.Popen( <TAB> <TAB> <TAB> cmd, env=os.environ, stdout=subprocess.PIPE, stderr=subprocess.PIPE <TAB> <TAB> ) <TAB> except OSError as e: <TAB> <TAB> log.error(""cannot decode %s with command '%s' (%s)"", path, "" "".join(cmd), e) <TAB> else: <TAB> <TAB> out, err = p.communicate() <TAB> <TAB> if p.returncode != 0: <TAB> <TAB> <TAB> log.error(err.decode(errors=""replace"").strip()) <TAB> <TAB> <TAB> return None <TAB> <TAB> return out.decode(errors=""replace"")",true,if p . returncode != 0 :,if p . returncode != 0 :,0.75,0.0
"def sort_nested_dictionary_lists(d): <TAB> for k, v in d.items(): <TAB> <TAB> if isinstance(v, list): <TAB> <TAB> <TAB> for i in range(0, len(v)): <TAB> <TAB> <TAB> <TAB> if isinstance(v[i], dict): <TAB> <TAB> <TAB> <TAB> <TAB> v[i] = await sort_nested_dictionary_lists(v[i]) <TAB> <TAB> <TAB> <TAB> d[k] = sorted(v) <TAB> <TAB> if isinstance(v, dict): <TAB> <TAB> <TAB> d[k] = await sort_nested_dictionary_lists(v) <TAB> return d",false,"if isinstance ( v , list ) :","if isinstance ( v , dict ) :",0.55,0.0
"def _the_callback(widget, event_id): <TAB> point = widget.GetCenter() <TAB> index = widget.WIDGET_INDEX <TAB> if hasattr(callback, ""__call__""): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> args = [point, index] <TAB> <TAB> else: <TAB> <TAB> <TAB> args = [point] <TAB> <TAB> if pass_widget: <TAB> <TAB> <TAB> args.append(widget) <TAB> <TAB> try_callback(callback, *args) <TAB> return",false,if num > 1 :,if pass_widget :,0.04,0.0
"def _add_cs(master_cs, sub_cs, prefix, delimiter=""."", parent_hp=None): <TAB> new_parameters = [] <TAB> for hp in sub_cs.get_hyperparameters(): <TAB> <TAB> new_parameter = copy.deepcopy(hp) <TAB> <TAB> # Allow for an empty top-level parameter <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> new_parameter.name = prefix <TAB> <TAB> elif not prefix == """": <TAB> <TAB> <TAB> new_parameter.name = ""{}{}{}"".format(prefix, SPLITTER, new_parameter.name) <TAB> <TAB> new_parameters.append(new_parameter) <TAB> for hp in new_parameters: <TAB> <TAB> _add_hp(master_cs, hp)",false,"if new_parameter . name == """" :",if parent_hp is not None :,0.02,0.0
"def tearDown(self): <TAB> """"""Shutdown the server."""""" <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.server.stop() <TAB> <TAB> if self.sl_hdlr: <TAB> <TAB> <TAB> self.root_logger.removeHandler(self.sl_hdlr) <TAB> <TAB> <TAB> self.sl_hdlr.close() <TAB> finally: <TAB> <TAB> BaseTest.tearDown(self)",true,if self . server :,if self . server :,0.75,0.0
"def app_uninstall_all(self, excludes=[], verbose=False): <TAB> """"""Uninstall all apps"""""" <TAB> our_apps = [""com.github.uiautomator"", ""com.github.uiautomator.test""] <TAB> output, _ = self.shell([""pm"", ""list"", ""packages"", ""-3""]) <TAB> pkgs = re.findall(r""package:([^\s]+)"", output) <TAB> pkgs = set(pkgs).difference(our_apps + excludes) <TAB> pkgs = list(pkgs) <TAB> for pkg_name in pkgs: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(""uninstalling"", pkg_name, "" "", end="""", flush=True) <TAB> <TAB> ok = self.app_uninstall(pkg_name) <TAB> <TAB> if verbose: <TAB> <TAB> <TAB> print(""OK"" if ok else ""FAIL"") <TAB> return pkgs",true,if verbose :,if verbose :,0.53,0.0
"def httpapi(self, arg, opts): <TAB> sc = HttpAPIStatsCollector() <TAB> headers = [""#Item"", ""Value""] <TAB> table = [] <TAB> for k, v in sc.get().getStats().items(): <TAB> <TAB> if isinstance(v, dict): <TAB> <TAB> <TAB> v = json.dumps(v) <TAB> <TAB> row = [] <TAB> <TAB> row.append(""#%s"" % k) <TAB> <TAB> if k[-3:] == ""_at"": <TAB> <TAB> <TAB> row.append(formatDateTime(v)) <TAB> <TAB> else: <TAB> <TAB> <TAB> row.append(v) <TAB> <TAB> table.append(row) <TAB> self.protocol.sendData( <TAB> <TAB> tabulate(table, headers, tablefmt=""plain"", numalign=""left"").encode(""ascii"") <TAB> )",true,"if k [ - 3 : ] == ""_at"" :","if k [ - 3 : ] == ""_at"" :",0.75,0.0
"def Get_Gene(self, id): <TAB> """"""Retreive the gene name (GN)."""""" <TAB> entry = self.Get(id) <TAB> if not entry: <TAB> <TAB> return None <TAB> GN = """" <TAB> for line in string.split(entry, ""\n""): <TAB> <TAB> if line[0:5] == ""GN   "": <TAB> <TAB> <TAB> GN = string.strip(line[5:]) <TAB> <TAB> <TAB> if GN[-1] == ""."": <TAB> <TAB> <TAB> <TAB> GN = GN[0:-1] <TAB> <TAB> <TAB> return GN <TAB> <TAB> if line[0:2] == ""//"": <TAB> <TAB> <TAB> break <TAB> return GN",false,"if line [ 0 : 5 ] == ""GN   "" :","if GN [ - 1 ] == ""."" :",0.03,0.0
"def replace_dir_vars(path, d): <TAB> """"""Replace common directory paths with appropriate variable references (e.g. /etc becomes ${sysconfdir})"""""" <TAB> dirvars = {} <TAB> # Sort by length so we get the variables we're interested in first <TAB> for var in sorted(list(d.keys()), key=len): <TAB> <TAB> if var.endswith(""dir"") and var.lower() == var: <TAB> <TAB> <TAB> value = d.getVar(var) <TAB> <TAB> <TAB> if value.startswith(""/"") and not ""\n"" in value and value not in dirvars: <TAB> <TAB> <TAB> <TAB> dirvars[value] = var <TAB> for dirpath in sorted(list(dirvars.keys()), reverse=True): <TAB> <TAB> path = path.replace(dirpath, ""${%s}"" % dirvars[dirpath]) <TAB> return path",true,"if value . startswith ( ""/"" ) and not ""\n"" in value and value not in dirvars :","if value . startswith ( ""/"" ) and not ""\n"" in value and value not in dirvars :",1.0,0.0
"def _scrub_generated_timestamps(self, target_workdir): <TAB> """"""Remove the first line of comment from each file if it contains a timestamp."""""" <TAB> for root, _, filenames in safe_walk(target_workdir): <TAB> <TAB> for filename in filenames: <TAB> <TAB> <TAB> source = os.path.join(root, filename) <TAB> <TAB> <TAB> with open(source, ""r"") as f: <TAB> <TAB> <TAB> <TAB> lines = f.readlines() <TAB> <TAB> <TAB> if len(lines) < 1: <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> with open(source, ""w"") as f: <TAB> <TAB> <TAB> <TAB> if not self._COMMENT_WITH_TIMESTAMP_RE.match(lines[0]): <TAB> <TAB> <TAB> <TAB> <TAB> f.write(lines[0]) <TAB> <TAB> <TAB> <TAB> for line in lines[1:]: <TAB> <TAB> <TAB> <TAB> <TAB> f.write(line)",true,if not self . _COMMENT_WITH_TIMESTAMP_RE . match ( lines [ 0 ] ) :,if not self . _COMMENT_WITH_TIMESTAMP_RE . match ( lines [ 0 ] ) :,0.75,0.0
"def get_all_active_plugins(self) -> List[BotPlugin]: <TAB> """"""This returns the list of plugins in the callback ordered defined from the config."""""" <TAB> all_plugins = [] <TAB> for name in self.plugins_callback_order: <TAB> <TAB> # None is a placeholder for any plugin not having a defined order <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> all_plugins += [ <TAB> <TAB> <TAB> <TAB> plugin <TAB> <TAB> <TAB> <TAB> for name, plugin in self.plugins.items() <TAB> <TAB> <TAB> <TAB> if name not in self.plugins_callback_order and plugin.is_activated <TAB> <TAB> <TAB> ] <TAB> <TAB> else: <TAB> <TAB> <TAB> plugin = self.plugins[name] <TAB> <TAB> <TAB> if plugin.is_activated: <TAB> <TAB> <TAB> <TAB> all_plugins.append(plugin) <TAB> return all_plugins",true,if name is None :,if name is None :,0.75,0.0
"def test_query_level(self): <TAB> ""Tests querying at a level other than max"" <TAB> # level 2 <TAB> l2 = set() <TAB> for p in self.tile_paths: <TAB> <TAB> l2.add(p[0:2]) <TAB> for path in iterate_base4(2): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.assertTrue(self.tree.query_path(path)) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.assertFalse(self.tree.query_path(path)) <TAB> # level 1: <TAB> self.assertTrue(self.tree.query_path((0,))) <TAB> self.assertTrue(self.tree.query_path((1,))) <TAB> self.assertTrue(self.tree.query_path((2,))) <TAB> self.assertFalse(self.tree.query_path((3,)))",true,if path in l2 :,if path in l2 :,0.75,0.0
"def program_exists(name): <TAB> paths = (os.getenv(""PATH"") or os.defpath).split(os.pathsep) <TAB> for p in paths: <TAB> <TAB> fn = ""%s/%s"" % (p, name) <TAB> <TAB> if os.path.exists(fn): <TAB> <TAB> <TAB> return not os.path.isdir(fn) and os.access(fn, os.X_OK)",true,if os . path . exists ( fn ) :,if os . path . exists ( fn ) :,0.75,0.0
"def decoration_helper(self, patched, args, keywargs): <TAB> extra_args = [] <TAB> with contextlib.ExitStack() as exit_stack: <TAB> <TAB> for patching in patched.patchings: <TAB> <TAB> <TAB> arg = exit_stack.enter_context(patching) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> keywargs.update(arg) <TAB> <TAB> <TAB> elif patching.new is DEFAULT: <TAB> <TAB> <TAB> <TAB> extra_args.append(arg) <TAB> <TAB> args += tuple(extra_args) <TAB> <TAB> yield (args, keywargs)",false,if patching . attribute_name is not None :,if patching . old is DEFAULT :,0.21,0.0
"def update_neighbor(neigh_ip_address, changes): <TAB> rets = [] <TAB> for k, v in changes.items(): <TAB> <TAB> if k == neighbors.MULTI_EXIT_DISC: <TAB> <TAB> <TAB> rets.append(_update_med(neigh_ip_address, v)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> rets.append(update_neighbor_enabled(neigh_ip_address, v)) <TAB> <TAB> if k == neighbors.CONNECT_MODE: <TAB> <TAB> <TAB> rets.append(_update_connect_mode(neigh_ip_address, v)) <TAB> return all(rets)",true,if k == neighbors . ENABLED :,if k == neighbors . ENABLED :,0.75,0.0
"def calcUniqueStates(self): <TAB> # Here we show which colors can be relied on to map to an <TAB> # internal state.  The current position will be at the first <TAB> # character in the buffer styled that color, so this might not <TAB> # work in all cases. <TAB> self.uniqueStates = {} <TAB> for k in self.holdUniqueStates.keys(): <TAB> <TAB> v = self.holdUniqueStates[k] <TAB> <TAB> if len(v.keys()) == 1: <TAB> <TAB> <TAB> self.uniqueStates[k] = v.keys()[0] <TAB> <TAB> <TAB> log.debug(""Map style [%s] to state [%s]"", k, v.keys()[0]) <TAB> <TAB> log.debug(""Style [%s] maps to states [%s]"", k, "", "".join(v.keys())) <TAB> self.holdUniqueStates = None",true,if len ( v . keys ( ) ) == 1 :,if len ( v . keys ( ) ) == 1 :,0.75,0.0
"def init_logger(): <TAB> configured_loggers = [log_config.get(""root"", {})] + [ <TAB> <TAB> logger for logger in log_config.get(""loggers"", {}).values() <TAB> ] <TAB> used_handlers = { <TAB> <TAB> handler for log in configured_loggers for handler in log.get(""handlers"", []) <TAB> } <TAB> for handler_id, handler in list(log_config[""handlers""].items()): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> del log_config[""handlers""][handler_id] <TAB> <TAB> elif ""filename"" in handler.keys(): <TAB> <TAB> <TAB> filename = handler[""filename""] <TAB> <TAB> <TAB> logfile_path = Path(filename).expanduser().resolve() <TAB> <TAB> <TAB> handler[""filename""] = str(logfile_path) <TAB> logging.config.dictConfig(log_config)",false,if handler_id not in used_handlers :,if handler_id in used_handlers :,0.23,0.0
"def _selected_machines(self, virtual_machines): <TAB> selected_machines = [] <TAB> for machine in virtual_machines: <TAB> <TAB> if self._args.host and self._args.host == machine.name: <TAB> <TAB> <TAB> selected_machines.append(machine) <TAB> <TAB> if self.tags and self._tags_match(machine.tags, self.tags): <TAB> <TAB> <TAB> selected_machines.append(machine) <TAB> <TAB> if self.locations and machine.location in self.locations: <TAB> <TAB> <TAB> selected_machines.append(machine) <TAB> return selected_machines",false,if self . _args . host and self . _args . host == machine . name :,"if self . tags and self . _tags_match ( machine . tags , self . tags ) :",0.18,0.0
"def init(self): <TAB> r = self.get_redis() <TAB> if r: <TAB> <TAB> key = ""pocsuite_target"" <TAB> <TAB> info_msg = ""[PLUGIN] try fetch targets from redis..."" <TAB> <TAB> logger.info(info_msg) <TAB> <TAB> targets = r.get(key) <TAB> <TAB> count = 0 <TAB> <TAB> if targets: <TAB> <TAB> <TAB> for target in targets: <TAB> <TAB> <TAB> <TAB> if self.add_target(target): <TAB> <TAB> <TAB> <TAB> <TAB> count += 1 <TAB> <TAB> info_msg = ""[PLUGIN] get {0} target(s) from redis"".format(count) <TAB> <TAB> logger.info(info_msg)",true,if self . add_target ( target ) :,if self . add_target ( target ) :,0.75,0.0
"def tearDown(self): <TAB> suffix = str(os.getgid()) <TAB> cli = monitoring_v3.MetricServiceClient() <TAB> for md in cli.list_metric_descriptors(""projects/{}"".format(PROJECT)): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> cli.delete_metric_descriptor(md.name) <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> pass",false,"if ""OpenCensus"" in md . name and suffix in md . name :",if md . name . endswith ( suffix ) and md . name != suffix :,0.32,0.0
"def InitializeColours(self): <TAB> """"""Initializes the 16 custom colours in :class:`CustomPanel`."""""" <TAB> curr = self._colourData.GetColour() <TAB> self._colourSelection = -1 <TAB> for i in range(16): <TAB> <TAB> c = self._colourData.GetCustomColour(i) <TAB> <TAB> if c.IsOk(): <TAB> <TAB> <TAB> self._customColours[i] = self._colourData.GetCustomColour(i) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._customColours[i] = wx.WHITE <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._colourSelection = i",false,if c == curr :,if i != curr :,0.31,0.0
"def __getitem__(self, index): <TAB> if self._check(): <TAB> <TAB> if isinstance(index, int): <TAB> <TAB> <TAB> if index < 0 or index >= len(self.features): <TAB> <TAB> <TAB> <TAB> raise IndexError(index) <TAB> <TAB> <TAB> if self.features[index] is None: <TAB> <TAB> <TAB> <TAB> feature = self.device.feature_request(FEATURE.FEATURE_SET, 0x10, index) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> (feature,) = _unpack(""!H"", feature[:2]) <TAB> <TAB> <TAB> <TAB> <TAB> self.features[index] = FEATURE[feature] <TAB> <TAB> <TAB> return self.features[index] <TAB> <TAB> elif isinstance(index, slice): <TAB> <TAB> <TAB> indices = index.indices(len(self.features)) <TAB> <TAB> <TAB> return [self.__getitem__(i) for i in range(*indices)]",false,if feature :,if len ( feature ) > 2 :,0.05,0.0
"def _get_data_from_buffer(obj): <TAB> try: <TAB> <TAB> view = memoryview(obj) <TAB> except TypeError: <TAB> <TAB> # try to use legacy buffer protocol if 2.7, otherwise re-raise <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> view = memoryview(buffer(obj)) <TAB> <TAB> <TAB> warnings.warn( <TAB> <TAB> <TAB> <TAB> ""using old buffer interface to unpack %s; "" <TAB> <TAB> <TAB> <TAB> ""this leads to unpacking errors if slicing is used and "" <TAB> <TAB> <TAB> <TAB> ""will be removed in a future version"" % type(obj), <TAB> <TAB> <TAB> <TAB> RuntimeWarning, <TAB> <TAB> <TAB> <TAB> stacklevel=3, <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise <TAB> if view.itemsize != 1: <TAB> <TAB> raise ValueError(""cannot unpack from multi-byte object"") <TAB> return view",false,if PY2 :,if sys . version_info [ 2 ] >= 3 :,0.04,0.0
"def import_modules(modules, safe=True): <TAB> """"""Safely import a list of *modules*"""""" <TAB> all = [] <TAB> for mname in modules: <TAB> <TAB> if mname.endswith("".*""): <TAB> <TAB> <TAB> to_load = expand_star(mname) <TAB> <TAB> else: <TAB> <TAB> <TAB> to_load = [mname] <TAB> <TAB> for module in to_load: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> all.append(import_module(module)) <TAB> <TAB> <TAB> except ImportError: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> return all",false,if not safe :,if safe :,0.1,0.0
"def pack(types, *args): <TAB> if len(types) != len(args): <TAB> <TAB> raise Exception(""number of arguments does not match format string"") <TAB> port = StringIO() <TAB> for (type, value) in zip(types, args): <TAB> <TAB> if type == ""V"": <TAB> <TAB> <TAB> write_vuint(port, value) <TAB> <TAB> elif type == ""v"": <TAB> <TAB> <TAB> write_vint(port, value) <TAB> <TAB> elif type == ""s"": <TAB> <TAB> <TAB> write_bvec(port, value) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception('unknown xpack format string item ""' + type + '""') <TAB> return port.getvalue()",true,"elif type == ""v"" :","elif type == ""v"" :",1.0,0.0
"def create_local_app_folder(local_app_path): <TAB> if exists(local_app_path): <TAB> <TAB> raise ValueError(""There is already a '%s' folder! Aborting!"" % local_app_path) <TAB> for folder in subfolders(local_app_path): <TAB> <TAB> if not exists(folder): <TAB> <TAB> <TAB> os.mkdir(folder) <TAB> <TAB> <TAB> init_path = join(folder, ""__init__.py"") <TAB> <TAB> <TAB> if not exists(init_path): <TAB> <TAB> <TAB> <TAB> create_file(init_path)",true,if not exists ( folder ) :,if not exists ( folder ) :,0.75,0.0
"def _get_node_type_specific_fields(self, node_id: str, fields_key: str) -> Any: <TAB> fields = self.config[fields_key] <TAB> node_tags = self.provider.node_tags(node_id) <TAB> if TAG_RAY_USER_NODE_TYPE in node_tags: <TAB> <TAB> node_type = node_tags[TAG_RAY_USER_NODE_TYPE] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError(f""Unknown node type tag: {node_type}."") <TAB> <TAB> node_specific_config = self.available_node_types[node_type] <TAB> <TAB> if fields_key in node_specific_config: <TAB> <TAB> <TAB> fields = node_specific_config[fields_key] <TAB> return fields",true,if node_type not in self . available_node_types :,if node_type not in self . available_node_types :,0.75,0.0
"def _maybe_fix_sequence_in_union( <TAB> aliases: List[Alias], typecst: cst.SubscriptElement ) -> cst.SubscriptElement: <TAB> slc = typecst.slice <TAB> if isinstance(slc, cst.Index): <TAB> <TAB> val = slc.value <TAB> <TAB> if isinstance(val, cst.Subscript): <TAB> <TAB> <TAB> return cst.ensure_type( <TAB> <TAB> <TAB> <TAB> typecst.deep_replace(val, _get_clean_type_from_subscript(aliases, val)), <TAB> <TAB> <TAB> <TAB> cst.SubscriptElement, <TAB> <TAB> <TAB> ) <TAB> return typecst",true,"if isinstance ( val , cst . Subscript ) :","if isinstance ( val , cst . Subscript ) :",0.75,0.0
"def cancel_download(self, downloads): <TAB> # Make sure we're always dealing with a list <TAB> if isinstance(downloads, Download): <TAB> <TAB> downloads = [downloads] <TAB> for download in downloads: <TAB> <TAB> if download == self.__current_download: <TAB> <TAB> <TAB> self.cancel_current_download() <TAB> <TAB> else: <TAB> <TAB> <TAB> self.__paused = True <TAB> <TAB> <TAB> new_queue = queue.Queue() <TAB> <TAB> <TAB> while not self.__queue.empty(): <TAB> <TAB> <TAB> <TAB> queued_download = self.__queue.get() <TAB> <TAB> <TAB> <TAB> if download == queued_download: <TAB> <TAB> <TAB> <TAB> <TAB> download.cancel() <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> new_queue.put(queued_download) <TAB> <TAB> <TAB> self.__queue = new_queue <TAB> <TAB> <TAB> self.__paused = False",true,if download == self . __current_download :,if download == self . __current_download :,0.75,0.0
"def migrate_account_metadata(account_id): <TAB> from inbox.models.session import session_scope <TAB> from inbox.models import Account <TAB> with session_scope(versioned=False) as db_session: <TAB> <TAB> account = db_session.query(Account).get(account_id) <TAB> <TAB> if account.discriminator == ""easaccount"": <TAB> <TAB> <TAB> create_categories_for_easfoldersyncstatuses(account, db_session) <TAB> <TAB> else: <TAB> <TAB> <TAB> create_categories_for_folders(account, db_session) <TAB> <TAB> if account.discriminator == ""gmailaccount"": <TAB> <TAB> <TAB> set_labels_for_imapuids(account, db_session) <TAB> <TAB> db_session.commit()",false,"if account . discriminator == ""gmailaccount"" :","if account . discriminator == ""easaccount"" :",0.57,0.0
"def __init__(self, fmt=None, *args): <TAB> if not isinstance(fmt, BaseException): <TAB> <TAB> Error.__init__(self, fmt, *args) <TAB> else: <TAB> <TAB> e = fmt <TAB> <TAB> cls = e.__class__ <TAB> <TAB> fmt = ""%s.%s: %s"" % (cls.__module__, cls.__name__, e) <TAB> <TAB> tb = sys.exc_info()[2] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> fmt += ""\n"" <TAB> <TAB> <TAB> fmt += """".join(traceback.format_tb(tb)) <TAB> <TAB> Error.__init__(self, fmt)",true,if tb :,if tb :,0.53,0.0
"def setLabel(self, label): <TAB> if label is None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.label.scene().removeItem(self.label) <TAB> <TAB> <TAB> self.label = None <TAB> else: <TAB> <TAB> if self.label is None: <TAB> <TAB> <TAB> self.label = TextItem() <TAB> <TAB> <TAB> self.label.setParentItem(self) <TAB> <TAB> self.label.setText(label) <TAB> <TAB> self._updateLabel()",true,if self . label is not None :,if self . label is not None :,0.75,0.0
"def serve_until_stopped(self) -> None: <TAB> while True: <TAB> <TAB> rd, wr, ex = select.select([self.socket.fileno()], [], [], self.timeout) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.handle_request() <TAB> <TAB> if self.event is not None and self.event.is_set(): <TAB> <TAB> <TAB> break",true,if rd :,if rd :,0.53,0.0
"def generateCompressedFile(inputfile, outputfile, formatstring): <TAB> try: <TAB> <TAB> if formatstring == ""w:xz"": <TAB> <TAB> <TAB> in_file = open(inputfile, ""rb"") <TAB> <TAB> <TAB> in_data = in_file.read() <TAB> <TAB> <TAB> out_file = open(inputfile + "".xz"", ""wb"") <TAB> <TAB> <TAB> out_file.write(xz.compress(in_data)) <TAB> <TAB> <TAB> in_file.close() <TAB> <TAB> <TAB> out_file.close() <TAB> <TAB> else: <TAB> <TAB> <TAB> tarout = tarfile.open(outputfile, formatstring) <TAB> <TAB> <TAB> tarout.add(inputfile, arcname=os.path.basename(inputfile)) <TAB> <TAB> <TAB> tarout.close() <TAB> except Exception as e: <TAB> <TAB> print(e) <TAB> <TAB> return False <TAB> return True",true,"if formatstring == ""w:xz"" :","if formatstring == ""w:xz"" :",0.75,0.0
"def _datastore_get_handler(signal, sender, keys, **kwargs): <TAB> txn = current_transaction() <TAB> if txn: <TAB> <TAB> for key in keys: <TAB> <TAB> <TAB> if key in txn._protected_keys: <TAB> <TAB> <TAB> <TAB> raise PreventedReadError( <TAB> <TAB> <TAB> <TAB> <TAB> ""Attempted to read key (%s:%s) inside a transaction "" <TAB> <TAB> <TAB> <TAB> <TAB> ""where it was marked protected"" % (key.kind(), key.id_or_name()) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> txn._fetched_keys.update(set(keys))",true,if key in txn . _protected_keys :,if key in txn . _protected_keys :,0.75,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.set_access_token(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 16: <TAB> <TAB> <TAB> self.set_expiration_time(d.getVarInt64()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0: <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 10 :,if tt == 10 :,0.75,0.0
"def write_vuint(port, x): <TAB> if x < 0: <TAB> <TAB> raise Exception(""vuints must not be negative"") <TAB> elif x == 0: <TAB> <TAB> port.write(""\0"") <TAB> else: <TAB> <TAB> while x: <TAB> <TAB> <TAB> seven_bits = x & 0x7F <TAB> <TAB> <TAB> x >>= 7 <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> port.write(chr(0x80 | seven_bits)) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> port.write(chr(seven_bits))",false,if x :,if x == 0 :,0.1,0.0
"def _expand_srcs(self): <TAB> """"""Expand src to [(src, full_path)]"""""" <TAB> result = [] <TAB> for src in self.srcs: <TAB> <TAB> full_path = self._source_file_path(src) <TAB> <TAB> if not os.path.exists(full_path): <TAB> <TAB> <TAB> # Assume generated <TAB> <TAB> <TAB> full_path = self._target_file_path(src) <TAB> <TAB> result.append((src, full_path)) <TAB> return result",true,if not os . path . exists ( full_path ) :,if not os . path . exists ( full_path ) :,0.75,0.0
"def pytest_collection_modifyitems(items): <TAB> for item in items: <TAB> <TAB> if item.nodeid.startswith(""tests/ops""): <TAB> <TAB> <TAB> if ""stage"" not in item.keywords: <TAB> <TAB> <TAB> <TAB> item.add_marker(pytest.mark.stage(""unit"")) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> item.add_marker(pytest.mark.init(rng_seed=123))",true,"if ""init"" not in item . keywords :","if ""init"" not in item . keywords :",0.75,0.0
"def set_shape(self, shape): <TAB> """"""Sets a shape."""""" <TAB> if self._shape is not None: <TAB> <TAB> logger.warning('Modifying the shape of Placeholder ""%s"".', self.name) <TAB> if not isinstance(shape, (list, tuple)): <TAB> <TAB> shape = (shape,) <TAB> shape = tuple(x if x != ""None"" else None for x in shape) <TAB> for x in shape: <TAB> <TAB> if not isinstance(x, (int, type(None))): <TAB> <TAB> <TAB> raise ParsingError( <TAB> <TAB> <TAB> <TAB> 'All entries in ""shape"" must be integers, or in special ' <TAB> <TAB> <TAB> <TAB> ""cases None. Shape is: {}"".format(shape) <TAB> <TAB> <TAB> ) <TAB> self._shape = shape",true,"if not isinstance ( x , ( int , type ( None ) ) ) :","if not isinstance ( x , ( int , type ( None ) ) ) :",0.75,0.0
"def _get_field_actual(cant_be_number, raw_string, field_names): <TAB> for line in raw_string.splitlines(): <TAB> <TAB> for field_name in field_names: <TAB> <TAB> <TAB> field_name = field_name.lower() <TAB> <TAB> <TAB> if "":"" in line: <TAB> <TAB> <TAB> <TAB> left, right = line.split("":"", 1) <TAB> <TAB> <TAB> <TAB> left = left.strip().lower() <TAB> <TAB> <TAB> <TAB> right = right.strip() <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> if cant_be_number: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if not right.isdigit(): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return right <TAB> <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return right <TAB> return None",false,if left == field_name and len ( right ) > 0 :,if field_name == left :,0.01,0.0
"def validate_attributes(self): <TAB> for attribute in self.get_all_attributes(): <TAB> <TAB> value = getattr(self, attribute.code, None) <TAB> <TAB> if value is None: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> <TAB> _(""%(attr)s attribute cannot be blank"") % {""attr"": attribute.code} <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> attribute.validate_value(value) <TAB> <TAB> <TAB> except ValidationError as e: <TAB> <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> <TAB> _(""%(attr)s attribute %(err)s"") % {""attr"": attribute.code, ""err"": e} <TAB> <TAB> <TAB> <TAB> )",false,if attribute . required :,if not attribute . blank :,0.06,0.0
"def append(self, s): <TAB> buf = self.buf <TAB> if buf is None: <TAB> <TAB> strbuf = self.strbuf <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.strbuf = strbuf + s <TAB> <TAB> <TAB> return <TAB> <TAB> buf = self._create_buffer() <TAB> buf.append(s) <TAB> # use buf.__len__ rather than len(buf) FBO of not getting <TAB> # OverflowError on Python 2 <TAB> sz = buf.__len__() <TAB> if not self.overflowed: <TAB> <TAB> if sz >= self.overflow: <TAB> <TAB> <TAB> self._set_large_buffer()",false,if len ( strbuf ) + len ( s ) < STRBUF_LIMIT :,if strbuf :,0.01,0.0
"def billing_invoice_show_validator(namespace): <TAB> from azure.cli.core.azclierror import ( <TAB> <TAB> RequiredArgumentMissingError, <TAB> <TAB> MutuallyExclusiveArgumentError, <TAB> ) <TAB> valid_combs = ( <TAB> <TAB> ""only --account-name, --name / --name / --name, --by-subscription is valid"" <TAB> ) <TAB> if namespace.account_name is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise MutuallyExclusiveArgumentError(valid_combs) <TAB> <TAB> if namespace.name is None: <TAB> <TAB> <TAB> raise RequiredArgumentMissingError(""--name is also required"") <TAB> if namespace.by_subscription is not None: <TAB> <TAB> if namespace.name is None: <TAB> <TAB> <TAB> raise RequiredArgumentMissingError(""--name is also required"")",true,if namespace . by_subscription is not None :,if namespace . by_subscription is not None :,0.75,0.0
"def Handle(self, args, context=None): <TAB> for client_id in args.client_ids: <TAB> <TAB> cid = str(client_id) <TAB> <TAB> data_store.REL_DB.RemoveClientLabels(cid, context.username, args.labels) <TAB> <TAB> labels_to_remove = set(args.labels) <TAB> <TAB> existing_labels = data_store.REL_DB.ReadClientLabels(cid) <TAB> <TAB> for label in existing_labels: <TAB> <TAB> <TAB> labels_to_remove.discard(label.name) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> idx = client_index.ClientIndex() <TAB> <TAB> <TAB> idx.RemoveClientLabels(cid, labels_to_remove)",true,if labels_to_remove :,if labels_to_remove :,0.53,0.0
"def delete_snapshot(self, snapshot): <TAB> snap_name = self._get_snap_name(snapshot[""id""]) <TAB> LOG.debug(""Deleting snapshot (%s)"", snapshot[""id""]) <TAB> self.client_login() <TAB> try: <TAB> <TAB> self.client.delete_snapshot(snap_name, self.backend_type) <TAB> except exception.DotHillRequestError as ex: <TAB> <TAB> # if the volume wasn't found, ignore the error <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> LOG.exception(""Deleting snapshot %s failed"", snapshot[""id""]) <TAB> <TAB> raise exception.Invalid(ex) <TAB> finally: <TAB> <TAB> self.client_logout()",false,"if ""The volume was not found on this system."" in ex . args :",if ex . status_code == 404 :,0.02,0.0
"def jobs(self): <TAB> # How many jobs have we done? <TAB> total_processed = 0 <TAB> for jobEntity in self.jobItems.query_entities(): <TAB> <TAB> # Process the items in the page <TAB> <TAB> yield AzureJob.fromEntity(jobEntity) <TAB> <TAB> total_processed += 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # Produce some feedback for the user, because this can take <TAB> <TAB> <TAB> # a long time on, for example, Azure <TAB> <TAB> <TAB> logger.debug(""Processed %d total jobs"" % total_processed) <TAB> logger.debug(""Processed %d total jobs"" % total_processed)",false,if total_processed % 1000 == 0 :,if total_processed % 100 == 0 :,0.39,0.0
def run(self): <TAB> while not self.completed: <TAB> <TAB> if self.block: <TAB> <TAB> <TAB> time.sleep(self.period) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._completed.wait(self.period) <TAB> <TAB> self.counter += 1 <TAB> <TAB> try: <TAB> <TAB> <TAB> self.callback(self.counter) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> self.stop() <TAB> <TAB> if self.timeout is not None: <TAB> <TAB> <TAB> dt = time.time() - self._start_time <TAB> <TAB> <TAB> if dt > self.timeout: <TAB> <TAB> <TAB> <TAB> self.stop() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.stop(),false,if self . counter == self . count :,if dt < self . timeout :,0.09,0.0
"def get_instance(cls, pool_size=None): <TAB> if cls._instance is not None: <TAB> <TAB> return cls._instance <TAB> # Lazy init <TAB> with cls._SINGLETON_LOCK: <TAB> <TAB> if cls._instance is None: <TAB> <TAB> <TAB> cls._instance = cls( <TAB> <TAB> <TAB> <TAB> ARCTIC_ASYNC_NWORKERS if pool_size is None else pool_size <TAB> <TAB> <TAB> ) <TAB> return cls._instance",true,if cls . _instance is None :,if cls . _instance is None :,0.75,0.0
"def set_state(self, state): <TAB> if self._inhibit_play: <TAB> <TAB> # PLAYING, PAUSED change the state for after buffering is finished, <TAB> <TAB> # everything else aborts buffering <TAB> <TAB> if state not in (Gst.State.PLAYING, Gst.State.PAUSED): <TAB> <TAB> <TAB> # abort <TAB> <TAB> <TAB> self.__set_inhibit_play(False) <TAB> <TAB> <TAB> self.bin.set_state(state) <TAB> <TAB> <TAB> return <TAB> <TAB> self._wanted_state = state <TAB> else: <TAB> <TAB> self.bin.set_state(state)",true,"if state not in ( Gst . State . PLAYING , Gst . State . PAUSED ) :","if state not in ( Gst . State . PLAYING , Gst . State . PAUSED ) :",1.0,0.0
"def seen_add(options): <TAB> seen_name = options.add_value <TAB> if is_imdb_url(seen_name): <TAB> <TAB> console(""IMDB url detected, try to parse ID"") <TAB> <TAB> imdb_id = extract_id(seen_name) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> seen_name = imdb_id <TAB> <TAB> else: <TAB> <TAB> <TAB> console(""Could not parse IMDB ID"") <TAB> db.add(seen_name, ""cli_add"", {""cli_add"": seen_name}) <TAB> console(""Added %s as seen. This will affect all tasks."" % seen_name)",true,if imdb_id :,if imdb_id :,0.53,0.0
"def test_204_invalid_content_length(self): <TAB> # 204 status with non-zero content length is malformed <TAB> with ExpectLog(gen_log, "".*Response with code 204 should not have body""): <TAB> <TAB> response = self.fetch(""/?error=1"") <TAB> <TAB> if not self.http1: <TAB> <TAB> <TAB> self.skipTest(""requires HTTP/1.x"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.skipTest(""curl client accepts invalid headers"") <TAB> <TAB> self.assertEqual(response.code, 599)",false,if self . http_client . configured_class != SimpleAsyncHTTPClient :,if response . status != 200 :,0.07,0.0
"def set_related_perm(_mapper: Mapper, _connection: Connection, target: Slice) -> None: <TAB> src_class = target.cls_model <TAB> id_ = target.datasource_id <TAB> if id_: <TAB> <TAB> ds = db.session.query(src_class).filter_by(id=int(id_)).first() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> target.perm = ds.perm <TAB> <TAB> <TAB> target.schema_perm = ds.schema_perm",true,if ds :,if ds :,0.53,0.0
"def on_modified_async(self, view): <TAB> if self.is_command_line(view): <TAB> <TAB> if view.size() > 6 and view.substr(sublime.Region(0, 6)).lower() == ""search"": <TAB> <TAB> <TAB> view.run_command(""text_pastry_selection_preview"")",true,"if view . size ( ) > 6 and view . substr ( sublime . Region ( 0 , 6 ) ) . lower ( ) == ""search"" :","if view . size ( ) > 6 and view . substr ( sublime . Region ( 0 , 6 ) ) . lower ( ) == ""search"" :",1.0,0.0
"def _improve_answer_span( <TAB> doc_tokens, input_start, input_end, tokenizer, orig_answer_text ): <TAB> """"""Returns tokenized answer spans that better match the annotated answer."""""" <TAB> tok_answer_text = "" "".join(tokenizer.tokenize(orig_answer_text)) <TAB> for new_start in range(input_start, input_end + 1): <TAB> <TAB> for new_end in range(input_end, new_start - 1, -1): <TAB> <TAB> <TAB> text_span = "" "".join(doc_tokens[new_start : (new_end + 1)]) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return new_start, new_end <TAB> return input_start, input_end",false,if text_span == tok_answer_text :,if text_span in tok_answer_text :,0.08,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.set_url(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 18: <TAB> <TAB> <TAB> self.set_app_version_id(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 26: <TAB> <TAB> <TAB> self.set_method(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 34: <TAB> <TAB> <TAB> self.set_queue(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0: <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 10 :,if tt == 10 :,0.75,0.0
"def _add_resource_group(obj): <TAB> if isinstance(obj, list): <TAB> <TAB> for array_item in obj: <TAB> <TAB> <TAB> _add_resource_group(array_item) <TAB> elif isinstance(obj, dict): <TAB> <TAB> try: <TAB> <TAB> <TAB> if ""resourcegroup"" not in [x.lower() for x in obj.keys()]: <TAB> <TAB> <TAB> <TAB> if obj[""id""]: <TAB> <TAB> <TAB> <TAB> <TAB> obj[""resourceGroup""] = _parse_id(obj[""id""])[""resource-group""] <TAB> <TAB> except (KeyError, IndexError, TypeError): <TAB> <TAB> <TAB> pass <TAB> <TAB> for item_key in obj: <TAB> <TAB> <TAB> if item_key != ""sourceVault"": <TAB> <TAB> <TAB> <TAB> _add_resource_group(obj[item_key])",false,"if ""resourcegroup"" not in [ x . lower ( ) for x in obj . keys ( ) ] :","if item_key != ""sourceVault"" :",0.0,0.0
"def build(opt): <TAB> dpath = os.path.join(opt[""datapath""], DECODE) <TAB> version = DECODE_VERSION <TAB> if not build_data.built(dpath, version_string=version): <TAB> <TAB> print(""[building data: "" + dpath + ""]"") <TAB> <TAB> if build_data.built(dpath): <TAB> <TAB> <TAB> # An older version exists, so remove these outdated files. <TAB> <TAB> <TAB> build_data.remove_dir(dpath) <TAB> <TAB> build_data.make_dir(dpath) <TAB> <TAB> # Download the data. <TAB> <TAB> for downloadable_file in RESOURCES: <TAB> <TAB> <TAB> downloadable_file.download_file(dpath) <TAB> <TAB> # Mark the data as built. <TAB> <TAB> build_data.mark_done(dpath, version_string=version)",true,if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,0.75,0.0
"def toterminal(self, tw): <TAB> # the entries might have different styles <TAB> last_style = None <TAB> for i, entry in enumerate(self.reprentries): <TAB> <TAB> if entry.style == ""long"": <TAB> <TAB> <TAB> tw.line("""") <TAB> <TAB> entry.toterminal(tw) <TAB> <TAB> if i < len(self.reprentries) - 1: <TAB> <TAB> <TAB> next_entry = self.reprentries[i + 1] <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> entry.style == ""long"" <TAB> <TAB> <TAB> <TAB> or entry.style == ""short"" <TAB> <TAB> <TAB> <TAB> and next_entry.style == ""long"" <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> tw.sep(self.entrysep) <TAB> if self.extraline: <TAB> <TAB> tw.line(self.extraline)",true,"if entry . style == ""long"" :","if entry . style == ""long"" :",0.75,0.0
"def reposition_division(f1): <TAB> lines = f1.splitlines() <TAB> if lines[2] == division: <TAB> <TAB> lines.pop(2) <TAB> found = 0 <TAB> for i, line in enumerate(lines): <TAB> <TAB> if line.startswith('""""""'): <TAB> <TAB> <TAB> found += 1 <TAB> <TAB> <TAB> if found == 2: <TAB> <TAB> <TAB> <TAB> if division in ""\n"".join(lines): <TAB> <TAB> <TAB> <TAB> <TAB> break  # already in the right place <TAB> <TAB> <TAB> <TAB> lines.insert(i + 1, """") <TAB> <TAB> <TAB> <TAB> lines.insert(i + 2, division) <TAB> <TAB> <TAB> <TAB> break <TAB> return ""\n"".join(lines)",true,"if line . startswith ( '""""""' ) :","if line . startswith ( '""""""' ) :",0.75,0.0
def run_on_module(self): <TAB> try: <TAB> <TAB> self.module_base.disable(self.opts.module_spec) <TAB> except dnf.exceptions.MarkingErrors as e: <TAB> <TAB> if self.base.conf.strict: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> e.module_depsolv_errors <TAB> <TAB> <TAB> <TAB> and e.module_depsolv_errors[1] <TAB> <TAB> <TAB> <TAB> != libdnf.module.ModulePackageContainer.ModuleErrorType_ERROR_IN_DEFAULTS <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> logger.error(str(e)),false,if e . no_match_group_specs or e . error_group_specs :,if e . module_depsolv_errors :,0.17,0.0
"def test_len(self): <TAB> eq = self.assertEqual <TAB> eq(base64mime.base64_len(""hello""), len(base64mime.encode(""hello"", eol=""""))) <TAB> for size in range(15): <TAB> <TAB> if size == 0: <TAB> <TAB> <TAB> bsize = 0 <TAB> <TAB> elif size <= 3: <TAB> <TAB> <TAB> bsize = 4 <TAB> <TAB> elif size <= 6: <TAB> <TAB> <TAB> bsize = 8 <TAB> <TAB> elif size <= 9: <TAB> <TAB> <TAB> bsize = 12 <TAB> <TAB> elif size <= 12: <TAB> <TAB> <TAB> bsize = 16 <TAB> <TAB> else: <TAB> <TAB> <TAB> bsize = 20 <TAB> <TAB> eq(base64mime.base64_len(""x"" * size), bsize)",false,elif size <= 9 :,elif size <= 6 :,0.39,0.0
"def is_valid(self): <TAB> """"""Determines whether file is valid for this reader"""""" <TAB> blocklist = self.open() <TAB> valid = True <TAB> for line in blocklist: <TAB> <TAB> line = decode_bytes(line) <TAB> <TAB> if not self.is_ignored(line): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> (start, end) = self.parse(line) <TAB> <TAB> <TAB> <TAB> if not re.match(r""^(\d{1,3}\.){4}$"", start + ""."") or not re.match( <TAB> <TAB> <TAB> <TAB> <TAB> r""^(\d{1,3}\.){4}$"", end + ""."" <TAB> <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> <TAB> valid = False <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> valid = False <TAB> <TAB> <TAB> break <TAB> blocklist.close() <TAB> return valid",false,if not self . is_ignored ( line ) :,"if not re . match ( r""^(\d{1,3}\.{4}$$"" , start + ""."" ) or not re . match (",0.09,0.0
"def next(self): <TAB> while self.index < len(self.data): <TAB> <TAB> uid = self._read_next_word() <TAB> <TAB> dont_care = self._read_next_word() <TAB> <TAB> entry = self._read_next_string() <TAB> <TAB> total_size = int(4 + 4 + len(entry)) <TAB> <TAB> count = int(total_size / self.SIZE) <TAB> <TAB> if count == 0: <TAB> <TAB> <TAB> mod = self.SIZE - total_size <TAB> <TAB> else: <TAB> <TAB> <TAB> mod = self.SIZE - int(total_size - (count * self.SIZE)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> remainder = self._read_next_block(mod) <TAB> <TAB> yield (uid, entry)",false,if mod > 0 :,if mod != 0 :,0.33,0.0
"def _str_param_list(self, name): <TAB> out = [] <TAB> if self[name]: <TAB> <TAB> out += self._str_header(name) <TAB> <TAB> for param in self[name]: <TAB> <TAB> <TAB> parts = [] <TAB> <TAB> <TAB> if param.name: <TAB> <TAB> <TAB> <TAB> parts.append(param.name) <TAB> <TAB> <TAB> if param.type: <TAB> <TAB> <TAB> <TAB> parts.append(param.type) <TAB> <TAB> <TAB> out += ["" : "".join(parts)] <TAB> <TAB> <TAB> if param.desc and """".join(param.desc).strip(): <TAB> <TAB> <TAB> <TAB> out += self._str_indent(param.desc) <TAB> <TAB> out += [""""] <TAB> return out",true,"if param . desc and """" . join ( param . desc ) . strip ( ) :","if param . desc and """" . join ( param . desc ) . strip ( ) :",0.75,0.0
"def assert_backend(self, expected_translated, language=""cs""): <TAB> """"""Check that backend has correct data."""""" <TAB> translation = self.get_translation(language) <TAB> translation.commit_pending(""test"", None) <TAB> store = translation.component.file_format_cls(translation.get_filename(), None) <TAB> messages = set() <TAB> translated = 0 <TAB> for unit in store.content_units: <TAB> <TAB> id_hash = unit.id_hash <TAB> <TAB> self.assertFalse(id_hash in messages, ""Duplicate string in in backend file!"") <TAB> <TAB> if unit.is_translated(): <TAB> <TAB> <TAB> translated += 1 <TAB> self.assertEqual( <TAB> <TAB> translated, <TAB> <TAB> expected_translated, <TAB> <TAB> ""Did not found expected number of translations ({} != {})."".format( <TAB> <TAB> <TAB> translated, expected_translated <TAB> <TAB> ), <TAB> )",true,if unit . is_translated ( ) :,if unit . is_translated ( ) :,0.75,0.0
"def status(self, name, error=""No matching script logs found""): <TAB> with self.script_lock: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return self.script_running[1:] <TAB> <TAB> elif self.script_last and self.script_last[1] == name: <TAB> <TAB> <TAB> return self.script_last[1:] <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(error)",true,if self . script_running and self . script_running [ 1 ] == name :,if self . script_running and self . script_running [ 1 ] == name :,0.75,0.0
"def dict_no_value_from_proto_list(obj_list): <TAB> d = dict() <TAB> for item in obj_list: <TAB> <TAB> possible_dict = json.loads(item.value_json) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # (tss) TODO: This is protecting against legacy 'wandb_version' field. <TAB> <TAB> <TAB> # Should investigate why the config payload even has 'wandb_version'. <TAB> <TAB> <TAB> logger.warning(""key '{}' has no 'value' attribute"".format(item.key)) <TAB> <TAB> <TAB> continue <TAB> <TAB> d[item.key] = possible_dict[""value""] <TAB> return d",false,"if not isinstance ( possible_dict , dict ) or ""value"" not in possible_dict :","if ""value"" not in possible_dict :",0.23,0.0
"def visit(self, node): <TAB> """"""dispatcher on node's class/bases name."""""" <TAB> cls = node.__class__ <TAB> try: <TAB> <TAB> visitmethod = self.cache[cls] <TAB> except KeyError: <TAB> <TAB> for subclass in cls.__mro__: <TAB> <TAB> <TAB> visitmethod = getattr(self, subclass.__name__, None) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> visitmethod = self.__object <TAB> <TAB> self.cache[cls] = visitmethod <TAB> visitmethod(node)",true,if visitmethod is not None :,if visitmethod is not None :,0.75,0.0
"def _get_adapter( <TAB> mcls, <TAB> reversed_mro: Tuple[type, ...], <TAB> collection: Dict[Any, Dict[type, Adapter]], <TAB> kwargs: Dict[str, Any], ) -> Optional[Adapter]: <TAB> registry_key = mcls.get_registry_key(kwargs) <TAB> adapters = collection.get(registry_key) <TAB> if adapters is None: <TAB> <TAB> return None <TAB> result = None <TAB> seen: Set[Adapter] = set() <TAB> for base in reversed_mro: <TAB> <TAB> for adaptee, adapter in adapters.items(): <TAB> <TAB> <TAB> found = mcls._match_adapter(base, adaptee, adapter) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> result = found <TAB> <TAB> <TAB> <TAB> seen.add(found) <TAB> return result",false,if found and found not in seen :,if found not in seen :,0.51,0.0
"def test_pt_BR_rg(self): <TAB> for _ in range(100): <TAB> <TAB> to_test = self.fake.rg() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> assert re.search(r""^\d{8}X"", to_test) <TAB> <TAB> else: <TAB> <TAB> <TAB> assert re.search(r""^\d{9}$"", to_test)",false,"if ""X"" in to_test :",if self . test_pt :,0.03,0.0
"def get_user_extra_data_by_client_id(self, client_id, username): <TAB> extra_data = {} <TAB> current_client = self.clients.get(client_id, None) <TAB> if current_client: <TAB> <TAB> for readable_field in current_client.get_readable_fields(): <TAB> <TAB> <TAB> attribute = list( <TAB> <TAB> <TAB> <TAB> filter( <TAB> <TAB> <TAB> <TAB> <TAB> lambda f: f[""Name""] == readable_field, <TAB> <TAB> <TAB> <TAB> <TAB> self.users.get(username).attributes, <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> extra_data.update({attribute[0][""Name""]: attribute[0][""Value""]}) <TAB> return extra_data",false,if len ( attribute ) > 0 :,if attribute :,0.02,0.0
"def augment(self, resources): <TAB> super().augment(resources) <TAB> for r in resources: <TAB> <TAB> md = r.get(""SAMLMetadataDocument"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> root = sso_metadata(md) <TAB> <TAB> r[""IDPSSODescriptor""] = root[""IDPSSODescriptor""] <TAB> return resources",false,if not md :,if md is None :,0.05,0.0
"def __init__(self, mode=0, decode=None): <TAB> self.regex = self.REGEX[mode] <TAB> self.decode = decode <TAB> if decode: <TAB> <TAB> self.header = _( <TAB> <TAB> <TAB> ""### This log has been decoded with automatic search pattern\n"" <TAB> <TAB> <TAB> ""### If some paths are not decoded you can manually decode them with:\n"" <TAB> <TAB> ) <TAB> <TAB> self.header += ""### 'backintime --quiet "" <TAB> <TAB> if int(decode.config.currentProfile()) > 1: <TAB> <TAB> <TAB> self.header += '--profile ""%s"" ' % decode.config.profileName() <TAB> <TAB> self.header += ""--decode <path>'\n\n"" <TAB> else: <TAB> <TAB> self.header = """"",true,if int ( decode . config . currentProfile ( ) ) > 1 :,if int ( decode . config . currentProfile ( ) ) > 1 :,0.75,0.0
"def _get_dynamic_attr(self, attname, obj, default=None): <TAB> try: <TAB> <TAB> attr = getattr(self, attname) <TAB> except AttributeError: <TAB> <TAB> return default <TAB> if callable(attr): <TAB> <TAB> # Check co_argcount rather than try/excepting the function and <TAB> <TAB> # catching the TypeError, because something inside the function <TAB> <TAB> # may raise the TypeError. This technique is more accurate. <TAB> <TAB> try: <TAB> <TAB> <TAB> code = six.get_function_code(attr) <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> code = six.get_function_code(attr.__call__) <TAB> <TAB><IF-STMT>  # one argument is 'self' <TAB> <TAB> <TAB> return attr(obj) <TAB> <TAB> else: <TAB> <TAB> <TAB> return attr() <TAB> return attr",false,if code . co_argcount == 2 :,if code == obj :,0.04,0.0
"def grep_full_py_identifiers(tokens): <TAB> global pykeywords <TAB> tokens = list(tokens) <TAB> i = 0 <TAB> while i < len(tokens): <TAB> <TAB> tokentype, token = tokens[i] <TAB> <TAB> i += 1 <TAB> <TAB> if tokentype != ""id"": <TAB> <TAB> <TAB> continue <TAB> <TAB> while ( <TAB> <TAB> <TAB> i + 1 < len(tokens) <TAB> <TAB> <TAB> and tokens[i] == (""op"", ""."") <TAB> <TAB> <TAB> and tokens[i + 1][0] == ""id"" <TAB> <TAB> ): <TAB> <TAB> <TAB> token += ""."" + tokens[i + 1][1] <TAB> <TAB> <TAB> i += 2 <TAB> <TAB> if token == """": <TAB> <TAB> <TAB> continue <TAB> <TAB> if token in pykeywords: <TAB> <TAB> <TAB> continue <TAB> <TAB> if token[0] in "".0123456789"": <TAB> <TAB> <TAB> continue <TAB> <TAB> yield token",false,"if tokentype != ""id"" :","if token [ 0 ] in "".0123456789"" :",0.03,0.0
"def _add_disk_config(self, context, images): <TAB> for image in images: <TAB> <TAB> metadata = image[""metadata""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raw_value = metadata[INTERNAL_DISK_CONFIG] <TAB> <TAB> <TAB> value = utils.bool_from_str(raw_value) <TAB> <TAB> <TAB> image[API_DISK_CONFIG] = disk_config_to_api(value)",true,if INTERNAL_DISK_CONFIG in metadata :,if INTERNAL_DISK_CONFIG in metadata :,0.75,0.0
"def test_edgeql_expr_valid_setop_07(self): <TAB> expected_error_msg = ""cannot be applied to operands"" <TAB> # IF ELSE with every scalar as the condition <TAB> for val in get_test_values(): <TAB> <TAB> query = f""""""SELECT 1 IF {val} ELSE 2;"""""" <TAB> <TAB> if val == ""<bool>True"": <TAB> <TAB> <TAB> await self.assert_query_result(query, [1]) <TAB> <TAB> else: <TAB> <TAB> <TAB> # every other combination must produce an error <TAB> <TAB> <TAB> with self.assertRaisesRegex( <TAB> <TAB> <TAB> <TAB> edgedb.QueryError, expected_error_msg, msg=query <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> async with self.con.transaction(): <TAB> <TAB> <TAB> <TAB> <TAB> await self.con.execute(query)",true,"if val == ""<bool>True"" :","if val == ""<bool>True"" :",0.75,0.0
"def get_all_url_infos() -> Dict[str, UrlInfo]: <TAB> """"""Returns dict associating URL to UrlInfo."""""" <TAB> url_infos = {} <TAB> for path in _checksum_paths().values(): <TAB> <TAB> dataset_url_infos = load_url_infos(path) <TAB> <TAB> for url, url_info in dataset_url_infos.items(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise AssertionError( <TAB> <TAB> <TAB> <TAB> <TAB> ""URL {} is registered with 2+ distinct size/checksum tuples. "" <TAB> <TAB> <TAB> <TAB> <TAB> ""{} vs {}"".format(url, url_info, url_infos[url]) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> url_infos.update(dataset_url_infos) <TAB> return url_infos",false,"if url_infos . get ( url , url_info ) != url_info :",if url in url_infos :,0.01,0.0
"def global_fixes(): <TAB> """"""Yield multiple (code, function) tuples."""""" <TAB> for function in list(globals().values()): <TAB> <TAB> if inspect.isfunction(function): <TAB> <TAB> <TAB> arguments = _get_parameters(function) <TAB> <TAB> <TAB> if arguments[:1] != [""source""]: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> code = extract_code_from_function(function) <TAB> <TAB> <TAB> if code: <TAB> <TAB> <TAB> <TAB> yield (code, function)",true,if inspect . isfunction ( function ) :,if inspect . isfunction ( function ) :,0.75,0.0
"def createSocket(self): <TAB> skt = Port.createSocket(self) <TAB> if self.listenMultiple: <TAB> <TAB> skt.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) <TAB> <TAB> if hasattr(socket, ""SO_REUSEPORT""): <TAB> <TAB> <TAB> skt.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1) <TAB> return skt",true,"if hasattr ( socket , ""SO_REUSEPORT"" ) :","if hasattr ( socket , ""SO_REUSEPORT"" ) :",0.75,0.0
"def _asStringList(self, sep=""""): <TAB> out = [] <TAB> for item in self._toklist: <TAB> <TAB> if out and sep: <TAB> <TAB> <TAB> out.append(sep) <TAB> <TAB> if isinstance(item, ParseResults): <TAB> <TAB> <TAB> out += item._asStringList() <TAB> <TAB> else: <TAB> <TAB> <TAB> out.append(str(item)) <TAB> return out",true,"if isinstance ( item , ParseResults ) :","if isinstance ( item , ParseResults ) :",0.75,0.0
"def parse_c_comments(lexer, tok, ntok): <TAB> if tok != ""/"" or ntok != ""*"": <TAB> <TAB> return False <TAB> quotes = lexer.quotes <TAB> lexer.quotes = """" <TAB> while True: <TAB> <TAB> tok = lexer.get_token() <TAB> <TAB> ntok = lexer.get_token() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> lexer.quotes = quotes <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> lexer.push_token(ntok) <TAB> return True",false,"if tok == ""*"" and ntok == ""/"" :","if tok == ""\\"" or ntok == ""*"" :",0.09,0.0
"def doWorkForFindAll(self, v, target, partialMatch): <TAB> sibling = self <TAB> while sibling: <TAB> <TAB> c1 = partialMatch and sibling.equalsTreePartial(target) <TAB> <TAB> if c1: <TAB> <TAB> <TAB> v.append(sibling) <TAB> <TAB> else: <TAB> <TAB> <TAB> c2 = not partialMatch and sibling.equalsTree(target) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> v.append(sibling) <TAB> <TAB> ### regardless of match or not, check any children for matches <TAB> <TAB> if sibling.getFirstChild(): <TAB> <TAB> <TAB> sibling.getFirstChild().doWorkForFindAll(v, target, partialMatch) <TAB> <TAB> sibling = sibling.getNextSibling()",true,if c2 :,if c2 :,0.53,0.0
"def __view_beside(self, onsideof, **kwargs): <TAB> bounds = self.info[""bounds""] <TAB> min_dist, found = -1, None <TAB> for ui in UiObject(self.session, Selector(**kwargs)): <TAB> <TAB> dist = onsideof(bounds, ui.info[""bounds""]) <TAB> <TAB> if dist >= 0 and (min_dist < 0 or dist < min_dist): <TAB> <TAB> <TAB> min_dist, found = dist, ui <TAB> return found",true,if dist >= 0 and ( min_dist < 0 or dist < min_dist ) :,if dist >= 0 and ( min_dist < 0 or dist < min_dist ) :,1.0,0.0
"def __eq__(self, other): <TAB> if isinstance(other, numeric_range): <TAB> <TAB> empty_self = not bool(self) <TAB> <TAB> empty_other = not bool(other) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return empty_self and empty_other  # True if both empty <TAB> <TAB> else: <TAB> <TAB> <TAB> return ( <TAB> <TAB> <TAB> <TAB> self._start == other._start <TAB> <TAB> <TAB> <TAB> and self._step == other._step <TAB> <TAB> <TAB> <TAB> and self._get_by_index(-1) == other._get_by_index(-1) <TAB> <TAB> <TAB> ) <TAB> else: <TAB> <TAB> return False",true,if empty_self or empty_other :,if empty_self or empty_other :,0.75,0.0
"def _buffered_generator(self, size): <TAB> buf = [] <TAB> c_size = 0 <TAB> push = buf.append <TAB> while 1: <TAB> <TAB> try: <TAB> <TAB> <TAB> while c_size < size: <TAB> <TAB> <TAB> <TAB> c = next(self._gen) <TAB> <TAB> <TAB> <TAB> push(c) <TAB> <TAB> <TAB> <TAB> if c: <TAB> <TAB> <TAB> <TAB> <TAB> c_size += 1 <TAB> <TAB> except StopIteration: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> yield concat(buf) <TAB> <TAB> del buf[:] <TAB> <TAB> c_size = 0",false,if not c_size :,if c_size >= size :,0.05,0.0
"def connect(self): <TAB> with self._conn_lock: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> ""Error, database not properly initialized "" ""before opening connection"" <TAB> <TAB> <TAB> ) <TAB> <TAB> with self.exception_wrapper(): <TAB> <TAB> <TAB> self.__local.conn = self._connect(self.database, **self.connect_kwargs) <TAB> <TAB> <TAB> self.__local.closed = False <TAB> <TAB> <TAB> self.initialize_connection(self.__local.conn)",false,if self . deferred :,if self . database is None :,0.2,0.0
"def _merge_substs(self, subst, new_substs): <TAB> subst = subst.copy() <TAB> for new_subst in new_substs: <TAB> <TAB> for name, var in new_subst.items(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> subst[name] = var <TAB> <TAB> <TAB> elif subst[name] is not var: <TAB> <TAB> <TAB> <TAB> subst[name].PasteVariable(var) <TAB> return subst",true,if name not in subst :,if name not in subst :,0.75,0.0
"def remove(self, tag): <TAB> """"""Removes a tag recursively from all containers."""""" <TAB> new_contents = [] <TAB> self.content_size = 0 <TAB> for element in self.contents: <TAB> <TAB> if element.name != tag: <TAB> <TAB> <TAB> new_contents.append(element) <TAB> <TAB> <TAB> if isinstance(element, Container): <TAB> <TAB> <TAB> <TAB> element.remove(tag) <TAB> <TAB> <TAB> self.content_size += element.size() <TAB> self.contents = new_contents",true,"if isinstance ( element , Container ) :","if isinstance ( element , Container ) :",0.75,0.0
"def _create_object(self, obj_body): <TAB> props = obj_body[SYMBOL_PROPERTIES] <TAB> for prop_name, prop_value in props.items(): <TAB> <TAB> if isinstance(prop_value, dict) and prop_value: <TAB> <TAB> <TAB> # get the first key as the convert function <TAB> <TAB> <TAB> func_name = list(prop_value.keys())[0] <TAB> <TAB> <TAB> if func_name.startswith(""_""): <TAB> <TAB> <TAB> <TAB> func = getattr(self, func_name) <TAB> <TAB> <TAB> <TAB> props[prop_name] = func(prop_value[func_name]) <TAB> if SYMBOL_TYPE in obj_body and obj_body[SYMBOL_TYPE] in self.fake_func_mapping: <TAB> <TAB> return self.fake_func_mapping[obj_body[SYMBOL_TYPE]](**props) <TAB> else: <TAB> <TAB> return props",true,"if func_name . startswith ( ""_"" ) :","if func_name . startswith ( ""_"" ) :",0.75,0.0
"def visit_try_stmt(self, o: ""mypy.nodes.TryStmt"") -> str: <TAB> a = [o.body]  # type: List[Any] <TAB> for i in range(len(o.vars)): <TAB> <TAB> a.append(o.types[i]) <TAB> <TAB> if o.vars[i]: <TAB> <TAB> <TAB> a.append(o.vars[i]) <TAB> <TAB> a.append(o.handlers[i]) <TAB> if o.else_body: <TAB> <TAB> a.append((""Else"", o.else_body.body)) <TAB> if o.finally_body: <TAB> <TAB> a.append((""Finally"", o.finally_body.body)) <TAB> return self.dump(a, o)",true,if o . vars [ i ] :,if o . vars [ i ] :,0.75,0.0
"def everythingIsUnicode(d): <TAB> """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB> for k, v in d.iteritems(): <TAB> <TAB> if isinstance(v, dict) and k != ""headers"": <TAB> <TAB> <TAB> if not everythingIsUnicode(v): <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance(v, list): <TAB> <TAB> <TAB> for i in v: <TAB> <TAB> <TAB> <TAB> if isinstance(i, dict) and not everythingIsUnicode(i): <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <TAB> elif isinstance(i, _bytes): <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance(v, _bytes): <TAB> <TAB> <TAB> return False <TAB> return True",false,"elif isinstance ( i , _bytes ) :","if isinstance ( v , dict ) and k != ""headers"" :",0.03,0.0
"def msg_ser(inst, sformat, lev=0): <TAB> if sformat in [""urlencoded"", ""json""]: <TAB> <TAB> if isinstance(inst, Message): <TAB> <TAB> <TAB> res = inst.serialize(sformat, lev) <TAB> <TAB> else: <TAB> <TAB> <TAB> res = inst <TAB> elif sformat == ""dict"": <TAB> <TAB> if isinstance(inst, Message): <TAB> <TAB> <TAB> res = inst.serialize(sformat, lev) <TAB> <TAB> elif isinstance(inst, dict): <TAB> <TAB> <TAB> res = inst <TAB> <TAB> elif isinstance(inst, str):  # Iff ID Token <TAB> <TAB> <TAB> res = inst <TAB> <TAB> else: <TAB> <TAB> <TAB> raise MessageException(""Wrong type: %s"" % type(inst)) <TAB> else: <TAB> <TAB> raise PyoidcError(""Unknown sformat"", inst) <TAB> return res",false,"elif isinstance ( inst , dict ) :","elif isinstance ( inst , str ) :",0.55,0.0
"def start_container_if_stopped(self, container, attach_logs=False, quiet=False): <TAB> if not container.is_running: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> log.info(""Starting %s"" % container.name) <TAB> <TAB> if attach_logs: <TAB> <TAB> <TAB> container.attach_log_stream() <TAB> <TAB> return self.start_container(container)",false,if not quiet :,if quiet :,0.1,0.0
"def layer_op(self, input_image, mask=None): <TAB> if not isinstance(input_image, dict): <TAB> <TAB> self._set_full_border(input_image) <TAB> <TAB> input_image = np.pad(input_image, self.full_border, mode=self.mode) <TAB> <TAB> return input_image, mask <TAB> for name, image in input_image.items(): <TAB> <TAB> self._set_full_border(image) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tf.logging.warning( <TAB> <TAB> <TAB> <TAB> ""could not pad, dict name %s not in %s"", name, self.image_name <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> input_image[name] = np.pad(image, self.full_border, mode=self.mode) <TAB> return input_image, mask",true,if name not in self . image_name :,if name not in self . image_name :,0.75,0.0
"def __Suffix_Noun_Step2b(self, token): <TAB> for suffix in self.__suffix_noun_step2b: <TAB> <TAB> if token.endswith(suffix) and len(token) >= 5: <TAB> <TAB> <TAB> token = token[:-2] <TAB> <TAB> <TAB> self.suffix_noun_step2b_success = True <TAB> <TAB> <TAB> break <TAB> return token",true,if token . endswith ( suffix ) and len ( token ) >= 5 :,if token . endswith ( suffix ) and len ( token ) >= 5 :,1.0,0.0
"def replace_header_items(ps, replacments): <TAB> match = read_while(ps, header_item_or_end_re.match, lambda match: match is None) <TAB> while not ps.current_line.startswith(""*/""): <TAB> <TAB> match = header_item_re.match(ps.current_line) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> key = match.groupdict()[""key""] <TAB> <TAB> <TAB> if key in replacments: <TAB> <TAB> <TAB> <TAB> ps.current_line = match.expand( <TAB> <TAB> <TAB> <TAB> <TAB> ""\g<key>\g<space>%s\n"" % replacments[key] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> ps.read_line()",false,if match is not None :,if match :,0.05,0.0
"def __projectBookmark(widget, location): <TAB> script = None <TAB> while widget is not None: <TAB> <TAB> if hasattr(widget, ""scriptNode""): <TAB> <TAB> <TAB> script = widget.scriptNode() <TAB> <TAB> <TAB> if isinstance(script, Gaffer.ScriptNode): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> widget = widget.parent() <TAB> if script is not None: <TAB> <TAB> p = script.context().substitute(location) <TAB> <TAB> if not os.path.exists(p): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> os.makedirs(p) <TAB> <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> return p <TAB> else: <TAB> <TAB> return os.getcwd()",false,"if hasattr ( widget , ""scriptNode"" ) :","if isinstance ( script , Gaffer . ScriptNode ) :",0.03,0.0
"def events_to_str(event_field, all_events): <TAB> result = [] <TAB> for (flag, string) in all_events: <TAB> <TAB> c_flag = flag <TAB> <TAB> if event_field & c_flag: <TAB> <TAB> <TAB> result.append(string) <TAB> <TAB> <TAB> event_field = event_field & (~c_flag) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> if event_field: <TAB> <TAB> result.append(hex(event_field)) <TAB> return ""|"".join(result)",false,if not event_field :,if event_field :,0.1,0.0
"def get_s3_bucket_locations(buckets, self_log=False): <TAB> """"""return (bucket_name, prefix) for all s3 logging targets"""""" <TAB> for b in buckets: <TAB> <TAB> if b.get(""Logging""): <TAB> <TAB> <TAB> if self_log: <TAB> <TAB> <TAB> <TAB> if b[""Name""] != b[""Logging""][""TargetBucket""]: <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield (b[""Logging""][""TargetBucket""], b[""Logging""][""TargetPrefix""]) <TAB> <TAB> if not self_log and b[""Name""].startswith(""cf-templates-""): <TAB> <TAB> <TAB> yield (b[""Name""], """")",false,"if not self_log and b [ ""Name"" ] . startswith ( ""cf-templates-"" ) :","if b [ ""Name"" ] != b [ ""Logging"" ] [ ""TargetBucket"" ] :",0.1,0.0
"def extract_file(tgz, tarinfo, dst_path, buffer_size=10 << 20, log_function=None): <TAB> """"""Extracts 'tarinfo' from 'tgz' and writes to 'dst_path'."""""" <TAB> src = tgz.extractfile(tarinfo) <TAB> if src is None: <TAB> <TAB> return <TAB> dst = tf.compat.v1.gfile.GFile(dst_path, ""wb"") <TAB> while 1: <TAB> <TAB> buf = src.read(buffer_size) <TAB> <TAB> if not buf: <TAB> <TAB> <TAB> break <TAB> <TAB> dst.write(buf) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> log_function(len(buf)) <TAB> dst.close() <TAB> src.close()",false,if log_function is not None :,if log_function :,0.05,0.0
"def make_index_fields(rec): <TAB> fields = {} <TAB> for k, v in rec.iteritems(): <TAB> <TAB> if k in (""lccn"", ""oclc"", ""isbn""): <TAB> <TAB> <TAB> fields[k] = v <TAB> <TAB> <TAB> continue <TAB> <TAB> if k == ""full_title"": <TAB> <TAB> <TAB> fields[""title""] = [read_short_title(v)] <TAB> return fields",false,"if k == ""full_title"" :","if k in ( ""lccn"" , ""oclc"" , ""isbn"" ) :",0.04,0.0
"def disconnect_application(self): <TAB> if not self.is_app_running(self.APP_BACKDROP): <TAB> <TAB> self.socket.send(commands.CloseCommand(destination_id=False)) <TAB> <TAB> start_time = time.time() <TAB> <TAB> while not self.is_app_running(None): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> self.socket.send_and_wait(commands.StatusCommand()) <TAB> <TAB> <TAB> except cast_socket.ConnectionTerminatedException: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> current_time = time.time() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise TimeoutException() <TAB> <TAB> <TAB> time.sleep(self.WAIT_INTERVAL) <TAB> else: <TAB> <TAB> logger.debug(""Closing not necessary. Backdrop is running ..."")",false,if current_time - start_time > self . timeout :,if current_time - start_time > self . WAIT_INTERVAL :,0.63,0.0
"def matches(self, cursor_offset, line, **kwargs): <TAB> cs = lineparts.current_string(cursor_offset, line) <TAB> if cs is None: <TAB> <TAB> return None <TAB> matches = set() <TAB> username = cs.word.split(os.path.sep, 1)[0] <TAB> user_dir = os.path.expanduser(username) <TAB> for filename in self.safe_glob(os.path.expanduser(cs.word)): <TAB> <TAB> if os.path.isdir(filename): <TAB> <TAB> <TAB> filename += os.path.sep <TAB> <TAB> if cs.word.startswith(""~""): <TAB> <TAB> <TAB> filename = username + filename[len(user_dir) :] <TAB> <TAB> matches.add(filename) <TAB> return matches",false,"if cs . word . startswith ( ""~"" ) :",if os . path . isdir ( filename ) :,0.08,0.0
"def eventFilter(self, obj, event): <TAB> if event.type() == QEvent.MouseButtonPress: <TAB> <TAB> button = event.button() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._app.browser.back() <TAB> <TAB> <TAB> return True <TAB> <TAB> elif button == Qt.ForwardButton: <TAB> <TAB> <TAB> self._app.browser.forward() <TAB> <TAB> <TAB> return True <TAB> return False",true,if button == Qt . BackButton :,if button == Qt . BackButton :,0.75,0.0
"def reset_parameters(self): <TAB> for m in self.modules(): <TAB> <TAB> if isinstance(m, nn.Embedding): <TAB> <TAB> <TAB> continue <TAB> <TAB> elif isinstance(m, nn.LayerNorm): <TAB> <TAB> <TAB> nn.init.constant_(m.weight, 0.1) <TAB> <TAB> <TAB> nn.init.constant_(m.bias, 0) <TAB> <TAB> else: <TAB> <TAB> <TAB> for p in m.parameters(): <TAB> <TAB> <TAB> <TAB> nn.init.normal_(p, 0, 0.1)",true,"elif isinstance ( m , nn . LayerNorm ) :","elif isinstance ( m , nn . LayerNorm ) :",0.75,0.0
"def get_scalding_core(self): <TAB> lib_dir = os.path.join(self.scalding_home, ""lib"") <TAB> for j in os.listdir(lib_dir): <TAB> <TAB> if j.startswith(""scalding-core-""): <TAB> <TAB> <TAB> p = os.path.join(lib_dir, j) <TAB> <TAB> <TAB> logger.debug(""Found scalding-core: %s"", p) <TAB> <TAB> <TAB> return p <TAB> raise luigi.contrib.hadoop.HadoopJobError(""Could not find scalding-core."")",true,"if j . startswith ( ""scalding-core-"" ) :","if j . startswith ( ""scalding-core-"" ) :",0.75,0.0
"def save(self): <TAB> """"""Saves a new set of golden output frames to disk."""""" <TAB> for pixels, (relative_to_assets, filename) in zip( <TAB> <TAB> self.iter_render(), self._iter_paths() <TAB> ): <TAB> <TAB> full_directory_path = os.path.join(self._ASSETS_DIR, relative_to_assets) <TAB> <TAB> if not os.path.exists(full_directory_path): <TAB> <TAB> <TAB> os.makedirs(full_directory_path) <TAB> <TAB> path = os.path.join(full_directory_path, filename) <TAB> <TAB> _save_pixels(pixels, path)",true,if not os . path . exists ( full_directory_path ) :,if not os . path . exists ( full_directory_path ) :,0.75,0.0
"def _fix_var_naming(operators, names, mod=""input""): <TAB> new_names = [] <TAB> map = {} <TAB> for op in operators: <TAB> <TAB> if mod == ""input"": <TAB> <TAB> <TAB> iter = op.inputs <TAB> <TAB> else: <TAB> <TAB> <TAB> iter = op.outputs <TAB> <TAB> for i in iter: <TAB> <TAB> <TAB> for name in names: <TAB> <TAB> <TAB> <TAB> if i.raw_name == name and name not in map: <TAB> <TAB> <TAB> <TAB> <TAB> map[i.raw_name] = i.full_name <TAB> <TAB> if len(map) == len(names): <TAB> <TAB> <TAB> break <TAB> for name in names: <TAB> <TAB> new_names.append(map[name]) <TAB> return new_names",true,"if mod == ""input"" :","if mod == ""input"" :",0.75,0.0
"def Tokenize(s): <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE.findall(s): <TAB> <TAB> # The type checker can't know the true type of item! <TAB> <TAB> item = cast(TupleStr4, item) <TAB> <TAB> if item[0]: <TAB> <TAB> <TAB> typ = ""number"" <TAB> <TAB> <TAB> val = item[0] <TAB> <TAB> elif item[1]: <TAB> <TAB> <TAB> typ = ""name"" <TAB> <TAB> <TAB> val = item[1] <TAB> <TAB> elif item[2]: <TAB> <TAB> <TAB> typ = item[2] <TAB> <TAB> <TAB> val = item[2] <TAB> <TAB> elif item[3]: <TAB> <TAB> <TAB> typ = item[3] <TAB> <TAB> <TAB> val = item[3] <TAB> <TAB> yield Token(typ, val)",false,elif item [ 1 ] :,elif item [ 3 ] :,0.38,0.0
"def init_errorhandler(): <TAB> # http error handling <TAB> for ex in default_exceptions: <TAB> <TAB> if ex < 500: <TAB> <TAB> <TAB> app.register_error_handler(ex, error_http) <TAB> <TAB> elif ex == 500: <TAB> <TAB> <TAB> app.register_error_handler(ex, internal_error) <TAB> if services.ldap: <TAB> <TAB> # Only way of catching the LDAPException upon logging in with LDAP server down <TAB> <TAB> @app.errorhandler(services.ldap.LDAPException) <TAB> <TAB> def handle_exception(e): <TAB> <TAB> <TAB> log.debug(""LDAP server not accessible while trying to login to opds feed"") <TAB> <TAB> <TAB> return error_http(FailedDependency())",true,elif ex == 500 :,elif ex == 500 :,1.0,0.0
"def decode(self, ids): <TAB> ids = pad_decr(ids) <TAB> tokens = [] <TAB> for int_id in ids: <TAB> <TAB> if int_id < len(self._vocab_list): <TAB> <TAB> <TAB> tokens.append(self._vocab_list[int_id]) <TAB> <TAB> else: <TAB> <TAB> <TAB> tokens.append(self._oov_token) <TAB> return self._decode_token_separator.join(tokens)",true,if int_id < len ( self . _vocab_list ) :,if int_id < len ( self . _vocab_list ) :,0.75,0.0
"def remove_contest(contest_id): <TAB> with SessionGen() as session: <TAB> <TAB> contest = session.query(Contest).filter(Contest.id == contest_id).first() <TAB> <TAB> if not contest: <TAB> <TAB> <TAB> print(""No contest with id %s found."" % contest_id) <TAB> <TAB> <TAB> return False <TAB> <TAB> contest_name = contest.name <TAB> <TAB> if not ask(contest): <TAB> <TAB> <TAB> print(""Not removing contest `%s'."" % contest_name) <TAB> <TAB> <TAB> return False <TAB> <TAB> session.delete(contest) <TAB> <TAB> session.commit() <TAB> <TAB> print(""Contest `%s' removed."" % contest_name) <TAB> return True",true,if not ask ( contest ) :,if not ask ( contest ) :,0.75,0.0
def get_hi_lineno(self): <TAB> lineno = Node.get_hi_lineno(self) <TAB> if self.expr1 is None: <TAB> <TAB> pass <TAB> else: <TAB> <TAB> lineno = self.expr1.get_hi_lineno() <TAB> <TAB> if self.expr2 is None: <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> lineno = self.expr2.get_hi_lineno() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> lineno = self.expr3.get_hi_lineno() <TAB> return lineno,true,if self . expr3 is None :,if self . expr3 is None :,0.75,0.0
"def _send_internal(self, bytes_): <TAB> # buffering <TAB> if self.pendings: <TAB> <TAB> self.pendings += bytes_ <TAB> <TAB> bytes_ = self.pendings <TAB> try: <TAB> <TAB> # reconnect if possible <TAB> <TAB> self._reconnect() <TAB> <TAB> # send message <TAB> <TAB> self.socket.sendall(bytes_) <TAB> <TAB> # send finished <TAB> <TAB> self.pendings = None <TAB> except Exception:  # pylint: disable=broad-except <TAB> <TAB> # close socket <TAB> <TAB> self._close() <TAB> <TAB> # clear buffer if it exceeds max bufer size <TAB> <TAB> if self.pendings and (len(self.pendings) > self.bufmax): <TAB> <TAB> <TAB> # TODO: add callback handler here <TAB> <TAB> <TAB> self.pendings = None <TAB> <TAB> else: <TAB> <TAB> <TAB> self.pendings = bytes_",true,if self . pendings and ( len ( self . pendings ) > self . bufmax ) :,if self . pendings and ( len ( self . pendings ) > self . bufmax ) :,1.0,0.0
"def _unpack(self, fmt, byt): <TAB> d = unpack(self._header[""byteorder""] + fmt, byt)[0] <TAB> if fmt[-1] in self.MISSING_VALUES: <TAB> <TAB> nmin, nmax = self.MISSING_VALUES[fmt[-1]] <TAB> <TAB> if d < nmin or d > nmax: <TAB> <TAB> <TAB> if self._missing_values: <TAB> <TAB> <TAB> <TAB> return StataMissingValue(nmax, d) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return None <TAB> return d",true,if self . _missing_values :,if self . _missing_values :,0.75,0.0
"def tuple_iter(self): <TAB> for x in range( <TAB> <TAB> self.center.x - self.max_radius, self.center.x + self.max_radius + 1 <TAB> ): <TAB> <TAB> for y in range( <TAB> <TAB> <TAB> self.center.y - self.max_radius, self.center.y + self.max_radius + 1 <TAB> <TAB> ): <TAB> <TAB> <TAB> if self.min_radius <= self.center.distance((x, y)) <= self.max_radius: <TAB> <TAB> <TAB> <TAB> yield (x, y)",true,"if self . min_radius <= self . center . distance ( ( x , y ) ) <= self . max_radius :","if self . min_radius <= self . center . distance ( ( x , y ) ) <= self . max_radius :",1.0,0.0
"def _parse_gene(element): <TAB> for genename_element in element: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ann_key = ""gene_%s_%s"" % ( <TAB> <TAB> <TAB> <TAB> genename_element.tag.replace(NS, """"), <TAB> <TAB> <TAB> <TAB> genename_element.attrib[""type""], <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if genename_element.attrib[""type""] == ""primary"": <TAB> <TAB> <TAB> <TAB> self.ParsedSeqRecord.annotations[ann_key] = genename_element.text <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> append_to_annotations(ann_key, genename_element.text)",true,"if ""type"" in genename_element . attrib :","if ""type"" in genename_element . attrib :",0.75,0.0
"def invalidateDependentSlices(self, iFirstCurve): <TAB> # only user defined curve can have slice dependency relationships <TAB> if self.isSystemCurveIndex(iFirstCurve): <TAB> <TAB> return <TAB> nCurves = self.getNCurves() <TAB> for i in range(iFirstCurve, nCurves): <TAB> <TAB> c = self.getSystemCurve(i) <TAB> <TAB> if isinstance(c.getSymbol().getSymbolType(), SymbolType.PieSliceSymbolType): <TAB> <TAB> <TAB> c.invalidate() <TAB> <TAB> elif i == iFirstCurve: <TAB> <TAB> <TAB> # if first curve isn't a slice, <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> # there are no dependent slices",false,elif i == iFirstCurve :,"if isinstance ( c . getSymbol ( ) . getSymbolType ( ) , SymbolType . PieSliceSymbolType ) :",0.02,0.0
"def gen_app_versions(self): <TAB> for app_config in apps.get_app_configs(): <TAB> <TAB> name = app_config.verbose_name <TAB> <TAB> app = app_config.module <TAB> <TAB> version = self.get_app_version(app) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield app.__name__, name, version",true,if version :,if version :,0.53,0.0
"def verify_relative_valid_path(root, path): <TAB> if len(path) < 1: <TAB> <TAB> raise PackagerError(""Empty chown path"") <TAB> checkpath = root <TAB> parts = path.split(os.sep) <TAB> for part in parts: <TAB> <TAB> if part in (""."", ""..""): <TAB> <TAB> <TAB> raise PackagerError("". and .. is not allowed in chown path"") <TAB> <TAB> checkpath = os.path.join(checkpath, part) <TAB> <TAB> relpath = checkpath[len(root) + 1 :] <TAB> <TAB> if not os.path.exists(checkpath): <TAB> <TAB> <TAB> raise PackagerError(f""chown path {relpath} does not exist"") <TAB> <TAB> if os.path.islink(checkpath): <TAB> <TAB> <TAB> raise PackagerError(f""chown path {relpath} is a soft link"")",false,if not os . path . exists ( checkpath ) :,"if part in ( ""."" , "".."" ) :",0.03,0.0
"def create_or_update_tag_at_scope(cmd, resource_id=None, tags=None, tag_name=None): <TAB> rcf = _resource_client_factory(cmd.cli_ctx) <TAB> if resource_id is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise IncorrectUsageError(""Tags could not be empty."") <TAB> <TAB> Tags = cmd.get_models(""Tags"") <TAB> <TAB> tag_obj = Tags(tags=tags) <TAB> <TAB> return rcf.tags.create_or_update_at_scope(scope=resource_id, properties=tag_obj) <TAB> return rcf.tags.create_or_update(tag_name=tag_name)",false,if not tags :,if tags is None :,0.05,0.0
"def generate_auto_complete(self, base, iterable_var): <TAB> sugg = [] <TAB> for entry in iterable_var: <TAB> <TAB> compare_entry = entry <TAB> <TAB> compare_base = base <TAB> <TAB> if self.settings.get(IGNORE_CASE_SETTING): <TAB> <TAB> <TAB> compare_entry = compare_entry.lower() <TAB> <TAB> <TAB> compare_base = compare_base.lower() <TAB> <TAB> if self.compare_entries(compare_entry, compare_base): <TAB> <TAB> <TAB> if entry not in sugg: <TAB> <TAB> <TAB> <TAB> sugg.append(entry) <TAB> return sugg",true,"if self . compare_entries ( compare_entry , compare_base ) :","if self . compare_entries ( compare_entry , compare_base ) :",0.75,0.0
"def createFields(self): <TAB> yield String(self, ""dict_start"", 2) <TAB> while not self.eof: <TAB> <TAB> addr = self.absolute_address + self.current_size <TAB> <TAB> if self.stream.readBytes(addr, 2) != "">>"": <TAB> <TAB> <TAB> for field in parsePDFType(self): <TAB> <TAB> <TAB> <TAB> yield field <TAB> <TAB> else: <TAB> <TAB> <TAB> break <TAB> yield String(self, ""dict_end"", 2)",true,"if self . stream . readBytes ( addr , 2 ) != "">>"" :","if self . stream . readBytes ( addr , 2 ) != "">>"" :",0.75,0.0
"def Visit_and_test(self, node):  # pylint: disable=invalid-name <TAB> # and_test ::= not_test ('and' not_test)* <TAB> for child in node.children: <TAB> <TAB> self.Visit(child) <TAB> <TAB> if isinstance(child, pytree.Leaf) and child.value == ""and"": <TAB> <TAB> <TAB> _AppendTokenSubtype(child, format_token.Subtype.BINARY_OPERATOR)",true,"if isinstance ( child , pytree . Leaf ) and child . value == ""and"" :","if isinstance ( child , pytree . Leaf ) and child . value == ""and"" :",1.0,0.0
"def getfiledata(directories): <TAB> columns = None <TAB> data = [] <TAB> counter = 1 <TAB> for directory in directories: <TAB> <TAB> for f in os.listdir(directory): <TAB> <TAB> <TAB> if not os.path.isfile(os.path.join(directory, f)): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> counter += 1 <TAB> <TAB> <TAB> st = os.stat(os.path.join(directory, f)) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> columns = [""rowid"", ""name"", ""directory""] + [ <TAB> <TAB> <TAB> <TAB> <TAB> x for x in dir(st) if x.startswith(""st_"") <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> data.append([counter, f, directory] + [getattr(st, x) for x in columns[3:]]) <TAB> return columns, data",true,if columns is None :,if columns is None :,0.75,0.0
"def copy_attributes(info_add, obj, name_fmt, attributes, formatter=None): <TAB> for attr in attributes: <TAB> <TAB> value = getattr(obj, attr, None) <TAB> <TAB> if value is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> name = name_fmt % attr <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> value = formatter(attr, value) <TAB> <TAB> info_add(name, value)",true,if formatter is not None :,if formatter is not None :,0.75,0.0
"def main(args): <TAB> ap = argparse.ArgumentParser() <TAB> ap.add_argument(""job_ids"", nargs=""+"", type=int, help=""ID of a running job"") <TAB> ns = ap.parse_args(args) <TAB> _stash = globals()[""_stash""] <TAB> """""":type : StaSh"""""" <TAB> for job_id in ns.job_ids: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(""killing job {} ..."".format(job_id)) <TAB> <TAB> <TAB> worker = _stash.runtime.worker_registry.get_worker(job_id) <TAB> <TAB> <TAB> worker.kill() <TAB> <TAB> <TAB> time.sleep(1) <TAB> <TAB> else: <TAB> <TAB> <TAB> print(""error: no such job with id: {}"".format(job_id)) <TAB> <TAB> <TAB> break",false,if job_id in _stash . runtime . worker_registry :,if job_id :,0.02,0.0
"def _check_choice(self): <TAB> if self.type == ""choice"": <TAB> <TAB> if self.choices is None: <TAB> <TAB> <TAB> raise OptionError(""must supply a list of choices for type 'choice'"", self) <TAB> <TAB> elif type(self.choices) not in (types.TupleType, types.ListType): <TAB> <TAB> <TAB> raise OptionError( <TAB> <TAB> <TAB> <TAB> ""choices must be a list of strings ('%s' supplied)"" <TAB> <TAB> <TAB> <TAB> % str(type(self.choices)).split(""'"")[1], <TAB> <TAB> <TAB> <TAB> self, <TAB> <TAB> <TAB> ) <TAB> elif self.choices is not None: <TAB> <TAB> raise OptionError(""must not supply choices for type %r"" % self.type, self)",true,"elif type ( self . choices ) not in ( types . TupleType , types . ListType ) :","elif type ( self . choices ) not in ( types . TupleType , types . ListType ) :",1.0,0.0
"def add_file(pipe, srcpath, tgtpath): <TAB> with open(srcpath, ""rb"") as handle: <TAB> <TAB> if os.access(srcpath, os.X_OK): <TAB> <TAB> <TAB> write(pipe, enc(""M 100755 inline %s\n"" % tgtpath)) <TAB> <TAB> else: <TAB> <TAB> <TAB> write(pipe, enc(""M 100644 inline %s\n"" % tgtpath)) <TAB> <TAB> data = handle.read() <TAB> <TAB> write(pipe, enc(""data %d\n"" % len(data))) <TAB> <TAB> write(pipe, enc(data)) <TAB> <TAB> write(pipe, enc(""\n""))",true,"if os . access ( srcpath , os . X_OK ) :","if os . access ( srcpath , os . X_OK ) :",1.0,0.0
"def cdf(self, x): <TAB> if x == numpy.inf: <TAB> <TAB> return 1.0 <TAB> else:  # Inefficient sum. <TAB> <TAB> if x != int(x): <TAB> <TAB> <TAB> raise RuntimeError(""Invalid value."") <TAB> <TAB> c = 0.0 <TAB> <TAB> for i in xrange(x + 1): <TAB> <TAB> <TAB> c += self.probability(i) <TAB> <TAB> return c",true,if x != int ( x ) :,if x != int ( x ) :,1.0,0.0
"def convert_to_strings(self, out, seq_len): <TAB> results = [] <TAB> for b, batch in enumerate(out): <TAB> <TAB> utterances = [] <TAB> <TAB> for p, utt in enumerate(batch): <TAB> <TAB> <TAB> size = seq_len[b][p] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> transcript = """".join( <TAB> <TAB> <TAB> <TAB> <TAB> map(lambda x: self.int_to_char[x.item()], utt[0:size]) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> transcript = """" <TAB> <TAB> <TAB> utterances.append(transcript) <TAB> <TAB> results.append(utterances) <TAB> return results",false,if size > 0 :,if size :,0.07,0.0
"def get_date_range(self): <TAB> if not hasattr(self, ""start"") or not hasattr(self, ""end""): <TAB> <TAB> args = (self.today.year, self.today.month) <TAB> <TAB> form = self.get_form() <TAB> <TAB> if form.is_valid(): <TAB> <TAB> <TAB> args = (int(form.cleaned_data[""year""]), int(form.cleaned_data[""month""])) <TAB> <TAB> self.start = self.get_start(*args) <TAB> <TAB> self.end = self.get_end(*args) <TAB> return self.start, self.end",true,if form . is_valid ( ) :,if form . is_valid ( ) :,0.75,0.0
"def save_stats(self): <TAB> LOGGER.info(""Saving task-level statistics."") <TAB> has_headers = os.path.isfile(paths.TABLE_COUNT_PATH) <TAB> with open(paths.TABLE_COUNT_PATH, ""a"") as csvfile: <TAB> <TAB> headers = [""start_time"", ""database_name"", ""number_tables""] <TAB> <TAB> writer = csv.DictWriter( <TAB> <TAB> <TAB> csvfile, delimiter="","", lineterminator=""\n"", fieldnames=headers <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> writer.writeheader() <TAB> <TAB> writer.writerow( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> ""start_time"": self.start_time, <TAB> <TAB> <TAB> <TAB> ""database_name"": self.database_name, <TAB> <TAB> <TAB> <TAB> ""number_tables"": self.count, <TAB> <TAB> <TAB> } <TAB> <TAB> )",false,if not has_headers :,if has_headers :,0.1,0.0
"def _CheckCanaryCommand(self): <TAB><IF-STMT>  # fast path <TAB> <TAB> return <TAB> with self._lock: <TAB> <TAB> if OpenStackVirtualMachine.command_works: <TAB> <TAB> <TAB> return <TAB> <TAB> logging.info(""Testing OpenStack CLI command is installed and working"") <TAB> <TAB> cmd = os_utils.OpenStackCLICommand(self, ""image"", ""list"") <TAB> <TAB> stdout, stderr, _ = cmd.Issue() <TAB> <TAB> if stderr: <TAB> <TAB> <TAB> raise errors.Config.InvalidValue( <TAB> <TAB> <TAB> <TAB> ""OpenStack CLI test command failed. Please make sure the OpenStack "" <TAB> <TAB> <TAB> <TAB> ""CLI client is installed and properly configured"" <TAB> <TAB> <TAB> ) <TAB> <TAB> OpenStackVirtualMachine.command_works = True",true,if OpenStackVirtualMachine . command_works :,if OpenStackVirtualMachine . command_works :,0.75,0.0
"def test_windows_hidden(self): <TAB> if not sys.platform == ""win32"": <TAB> <TAB> self.skipTest(""sys.platform is not windows"") <TAB> <TAB> return <TAB> # FILE_ATTRIBUTE_HIDDEN = 2 (0x2) from GetFileAttributes documentation. <TAB> hidden_mask = 2 <TAB> with tempfile.NamedTemporaryFile() as f: <TAB> <TAB> # Hide the file using <TAB> <TAB> success = ctypes.windll.kernel32.SetFileAttributesW(f.name, hidden_mask) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.skipTest(""unable to set file attributes"") <TAB> <TAB> self.assertTrue(hidden.is_hidden(f.name))",true,if not success :,if not success :,0.75,0.0
"def recv_some(p, t=0.1, e=1, tr=5, stderr=0): <TAB> if tr < 1: <TAB> <TAB> tr = 1 <TAB> x = time.time() + t <TAB> y = [] <TAB> r = """" <TAB> if stderr: <TAB> <TAB> pr = p.recv_err <TAB> else: <TAB> <TAB> pr = p.recv <TAB> while time.time() < x or r: <TAB> <TAB> r = pr() <TAB> <TAB> if r is None: <TAB> <TAB> <TAB> break <TAB> <TAB> elif r: <TAB> <TAB> <TAB> y.append(r) <TAB> <TAB> else: <TAB> <TAB> <TAB> time.sleep(max((x - time.time()) / tr, 0)) <TAB> return b"""".join(y)",true,elif r :,elif r :,0.51,0.0
"def _is_xml(accepts): <TAB> if accepts.startswith(b""application/""): <TAB> <TAB> has_xml = accepts.find(b""xml"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> semicolon = accepts.find(b"";"") <TAB> <TAB> <TAB> if semicolon < 0 or has_xml < semicolon: <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",true,if has_xml > 0 :,if has_xml > 0 :,0.75,0.0
"def times(self, value: int): <TAB> if value is None: <TAB> <TAB> self._times = None <TAB> else: <TAB> <TAB> try: <TAB> <TAB> <TAB> candidate = int(value) <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> # pylint: disable:raise-missing-from <TAB> <TAB> <TAB> raise BarException(f""cannot set repeat times to: {value!r}"") <TAB> <TAB> if candidate < 0: <TAB> <TAB> <TAB> raise BarException( <TAB> <TAB> <TAB> <TAB> f""cannot set repeat times to a value less than zero: {value}"" <TAB> <TAB> <TAB> ) <TAB> <TAB> if self.direction == ""start"": <TAB> <TAB> <TAB> raise BarException(""cannot set repeat times on a start Repeat"") <TAB> <TAB> self._times = candidate",true,"if self . direction == ""start"" :","if self . direction == ""start"" :",0.75,0.0
"def __call__(self, *args, **kwargs): <TAB> if not NET_INITTED: <TAB> <TAB> return self.raw(*args, **kwargs) <TAB> for stack in traceback.walk_stack(None): <TAB> <TAB> if ""self"" in stack[0].f_locals: <TAB> <TAB> <TAB> layer = stack[0].f_locals[""self""] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> log.pytorch_layer_name = layer_names[layer] <TAB> <TAB> <TAB> <TAB> print(layer_names[layer]) <TAB> <TAB> <TAB> <TAB> break <TAB> out = self.obj(self.raw, *args, **kwargs) <TAB> # if isinstance(out,Variable): <TAB> # <TAB> out=[out] <TAB> return out",true,if layer in layer_names :,if layer in layer_names :,0.75,0.0
"def do_begin(self, byte): <TAB> if byte.isspace(): <TAB> <TAB> return <TAB> if byte != ""<"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._leadingBodyData = byte <TAB> <TAB> <TAB> return ""bodydata"" <TAB> <TAB> self._parseError(""First char of document [{!r}] wasn't <"".format(byte)) <TAB> return ""tagstart""",false,if self . beExtremelyLenient :,if byte in self . leadingBodyData :,0.22,0.0
"def pretty(self, n, comment=True): <TAB> if isinstance(n, (str, bytes, list, tuple, dict)): <TAB> <TAB> r = repr(n) <TAB> <TAB><IF-STMT>  # then it can be inside a comment! <TAB> <TAB> <TAB> r = r.replace(""*/"", r""\x2a/"") <TAB> <TAB> return r <TAB> if not isinstance(n, six.integer_types): <TAB> <TAB> return n <TAB> if isinstance(n, constants.Constant): <TAB> <TAB> if comment: <TAB> <TAB> <TAB> return ""%s /* %s */"" % (n, self.pretty(int(n))) <TAB> <TAB> else: <TAB> <TAB> <TAB> return ""%s (%s)"" % (n, self.pretty(int(n))) <TAB> elif abs(n) < 10: <TAB> <TAB> return str(n) <TAB> else: <TAB> <TAB> return hex(n)",false,if not comment :,if comment :,0.1,0.0
"def test_training_script_with_max_history_set(tmpdir): <TAB> train_dialogue_model( <TAB> <TAB> DEFAULT_DOMAIN_PATH, <TAB> <TAB> DEFAULT_STORIES_FILE, <TAB> <TAB> tmpdir.strpath, <TAB> <TAB> interpreter=RegexInterpreter(), <TAB> <TAB> policy_config=""data/test_config/max_hist_config.yml"", <TAB> <TAB> kwargs={}, <TAB> ) <TAB> agent = Agent.load(tmpdir.strpath) <TAB> for policy in agent.policy_ensemble.policies: <TAB> <TAB> if hasattr(policy.featurizer, ""max_history""): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> assert policy.featurizer.max_history == 2 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> assert policy.featurizer.max_history == 5",false,if type ( policy ) == FormPolicy :,if policy . featurizer . max_history > 2 :,0.02,0.0
"def cli_uninstall_distro(): <TAB> distro_list = install_distro_list() <TAB> if distro_list is not None: <TAB> <TAB> for index, _distro_dir in enumerate(distro_list): <TAB> <TAB> <TAB> log(str(index) + ""  --->>  "" + _distro_dir) <TAB> <TAB> user_input = read_input_uninstall() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for index, _distro_dir in enumerate(distro_list): <TAB> <TAB> <TAB> <TAB> if index == user_input: <TAB> <TAB> <TAB> <TAB> <TAB> config.uninstall_distro_dir_name = _distro_dir <TAB> <TAB> <TAB> <TAB> <TAB> unin_distro() <TAB> else: <TAB> <TAB> log(""No distro installed on "" + config.usb_disk)",false,if user_input is not False :,if user_input is not None :,0.52,0.0
"def set_random_avatar(user): <TAB> galleries = get_available_galleries(include_default=True) <TAB> if not galleries: <TAB> <TAB> raise RuntimeError(""no avatar galleries are set"") <TAB> avatars_list = [] <TAB> for gallery in galleries: <TAB> <TAB> if gallery[""name""] == DEFAULT_GALLERY: <TAB> <TAB> <TAB> avatars_list = gallery[""images""] <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> avatars_list += gallery[""images""] <TAB> random_avatar = random.choice(avatars_list) <TAB> store.store_new_avatar(user, Image.open(random_avatar.image))",true,"if gallery [ ""name"" ] == DEFAULT_GALLERY :","if gallery [ ""name"" ] == DEFAULT_GALLERY :",0.75,0.0
"def make_query(self, key, filters): <TAB> meta = self.get_meta(key) <TAB> q = {meta.facet_key: self.normalize_key(meta.path)} <TAB> if filters: <TAB> <TAB> if filters.get(""has_fulltext"") == ""true"": <TAB> <TAB> <TAB> q[""has_fulltext""] = ""true"" <TAB> <TAB> if filters.get(""publish_year""): <TAB> <TAB> <TAB> q[""publish_year""] = filters[""publish_year""] <TAB> return q",true,"if filters . get ( ""publish_year"" ) :","if filters . get ( ""publish_year"" ) :",0.75,0.0
"def test_named_parameters_and_constraints(self): <TAB> likelihood = gpytorch.likelihoods.GaussianLikelihood() <TAB> model = ExactGPModel(None, None, likelihood) <TAB> for name, _param, constraint in model.named_parameters_and_constraints(): <TAB> <TAB> if name == ""likelihood.noise_covar.raw_noise"": <TAB> <TAB> <TAB> self.assertIsInstance(constraint, gpytorch.constraints.GreaterThan) <TAB> <TAB> elif name == ""mean_module.constant"": <TAB> <TAB> <TAB> self.assertIsNone(constraint) <TAB> <TAB> elif name == ""covar_module.raw_outputscale"": <TAB> <TAB> <TAB> self.assertIsInstance(constraint, gpytorch.constraints.Positive) <TAB> <TAB> elif name == ""covar_module.base_kernel.raw_lengthscale"": <TAB> <TAB> <TAB> self.assertIsInstance(constraint, gpytorch.constraints.Positive)",false,"elif name == ""mean_module.constant"" :","elif name == ""covar_module.base_kernel.raw_lengthscale"" :",0.64,0.0
"def _test_pooling(input_shape, **kwargs): <TAB> _test_pooling_iteration(input_shape, **kwargs) <TAB> if is_gpu_available(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> input_shape = [input_shape[ii] for ii in (0, 3, 1, 2)] <TAB> <TAB> <TAB> kwargs[""data_format""] = ""NCHW"" <TAB> <TAB> <TAB> _test_pooling_iteration(input_shape, **kwargs)",false,if len ( input_shape ) == 4 :,if input_shape . shape [ 0 ] == 3 :,0.02,0.0
"def init(self): <TAB> r = self.get_redis() <TAB> if r: <TAB> <TAB> key = ""pocsuite_target"" <TAB> <TAB> info_msg = ""[PLUGIN] try fetch targets from redis..."" <TAB> <TAB> logger.info(info_msg) <TAB> <TAB> targets = r.get(key) <TAB> <TAB> count = 0 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for target in targets: <TAB> <TAB> <TAB> <TAB> if self.add_target(target): <TAB> <TAB> <TAB> <TAB> <TAB> count += 1 <TAB> <TAB> info_msg = ""[PLUGIN] get {0} target(s) from redis"".format(count) <TAB> <TAB> logger.info(info_msg)",true,if targets :,if targets :,0.53,0.0
"def reload_json_api_settings(*args, **kwargs): <TAB> django_setting = kwargs[""setting""] <TAB> setting = django_setting.replace(JSON_API_SETTINGS_PREFIX, """") <TAB> value = kwargs[""value""] <TAB> if setting in DEFAULTS.keys(): <TAB> <TAB> if value is not None: <TAB> <TAB> <TAB> setattr(json_api_settings, setting, value) <TAB> <TAB> elif hasattr(json_api_settings, setting): <TAB> <TAB> <TAB> delattr(json_api_settings, setting)",true,"elif hasattr ( json_api_settings , setting ) :","elif hasattr ( json_api_settings , setting ) :",0.75,0.0
"def update_metadata(self): <TAB> for attrname in dir(self): <TAB> <TAB> if attrname.startswith(""__""): <TAB> <TAB> <TAB> continue <TAB> <TAB> attrvalue = getattr(self, attrname, None) <TAB> <TAB> if attrvalue == 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> if attrname == ""salt_version"": <TAB> <TAB> <TAB> attrname = ""version"" <TAB> <TAB> if hasattr(self.metadata, ""set_{0}"".format(attrname)): <TAB> <TAB> <TAB> getattr(self.metadata, ""set_{0}"".format(attrname))(attrvalue) <TAB> <TAB> elif hasattr(self.metadata, attrname): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> setattr(self.metadata, attrname, attrvalue) <TAB> <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> <TAB> pass",false,"elif hasattr ( self . metadata , attrname ) :","if attrname . startswith ( ""__"" ) :",0.03,0.0
"def test_02_looking_at_listdir_path_(name): <TAB> for dline in listdir.json(): <TAB> <TAB> if dline[""path""] == f""{path}/{name}"": <TAB> <TAB> <TAB> assert dline[""type""] in (""DIRECTORY"", ""FILE""), listdir.text <TAB> <TAB> <TAB> assert dline[""uid""] == 0, listdir.text <TAB> <TAB> <TAB> assert dline[""gid""] == 0, listdir.text <TAB> <TAB> <TAB> assert dline[""name""] == name, listdir.text <TAB> <TAB> <TAB> break <TAB> else: <TAB> <TAB> raise AssertionError(f""/{path}/{name} not found"")",true,"if dline [ ""path"" ] == f""{path}/{name}"" :","if dline [ ""path"" ] == f""{path}/{name}"" :",0.75,0.0
"def DeletePlugin(): <TAB> oid = request.form.get(""oid"", """") <TAB> if oid: <TAB> <TAB> result = Mongo.coll[""Plugin""].find_one_and_delete( <TAB> <TAB> <TAB> {""_id"": ObjectId(oid)}, remove=True <TAB> <TAB> ) <TAB> <TAB> if not result[""filename""].find(""."") > -1: <TAB> <TAB> <TAB> result[""filename""] = result[""filename""] + "".py"" <TAB> <TAB> if os.path.exists(file_path + result[""filename""]): <TAB> <TAB> <TAB> os.remove(file_path + result[""filename""]) <TAB> <TAB> <TAB> return ""success"" <TAB> return ""fail""",false,"if not result [ ""filename"" ] . find ( ""."" ) > - 1 :","if os . path . exists ( file_path + result [ ""filename"" ] ) :",0.1,0.0
"def iterparent(self, node): <TAB> """"""Iterator wrapper to get allowed parent and child all at once."""""" <TAB> # We do not allow the marker inside a header as that <TAB> # would causes an enless loop of placing a new TOC <TAB> # inside previously generated TOC. <TAB> for child in node: <TAB> <TAB> if not self.header_rgx.match(child.tag) and child.tag not in [""pre"", ""code""]: <TAB> <TAB> <TAB> yield node, child <TAB> <TAB> <TAB> yield from self.iterparent(child)",true,"if not self . header_rgx . match ( child . tag ) and child . tag not in [ ""pre"" , ""code"" ] :","if not self . header_rgx . match ( child . tag ) and child . tag not in [ ""pre"" , ""code"" ] :",0.75,0.0
"def _get_matched_layout(command): <TAB> # don't use command.split_script here because a layout mismatch will likely <TAB> # result in a non-splitable script as per shlex <TAB> cmd = command.script.split("" "") <TAB> for source_layout in source_layouts: <TAB> <TAB> is_all_match = True <TAB> <TAB> for cmd_part in cmd: <TAB> <TAB> <TAB> if not all([ch in source_layout or ch in ""-_"" for ch in cmd_part]): <TAB> <TAB> <TAB> <TAB> is_all_match = False <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return source_layout",true,if is_all_match :,if is_all_match :,0.53,0.0
"def _update_tileable_and_chunk_shape(self, tileable_graph, chunk_result, failed_ops): <TAB> for n in tileable_graph: <TAB> <TAB> if n.op in failed_ops: <TAB> <TAB> <TAB> continue <TAB> <TAB> tiled_n = get_tiled(n) <TAB> <TAB> if has_unknown_shape(tiled_n): <TAB> <TAB> <TAB> if any(c.key not in chunk_result for c in tiled_n.chunks): <TAB> <TAB> <TAB> <TAB> # some of the chunks has been fused <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_nsplits = self.get_tileable_nsplits(n, chunk_result=chunk_result) <TAB> <TAB> <TAB> for node in (n, tiled_n): <TAB> <TAB> <TAB> <TAB> node._update_shape(tuple(sum(nsplit) for nsplit in new_nsplits)) <TAB> <TAB> <TAB> tiled_n._nsplits = new_nsplits",true,if any ( c . key not in chunk_result for c in tiled_n . chunks ) :,if any ( c . key not in chunk_result for c in tiled_n . chunks ) :,0.75,0.0
"def _get_items(self, name, target=1): <TAB> all_items = self.get_items(name) <TAB> items = [o for o in all_items if not o.disabled] <TAB> if len(items) < target: <TAB> <TAB> if len(all_items) < target: <TAB> <TAB> <TAB> raise ItemNotFoundError(""insufficient items with name %r"" % name) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise AttributeError(""insufficient non-disabled items with name %s"" % name) <TAB> on = [] <TAB> off = [] <TAB> for o in items: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> on.append(o) <TAB> <TAB> else: <TAB> <TAB> <TAB> off.append(o) <TAB> return on, off",false,if o . selected :,if o . disabled :,0.39,0.0
"def parse_flow_sequence_entry_mapping_value(self): <TAB> if self.check_token(ValueToken): <TAB> <TAB> token = self.get_token() <TAB> <TAB> if not self.check_token(FlowEntryToken, FlowSequenceEndToken): <TAB> <TAB> <TAB> self.states.append(self.parse_flow_sequence_entry_mapping_end) <TAB> <TAB> <TAB> return self.parse_flow_node() <TAB> <TAB> else: <TAB> <TAB> <TAB> self.state = self.parse_flow_sequence_entry_mapping_end <TAB> <TAB> <TAB> return self.process_empty_scalar(token.end_mark) <TAB> else: <TAB> <TAB> self.state = self.parse_flow_sequence_entry_mapping_end <TAB> <TAB> token = self.peek_token() <TAB> <TAB> return self.process_empty_scalar(token.start_mark)",true,"if not self . check_token ( FlowEntryToken , FlowSequenceEndToken ) :","if not self . check_token ( FlowEntryToken , FlowSequenceEndToken ) :",0.75,0.0
"def serialize_config(self, session, key, tid, language): <TAB> cache_key = gen_cache_key(key, tid, language) <TAB> cache_obj = None <TAB> if cache_key not in self.cache: <TAB> <TAB> if key == ""node"": <TAB> <TAB> <TAB> cache_obj = db_admin_serialize_node(session, tid, language) <TAB> <TAB> elif key == ""notification"": <TAB> <TAB> <TAB> cache_obj = db_get_notification(session, tid, language) <TAB> <TAB> self.cache[cache_key] = cache_obj <TAB> return self.cache[cache_key]",false,"if key == ""node"" :","elif key == ""notification"" :",0.06,0.0
"def get_lldp_neighbors(self): <TAB> commands = [""show lldp neighbors""] <TAB> output = self.device.run_commands(commands)[0][""lldpNeighbors""] <TAB> lldp = {} <TAB> for n in output: <TAB> <TAB> if n[""port""] not in lldp.keys(): <TAB> <TAB> <TAB> lldp[n[""port""]] = [] <TAB> <TAB> lldp[n[""port""]].append( <TAB> <TAB> <TAB> {""hostname"": n[""neighborDevice""], ""port"": n[""neighborPort""]} <TAB> <TAB> ) <TAB> return lldp",true,"if n [ ""port"" ] not in lldp . keys ( ) :","if n [ ""port"" ] not in lldp . keys ( ) :",0.75,0.0
"def handle(self): <TAB> from poetry.utils.env import EnvManager <TAB> manager = EnvManager(self.poetry) <TAB> current_env = manager.get() <TAB> for venv in manager.list(): <TAB> <TAB> name = venv.path.name <TAB> <TAB> if self.option(""full-path""): <TAB> <TAB> <TAB> name = str(venv.path) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.line(""<info>{} (Activated)</info>"".format(name)) <TAB> <TAB> <TAB> continue <TAB> <TAB> self.line(name)",false,if venv == current_env :,if name in current_env :,0.06,0.0
"def resolve_env_secrets(config, environ): <TAB> """"""Create copy that recursively replaces {""$env"": ""NAME""} with values from environ"""""" <TAB> if isinstance(config, dict): <TAB> <TAB> if list(config.keys()) == [""$env""]: <TAB> <TAB> <TAB> return environ.get(list(config.values())[0]) <TAB> <TAB> elif list(config.keys()) == [""$file""]: <TAB> <TAB> <TAB> return open(list(config.values())[0]).read() <TAB> <TAB> else: <TAB> <TAB> <TAB> return { <TAB> <TAB> <TAB> <TAB> key: resolve_env_secrets(value, environ) <TAB> <TAB> <TAB> <TAB> for key, value in config.items() <TAB> <TAB> <TAB> } <TAB> elif isinstance(config, list): <TAB> <TAB> return [resolve_env_secrets(value, environ) for value in config] <TAB> else: <TAB> <TAB> return config",false,"elif list ( config . keys ( ) ) == [ ""$file"" ] :","if list ( config . keys ( ) ) == [ ""$env"" ] :",0.45,0.0
"def _is_valid_16bit_as_path(cls, buf): <TAB> two_byte_as_size = struct.calcsize(""!H"") <TAB> while buf: <TAB> <TAB> (type_, num_as) = struct.unpack_from( <TAB> <TAB> <TAB> cls._SEG_HDR_PACK_STR, six.binary_type(buf) <TAB> <TAB> ) <TAB> <TAB> if type_ is not cls._AS_SET and type_ is not cls._AS_SEQUENCE: <TAB> <TAB> <TAB> return False <TAB> <TAB> buf = buf[struct.calcsize(cls._SEG_HDR_PACK_STR) :] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> buf = buf[num_as * two_byte_as_size :] <TAB> return True",false,if len ( buf ) < num_as * two_byte_as_size :,if num_as * two_byte_as_size > 2 :,0.1,0.0
"def reparentChildren(self, newParent): <TAB> if newParent.childNodes: <TAB> <TAB> newParent.childNodes[-1]._element.tail += self._element.text <TAB> else: <TAB> <TAB> if not newParent._element.text: <TAB> <TAB> <TAB> newParent._element.text = """" <TAB> <TAB> if self._element.text is not None: <TAB> <TAB> <TAB> newParent._element.text += self._element.text <TAB> self._element.text = """" <TAB> base.Node.reparentChildren(self, newParent)",false,if not newParent . _element . text :,if self . _element . text is not None :,0.18,0.0
"def get_operation_ast(document_ast, operation_name=None): <TAB> operation = None <TAB> for definition in document_ast.definitions: <TAB> <TAB> if isinstance(definition, ast.OperationDefinition): <TAB> <TAB> <TAB> if not operation_name: <TAB> <TAB> <TAB> <TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB> <TAB> <TAB> <TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB> <TAB> <TAB> <TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB> <TAB> <TAB> <TAB> if operation: <TAB> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> <TAB> operation = definition <TAB> <TAB> <TAB> elif definition.name and definition.name.value == operation_name: <TAB> <TAB> <TAB> <TAB> return definition <TAB> return operation",true,elif definition . name and definition . name . value == operation_name :,elif definition . name and definition . name . value == operation_name :,1.0,0.0
"def reprSmart(vw, item): <TAB> ptype = type(item) <TAB> if ptype is int: <TAB> <TAB> if -1024 < item < 1024: <TAB> <TAB> <TAB> return str(item) <TAB> <TAB> elif vw.isValidPointer(item): <TAB> <TAB> <TAB> return vw.reprPointer(item) <TAB> <TAB> else: <TAB> <TAB> <TAB> return hex(item) <TAB> elif ptype in (list, tuple): <TAB> <TAB> return reprComplex(vw, item)  # recurse <TAB> elif ptype is dict: <TAB> <TAB> return ""{%s}"" % "","".join( <TAB> <TAB> <TAB> [""%s:%s"" % (reprSmart(vw, k), reprSmart(vw, v)) for k, v in item.items()] <TAB> <TAB> ) <TAB> else: <TAB> <TAB> return repr(item)",false,if - 1024 < item < 1024 :,elif vw . isValidPointer ( item ) :,0.02,0.0
"def cleanDataCmd(cmd): <TAB> newcmd = ""AbracadabrA ** <?php "" <TAB> if cmd[:6] != ""php://"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> cmds = cmd.split(""&"") <TAB> <TAB> <TAB> for c in cmds: <TAB> <TAB> <TAB> <TAB> if len(c) > 0: <TAB> <TAB> <TAB> <TAB> <TAB> newcmd += ""system('%s');"" % c <TAB> <TAB> else: <TAB> <TAB> <TAB> b64cmd = base64.b64encode(cmd) <TAB> <TAB> <TAB> newcmd += ""system(base64_decode('%s'));"" % b64cmd <TAB> else: <TAB> <TAB> newcmd += cmd[6:] <TAB> newcmd += ""?> **"" <TAB> return newcmd",false,if reverseConn not in cmd :,"if ""&"" in cmd :",0.12,0.0
"def render_tasks(self) -> List: <TAB> results = [] <TAB> for task in self.tasks.values(): <TAB> <TAB> job_entry = self.jobs.get(task.job_id) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if not self.should_render_job(job_entry): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> files = self.get_file_counts([task]) <TAB> <TAB> entry = ( <TAB> <TAB> <TAB> task.job_id, <TAB> <TAB> <TAB> task.task_id, <TAB> <TAB> <TAB> task.state, <TAB> <TAB> <TAB> task.type.name, <TAB> <TAB> <TAB> task.target, <TAB> <TAB> <TAB> files, <TAB> <TAB> <TAB> task.pool, <TAB> <TAB> <TAB> task.end_time, <TAB> <TAB> ) <TAB> <TAB> results.append(entry) <TAB> return results",true,if job_entry :,if job_entry :,0.53,0.0
"def __call__(self, environ, start_response): <TAB> for key in ""REQUEST_URL"", ""REQUEST_URI"", ""UNENCODED_URL"": <TAB> <TAB> if key not in environ: <TAB> <TAB> <TAB> continue <TAB> <TAB> request_uri = unquote(environ[key]) <TAB> <TAB> script_name = unquote(environ.get(""SCRIPT_NAME"", """")) <TAB> <TAB> if request_uri.startswith(script_name): <TAB> <TAB> <TAB> environ[""PATH_INFO""] = request_uri[len(script_name) :].split(""?"", 1)[0] <TAB> <TAB> <TAB> break <TAB> return self.app(environ, start_response)",true,if request_uri . startswith ( script_name ) :,if request_uri . startswith ( script_name ) :,0.75,0.0
"def _add_role_information(self, function_dict, role_id): <TAB> # Make it easier to build rules based on policies attached to execution roles <TAB> function_dict[""role_arn""] = role_id <TAB> role_name = role_id.split(""/"")[-1] <TAB> function_dict[ <TAB> <TAB> ""execution_role"" <TAB> ] = await self.facade.awslambda.get_role_with_managed_policies(role_name) <TAB> if function_dict.get(""execution_role""): <TAB> <TAB> statements = [] <TAB> <TAB> for policy in function_dict[""execution_role""].get(""policies""): <TAB> <TAB> <TAB> if ""Document"" in policy and ""Statement"" in policy[""Document""]: <TAB> <TAB> <TAB> <TAB> statements += policy[""Document""][""Statement""] <TAB> <TAB> function_dict[""execution_role""][""policy_statements""] = statements",true,"if ""Document"" in policy and ""Statement"" in policy [ ""Document"" ] :","if ""Document"" in policy and ""Statement"" in policy [ ""Document"" ] :",1.0,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB> if tt == 8: <TAB> <TAB> <TAB> self.set_ts(d.getVarInt64()) <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 0 :,if tt == 0 :,0.75,0.0
"def format_counts(results, json_output=False, human_readable=False): <TAB> if json_output: <TAB> <TAB> for result in results: <TAB> <TAB> <TAB> yield json.dumps(result) <TAB> else: <TAB> <TAB> for result in results: <TAB> <TAB> <TAB> space_consumed = result.get(""spaceConsumed"") <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> space_consumed = _sizeof_fmt(int(result.get(""spaceConsumed""))) <TAB> <TAB> <TAB> yield ""%12s %12s %18s %s"" % ( <TAB> <TAB> <TAB> <TAB> result.get(""directoryCount""), <TAB> <TAB> <TAB> <TAB> result.get(""fileCount""), <TAB> <TAB> <TAB> <TAB> space_consumed, <TAB> <TAB> <TAB> <TAB> result.get(""path""), <TAB> <TAB> <TAB> )",true,if human_readable :,if human_readable :,0.53,0.0
"def parse_edges(self, pcb): <TAB> edges = [] <TAB> drawings = list(pcb.GetDrawings()) <TAB> bbox = None <TAB> for m in pcb.GetModules(): <TAB> <TAB> for g in m.GraphicalItems(): <TAB> <TAB> <TAB> drawings.append(g) <TAB> for d in drawings: <TAB> <TAB> if d.GetLayer() == pcbnew.Edge_Cuts: <TAB> <TAB> <TAB> parsed_drawing = self.parse_drawing(d) <TAB> <TAB> <TAB> if parsed_drawing: <TAB> <TAB> <TAB> <TAB> edges.append(parsed_drawing) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> bbox = d.GetBoundingBox() <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> bbox.Merge(d.GetBoundingBox()) <TAB> if bbox: <TAB> <TAB> bbox.Normalize() <TAB> return edges, bbox",true,if bbox is None :,if bbox is None :,0.75,0.0
"def __getitem__(self, k) -> ""SimMemView"": <TAB> if isinstance(k, slice): <TAB> <TAB> if k.step is not None: <TAB> <TAB> <TAB> raise ValueError(""Slices with strides are not supported"") <TAB> <TAB> elif k.start is None: <TAB> <TAB> <TAB> raise ValueError(""Must specify start index"") <TAB> <TAB> elif k.stop is not None: <TAB> <TAB> <TAB> raise ValueError(""Slices with stop index are not supported"") <TAB> <TAB> else: <TAB> <TAB> <TAB> addr = k.start <TAB> elif self._type is not None and self._type._can_refine_int: <TAB> <TAB> return self._type._refine(self, k) <TAB> else: <TAB> <TAB> addr = k <TAB> return self._deeper(addr=addr)",false,elif k . start is None :,elif k . stop is None :,0.39,0.0
"def _parse(self, stream, context): <TAB> obj = [] <TAB> try: <TAB> <TAB> if self.subcon.conflags & self.FLAG_COPY_CONTEXT: <TAB> <TAB> <TAB> while True: <TAB> <TAB> <TAB> <TAB> subobj = self.subcon._parse(stream, context.__copy__()) <TAB> <TAB> <TAB> <TAB> obj.append(subobj) <TAB> <TAB> <TAB> <TAB> if self.predicate(subobj, context): <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> while True: <TAB> <TAB> <TAB> <TAB> subobj = self.subcon._parse(stream, context) <TAB> <TAB> <TAB> <TAB> obj.append(subobj) <TAB> <TAB> <TAB> <TAB> if self.predicate(subobj, context): <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> except ConstructError as ex: <TAB> <TAB> raise ArrayError(""missing terminator"", ex) <TAB> return obj",true,"if self . predicate ( subobj , context ) :","if self . predicate ( subobj , context ) :",0.75,0.0
"def before_run(self, run_context): <TAB> if ""featurizer"" in self.model_portion and ( <TAB> <TAB> self.need_to_refresh or self.refresh_base_model <TAB> ): <TAB> <TAB> if self.model_portion == ""whole_featurizer"": <TAB> <TAB> <TAB> self.refresh_base_model = True <TAB> <TAB> self.init_fn( <TAB> <TAB> <TAB> None, run_context.session, self.model_portion, self.refresh_base_model <TAB> <TAB> ) <TAB> <TAB> self.need_to_refresh = False <TAB> <TAB> self.refresh_base_model = False",true,"if self . model_portion == ""whole_featurizer"" :","if self . model_portion == ""whole_featurizer"" :",0.75,0.0
"def run(self): <TAB> while True: <TAB> <TAB> task = self.requestQueue.get() <TAB> <TAB> if task is None: <TAB> <TAB> <TAB> # The ""None"" value is used as a sentinel by <TAB> <TAB> <TAB> # ThreadPool.cleanup().  This indicates that there <TAB> <TAB> <TAB> # are no more tasks, so we should quit. <TAB> <TAB> <TAB> break <TAB> <TAB> try: <TAB> <TAB> <TAB> if self.interrupted(): <TAB> <TAB> <TAB> <TAB> raise SCons.Errors.BuildError(task.targets[0], errstr=interrupt_msg) <TAB> <TAB> <TAB> task.execute() <TAB> <TAB> except: <TAB> <TAB> <TAB> task.exception_set() <TAB> <TAB> <TAB> ok = False <TAB> <TAB> else: <TAB> <TAB> <TAB> ok = True <TAB> <TAB> self.resultsQueue.put((task, ok))",true,if self . interrupted ( ) :,if self . interrupted ( ) :,0.75,0.0
"def get_overdue_evergreen_documents(*, db_session) -> List[Optional[Document]]: <TAB> """"""Returns all documents that have need had a recent evergreen notification."""""" <TAB> documents = ( <TAB> <TAB> db_session.query(Document).filter(Document.evergreen == True) <TAB> ).all()  # noqa <TAB> overdue_documents = [] <TAB> now = datetime.utcnow() <TAB> for d in documents: <TAB> <TAB> next_reminder = d.evergreen_last_reminder_at + timedelta( <TAB> <TAB> <TAB> days=d.evergreen_reminder_interval <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> overdue_documents.append(d) <TAB> return overdue_documents",false,if now > next_reminder :,if next_reminder > now :,0.29,0.0
"def create_local_app_folder(local_app_path): <TAB> if exists(local_app_path): <TAB> <TAB> raise ValueError(""There is already a '%s' folder! Aborting!"" % local_app_path) <TAB> for folder in subfolders(local_app_path): <TAB> <TAB> if not exists(folder): <TAB> <TAB> <TAB> os.mkdir(folder) <TAB> <TAB> <TAB> init_path = join(folder, ""__init__.py"") <TAB> <TAB> <TAB> if not exists(init_path): <TAB> <TAB> <TAB> <TAB> create_file(init_path)",false,if not exists ( init_path ) :,if not exists ( folder ) :,0.5,0.0
"def generate(): <TAB> for leaf in u.leaves: <TAB> <TAB> if isinstance(leaf, Integer): <TAB> <TAB> <TAB> val = leaf.get_int_value() <TAB> <TAB> <TAB> if val in (0, 1): <TAB> <TAB> <TAB> <TAB> yield val <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> elif isinstance(leaf, Symbol): <TAB> <TAB> <TAB> if leaf == SymbolTrue: <TAB> <TAB> <TAB> <TAB> yield 1 <TAB> <TAB> <TAB> elif leaf == SymbolFalse: <TAB> <TAB> <TAB> <TAB> yield 0 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> else: <TAB> <TAB> <TAB> raise _NoBoolVector",false,"if isinstance ( leaf , Integer ) :",elif leaf == SymbolFalse :,0.02,0.0
"def replace(self, old, new): <TAB> v_m = self.var_map <TAB> size = v_m[self.size] <TAB> if not (size.is_const() or size.is_ident()): <TAB> <TAB> size.replace(old, new) <TAB> else: <TAB> <TAB> if new.is_ident(): <TAB> <TAB> <TAB> v_m[new.value()] = new <TAB> <TAB> <TAB> self.size = new.value() <TAB> <TAB> else: <TAB> <TAB> <TAB> v_m[old] = new",true,if new . is_ident ( ) :,if new . is_ident ( ) :,0.75,0.0
"def method_for_doctype(doctype): <TAB> method = ""xhtml"" <TAB> if doctype: <TAB> <TAB> if doctype.startswith(""html""): <TAB> <TAB> <TAB> method = ""html"" <TAB> <TAB> elif doctype.startswith(""xhtml""): <TAB> <TAB> <TAB> method = ""xhtml"" <TAB> <TAB> elif doctype.startswith(""svg""): <TAB> <TAB> <TAB> method = ""xml"" <TAB> <TAB> else: <TAB> <TAB> <TAB> method = ""xhtml"" <TAB> return method",true,"elif doctype . startswith ( ""xhtml"" ) :","elif doctype . startswith ( ""xhtml"" ) :",0.75,0.0
"def delete(self, trans, **kwd): <TAB> idnum = kwd[self.tagged_item_id] <TAB> item = self._get_item_from_id(trans, idnum, check_writable=True) <TAB> if item is not None: <TAB> <TAB> ex_obj = self.get_item_extended_metadata_obj(trans, item) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.unset_item_extended_metadata_obj(trans, item) <TAB> <TAB> <TAB> self.delete_extended_metadata(trans, ex_obj)",true,if ex_obj is not None :,if ex_obj is not None :,0.75,0.0
"def check_testv(self, testv): <TAB> test_good = True <TAB> f = open(self.home, ""rb+"") <TAB> for (offset, length, operator, specimen) in testv: <TAB> <TAB> data = self._read_share_data(f, offset, length) <TAB> <TAB> if not testv_compare(data, operator, specimen): <TAB> <TAB> <TAB> test_good = False <TAB> <TAB> <TAB> break <TAB> f.close() <TAB> return test_good",true,"if not testv_compare ( data , operator , specimen ) :","if not testv_compare ( data , operator , specimen ) :",0.75,0.0
"def get_history_user(self, instance): <TAB> """"""Get the modifying user from instance or middleware."""""" <TAB> try: <TAB> <TAB> return instance._history_user <TAB> except AttributeError: <TAB> <TAB> request = None <TAB> <TAB> try: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> request = self.thread.request <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> pass <TAB> return self.get_user(instance=instance, request=request)",false,if self . thread . request . user . is_authenticated :,if self . thread :,0.16,0.0
"def _check(self, name, size=None, *extra): <TAB> func = getattr(imageop, name) <TAB> for height in VALUES: <TAB> <TAB> for width in VALUES: <TAB> <TAB> <TAB> strlen = abs(width * height) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> strlen *= size <TAB> <TAB> <TAB> if strlen < MAX_LEN: <TAB> <TAB> <TAB> <TAB> data = ""A"" * strlen <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> data = AAAAA <TAB> <TAB> <TAB> if size: <TAB> <TAB> <TAB> <TAB> arguments = (data, size, width, height) + extra <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> arguments = (data, width, height) + extra <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> func(*arguments) <TAB> <TAB> <TAB> except (ValueError, imageop.error): <TAB> <TAB> <TAB> <TAB> pass",true,if size :,if size :,0.53,0.0
"def __setattr__(self, name, value): <TAB> if name == ""path"": <TAB> <TAB> if value and value != """": <TAB> <TAB> <TAB> if value[0] != ""/"": <TAB> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> <TAB> 'The page path should always start with a slash (""/"").' <TAB> <TAB> <TAB> <TAB> ) <TAB> elif name == ""load_time"": <TAB> <TAB> if value and not isinstance(value, int): <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""Page load time must be specified in integer milliseconds."" <TAB> <TAB> <TAB> ) <TAB> object.__setattr__(self, name, value)",true,"if value and not isinstance ( value , int ) :","if value and not isinstance ( value , int ) :",0.75,0.0
"def __repr__(self): <TAB> if self._in_repr: <TAB> <TAB> return ""<recursion>"" <TAB> try: <TAB> <TAB> self._in_repr = True <TAB> <TAB> if self.is_computed(): <TAB> <TAB> <TAB> status = ""computed, "" <TAB> <TAB> <TAB> if self.error() is None: <TAB> <TAB> <TAB> <TAB> if self.value() is self: <TAB> <TAB> <TAB> <TAB> <TAB> status += ""= self"" <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> status += ""= "" + repr(self.value()) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> status += ""error = "" + repr(self.error()) <TAB> <TAB> else: <TAB> <TAB> <TAB> status = ""isn't computed"" <TAB> <TAB> return ""%s (%s)"" % (type(self), status) <TAB> finally: <TAB> <TAB> self._in_repr = False",false,if self . error ( ) is None :,if self . is_computed ( ) :,0.21,0.0
"def _exclude_node(self, name): <TAB> if ""exclude_nodes"" in self.node_filters: <TAB> <TAB> if name in self.node_filters[""exclude_nodes""]: <TAB> <TAB> <TAB> self.loggit.info('Excluding node ""{0}"" due to node_filters'.format(name)) <TAB> <TAB> <TAB> return True <TAB> return False",true,"if name in self . node_filters [ ""exclude_nodes"" ] :","if name in self . node_filters [ ""exclude_nodes"" ] :",0.75,0.0
"def enumerate_projects(): <TAB> """"""List projects in _DEFAULT_APP_DIR."""""" <TAB> src_path = os.path.join(_DEFAULT_APP_DIR, ""src"") <TAB> projects = {} <TAB> for project in os.listdir(src_path): <TAB> <TAB> projects[project] = [] <TAB> <TAB> project_path = os.path.join(src_path, project) <TAB> <TAB> for file in os.listdir(project_path): <TAB> <TAB> <TAB> if file.endswith("".gwt.xml""): <TAB> <TAB> <TAB> <TAB> projects[project].append(file[:-8]) <TAB> return projects",true,"if file . endswith ( "".gwt.xml"" ) :","if file . endswith ( "".gwt.xml"" ) :",0.75,0.0
"def zip_readline_read_test(self, f, compression): <TAB> self.make_test_archive(f, compression) <TAB> # Read the ZIP archive <TAB> with zipfile.ZipFile(f, ""r"") as zipfp, zipfp.open(TESTFN) as zipopen: <TAB> <TAB> data = b"""" <TAB> <TAB> while True: <TAB> <TAB> <TAB> read = zipopen.readline() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> data += read <TAB> <TAB> <TAB> read = zipopen.read(100) <TAB> <TAB> <TAB> if not read: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> data += read <TAB> self.assertEqual(data, self.data)",true,if not read :,if not read :,0.75,0.0
"def f(view, s): <TAB> if mode == modes.NORMAL: <TAB> <TAB> return sublime.Region(0) <TAB> elif mode == modes.VISUAL: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return sublime.Region(s.a + 1, 0) <TAB> <TAB> else: <TAB> <TAB> <TAB> return sublime.Region(s.a, 0) <TAB> elif mode == modes.INTERNAL_NORMAL: <TAB> <TAB> return sublime.Region(view.full_line(s.b).b, 0) <TAB> elif mode == modes.VISUAL_LINE: <TAB> <TAB> if s.a < s.b: <TAB> <TAB> <TAB> return sublime.Region(0, s.b) <TAB> <TAB> else: <TAB> <TAB> <TAB> return sublime.Region(0, s.a) <TAB> return s",true,if s . a < s . b :,if s . a < s . b :,0.75,0.0
"def response(self): <TAB> try: <TAB> <TAB> response = requests.get(str(self)) <TAB> <TAB> rjson = response.json() <TAB> <TAB> if not isinstance(rjson, dict): <TAB> <TAB> <TAB> raise Exception(response.text) <TAB> <TAB> return rjson <TAB> except Exception as e: <TAB> <TAB> raise ResponseFanartError(str(e))",true,"if not isinstance ( rjson , dict ) :","if not isinstance ( rjson , dict ) :",0.75,0.0
"def __get_type(self, cexpr): <TAB> """"""Returns one of the following types: 'R' - read value, 'W' - write value, 'A' - function argument"""""" <TAB> child = cexpr <TAB> for p in reversed(self.parents): <TAB> <TAB> assert p, ""Failed to get type at "" + helper.to_hex(self.__function_address) <TAB> <TAB> if p.cexpr.op == idaapi.cot_call: <TAB> <TAB> <TAB> return ""Arg"" <TAB> <TAB> if not p.is_expr(): <TAB> <TAB> <TAB> return ""R"" <TAB> <TAB> if p.cexpr.op == idaapi.cot_asg: <TAB> <TAB> <TAB> if p.cexpr.x == child: <TAB> <TAB> <TAB> <TAB> return ""W"" <TAB> <TAB> <TAB> return ""R"" <TAB> <TAB> child = p.cexpr",false,if p . cexpr . x == child :,if p . cpr . op == idaapi . cot_call :,0.16,0.0
"def _extract_lemma(self, parse: Parse) -> str: <TAB> special_feats = [x for x in self.SPECIAL_FEATURES if x in parse.tag] <TAB> if len(special_feats) == 0: <TAB> <TAB> return parse.normal_form <TAB> # here we process surnames and patronyms since PyMorphy lemmatizes them incorrectly <TAB> for other in parse.lexeme: <TAB> <TAB> tag = other.tag <TAB> <TAB> if any(x not in tag for x in special_feats): <TAB> <TAB> <TAB> continue <TAB> <TAB> if ( <TAB> <TAB> <TAB> tag.case == ""nomn"" <TAB> <TAB> <TAB> and tag.gender == parse.tag.gender <TAB> <TAB> <TAB> and tag.number == ""sing"" <TAB> <TAB> ): <TAB> <TAB> <TAB> return other.word <TAB> return parse.normal_form",true,if any ( x not in tag for x in special_feats ) :,if any ( x not in tag for x in special_feats ) :,0.75,0.0
"def evaluateWord(self, argument): <TAB> wildcard_count = argument[0].count(""*"") <TAB> if wildcard_count > 0: <TAB> <TAB> if wildcard_count == 1 and argument[0].startswith(""*""): <TAB> <TAB> <TAB> return self.GetWordWildcard(argument[0][1:], method=""endswith"") <TAB> <TAB> if wildcard_count == 1 and argument[0].endswith(""*""): <TAB> <TAB> <TAB> return self.GetWordWildcard(argument[0][:-1], method=""startswith"") <TAB> <TAB> else: <TAB> <TAB> <TAB> _regex = argument[0].replace(""*"", "".+"") <TAB> <TAB> <TAB> matched = False <TAB> <TAB> <TAB> for w in self.words: <TAB> <TAB> <TAB> <TAB> matched = bool(re.search(_regex, w)) <TAB> <TAB> <TAB> <TAB> if matched: <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> return matched <TAB> return self.GetWord(argument[0])",false,"if wildcard_count == 1 and argument [ 0 ] . endswith ( ""*"" ) :","if wildcard_count == 1 and argument [ 0 ] . startswith ( ""*"" ) :",0.65,0.0
def getAllEntries(self): <TAB> entries = [] <TAB> for bucket in self.buckets: <TAB> <TAB> last = None <TAB> <TAB> for entry in bucket.entries: <TAB> <TAB> <TAB> if last is not None: <TAB> <TAB> <TAB> <TAB> last.size = entry.virtualOffset - last.virtualOffset <TAB> <TAB> <TAB> last = entry <TAB> <TAB> <TAB> entries.append(entry) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> entries[-1].size = bucket.endOffset - entries[-1].virtualOffset <TAB> return entries,false,if len ( entries ) != 0 :,if len ( entries ) > 1 :,0.52,0.0
"def clean(self): <TAB> if self._ctx: <TAB> <TAB> if hasattr(libcrypto, ""EVP_CIPHER_CTX_cleanup""): <TAB> <TAB> <TAB> libcrypto.EVP_CIPHER_CTX_cleanup(self._ctx) <TAB> <TAB> else: <TAB> <TAB> <TAB> libcrypto.EVP_CIPHER_CTX_reset(self._ctx) <TAB> <TAB> libcrypto.EVP_CIPHER_CTX_free(self._ctx)",true,"if hasattr ( libcrypto , ""EVP_CIPHER_CTX_cleanup"" ) :","if hasattr ( libcrypto , ""EVP_CIPHER_CTX_cleanup"" ) :",0.75,0.0
"def _addTab(self, name, label, idx=None): <TAB> label = getLanguageString(label) <TAB> tab = Tab(self, name, label) <TAB> tab.idx = self._makeTab(tab, idx) <TAB> if idx != None: <TAB> <TAB> # Update index list when inserting tabs at arbitrary positions <TAB> <TAB> newIdxList = {} <TAB> <TAB> for tIdx, t in list(self._tabs_by_idx.items()): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> t.idx += 1 <TAB> <TAB> <TAB> newIdxList[t.idx] = t <TAB> <TAB> self._tabs_by_idx = newIdxList <TAB> self._tabs_by_idx[tab.idx] = tab <TAB> self._tabs_by_name[tab.name] = tab <TAB> return tab",false,if int ( tIdx ) >= idx :,if tIdx == idx :,0.04,0.0
"def set(self, _key, _new_login=True): <TAB> with self.lock: <TAB> <TAB> user = self.users.get(current_user.id, None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.users[current_user.id] = dict(session_count=1, key=_key) <TAB> <TAB> else: <TAB> <TAB> <TAB> if _new_login: <TAB> <TAB> <TAB> <TAB> user[""session_count""] += 1 <TAB> <TAB> <TAB> user[""key""] = _key",true,if user is None :,if user is None :,0.75,0.0
"def stop(self): <TAB> # Try to shut the connection down, but if we get any sort of <TAB> # errors, go ahead and ignore them.. as we're shutting down anyway <TAB> try: <TAB> <TAB> self.rpcserver.stop() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.backend_rpcserver.stop() <TAB> <TAB> if self.cluster_rpcserver: <TAB> <TAB> <TAB> self.cluster_rpcserver.stop() <TAB> except Exception: <TAB> <TAB> pass <TAB> if self.coordination: <TAB> <TAB> try: <TAB> <TAB> <TAB> coordination.COORDINATOR.stop() <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> pass <TAB> super(Service, self).stop(graceful=True)",true,if self . backend_rpcserver :,if self . backend_rpcserver :,0.75,0.0
"def __genmenuOnlyAllocated(menu): <TAB> for submenu in menu.Submenus: <TAB> <TAB> __genmenuOnlyAllocated(submenu) <TAB> if menu.OnlyUnallocated == True: <TAB> <TAB> tmp[""cache""].addMenuEntries(menu.AppDirs) <TAB> <TAB> menuentries = [] <TAB> <TAB> for rule in menu.Rules: <TAB> <TAB> <TAB> menuentries = rule.do( <TAB> <TAB> <TAB> <TAB> tmp[""cache""].getMenuEntries(menu.AppDirs), rule.Type, 2 <TAB> <TAB> <TAB> ) <TAB> <TAB> for menuentry in menuentries: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> menuentry.Parents.append(menu) <TAB> <TAB> <TAB> <TAB> #   menuentry.Add = False <TAB> <TAB> <TAB> <TAB> #   menuentry.Allocated = True <TAB> <TAB> <TAB> <TAB> menu.MenuEntries.append(menuentry)",true,if menuentry . Add == True :,if menuentry . Add == True :,0.75,0.0
"def __init__(self, **options): <TAB> self.func_name_highlighting = get_bool_opt(options, ""func_name_highlighting"", True) <TAB> self.disabled_modules = get_list_opt(options, ""disabled_modules"", []) <TAB> self._functions = set() <TAB> if self.func_name_highlighting: <TAB> <TAB> from pygments.lexers._lua_builtins import MODULES <TAB> <TAB> for mod, func in iteritems(MODULES): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self._functions.update(func) <TAB> RegexLexer.__init__(self, **options)",false,if mod not in self . disabled_modules :,if mod in self . disabled_modules :,0.43,0.0
"def recv_some(p, t=0.1, e=1, tr=5, stderr=0): <TAB> if tr < 1: <TAB> <TAB> tr = 1 <TAB> x = time.time() + t <TAB> y = [] <TAB> r = """" <TAB> if stderr: <TAB> <TAB> pr = p.recv_err <TAB> else: <TAB> <TAB> pr = p.recv <TAB> while time.time() < x or r: <TAB> <TAB> r = pr() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> elif r: <TAB> <TAB> <TAB> y.append(r) <TAB> <TAB> else: <TAB> <TAB> <TAB> time.sleep(max((x - time.time()) / tr, 0)) <TAB> return """".join(y)",false,if r is None :,"if r == """" :",0.06,0.0
"def get_menu_items(node): <TAB> aList = [] <TAB> for child in node.children: <TAB> <TAB> for tag in (""@menu"", ""@item""): <TAB> <TAB> <TAB> if child.h.startswith(tag): <TAB> <TAB> <TAB> <TAB> name = child.h[len(tag) + 1 :].strip() <TAB> <TAB> <TAB> <TAB> if tag == ""@menu"": <TAB> <TAB> <TAB> <TAB> <TAB> aList.append((""%s %s"" % (tag, name), get_menu_items(child), None)) <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> b = g.splitLines("""".join(child.b)) <TAB> <TAB> <TAB> <TAB> <TAB> aList.append((tag, name, b[0] if b else """")) <TAB> <TAB> <TAB> <TAB> break <TAB> return aList",false,"if tag == ""@menu"" :",if child . h . startswith ( tag ) :,0.03,0.0
"def import_suffix_generator(a_block, datatype=False): <TAB> if datatype is False: <TAB> <TAB> for name, suffix in iteritems(a_block.component_map(Suffix)): <TAB> <TAB> <TAB> if suffix.import_enabled() is True: <TAB> <TAB> <TAB> <TAB> yield name, suffix <TAB> else: <TAB> <TAB> for name, suffix in iteritems(a_block.component_map(Suffix)): <TAB> <TAB> <TAB> if (suffix.import_enabled() is True) and ( <TAB> <TAB> <TAB> <TAB> suffix.get_datatype() is datatype <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> yield name, suffix",true,if suffix . import_enabled ( ) is True :,if suffix . import_enabled ( ) is True :,0.75,0.0
"def verify_relative_valid_path(root, path): <TAB> if len(path) < 1: <TAB> <TAB> raise PackagerError(""Empty chown path"") <TAB> checkpath = root <TAB> parts = path.split(os.sep) <TAB> for part in parts: <TAB> <TAB> if part in (""."", ""..""): <TAB> <TAB> <TAB> raise PackagerError("". and .. is not allowed in chown path"") <TAB> <TAB> checkpath = os.path.join(checkpath, part) <TAB> <TAB> relpath = checkpath[len(root) + 1 :] <TAB> <TAB> if not os.path.exists(checkpath): <TAB> <TAB> <TAB> raise PackagerError(f""chown path {relpath} does not exist"") <TAB> <TAB> if os.path.islink(checkpath): <TAB> <TAB> <TAB> raise PackagerError(f""chown path {relpath} is a soft link"")",false,if os . path . islink ( checkpath ) :,"if part in ( ""."" , "".."" ) :",0.03,0.0
"def load_syntax(syntax): <TAB> context = _create_scheme() or {} <TAB> partition_scanner = PartitionScanner(syntax.get(""partitions"", [])) <TAB> scanners = {} <TAB> for part_name, part_scanner in list(syntax.get(""scanner"", {}).items()): <TAB> <TAB> scanners[part_name] = Scanner(part_scanner) <TAB> formats = [] <TAB> for fname, fstyle in list(syntax.get(""formats"", {}).items()): <TAB> <TAB> if isinstance(fstyle, basestring): <TAB> <TAB> <TAB> if fstyle.startswith(""%("") and fstyle.endswith("")s""): <TAB> <TAB> <TAB> <TAB> key = fstyle[2:-2] <TAB> <TAB> <TAB> <TAB> fstyle = context[key] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> fstyle = fstyle % context <TAB> <TAB> formats.append((fname, fstyle)) <TAB> return partition_scanner, scanners, formats",true,"if isinstance ( fstyle , basestring ) :","if isinstance ( fstyle , basestring ) :",0.75,0.0
"def should_keep_alive(commit_msg): <TAB> result = False <TAB> ci = get_current_ci() or """" <TAB> for line in commit_msg.splitlines(): <TAB> <TAB> parts = line.strip(""# "").split("":"", 1) <TAB> <TAB> (key, val) = parts if len(parts) > 1 else (parts[0], """") <TAB> <TAB> if key == ""CI_KEEP_ALIVE"": <TAB> <TAB> <TAB> ci_names = val.replace("","", "" "").lower().split() if val else [] <TAB> <TAB> <TAB> if len(ci_names) == 0 or ci.lower() in ci_names: <TAB> <TAB> <TAB> <TAB> result = True <TAB> return result",true,"if key == ""CI_KEEP_ALIVE"" :","if key == ""CI_KEEP_ALIVE"" :",0.75,0.0
"def get_note_title_file(note): <TAB> mo = note_title_re.match(note.get(""content"", """")) <TAB> if mo: <TAB> <TAB> fn = mo.groups()[0] <TAB> <TAB> fn = fn.replace("" "", ""_"") <TAB> <TAB> fn = fn.replace(""/"", ""_"") <TAB> <TAB> if not fn: <TAB> <TAB> <TAB> return """" <TAB> <TAB> if isinstance(fn, str): <TAB> <TAB> <TAB> fn = unicode(fn, ""utf-8"") <TAB> <TAB> else: <TAB> <TAB> <TAB> fn = unicode(fn) <TAB> <TAB> if note_markdown(note): <TAB> <TAB> <TAB> fn += "".mkdn"" <TAB> <TAB> else: <TAB> <TAB> <TAB> fn += "".txt"" <TAB> <TAB> return fn <TAB> else: <TAB> <TAB> return """"",false,"if isinstance ( fn , str ) :",if note_markdown ( note ) :,0.04,0.0
"def post(self, orgname, teamname): <TAB> if _syncing_setup_allowed(orgname): <TAB> <TAB> try: <TAB> <TAB> <TAB> team = model.team.get_organization_team(orgname, teamname) <TAB> <TAB> except model.InvalidTeamException: <TAB> <TAB> <TAB> raise NotFound() <TAB> <TAB> config = request.get_json() <TAB> <TAB> # Ensure that the specified config points to a valid group. <TAB> <TAB> status, err = authentication.check_group_lookup_args(config) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise InvalidRequest(""Could not sync to group: %s"" % err) <TAB> <TAB> # Set the team's syncing config. <TAB> <TAB> model.team.set_team_syncing(team, authentication.federated_service, config) <TAB> <TAB> return team_view(orgname, team) <TAB> raise Unauthorized()",false,if not status :,if status != 200 :,0.05,0.0
"def _marshalData(self): <TAB> if self._cache == None: <TAB> <TAB> d = self._data <TAB> <TAB> s = """" <TAB> <TAB> s = time.strftime(""%H:%M:%S"", (0, 0, 0) + d + (0, 0, -1)) <TAB> <TAB> f = d[2] - int(d[2]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> s += (""%g"" % f)[1:] <TAB> <TAB> s += ""Z"" <TAB> <TAB> self._cache = s <TAB> return self._cache",false,if f != 0 :,if f > 0 :,0.33,0.0
"def _get_level(levels, level_ref): <TAB> if level_ref in levels: <TAB> <TAB> return levels.index(level_ref) <TAB> if isinstance(level_ref, six.integer_types): <TAB> <TAB> if level_ref < 0: <TAB> <TAB> <TAB> level_ref += len(levels) <TAB> <TAB> if not (0 <= level_ref < len(levels)): <TAB> <TAB> <TAB> raise PatsyError(""specified level %r is out of range"" % (level_ref,)) <TAB> <TAB> return level_ref <TAB> raise PatsyError(""specified level %r not found"" % (level_ref,))",true,if not ( 0 <= level_ref < len ( levels ) ) :,if not ( 0 <= level_ref < len ( levels ) ) :,0.75,0.0
"def iterfieldselect(source, field, where, complement, missing): <TAB> it = iter(source) <TAB> hdr = next(it) <TAB> yield tuple(hdr) <TAB> indices = asindices(hdr, field) <TAB> getv = operator.itemgetter(*indices) <TAB> for row in it: <TAB> <TAB> try: <TAB> <TAB> <TAB> v = getv(row) <TAB> <TAB> except IndexError: <TAB> <TAB> <TAB> v = missing <TAB> <TAB> if bool(where(v)) != complement:  # XOR <TAB> <TAB> <TAB> yield tuple(row)",true,if bool ( where ( v ) ) != complement :,if bool ( where ( v ) ) != complement :,0.75,0.0
"def _test_wait_read_invalid_switch(self, sleep): <TAB> sock1, sock2 = socket.socketpair() <TAB> try: <TAB> <TAB> p = gevent.spawn( <TAB> <TAB> <TAB> util.wrap_errors( <TAB> <TAB> <TAB> <TAB> AssertionError, socket.wait_read <TAB> <TAB> <TAB> ),  # pylint:disable=no-member <TAB> <TAB> <TAB> sock1.fileno(), <TAB> <TAB> ) <TAB> <TAB> gevent.get_hub().loop.run_callback(switch_None, p) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> gevent.sleep(sleep) <TAB> <TAB> result = p.get() <TAB> <TAB> assert isinstance(result, AssertionError), result <TAB> <TAB> assert ""Invalid switch"" in str(result), repr(str(result)) <TAB> finally: <TAB> <TAB> sock1.close() <TAB> <TAB> sock2.close()",false,if sleep is not None :,if sleep :,0.05,0.0
"def train(config, args): <TAB> gan = setup_gan(config, inputs, args) <TAB> test_batches = [] <TAB> for i in range(args.steps): <TAB> <TAB> gan.step() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> correct_prediction = 0 <TAB> <TAB> <TAB> total = 0 <TAB> <TAB> <TAB> for (x, y) in gan.inputs.testdata(): <TAB> <TAB> <TAB> <TAB> prediction = gan.generator(x) <TAB> <TAB> <TAB> <TAB> correct_prediction += ( <TAB> <TAB> <TAB> <TAB> <TAB> torch.argmax(prediction, 1) == torch.argmax(y, 1) <TAB> <TAB> <TAB> <TAB> ).sum() <TAB> <TAB> <TAB> <TAB> total += y.shape[0] <TAB> <TAB> <TAB> accuracy = (float(correct_prediction) / total) * 100 <TAB> <TAB> <TAB> print(""accuracy: "", accuracy) <TAB> return sum_metrics",false,if i % args . sample_every == 0 and i > 0 :,if i % args . steps == 0 :,0.29,0.0
"def process_response(self, request, response, spider): <TAB> if not response.body: <TAB> <TAB> return response <TAB> for fmt, func in six.iteritems(self._formats): <TAB> <TAB> new_response = func(response) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> logger.debug( <TAB> <TAB> <TAB> <TAB> ""Decompressed response with format: %(responsefmt)s"", <TAB> <TAB> <TAB> <TAB> {""responsefmt"": fmt}, <TAB> <TAB> <TAB> <TAB> extra={""spider"": spider}, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return new_response <TAB> return response",true,if new_response :,if new_response :,0.53,0.0
"def detect_ssl_option(self): <TAB> for option in self.ssl_options(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for other_option in self.ssl_options(): <TAB> <TAB> <TAB> <TAB> if option != other_option: <TAB> <TAB> <TAB> <TAB> <TAB> if scan_argv(self.argv, other_option) is not None: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ConfigurationError( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""Cannot give both %s and %s"" % (option, other_option) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return option",false,"if scan_argv ( self . argv , option ) is not None :",if option is not None :,0.17,0.0
"def load(cls, storefile, template_store): <TAB> # Did we get file or filename? <TAB> if not hasattr(storefile, ""read""): <TAB> <TAB> storefile = open(storefile, ""rb"") <TAB> # Adjust store to have translations <TAB> store = cls.convertfile(storefile, template_store) <TAB> for unit in store.units: <TAB> <TAB> if unit.isheader(): <TAB> <TAB> <TAB> continue <TAB> <TAB> # HTML does this properly on loading, others need it <TAB> <TAB> if cls.needs_target_sync: <TAB> <TAB> <TAB> unit.target = unit.source <TAB> <TAB> <TAB> unit.rich_target = unit.rich_source <TAB> return store",true,if unit . isheader ( ) :,if unit . isheader ( ) :,0.75,0.0
"def _pre_get_table(self, _ctx, table_name): <TAB> vsctl_table = self._get_table(table_name) <TAB> schema_helper = self.schema_helper <TAB> schema_helper.register_table(vsctl_table.table_name) <TAB> for row_id in vsctl_table.row_ids: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> schema_helper.register_table(row_id.table) <TAB> <TAB> if row_id.name_column: <TAB> <TAB> <TAB> schema_helper.register_columns(row_id.table, [row_id.name_column]) <TAB> <TAB> if row_id.uuid_column: <TAB> <TAB> <TAB> schema_helper.register_columns(row_id.table, [row_id.uuid_column]) <TAB> return vsctl_table",true,if row_id . table :,if row_id . table :,0.75,0.0
"def __init__(self, pin=None, pull_up=False): <TAB> super(InputDevice, self).__init__(pin) <TAB> try: <TAB> <TAB> self.pin.function = ""input"" <TAB> <TAB> pull = ""up"" if pull_up else ""down"" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.pin.pull = pull <TAB> except: <TAB> <TAB> self.close() <TAB> <TAB> raise <TAB> self._active_state = False if pull_up else True <TAB> self._inactive_state = True if pull_up else False",false,if self . pin . pull != pull :,if pull :,0.02,0.0
"def _increment_operations_count(self, operation, executed): <TAB> with self._lock: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._executed_operations += 1 <TAB> <TAB> <TAB> self._executed[operation.job_type] += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> self._skipped[operation.job_type] += 1",true,if executed :,if executed :,0.53,0.0
"def emit(self, type, info=None): <TAB> # Overload emit() to send events to the proxy object at the other end <TAB> ev = super().emit(type, info) <TAB> if self._has_proxy is True and self._session.status > 0: <TAB> <TAB> # implicit: and self._disposed is False: <TAB> <TAB> if type in self.__proxy_properties__: <TAB> <TAB> <TAB> self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev]) <TAB> <TAB> elif type in self.__event_types_at_proxy: <TAB> <TAB> <TAB> self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev])",false,if type in self . __proxy_properties__ :,elif type in self . __event_types_at_proxy :,0.29,0.0
"def validate_pull_secret(namespace): <TAB> if namespace.pull_secret is None: <TAB> <TAB> # TODO: add aka.ms link here <TAB> <TAB> warning = ( <TAB> <TAB> <TAB> ""No --pull-secret provided: cluster will not include samples or operators from "" <TAB> <TAB> <TAB> + ""Red Hat or from certified partners."" <TAB> <TAB> ) <TAB> <TAB> logger.warning(warning) <TAB> else: <TAB> <TAB> try: <TAB> <TAB> <TAB> if not isinstance(json.loads(namespace.pull_secret), dict): <TAB> <TAB> <TAB> <TAB> raise Exception() <TAB> <TAB> except: <TAB> <TAB> <TAB> raise InvalidArgumentValueError(""Invalid --pull-secret."")",true,"if not isinstance ( json . loads ( namespace . pull_secret ) , dict ) :","if not isinstance ( json . loads ( namespace . pull_secret ) , dict ) :",0.75,0.0
"def pack(types, *args): <TAB> if len(types) != len(args): <TAB> <TAB> raise Exception(""number of arguments does not match format string"") <TAB> port = StringIO() <TAB> for (type, value) in zip(types, args): <TAB> <TAB> if type == ""V"": <TAB> <TAB> <TAB> write_vuint(port, value) <TAB> <TAB> elif type == ""v"": <TAB> <TAB> <TAB> write_vint(port, value) <TAB> <TAB> elif type == ""s"": <TAB> <TAB> <TAB> write_bvec(port, value) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception('unknown xpack format string item ""' + type + '""') <TAB> return port.getvalue()",false,"elif type == ""s"" :","elif type == ""v"" :",0.64,0.0
"def data(self): <TAB> if self._data is not None: <TAB> <TAB> return self._data <TAB> else: <TAB> <TAB> if os.path.exists(self.path): <TAB> <TAB> <TAB> with open(self.path, ""rb"") as jsonfile: <TAB> <TAB> <TAB> <TAB> data = jsonfile.read().decode(""utf8"") <TAB> <TAB> <TAB> <TAB> data = json.loads(data) <TAB> <TAB> <TAB> <TAB> self._data = data <TAB> <TAB> <TAB> <TAB> return self._data <TAB> <TAB> else: <TAB> <TAB> <TAB> return dict()",true,if os . path . exists ( self . path ) :,if os . path . exists ( self . path ) :,1.0,0.0
"def interact(self): <TAB> self.output.write(""\n"") <TAB> while True: <TAB> <TAB> try: <TAB> <TAB> <TAB> request = self.getline(""help> "") <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> except (KeyboardInterrupt, EOFError): <TAB> <TAB> <TAB> break <TAB> <TAB> request = strip(request) <TAB> <TAB> # Make sure significant trailing quotation marks of literals don't <TAB> <TAB> # get deleted while cleaning input <TAB> <TAB> if ( <TAB> <TAB> <TAB> len(request) > 2 <TAB> <TAB> <TAB> and request[0] == request[-1] in (""'"", '""') <TAB> <TAB> <TAB> and request[0] not in request[1:-1] <TAB> <TAB> ): <TAB> <TAB> <TAB> request = request[1:-1] <TAB> <TAB> if lower(request) in (""q"", ""quit""): <TAB> <TAB> <TAB> break <TAB> <TAB> self.help(request)",true,if not request :,if not request :,0.75,0.0
"def api_attachment_metadata(self): <TAB> resp = [] <TAB> for part in self.parts: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> k = { <TAB> <TAB> <TAB> ""content_type"": part.block.content_type, <TAB> <TAB> <TAB> ""size"": part.block.size, <TAB> <TAB> <TAB> ""filename"": part.block.filename, <TAB> <TAB> <TAB> ""id"": part.block.public_id, <TAB> <TAB> } <TAB> <TAB> content_id = part.content_id <TAB> <TAB> if content_id: <TAB> <TAB> <TAB> if content_id[0] == ""<"" and content_id[-1] == "">"": <TAB> <TAB> <TAB> <TAB> content_id = content_id[1:-1] <TAB> <TAB> <TAB> k[""content_id""] = content_id <TAB> <TAB> resp.append(k) <TAB> return resp",false,if not part . is_attachment :,if part . block is None :,0.05,0.0
"def _notin_text(term, text, verbose=False): <TAB> index = text.find(term) <TAB> head = text[:index] <TAB> tail = text[index + len(term) :] <TAB> correct_text = head + tail <TAB> diff = _diff_text(correct_text, text, verbose) <TAB> newdiff = [u(""%s is contained here:"") % py.io.saferepr(term, maxsize=42)] <TAB> for line in diff: <TAB> <TAB> if line.startswith(u(""Skipping"")): <TAB> <TAB> <TAB> continue <TAB> <TAB> if line.startswith(u(""- "")): <TAB> <TAB> <TAB> continue <TAB> <TAB> if line.startswith(u(""+ "")): <TAB> <TAB> <TAB> newdiff.append(u(""  "") + line[2:]) <TAB> <TAB> else: <TAB> <TAB> <TAB> newdiff.append(line) <TAB> return newdiff",false,"if line . startswith ( u ( ""- "" ) ) :","if line . startswith ( u ( ""+"" ) ) :",0.57,0.0
"def get_api(user, url): <TAB> global API_CACHE <TAB> if API_CACHE is None or API_CACHE.get(url) is None: <TAB> <TAB> API_CACHE_LOCK.acquire() <TAB> <TAB> try: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> API_CACHE = {} <TAB> <TAB> <TAB> if API_CACHE.get(url) is None: <TAB> <TAB> <TAB> <TAB> API_CACHE[url] = ImpalaDaemonApi(url) <TAB> <TAB> finally: <TAB> <TAB> <TAB> API_CACHE_LOCK.release() <TAB> api = API_CACHE[url] <TAB> api.set_user(user) <TAB> return api",true,if API_CACHE is None :,if API_CACHE is None :,0.75,0.0
"def __str__(self, prefix="""", printElemNumber=0): <TAB> res = """" <TAB> if self.has_index_name_: <TAB> <TAB> res += prefix + (""index_name: %s\n"" % self.DebugFormatString(self.index_name_)) <TAB> cnt = 0 <TAB> for e in self.prefix_value_: <TAB> <TAB> elm = """" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> elm = ""(%d)"" % cnt <TAB> <TAB> res += prefix + (""prefix_value%s: %s\n"" % (elm, self.DebugFormatString(e))) <TAB> <TAB> cnt += 1 <TAB> if self.has_value_prefix_: <TAB> <TAB> res += prefix + ( <TAB> <TAB> <TAB> ""value_prefix: %s\n"" % self.DebugFormatBool(self.value_prefix_) <TAB> <TAB> ) <TAB> return res",true,if printElemNumber :,if printElemNumber :,0.53,0.0
"def add_group(x, nl, in_group, mw): <TAB> if len(x) == 0: <TAB> <TAB> return x <TAB> if len(x) > 1 and not in_group: <TAB> <TAB> if supports_group(x, nl): <TAB> <TAB> <TAB> return [""[[""] + x + [""]]""] <TAB> <TAB> mw.warn( <TAB> <TAB> <TAB> ""Equation will multiplex and may produce inaccurate results (see manual)"" <TAB> <TAB> ) <TAB> return [""[""] + x + [""]""]",true,"if supports_group ( x , nl ) :","if supports_group ( x , nl ) :",0.75,0.0
"def unfulfilled_items(self): <TAB> unfulfilled_items = 0 <TAB> for order_item in self.items.all(): <TAB> <TAB> if not order_item.canceled: <TAB> <TAB> <TAB> aggr = order_item.deliver_item.aggregate(delivered=Sum(""quantity"")) <TAB> <TAB> <TAB> unfulfilled_items += order_item.quantity - (aggr[""delivered""] or 0) <TAB> return unfulfilled_items",true,if not order_item . canceled :,if not order_item . canceled :,0.75,0.0
"def _get_pattern(self, pattern_id): <TAB> """"""Get pattern item by id."""""" <TAB> for key in (Tag.PATTERNS1, Tag.PATTERNS2, Tag.PATTERNS3): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> data = self.tagged_blocks.get_data(key) <TAB> <TAB> <TAB> for pattern in data: <TAB> <TAB> <TAB> <TAB> if pattern.pattern_id == pattern_id: <TAB> <TAB> <TAB> <TAB> <TAB> return pattern <TAB> return None",true,if key in self . tagged_blocks :,if key in self . tagged_blocks :,0.75,0.0
"def query_lister(domain, query="""", max_items=None, attr_names=None): <TAB> more_results = True <TAB> num_results = 0 <TAB> next_token = None <TAB> while more_results: <TAB> <TAB> rs = domain.connection.query_with_attributes( <TAB> <TAB> <TAB> domain, query, attr_names, next_token=next_token <TAB> <TAB> ) <TAB> <TAB> for item in rs: <TAB> <TAB> <TAB> if max_items: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise StopIteration <TAB> <TAB> <TAB> yield item <TAB> <TAB> <TAB> num_results += 1 <TAB> <TAB> next_token = rs.next_token <TAB> <TAB> more_results = next_token != None",true,if num_results == max_items :,if num_results == max_items :,0.75,0.0
"def find_deprecated_settings(source):  # pragma: no cover <TAB> from celery.utils import deprecated <TAB> for name, opt in flatten(NAMESPACES): <TAB> <TAB> if (opt.deprecate_by or opt.remove_by) and getattr(source, name, None): <TAB> <TAB> <TAB> deprecated.warn( <TAB> <TAB> <TAB> <TAB> description=""The {0!r} setting"".format(name), <TAB> <TAB> <TAB> <TAB> deprecation=opt.deprecate_by, <TAB> <TAB> <TAB> <TAB> removal=opt.remove_by, <TAB> <TAB> <TAB> <TAB> alternative=""Use the {0.alt} instead"".format(opt), <TAB> <TAB> <TAB> ) <TAB> return source",false,"if ( opt . deprecate_by or opt . remove_by ) and getattr ( source , name , None ) :","if ( opt . deprecation_by or opt . remove_by ) and getattr ( source , name , None ) :",0.68,0.0
"def tearDown(self): <TAB> """"""Shutdown the server."""""" <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.server.stop(2.0) <TAB> <TAB> if self.sl_hdlr: <TAB> <TAB> <TAB> self.root_logger.removeHandler(self.sl_hdlr) <TAB> <TAB> <TAB> self.sl_hdlr.close() <TAB> finally: <TAB> <TAB> BaseTest.tearDown(self)",true,if self . server :,if self . server :,0.75,0.0
"def broadcast_events(self, events): <TAB> LOGGER.debug(""Broadcasting events: %s"", events) <TAB> with self._subscribers_cv: <TAB> <TAB> # Copy the subscribers <TAB> <TAB> subscribers = {conn: sub.copy() for conn, sub in self._subscribers.items()} <TAB> if subscribers: <TAB> <TAB> for connection_id, subscriber in subscribers.items(): <TAB> <TAB> <TAB> if subscriber.is_listening(): <TAB> <TAB> <TAB> <TAB> subscriber_events = [ <TAB> <TAB> <TAB> <TAB> <TAB> event for event in events if subscriber.is_subscribed(event) <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> <TAB> event_list = EventList(events=subscriber_events) <TAB> <TAB> <TAB> <TAB> self._send(connection_id, event_list.SerializeToString())",true,if subscriber . is_listening ( ) :,if subscriber . is_listening ( ) :,0.75,0.0
"def _get_info(self, path): <TAB> info = OrderedDict() <TAB> if not self._is_mac() or self._has_xcode_tools(): <TAB> <TAB> stdout = None <TAB> <TAB> try: <TAB> <TAB> <TAB> stdout, stderr = Popen( <TAB> <TAB> <TAB> <TAB> [self._find_binary(), ""info"", os.path.realpath(path)], <TAB> <TAB> <TAB> <TAB> stdout=PIPE, <TAB> <TAB> <TAB> <TAB> stderr=PIPE, <TAB> <TAB> <TAB> ).communicate() <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> if stdout: <TAB> <TAB> <TAB> <TAB> for line in stdout.splitlines(): <TAB> <TAB> <TAB> <TAB> <TAB> line = u(line).split("": "", 1) <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> info[line[0]] = line[1] <TAB> return info",false,if len ( line ) == 2 :,if len ( line ) > 1 :,0.52,0.0
"def test_call_extern_c_fn(self): <TAB> global memcmp <TAB> memcmp = cffi_support.ExternCFunction( <TAB> <TAB> ""memcmp"", <TAB> <TAB> (""int memcmp ( const uint8_t * ptr1, "" ""const uint8_t * ptr2, size_t num )""), <TAB> ) <TAB> @udf(BooleanVal(FunctionContext, StringVal, StringVal)) <TAB> def fn(context, a, b): <TAB> <TAB> if a.is_null != b.is_null: <TAB> <TAB> <TAB> return False <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> if len(a) != b.len: <TAB> <TAB> <TAB> return False <TAB> <TAB> if a.ptr == b.ptr: <TAB> <TAB> <TAB> return True <TAB> <TAB> return memcmp(a.ptr, b.ptr, a.len) == 0",false,if a is None :,if a . ptr == b . ptr :,0.05,0.0
"def _flatten(*args): <TAB> ahs = set() <TAB> if len(args) > 0: <TAB> <TAB> for item in args: <TAB> <TAB> <TAB> if type(item) is ActionHandle: <TAB> <TAB> <TAB> <TAB> ahs.add(item) <TAB> <TAB> <TAB> elif type(item) in (list, tuple, dict, set): <TAB> <TAB> <TAB> <TAB> for ah in item: <TAB> <TAB> <TAB> <TAB> <TAB> if type(ah) is not ActionHandle:  # pragma:nocover <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ActionManagerError(""Bad argument type %s"" % str(ah)) <TAB> <TAB> <TAB> <TAB> <TAB> ahs.add(ah) <TAB> <TAB> <TAB> else:  # pragma:nocover <TAB> <TAB> <TAB> <TAB> raise ActionManagerError(""Bad argument type %s"" % str(item)) <TAB> return ahs",false,if type ( ah ) is not ActionHandle :,"elif type ( item ) in ( list , tuple , dict , set ) :",0.1,0.0
"def startElement(self, name, attrs, connection): <TAB> if name == ""Parameter"": <TAB> <TAB> if self._current_param: <TAB> <TAB> <TAB> self[self._current_param.name] = self._current_param <TAB> <TAB> self._current_param = Parameter(self) <TAB> <TAB> return self._current_param",true,if self . _current_param :,if self . _current_param :,0.75,0.0
"def _find_class_in_descendants(self, search_key): <TAB> for cls in self.primitive_classes: <TAB> <TAB> cls_key = (cls.__name__, cls.__module__) <TAB> <TAB> self.class_cache[cls_key] = cls <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return cls",true,if cls_key == search_key :,if cls_key == search_key :,0.75,0.0
"def doWorkForFindAll(self, v, target, partialMatch): <TAB> sibling = self <TAB> while sibling: <TAB> <TAB> c1 = partialMatch and sibling.equalsTreePartial(target) <TAB> <TAB> if c1: <TAB> <TAB> <TAB> v.append(sibling) <TAB> <TAB> else: <TAB> <TAB> <TAB> c2 = not partialMatch and sibling.equalsTree(target) <TAB> <TAB> <TAB> if c2: <TAB> <TAB> <TAB> <TAB> v.append(sibling) <TAB> <TAB> ### regardless of match or not, check any children for matches <TAB> <TAB> if sibling.getFirstChild(): <TAB> <TAB> <TAB> sibling.getFirstChild().doWorkForFindAll(v, target, partialMatch) <TAB> <TAB> sibling = sibling.getNextSibling()",true,if sibling . getFirstChild ( ) :,if sibling . getFirstChild ( ) :,0.75,0.0
"def forward(self, inputs: paddle.Tensor): <TAB> outputs = [] <TAB> blocks = self.block(inputs) <TAB> route = None <TAB> for i, block in enumerate(blocks): <TAB> <TAB> if i > 0: <TAB> <TAB> <TAB> block = paddle.concat([route, block], axis=1) <TAB> <TAB> route, tip = self.yolo_blocks[i](block) <TAB> <TAB> block_out = self.block_outputs[i](tip) <TAB> <TAB> outputs.append(block_out) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> route = self.route_blocks_2[i](route) <TAB> <TAB> <TAB> route = self.upsample(route) <TAB> return outputs",false,if i < 2 :,if i > 0 :,0.31,0.0
"def _filter_paths(basename, path, is_dir, exclude): <TAB> """""".gitignore style file filtering."""""" <TAB> for item in exclude: <TAB> <TAB> # Items ending in '/' apply only to directories. <TAB> <TAB> if item.endswith(""/"") and not is_dir: <TAB> <TAB> <TAB> continue <TAB> <TAB> # Items starting with '/' apply to the whole path. <TAB> <TAB> # In any other cases just the basename is used. <TAB> <TAB> match = path if item.startswith(""/"") else basename <TAB> <TAB> if fnmatch.fnmatch(match, item.strip(""/"")): <TAB> <TAB> <TAB> return True <TAB> return False",false,"if item . endswith ( ""/"" ) and not is_dir :","if fnmatch . fnmatch ( match , item . strip ( ""/"" ) ) :",0.14,0.0
"def reposition_division(f1): <TAB> lines = f1.splitlines() <TAB> if lines[2] == division: <TAB> <TAB> lines.pop(2) <TAB> found = 0 <TAB> for i, line in enumerate(lines): <TAB> <TAB> if line.startswith('""""""'): <TAB> <TAB> <TAB> found += 1 <TAB> <TAB> <TAB> if found == 2: <TAB> <TAB> <TAB> <TAB> if division in ""\n"".join(lines): <TAB> <TAB> <TAB> <TAB> <TAB> break  # already in the right place <TAB> <TAB> <TAB> <TAB> lines.insert(i + 1, """") <TAB> <TAB> <TAB> <TAB> lines.insert(i + 2, division) <TAB> <TAB> <TAB> <TAB> break <TAB> return ""\n"".join(lines)",false,"if division in ""\n"" . join ( lines ) :","if line . startswith ( '""""""' ) :",0.03,0.0
"def buildImage(opt): <TAB> dpath = os.path.join(opt[""datapath""], ""COCO-IMG-2015"") <TAB> version = ""1"" <TAB> if not build_data.built(dpath, version_string=version): <TAB> <TAB> print(""[building image data: "" + dpath + ""]"") <TAB> <TAB> if build_data.built(dpath): <TAB> <TAB> <TAB> # An older version exists, so remove these outdated files. <TAB> <TAB> <TAB> build_data.remove_dir(dpath) <TAB> <TAB> build_data.make_dir(dpath) <TAB> <TAB> # Download the data. <TAB> <TAB> for downloadable_file in RESOURCES[:1]: <TAB> <TAB> <TAB> downloadable_file.download_file(dpath) <TAB> <TAB> # Mark the data as built. <TAB> <TAB> build_data.mark_done(dpath, version_string=version)",true,if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,0.75,0.0
"def colorformat(text): <TAB> if text[0:1] == ""#"": <TAB> <TAB> col = text[1:] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return col <TAB> <TAB> elif len(col) == 3: <TAB> <TAB> <TAB> return col[0] * 2 + col[1] * 2 + col[2] * 2 <TAB> elif text == """": <TAB> <TAB> return """" <TAB> assert False, ""wrong color format %r"" % text",false,if len ( col ) == 6 :,if len ( col ) == 2 :,0.61,0.0
"def tree_print(tree): <TAB> for key in tree: <TAB> <TAB> print(key, end="" "")  # end=' ' prevents a newline character <TAB> <TAB> tree_element = tree[key]  # multiple lookups is expensive, even amortized O(1)! <TAB> <TAB> for subElem in tree_element: <TAB> <TAB> <TAB> print("" -> "", subElem, end="" "") <TAB> <TAB> <TAB><IF-STMT>  # OP wants indenting after digits <TAB> <TAB> <TAB> <TAB> print(""\n "")  # newline and a space to match indenting <TAB> <TAB> print()  # forces a newline",false,if type ( subElem ) != str :,if len ( subElem ) > 0 :,0.18,0.0
"def is_dse_cluster(path): <TAB> try: <TAB> <TAB> with open(os.path.join(path, ""CURRENT""), ""r"") as f: <TAB> <TAB> <TAB> name = f.readline().strip() <TAB> <TAB> <TAB> cluster_path = os.path.join(path, name) <TAB> <TAB> <TAB> filename = os.path.join(cluster_path, ""cluster.conf"") <TAB> <TAB> <TAB> with open(filename, ""r"") as f: <TAB> <TAB> <TAB> <TAB> data = yaml.load(f) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> except IOError: <TAB> <TAB> return False",false,"if ""dse_dir"" in data :","if ""dse"" in data :",0.39,0.0
"def delete_old_target_output_files(classpath_prefix): <TAB> """"""Delete existing output files or symlinks for target."""""" <TAB> directory, basename = os.path.split(classpath_prefix) <TAB> pattern = re.compile( <TAB> <TAB> r""^{basename}(([0-9]+)(\.jar)?|classpath\.txt)$"".format( <TAB> <TAB> <TAB> basename=re.escape(basename) <TAB> <TAB> ) <TAB> ) <TAB> files = [filename for filename in os.listdir(directory) if pattern.match(filename)] <TAB> for rel_path in files: <TAB> <TAB> path = os.path.join(directory, rel_path) <TAB> <TAB> if os.path.islink(path) or os.path.isfile(path): <TAB> <TAB> <TAB> safe_delete(path)",true,if os . path . islink ( path ) or os . path . isfile ( path ) :,if os . path . islink ( path ) or os . path . isfile ( path ) :,1.0,0.0
"def test_files(self): <TAB> # get names of files to test <TAB> dist_dir = os.path.join(os.path.dirname(__file__), os.pardir, os.pardir) <TAB> names = [] <TAB> for d in self.test_directories: <TAB> <TAB> test_dir = os.path.join(dist_dir, d) <TAB> <TAB> for n in os.listdir(test_dir): <TAB> <TAB> <TAB> if n.endswith("".py"") and not n.startswith(""bad""): <TAB> <TAB> <TAB> <TAB> names.append(os.path.join(test_dir, n)) <TAB> for filename in names: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(""Testing %s"" % filename) <TAB> <TAB> source = read_pyfile(filename) <TAB> <TAB> self.check_roundtrip(source)",false,if test_support . verbose :,if self . verbose :,0.39,0.0
"def __str__(self): <TAB> if self.HasError(): <TAB> <TAB> return self.ErrorAsStr() <TAB> else: <TAB> <TAB> # Format is: {action} ""{target}"" ({filename}:{lineno}) <TAB> <TAB> string = self._action <TAB> <TAB> if self._target is not None: <TAB> <TAB> <TAB> string += ' ""{target}""'.format(target=self._target) <TAB> <TAB> if self._filename is not None: <TAB> <TAB> <TAB> path = self._filename <TAB> <TAB> <TAB> if self._lineno is not None: <TAB> <TAB> <TAB> <TAB> path += "":{lineno}"".format(lineno=self._lineno) <TAB> <TAB> <TAB> string += "" ({path})"".format(path=path) <TAB> <TAB> return string",true,if self . _filename is not None :,if self . _filename is not None :,0.75,0.0
"def extra_action_out(self, input_dict, state_batches, model, action_dist): <TAB> with self._no_grad_context(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> stats_dict = extra_action_out_fn( <TAB> <TAB> <TAB> <TAB> self, input_dict, state_batches, model, action_dist <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> stats_dict = parent_cls.extra_action_out( <TAB> <TAB> <TAB> <TAB> self, input_dict, state_batches, model, action_dist <TAB> <TAB> <TAB> ) <TAB> <TAB> return self._convert_to_non_torch_type(stats_dict)",true,if extra_action_out_fn :,if extra_action_out_fn :,0.53,0.0
"def _retract_bindings(fstruct, inv_bindings, fs_class, visited): <TAB> # Visit each node only once: <TAB> if id(fstruct) in visited: <TAB> <TAB> return <TAB> visited.add(id(fstruct)) <TAB> if _is_mapping(fstruct): <TAB> <TAB> items = fstruct.items() <TAB> elif _is_sequence(fstruct): <TAB> <TAB> items = enumerate(fstruct) <TAB> else: <TAB> <TAB> raise ValueError(""Expected mapping or sequence"") <TAB> for (fname, fval) in items: <TAB> <TAB> if isinstance(fval, fs_class): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> fstruct[fname] = inv_bindings[id(fval)] <TAB> <TAB> <TAB> _retract_bindings(fval, inv_bindings, fs_class, visited)",false,if id ( fval ) in inv_bindings :,if id ( fval ) not in visited :,0.39,0.0
"def warehouses(self) -> tuple: <TAB> from ..repositories import WarehouseBaseRepo <TAB> repos = dict() <TAB> for dep in chain(self.dependencies, [self]): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not isinstance(dep.repo, WarehouseBaseRepo): <TAB> <TAB> <TAB> continue <TAB> <TAB> for repo in dep.repo.repos: <TAB> <TAB> <TAB> if repo.from_config: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> repos[repo.name] = repo <TAB> return tuple(repos.values())",true,if dep . repo is None :,if dep . repo is None :,0.75,0.0
"def detype(self): <TAB> if self._detyped is not None: <TAB> <TAB> return self._detyped <TAB> ctx = {} <TAB> for key, val in self._d.items(): <TAB> <TAB> if not isinstance(key, str): <TAB> <TAB> <TAB> key = str(key) <TAB> <TAB> detyper = self.get_detyper(key) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # cannot be detyped <TAB> <TAB> <TAB> continue <TAB> <TAB> deval = detyper(val) <TAB> <TAB> if deval is None: <TAB> <TAB> <TAB> # cannot be detyped <TAB> <TAB> <TAB> continue <TAB> <TAB> ctx[key] = deval <TAB> self._detyped = ctx <TAB> return ctx",true,if detyper is None :,if detyper is None :,0.75,0.0
"def populate_obj(self, obj, name): <TAB> field = getattr(obj, name, None) <TAB> if field is not None: <TAB> <TAB> # If field should be deleted, clean it up <TAB> <TAB> if self._should_delete: <TAB> <TAB> <TAB> field.delete() <TAB> <TAB> <TAB> return <TAB> <TAB> if isinstance(self.data, FileStorage) and not is_empty(self.data.stream): <TAB> <TAB> <TAB> if not field.grid_id: <TAB> <TAB> <TAB> <TAB> func = field.put <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> func = field.replace <TAB> <TAB> <TAB> func( <TAB> <TAB> <TAB> <TAB> self.data.stream, <TAB> <TAB> <TAB> <TAB> filename=self.data.filename, <TAB> <TAB> <TAB> <TAB> content_type=self.data.content_type, <TAB> <TAB> <TAB> )",true,if self . _should_delete :,if self . _should_delete :,0.75,0.0
"def _load(container): <TAB> if isinstance(container, str): <TAB> <TAB> # If container is a filename. <TAB> <TAB> if all(c in string.printable for c in container) and os.path.exists(container): <TAB> <TAB> <TAB> with open(container, ""rb"") as f: <TAB> <TAB> <TAB> <TAB> return pickle.load(f) <TAB> <TAB> # If container is a pickle string. <TAB> <TAB> else: <TAB> <TAB> <TAB> return pickle.loads(container) <TAB> # If container is an open file <TAB> elif isinstance(container, IOBase): <TAB> <TAB> return pickle.load(container) <TAB> # What else could it be? <TAB> else: <TAB> <TAB> l.error(""Cannot unpickle container of type %s"", type(container)) <TAB> <TAB> return None",true,if all ( c in string . printable for c in container ) and os . path . exists ( container ) :,if all ( c in string . printable for c in container ) and os . path . exists ( container ) :,1.0,0.0
"def append_row(self, row): <TAB> self.allocate_future_payments(row) <TAB> self.set_invoice_details(row) <TAB> self.set_party_details(row) <TAB> self.set_ageing(row) <TAB> if self.filters.get(""group_by_party""): <TAB> <TAB> self.update_sub_total_row(row, row.party) <TAB> <TAB> if self.previous_party and (self.previous_party != row.party): <TAB> <TAB> <TAB> self.append_subtotal_row(self.previous_party) <TAB> <TAB> self.previous_party = row.party <TAB> self.data.append(row)",true,if self . previous_party and ( self . previous_party != row . party ) :,if self . previous_party and ( self . previous_party != row . party ) :,0.75,0.0
"def gg1(): <TAB> while 1: <TAB> <TAB> tt = 3 <TAB> <TAB> while tt > 0: <TAB> <TAB> <TAB> trace.append(tt) <TAB> <TAB> <TAB> val = yield <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> tt = 10  # <= uncomment this line <TAB> <TAB> <TAB> <TAB> trace.append(""breaking early..."") <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> tt -= 1 <TAB> <TAB> trace.append(""try!"")",false,if val is not None :,if val is None :,0.23,0.0
"def migrate_common_facts(facts): <TAB> """"""Migrate facts from various roles into common"""""" <TAB> params = {""node"": (""portal_net""), ""master"": (""portal_net"")} <TAB> if ""common"" not in facts: <TAB> <TAB> facts[""common""] = {} <TAB> # pylint: disable=consider-iterating-dictionary <TAB> for role in params.keys(): <TAB> <TAB> if role in facts: <TAB> <TAB> <TAB> for param in params[role]: <TAB> <TAB> <TAB> <TAB> if param in facts[role]: <TAB> <TAB> <TAB> <TAB> <TAB> facts[""common""][param] = facts[role].pop(param) <TAB> return facts",true,if param in facts [ role ] :,if param in facts [ role ] :,0.75,0.0
"def get_measurements(self, pipeline, object_name, category): <TAB> if self.get_categories(pipeline, object_name) == [category]: <TAB> <TAB> results = [] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if object_name == ""Image"": <TAB> <TAB> <TAB> <TAB> results += [""Correlation"", ""Slope""] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> results += [""Correlation""] <TAB> <TAB> if self.do_overlap: <TAB> <TAB> <TAB> results += [""Overlap"", ""K""] <TAB> <TAB> if self.do_manders: <TAB> <TAB> <TAB> results += [""Manders""] <TAB> <TAB> if self.do_rwc: <TAB> <TAB> <TAB> results += [""RWC""] <TAB> <TAB> if self.do_costes: <TAB> <TAB> <TAB> results += [""Costes""] <TAB> <TAB> return results <TAB> return []",false,if self . do_corr_and_slope :,if self . do_correlation :,0.39,0.0
"def access_modes(self): <TAB> """"""access_modes property"""""" <TAB> if self._access_modes is None: <TAB> <TAB> self._access_modes = self.get_access_modes() <TAB> <TAB> if not isinstance(self._access_modes, list): <TAB> <TAB> <TAB> self._access_modes = list(self._access_modes) <TAB> return self._access_modes",true,"if not isinstance ( self . _access_modes , list ) :","if not isinstance ( self . _access_modes , list ) :",0.75,0.0
"def unwrap_envelope(self, data, many): <TAB> if many: <TAB> <TAB> if data[""items""]: <TAB> <TAB> <TAB> if isinstance(data, InstrumentedList) or isinstance(data, list): <TAB> <TAB> <TAB> <TAB> self.context[""total""] = len(data) <TAB> <TAB> <TAB> <TAB> return data <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.context[""total""] = data[""total""] <TAB> <TAB> else: <TAB> <TAB> <TAB> self.context[""total""] = 0 <TAB> <TAB> <TAB> data = {""items"": []} <TAB> <TAB> return data[""items""] <TAB> return data",false,"if data [ ""items"" ] :","if isinstance ( data , InstrumentedList ) or isinstance ( data , list ) :",0.02,0.0
"def to_string(self, fmt=""{:.4f}""): <TAB> result_str = """" <TAB> for key in self.measures: <TAB> <TAB> result = self.m_dict[key][0]() <TAB> <TAB> result_str += ( <TAB> <TAB> <TAB> "","".join(fmt.format(x) for x in result) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> else fmt.format(result) <TAB> <TAB> ) <TAB> <TAB> result_str += "","" <TAB> return result_str[:-1]  # trim the last comma",false,"if isinstance ( result , tuple )",if type ( result ) == list,0.04,0.0
"def on_torrent_created(self, result): <TAB> if not result: <TAB> <TAB> return <TAB> self.dialog_widget.btn_create.setEnabled(True) <TAB> self.dialog_widget.edit_channel_create_torrent_progress_label.setText( <TAB> <TAB> ""Created torrent"" <TAB> ) <TAB> if ""torrent"" in result: <TAB> <TAB> self.create_torrent_notification.emit({""msg"": ""Torrent successfully created""}) <TAB> <TAB> if self.dialog_widget.add_to_channel_checkbox.isChecked(): <TAB> <TAB> <TAB> self.add_torrent_to_channel(result[""torrent""]) <TAB> <TAB> self.close_dialog()",true,if self . dialog_widget . add_to_channel_checkbox . isChecked ( ) :,if self . dialog_widget . add_to_channel_checkbox . isChecked ( ) :,0.75,0.0
"def save(self): <TAB> for var_name in self.default_config: <TAB> <TAB> if getattr(self, var_name, None) == self.default_config[var_name]: <TAB> <TAB> <TAB> if var_name in self.file_config: <TAB> <TAB> <TAB> <TAB> del self.file_config[var_name] <TAB> <TAB> else: <TAB> <TAB> <TAB> self.file_config[var_name] = getattr(self, var_name) <TAB> with open(self.config_path, ""w"") as f: <TAB> <TAB> f.write(json.dumps(self.file_config, indent=2))",true,"if getattr ( self , var_name , None ) == self . default_config [ var_name ] :","if getattr ( self , var_name , None ) == self . default_config [ var_name ] :",1.0,0.0
"def get_class_parameters(kwarg): <TAB> ret = {""attrs"": []} <TAB> for key in (""rsc"", ""fsc"", ""usc""): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ret[""attrs""].append( <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> ""TCA_HFSC_%s"" % key.upper(), <TAB> <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""m1"": get_rate(kwarg[key].get(""m1"", 0)), <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""d"": get_time(kwarg[key].get(""d"", 0)), <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""m2"": get_rate(kwarg[key].get(""m2"", 0)), <TAB> <TAB> <TAB> <TAB> <TAB> }, <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> ) <TAB> return ret",true,if key in kwarg :,if key in kwarg :,0.75,0.0
"def forward(self, x): <TAB> f_x = x <TAB> if self.exp: <TAB> <TAB> f_x = self.exp_swish(self.exp_bn(self.exp(f_x))) <TAB> f_x = self.dwise_swish(self.dwise_bn(self.dwise(f_x))) <TAB> f_x = self.se(f_x) <TAB> f_x = self.lin_proj_bn(self.lin_proj(f_x)) <TAB> if self.has_skip: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> f_x = drop_connect(f_x, effnet_cfg.EN.DC_RATIO) <TAB> <TAB> f_x = x + f_x <TAB> return f_x",false,if self . training and effnet_cfg . EN . DC_RATIO > 0.0 :,if self . drop_connect :,0.07,0.0
"def cli_uninstall_distro(): <TAB> distro_list = install_distro_list() <TAB> if distro_list is not None: <TAB> <TAB> for index, _distro_dir in enumerate(distro_list): <TAB> <TAB> <TAB> log(str(index) + ""  --->>  "" + _distro_dir) <TAB> <TAB> user_input = read_input_uninstall() <TAB> <TAB> if user_input is not False: <TAB> <TAB> <TAB> for index, _distro_dir in enumerate(distro_list): <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> config.uninstall_distro_dir_name = _distro_dir <TAB> <TAB> <TAB> <TAB> <TAB> unin_distro() <TAB> else: <TAB> <TAB> log(""No distro installed on "" + config.usb_disk)",false,if index == user_input :,if _distro_dir != config . usb_disk :,0.03,0.0
"def IMPORTFROM(self, node): <TAB> if node.module == ""__future__"": <TAB> <TAB> if not self.futuresAllowed: <TAB> <TAB> <TAB> self.report(messages.LateFutureImport, node, [n.name for n in node.names]) <TAB> else: <TAB> <TAB> self.futuresAllowed = False <TAB> for alias in node.names: <TAB> <TAB> if alias.name == ""*"": <TAB> <TAB> <TAB> self.scope.importStarred = True <TAB> <TAB> <TAB> self.report(messages.ImportStarUsed, node, node.module) <TAB> <TAB> <TAB> continue <TAB> <TAB> name = alias.asname or alias.name <TAB> <TAB> importation = Importation(name, node) <TAB> <TAB> if node.module == ""__future__"": <TAB> <TAB> <TAB> importation.used = (self.scope, node) <TAB> <TAB> self.addBinding(node, importation)",false,if not self . futuresAllowed :,"if alias . name == ""*"" :",0.03,0.0
"def _split_and_load(batch, ctx_list): <TAB> """"""Split data to 1 batch each device."""""" <TAB> new_batch = [] <TAB> for _, data in enumerate(batch): <TAB> <TAB> if isinstance(data, (list, tuple)): <TAB> <TAB> <TAB> new_data = [x.as_in_context(ctx) for x, ctx in zip(data, ctx_list)] <TAB> <TAB> else: <TAB> <TAB> <TAB> new_data = [data.as_in_context(ctx_list[0])] <TAB> <TAB> new_batch.append(new_data) <TAB> return new_batch",true,"if isinstance ( data , ( list , tuple ) ) :","if isinstance ( data , ( list , tuple ) ) :",0.75,0.0
"def wait_success(self, timeout=60 * 10): <TAB> for i in range(timeout // 10): <TAB> <TAB> time.sleep(10) <TAB> <TAB> status = self.query_job() <TAB> <TAB> print(""job {} status is {}"".format(self.job_id, status)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> if status and status in [ <TAB> <TAB> <TAB> StatusSet.CANCELED, <TAB> <TAB> <TAB> StatusSet.TIMEOUT, <TAB> <TAB> <TAB> StatusSet.FAILED, <TAB> <TAB> ]: <TAB> <TAB> <TAB> return False <TAB> return False",false,if status and status == StatusSet . SUCCESS :,if status :,0.02,0.0
"def copy_tree(self, src_dir, dst_dir, skip_variables=False): <TAB> for src_root, _, files in os.walk(src_dir): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> rel_root = os.path.relpath(src_root, src_dir) <TAB> <TAB> else: <TAB> <TAB> <TAB> rel_root = """" <TAB> <TAB> if skip_variables and rel_root.startswith(""variables""): <TAB> <TAB> <TAB> continue <TAB> <TAB> dst_root = os.path.join(dst_dir, rel_root) <TAB> <TAB> if not os.path.exists(dst_root): <TAB> <TAB> <TAB> os.makedirs(dst_root) <TAB> <TAB> for f in files: <TAB> <TAB> <TAB> shutil.copy(os.path.join(src_root, f), os.path.join(dst_root, f))",false,if src_root != src_dir :,if src_root :,0.07,0.0
"def _make_padded_shapes(self, dataset, decoders): <TAB> padded_shapes = dataset.output_shapes <TAB> for i, hparams_i in enumerate(self._hparams.datasets): <TAB> <TAB> if not _is_text_data(hparams_i[""data_type""]): <TAB> <TAB> <TAB> continue <TAB> <TAB> if not hparams_i[""pad_to_max_seq_length""]: <TAB> <TAB> <TAB> continue <TAB> <TAB> text_and_id_shapes = MonoTextData._make_padded_text_and_id_shapes( <TAB> <TAB> <TAB> dataset, hparams_i, decoders[i], self.text_name(i), self.text_id_name(i) <TAB> <TAB> ) <TAB> <TAB> padded_shapes.update(text_and_id_shapes) <TAB> return padded_shapes",true,"if not _is_text_data ( hparams_i [ ""data_type"" ] ) :","if not _is_text_data ( hparams_i [ ""data_type"" ] ) :",0.75,0.0
"def format_errors(messages): <TAB> errors = {} <TAB> for k, v in messages.items(): <TAB> <TAB> key = camelize(k, uppercase_first_letter=False) <TAB> <TAB> if isinstance(v, dict): <TAB> <TAB> <TAB> errors[key] = format_errors(v) <TAB> <TAB> elif isinstance(v, list): <TAB> <TAB> <TAB> errors[key] = v[0] <TAB> return errors",false,"if isinstance ( v , dict ) :","elif isinstance ( v , list ) :",0.2,0.0
"def generic_visit(self, node, parents=None): <TAB> parents = (parents or []) + [node] <TAB> for field, value in iter_fields(node): <TAB> <TAB> if isinstance(value, list): <TAB> <TAB> <TAB> for item in value: <TAB> <TAB> <TAB> <TAB> if isinstance(item, AST): <TAB> <TAB> <TAB> <TAB> <TAB> self.visit(item, parents) <TAB> <TAB> elif isinstance(value, AST): <TAB> <TAB> <TAB> self.visit(value, parents)",true,"if isinstance ( value , list ) :","if isinstance ( value , list ) :",0.75,0.0
"def get_override_css(self): <TAB> """"""handls allow_css_overrides setting."""""" <TAB> if self.settings.get(""allow_css_overrides""): <TAB> <TAB> filename = self.view.file_name() <TAB> <TAB> filetypes = self.settings.get(""markdown_filetypes"") <TAB> <TAB> if filename and filetypes: <TAB> <TAB> <TAB> for filetype in filetypes: <TAB> <TAB> <TAB> <TAB> if filename.endswith(filetype): <TAB> <TAB> <TAB> <TAB> <TAB> css_filename = filename.rpartition(filetype)[0] + "".css"" <TAB> <TAB> <TAB> <TAB> <TAB> if os.path.isfile(css_filename): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return u""<style>%s</style>"" % load_utf8(css_filename) <TAB> return """"",false,if filename . endswith ( filetype ) :,if os . path . isfile ( css_filename ) :,0.1,0.0
"def clean(self): <TAB> super().clean() <TAB> # If the Cluster is assigned to a Site, all Devices must be assigned to that Site. <TAB> if self.cluster.site is not None: <TAB> <TAB> for device in self.cleaned_data.get(""devices"", []): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""devices"": ""{} belongs to a different site ({}) than the cluster ({})"".format( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> device, device.site, self.cluster.site <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> <TAB> )",true,if device . site != self . cluster . site :,if device . site != self . cluster . site :,1.0,0.0
"def _setProcessPriority(process, nice_val, disable_gc): <TAB> org_nice_val = Computer._process_original_nice_value <TAB> try: <TAB> <TAB> process.nice(nice_val) <TAB> <TAB> Computer.in_high_priority_mode = nice_val != org_nice_val <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> gc.disable() <TAB> <TAB> else: <TAB> <TAB> <TAB> gc.enable() <TAB> <TAB> return True <TAB> except psutil.AccessDenied: <TAB> <TAB> print2err( <TAB> <TAB> <TAB> ""WARNING: Could not set process {} priority "" <TAB> <TAB> <TAB> ""to {}"".format(process.pid, nice_val) <TAB> <TAB> ) <TAB> <TAB> return False",true,if disable_gc :,if disable_gc :,0.53,0.0
"def _setResultsName(self, name, listAllMatches=False): <TAB> if __diag__.warn_multiple_tokens_in_named_alternation: <TAB> <TAB> if any(isinstance(e, And) for e in self.exprs): <TAB> <TAB> <TAB> warnings.warn( <TAB> <TAB> <TAB> <TAB> ""{}: setting results name {!r} on {} expression "" <TAB> <TAB> <TAB> <TAB> ""may only return a single token for an And alternative, "" <TAB> <TAB> <TAB> <TAB> ""in future will return the full list of tokens"".format( <TAB> <TAB> <TAB> <TAB> <TAB> ""warn_multiple_tokens_in_named_alternation"", <TAB> <TAB> <TAB> <TAB> <TAB> name, <TAB> <TAB> <TAB> <TAB> <TAB> type(self).__name__, <TAB> <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> <TAB> stacklevel=3, <TAB> <TAB> <TAB> ) <TAB> return super()._setResultsName(name, listAllMatches)",true,"if any ( isinstance ( e , And ) for e in self . exprs ) :","if any ( isinstance ( e , And ) for e in self . exprs ) :",1.0,0.0
"def make_sources(project: RootDependency) -> str: <TAB> content = [] <TAB> if project.readme: <TAB> <TAB> content.append(project.readme.path.name) <TAB> <TAB> if project.readme.markup != ""rst"": <TAB> <TAB> <TAB> content.append(project.readme.to_rst().path.name) <TAB> path = project.package.path <TAB> for fname in (""setup.cfg"", ""setup.py""): <TAB> <TAB> if (path / fname).exists(): <TAB> <TAB> <TAB> content.append(fname) <TAB> for package in chain(project.package.packages, project.package.data): <TAB> <TAB> for fpath in package: <TAB> <TAB> <TAB> fpath = fpath.relative_to(project.package.path) <TAB> <TAB> <TAB> content.append(""/"".join(fpath.parts)) <TAB> return ""\n"".join(content)",true,if ( path / fname ) . exists ( ) :,if ( path / fname ) . exists ( ) :,0.75,0.0
"def findControlPointsInMesh(glyph, va, subsegments): <TAB> controlPointIndices = np.zeros((len(va), 1)) <TAB> index = 0 <TAB> for i, c in enumerate(subsegments): <TAB> <TAB> segmentCount = len(glyph.contours[i].segments) - 1 <TAB> <TAB> for j, s in enumerate(c): <TAB> <TAB> <TAB> if j < segmentCount: <TAB> <TAB> <TAB> <TAB> if glyph.contours[i].segments[j].type == ""line"": <TAB> <TAB> <TAB> <TAB> <TAB> controlPointIndices[index] = 1 <TAB> <TAB> <TAB> index += s[1] <TAB> return controlPointIndices",false,"if glyph . contours [ i ] . segments [ j ] . type == ""line"" :","if glyph . contour [ i ] . segments [ j ] . type == ""line"" :",0.66,0.0
"def MergeFrom(self, other): <TAB> if self.message_class is not None: <TAB> <TAB> if other.Parse(self.message_class): <TAB> <TAB> <TAB> self.message.MergeFrom(other.message) <TAB> elif other.message_class is not None: <TAB> <TAB> if not self.Parse(other.message_class): <TAB> <TAB> <TAB> self.message = other.message_class() <TAB> <TAB> <TAB> self.message_class = other.message_class <TAB> <TAB> self.message.MergeFrom(other.message) <TAB> else: <TAB> <TAB> self.message += other.message",false,if not self . Parse ( other . message_class ) :,if other . Parse ( self . message_class ) :,0.2,0.0
"def remove_old_snapshot(install_dir): <TAB> logging.info(""Removing any old files in {}"".format(install_dir)) <TAB> for file in glob.glob(""{}/*"".format(install_dir)): <TAB> <TAB> try: <TAB> <TAB> <TAB> if os.path.isfile(file): <TAB> <TAB> <TAB> <TAB> os.unlink(file) <TAB> <TAB> <TAB> elif os.path.isdir(file): <TAB> <TAB> <TAB> <TAB> shutil.rmtree(file) <TAB> <TAB> except Exception as error: <TAB> <TAB> <TAB> logging.error(""Error: {}"".format(error)) <TAB> <TAB> <TAB> sys.exit(1)",false,if os . path . isfile ( file ) :,elif os . path . isdir ( file ) :,0.25,0.0
"def writexml( <TAB> self, <TAB> stream, <TAB> indent="""", <TAB> addindent="""", <TAB> newl="""", <TAB> strip=0, <TAB> nsprefixes={}, <TAB> namespace="""", ): <TAB> w = _streamWriteWrapper(stream) <TAB> if self.raw: <TAB> <TAB> val = self.nodeValue <TAB> <TAB> if not isinstance(val, str): <TAB> <TAB> <TAB> val = str(self.nodeValue) <TAB> else: <TAB> <TAB> v = self.nodeValue <TAB> <TAB> if not isinstance(v, str): <TAB> <TAB> <TAB> v = str(v) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> v = "" "".join(v.split()) <TAB> <TAB> val = escape(v) <TAB> w(val)",true,if strip :,if strip :,0.53,0.0
"def validate_attributes(self): <TAB> for attribute in self.get_all_attributes(): <TAB> <TAB> value = getattr(self, attribute.code, None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if attribute.required: <TAB> <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> <TAB> _(""%(attr)s attribute cannot be blank"") % {""attr"": attribute.code} <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> attribute.validate_value(value) <TAB> <TAB> <TAB> except ValidationError as e: <TAB> <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> <TAB> _(""%(attr)s attribute %(err)s"") % {""attr"": attribute.code, ""err"": e} <TAB> <TAB> <TAB> <TAB> )",true,if value is None :,if value is None :,0.75,0.0
"def PyJsHoisted_BinaryExpression_(node, parent, this, arguments, var=var): <TAB> var = Scope( <TAB> <TAB> {u""node"": node, u""this"": this, u""arguments"": arguments, u""parent"": parent}, var <TAB> ) <TAB> var.registers([u""node"", u""parent""]) <TAB> if PyJsStrictEq(var.get(u""node"").get(u""operator""), Js(u""in"")): <TAB> <TAB> if var.get(u""t"").callprop(u""isVariableDeclarator"", var.get(u""parent"")): <TAB> <TAB> <TAB> return var.get(u""true"") <TAB> <TAB> if var.get(u""t"").callprop(u""isFor"", var.get(u""parent"")): <TAB> <TAB> <TAB> return var.get(u""true"") <TAB> return Js(False)",true,"if var . get ( u""t"" ) . callprop ( u""isVariableDeclarator"" , var . get ( u""parent"" ) ) :","if var . get ( u""t"" ) . callprop ( u""isVariableDeclarator"" , var . get ( u""parent"" ) ) :",1.0,0.0
"def distinct(expr, *on): <TAB> fields = frozenset(expr.fields) <TAB> _on = [] <TAB> append = _on.append <TAB> for n in on: <TAB> <TAB> if isinstance(n, Field): <TAB> <TAB> <TAB> if n._child.isidentical(expr): <TAB> <TAB> <TAB> <TAB> n = n._name <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise ValueError(""{0} is not a field of {1}"".format(n, expr)) <TAB> <TAB> if not isinstance(n, _strtypes): <TAB> <TAB> <TAB> raise TypeError(""on must be a name or field, not: {0}"".format(n)) <TAB> <TAB> elif n not in fields: <TAB> <TAB> <TAB> raise ValueError(""{0} is not a field of {1}"".format(n, expr)) <TAB> <TAB> append(n) <TAB> return Distinct(expr, tuple(_on))",false,"if not isinstance ( n , _strtypes ) :",if n . _child . isidentical ( expr ) :,0.03,0.0
"def encode(self, msg): <TAB> """"""Encodes the message to the stream encoding."""""" <TAB> stream = self.stream <TAB> rv = msg + ""\n"" <TAB> if (PY2 and is_unicode(rv)) or not ( <TAB> <TAB> PY2 or is_unicode(rv) or _is_text_stream(stream) <TAB> ): <TAB> <TAB> enc = self.encoding <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> enc = getattr(stream, ""encoding"", None) or ""utf-8"" <TAB> <TAB> rv = rv.encode(enc, ""replace"") <TAB> return rv",true,if enc is None :,if enc is None :,0.75,0.0
"def color_convert(self, to_color_space, preserve_alpha=True): <TAB> if to_color_space == self.color_space and preserve_alpha: <TAB> <TAB> return self <TAB> else: <TAB> <TAB> pixels = pixels_as_float(self.pixels) <TAB> <TAB> converted = convert_color( <TAB> <TAB> <TAB> pixels, self.color_space, to_color_space, preserve_alpha <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> return Image(converted, to_color_space)",true,if converted is None :,if converted is None :,0.75,0.0
"def seek(self, pos): <TAB> if self.closed: <TAB> <TAB> raise IOError(""Cannot seek on a closed file"") <TAB> for n, idx in enumerate(self._indexes[::-1]): <TAB> <TAB> if idx.offset <= pos: <TAB> <TAB> <TAB> if idx != self._curidx: <TAB> <TAB> <TAB> <TAB> self._idxiter = iter(self._indexes[-(n + 1) :]) <TAB> <TAB> <TAB> <TAB> self._nextidx() <TAB> <TAB> <TAB> break <TAB> else: <TAB> <TAB> raise Exception(""Cannot seek to pos"") <TAB> self._curfile.seek(pos - self._curidx.offset)",true,if idx != self . _curidx :,if idx != self . _curidx :,0.75,0.0
"def load_from_json(self, node_data: dict, import_version: float): <TAB> if import_version <= 0.08: <TAB> <TAB> self.image_pointer = unpack_pointer_property_name( <TAB> <TAB> <TAB> bpy.data.images, node_data, ""image_name"" <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> proposed_name = node_data.get(""image_name"") <TAB> <TAB> <TAB> self.info(f""image data not found in current {proposed_name}"")",false,if not self . image_pointer :,if self . image_pointer :,0.28,0.0
"def __init__(self, execution_context, aggregate_operators): <TAB> super(_QueryExecutionAggregateEndpointComponent, self).__init__(execution_context) <TAB> self._local_aggregators = [] <TAB> self._results = None <TAB> self._result_index = 0 <TAB> for operator in aggregate_operators: <TAB> <TAB> if operator == ""Average"": <TAB> <TAB> <TAB> self._local_aggregators.append(_AverageAggregator()) <TAB> <TAB> elif operator == ""Count"": <TAB> <TAB> <TAB> self._local_aggregators.append(_CountAggregator()) <TAB> <TAB> elif operator == ""Max"": <TAB> <TAB> <TAB> self._local_aggregators.append(_MaxAggregator()) <TAB> <TAB> elif operator == ""Min"": <TAB> <TAB> <TAB> self._local_aggregators.append(_MinAggregator()) <TAB> <TAB> elif operator == ""Sum"": <TAB> <TAB> <TAB> self._local_aggregators.append(_SumAggregator())",false,"elif operator == ""Count"" :","elif operator == ""Min"" :",0.64,0.0
"def attrgetter(item): <TAB> items = [None] * len(attribute) <TAB> for i, attribute_part in enumerate(attribute): <TAB> <TAB> item_i = item <TAB> <TAB> for part in attribute_part: <TAB> <TAB> <TAB> item_i = environment.getitem(item_i, part) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> item_i = postprocess(item_i) <TAB> <TAB> items[i] = item_i <TAB> return items",false,if postprocess is not None :,if postprocess :,0.05,0.0
"def work(self): <TAB> while True: <TAB> <TAB> timeout = self.timeout <TAB> <TAB> if idle.is_set(): <TAB> <TAB> <TAB> timeout = self.idle_timeout <TAB> <TAB> log.debug(""Wait for {}"".format(timeout)) <TAB> <TAB> fetch.wait(timeout) <TAB> <TAB> if shutting_down.is_set(): <TAB> <TAB> <TAB> log.info(""Stop fetch worker"") <TAB> <TAB> <TAB> break <TAB> <TAB> self.fetch()",true,if idle . is_set ( ) :,if idle . is_set ( ) :,0.75,0.0
"def testCoreInterfaceIntInputData(): <TAB> result_testing = False <TAB> for _ in range(10): <TAB> <TAB> hsyncnet_instance = hsyncnet( <TAB> <TAB> <TAB> [[1], [2], [3], [20], [21], [22]], 2, initial_type.EQUIPARTITION, ccore=True <TAB> <TAB> ) <TAB> <TAB> analyser = hsyncnet_instance.process() <TAB> <TAB> if len(analyser.allocate_clusters(0.1)) == 2: <TAB> <TAB> <TAB> result_testing = True <TAB> <TAB> <TAB> break <TAB> assert result_testing",true,if len ( analyser . allocate_clusters ( 0.1 ) ) == 2 :,if len ( analyser . allocate_clusters ( 0.1 ) ) == 2 :,0.75,0.0
"def _gen(): <TAB> buf = [] <TAB> iterable = dataset() <TAB> try: <TAB> <TAB> while len(buf) < buffer_size: <TAB> <TAB> <TAB> buf.append(next(iterable)) <TAB> <TAB> while 1: <TAB> <TAB> <TAB> i = random.randint(0, buffer_size - 1) <TAB> <TAB> <TAB> n = next(iterable) <TAB> <TAB> <TAB> yield buf[i] <TAB> <TAB> <TAB> buf[i] = n <TAB> except StopIteration: <TAB> <TAB> if len(buf): <TAB> <TAB> <TAB> random.shuffle(buf) <TAB> <TAB> <TAB> for i in buf: <TAB> <TAB> <TAB> <TAB> yield i",true,if len ( buf ) :,if len ( buf ) :,0.75,0.0
"def debug_tree(tree): <TAB> l = [] <TAB> for elt in tree: <TAB> <TAB> if isinstance(elt, (int, long)): <TAB> <TAB> <TAB> l.append(_names.get(elt, elt)) <TAB> <TAB> elif isinstance(elt, str): <TAB> <TAB> <TAB> l.append(elt) <TAB> <TAB> else: <TAB> <TAB> <TAB> l.append(debug_tree(elt)) <TAB> return l",true,"elif isinstance ( elt , str ) :","elif isinstance ( elt , str ) :",0.75,0.0
"def reverse_code(apps: StateApps, schema_editor: DatabaseSchemaEditor) -> None: <TAB> PreregistrationUser = apps.get_model(""zerver"", ""PreregistrationUser"") <TAB> for user in PreregistrationUser.objects.all(): <TAB> <TAB><IF-STMT>  # PreregistrationUser.INVITE_AS['REALM_ADMIN'] <TAB> <TAB> <TAB> user.invited_as_admin = True <TAB> <TAB> else:  # PreregistrationUser.INVITE_AS['MEMBER'] <TAB> <TAB> <TAB> user.invited_as_admin = False <TAB> <TAB> user.save(update_fields=[""invited_as_admin""])",false,if user . invited_as == 2 :,if user . invited_as_admin :,0.09,0.0
"def _fastqc_data_section(self, section_name): <TAB> out = [] <TAB> in_section = False <TAB> data_file = os.path.join(self._dir, ""fastqc_data.txt"") <TAB> if os.path.exists(data_file): <TAB> <TAB> with open(data_file) as in_handle: <TAB> <TAB> <TAB> for line in in_handle: <TAB> <TAB> <TAB> <TAB> if line.startswith("">>%s"" % section_name): <TAB> <TAB> <TAB> <TAB> <TAB> in_section = True <TAB> <TAB> <TAB> <TAB> elif in_section: <TAB> <TAB> <TAB> <TAB> <TAB> if line.startswith("">>END""): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> <TAB> out.append(line.rstrip(""\r\n"")) <TAB> return out",false,"if line . startswith ( "">>END"" ) :","if line . startswith ( "">END"" ) :",0.55,0.0
"def determine_block_hints(self, text): <TAB> hints = """" <TAB> if text: <TAB> <TAB> if text[0] in "" \n\x85\u2028\u2029"": <TAB> <TAB> <TAB> hints += str(self.best_indent) <TAB> <TAB> if text[-1] not in ""\n\x85\u2028\u2029"": <TAB> <TAB> <TAB> hints += ""-"" <TAB> <TAB> elif len(text) == 1 or text[-2] in ""\n\x85\u2028\u2029"": <TAB> <TAB> <TAB> hints += ""+"" <TAB> return hints",true,"if text [ - 1 ] not in ""\n\x85\u2028\u2029"" :","if text [ - 1 ] not in ""\n\x85\u2028\u2029"" :",0.75,0.0
"def database_app(request): <TAB> if request.param == ""postgres_app"": <TAB> <TAB> if not which(""initdb""): <TAB> <TAB> <TAB> pytest.skip(""initdb must be on PATH for postgresql fixture"") <TAB> <TAB> if not psycopg2: <TAB> <TAB> <TAB> pytest.skip(""psycopg2 must be installed for postgresql fixture"") <TAB> if request.param == ""sqlite_rabbitmq_app"": <TAB> <TAB> if not os.environ.get(""GALAXY_TEST_AMQP_INTERNAL_CONNECTION""): <TAB> <TAB> <TAB> pytest.skip( <TAB> <TAB> <TAB> <TAB> ""rabbitmq tests will be skipped if GALAXY_TEST_AMQP_INTERNAL_CONNECTION env var is unset"" <TAB> <TAB> <TAB> ) <TAB> return request.getfixturevalue(request.param)",true,"if not os . environ . get ( ""GALAXY_TEST_AMQP_INTERNAL_CONNECTION"" ) :","if not os . environ . get ( ""GALAXY_TEST_AMQP_INTERNAL_CONNECTION"" ) :",0.75,0.0
"def do_rollout(agent, env, num_steps, render=False): <TAB> total_rew = 0 <TAB> ob = env.reset() <TAB> for t in range(num_steps): <TAB> <TAB> a = agent.act(ob) <TAB> <TAB> (ob, reward, done, _info) = env.step(a) <TAB> <TAB> total_rew += reward <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> env.render() <TAB> <TAB> if done: <TAB> <TAB> <TAB> break <TAB> return total_rew, t + 1",false,if render and t % 3 == 0 :,if render :,0.02,0.0
"def _handle_subrepos(self, ctx, dirty_trees): <TAB> substate = util.parse_hgsubstate(ctx["".hgsubstate""].data().splitlines()) <TAB> sub = util.OrderedDict() <TAB> if "".hgsub"" in ctx: <TAB> <TAB> sub = util.parse_hgsub(ctx["".hgsub""].data().splitlines()) <TAB> for path, sha in substate.iteritems(): <TAB> <TAB> # Ignore non-Git repositories keeping state in .hgsubstate. <TAB> <TAB> if path in sub and not sub[path].startswith(""[git]""): <TAB> <TAB> <TAB> continue <TAB> <TAB> d = os.path.dirname(path) <TAB> <TAB> dirty_trees.add(d) <TAB> <TAB> tree = self._dirs.setdefault(d, dulobjs.Tree()) <TAB> <TAB> tree.add(os.path.basename(path), dulobjs.S_IFGITLINK, sha)",true,"if path in sub and not sub [ path ] . startswith ( ""[git]"" ) :","if path in sub and not sub [ path ] . startswith ( ""[git]"" ) :",0.75,0.0
"def get_property_file_image_choices(self, pipeline): <TAB> columns = pipeline.get_measurement_columns() <TAB> image_names = [] <TAB> for column in columns: <TAB> <TAB> object_name, feature, coltype = column[:3] <TAB> <TAB> choice = feature[(len(C_FILE_NAME) + 1) :] <TAB> <TAB> if object_name == ""Image"" and (feature.startswith(C_FILE_NAME)): <TAB> <TAB> <TAB> image_names.append(choice) <TAB> return image_names",true,"if object_name == ""Image"" and ( feature . startswith ( C_FILE_NAME ) ) :","if object_name == ""Image"" and ( feature . startswith ( C_FILE_NAME ) ) :",0.75,0.0
"def check_all_decorator_order(): <TAB> """"""Check that in all test files, the slow decorator is always last."""""" <TAB> errors = [] <TAB> for fname in os.listdir(PATH_TO_TESTS): <TAB> <TAB> if fname.endswith("".py""): <TAB> <TAB> <TAB> filename = os.path.join(PATH_TO_TESTS, fname) <TAB> <TAB> <TAB> new_errors = check_decorator_order(filename) <TAB> <TAB> <TAB> errors += [f""- {filename}, line {i}"" for i in new_errors] <TAB> if len(errors) > 0: <TAB> <TAB> msg = ""\n"".join(errors) <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> f""The parameterized decorator (and its variants) should always be first, but this is not the case in the following files:\n{msg}"" <TAB> <TAB> )",true,"if fname . endswith ( "".py"" ) :","if fname . endswith ( "".py"" ) :",0.75,0.0
"def on_edit_button_clicked(self, event=None, a=None, col=None): <TAB> tree, tree_id = self.treeView.get_selection().get_selected() <TAB> watchdir_id = str(self.store.get_value(tree_id, 0)) <TAB> if watchdir_id: <TAB> <TAB> if col and col.get_title() == _(""Active""): <TAB> <TAB> <TAB> if self.watchdirs[watchdir_id][""enabled""]: <TAB> <TAB> <TAB> <TAB> client.autoadd.disable_watchdir(watchdir_id) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> client.autoadd.enable_watchdir(watchdir_id) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.opts_dialog.show(self.watchdirs[watchdir_id], watchdir_id)",false,"if self . watchdirs [ watchdir_id ] [ ""enabled"" ] :","if col and col . get_title ( ) == _ ( ""Active"" ) :",0.01,0.0
"def get_conv_output_size(input_size, kernel_size, stride, padding, dilation): <TAB> ndim = len(input_size) <TAB> output_size = [] <TAB> for i in range(ndim): <TAB> <TAB> size = ( <TAB> <TAB> <TAB> input_size[i] + 2 * padding[i] - dilation[i] * (kernel_size[i] - 1) - 1 <TAB> <TAB> ) // stride[i] + 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> output_size.append(1) <TAB> <TAB> else: <TAB> <TAB> <TAB> output_size.append(size) <TAB> return output_size",false,if kernel_size [ i ] == - 1 :,if size == 0 :,0.02,0.0
"def from_location(cls, location, basename, metadata=None, **kw): <TAB> project_name, version, py_version, platform = [None] * 4 <TAB> basename, ext = os.path.splitext(basename) <TAB> if ext.lower() in ("".egg"", "".egg-info""): <TAB> <TAB> match = EGG_NAME(basename) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> project_name, version, py_version, platform = match.group( <TAB> <TAB> <TAB> <TAB> ""name"", ""ver"", ""pyver"", ""plat"" <TAB> <TAB> <TAB> ) <TAB> return cls( <TAB> <TAB> location, <TAB> <TAB> metadata, <TAB> <TAB> project_name=project_name, <TAB> <TAB> version=version, <TAB> <TAB> py_version=py_version, <TAB> <TAB> platform=platform, <TAB> <TAB> **kw <TAB> )",true,if match :,if match :,0.53,0.0
"def __new__(metacls, typename, bases, namespace): <TAB> annotations = namespace.get(""__annotations__"", {}) <TAB> for t in annotations.values(): <TAB> <TAB> if getattr(t, ""__origin__"", """") is Union: <TAB> <TAB> <TAB> for ut in t.__args__: <TAB> <TAB> <TAB> <TAB> _assert_tensorizer_type(ut) <TAB> <TAB> else: <TAB> <TAB> <TAB> _assert_tensorizer_type(t) <TAB> return super().__new__(metacls, typename, bases, namespace)",true,"if getattr ( t , ""__origin__"" , """" ) is Union :","if getattr ( t , ""__origin__"" , """" ) is Union :",0.75,0.0
"def decode_content(self): <TAB> """"""Return the best possible representation of the response body."""""" <TAB> ct = self.headers.get(""content-type"") <TAB> if ct: <TAB> <TAB> ct, options = parse_options_header(ct) <TAB> <TAB> charset = options.get(""charset"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return self.json(charset) <TAB> <TAB> elif ct.startswith(""text/""): <TAB> <TAB> <TAB> return self.text(charset) <TAB> <TAB> elif ct == FORM_URL_ENCODED: <TAB> <TAB> <TAB> return parse_qsl(self.content.decode(charset), keep_blank_values=True) <TAB> return self.content",false,if ct in JSON_CONTENT_TYPES :,if charset :,0.04,0.0
"def get_full_path(path): <TAB> if ""://"" not in path: <TAB> <TAB> path = os.path.join(self.AUTO_COLL_TEMPL, path, """") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> path = os.path.join(abs_path, path) <TAB> return path",true,if abs_path :,if abs_path :,0.53,0.0
"def __getitem__(self, name_or_path): <TAB> if isinstance(name_or_path, integer_types): <TAB> <TAB> return list.__getitem__(self, name_or_path) <TAB> elif isinstance(name_or_path, tuple): <TAB> <TAB> try: <TAB> <TAB> <TAB> val = self <TAB> <TAB> <TAB> for fid in name_or_path: <TAB> <TAB> <TAB> <TAB> if not isinstance(val, FeatStruct): <TAB> <TAB> <TAB> <TAB> <TAB> raise KeyError  # path contains base value <TAB> <TAB> <TAB> <TAB> val = val[fid] <TAB> <TAB> <TAB> return val <TAB> <TAB> except (KeyError, IndexError): <TAB> <TAB> <TAB> raise KeyError(name_or_path) <TAB> else: <TAB> <TAB> raise TypeError(self._INDEX_ERROR % name_or_path)",true,"if not isinstance ( val , FeatStruct ) :","if not isinstance ( val , FeatStruct ) :",0.75,0.0
"def scan(scope): <TAB> for s in scope.children: <TAB> <TAB> if s.start_pos <= position <= s.end_pos: <TAB> <TAB> <TAB> if isinstance(s, (tree.Scope, tree.Flow)): <TAB> <TAB> <TAB> <TAB> return scan(s) or s <TAB> <TAB> <TAB> elif s.type in (""suite"", ""decorated""): <TAB> <TAB> <TAB> <TAB> return scan(s) <TAB> return None",false,"elif s . type in ( ""suite"" , ""decorated"" ) :","if isinstance ( s , ( tree . Scope , tree . Flow ) ) :",0.02,0.0
"def _get_key(self): <TAB> if not self.key: <TAB> <TAB> self._channel.send(u""pake"", self.msg1) <TAB> <TAB> pake_msg = self._channel.get(u""pake"") <TAB> <TAB> self.key = self.sp.finish(pake_msg) <TAB> <TAB> self.verifier = self.derive_key(u""wormhole:verifier"") <TAB> <TAB> if not self._send_confirm: <TAB> <TAB> <TAB> return <TAB> <TAB> confkey = self.derive_key(u""wormhole:confirmation"") <TAB> <TAB> nonce = os.urandom(CONFMSG_NONCE_LENGTH) <TAB> <TAB> confmsg = make_confmsg(confkey, nonce) <TAB> <TAB> self._channel.send(u""_confirm"", confmsg)",true,if not self . _send_confirm :,if not self . _send_confirm :,0.75,0.0
"def executeScript(self, script): <TAB> if len(script) > 0: <TAB> <TAB> commands = [] <TAB> <TAB> for l in script: <TAB> <TAB> <TAB> extracted = self.extract_command(l) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> commands.append(extracted) <TAB> <TAB> for command in commands: <TAB> <TAB> <TAB> cmd, argv = command <TAB> <TAB> <TAB> self.dispatch_command(cmd, argv)",false,if extracted :,if extracted is not None :,0.09,0.0
"def create_path(n, fullname, meta): <TAB> if meta: <TAB> <TAB> meta.create_path(fullname) <TAB> else: <TAB> <TAB> # These fallbacks are important -- meta could be null if, for <TAB> <TAB> # example, save created a ""fake"" item, i.e. a new strip/graft <TAB> <TAB> # path element, etc.  You can find cases like that by <TAB> <TAB> # searching for ""Metadata()"". <TAB> <TAB> unlink(fullname) <TAB> <TAB> if stat.S_ISDIR(n.mode): <TAB> <TAB> <TAB> mkdirp(fullname) <TAB> <TAB> elif stat.S_ISLNK(n.mode): <TAB> <TAB> <TAB> os.symlink(n.readlink(), fullname)",false,elif stat . S_ISLNK ( n . mode ) :,if stat . S_ISDIR ( n . mode ) :,0.29,0.0
def get_cycle(self): <TAB> if self.has_cycle(): <TAB> <TAB> cross_node = self.path[-1] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return self.path[self.path.index(cross_node) :] <TAB> <TAB> else: <TAB> <TAB> <TAB> return self.path <TAB> return [],false,if self . path . count ( cross_node ) > 1 :,if cross_node in self . path :,0.05,0.0
"def _select_block(str_in, start_tag, end_tag): <TAB> """"""Select first block delimited by start_tag and end_tag"""""" <TAB> start_pos = str_in.find(start_tag) <TAB> if start_pos < 0: <TAB> <TAB> raise ValueError(""start_tag not found"") <TAB> depth = 0 <TAB> for pos in range(start_pos, len(str_in)): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> depth += 1 <TAB> <TAB> elif str_in[pos] == end_tag: <TAB> <TAB> <TAB> depth -= 1 <TAB> <TAB> if depth == 0: <TAB> <TAB> <TAB> break <TAB> sel = str_in[start_pos + 1 : pos] <TAB> return sel",true,if str_in [ pos ] == start_tag :,if str_in [ pos ] == start_tag :,0.75,0.0
"def device(self): <TAB> """"""Device on which the data array of this variable reside."""""" <TAB> # lazy initialization for performance <TAB> if self._device is None: <TAB> <TAB> if self._data[0] is None: <TAB> <TAB> <TAB> self._device = backend.CpuDevice() <TAB> <TAB> else: <TAB> <TAB> <TAB> self._device = backend.get_device_from_array(self._data[0]) <TAB> return self._device",true,if self . _data [ 0 ] is None :,if self . _data [ 0 ] is None :,0.75,0.0
"def function_out(*args, **kwargs): <TAB> try: <TAB> <TAB> return function_in(*args, **kwargs) <TAB> except dbus.exceptions.DBusException as e: <TAB> <TAB> if e.get_dbus_name() == DBUS_UNKNOWN_METHOD: <TAB> <TAB> <TAB> raise ItemNotFoundException(""Item does not exist!"") <TAB> <TAB> if e.get_dbus_name() == DBUS_NO_SUCH_OBJECT: <TAB> <TAB> <TAB> raise ItemNotFoundException(e.get_dbus_message()) <TAB> <TAB> if e.get_dbus_name() in (DBUS_NO_REPLY, DBUS_NOT_SUPPORTED): <TAB> <TAB> <TAB> raise SecretServiceNotAvailableException(e.get_dbus_message()) <TAB> <TAB> raise",false,if e . get_dbus_name ( ) == DBUS_NO_SUCH_OBJECT :,if e . get_dbus_name ( ) == DBUS_UNKNOWN_METHOD :,0.63,0.0
"def run(self): <TAB> """"""Continual loop evaluating when_statements"""""" <TAB> while len(self.library) > 0: <TAB> <TAB> for name, expression in self.library.items(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> del self.library[name] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> expression.evaluate() <TAB> <TAB> sleep(0.01) <TAB> return",false,if expression . remove_me == True :,if name in self . when_statements :,0.02,0.0
"def tamper(payload, **kwargs): <TAB> junk_chars = ""!#$%&()*~+-_.,:;?@[/|\]^`"" <TAB> retval = """" <TAB> for i, char in enumerate(payload, start=1): <TAB> <TAB> amount = random.randint(10, 15) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> retval += "">"" <TAB> <TAB> <TAB> for _ in range(amount): <TAB> <TAB> <TAB> <TAB> retval += random.choice(junk_chars) <TAB> <TAB> elif char == ""<"": <TAB> <TAB> <TAB> retval += ""<"" <TAB> <TAB> <TAB> for _ in range(amount): <TAB> <TAB> <TAB> <TAB> retval += random.choice(junk_chars) <TAB> <TAB> elif char == "" "": <TAB> <TAB> <TAB> for _ in range(amount): <TAB> <TAB> <TAB> <TAB> retval += random.choice(junk_chars) <TAB> <TAB> else: <TAB> <TAB> <TAB> retval += char <TAB> return retval",false,"if char == "">"" :",if i % 2 == 0 :,0.03,0.0
"def _source_target_path(source, source_path, source_location): <TAB> target_path_attr = source.target_path or source.resdef.target_path <TAB> if source.preserve_path: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> log.warning( <TAB> <TAB> <TAB> <TAB> ""target-path '%s' specified with preserve-path - ignoring"", <TAB> <TAB> <TAB> <TAB> target_path_attr, <TAB> <TAB> <TAB> ) <TAB> <TAB> return os.path.relpath(os.path.dirname(source_path), source_location) <TAB> else: <TAB> <TAB> return target_path_attr or source.resdef.target_path or """"",true,if target_path_attr :,if target_path_attr :,0.53,0.0
"def _load_user_from_header(self, header): <TAB> if self._header_callback: <TAB> <TAB> user = self._header_callback(header) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> app = current_app._get_current_object() <TAB> <TAB> <TAB> user_loaded_from_header.send(app, user=user) <TAB> <TAB> <TAB> return user <TAB> return None",false,if user is not None :,if user :,0.05,0.0
"def setup(cls): <TAB> ""Check dependencies and warn about firewalling"" <TAB> pathCheck(""brctl"", moduleName=""bridge-utils"") <TAB> # Disable Linux bridge firewalling so that traffic can flow! <TAB> for table in ""arp"", ""ip"", ""ip6"": <TAB> <TAB> cmd = ""sysctl net.bridge.bridge-nf-call-%stables"" % table <TAB> <TAB> out = quietRun(cmd).strip() <TAB> <TAB> if out.endswith(""1""): <TAB> <TAB> <TAB> warn(""Warning: Linux bridge may not work with"", out, ""\n"")",true,"if out . endswith ( ""1"" ) :","if out . endswith ( ""1"" ) :",0.75,0.0
"def _browse_your_music(web_client, variant): <TAB> if not web_client.logged_in: <TAB> <TAB> return [] <TAB> if variant in (""tracks"", ""albums""): <TAB> <TAB> items = flatten( <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> page.get(""items"", []) <TAB> <TAB> <TAB> <TAB> for page in web_client.get_all( <TAB> <TAB> <TAB> <TAB> <TAB> f""me/{variant}"", <TAB> <TAB> <TAB> <TAB> <TAB> params={""market"": ""from_token"", ""limit"": 50}, <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> if page <TAB> <TAB> <TAB> ] <TAB> <TAB> ) <TAB> <TAB> if variant == ""tracks"": <TAB> <TAB> <TAB> return list(translator.web_to_track_refs(items)) <TAB> <TAB> else: <TAB> <TAB> <TAB> return list(translator.web_to_album_refs(items)) <TAB> else: <TAB> <TAB> return []",true,"if variant == ""tracks"" :","if variant == ""tracks"" :",0.75,0.0
"def reset_styling(self): <TAB> for edge in self.fsm_graph.edges_iter(): <TAB> <TAB> style_attr = self.fsm_graph.style_attributes.get(""edge"", {}).get(""default"") <TAB> <TAB> edge.attr.update(style_attr) <TAB> for node in self.fsm_graph.nodes_iter(): <TAB> <TAB> if ""point"" not in node.attr[""shape""]: <TAB> <TAB> <TAB> style_attr = self.fsm_graph.style_attributes.get(""node"", {}).get(""inactive"") <TAB> <TAB> <TAB> node.attr.update(style_attr) <TAB> for sub_graph in self.fsm_graph.subgraphs_iter(): <TAB> <TAB> style_attr = self.fsm_graph.style_attributes.get(""graph"", {}).get(""default"") <TAB> <TAB> sub_graph.graph_attr.update(style_attr)",true,"if ""point"" not in node . attr [ ""shape"" ] :","if ""point"" not in node . attr [ ""shape"" ] :",0.75,0.0
"def set_message_type_visibility(self, message_type: MessageType): <TAB> try: <TAB> <TAB> rows = { <TAB> <TAB> <TAB> i <TAB> <TAB> <TAB> for i, msg in enumerate(self.proto_analyzer.messages) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> } <TAB> <TAB> if message_type.show: <TAB> <TAB> <TAB> self.ui.tblViewProtocol.show_rows(rows) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.ui.tblViewProtocol.hide_rows(rows) <TAB> except Exception as e: <TAB> <TAB> logger.exception(e)",false,if msg . message_type == message_type,if msg . visibility == message_type . visibility,0.42,0.0
"def POP(cpu, *regs): <TAB> for reg in regs: <TAB> <TAB> val = cpu.stack_pop(cpu.address_bit_size // 8) <TAB> <TAB> if reg.reg in (""PC"", ""R15""): <TAB> <TAB> <TAB> cpu._set_mode_by_val(val) <TAB> <TAB> <TAB> val = val & ~0x1 <TAB> <TAB> reg.write(val)",true,"if reg . reg in ( ""PC"" , ""R15"" ) :","if reg . reg in ( ""PC"" , ""R15"" ) :",0.75,0.0
"def processMovie(self, atom): <TAB> for field in atom: <TAB> <TAB> if ""track"" in field: <TAB> <TAB> <TAB> self.processTrack(field[""track""]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.processMovieHeader(field[""movie_hdr""])",true,"if ""movie_hdr"" in field :","if ""movie_hdr"" in field :",0.75,0.0
"def check_update_function(url, folder, update_setter, version_setter, auto): <TAB> remote_version = urllib.urlopen(url).read() <TAB> if remote_version.isdigit(): <TAB> <TAB> local_version = get_local_timestamp(folder) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if auto: <TAB> <TAB> <TAB> <TAB> update_setter.set_value(True) <TAB> <TAB> <TAB> version_setter.set_value(remote_version) <TAB> <TAB> <TAB> return True <TAB> <TAB> else: <TAB> <TAB> <TAB> return False <TAB> else: <TAB> <TAB> return False",false,if remote_version > local_version :,if local_version > remote_version :,0.29,0.0
"def init(self, view, items=None): <TAB> selections = [] <TAB> if view.sel(): <TAB> <TAB> for region in view.sel(): <TAB> <TAB> <TAB> selections.append(view.substr(region)) <TAB> values = [] <TAB> for idx, index in enumerate(map(int, items)): <TAB> <TAB> if idx >= len(selections): <TAB> <TAB> <TAB> break <TAB> <TAB> i = index - 1 <TAB> <TAB> if i >= 0 and i < len(selections): <TAB> <TAB> <TAB> values.append(selections[i]) <TAB> <TAB> else: <TAB> <TAB> <TAB> values.append(None) <TAB> # fill up <TAB> for idx, value in enumerate(selections): <TAB> <TAB> if len(values) + 1 < idx: <TAB> <TAB> <TAB> values.append(value) <TAB> self.stack = values",false,if i >= 0 and i < len ( selections ) :,if idx >= len ( selections ) :,0.18,0.0
"def find_int_identifiers(directory): <TAB> results = find_rules(directory, has_int_identifier) <TAB> print(""Number of rules with integer identifiers: %d"" % len(results)) <TAB> for result in results: <TAB> <TAB> rule_path = result[0] <TAB> <TAB> product_yaml_path = result[1] <TAB> <TAB> product_yaml = None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> product_yaml = yaml.open_raw(product_yaml_path) <TAB> <TAB> fix_file(rule_path, product_yaml, fix_int_identifier)",false,if product_yaml_path is not None :,if product_yaml_path :,0.05,0.0
"def condition(self): <TAB> if self.__condition is None: <TAB> <TAB> if len(self.flat_conditions) == 1: <TAB> <TAB> <TAB> # Avoid an extra indirection in the common case of only one condition. <TAB> <TAB> <TAB> self.__condition = self.flat_conditions[0] <TAB> <TAB> elif len(self.flat_conditions) == 0: <TAB> <TAB> <TAB> # Possible, if unlikely, due to filter predicate rewriting <TAB> <TAB> <TAB> self.__condition = lambda _: True <TAB> <TAB> else: <TAB> <TAB> <TAB> self.__condition = lambda x: all(cond(x) for cond in self.flat_conditions) <TAB> return self.__condition",true,elif len ( self . flat_conditions ) == 0 :,elif len ( self . flat_conditions ) == 0 :,0.75,0.0
"def get_scene_exceptions_by_season(self, season=-1): <TAB> scene_exceptions = [] <TAB> for scene_exception in self.scene_exceptions: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> scene_name, scene_season = scene_exception.split(""|"") <TAB> <TAB> if season == scene_season: <TAB> <TAB> <TAB> scene_exceptions.append(scene_name) <TAB> return scene_exceptions",false,if not len ( scene_exception ) == 2 :,"if ""|"" not in scene_exception :",0.02,0.0
"def init(self, view, items=None): <TAB> selections = [] <TAB> if view.sel(): <TAB> <TAB> for region in view.sel(): <TAB> <TAB> <TAB> selections.append(view.substr(region)) <TAB> values = [] <TAB> for idx, index in enumerate(map(int, items)): <TAB> <TAB> if idx >= len(selections): <TAB> <TAB> <TAB> break <TAB> <TAB> i = index - 1 <TAB> <TAB> if i >= 0 and i < len(selections): <TAB> <TAB> <TAB> values.append(selections[i]) <TAB> <TAB> else: <TAB> <TAB> <TAB> values.append(None) <TAB> # fill up <TAB> for idx, value in enumerate(selections): <TAB> <TAB> if len(values) + 1 < idx: <TAB> <TAB> <TAB> values.append(value) <TAB> self.stack = values",true,if idx >= len ( selections ) :,if idx >= len ( selections ) :,0.75,0.0
"def to_tool_path(self, path_or_uri_like, **kwds): <TAB> if ""://"" not in path_or_uri_like: <TAB> <TAB> path = path_or_uri_like <TAB> else: <TAB> <TAB> uri_like = path_or_uri_like <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise Exception(""Invalid URI passed to get_tool_source"") <TAB> <TAB> scheme, rest = uri_like.split("":"", 2) <TAB> <TAB> if scheme not in self.resolver_classes: <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> ""Unknown tool scheme [{}] for URI [{}]"".format(scheme, uri_like) <TAB> <TAB> <TAB> ) <TAB> <TAB> path = self.resolver_classes[scheme]().get_tool_source_path(uri_like) <TAB> return path",false,"if "":"" not in path_or_uri_like :","if "":"" not in uri_like :",0.52,0.0
"def mainWindow(): <TAB> global MW <TAB> if not MW: <TAB> <TAB> for i in qApp.topLevelWidgets(): <TAB> <TAB> <TAB> if i.objectName() == ""MainWindow"": <TAB> <TAB> <TAB> <TAB> MW = i <TAB> <TAB> <TAB> <TAB> return MW <TAB> <TAB> return None <TAB> else: <TAB> <TAB> return MW",true,"if i . objectName ( ) == ""MainWindow"" :","if i . objectName ( ) == ""MainWindow"" :",0.75,0.0
"def async_get_service(hass, config, discovery_info=None): <TAB> # pylint: disable=unused-argument <TAB> """"""Get the demo notification service."""""" <TAB> for account, account_dict in hass.data[DATA_ALEXAMEDIA][""accounts""].items(): <TAB> <TAB> for key, _ in account_dict[""devices""][""media_player""].items(): <TAB> <TAB> <TAB> if key not in account_dict[""entities""][""media_player""]: <TAB> <TAB> <TAB> <TAB> _LOGGER.debug( <TAB> <TAB> <TAB> <TAB> <TAB> ""%s: Media player %s not loaded yet; delaying load"", <TAB> <TAB> <TAB> <TAB> <TAB> hide_email(account), <TAB> <TAB> <TAB> <TAB> <TAB> hide_serial(key), <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return False <TAB> return AlexaNotificationService(hass)",true,"if key not in account_dict [ ""entities"" ] [ ""media_player"" ] :","if key not in account_dict [ ""entities"" ] [ ""media_player"" ] :",0.75,0.0
"def _migrate_bool(self, name: str, true_value: str, false_value: str) -> None: <TAB> if name not in self._settings: <TAB> <TAB> return <TAB> values = self._settings[name] <TAB> if not isinstance(values, dict): <TAB> <TAB> return <TAB> for scope, val in values.items(): <TAB> <TAB> if isinstance(val, bool): <TAB> <TAB> <TAB> new_value = true_value if val else false_value <TAB> <TAB> <TAB> self._settings[name][scope] = new_value <TAB> <TAB> <TAB> self.changed.emit()",true,"if isinstance ( val , bool ) :","if isinstance ( val , bool ) :",0.75,0.0
"def send(self, data, flags=0): <TAB> self._checkClosed() <TAB> if self._sslobj: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""non-zero flags not allowed in calls to send() on %s"" % self.__class__ <TAB> <TAB> <TAB> ) <TAB> <TAB> return self._sslobj.write(data) <TAB> else: <TAB> <TAB> return socket.send(self, data, flags)",true,if flags != 0 :,if flags != 0 :,0.75,0.0
"def rec_deps(services, container_by_name, cnt, init_service): <TAB> deps = cnt[""_deps""] <TAB> for dep in deps.copy(): <TAB> <TAB> dep_cnts = services.get(dep) <TAB> <TAB> if not dep_cnts: <TAB> <TAB> <TAB> continue <TAB> <TAB> dep_cnt = container_by_name.get(dep_cnts[0]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # TODO: avoid creating loops, A->B->A <TAB> <TAB> <TAB> if init_service and init_service in dep_cnt[""_deps""]: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_deps = rec_deps(services, container_by_name, dep_cnt, init_service) <TAB> <TAB> <TAB> deps.update(new_deps) <TAB> return deps",true,if dep_cnt :,if dep_cnt :,0.53,0.0
"def as_dict(path="""", version=""latest"", section=""meta-data""): <TAB> result = {} <TAB> dirs = dir(path, version, section) <TAB> if not dirs: <TAB> <TAB> return None <TAB> for item in dirs: <TAB> <TAB> if item.endswith(""/""): <TAB> <TAB> <TAB> records = as_dict(path + item, version, section) <TAB> <TAB> <TAB> if records: <TAB> <TAB> <TAB> <TAB> result[item[:-1]] = records <TAB> <TAB> elif is_dict.match(item): <TAB> <TAB> <TAB> idx, name = is_dict.match(item).groups() <TAB> <TAB> <TAB> records = as_dict(path + idx + ""/"", version, section) <TAB> <TAB> <TAB> if records: <TAB> <TAB> <TAB> <TAB> result[name] = records <TAB> <TAB> else: <TAB> <TAB> <TAB> result[item] = valueconv(get(path + item, version, section)) <TAB> return result",false,elif is_dict . match ( item ) :,"if item . endswith ( ""/"" ) :",0.04,0.0
"def PrintColGroup(col_names, schema): <TAB> """"""Print HTML colgroup element, used for JavaScript sorting."""""" <TAB> print(""  <colgroup>"") <TAB> for i, col in enumerate(col_names): <TAB> <TAB> if col.endswith(""_HREF""): <TAB> <TAB> <TAB> continue <TAB> <TAB> # CSS class is used for sorting <TAB> <TAB> if schema.IsNumeric(col): <TAB> <TAB> <TAB> css_class = ""number"" <TAB> <TAB> else: <TAB> <TAB> <TAB> css_class = ""case-insensitive"" <TAB> <TAB> # NOTE: id is a comment only; not used <TAB> <TAB> print(' <TAB><col id=""{}"" type=""{}"" />'.format(col, css_class)) <TAB> print(""  </colgroup>"")",true,if schema . IsNumeric ( col ) :,if schema . IsNumeric ( col ) :,0.75,0.0
"def check_region(self, region): <TAB> for other in self.regions: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if (other.start < region.start < other.end) or ( <TAB> <TAB> <TAB> other.start < region.end < other.end <TAB> <TAB> ): <TAB> <TAB> <TAB> raise Exception(""%r overlaps with %r"" % (region, other))",false,if other is region :,if other . start == region . start and other . end == region . end :,0.04,0.0
"def _write_value(self, rng, value, scalar): <TAB> if rng.api and value: <TAB> <TAB> # it is assumed by this stage that value is a list of lists <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> value = value[0][0] <TAB> <TAB> else: <TAB> <TAB> <TAB> rng = rng.resize(len(value), len(value[0])) <TAB> <TAB> rng.raw_value = value",true,if scalar :,if scalar :,0.53,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB> if tt == 10: <TAB> <TAB> <TAB> length = d.getVarInt32() <TAB> <TAB> <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB> <TAB> <TAB> d.skip(length) <TAB> <TAB> <TAB> self.mutable_cost().TryMerge(tmp) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 24: <TAB> <TAB> <TAB> self.add_version(d.getVarInt64()) <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 0 :,if tt == 0 :,0.75,0.0
"def generate_sv_faces(dcel_mesh, point_index, only_select=False, del_flag=None): <TAB> # This part of function creates faces in SV format <TAB> # It ignores  boundless super face <TAB> sv_faces = [] <TAB> for i, face in enumerate(dcel_mesh.faces): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ""Face ({}) has inner components! Sverchok cant show polygons with holes."".format( <TAB> <TAB> <TAB> <TAB> i <TAB> <TAB> <TAB> ) <TAB> <TAB> if not face.outer or del_flag in face.flags: <TAB> <TAB> <TAB> continue <TAB> <TAB> if only_select and not face.select: <TAB> <TAB> <TAB> continue <TAB> <TAB> sv_faces.append([point_index[hedge.origin] for hedge in face.outer.loop_hedges]) <TAB> return sv_faces",false,if face . inners and face . outer :,if i > 0 :,0.02,0.0
"def _get_x_for_y(self, xValue, x, y): <TAB> # print(""searching ""+x+"" with the value ""+str(xValue)+"" and want to give back ""+y) <TAB> x_value = str(xValue) <TAB> for anime in self.xmlMap.findall(""anime""): <TAB> <TAB> try: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return int(anime.get(y, 0)) <TAB> <TAB> except ValueError as e: <TAB> <TAB> <TAB> continue <TAB> return 0",false,"if anime . get ( x , False ) == x_value :",if x in x_value :,0.02,0.0
"def dir_copy(src_dir, dest_dir, merge_if_exists=True): <TAB> try: <TAB> <TAB> if not os.path.exists(dest_dir): <TAB> <TAB> <TAB> shutil.copytree(src_dir, dest_dir) <TAB> <TAB> elif merge_if_exists: <TAB> <TAB> <TAB> merge_dir(src_dir, dest_dir) <TAB> except OSError as e: <TAB> <TAB> # If source is not a directory, copy with shutil.copy <TAB> <TAB> if e.errno == errno.ENOTDIR: <TAB> <TAB> <TAB> shutil.copy(src_dir, dest_dir) <TAB> <TAB> else: <TAB> <TAB> <TAB> logging.error(""Could not copy %s to %s"", src_dir, dest_dir)",true,elif merge_if_exists :,elif merge_if_exists :,0.51,0.0
"def mapping(self): <TAB> m = {} <TAB> if getGdriveCredentialsFile() is not None: <TAB> <TAB> m[""gdrive""] = """" <TAB> unknown = 0 <TAB> for f in self.scan: <TAB> <TAB> bits = f.split(""#"", 2) <TAB> <TAB> if len(bits) == 1: <TAB> <TAB> <TAB> label = os.path.basename(f) <TAB> <TAB> else: <TAB> <TAB> <TAB> label = bits[1] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> label = ""L"" + str(unknown) <TAB> <TAB> <TAB> unknown += 1 <TAB> <TAB> m[label] = bits[0] <TAB> return m",false,"if not label or len ( label ) == 0 or label == """" :",if unknown :,0.01,0.0
"def get_tag_values(self, event): <TAB> http = event.interfaces.get(""sentry.interfaces.Http"") <TAB> if not http: <TAB> <TAB> return [] <TAB> if not http.headers: <TAB> <TAB> return [] <TAB> headers = http.headers <TAB> # XXX: transitional support for workers <TAB> if isinstance(headers, dict): <TAB> <TAB> headers = headers.items() <TAB> output = [] <TAB> for key, value in headers: <TAB> <TAB> if key != ""User-Agent"": <TAB> <TAB> <TAB> continue <TAB> <TAB> ua = Parse(value) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> result = self.get_tag_from_ua(ua) <TAB> <TAB> if result: <TAB> <TAB> <TAB> output.append(result) <TAB> return output",true,if not ua :,if not ua :,0.75,0.0
"def __iter__(self): <TAB> it = DiskHashMerger.__iter__(self) <TAB> direct_upstreams = self.direct_upstreams <TAB> for k, groups in it: <TAB> <TAB> t = list([[] for _ in range(self.size)]) <TAB> <TAB> for i, g in enumerate(groups): <TAB> <TAB> <TAB> if g: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> t[i] = g <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> g.sort(key=itemgetter(0)) <TAB> <TAB> <TAB> <TAB> <TAB> g1 = [] <TAB> <TAB> <TAB> <TAB> <TAB> for _, vs in g: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> g1.extend(vs) <TAB> <TAB> <TAB> <TAB> <TAB> t[i] = g1 <TAB> <TAB> yield k, tuple(t)",false,if i in direct_upstreams :,if i not in direct_upstreams :,0.15,0.0
"def process_question(qtxt): <TAB> question = """" <TAB> skip = False <TAB> for letter in qtxt: <TAB> <TAB> if letter == ""<"": <TAB> <TAB> <TAB> skip = True <TAB> <TAB> if letter == "">"": <TAB> <TAB> <TAB> skip = False <TAB> <TAB> if skip: <TAB> <TAB> <TAB> continue <TAB> <TAB> if letter.isalnum() or letter == "" "": <TAB> <TAB> <TAB> if letter == "" "": <TAB> <TAB> <TAB> <TAB> letter = ""_"" <TAB> <TAB> <TAB> question += letter.lower() <TAB> return question",false,"if letter == ""<"" :","if letter . isalnum ( ) or letter == "" "" :",0.05,0.0
"def _module_repr_from_spec(spec): <TAB> """"""Return the repr to use for the module."""""" <TAB> # We mostly replicate _module_repr() using the spec attributes. <TAB> name = ""?"" if spec.name is None else spec.name <TAB> if spec.origin is None: <TAB> <TAB> if spec.loader is None: <TAB> <TAB> <TAB> return ""<module {!r}>"".format(name) <TAB> <TAB> else: <TAB> <TAB> <TAB> return ""<module {!r} ({!r})>"".format(name, spec.loader) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ""<module {!r} from {!r}>"".format(name, spec.origin) <TAB> <TAB> else: <TAB> <TAB> <TAB> return ""<module {!r} ({})>"".format(spec.name, spec.origin)",false,if spec . has_location :,if spec . loader is None :,0.2,0.0
"def test_row(self, row): <TAB> for idx, test in self.patterns.items(): <TAB> <TAB> try: <TAB> <TAB> <TAB> value = row[idx] <TAB> <TAB> except IndexError: <TAB> <TAB> <TAB> value = """" <TAB> <TAB> result = test(value) <TAB> <TAB> if self.any_match: <TAB> <TAB> <TAB> if result: <TAB> <TAB> <TAB> <TAB> return not self.inverse  # True <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return self.inverse  # False <TAB> if self.any_match: <TAB> <TAB> return self.inverse  # False <TAB> else: <TAB> <TAB> return not self.inverse  # True",false,if not result :,if self . any_match :,0.04,0.0
"def frequent_thread_switches(): <TAB> """"""Make concurrency bugs more likely to manifest."""""" <TAB> interval = None <TAB> if not sys.platform.startswith(""java""): <TAB> <TAB> if hasattr(sys, ""getswitchinterval""): <TAB> <TAB> <TAB> interval = sys.getswitchinterval() <TAB> <TAB> <TAB> sys.setswitchinterval(1e-6) <TAB> <TAB> else: <TAB> <TAB> <TAB> interval = sys.getcheckinterval() <TAB> <TAB> <TAB> sys.setcheckinterval(1) <TAB> try: <TAB> <TAB> yield <TAB> finally: <TAB> <TAB> if not sys.platform.startswith(""java""): <TAB> <TAB> <TAB> if hasattr(sys, ""setswitchinterval""): <TAB> <TAB> <TAB> <TAB> sys.setswitchinterval(interval) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> sys.setcheckinterval(interval)",false,"if hasattr ( sys , ""getswitchinterval"" ) :","if hasattr ( sys , ""setswitchinterval"" ) :",0.55,0.0
"def record_expected_exportable_production(self, ticks): <TAB> """"""Record the amount of production that should be transferred to other islands."""""" <TAB> for (quota_holder, resource_id), amount in self._low_priority_requests.items(): <TAB> <TAB> if quota_holder not in self._settlement_manager_id: <TAB> <TAB> <TAB> self._settlement_manager_id[quota_holder] = WorldObject.get_object_by_id( <TAB> <TAB> <TAB> <TAB> int(quota_holder[1:].split("","")[0]) <TAB> <TAB> <TAB> ).settlement_manager.worldid <TAB> <TAB> self.trade_storage[self._settlement_manager_id[quota_holder]][resource_id] += ( <TAB> <TAB> <TAB> ticks * amount <TAB> <TAB> )",true,if quota_holder not in self . _settlement_manager_id :,if quota_holder not in self . _settlement_manager_id :,0.75,0.0
"def _method_events_callback(self, values): <TAB> try: <TAB> <TAB> previous_echoed = ( <TAB> <TAB> <TAB> values[""child_result_list""][-1].decode().split(""\n"")[-2].strip() <TAB> <TAB> ) <TAB> <TAB> if previous_echoed.endswith(""foo1""): <TAB> <TAB> <TAB> return ""echo foo2\n"" <TAB> <TAB> elif previous_echoed.endswith(""foo2""): <TAB> <TAB> <TAB> return ""echo foo3\n"" <TAB> <TAB> elif previous_echoed.endswith(""foo3""): <TAB> <TAB> <TAB> return ""exit\n"" <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception(""Unexpected output {0!r}"".format(previous_echoed)) <TAB> except IndexError: <TAB> <TAB> return ""echo foo1\n""",false,"if previous_echoed . endswith ( ""foo1"" ) :","elif previous_echoed . endswith ( ""foo3"" ) :",0.2,0.0
"def describe_cluster_snapshots(self, cluster_identifier=None, snapshot_identifier=None): <TAB> if cluster_identifier: <TAB> <TAB> cluster_snapshots = [] <TAB> <TAB> for snapshot in self.snapshots.values(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> cluster_snapshots.append(snapshot) <TAB> <TAB> if cluster_snapshots: <TAB> <TAB> <TAB> return cluster_snapshots <TAB> if snapshot_identifier: <TAB> <TAB> if snapshot_identifier in self.snapshots: <TAB> <TAB> <TAB> return [self.snapshots[snapshot_identifier]] <TAB> <TAB> raise ClusterSnapshotNotFoundError(snapshot_identifier) <TAB> return self.snapshots.values()",false,if snapshot . cluster . cluster_identifier == cluster_identifier :,if snapshot . cluster_identifier == cluster_identifier :,0.6,0.0
"def get_snippet_edit_handler(model): <TAB> if model not in SNIPPET_EDIT_HANDLERS: <TAB> <TAB> if hasattr(model, ""edit_handler""): <TAB> <TAB> <TAB> # use the edit handler specified on the page class <TAB> <TAB> <TAB> edit_handler = model.edit_handler <TAB> <TAB> else: <TAB> <TAB> <TAB> panels = extract_panel_definitions_from_model_class(model) <TAB> <TAB> <TAB> edit_handler = ObjectList(panels) <TAB> <TAB> SNIPPET_EDIT_HANDLERS[model] = edit_handler.bind_to(model=model) <TAB> return SNIPPET_EDIT_HANDLERS[model]",true,"if hasattr ( model , ""edit_handler"" ) :","if hasattr ( model , ""edit_handler"" ) :",0.75,0.0
"def start(): <TAB> if os.environ.get(""RUN_MAIN"") != ""true"": <TAB> <TAB> try: <TAB> <TAB> <TAB> exit_code = restart_with_reloader() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> os.kill(os.getpid(), -exit_code) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> sys.exit(exit_code) <TAB> <TAB> except KeyboardInterrupt: <TAB> <TAB> <TAB> pass",true,if exit_code < 0 :,if exit_code < 0 :,0.75,0.0
"def discover(self, *objlist): <TAB> ret = [] <TAB> for l in self.splitlines(): <TAB> <TAB> if len(l) < 5: <TAB> <TAB> <TAB> continue <TAB> <TAB> if l[0] == ""Filename"": <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> int(l[2]) <TAB> <TAB> <TAB> int(l[3]) <TAB> <TAB> except: <TAB> <TAB> <TAB> continue <TAB> <TAB> # <TAB> <TAB>   ret.append(improve(l[0])) <TAB> <TAB> ret.append(l[0]) <TAB> ret.sort() <TAB> for item in objlist: <TAB> <TAB> ret.append(item) <TAB> return ret",true,"if l [ 0 ] == ""Filename"" :","if l [ 0 ] == ""Filename"" :",0.75,0.0
"def ipfs_publish(self, lib): <TAB> with tempfile.NamedTemporaryFile() as tmp: <TAB> <TAB> self.ipfs_added_albums(lib, tmp.name) <TAB> <TAB> try: <TAB> <TAB> <TAB> if self.config[""nocopy""]: <TAB> <TAB> <TAB> <TAB> cmd = ""ipfs add --nocopy -q "".split() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> cmd = ""ipfs add -q "".split() <TAB> <TAB> <TAB> cmd.append(tmp.name) <TAB> <TAB> <TAB> output = util.command_output(cmd) <TAB> <TAB> except (OSError, subprocess.CalledProcessError) as err: <TAB> <TAB> <TAB> msg = ""Failed to publish library. Error: {0}"".format(err) <TAB> <TAB> <TAB> self._log.error(msg) <TAB> <TAB> <TAB> return False <TAB> <TAB> self._log.info(""hash of library: {0}"", output)",true,"if self . config [ ""nocopy"" ] :","if self . config [ ""nocopy"" ] :",0.75,0.0
"def spends(self): <TAB> # Return spends indexed by hashX <TAB> spends = defaultdict(list) <TAB> utxos = self.mempool_utxos() <TAB> for tx_hash, tx in self.txs.items(): <TAB> <TAB> for n, input in enumerate(tx.inputs): <TAB> <TAB> <TAB> if input.is_generation(): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> prevout = (input.prev_hash, input.prev_idx) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> hashX, value = utxos.pop(prevout) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> hashX, value = self.db_utxos[prevout] <TAB> <TAB> <TAB> spends[hashX].append(prevout) <TAB> return spends",false,if prevout in utxos :,if n == 0 :,0.03,0.0
"def terminate(self): <TAB> if self.returncode is None: <TAB> <TAB> try: <TAB> <TAB> <TAB> os.kill(self.pid, TERM_SIGNAL) <TAB> <TAB> except OSError as exc: <TAB> <TAB> <TAB> if getattr(exc, ""errno"", None) != errno.ESRCH: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise",false,if self . wait ( timeout = 0.1 ) is None :,if self . raisecode is not None :,0.06,0.0
"def _getVolumeScalar(self): <TAB> if self._volumeScalar is not None: <TAB> <TAB> return self._volumeScalar <TAB> # use default <TAB> elif self._value in dynamicStrToScalar: <TAB> <TAB> return dynamicStrToScalar[self._value] <TAB> else: <TAB> <TAB> thisDynamic = self._value <TAB> <TAB> # ignore leading s like in sf <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> thisDynamic = thisDynamic[1:] <TAB> <TAB> # ignore closing z like in fz <TAB> <TAB> if thisDynamic[-1] == ""z"": <TAB> <TAB> <TAB> thisDynamic = thisDynamic[:-1] <TAB> <TAB> if thisDynamic in dynamicStrToScalar: <TAB> <TAB> <TAB> return dynamicStrToScalar[thisDynamic] <TAB> <TAB> else: <TAB> <TAB> <TAB> return dynamicStrToScalar[None]",false,"if ""s"" in thisDynamic :",if len ( thisDynamic ) > 1 :,0.03,0.0
"def init_values(self): <TAB> config = self._raw_config <TAB> for valname, value in self.overrides.iteritems(): <TAB> <TAB> if ""."" in valname: <TAB> <TAB> <TAB> realvalname, key = valname.split(""."", 1) <TAB> <TAB> <TAB> config.setdefault(realvalname, {})[key] = value <TAB> <TAB> else: <TAB> <TAB> <TAB> config[valname] = value <TAB> for name in config: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.__dict__[name] = config[name] <TAB> del self._raw_config",false,if name in self . values :,if name in config :,0.18,0.0
"def modified(self): <TAB> paths = set() <TAB> dictionary_list = [] <TAB> for op_list in self._operations: <TAB> <TAB> if not isinstance(op_list, list): <TAB> <TAB> <TAB> op_list = (op_list,) <TAB> <TAB> for item in chain(*op_list): <TAB> <TAB> <TAB> if item is None: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> dictionary = item.dictionary <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> paths.add(dictionary.path) <TAB> <TAB> <TAB> dictionary_list.append(dictionary) <TAB> return dictionary_list",true,if dictionary . path in paths :,if dictionary . path in paths :,0.75,0.0
"def __getitem__(self, key, _get_mode=False): <TAB> if not _get_mode: <TAB> <TAB> if isinstance(key, (int, long)): <TAB> <TAB> <TAB> return self._list[key] <TAB> <TAB> elif isinstance(key, slice): <TAB> <TAB> <TAB> return self.__class__(self._list[key]) <TAB> ikey = key.lower() <TAB> for k, v in self._list: <TAB> <TAB> if k.lower() == ikey: <TAB> <TAB> <TAB> return v <TAB> # micro optimization: if we are in get mode we will catch that <TAB> # exception one stack level down so we can raise a standard <TAB> # key error instead of our special one. <TAB> if _get_mode: <TAB> <TAB> raise KeyError() <TAB> raise BadRequestKeyError(key)",false,"if isinstance ( key , ( int , long ) ) :",if k . lower ( ) == ikey :,0.01,0.0
"def _get_items(self, name, target=1): <TAB> all_items = self.get_items(name) <TAB> items = [o for o in all_items if not o.disabled] <TAB> if len(items) < target: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ItemNotFoundError(""insufficient items with name %r"" % name) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise AttributeError(""insufficient non-disabled items with name %s"" % name) <TAB> on = [] <TAB> off = [] <TAB> for o in items: <TAB> <TAB> if o.selected: <TAB> <TAB> <TAB> on.append(o) <TAB> <TAB> else: <TAB> <TAB> <TAB> off.append(o) <TAB> return on, off",false,if len ( all_items ) < target :,if len ( items ) == target :,0.34,0.0
"def get_genome_dir(gid, galaxy_dir, data): <TAB> """"""Return standard location of genome directories."""""" <TAB> if galaxy_dir: <TAB> <TAB> refs = genome.get_refs(gid, None, galaxy_dir, data) <TAB> <TAB> seq_file = tz.get_in([""fasta"", ""base""], refs) <TAB> <TAB> if seq_file and os.path.exists(seq_file): <TAB> <TAB> <TAB> return os.path.dirname(os.path.dirname(seq_file)) <TAB> else: <TAB> <TAB> gdirs = glob.glob(os.path.join(_get_data_dir(), ""genomes"", ""*"", gid)) <TAB> <TAB> if len(gdirs) == 1 and os.path.exists(gdirs[0]): <TAB> <TAB> <TAB> return gdirs[0]",true,if seq_file and os . path . exists ( seq_file ) :,if seq_file and os . path . exists ( seq_file ) :,0.75,0.0
"def _PrintFuncs(self, names): <TAB> # type: (List[str]) -> int <TAB> status = 0 <TAB> for name in names: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(name) <TAB> <TAB> <TAB> # TODO: Could print LST for -f, or render LST.  Bash does this.  'trap' <TAB> <TAB> <TAB> # could use that too. <TAB> <TAB> else: <TAB> <TAB> <TAB> status = 1 <TAB> return status",false,if name in self . funcs :,if name in self . LST_NAMES :,0.57,0.0
"def package_files(self): <TAB> seen_package_directories = () <TAB> directories = self.distribution.package_dir or {} <TAB> empty_directory_exists = """" in directories <TAB> packages = self.distribution.packages or [] <TAB> for package in packages: <TAB> <TAB> if package in directories: <TAB> <TAB> <TAB> package_directory = directories[package] <TAB> <TAB> elif empty_directory_exists: <TAB> <TAB> <TAB> package_directory = os.path.join(directories[""""], package) <TAB> <TAB> else: <TAB> <TAB> <TAB> package_directory = package <TAB> <TAB> if not package_directory.startswith(seen_package_directories): <TAB> <TAB> <TAB> seen_package_directories += (package_directory + ""."",) <TAB> <TAB> <TAB> yield package_directory",false,if not package_directory . startswith ( seen_package_directories ) :,elif empty_directory_exists :,0.01,0.0
"def apply_conf_file(fn, conf_filename): <TAB> for env in LSF_CONF_ENV: <TAB> <TAB> conf_file = get_conf_file(conf_filename, env) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> with open(conf_file) as conf_handle: <TAB> <TAB> <TAB> <TAB> value = fn(conf_handle) <TAB> <TAB> <TAB> if value: <TAB> <TAB> <TAB> <TAB> return value <TAB> return None",true,if conf_file :,if conf_file :,0.53,0.0
"def on_text(self, text): <TAB> if text != self.chosen_text: <TAB> <TAB> self.fail_test('Expected ""{}"", received ""{}""'.format(self.chosen_text, text)) <TAB> else: <TAB> <TAB> self.checks_passed += 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.pass_test() <TAB> <TAB> else: <TAB> <TAB> <TAB> self._select_next_text()",false,if self . checks_passed >= self . number_of_checks :,if self . checks_passed >= self . max_checks :,0.88,0.0
"def test_field_attr_existence(self): <TAB> for name, item in ast.__dict__.items(): <TAB> <TAB> if self._is_ast_node(name, item): <TAB> <TAB> <TAB> if name == ""Index"": <TAB> <TAB> <TAB> <TAB> # Index(value) just returns value now. <TAB> <TAB> <TAB> <TAB> # The argument is required. <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> x = item() <TAB> <TAB> <TAB> if isinstance(x, ast.AST): <TAB> <TAB> <TAB> <TAB> self.assertEqual(type(x._fields), tuple)",false,"if name == ""Index"" :","if isinstance ( x , ast . AST ) :",0.02,0.0
"def apply(self, response): <TAB> updated_headers = self.update_headers(response) <TAB> if updated_headers: <TAB> <TAB> response.headers.update(updated_headers) <TAB> <TAB> warning_header_value = self.warning(response) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> response.headers.update({""Warning"": warning_header_value}) <TAB> return response",false,if warning_header_value is not None :,if warning_header_value :,0.05,0.0
"def validate(self): <TAB> self.assertEqual(len(self.inputs), len(self.outputs)) <TAB> for batch_in, batch_out in zip(self.inputs, self.outputs): <TAB> <TAB> self.assertEqual(len(batch_in), len(batch_out)) <TAB> <TAB> if self.use_parallel_executor and not self.use_double_buffer: <TAB> <TAB> <TAB> self.validate_unordered_batch(batch_in, batch_out) <TAB> <TAB> else: <TAB> <TAB> <TAB> for in_data, out_data in zip(batch_in, batch_out): <TAB> <TAB> <TAB> <TAB> self.assertEqual(in_data.shape, out_data.shape) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self.assertTrue((in_data == out_data).all())",false,if not self . use_parallel_executor :,if self . use_parallel_executor and not self . use_double_buffer :,0.29,0.0
def finalize(self): <TAB> if self._started: <TAB> <TAB> if not self._finalized: <TAB> <TAB> <TAB> self._queue.put(None) <TAB> <TAB> <TAB> self._queue.join() <TAB> <TAB> <TAB> self._consumer.join() <TAB> <TAB> self._started = False <TAB> self._finalized = True,true,if not self . _finalized :,if not self . _finalized :,0.75,0.0
"def _get_ilo_version(self): <TAB> try: <TAB> <TAB> self._get_ilo2('<?xml version=""1.0""?><RIBCL VERSION=""2.0""></RIBCL>') <TAB> except ResponseError as e: <TAB> <TAB> if hasattr(e, ""code""): <TAB> <TAB> <TAB> if e.code == 405: <TAB> <TAB> <TAB> <TAB> return 3 <TAB> <TAB> <TAB> if e.code == 501: <TAB> <TAB> <TAB> <TAB> return 1 <TAB> <TAB> raise <TAB> return 2",true,"if hasattr ( e , ""code"" ) :","if hasattr ( e , ""code"" ) :",0.75,0.0
"def _check_data(self, source, expected_bytes, expected_duration): <TAB> received_bytes = 0 <TAB> received_seconds = 0.0 <TAB> bytes_to_read = 1024 <TAB> while True: <TAB> <TAB> data = source.get_audio_data(bytes_to_read) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> received_bytes += data.length <TAB> <TAB> received_seconds += data.duration <TAB> <TAB> self.assertEqual(data.length, len(data.data)) <TAB> self.assertAlmostEqual(expected_duration, received_seconds, places=1) <TAB> self.assertAlmostEqual(expected_bytes, received_bytes, delta=5)",false,if data is None :,if not data :,0.04,0.0
"def __randomize_interval_task(self): <TAB> for job in self.aps_scheduler.get_jobs(): <TAB> <TAB> if isinstance(job.trigger, IntervalTrigger): <TAB> <TAB> <TAB> self.aps_scheduler.modify_job( <TAB> <TAB> <TAB> <TAB> job.id, <TAB> <TAB> <TAB> <TAB> next_run_time=datetime.now() <TAB> <TAB> <TAB> <TAB> + timedelta( <TAB> <TAB> <TAB> <TAB> <TAB> seconds=randrange( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> job.trigger.interval.total_seconds() * 0.75, <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> job.trigger.interval.total_seconds(), <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> )",true,"if isinstance ( job . trigger , IntervalTrigger ) :","if isinstance ( job . trigger , IntervalTrigger ) :",0.75,0.0
"def find_approximant(x): <TAB> c = 1e-4 <TAB> it = sympy.ntheory.continued_fraction_convergents( <TAB> <TAB> sympy.ntheory.continued_fraction_iterator(x) <TAB> ) <TAB> for i in it: <TAB> <TAB> p, q = i.as_numer_denom() <TAB> <TAB> tol = c / q ** 2 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return i <TAB> <TAB> if tol < machine_epsilon: <TAB> <TAB> <TAB> break <TAB> return x",false,if abs ( i - x ) <= tol :,if tol > p ** 2 :,0.01,0.0
"def fix_newlines(lines): <TAB> """"""Convert newlines to unix."""""" <TAB> for i, line in enumerate(lines): <TAB> <TAB> if line.endswith(""\r\n""): <TAB> <TAB> <TAB> lines[i] = line[:-2] + ""\n"" <TAB> <TAB> elif line.endswith(""\r""): <TAB> <TAB> <TAB> lines[i] = line[:-1] + ""\n""",true,"elif line . endswith ( ""\r"" ) :","elif line . endswith ( ""\r"" ) :",0.75,0.0
"def payment_control_render(self, request: HttpRequest, payment: OrderPayment): <TAB> template = get_template(""pretixplugins/paypal/control.html"") <TAB> sale_id = None <TAB> for trans in payment.info_data.get(""transactions"", []): <TAB> <TAB> for res in trans.get(""related_resources"", []): <TAB> <TAB> <TAB> if ""sale"" in res and ""id"" in res[""sale""]: <TAB> <TAB> <TAB> <TAB> sale_id = res[""sale""][""id""] <TAB> ctx = { <TAB> <TAB> ""request"": request, <TAB> <TAB> ""event"": self.event, <TAB> <TAB> ""settings"": self.settings, <TAB> <TAB> ""payment_info"": payment.info_data, <TAB> <TAB> ""order"": payment.order, <TAB> <TAB> ""sale_id"": sale_id, <TAB> } <TAB> return template.render(ctx)",true,"if ""sale"" in res and ""id"" in res [ ""sale"" ] :","if ""sale"" in res and ""id"" in res [ ""sale"" ] :",1.0,0.0
"def for_name(self, name): <TAB> try: <TAB> <TAB> name_resources = self._resources[name] <TAB> except KeyError: <TAB> <TAB> raise LookupError(name) <TAB> else: <TAB> <TAB> for res in name_resources: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> inst = res.inst() <TAB> <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> <TAB> if log.getEffectiveLevel() <= logging.DEBUG: <TAB> <TAB> <TAB> <TAB> <TAB> log.exception(""error initializing %s"", res) <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> log.error(""error initializing %s: %s"", res, e) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> yield inst",true,if log . getEffectiveLevel ( ) <= logging . DEBUG :,if log . getEffectiveLevel ( ) <= logging . DEBUG :,0.75,0.0
"def describe(self, done=False): <TAB> description = ShellCommand.describe(self, done) <TAB> if done: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> description = [""compile""] <TAB> <TAB> description.append(""%d projects"" % self.getStatistic(""projects"", 0)) <TAB> <TAB> description.append(""%d files"" % self.getStatistic(""files"", 0)) <TAB> <TAB> warnings = self.getStatistic(""warnings"", 0) <TAB> <TAB> if warnings > 0: <TAB> <TAB> <TAB> description.append(""%d warnings"" % warnings) <TAB> <TAB> errors = self.getStatistic(""errors"", 0) <TAB> <TAB> if errors > 0: <TAB> <TAB> <TAB> description.append(""%d errors"" % errors) <TAB> return description",false,if not description :,if description is None :,0.05,0.0
"def parse_list(tl): <TAB> ls = [] <TAB> nm = [] <TAB> while True: <TAB> <TAB> term, nmt, tl = parse_term(tl) <TAB> <TAB> ls.append(term) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> nm.append(nmt) <TAB> <TAB> if tl[0] != "","": <TAB> <TAB> <TAB> break <TAB> <TAB> tl = tl[1:] <TAB> return ls, nm, tl",false,if nmt is not None :,if nmt :,0.05,0.0
"def infer_dataset_impl(path): <TAB> if IndexedRawTextDataset.exists(path): <TAB> <TAB> return ""raw"" <TAB> elif IndexedDataset.exists(path): <TAB> <TAB> with open(index_file_path(path), ""rb"") as f: <TAB> <TAB> <TAB> magic = f.read(8) <TAB> <TAB> <TAB> if magic == IndexedDataset._HDR_MAGIC: <TAB> <TAB> <TAB> <TAB> return ""cached"" <TAB> <TAB> <TAB> elif magic == MMapIndexedDataset.Index._HDR_MAGIC[:8]: <TAB> <TAB> <TAB> <TAB> return ""mmap"" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return None <TAB> elif FastaDataset.exists(path): <TAB> <TAB> return ""fasta"" <TAB> else: <TAB> <TAB> return None",false,if magic == IndexedDataset . _HDR_MAGIC :,elif magic == MMapIndexedDataset . Index . _HDR_MAGIC [ : 8 ] :,0.12,0.0
"def _get(self): <TAB> fut = item = None <TAB> with self._mutex: <TAB> <TAB> # Critical section never blocks. <TAB> <TAB> if not self._queue or self._getters: <TAB> <TAB> <TAB> fut = Future() <TAB> <TAB> <TAB> fut.add_done_callback( <TAB> <TAB> <TAB> <TAB> lambda f: self._get_complete() if not f.cancelled() else None <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self._getters.append(fut) <TAB> <TAB> else: <TAB> <TAB> <TAB> item = self._get_item() <TAB> <TAB> <TAB> self._get_complete() <TAB> return item, fut",true,if not self . _queue or self . _getters :,if not self . _queue or self . _getters :,1.0,0.0
"def validate(self): <TAB> dates = [] <TAB> for d in self.get(""leave_block_list_dates""): <TAB> <TAB> # date is not repeated <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> frappe.msgprint( <TAB> <TAB> <TAB> <TAB> _(""Date is repeated"") + "":"" + d.block_date, raise_exception=1 <TAB> <TAB> <TAB> ) <TAB> <TAB> dates.append(d.block_date)",false,if d . block_date in dates :,if d . block_date not in dates :,0.42,0.0
"def on_choose_watch_dir_clicked(self): <TAB> if self.window().watchfolder_enabled_checkbox.isChecked(): <TAB> <TAB> previous_watch_dir = self.window().watchfolder_location_input.text() or """" <TAB> <TAB> watch_dir = QFileDialog.getExistingDirectory( <TAB> <TAB> <TAB> self.window(), <TAB> <TAB> <TAB> ""Please select the watch folder"", <TAB> <TAB> <TAB> previous_watch_dir, <TAB> <TAB> <TAB> QFileDialog.ShowDirsOnly, <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> self.window().watchfolder_location_input.setText(watch_dir)",false,if not watch_dir :,if watch_dir is None :,0.05,0.0
"def log_generator(self, limit=6000, **kwargs): <TAB> # Generator for show_log_panel <TAB> skip = 0 <TAB> while True: <TAB> <TAB> logs = self.log(limit=limit, skip=skip, **kwargs) <TAB> <TAB> if not logs: <TAB> <TAB> <TAB> break <TAB> <TAB> for entry in logs: <TAB> <TAB> <TAB> yield entry <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> skip = skip + limit",false,if len ( logs ) < limit :,if skip >= limit :,0.04,0.0
"def _setUpClass(cls): <TAB> global solver <TAB> import pyomo.environ <TAB> from pyomo.solvers.tests.io.writer_test_cases import testCases <TAB> for test_case in testCases: <TAB> <TAB> if ((test_case.name, test_case.io) in solver) and (test_case.available): <TAB> <TAB> <TAB> solver[(test_case.name, test_case.io)] = True",true,"if ( ( test_case . name , test_case . io ) in solver ) and ( test_case . available ) :","if ( ( test_case . name , test_case . io ) in solver ) and ( test_case . available ) :",0.75,0.0
"def _get_file_data(self, normpath, normrev): <TAB> data = self.client.cat(normpath, normrev) <TAB> if has_expanded_svn_keywords(data): <TAB> <TAB> # Find out if this file has any keyword expansion set. <TAB> <TAB> # If it does, collapse these keywords. This is because SVN <TAB> <TAB> # will return the file expanded to us, which would break patching. <TAB> <TAB> keywords = self.client.propget(""svn:keywords"", normpath, normrev, recurse=True) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> data = collapse_svn_keywords(data, force_bytes(keywords[normpath])) <TAB> return data",true,if normpath in keywords :,if normpath in keywords :,0.75,0.0
"def add_controller_list(path): <TAB> if not os.path.exists(os.path.join(path, ""__init__.py"")): <TAB> <TAB> bb.fatal(""Controllers directory %s exists but is missing __init__.py"" % path) <TAB> files = sorted( <TAB> <TAB> [f for f in os.listdir(path) if f.endswith("".py"") and not f.startswith(""_"")] <TAB> ) <TAB> for f in files: <TAB> <TAB> module = ""oeqa.controllers."" + f[:-3] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> controllerslist.append(module) <TAB> <TAB> else: <TAB> <TAB> <TAB> bb.warn( <TAB> <TAB> <TAB> <TAB> ""Duplicate controller module found for %s, only one added. Layers should create unique controller module names"" <TAB> <TAB> <TAB> <TAB> % module <TAB> <TAB> <TAB> )",true,if module not in controllerslist :,if module not in controllerslist :,0.75,0.0
"def on_session2(event): <TAB> new_xmpp.get_roster() <TAB> new_xmpp.send_presence() <TAB> logging.info(roster[0]) <TAB> data = roster[0][""roster""][""items""] <TAB> logging.info(data) <TAB> for jid, item in data.items(): <TAB> <TAB> if item[""subscription""] != ""none"": <TAB> <TAB> <TAB> new_xmpp.send_presence(ptype=""subscribe"", pto=jid) <TAB> <TAB> new_xmpp.update_roster(jid, name=item[""name""], groups=item[""groups""]) <TAB> new_xmpp.disconnect()",true,"if item [ ""subscription"" ] != ""none"" :","if item [ ""subscription"" ] != ""none"" :",0.75,0.0
"def _parse_class_simplified(symbol): <TAB> results = {} <TAB> name = symbol.name + ""("" <TAB> name += "", "".join([analyzer.expand_attribute(base) for base in symbol.bases]) <TAB> name += "")"" <TAB> for sym in symbol.body: <TAB> <TAB> if isinstance(sym, ast.FunctionDef): <TAB> <TAB> <TAB> result = _parse_function_simplified(sym, symbol.name) <TAB> <TAB> <TAB> results.update(result) <TAB> <TAB> elif isinstance(sym, ast.ClassDef): <TAB> <TAB> <TAB> result = _parse_class_simplified(sym) <TAB> <TAB> <TAB> results.update(result) <TAB> lineno = symbol.lineno <TAB> for decorator in symbol.decorator_list: <TAB> <TAB> lineno += 1 <TAB> results[lineno] = (name, ""c"") <TAB> return results",false,"if isinstance ( sym , ast . FunctionDef ) :","elif isinstance ( sym , ast . ClassDef ) :",0.28,0.0
"def check_args(args): <TAB> """"""Checks that the args are coherent."""""" <TAB> check_args_has_attributes(args) <TAB> if args.v: <TAB> <TAB> non_version_attrs = [v for k, v in args.__dict__.items() if k != ""v""] <TAB> <TAB> print(""non_version_attrs"", non_version_attrs) <TAB> <TAB> if len([v for v in non_version_attrs if v is not None]) != 0: <TAB> <TAB> <TAB> fail(""Cannot show the version number with another command."") <TAB> <TAB> return <TAB> if args.i is None: <TAB> <TAB> fail(""Cannot draw ER diagram of no database."") <TAB> if args.o is None: <TAB> <TAB> fail(""Cannot draw ER diagram with no output file."")",true,if len ( [ v for v in non_version_attrs if v is not None ] ) != 0 :,if len ( [ v for v in non_version_attrs if v is not None ] ) != 0 :,0.75,0.0
"def handle(self, *args, **options): <TAB> if not settings.ST_BASE_DIR.endswith(""spirit""): <TAB> <TAB> raise CommandError( <TAB> <TAB> <TAB> ""settings.ST_BASE_DIR is not the spirit root folder, are you overriding it?"" <TAB> <TAB> ) <TAB> for root, dirs, files in os.walk(settings.ST_BASE_DIR): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> with utils.pushd(root): <TAB> <TAB> <TAB> call_command( <TAB> <TAB> <TAB> <TAB> ""makemessages"", stdout=self.stdout, stderr=self.stderr, **options <TAB> <TAB> <TAB> ) <TAB> self.stdout.write(""ok"")",false,"if ""locale"" not in dirs :","if ""spirit"" in root :",0.03,0.0
"def scan(scope): <TAB> for s in scope.children: <TAB> <TAB> if s.start_pos <= position <= s.end_pos: <TAB> <TAB> <TAB> if isinstance(s, (tree.Scope, tree.Flow)): <TAB> <TAB> <TAB> <TAB> return scan(s) or s <TAB> <TAB> <TAB> elif s.type in (""suite"", ""decorated""): <TAB> <TAB> <TAB> <TAB> return scan(s) <TAB> return None",true,"if isinstance ( s , ( tree . Scope , tree . Flow ) ) :","if isinstance ( s , ( tree . Scope , tree . Flow ) ) :",0.75,0.0
def run_sync(self): <TAB> count = 0 <TAB> while count < self.args.num_messages: <TAB> <TAB> batch = self.receiver.fetch_next(max_batch_size=self.args.num_messages - count) <TAB> <TAB> if self.args.peeklock: <TAB> <TAB> <TAB> for msg in batch: <TAB> <TAB> <TAB> <TAB> msg.complete() <TAB> <TAB> count += len(batch),true,if self . args . peeklock :,if self . args . peeklock :,0.75,0.0
"def __getitem__(self, item): <TAB> if self._datas is not None: <TAB> <TAB> ret = [] <TAB> <TAB> for data in self._datas: <TAB> <TAB> <TAB> if isinstance(data, np.ndarray): <TAB> <TAB> <TAB> <TAB> ret.append(data[self._offset]) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> ret.append(data.iloc[self._offset]) <TAB> <TAB> self._offset += 1 <TAB> <TAB> return ret <TAB> else: <TAB> <TAB> return self._get_data(item)",true,"if isinstance ( data , np . ndarray ) :","if isinstance ( data , np . ndarray ) :",0.75,0.0
"def removedir(self, path): <TAB> # type: (Text) -> None <TAB> _path = self.validatepath(path) <TAB> if _path == ""/"": <TAB> <TAB> raise errors.RemoveRootError() <TAB> with ftp_errors(self, path): <TAB> <TAB> try: <TAB> <TAB> <TAB> self.ftp.rmd(_encode(_path, self.ftp.encoding)) <TAB> <TAB> except error_perm as error: <TAB> <TAB> <TAB> code, _ = _parse_ftp_error(error) <TAB> <TAB> <TAB> if code == ""550"": <TAB> <TAB> <TAB> <TAB> if self.isfile(path): <TAB> <TAB> <TAB> <TAB> <TAB> raise errors.DirectoryExpected(path) <TAB> <TAB> <TAB> <TAB> if not self.isempty(path): <TAB> <TAB> <TAB> <TAB> <TAB> raise errors.DirectoryNotEmpty(path) <TAB> <TAB> <TAB> raise  # pragma: no cover",false,if self . isfile ( path ) :,"if code == ""550"" :",0.02,0.0
"def replaces_in_file(file, replacement_list): <TAB> rs = [(re.compile(regexp), repl) for (regexp, repl) in replacement_list] <TAB> file_tmp = file + ""."" + str(os.getpid()) + "".tmp"" <TAB> with open(file, ""r"") as f: <TAB> <TAB> with open(file_tmp, ""w"") as f_tmp: <TAB> <TAB> <TAB> for line in f: <TAB> <TAB> <TAB> <TAB> for r, replace in rs: <TAB> <TAB> <TAB> <TAB> <TAB> match = r.search(line) <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> line = replace + ""\n"" <TAB> <TAB> <TAB> <TAB> f_tmp.write(line) <TAB> shutil.move(file_tmp, file)",true,if match :,if match :,0.53,0.0
"def _get_path_check_mem(self, i, size): <TAB> if size > 0: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> p = self._get_path(i, -1) <TAB> <TAB> else: <TAB> <TAB> <TAB> p = self._get_path(i, size) <TAB> <TAB> <TAB> if p.startswith(""/dev/shm""): <TAB> <TAB> <TAB> <TAB> env.meminfo.add(size) <TAB> else: <TAB> <TAB> p = self._get_path(i, size) <TAB> return p",false,if env . meminfo . rss + size > env . meminfo . mem_limit_soft :,if size == 0 :,0.01,0.0
"def find_widget_by_id(self, id, parent=None): <TAB> """"""Recursively searches for widget with specified ID"""""" <TAB> if parent == None: <TAB> <TAB> if id in self: <TAB> <TAB> <TAB> return self[id]  # Do things fast if possible <TAB> <TAB> parent = self[""editor""] <TAB> for c in parent.get_children(): <TAB> <TAB> if hasattr(c, ""get_id""): <TAB> <TAB> <TAB> if c.get_id() == id: <TAB> <TAB> <TAB> <TAB> return c <TAB> <TAB> if isinstance(c, Gtk.Container): <TAB> <TAB> <TAB> r = self.find_widget_by_id(id, c) <TAB> <TAB> <TAB> if not r is None: <TAB> <TAB> <TAB> <TAB> return r <TAB> return None",false,"if hasattr ( c , ""get_id"" ) :","if isinstance ( c , Gtk . Container ) :",0.08,0.0
"def _deserialize(cls, io): <TAB> flags = VideoFlags() <TAB> flags.byte = U8.read(io) <TAB> if flags.bit.type == VIDEO_FRAME_TYPE_COMMAND_FRAME: <TAB> <TAB> data = VideoCommandFrame.deserialize(io) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> data = AVCVideoData.deserialize(io) <TAB> <TAB> else: <TAB> <TAB> <TAB> data = io.read() <TAB> return cls(flags.bit.type, flags.bit.codec, data)",false,if flags . bit . codec == VIDEO_CODEC_ID_AVC :,if flags . bit . type == VIDEO_FRAME_TYPE_AVC_DATA :,0.5,0.0
"def asciiLogData(data, maxlen=64, replace=False): <TAB> ellipses = "" ..."" <TAB> try: <TAB> <TAB> if len(data) > maxlen - len(ellipses): <TAB> <TAB> <TAB> dd = data[:maxlen] + ellipses <TAB> <TAB> else: <TAB> <TAB> <TAB> dd = data <TAB> <TAB> return dd.decode(""utf8"", errors=""replace"" if replace else ""strict"") <TAB> except: <TAB> <TAB> return ""0x"" + binLogData(data, maxlen)",true,if len ( data ) > maxlen - len ( ellipses ) :,if len ( data ) > maxlen - len ( ellipses ) :,1.0,0.0
"def _check_units(self, new_unit_system): <TAB> # If no unit system has been specified for me yet, adopt the incoming <TAB> # system <TAB> if self.unit_system is None: <TAB> <TAB> self.unit_system = new_unit_system <TAB> else: <TAB> <TAB> # Otherwise, make sure they match <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""Unit system mismatch %d v. %d"" % (self.unit_system, new_unit_system) <TAB> <TAB> <TAB> )",true,if self . unit_system != new_unit_system :,if self . unit_system != new_unit_system :,0.75,0.0
"def command(filenames, dirnames, fix): <TAB> for filename in gather_files(dirnames, filenames): <TAB> <TAB> visitor = process_file(filename) <TAB> <TAB> if visitor.needs_fix(): <TAB> <TAB> <TAB> print(""%s: %s"" % (filename, visitor.get_stats())) <TAB> <TAB> <TAB> if fix: <TAB> <TAB> <TAB> <TAB> print(""Fixing: %s"" % filename) <TAB> <TAB> <TAB> <TAB> fix_file(filename)",true,if visitor . needs_fix ( ) :,if visitor . needs_fix ( ) :,0.75,0.0
"def assign_attributes_to_variants(variant_attributes): <TAB> for value in variant_attributes: <TAB> <TAB> pk = value[""pk""] <TAB> <TAB> defaults = value[""fields""] <TAB> <TAB> defaults[""variant_id""] = defaults.pop(""variant"") <TAB> <TAB> defaults[""assignment_id""] = defaults.pop(""assignment"") <TAB> <TAB> assigned_values = defaults.pop(""values"") <TAB> <TAB> assoc, created = AssignedVariantAttribute.objects.update_or_create( <TAB> <TAB> <TAB> pk=pk, defaults=defaults <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> assoc.values.set(AttributeValue.objects.filter(pk__in=assigned_values))",true,if created :,if created :,0.53,0.0
"def _info(self, userlist): <TAB> for strng in userlist: <TAB> <TAB> group_matched = False <TAB> <TAB> for env in self.base.comps.environments_by_pattern(strng): <TAB> <TAB> <TAB> self.output.display_groups_in_environment(env) <TAB> <TAB> <TAB> group_matched = True <TAB> <TAB> for group in self.base.comps.groups_by_pattern(strng): <TAB> <TAB> <TAB> self.output.display_pkgs_in_groups(group) <TAB> <TAB> <TAB> group_matched = True <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> logger.error(_(""Warning: Group %s does not exist.""), strng) <TAB> return 0, []",false,if not group_matched :,if group_matched :,0.1,0.0
"def parse_implements_interfaces(parser): <TAB> types = [] <TAB> if parser.token.value == ""implements"": <TAB> <TAB> advance(parser) <TAB> <TAB> while True: <TAB> <TAB> <TAB> types.append(parse_named_type(parser)) <TAB> <TAB> <TAB> if not peek(parser, TokenKind.NAME): <TAB> <TAB> <TAB> <TAB> break <TAB> return types",true,"if not peek ( parser , TokenKind . NAME ) :","if not peek ( parser , TokenKind . NAME ) :",0.75,0.0
"def generate(): <TAB> for leaf in u.leaves: <TAB> <TAB> if isinstance(leaf, Integer): <TAB> <TAB> <TAB> val = leaf.get_int_value() <TAB> <TAB> <TAB> if val in (0, 1): <TAB> <TAB> <TAB> <TAB> yield val <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> elif isinstance(leaf, Symbol): <TAB> <TAB> <TAB> if leaf == SymbolTrue: <TAB> <TAB> <TAB> <TAB> yield 1 <TAB> <TAB> <TAB> elif leaf == SymbolFalse: <TAB> <TAB> <TAB> <TAB> yield 0 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> else: <TAB> <TAB> <TAB> raise _NoBoolVector",true,elif leaf == SymbolFalse :,elif leaf == SymbolFalse :,1.0,0.0
"def update_gstin(context): <TAB> dirty = False <TAB> for key, value in iteritems(frappe.form_dict): <TAB> <TAB> if key != ""party"": <TAB> <TAB> <TAB> address_name = frappe.get_value(""Address"", key) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> address = frappe.get_doc(""Address"", address_name) <TAB> <TAB> <TAB> <TAB> address.gstin = value.upper() <TAB> <TAB> <TAB> <TAB> address.save(ignore_permissions=True) <TAB> <TAB> <TAB> <TAB> dirty = True <TAB> if dirty: <TAB> <TAB> frappe.db.commit() <TAB> <TAB> context.updated = True",true,if address_name :,if address_name :,0.53,0.0
"def everythingIsUnicode(d): <TAB> """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB> for k, v in d.iteritems(): <TAB> <TAB> if isinstance(v, dict) and k != ""headers"": <TAB> <TAB> <TAB> if not everythingIsUnicode(v): <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance(v, list): <TAB> <TAB> <TAB> for i in v: <TAB> <TAB> <TAB> <TAB> if isinstance(i, dict) and not everythingIsUnicode(i): <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <TAB> elif isinstance(i, _bytes): <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance(v, _bytes): <TAB> <TAB> <TAB> return False <TAB> return True",true,"if isinstance ( v , dict ) and k != ""headers"" :","if isinstance ( v , dict ) and k != ""headers"" :",0.75,0.0
"def check_graph(graph):  # pragma: no cover <TAB> for c in graph: <TAB> <TAB> if isinstance(c.op, Fuse): <TAB> <TAB> <TAB> raise RuntimeError(""cannot have fuse"") <TAB> <TAB> for inp in c.inputs: <TAB> <TAB> <TAB> if isinstance(inp.op, Fuse): <TAB> <TAB> <TAB> <TAB> raise RuntimeError(""cannot have fuse"")",true,"if isinstance ( c . op , Fuse ) :","if isinstance ( c . op , Fuse ) :",0.75,0.0
"def __getattr__(self, key): <TAB> try: <TAB> <TAB> value = self.__parent.contents[key] <TAB> except KeyError: <TAB> <TAB> pass <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if isinstance(value, _ModuleMarker): <TAB> <TAB> <TAB> <TAB> return value.mod_ns <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> assert isinstance(value, _MultipleClassMarker) <TAB> <TAB> <TAB> <TAB> return value.attempt_get(self.__parent.path, key) <TAB> raise AttributeError( <TAB> <TAB> ""Module %r has no mapped classes "" <TAB> <TAB> ""registered under the name %r"" % (self.__parent.name, key) <TAB> )",false,if value is not None :,if key in self . mapped_classes :,0.17,0.0
"def filter_ports(self, dpid, in_port, nw_id, allow_nw_id_external=None): <TAB> assert nw_id != self.nw_id_unknown <TAB> ret = [] <TAB> for port in self.get_ports(dpid): <TAB> <TAB> nw_id_ = port.network_id <TAB> <TAB> if port.port_no == in_port: <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ret.append(port.port_no) <TAB> <TAB> elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external: <TAB> <TAB> <TAB> ret.append(port.port_no) <TAB> return ret",true,if nw_id_ == nw_id :,if nw_id_ == nw_id :,0.75,0.0
"def _parse(self, contents): <TAB> entries = [] <TAB> for line in contents.splitlines(): <TAB> <TAB> if not len(line.strip()): <TAB> <TAB> <TAB> entries.append((""blank"", [line])) <TAB> <TAB> <TAB> continue <TAB> <TAB> (head, tail) = chop_comment(line.strip(), ""#"") <TAB> <TAB> if not len(head): <TAB> <TAB> <TAB> entries.append((""all_comment"", [line])) <TAB> <TAB> <TAB> continue <TAB> <TAB> entries.append((""option"", [head.split(None), tail])) <TAB> return entries",false,if not len ( head ) :,if not len ( line . strip ( ) ) :,0.19,0.0
"def _get_documented_completions(self, table, startswith=None): <TAB> names = [] <TAB> for key, command in table.items(): <TAB> <TAB> if getattr(command, ""_UNDOCUMENTED"", False): <TAB> <TAB> <TAB> # Don't tab complete undocumented commands/params <TAB> <TAB> <TAB> continue <TAB> <TAB> if startswith is not None and not key.startswith(startswith): <TAB> <TAB> <TAB> continue <TAB> <TAB> if getattr(command, ""positional_arg"", False): <TAB> <TAB> <TAB> continue <TAB> <TAB> names.append(key) <TAB> return names",true,if startswith is not None and not key . startswith ( startswith ) :,if startswith is not None and not key . startswith ( startswith ) :,1.0,0.0
"def _convert_example(example, use_bfloat16): <TAB> """"""Cast int64 into int32 and float32 to bfloat16 if use_bfloat16."""""" <TAB> for key in list(example.keys()): <TAB> <TAB> val = example[key] <TAB> <TAB> if tf.keras.backend.is_sparse(val): <TAB> <TAB> <TAB> val = tf.sparse.to_dense(val) <TAB> <TAB> if val.dtype == tf.int64: <TAB> <TAB> <TAB> val = tf.cast(val, tf.int32) <TAB> <TAB> if use_bfloat16 and val.dtype == tf.float32: <TAB> <TAB> <TAB> val = tf.cast(val, tf.bfloat16) <TAB> <TAB> example[key] = val",true,if tf . keras . backend . is_sparse ( val ) :,if tf . keras . backend . is_sparse ( val ) :,0.75,0.0
"def _get_lang_zone(self, lang): <TAB> if lang not in self._lang_zone_from_lang: <TAB> <TAB> if self.mgr.is_multilang(lang): <TAB> <TAB> <TAB> self._lang_zone_from_lang[lang] = MultiLangZone(self.mgr, lang) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._lang_zone_from_lang[lang] = LangZone(self.mgr, lang) <TAB> return self._lang_zone_from_lang[lang]",true,if self . mgr . is_multilang ( lang ) :,if self . mgr . is_multilang ( lang ) :,0.75,0.0
"def dispatch(self, request, *args, **kwargs): <TAB> try: <TAB> <TAB> return super(Handler, self).dispatch(request, *args, **kwargs) <TAB> except Http404 as e: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> request.original_path_info = request.path_info <TAB> <TAB> <TAB> <TAB> request.path_info = settings.FEINCMS_CMS_404_PAGE <TAB> <TAB> <TAB> <TAB> response = super(Handler, self).dispatch(request, *args, **kwargs) <TAB> <TAB> <TAB> <TAB> response.status_code = 404 <TAB> <TAB> <TAB> <TAB> return response <TAB> <TAB> <TAB> except Http404: <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> else: <TAB> <TAB> <TAB> raise",true,if settings . FEINCMS_CMS_404_PAGE :,if settings . FEINCMS_CMS_404_PAGE :,0.75,0.0
"def _maybe_update_dropout(self, step): <TAB> for i in range(len(self.dropout_steps)): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.model.update_dropout(self.dropout[i]) <TAB> <TAB> <TAB> logger.info(""Updated dropout to %f from step %d"" % (self.dropout[i], step))",false,if step > 1 and step == self . dropout_steps [ i ] + 1 :,if self . dropout [ i ] != step :,0.09,0.0
"def bulk_move(*args, **kwargs): <TAB> for arg in args: <TAB> <TAB> if arg[""src_path""] == arg[""dest_path""]: <TAB> <TAB> <TAB> raise PopupException(_(""Source path and destination path cannot be same"")) <TAB> <TAB> request.fs.rename( <TAB> <TAB> <TAB> urllib.unquote(arg[""src_path""]), urllib.unquote(arg[""dest_path""]) <TAB> <TAB> )",true,"if arg [ ""src_path"" ] == arg [ ""dest_path"" ] :","if arg [ ""src_path"" ] == arg [ ""dest_path"" ] :",1.0,0.0
"def asisWrite(self, root): <TAB> at, c = self, self.c <TAB> try: <TAB> <TAB> c.endEditing() <TAB> <TAB> c.init_error_dialogs() <TAB> <TAB> fileName = at.initWriteIvars(root, root.atAsisFileNodeName()) <TAB> <TAB> if not at.precheck(fileName, root): <TAB> <TAB> <TAB> at.addToOrphanList(root) <TAB> <TAB> <TAB> return <TAB> <TAB> at.openOutputStream() <TAB> <TAB> for p in root.self_and_subtree(copy=False): <TAB> <TAB> <TAB> at.writeAsisNode(p) <TAB> <TAB> contents = at.closeOutputStream() <TAB> <TAB> at.replaceFile(contents, at.encoding, fileName, root) <TAB> except Exception: <TAB> <TAB> at.writeException(fileName, root)",true,"if not at . precheck ( fileName , root ) :","if not at . precheck ( fileName , root ) :",0.75,0.0
"def next_event(it): <TAB> """"""read an event from an eventstream"""""" <TAB> while True: <TAB> <TAB> try: <TAB> <TAB> <TAB> line = next(it) <TAB> <TAB> except StopIteration: <TAB> <TAB> <TAB> return <TAB> <TAB> if line.startswith(""data:""): <TAB> <TAB> <TAB> return json.loads(line.split("":"", 1)[1])",true,"if line . startswith ( ""data:"" ) :","if line . startswith ( ""data:"" ) :",0.75,0.0
"def process_formdata(self, valuelist): <TAB> if valuelist: <TAB> <TAB> if valuelist[0] == ""__None"": <TAB> <TAB> <TAB> self.data = None <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.data = None <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> obj = self.queryset.get(pk=valuelist[0]) <TAB> <TAB> <TAB> <TAB> self.data = obj <TAB> <TAB> <TAB> except DoesNotExist: <TAB> <TAB> <TAB> <TAB> self.data = None",false,if self . queryset is None :,if len ( valuelist ) == 0 :,0.02,0.0
"def _setResultsName(self, name, listAllMatches=False): <TAB> if __diag__.warn_multiple_tokens_in_named_alternation: <TAB> <TAB> if any(isinstance(e, And) for e in self.exprs): <TAB> <TAB> <TAB> warnings.warn( <TAB> <TAB> <TAB> <TAB> ""{}: setting results name {!r} on {} expression "" <TAB> <TAB> <TAB> <TAB> ""will return a list of all parsed tokens in an And alternative, "" <TAB> <TAB> <TAB> <TAB> ""in prior versions only the first token was returned"".format( <TAB> <TAB> <TAB> <TAB> <TAB> ""warn_multiple_tokens_in_named_alternation"", <TAB> <TAB> <TAB> <TAB> <TAB> name, <TAB> <TAB> <TAB> <TAB> <TAB> type(self).__name__, <TAB> <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> <TAB> stacklevel=3, <TAB> <TAB> <TAB> ) <TAB> return super()._setResultsName(name, listAllMatches)",true,"if any ( isinstance ( e , And ) for e in self . exprs ) :","if any ( isinstance ( e , And ) for e in self . exprs ) :",1.0,0.0
"def add(request): <TAB> form_type = ""servers"" <TAB> if request.method == ""POST"": <TAB> <TAB> form = BookMarkForm(request.POST) <TAB> <TAB> if form.is_valid(): <TAB> <TAB> <TAB> form_type = form.save() <TAB> <TAB> <TAB> messages.add_message(request, messages.INFO, ""Bookmark created"") <TAB> <TAB> else: <TAB> <TAB> <TAB> messages.add_message(request, messages.INFO, form.errors) <TAB> <TAB> if form_type == ""server"": <TAB> <TAB> <TAB> url = reverse(""servers"") <TAB> <TAB> else: <TAB> <TAB> <TAB> url = reverse(""metrics"") <TAB> <TAB> return redirect(url) <TAB> else: <TAB> <TAB> return redirect(reverse(""servers""))",false,"if form_type == ""server"" :",if form . is_valid ( ) :,0.03,0.0
"def __init__(self, post_id, artist, page, tzInfo=None, dateFormat=None): <TAB> self.imageUrls = list() <TAB> self.imageResizedUrls = list() <TAB> self.imageId = int(post_id) <TAB> self._tzInfo = tzInfo <TAB> self.dateFormat = dateFormat <TAB> if page is not None: <TAB> <TAB> post_json = demjson.decode(page) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> artist_id = post_json[""data""][""item""][""user""][""id""] <TAB> <TAB> <TAB> self.artist = SketchArtist(artist_id, page, tzInfo, dateFormat) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.artist = artist <TAB> <TAB> self.parse_post(post_json[""data""][""item""])",false,if artist is None :,"if ""user"" in post_json :",0.03,0.0
"def _create_batch_iterator( <TAB> self, <TAB> mark_as_delete: Callable[[Any], None], <TAB> to_key: Callable[[Any], Any], <TAB> to_value: Callable[[Any], Any], <TAB> batch: Iterable[EventT], ) -> Iterable[Tuple[Any, Any]]: <TAB> for event in batch: <TAB> <TAB> key = to_key(event.key) <TAB> <TAB> # to delete keys in the table we set the raw value to None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> mark_as_delete(key) <TAB> <TAB> <TAB> continue <TAB> <TAB> yield key, to_value(event.value)",false,if event . message . value is None :,if mark_as_delete :,0.01,0.0
"def test_lc_numeric_nl_langinfo(self): <TAB> # Test nl_langinfo against known values <TAB> tested = False <TAB> for loc in candidate_locales: <TAB> <TAB> try: <TAB> <TAB> <TAB> setlocale(LC_NUMERIC, loc) <TAB> <TAB> <TAB> setlocale(LC_CTYPE, loc) <TAB> <TAB> except Error: <TAB> <TAB> <TAB> continue <TAB> <TAB> for li, lc in ((RADIXCHAR, ""decimal_point""), (THOUSEP, ""thousands_sep"")): <TAB> <TAB> <TAB> if self.numeric_tester(""nl_langinfo"", nl_langinfo(li), lc, loc): <TAB> <TAB> <TAB> <TAB> tested = True <TAB> if not tested: <TAB> <TAB> self.skipTest(""no suitable locales"")",true,"if self . numeric_tester ( ""nl_langinfo"" , nl_langinfo ( li ) , lc , loc ) :","if self . numeric_tester ( ""nl_langinfo"" , nl_langinfo ( li ) , lc , loc ) :",0.75,0.0
"def _level_up_logging(self): <TAB> for handler in self.log.handlers: <TAB> <TAB> if issubclass(handler.__class__, logging.FileHandler): <TAB> <TAB> <TAB> if handler.level != logging.DEBUG: <TAB> <TAB> <TAB> <TAB> handler.setLevel(logging.DEBUG) <TAB> <TAB> <TAB> <TAB> self.log.debug(""Leveled up log file verbosity"")",true,"if issubclass ( handler . __class__ , logging . FileHandler ) :","if issubclass ( handler . __class__ , logging . FileHandler ) :",0.75,0.0
def _show_axes_changed(self): <TAB> marker = self.marker <TAB> if (self._vtk_control is not None) and (marker is not None): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> marker.interactor = None <TAB> <TAB> <TAB> marker.enabled = False <TAB> <TAB> else: <TAB> <TAB> <TAB> marker.interactor = self.interactor <TAB> <TAB> <TAB> marker.enabled = True <TAB> <TAB> self.render(),false,if not self . show_axes :,if marker . axes is not None :,0.02,0.0
"def handle_keypress(self, rawKey, modifiers, key, *args): <TAB> if self.recordKeyboard and self.__delayPassed(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.insideKeys = True <TAB> <TAB> <TAB> self.targetParent.start_key_sequence() <TAB> <TAB> modifierCount = len(modifiers) <TAB> <TAB> if ( <TAB> <TAB> <TAB> modifierCount > 1 <TAB> <TAB> <TAB> or (modifierCount == 1 and Key.SHIFT not in modifiers) <TAB> <TAB> <TAB> or (Key.SHIFT in modifiers and len(rawKey) > 1) <TAB> <TAB> ): <TAB> <TAB> <TAB> self.targetParent.append_hotkey(rawKey, modifiers) <TAB> <TAB> elif key not in MODIFIERS: <TAB> <TAB> <TAB> self.targetParent.append_key(key)",false,if not self . insideKeys :,if key in MODIFIERS :,0.03,0.0
"def transform(self, data): <TAB> with timer(""transform %s"" % self.name, logging.DEBUG): <TAB> <TAB> if self.operator in {""lat"", ""latitude""}: <TAB> <TAB> <TAB> return self.series(data).apply(GeoIP.get_latitude) <TAB> <TAB> elif self.operator in {""lon"", ""longitude""}: <TAB> <TAB> <TAB> return self.series(data).apply(GeoIP.get_longitude) <TAB> <TAB> elif self.operator in {""acc"", ""accuracy""}: <TAB> <TAB> <TAB> return self.series(data).apply(GeoIP.get_accuracy) <TAB> <TAB> raise NameError(""Unknown GeoIP operator [lat, lon, acc]: %s"" % self.operator)",true,"elif self . operator in { ""lon"" , ""longitude"" } :","elif self . operator in { ""lon"" , ""longitude"" } :",0.75,0.0
"def _get_sidebar_selected(self): <TAB> sidebar_selected = None <TAB> if self.businessline_id: <TAB> <TAB> sidebar_selected = ""bl_%s"" % self.businessline_id <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> sidebar_selected += ""_s_%s"" % self.service_id <TAB> <TAB> <TAB> if self.environment_id: <TAB> <TAB> <TAB> <TAB> sidebar_selected += ""_env_%s"" % self.environment_id <TAB> return sidebar_selected",true,if self . service_id :,if self . service_id :,0.75,0.0
"def _run_response_middleware(self, request, response, request_name=None): <TAB> named_middleware = self.named_response_middleware.get(request_name, deque()) <TAB> applicable_middleware = self.response_middleware + named_middleware <TAB> if applicable_middleware: <TAB> <TAB> for middleware in applicable_middleware: <TAB> <TAB> <TAB> _response = middleware(request, response) <TAB> <TAB> <TAB> if isawaitable(_response): <TAB> <TAB> <TAB> <TAB> _response = await _response <TAB> <TAB> <TAB> if _response: <TAB> <TAB> <TAB> <TAB> response = _response <TAB> <TAB> <TAB> <TAB> break <TAB> return response",true,if isawaitable ( _response ) :,if isawaitable ( _response ) :,0.75,0.0
"def populate_obj(self, obj, name): <TAB> field = getattr(obj, name, None) <TAB> if field is not None: <TAB> <TAB> # If field should be deleted, clean it up <TAB> <TAB> if self._should_delete: <TAB> <TAB> <TAB> field.delete() <TAB> <TAB> <TAB> return <TAB> <TAB> if isinstance(self.data, FileStorage) and not is_empty(self.data.stream): <TAB> <TAB> <TAB> if not field.grid_id: <TAB> <TAB> <TAB> <TAB> func = field.put <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> func = field.replace <TAB> <TAB> <TAB> func( <TAB> <TAB> <TAB> <TAB> self.data.stream, <TAB> <TAB> <TAB> <TAB> filename=self.data.filename, <TAB> <TAB> <TAB> <TAB> content_type=self.data.content_type, <TAB> <TAB> <TAB> )",false,"if isinstance ( self . data , FileStorage ) and not is_empty ( self . data . stream ) :",if self . _should_delete :,0.01,0.0
"def _import_hash(self, operator): <TAB> # Import required modules into local namespace so that pipelines <TAB> # may be evaluated directly <TAB> for key in sorted(operator.import_hash.keys()): <TAB> <TAB> module_list = "", "".join(sorted(operator.import_hash[key])) <TAB> <TAB> if key.startswith(""tpot.""): <TAB> <TAB> <TAB> exec(""from {} import {}"".format(key[4:], module_list)) <TAB> <TAB> else: <TAB> <TAB> <TAB> exec(""from {} import {}"".format(key, module_list)) <TAB> <TAB> for var in operator.import_hash[key]: <TAB> <TAB> <TAB> self.operators_context[var] = eval(var)",true,"if key . startswith ( ""tpot."" ) :","if key . startswith ( ""tpot."" ) :",0.75,0.0
"def remove_files(folder, file_extensions): <TAB> for f in os.listdir(folder): <TAB> <TAB> f_path = os.path.join(folder, f) <TAB> <TAB> if os.path.isfile(f_path): <TAB> <TAB> <TAB> extension = os.path.splitext(f_path)[1] <TAB> <TAB> <TAB> if extension in file_extensions: <TAB> <TAB> <TAB> <TAB> os.remove(f_path)",true,if os . path . isfile ( f_path ) :,if os . path . isfile ( f_path ) :,0.75,0.0
"def clearBuffer(self): <TAB> if self.shouldLose == -1: <TAB> <TAB> return <TAB> if self.producer: <TAB> <TAB> self.producer.resumeProducing() <TAB> if self.buffer: <TAB> <TAB> if self.logFile: <TAB> <TAB> <TAB> self.logFile.write(""loopback receiving %s\n"" % repr(self.buffer)) <TAB> <TAB> buffer = self.buffer <TAB> <TAB> self.buffer = b"""" <TAB> <TAB> self.target.dataReceived(buffer) <TAB> if self.shouldLose == 1: <TAB> <TAB> self.shouldLose = -1 <TAB> <TAB> self.target.connectionLost(failure.Failure(main.CONNECTION_DONE))",true,if self . logFile :,if self . logFile :,0.75,0.0
"def write(self, data): <TAB> if mock_target._mirror_on_stderr: <TAB> <TAB> if self._write_line: <TAB> <TAB> <TAB> sys.stderr.write(fn + "": "") <TAB> <TAB> if bytes: <TAB> <TAB> <TAB> sys.stderr.write(data.decode(""utf8"")) <TAB> <TAB> else: <TAB> <TAB> <TAB> sys.stderr.write(data) <TAB> <TAB> if (data[-1]) == ""\n"": <TAB> <TAB> <TAB> self._write_line = True <TAB> <TAB> else: <TAB> <TAB> <TAB> self._write_line = False <TAB> super(Buffer, self).write(data)",true,"if ( data [ - 1 ] ) == ""\n"" :","if ( data [ - 1 ] ) == ""\n"" :",0.75,0.0
def stop(self): <TAB> self.queue_com.state_lock.acquire() <TAB> try: <TAB> <TAB> if self.queue_com.state == RUNNING and self.stop_task(): <TAB> <TAB> <TAB> self.queue_com.state = STOPPED <TAB> <TAB> <TAB> self.remove() <TAB> <TAB> <TAB> return True <TAB> <TAB> return False <TAB> finally: <TAB> <TAB> self.queue_com.state_lock.release(),true,if self . queue_com . state == RUNNING and self . stop_task ( ) :,if self . queue_com . state == RUNNING and self . stop_task ( ) :,1.0,0.0
"def _handle_special_args(self, pyobjects): <TAB> if len(pyobjects) == len(self.arguments.args): <TAB> <TAB> if self.arguments.vararg: <TAB> <TAB> <TAB> pyobjects.append(rope.base.builtins.get_list()) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> pyobjects.append(rope.base.builtins.get_dict())",false,if self . arguments . kwarg :,if self . arguments . varname :,0.57,0.0
"def go_to_last_edit_location(self): <TAB> if self.last_edit_cursor_pos is not None: <TAB> <TAB> filename, position = self.last_edit_cursor_pos <TAB> <TAB> if not osp.isfile(filename): <TAB> <TAB> <TAB> self.last_edit_cursor_pos = None <TAB> <TAB> <TAB> return <TAB> <TAB> else: <TAB> <TAB> <TAB> self.load(filename) <TAB> <TAB> <TAB> editor = self.get_current_editor() <TAB> <TAB> <TAB> if position < editor.document().characterCount(): <TAB> <TAB> <TAB> <TAB> editor.set_cursor_position(position)",true,if position < editor . document ( ) . characterCount ( ) :,if position < editor . document ( ) . characterCount ( ) :,0.75,0.0
"def _create_sentence_objects(self): <TAB> """"""Returns a list of Sentence objects from the raw text."""""" <TAB> sentence_objects = [] <TAB> sent_tokenizer = SentenceTokenizer(locale=self.language.code) <TAB> seq = Sequence(self.raw) <TAB> seq = sent_tokenizer.transform(seq) <TAB> for start_index, end_index in zip(seq.idx[:-1], seq.idx[1:]): <TAB> <TAB> # Sentences share the same models as their parent blob <TAB> <TAB> sent = seq.text[start_index:end_index].strip() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> s = Sentence(sent, start_index=start_index, end_index=end_index) <TAB> <TAB> s.detected_languages = self.detected_languages <TAB> <TAB> sentence_objects.append(s) <TAB> return sentence_objects",false,if not sent :,"if sent == """" :",0.05,0.0
"def to_json_schema(self, parent=None): <TAB> schema = {} <TAB> if not parent: <TAB> <TAB> schema[""title""] = self.title <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> schema[""description""] = self.description <TAB> <TAB> if self.has_default: <TAB> <TAB> <TAB> schema[""default""] = self.default <TAB> <TAB> schema[""_required_""] = self.required <TAB> if self.null: <TAB> <TAB> schema[""type""] = [""string"", ""null""] <TAB> else: <TAB> <TAB> schema[""type""] = ""string"" <TAB> if self.enum is not None: <TAB> <TAB> schema[""enum""] = self.enum <TAB> return schema",false,if self . description :,if self . description is not None :,0.35,0.0
"def rmdir(dirname): <TAB> if dirname[-1] == os.sep: <TAB> <TAB> dirname = dirname[:-1] <TAB> if os.path.islink(dirname): <TAB> <TAB> return  # do not clear link - we can get out of dir <TAB> for f in os.listdir(dirname): <TAB> <TAB> if f in (""."", ""..""): <TAB> <TAB> <TAB> continue <TAB> <TAB> path = dirname + os.sep + f <TAB> <TAB> if os.path.isdir(path): <TAB> <TAB> <TAB> rmdir(path) <TAB> <TAB> else: <TAB> <TAB> <TAB> os.unlink(path) <TAB> os.rmdir(dirname)",false,"if f in ( ""."" , "".."" ) :",if os . path . isdir ( path ) :,0.03,0.0
"def convert_whole_dir(path=Path(""marian_ckpt/"")): <TAB> for subdir in tqdm(list(path.ls())): <TAB> <TAB> dest_dir = f""marian_converted/{subdir.name}"" <TAB> <TAB> if (dest_dir / ""pytorch_model.bin"").exists(): <TAB> <TAB> <TAB> continue <TAB> <TAB> convert(source_dir, dest_dir)",true,"if ( dest_dir / ""pytorch_model.bin"" ) . exists ( ) :","if ( dest_dir / ""pytorch_model.bin"" ) . exists ( ) :",0.75,0.0
"def colorformat(text): <TAB> if text[0:1] == ""#"": <TAB> <TAB> col = text[1:] <TAB> <TAB> if len(col) == 6: <TAB> <TAB> <TAB> return col <TAB> <TAB> elif len(col) == 3: <TAB> <TAB> <TAB> return col[0] * 2 + col[1] * 2 + col[2] * 2 <TAB> elif text == """": <TAB> <TAB> return """" <TAB> assert False, ""wrong color format %r"" % text",true,elif len ( col ) == 3 :,elif len ( col ) == 3 :,0.75,0.0
"def _init_rel_seek(self): <TAB> ""Sets the file object's position to the relative location set above."" <TAB> rs, fo = self._rel_seek, self._file_obj <TAB> if rs == 0.0: <TAB> <TAB> fo.seek(0, os.SEEK_SET) <TAB> else: <TAB> <TAB> fo.seek(0, os.SEEK_END) <TAB> <TAB> size = fo.tell() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._cur_pos = size <TAB> <TAB> else: <TAB> <TAB> <TAB> target = int(size * rs) <TAB> <TAB> <TAB> fo.seek(target, os.SEEK_SET) <TAB> <TAB> <TAB> self._align_to_newline() <TAB> <TAB> <TAB> self._cur_pos = fo.tell()",false,if rs == 1.0 :,if rs == 0 :,0.14,0.0
"def parse_command_line(self, argv=None): <TAB> """"""Parse the command line"""""" <TAB> if self.config: <TAB> <TAB> parser = argparse.ArgumentParser(add_help=False) <TAB> <TAB> self.settings[""config""].add_argument(parser) <TAB> <TAB> opts, _ = parser.parse_known_args(argv) <TAB> <TAB> if opts.config is not None: <TAB> <TAB> <TAB> self.set(""config"", opts.config) <TAB> <TAB> self.params.update(self.import_from_module()) <TAB> parser = self.parser() <TAB> opts = parser.parse_args(argv) <TAB> for k, v in opts.__dict__.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> self.set(k.lower(), v)",false,if v is None :,if k in self . params :,0.03,0.0
"def process(self, resources, event=None): <TAB> client = local_session(self.manager.session_factory).client( <TAB> <TAB> ""shield"", region_name=""us-east-1"" <TAB> ) <TAB> protections = get_type_protections(client, self.manager.get_model()) <TAB> protected_resources = {p[""ResourceArn""] for p in protections} <TAB> state = self.data.get(""state"", False) <TAB> results = [] <TAB> for arn, r in zip(self.manager.get_arns(resources), resources): <TAB> <TAB> r[""c7n:ShieldProtected""] = shielded = arn in protected_resources <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> results.append(r) <TAB> <TAB> elif not shielded and not state: <TAB> <TAB> <TAB> results.append(r) <TAB> return results",true,if shielded and state :,if shielded and state :,0.75,0.0
"def removeTrailingWs(self, aList): <TAB> i = 0 <TAB> while i < len(aList): <TAB> <TAB> if self.is_ws(aList[i]): <TAB> <TAB> <TAB> j = i <TAB> <TAB> <TAB> i = self.skip_ws(aList, i) <TAB> <TAB> <TAB> assert j < i <TAB> <TAB> <TAB> if i >= len(aList) or aList[i] == ""\n"": <TAB> <TAB> <TAB> <TAB> # print ""removing trailing ws:"", `i-j` <TAB> <TAB> <TAB> <TAB> del aList[j:i] <TAB> <TAB> <TAB> <TAB> i = j <TAB> <TAB> else: <TAB> <TAB> <TAB> i += 1",true,if self . is_ws ( aList [ i ] ) :,if self . is_ws ( aList [ i ] ) :,0.75,0.0
"def predict(request: Request): <TAB> form = await request.form() <TAB> files, entry = convert_input(form) <TAB> try: <TAB> <TAB> if (entry.keys() & input_features) != input_features: <TAB> <TAB> <TAB> return JSONResponse(ALL_FEATURES_PRESENT_ERROR, status_code=400) <TAB> <TAB> try: <TAB> <TAB> <TAB> resp = model.predict(data_dict=[entry]).to_dict(""records"")[0] <TAB> <TAB> <TAB> return JSONResponse(resp) <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> logger.error(""Error: {}"".format(str(e))) <TAB> <TAB> <TAB> return JSONResponse(COULD_NOT_RUN_INFERENCE_ERROR, status_code=500) <TAB> finally: <TAB> <TAB> for f in files: <TAB> <TAB> <TAB> os.remove(f.name)",true,if ( entry . keys ( ) & input_features ) != input_features :,if ( entry . keys ( ) & input_features ) != input_features :,1.0,0.0
"def reset(self): <TAB> logger.debug(""Arctic.reset()"") <TAB> with self._lock: <TAB> <TAB> if self.__conn is not None: <TAB> <TAB> <TAB> self.__conn.close() <TAB> <TAB> <TAB> self.__conn = None <TAB> <TAB> for _, l in self._library_cache.items(): <TAB> <TAB> <TAB> if hasattr(l, ""_reset"") and callable(l._reset): <TAB> <TAB> <TAB> <TAB> logger.debug(""Library reset() %s"" % l) <TAB> <TAB> <TAB> <TAB> l._reset()  # the existence of _reset() is not guaranteed/enforced, it also triggers re-auth",false,if self . __conn is not None :,"if hasattr ( l , ""_reset"" ) and callable ( l . _reset ) :",0.06,0.0
"def read(self): <TAB> if op.isfile(self.fileName): <TAB> <TAB> with textfile_open(self.fileName, ""rt"") as fid: <TAB> <TAB> <TAB> items = json.load(fid) <TAB> <TAB> <TAB> # TODO: catch JSON exception... <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> items = dict() <TAB> else: <TAB> <TAB> items = dict() <TAB> self._items.clear() <TAB> self._items.update(items) <TAB> self._haveReadData = True",true,if items is None :,if items is None :,0.75,0.0
"def get_django_comment(text: str, i: int) -> str: <TAB> end = i + 4 <TAB> unclosed_end = 0 <TAB> while end <= len(text): <TAB> <TAB> if text[end - 2 : end] == ""#}"": <TAB> <TAB> <TAB> return text[i:end] <TAB> <TAB> if not unclosed_end and text[end] == ""<"": <TAB> <TAB> <TAB> unclosed_end = end <TAB> <TAB> end += 1 <TAB> raise TokenizationException(""Unclosed comment"", text[i:unclosed_end])",true,"if not unclosed_end and text [ end ] == ""<"" :","if not unclosed_end and text [ end ] == ""<"" :",1.0,0.0
"def _wrap_forwarded(self, key, value): <TAB> if isinstance(value, SourceCode) and value.late_binding: <TAB> <TAB> # get cached return value if present <TAB> <TAB> value_ = self._late_binding_returnvalues.get(key, KeyError) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # evaluate the late-bound function <TAB> <TAB> <TAB> value_ = self._eval_late_binding(value) <TAB> <TAB> <TAB> schema = self.late_bind_schemas.get(key) <TAB> <TAB> <TAB> if schema is not None: <TAB> <TAB> <TAB> <TAB> value_ = schema.validate(value_) <TAB> <TAB> <TAB> # cache result of late bound func <TAB> <TAB> <TAB> self._late_binding_returnvalues[key] = value_ <TAB> <TAB> return value_ <TAB> else: <TAB> <TAB> return value",false,if value_ is KeyError :,if value_ is None :,0.39,0.0
"def connect(*args, **ckwargs): <TAB> if ""give_content_type"" in kwargs: <TAB> <TAB> if len(args) >= 7 and ""content_type"" in args[6]: <TAB> <TAB> <TAB> kwargs[""give_content_type""](args[6][""content-type""]) <TAB> <TAB> else: <TAB> <TAB> <TAB> kwargs[""give_content_type""]("""") <TAB> if ""give_connect"" in kwargs: <TAB> <TAB> kwargs[""give_connect""](*args, **ckwargs) <TAB> status = code_iter.next() <TAB> etag = etag_iter.next() <TAB> timestamp = timestamps_iter.next() <TAB> if status == -1: <TAB> <TAB> raise HTTPException() <TAB> return FakeConn(status, etag, body=kwargs.get(""body"", """"), timestamp=timestamp)",true,"if len ( args ) >= 7 and ""content_type"" in args [ 6 ] :","if len ( args ) >= 7 and ""content_type"" in args [ 6 ] :",1.0,0.0
"def _reset(self): <TAB> self._handle_connect() <TAB> if self.rewarder_session: <TAB> <TAB> if self._sample_env_ids: <TAB> <TAB> <TAB> env_id = random.choice(self._sample_env_ids) <TAB> <TAB> <TAB> logger.info(""Randomly sampled env_id={}"".format(env_id)) <TAB> <TAB> else: <TAB> <TAB> <TAB> env_id = None <TAB> <TAB> self.rewarder_session.reset(env_id=env_id) <TAB> else: <TAB> <TAB> logger.info( <TAB> <TAB> <TAB> ""No rewarder session exists, so cannot send a reset via the rewarder channel"" <TAB> <TAB> ) <TAB> self._reset_mask() <TAB> return [None] * self.n",true,if self . _sample_env_ids :,if self . _sample_env_ids :,0.75,0.0
"def _create_architecture_list(architectures, current_arch): <TAB> if not architectures: <TAB> <TAB> return [_Architecture(build_on=[current_arch])] <TAB> build_architectures: List[str] = [] <TAB> architecture_list: List[_Architecture] = [] <TAB> for item in architectures: <TAB> <TAB> if isinstance(item, str): <TAB> <TAB> <TAB> build_architectures.append(item) <TAB> <TAB> if isinstance(item, dict): <TAB> <TAB> <TAB> architecture_list.append( <TAB> <TAB> <TAB> <TAB> _Architecture(build_on=item.get(""build-on""), run_on=item.get(""run-on"")) <TAB> <TAB> <TAB> ) <TAB> if build_architectures: <TAB> <TAB> architecture_list.append(_Architecture(build_on=build_architectures)) <TAB> return architecture_list",true,"if isinstance ( item , dict ) :","if isinstance ( item , dict ) :",0.75,0.0
"def inspect(self, pokemon): <TAB> # Make sure it was not caught! <TAB> for caught_pokemon in self.cache: <TAB> <TAB> same_latitude = ""{0:.4f}"".format(pokemon[""latitude""]) == ""{0:.4f}"".format( <TAB> <TAB> <TAB> caught_pokemon[""latitude""] <TAB> <TAB> ) <TAB> <TAB> same_longitude = ""{0:.4f}"".format(pokemon[""longitude""]) == ""{0:.4f}"".format( <TAB> <TAB> <TAB> caught_pokemon[""longitude""] <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> if len(self.cache) >= 200: <TAB> <TAB> self.cache.pop(0) <TAB> self.cache.append(pokemon)",true,if same_latitude and same_longitude :,if same_latitude and same_longitude :,0.75,0.0
"def parley(self): <TAB> for x in [0, 1]: <TAB> <TAB> a = self.agents[x].act() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if ""[DONE]"" in a[""text""]: <TAB> <TAB> <TAB> <TAB> self.agents[x - 1].observe( <TAB> <TAB> <TAB> <TAB> <TAB> {""id"": ""World"", ""text"": ""The other agent has ended the chat.""} <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> self.episodeDone = True <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.agents[x - 1].observe(a)",false,if a is not None :,if a :,0.05,0.0
"def _prepare_subset( <TAB> full_data: torch.Tensor, <TAB> full_targets: torch.Tensor, <TAB> num_samples: int, <TAB> digits: Sequence, ): <TAB> classes = {d: 0 for d in digits} <TAB> indexes = [] <TAB> for idx, target in enumerate(full_targets): <TAB> <TAB> label = target.item() <TAB> <TAB> if classes.get(label, float(""inf"")) >= num_samples: <TAB> <TAB> <TAB> continue <TAB> <TAB> indexes.append(idx) <TAB> <TAB> classes[label] += 1 <TAB> <TAB> if all(classes[k] >= num_samples for k in classes): <TAB> <TAB> <TAB> break <TAB> data = full_data[indexes] <TAB> targets = full_targets[indexes] <TAB> return data, targets",true,if all ( classes [ k ] >= num_samples for k in classes ) :,if all ( classes [ k ] >= num_samples for k in classes ) :,1.0,0.0
"def get_work_root(self, flags): <TAB> _flags = flags.copy() <TAB> _flags[""is_toplevel""] = True <TAB> target = self._get_target(_flags) <TAB> if target: <TAB> <TAB> _flags[""target""] = target.name <TAB> <TAB> tool = self.get_tool(_flags) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return target.name + ""-"" + tool <TAB> <TAB> else: <TAB> <TAB> <TAB> raise SyntaxError( <TAB> <TAB> <TAB> <TAB> ""Failed to determine work root. Could not resolve tool for target "" <TAB> <TAB> <TAB> <TAB> + target.name <TAB> <TAB> <TAB> ) <TAB> else: <TAB> <TAB> raise SyntaxError(""Failed to determine work root. Could not resolve target"")",true,if tool :,if tool :,0.53,0.0
"def run_command(self, data): <TAB> """"""Run editor commands."""""" <TAB> parts = data.split("" "") <TAB> cmd = parts[0].lower() <TAB> if cmd in self.operations.keys(): <TAB> <TAB> return self.run_operation(cmd) <TAB> args = "" "".join(parts[1:]) <TAB> self.logger.debug(""Looking for command '{0}'"".format(cmd)) <TAB> if cmd in self.modules.modules.keys(): <TAB> <TAB> self.logger.debug(""Trying to run command '{0}'"".format(cmd)) <TAB> <TAB> self.get_editor().store_action_state(cmd) <TAB> <TAB> if not self.run_module(cmd, args): <TAB> <TAB> <TAB> return False <TAB> else: <TAB> <TAB> self.set_status(""Command '{0}' not found."".format(cmd)) <TAB> <TAB> return False <TAB> return True",true,"if not self . run_module ( cmd , args ) :","if not self . run_module ( cmd , args ) :",0.75,0.0
"def get_main_chain_layers(self): <TAB> """"""Return a list of layer IDs in the main chain."""""" <TAB> main_chain = self.get_main_chain() <TAB> ret = [] <TAB> for u in main_chain: <TAB> <TAB> for v, layer_id in self.adj_list[u]: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> ret.append(layer_id) <TAB> return ret",false,if v in main_chain and u in main_chain :,if v == u :,0.03,0.0
"def hash(self, context): <TAB> with context: <TAB> <TAB> if not self[""fileName""].getValue() or self[""in""].source() == self[""in""]: <TAB> <TAB> <TAB> return IECore.MurmurHash() <TAB> <TAB> h = GafferDispatch.TaskNode.hash(self, context) <TAB> <TAB> h.append(self[""fileName""].hash()) <TAB> <TAB> h.append(self[""in""].hash()) <TAB> <TAB> h.append(self.__parameterHandler.hash()) <TAB> <TAB> return h",true,"if not self [ ""fileName"" ] . getValue ( ) or self [ ""in"" ] . source ( ) == self [ ""in"" ] :","if not self [ ""fileName"" ] . getValue ( ) or self [ ""in"" ] . source ( ) == self [ ""in"" ] :",1.0,0.0
"def consume_buf(): <TAB> ty = state[""ty""] - 1 <TAB> for i in xrange(state[""buf""].shape[1] // N): <TAB> <TAB> tx = x // N + i <TAB> <TAB> src = state[""buf""][:, i * N : (i + 1) * N, :] <TAB> <TAB> if src[:, :, 3].any(): <TAB> <TAB> <TAB> with self.tile_request(tx, ty, readonly=False) as dst: <TAB> <TAB> <TAB> <TAB> mypaintlib.tile_convert_rgba8_to_rgba16(src, dst, self.EOTF) <TAB> if state[""progress""]: <TAB> <TAB> try: <TAB> <TAB> <TAB> state[""progress""].completed(ty - ty0) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> logger.exception(""Progress.completed() failed"") <TAB> <TAB> <TAB> state[""progress""] = None",true,"if src [ : , : , 3 ] . any ( ) :","if src [ : , : , 3 ] . any ( ) :",0.75,0.0
"def check_permissions(self, obj): <TAB> request = self.context.get(""request"") <TAB> for Perm in permissions: <TAB> <TAB> perm = Perm() <TAB> <TAB> if not perm.has_permission(request, self): <TAB> <TAB> <TAB> return False <TAB> <TAB> if not perm.has_object_permission(request, self, obj): <TAB> <TAB> <TAB> return False <TAB> return True",true,"if not perm . has_object_permission ( request , self , obj ) :","if not perm . has_object_permission ( request , self , obj ) :",0.75,0.0
"def _post_order(op): <TAB> if isinstance(op, tvm.tir.Allocate): <TAB> <TAB> lift_stmt[-1].append(op) <TAB> <TAB> return op.body <TAB> if isinstance(op, tvm.tir.AttrStmt): <TAB> <TAB> if op.attr_key == ""storage_scope"": <TAB> <TAB> <TAB> lift_stmt[-1].append(op) <TAB> <TAB> <TAB> return op.body <TAB> <TAB> if op.attr_key == ""virtual_thread"": <TAB> <TAB> <TAB> return _merge_block(lift_stmt.pop() + [op], op.body) <TAB> <TAB> return op <TAB> if isinstance(op, tvm.tir.For): <TAB> <TAB> return _merge_block(lift_stmt.pop() + [op], op.body) <TAB> raise RuntimeError(""not reached"")",false,"if op . attr_key == ""virtual_thread"" :","if op . attr_key == ""storage_scope"" :",0.57,0.0
"def task_done(self): <TAB> with self._cond: <TAB> <TAB> if not self._unfinished_tasks.acquire(False): <TAB> <TAB> <TAB> raise ValueError(""task_done() called too many times"") <TAB> <TAB> if self._unfinished_tasks._semlock._is_zero(): <TAB> <TAB> <TAB> self._cond.notify_all()",true,if self . _unfinished_tasks . _semlock . _is_zero ( ) :,if self . _unfinished_tasks . _semlock . _is_zero ( ) :,0.75,0.0
"def get_json(self): <TAB> if not hasattr(self, ""_json""): <TAB> <TAB> self._json = None <TAB> <TAB> if self.request.headers.get(""Content-Type"", """").startswith(""application/json""): <TAB> <TAB> <TAB> self._json = json.loads(self.request.body) <TAB> return self._json",true,"if self . request . headers . get ( ""Content-Type"" , """" ) . startswith ( ""application/json"" ) :","if self . request . headers . get ( ""Content-Type"" , """" ) . startswith ( ""application/json"" ) :",0.75,0.0
"def userfullname(): <TAB> """"""Get the user's full name."""""" <TAB> global _userfullname <TAB><IF-STMT> <TAB> <TAB> uid = os.getuid() <TAB> <TAB> entry = pwd_from_uid(uid) <TAB> <TAB> if entry: <TAB> <TAB> <TAB> _userfullname = entry[4].split("","")[0] or entry[0] <TAB> <TAB> if not _userfullname: <TAB> <TAB> <TAB> _userfullname = ""user%d"" % uid <TAB> return _userfullname",true,if not _userfullname :,if not _userfullname :,0.75,0.0
"def test_scatter(self): <TAB> for rank in range(self.world_size): <TAB> <TAB> tensor = [] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tensor = [torch.tensor(i) for i in range(self.world_size)] <TAB> <TAB> result = comm.get().scatter(tensor, rank, size=()) <TAB> <TAB> self.assertTrue(torch.is_tensor(result)) <TAB> <TAB> self.assertEqual(result.item(), self.rank)",false,if self . rank == rank :,if rank == self . rank :,0.37,0.0
"def decompile(decompiler): <TAB> for pos, next_pos, opname, arg in decompiler.instructions: <TAB> <TAB> if pos in decompiler.targets: <TAB> <TAB> <TAB> decompiler.process_target(pos) <TAB> <TAB> method = getattr(decompiler, opname, None) <TAB> <TAB> if method is None: <TAB> <TAB> <TAB> throw(DecompileError(""Unsupported operation: %s"" % opname)) <TAB> <TAB> decompiler.pos = pos <TAB> <TAB> decompiler.next_pos = next_pos <TAB> <TAB> x = method(*arg) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> decompiler.stack.append(x)",true,if x is not None :,if x is not None :,0.75,0.0
"def print_scenario_ran(self, scenario): <TAB> if scenario.passed: <TAB> <TAB> self.wrt(""OK"") <TAB> elif scenario.failed: <TAB> <TAB> reason = self.scenarios_and_its_fails[scenario] <TAB> <TAB> if isinstance(reason.exception, AssertionError): <TAB> <TAB> <TAB> self.wrt(""FAILED"") <TAB> <TAB> else: <TAB> <TAB> <TAB> self.wrt(""ERROR"") <TAB> self.wrt(""\n"")",true,"if isinstance ( reason . exception , AssertionError ) :","if isinstance ( reason . exception , AssertionError ) :",0.75,0.0
"def detect_ssl_option(self): <TAB> for option in self.ssl_options(): <TAB> <TAB> if scan_argv(self.argv, option) is not None: <TAB> <TAB> <TAB> for other_option in self.ssl_options(): <TAB> <TAB> <TAB> <TAB> if option != other_option: <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ConfigurationError( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""Cannot give both %s and %s"" % (option, other_option) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return option",false,"if scan_argv ( self . argv , other_option ) is not None :",if other_option in self . ssl_options :,0.09,0.0
"def print_po_snippet(en_loc_old_lists, context): <TAB> for m, localized, old in zip(*en_loc_old_lists): <TAB> <TAB> if m == """": <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> localized = old <TAB> <TAB> print( <TAB> <TAB> <TAB> ""#: {file}:{line}\n"" <TAB> <TAB> <TAB> 'msgid ""{context}{en_month}""\n' <TAB> <TAB> <TAB> 'msgstr ""{localized_month}""\n'.format( <TAB> <TAB> <TAB> <TAB> context=context, <TAB> <TAB> <TAB> <TAB> file=filename, <TAB> <TAB> <TAB> <TAB> line=print_po_snippet.line, <TAB> <TAB> <TAB> <TAB> en_month=m, <TAB> <TAB> <TAB> <TAB> localized_month=localized, <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> print_po_snippet.line += 1",false,if m == localized :,"if localized == """" :",0.04,0.0
"def set_status(self, dict_new): <TAB> for i, value in dict_new.items(): <TAB> <TAB> self.dict_bili[i] = value <TAB> <TAB> if i == ""cookie"": <TAB> <TAB> <TAB> self.dict_bili[""pcheaders""][""cookie""] = value <TAB> <TAB> <TAB> self.dict_bili[""appheaders""][""cookie""] = value",true,"if i == ""cookie"" :","if i == ""cookie"" :",0.75,0.0
"def makeSomeFiles(pathobj, dirdict): <TAB> pathdict = {} <TAB> for (key, value) in dirdict.items(): <TAB> <TAB> child = pathobj.child(key) <TAB> <TAB> if isinstance(value, bytes): <TAB> <TAB> <TAB> pathdict[key] = child <TAB> <TAB> <TAB> child.setContent(value) <TAB> <TAB> elif isinstance(value, dict): <TAB> <TAB> <TAB> child.createDirectory() <TAB> <TAB> <TAB> pathdict[key] = makeSomeFiles(child, value) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""only strings and dicts allowed as values"") <TAB> return pathdict",false,"if isinstance ( value , bytes ) :","elif isinstance ( value , dict ) :",0.2,0.0
"def _truncate_to_length(generator, len_map=None): <TAB> for example in generator: <TAB> <TAB> example = list(example) <TAB> <TAB> if len_map is not None: <TAB> <TAB> <TAB> for key, max_len in len_map.items(): <TAB> <TAB> <TAB> <TAB> example_len = example[key].shape <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> example[key] = np.resize(example[key], max_len) <TAB> <TAB> yield tuple(example)",true,if example_len > max_len :,if example_len > max_len :,0.75,0.0
"def check(self, **kw): <TAB> if not kw: <TAB> <TAB> return exists(self.strpath) <TAB> if len(kw) == 1: <TAB> <TAB> if ""dir"" in kw: <TAB> <TAB> <TAB> return not kw[""dir""] ^ isdir(self.strpath) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return not kw[""file""] ^ isfile(self.strpath) <TAB> return super(LocalPath, self).check(**kw)",true,"if ""file"" in kw :","if ""file"" in kw :",0.75,0.0
"def next_instruction_is_function_or_class(lines): <TAB> """"""Is the first non-empty, non-commented line of the cell either a function or a class?"""""" <TAB> parser = StringParser(""python"") <TAB> for i, line in enumerate(lines): <TAB> <TAB> if parser.is_quoted(): <TAB> <TAB> <TAB> parser.read_line(line) <TAB> <TAB> <TAB> continue <TAB> <TAB> parser.read_line(line) <TAB> <TAB> if not line.strip():  # empty line <TAB> <TAB> <TAB> if i > 0 and not lines[i - 1].strip(): <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> continue <TAB> <TAB> if line.startswith(""def "") or line.startswith(""class ""): <TAB> <TAB> <TAB> return True <TAB> <TAB> if line.startswith((""#"", ""@"", "" "", "")"")): <TAB> <TAB> <TAB> continue <TAB> <TAB> return False <TAB> return False",true,"if line . startswith ( ( ""#"" , ""@"" , "" "" , "")"" ) ) :","if line . startswith ( ( ""#"" , ""@"" , "" "" , "")"" ) ) :",0.75,0.0
"def askCheckReadFile(self, localFile, remoteFile): <TAB> if not kb.bruteMode: <TAB> <TAB> message = ""do you want confirmation that the remote file '%s' "" % remoteFile <TAB> <TAB> message += ""has been successfully downloaded from the back-end "" <TAB> <TAB> message += ""DBMS file system? [Y/n] "" <TAB> <TAB> if readInput(message, default=""Y"", boolean=True): <TAB> <TAB> <TAB> return self._checkFileLength(localFile, remoteFile, True) <TAB> return None",true,"if readInput ( message , default = ""Y"" , boolean = True ) :","if readInput ( message , default = ""Y"" , boolean = True ) :",1.0,0.0
"def process_tag(hive_name, company, company_key, tag, default_arch): <TAB> with winreg.OpenKeyEx(company_key, tag) as tag_key: <TAB> <TAB> version = load_version_data(hive_name, company, tag, tag_key) <TAB> <TAB> if version is not None:  # if failed to get version bail <TAB> <TAB> <TAB> major, minor, _ = version <TAB> <TAB> <TAB> arch = load_arch_data(hive_name, company, tag, tag_key, default_arch) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> exe_data = load_exe(hive_name, company, company_key, tag) <TAB> <TAB> <TAB> <TAB> if exe_data is not None: <TAB> <TAB> <TAB> <TAB> <TAB> exe, args = exe_data <TAB> <TAB> <TAB> <TAB> <TAB> return company, major, minor, arch, exe, args",true,if arch is not None :,if arch is not None :,0.75,0.0
"def _get_matching_bracket(self, s, pos): <TAB> if s[pos] != ""{"": <TAB> <TAB> return None <TAB> end = len(s) <TAB> depth = 1 <TAB> pos += 1 <TAB> while pos != end: <TAB> <TAB> c = s[pos] <TAB> <TAB> if c == ""{"": <TAB> <TAB> <TAB> depth += 1 <TAB> <TAB> elif c == ""}"": <TAB> <TAB> <TAB> depth -= 1 <TAB> <TAB> if depth == 0: <TAB> <TAB> <TAB> break <TAB> <TAB> pos += 1 <TAB> if pos < end and s[pos] == ""}"": <TAB> <TAB> return pos <TAB> return None",true,"elif c == ""}"" :","elif c == ""}"" :",1.0,0.0
"def pred(field, value, item): <TAB> for suffix, p in _BUILTIN_PREDS.iteritems(): <TAB> <TAB> if field.endswith(suffix): <TAB> <TAB> <TAB> f = field[: field.index(suffix)] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> return p(getattr(item, f), value) <TAB> if not hasattr(item, field) or getattr(item, field) is None: <TAB> <TAB> return False <TAB> if isinstance(value, type(lambda x: x)): <TAB> <TAB> return value(getattr(item, field)) <TAB> return getattr(item, field) == value",false,"if not hasattr ( item , f ) or getattr ( item , f ) is None :",if f not in item :,0.01,0.0
"def init_weights(self): <TAB> """"""Initialize model weights."""""" <TAB> for _, m in self.multi_deconv_layers.named_modules(): <TAB> <TAB> if isinstance(m, nn.ConvTranspose2d): <TAB> <TAB> <TAB> normal_init(m, std=0.001) <TAB> <TAB> elif isinstance(m, nn.BatchNorm2d): <TAB> <TAB> <TAB> constant_init(m, 1) <TAB> for m in self.multi_final_layers.modules(): <TAB> <TAB> if isinstance(m, nn.Conv2d): <TAB> <TAB> <TAB> normal_init(m, std=0.001, bias=0)",false,"if isinstance ( m , nn . Conv2d ) :","if isinstance ( m , nn . ConvTranspose2d ) :",0.6,0.0
"def test_byteswap(self): <TAB> if self.typecode == ""u"": <TAB> <TAB> example = ""\U00100100"" <TAB> else: <TAB> <TAB> example = self.example <TAB> a = array.array(self.typecode, example) <TAB> self.assertRaises(TypeError, a.byteswap, 42) <TAB> if a.itemsize in (1, 2, 4, 8): <TAB> <TAB> b = array.array(self.typecode, example) <TAB> <TAB> b.byteswap() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.assertEqual(a, b) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.assertNotEqual(a, b) <TAB> <TAB> b.byteswap() <TAB> <TAB> self.assertEqual(a, b)",true,if a . itemsize == 1 :,if a . itemsize == 1 :,0.75,0.0
"def _remove_blocks_from_variables(variables): <TAB> new_variables = [] <TAB> for name, variable in variables: <TAB> <TAB> if variable.is_block(): <TAB> <TAB> <TAB> new_variables.extend(variable.locals) <TAB> <TAB> <TAB> new_variables.append((name, variable.result)) <TAB> <TAB> else: <TAB> <TAB> <TAB> new_variables.append((name, variable)) <TAB> return new_variables",true,if variable . is_block ( ) :,if variable . is_block ( ) :,0.75,0.0
def scope(self): <TAB><IF-STMT> <TAB> <TAB> self.lazy_init_lock_.acquire() <TAB> <TAB> try: <TAB> <TAB> <TAB> if self.scope_ is None: <TAB> <TAB> <TAB> <TAB> self.scope_ = Scope() <TAB> <TAB> finally: <TAB> <TAB> <TAB> self.lazy_init_lock_.release() <TAB> return self.scope_,true,if self . scope_ is None :,if self . scope_ is None :,0.75,0.0
"def translate(): <TAB> assert Lex.next() is AttributeList <TAB> reader.read()  # Discard attribute list from reader. <TAB> attrs = {} <TAB> d = AttributeList.match.groupdict() <TAB> for k, v in d.items(): <TAB> <TAB> if v is not None: <TAB> <TAB> <TAB> if k == ""attrlist"": <TAB> <TAB> <TAB> <TAB> v = subs_attrs(v) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> parse_attributes(v, attrs) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> AttributeList.attrs[k] = v <TAB> AttributeList.subs(attrs) <TAB> AttributeList.attrs.update(attrs)",false,if v :,if k in AttributeList . attrs :,0.05,0.0
"def parse(self, response): <TAB> try: <TAB> <TAB> content = response.content.decode(""utf-8"", ""ignore"") <TAB> <TAB> content = json.loads(content, strict=False) <TAB> except: <TAB> <TAB> self.logger.error(""Fail to parse the response in json format"") <TAB> <TAB> return <TAB> for item in content[""data""]: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> img_url = self._decode_url(item[""objURL""]) <TAB> <TAB> elif ""hoverURL"" in item: <TAB> <TAB> <TAB> img_url = item[""hoverURL""] <TAB> <TAB> else: <TAB> <TAB> <TAB> continue <TAB> <TAB> yield dict(file_url=img_url)",true,"if ""objURL"" in item :","if ""objURL"" in item :",0.75,0.0
"def canonicalize_instruction_name(instr): <TAB> name = instr.insn_name().upper() <TAB> # XXX bypass a capstone bug that incorrectly labels some insns as mov <TAB> if name == ""MOV"": <TAB> <TAB> if instr.mnemonic.startswith(""lsr""): <TAB> <TAB> <TAB> return ""LSR"" <TAB> <TAB> elif instr.mnemonic.startswith(""lsl""): <TAB> <TAB> <TAB> return ""LSL"" <TAB> <TAB> elif instr.mnemonic.startswith(""asr""): <TAB> <TAB> <TAB> return ""ASR"" <TAB> return OP_NAME_MAP.get(name, name)",true,"elif instr . mnemonic . startswith ( ""asr"" ) :","elif instr . mnemonic . startswith ( ""asr"" ) :",0.75,0.0
"def _clean_regions(items, region): <TAB> """"""Intersect region with target file if it exists"""""" <TAB> variant_regions = bedutils.population_variant_regions(items, merged=True) <TAB> with utils.tmpfile() as tx_out_file: <TAB> <TAB> target = subset_variant_regions(variant_regions, region, tx_out_file, items) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if isinstance(target, six.string_types) and os.path.isfile(target): <TAB> <TAB> <TAB> <TAB> target = _load_regions(target) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> target = [target] <TAB> <TAB> <TAB> return target",true,if target :,if target :,0.53,0.0
def reader_leaves(self): <TAB> self.mutex.acquire() <TAB> try: <TAB> <TAB> self.active_readers -= 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.active_writers += 1 <TAB> <TAB> <TAB> self.waiting_writers -= 1 <TAB> <TAB> <TAB> self.can_write.release() <TAB> finally: <TAB> <TAB> self.mutex.release(),false,if self . active_readers == 0 and self . waiting_writers != 0 :,if self . waiting_readers > 0 :,0.12,0.0
"def _bpe_to_words(sentence, delimiter=""@@""): <TAB> """"""Convert a sequence of bpe words into sentence."""""" <TAB> words = [] <TAB> word = """" <TAB> delimiter_len = len(delimiter) <TAB> for subwords in sentence: <TAB> <TAB> if len(subwords) >= delimiter_len and subwords[-delimiter_len:] == delimiter: <TAB> <TAB> <TAB> word += subwords[:-delimiter_len] <TAB> <TAB> else: <TAB> <TAB> <TAB> word += subwords <TAB> <TAB> <TAB> words.append(word) <TAB> <TAB> <TAB> word = """" <TAB> return words",true,if len ( subwords ) >= delimiter_len and subwords [ - delimiter_len : ] == delimiter :,if len ( subwords ) >= delimiter_len and subwords [ - delimiter_len : ] == delimiter :,1.0,0.0
"def _make_var_names(exog): <TAB> if hasattr(exog, ""name""): <TAB> <TAB> var_names = exog.name <TAB> elif hasattr(exog, ""columns""): <TAB> <TAB> var_names = exog.columns <TAB> else: <TAB> <TAB> raise ValueError(""exog is not a Series or DataFrame or is unnamed."") <TAB> try: <TAB> <TAB> var_names = "" "".join(var_names) <TAB> except TypeError:  # cannot have names that are numbers, pandas default <TAB> <TAB> from statsmodels.base.data import _make_exog_names <TAB> <TAB> if exog.ndim == 1: <TAB> <TAB> <TAB> var_names = ""x1"" <TAB> <TAB> else: <TAB> <TAB> <TAB> var_names = "" "".join(_make_exog_names(exog)) <TAB> return var_names",true,if exog . ndim == 1 :,if exog . ndim == 1 :,0.75,0.0
"def __start_element_handler(self, name, attrs): <TAB> if name == ""mime-type"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for extension in self.extensions: <TAB> <TAB> <TAB> <TAB> self[extension] = self.type <TAB> <TAB> self.type = attrs[""type""].lower() <TAB> <TAB> self.extensions = [] <TAB> elif name == ""glob"": <TAB> <TAB> pattern = attrs[""pattern""] <TAB> <TAB> if pattern.startswith(""*.""): <TAB> <TAB> <TAB> self.extensions.append(pattern[1:].lower())",false,if self . type :,if self . extensions :,0.39,0.0
"def nodes(self, id=None, name=None): <TAB> for node_dict in self.node_ls(id=id, name=name): <TAB> <TAB> node_id = node_dict[""ID""] <TAB> <TAB> node = DockerNode(self, node_id, inspect=node_dict) <TAB> <TAB> if self._node_prefix and not node.name.startswith(self._node_prefix): <TAB> <TAB> <TAB> continue <TAB> <TAB> yield node",true,if self . _node_prefix and not node . name . startswith ( self . _node_prefix ) :,if self . _node_prefix and not node . name . startswith ( self . _node_prefix ) :,0.75,0.0
"def fix_repeating_arguments(self): <TAB> """"""Fix elements that should accumulate/increment values."""""" <TAB> either = [list(child.children) for child in transform(self).children] <TAB> for case in either: <TAB> <TAB> for e in [child for child in case if case.count(child) > 1]: <TAB> <TAB> <TAB> if type(e) is Argument or type(e) is Option and e.argcount: <TAB> <TAB> <TAB> <TAB> if e.value is None: <TAB> <TAB> <TAB> <TAB> <TAB> e.value = [] <TAB> <TAB> <TAB> <TAB> elif type(e.value) is not list: <TAB> <TAB> <TAB> <TAB> <TAB> e.value = e.value.split() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> e.value = 0 <TAB> return self",false,if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 :,if type ( e ) is Argument or type ( e ) is Option and e . argcount :,0.77,0.0
"def vi_search(self, rng): <TAB> for i in rng: <TAB> <TAB> line_history = self._history.history[i] <TAB> <TAB> pos = line_history.get_line_text().find(self._vi_search_text) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._history.history_cursor = i <TAB> <TAB> <TAB> self.l_buffer.line_buffer = list(line_history.line_buffer) <TAB> <TAB> <TAB> self.l_buffer.point = pos <TAB> <TAB> <TAB> self.vi_undo_restart() <TAB> <TAB> <TAB> return True <TAB> self._bell() <TAB> return False",false,if pos >= 0 :,if pos != - 1 :,0.06,0.0
"def visitIf(self, node, scope): <TAB> for test, body in node.tests: <TAB> <TAB> if isinstance(test, ast.Const): <TAB> <TAB> <TAB> if type(test.value) in self._const_types: <TAB> <TAB> <TAB> <TAB> if not test.value: <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> self.visit(test, scope) <TAB> <TAB> self.visit(body, scope) <TAB> if node.else_: <TAB> <TAB> self.visit(node.else_, scope)",true,"if isinstance ( test , ast . Const ) :","if isinstance ( test , ast . Const ) :",0.75,0.0
"def collect(self): <TAB> for nickname in self.squid_hosts.keys(): <TAB> <TAB> squid_host = self.squid_hosts[nickname] <TAB> <TAB> fulldata = self._getData(squid_host[""host""], squid_host[""port""]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> fulldata = fulldata.splitlines() <TAB> <TAB> <TAB> for data in fulldata: <TAB> <TAB> <TAB> <TAB> matches = self.stat_pattern.match(data) <TAB> <TAB> <TAB> <TAB> if matches: <TAB> <TAB> <TAB> <TAB> <TAB> self.publish_counter( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""%s.%s"" % (nickname, matches.group(1)), float(matches.group(2)) <TAB> <TAB> <TAB> <TAB> <TAB> )",false,if fulldata is not None :,if fulldata :,0.05,0.0
"def convert(x, base, exponents): <TAB> out = [] <TAB> for e in exponents: <TAB> <TAB> d = int(x / (base ** e)) <TAB> <TAB> x -= d * (base ** e) <TAB> <TAB> out.append(digits[d]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> return out",false,if x == 0 and e < 0 :,if x < 0 :,0.13,0.0
"def print_doc(manager, options): <TAB> plugin_name = options.doc <TAB> plugin = plugins.get(plugin_name, None) <TAB> if plugin: <TAB> <TAB> if not plugin.instance.__doc__: <TAB> <TAB> <TAB> console(""Plugin %s does not have documentation"" % plugin_name) <TAB> <TAB> else: <TAB> <TAB> <TAB> console("""") <TAB> <TAB> <TAB> console(trim(plugin.instance.__doc__)) <TAB> <TAB> <TAB> console("""") <TAB> else: <TAB> <TAB> console(""Could not find plugin %s"" % plugin_name)",true,if not plugin . instance . __doc__ :,if not plugin . instance . __doc__ :,0.75,0.0
"def _set_attrs(self, attrs): <TAB> for attr in self.ATTRS: <TAB> <TAB> if attr in attrs: <TAB> <TAB> <TAB> setattr(self, attr, attrs[attr]) <TAB> <TAB> <TAB> del attrs[attr] <TAB> <TAB> else: <TAB> <TAB> <TAB> if attr == ""default"": <TAB> <TAB> <TAB> <TAB> setattr(self, attr, NO_DEFAULT) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> setattr(self, attr, None) <TAB> if attrs: <TAB> <TAB> attrs = sorted(attrs.keys()) <TAB> <TAB> raise OptionError(""invalid keyword arguments: %s"" % "", "".join(attrs), self)",true,"if attr == ""default"" :","if attr == ""default"" :",0.75,0.0
"def _get_set_scope( <TAB> ir_set: irast.Set, scope_tree: irast.ScopeTreeNode ) -> irast.ScopeTreeNode: <TAB> if ir_set.path_scope_id: <TAB> <TAB> new_scope = scope_tree.root.find_by_unique_id(ir_set.path_scope_id) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise errors.InternalServerError( <TAB> <TAB> <TAB> <TAB> f""dangling scope pointer to node with uid"" <TAB> <TAB> <TAB> <TAB> f"":{ir_set.path_scope_id} in {ir_set!r}"" <TAB> <TAB> <TAB> ) <TAB> else: <TAB> <TAB> new_scope = scope_tree <TAB> return new_scope",true,if new_scope is None :,if new_scope is None :,0.75,0.0
"def test_leave_one_out(self): <TAB> correct = 0 <TAB> k = 3 <TAB> model = kNN.train(xs, ys, k) <TAB> predictions = [1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1] <TAB> for i in range(len(predictions)): <TAB> <TAB> model = kNN.train(xs[:i] + xs[i + 1 :], ys[:i] + ys[i + 1 :], k) <TAB> <TAB> prediction = kNN.classify(model, xs[i]) <TAB> <TAB> self.assertEqual(prediction, predictions[i]) <TAB> <TAB> if prediction == ys[i]: <TAB> <TAB> <TAB> correct += 1 <TAB> self.assertEqual(correct, 13)",true,if prediction == ys [ i ] :,if prediction == ys [ i ] :,0.75,0.0
"def import_files(self, files): <TAB> """"""Import a list of MORE (.csv) files."""""" <TAB> c = self.c <TAB> if files: <TAB> <TAB> changed = False <TAB> <TAB> self.tab_width = c.getTabWidth(c.p) <TAB> <TAB> for fileName in files: <TAB> <TAB> <TAB> g.setGlobalOpenDir(fileName) <TAB> <TAB> <TAB> p = self.import_file(fileName) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> p.contract() <TAB> <TAB> <TAB> <TAB> p.setDirty() <TAB> <TAB> <TAB> <TAB> c.setChanged(True) <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> if changed: <TAB> <TAB> <TAB> c.redraw(p)",true,if p :,if p :,0.53,0.0
"def getPageTemplate(payload, place): <TAB> retVal = (kb.originalPage, kb.errorIsNone) <TAB> if payload and place: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> page, _, _ = Request.queryPage(payload, place, content=True, raise404=False) <TAB> <TAB> <TAB> kb.pageTemplates[(payload, place)] = (page, kb.lastParserStatus is None) <TAB> <TAB> retVal = kb.pageTemplates[(payload, place)] <TAB> return retVal",true,"if ( payload , place ) not in kb . pageTemplates :","if ( payload , place ) not in kb . pageTemplates :",0.75,0.0
"def _skip_trivial(constraint_data): <TAB> if skip_trivial_constraints: <TAB> <TAB> if isinstance(constraint_data, LinearCanonicalRepn): <TAB> <TAB> <TAB> if constraint_data.variables is None: <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> else: <TAB> <TAB> <TAB> if constraint_data.body.polynomial_degree() == 0: <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",false,if constraint_data . body . polynomial_degree ( ) == 0 :,"if isinstance ( constraint_data , LinearCanonicalRepn ) :",0.01,0.0
"def get_unique_attribute(self, name: str): <TAB> feat = None <TAB> for f in self.features: <TAB> <TAB> if self._return_feature(f) and hasattr(f, name): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise RuntimeError(""The attribute was not unique."") <TAB> <TAB> <TAB> feat = f <TAB> if feat is None: <TAB> <TAB> raise RuntimeError(""The attribute did not exist"") <TAB> return getattr(feat, name)",false,if feat is not None :,if f . unique :,0.03,0.0
"def hideEvent(self, event): <TAB> """"""Reimplement Qt method"""""" <TAB> if not self.light: <TAB> <TAB> for plugin in self.widgetlist: <TAB> <TAB> <TAB> if plugin.isAncestorOf(self.last_focused_widget): <TAB> <TAB> <TAB> <TAB> plugin.visibility_changed(True) <TAB> QMainWindow.hideEvent(self, event)",true,if plugin . isAncestorOf ( self . last_focused_widget ) :,if plugin . isAncestorOf ( self . last_focused_widget ) :,0.75,0.0
"def move_stdout_to_stderr(self): <TAB> to_remove = [] <TAB> to_add = [] <TAB> for consumer_level, consumer in self.consumers: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> to_remove.append((consumer_level, consumer)) <TAB> <TAB> <TAB> to_add.append((consumer_level, sys.stderr)) <TAB> for item in to_remove: <TAB> <TAB> self.consumers.remove(item) <TAB> self.consumers.extend(to_add)",false,if consumer == sys . stdout :,if consumer . is_stdout :,0.13,0.0
"def create(exported_python_target): <TAB> if exported_python_target not in created: <TAB> <TAB> self.context.log.info( <TAB> <TAB> <TAB> ""Creating setup.py project for {}"".format(exported_python_target) <TAB> <TAB> ) <TAB> <TAB> subject = self.derived_by_original.get( <TAB> <TAB> <TAB> exported_python_target, exported_python_target <TAB> <TAB> ) <TAB> <TAB> setup_dir, dependencies = self.create_setup_py(subject, dist_dir) <TAB> <TAB> created[exported_python_target] = setup_dir <TAB> <TAB> if self._recursive: <TAB> <TAB> <TAB> for dep in dependencies: <TAB> <TAB> <TAB> <TAB> if is_exported_python_target(dep): <TAB> <TAB> <TAB> <TAB> <TAB> create(dep)",true,if self . _recursive :,if self . _recursive :,0.75,0.0
"def __add__(self, other): <TAB> other = ArithmeticExpression.try_unpack_const(other) <TAB> if not self.symbolic and type(other) is int: <TAB> <TAB> return SpOffset(self._bits, self._to_signed(self.offset + other)) <TAB> else: <TAB> <TAB> if self.symbolic: <TAB> <TAB> <TAB> return SpOffset(self._bits, self.offset + other) <TAB> <TAB> else: <TAB> <TAB> <TAB> return SpOffset( <TAB> <TAB> <TAB> <TAB> self._bits, <TAB> <TAB> <TAB> <TAB> ArithmeticExpression( <TAB> <TAB> <TAB> <TAB> <TAB> ArithmeticExpression.Add, <TAB> <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self.offset, <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> other, <TAB> <TAB> <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> )",true,if self . symbolic :,if self . symbolic :,0.75,0.0
"def check_connection(conn): <TAB> tables = [ <TAB> <TAB> r[0] <TAB> <TAB> for r in conn.execute( <TAB> <TAB> <TAB> ""select name from sqlite_master where type='table'"" <TAB> <TAB> ).fetchall() <TAB> ] <TAB> for table in tables: <TAB> <TAB> try: <TAB> <TAB> <TAB> conn.execute( <TAB> <TAB> <TAB> <TAB> f""PRAGMA table_info({escape_sqlite(table)});"", <TAB> <TAB> <TAB> ) <TAB> <TAB> except sqlite3.OperationalError as e: <TAB> <TAB> <TAB> if e.args[0] == ""no such module: VirtualSpatialIndex"": <TAB> <TAB> <TAB> <TAB> raise SpatialiteConnectionProblem(e) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise ConnectionProblem(e)",true,"if e . args [ 0 ] == ""no such module: VirtualSpatialIndex"" :","if e . args [ 0 ] == ""no such module: VirtualSpatialIndex"" :",0.75,0.0
"def _get_github_client(self) -> ""Github"": <TAB> from github import Github <TAB> if self.access_token_secret is not None: <TAB> <TAB> # If access token secret specified, load it <TAB> <TAB> access_token = Secret(self.access_token_secret).get() <TAB> else: <TAB> <TAB> # Otherwise, fallback to loading from local secret or environment variable <TAB> <TAB> access_token = prefect.context.get(""secrets"", {}).get(""GITHUB_ACCESS_TOKEN"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> access_token = os.getenv(""GITHUB_ACCESS_TOKEN"") <TAB> return Github(access_token)",true,if access_token is None :,if access_token is None :,0.75,0.0
"def make_tab(lists): <TAB> if hasattr(lists, ""tolist""): <TAB> <TAB> lists = lists.tolist() <TAB> ut = [] <TAB> for rad in lists: <TAB> <TAB> if type(rad) in [list, tuple]: <TAB> <TAB> <TAB> ut.append(""\t"".join([""%s"" % x for x in rad])) <TAB> <TAB> else: <TAB> <TAB> <TAB> ut.append(""%s"" % rad) <TAB> return ""\n"".join(ut)",true,"if type ( rad ) in [ list , tuple ] :","if type ( rad ) in [ list , tuple ] :",0.75,0.0
"def _ensure_ffi_initialized(cls): <TAB> with cls._init_lock: <TAB> <TAB> if not cls._lib_loaded: <TAB> <TAB> <TAB> cls.lib = build_conditional_library(lib, CONDITIONAL_NAMES) <TAB> <TAB> <TAB> cls._lib_loaded = True <TAB> <TAB> <TAB> # initialize the SSL library <TAB> <TAB> <TAB> cls.lib.SSL_library_init() <TAB> <TAB> <TAB> # adds all ciphers/digests for EVP <TAB> <TAB> <TAB> cls.lib.OpenSSL_add_all_algorithms() <TAB> <TAB> <TAB> # loads error strings for libcrypto and libssl functions <TAB> <TAB> <TAB> cls.lib.SSL_load_error_strings() <TAB> <TAB> <TAB> cls._register_osrandom_engine()",true,if not cls . _lib_loaded :,if not cls . _lib_loaded :,0.75,0.0
def writer_leaves(self): <TAB> self.mutex.acquire() <TAB> try: <TAB> <TAB> self.active_writers -= 1 <TAB> <TAB> if self.waiting_writers != 0: <TAB> <TAB> <TAB> self.active_writers += 1 <TAB> <TAB> <TAB> self.waiting_writers -= 1 <TAB> <TAB> <TAB> self.can_write.release() <TAB> <TAB> elif self.waiting_readers != 0: <TAB> <TAB> <TAB> t = self.waiting_readers <TAB> <TAB> <TAB> self.waiting_readers = 0 <TAB> <TAB> <TAB> self.active_readers += t <TAB> <TAB> <TAB> while t > 0: <TAB> <TAB> <TAB> <TAB> self.can_read.release() <TAB> <TAB> <TAB> <TAB> t -= 1 <TAB> finally: <TAB> <TAB> self.mutex.release(),true,elif self . waiting_readers != 0 :,elif self . waiting_readers != 0 :,0.75,0.0
"def _spans(self, operands): <TAB> spans = {} <TAB> k = 0 <TAB> j = 0 <TAB> for mode in (self.FLOAT, self.MPMATH): <TAB> <TAB> for i, operand in enumerate(operands[k:]): <TAB> <TAB> <TAB> if operand[0] > mode: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> j = i + k + 1 <TAB> <TAB><IF-STMT>  # only init state? then ignore. <TAB> <TAB> <TAB> j = 0 <TAB> <TAB> spans[mode] = slice(k, j) <TAB> <TAB> k = j <TAB> spans[self.SYMBOLIC] = slice(k, len(operands)) <TAB> return spans",false,if k == 0 and j == 1 :,if j == k :,0.03,0.0
"def _report_error(self, completion_routine, response=None, message=None): <TAB> if response: <TAB> <TAB> # Only include the text in case of error. <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> status = location.Status(response.status_code, response.text) <TAB> <TAB> else: <TAB> <TAB> <TAB> status = location.Status(response.status_code) <TAB> else: <TAB> <TAB> status = location.Status(500, message) <TAB> if response is None or not response.ok: <TAB> <TAB> if completion_routine: <TAB> <TAB> <TAB> return completion_routine(status) <TAB> <TAB> raise IOError(response.text) <TAB> else: <TAB> <TAB> if completion_routine: <TAB> <TAB> <TAB> completion_routine(status) <TAB> return location.Status(200, response.content)",false,if not response . ok :,if response . text :,0.05,0.0
"def readinto(self, buf): <TAB> if self.current_frame: <TAB> <TAB> n = self.current_frame.readinto(buf) <TAB> <TAB> if n == 0 and len(buf) != 0: <TAB> <TAB> <TAB> self.current_frame = None <TAB> <TAB> <TAB> n = len(buf) <TAB> <TAB> <TAB> buf[:] = self.file_read(n) <TAB> <TAB> <TAB> return n <TAB> <TAB> if n < len(buf): <TAB> <TAB> <TAB> raise UnpicklingError(""pickle exhausted before end of frame"") <TAB> <TAB> return n <TAB> else: <TAB> <TAB> n = len(buf) <TAB> <TAB> buf[:] = self.file_read(n) <TAB> <TAB> return n",true,if n < len ( buf ) :,if n < len ( buf ) :,0.75,0.0
"def __getitem__(self, name, set=set, getattr=getattr, id=id): <TAB> visited = set() <TAB> mydict = self.basedict <TAB> while 1: <TAB> <TAB> value = mydict[name] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return value <TAB> <TAB> myid = id(mydict) <TAB> <TAB> assert myid not in visited <TAB> <TAB> visited.add(myid) <TAB> <TAB> mydict = mydict.Parent <TAB> <TAB> if mydict is None: <TAB> <TAB> <TAB> return",true,if value is not None :,if value is not None :,0.75,0.0
"def _handle_Mul(self, expr): <TAB> arg0, arg1 = expr.args <TAB> expr_0 = self._expr(arg0) <TAB> if expr_0 is None: <TAB> <TAB> return None <TAB> expr_1 = self._expr(arg1) <TAB> if expr_1 is None: <TAB> <TAB> return None <TAB> try: <TAB> <TAB> if isinstance(expr_0, int) and isinstance(expr_1, int): <TAB> <TAB> <TAB> # self.tyenv is not used <TAB> <TAB> <TAB> mask = (1 << expr.result_size(self.tyenv)) - 1 <TAB> <TAB> <TAB> return (expr_0 * expr_1) & mask <TAB> <TAB> else: <TAB> <TAB> <TAB> return expr_0 * expr_1 <TAB> except TypeError as e: <TAB> <TAB> self.l.warning(e) <TAB> <TAB> return None",true,"if isinstance ( expr_0 , int ) and isinstance ( expr_1 , int ) :","if isinstance ( expr_0 , int ) and isinstance ( expr_1 , int ) :",1.0,0.0
"def end_request(self, request_id): <TAB> """"""Removes the information associated with given request_id."""""" <TAB> with self._lock: <TAB> <TAB> del self._request_wsgi_environ[request_id] <TAB> <TAB> del self._request_id_to_server_configuration[request_id] <TAB> <TAB> if request_id in self._request_id_to_instance: <TAB> <TAB> <TAB> del self._request_id_to_instance[request_id]",true,if request_id in self . _request_id_to_instance :,if request_id in self . _request_id_to_instance :,0.75,0.0
def generate(): <TAB> if self._gzipped: <TAB> <TAB> decoder = zlib.decompressobj(16 + zlib.MAX_WBITS) <TAB> while True: <TAB> <TAB> chunk = self.raw.read(chunk_size) <TAB> <TAB> if not chunk: <TAB> <TAB> <TAB> break <TAB> <TAB> if self._gzipped: <TAB> <TAB> <TAB> chunk = decoder.decompress(chunk) <TAB> <TAB> yield chunk,true,if self . _gzipped :,if self . _gzipped :,0.75,0.0
"def handle(self): <TAB> from poetry.utils.env import EnvManager <TAB> manager = EnvManager(self.poetry) <TAB> current_env = manager.get() <TAB> for venv in manager.list(): <TAB> <TAB> name = venv.path.name <TAB> <TAB> if self.option(""full-path""): <TAB> <TAB> <TAB> name = str(venv.path) <TAB> <TAB> if venv == current_env: <TAB> <TAB> <TAB> self.line(""<info>{} (Activated)</info>"".format(name)) <TAB> <TAB> <TAB> continue <TAB> <TAB> self.line(name)",true,"if self . option ( ""full-path"" ) :","if self . option ( ""full-path"" ) :",0.75,0.0
"def addAggregators(sheet, cols, aggrnames): <TAB> ""Add each aggregator in list of *aggrnames* to each of *cols*."" <TAB> for aggrname in aggrnames: <TAB> <TAB> aggrs = vd.aggregators.get(aggrname) <TAB> <TAB> aggrs = aggrs if isinstance(aggrs, list) else [aggrs] <TAB> <TAB> for aggr in aggrs: <TAB> <TAB> <TAB> for c in cols: <TAB> <TAB> <TAB> <TAB> if not hasattr(c, ""aggregators""): <TAB> <TAB> <TAB> <TAB> <TAB> c.aggregators = [] <TAB> <TAB> <TAB> <TAB> if aggr and aggr not in c.aggregators: <TAB> <TAB> <TAB> <TAB> <TAB> c.aggregators += [aggr]",true,"if not hasattr ( c , ""aggregators"" ) :","if not hasattr ( c , ""aggregators"" ) :",0.75,0.0
"def on_pre_output_coercion( <TAB> directive_args: Dict[str, Any], <TAB> next_directive: Callable, <TAB> value: Any, <TAB> ctx: Optional[Any], <TAB> info: ""ResolveInfo"", ): <TAB> value = await next_directive(value, ctx, info) <TAB> if value is None: <TAB> <TAB> return value <TAB> try: <TAB> <TAB> py_enum = _ENUM_MAP[directive_args[""name""]] <TAB> <TAB> if isinstance(value, list): <TAB> <TAB> <TAB> return [None if item is None else py_enum(item).name for item in value] <TAB> <TAB> return py_enum(value).name <TAB> except Exception: <TAB> <TAB> pass <TAB> return value",true,"if isinstance ( value , list ) :","if isinstance ( value , list ) :",0.75,0.0
def cut(sentence): <TAB> sentence = strdecode(sentence) <TAB> blocks = re_han.split(sentence) <TAB> for blk in blocks: <TAB> <TAB> if re_han.match(blk): <TAB> <TAB> <TAB> for word in __cut(blk): <TAB> <TAB> <TAB> <TAB> if word not in Force_Split_Words: <TAB> <TAB> <TAB> <TAB> <TAB> yield word <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> for c in word: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield c <TAB> <TAB> else: <TAB> <TAB> <TAB> tmp = re_skip.split(blk) <TAB> <TAB> <TAB> for x in tmp: <TAB> <TAB> <TAB> <TAB> if x: <TAB> <TAB> <TAB> <TAB> <TAB> yield x,true,if re_han . match ( blk ) :,if re_han . match ( blk ) :,0.75,0.0
"def refresh_archive_action(self): <TAB> archive_name = self.selected_archive_name() <TAB> if archive_name is not None: <TAB> <TAB> params = BorgInfoArchiveThread.prepare(self.profile(), archive_name) <TAB> <TAB> if params[""ok""]: <TAB> <TAB> <TAB> thread = BorgInfoArchiveThread(params[""cmd""], params, parent=self.app) <TAB> <TAB> <TAB> thread.updated.connect(self._set_status) <TAB> <TAB> <TAB> thread.result.connect(self.refresh_archive_result) <TAB> <TAB> <TAB> self._toggle_all_buttons(False) <TAB> <TAB> <TAB> thread.start()",true,"if params [ ""ok"" ] :","if params [ ""ok"" ] :",0.75,0.0
"def get_resource_public_actions(resource_class): <TAB> resource_class_members = inspect.getmembers(resource_class) <TAB> resource_methods = {} <TAB> for name, member in resource_class_members: <TAB> <TAB> if not name.startswith(""_""): <TAB> <TAB> <TAB> if not name[0].isupper(): <TAB> <TAB> <TAB> <TAB> if not name.startswith(""wait_until""): <TAB> <TAB> <TAB> <TAB> <TAB> if is_resource_action(member): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> resource_methods[name] = member <TAB> return resource_methods",true,if is_resource_action ( member ) :,if is_resource_action ( member ) :,0.75,0.0
"def _get_compressor(compress_type, compresslevel=None): <TAB> if compress_type == ZIP_DEFLATED: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return zlib.compressobj(compresslevel, zlib.DEFLATED, -15) <TAB> <TAB> return zlib.compressobj(zlib.Z_DEFAULT_COMPRESSION, zlib.DEFLATED, -15) <TAB> elif compress_type == ZIP_BZIP2: <TAB> <TAB> if compresslevel is not None: <TAB> <TAB> <TAB> return bz2.BZ2Compressor(compresslevel) <TAB> <TAB> return bz2.BZ2Compressor() <TAB> # compresslevel is ignored for ZIP_LZMA <TAB> elif compress_type == ZIP_LZMA: <TAB> <TAB> return LZMACompressor() <TAB> else: <TAB> <TAB> return None",true,if compresslevel is not None :,if compresslevel is not None :,0.75,0.0
"def parse_header(plyfile, ext): <TAB> # Variables <TAB> line = [] <TAB> properties = [] <TAB> num_points = None <TAB> while b""end_header"" not in line and line != b"""": <TAB> <TAB> line = plyfile.readline() <TAB> <TAB> if b""element"" in line: <TAB> <TAB> <TAB> line = line.split() <TAB> <TAB> <TAB> num_points = int(line[2]) <TAB> <TAB> elif b""property"" in line: <TAB> <TAB> <TAB> line = line.split() <TAB> <TAB> <TAB> properties.append((line[2].decode(), ext + ply_dtypes[line[1]])) <TAB> return num_points, properties",true,"elif b""property"" in line :","elif b""property"" in line :",0.75,0.0
"def download_release_artifacts(self, version): <TAB> try: <TAB> <TAB> os.mkdir(self.artifacts_dir) <TAB> except FileExistsError: <TAB> <TAB> pass <TAB> for job_name in self.build_ids: <TAB> <TAB> build_number = self.build_ids.get(job_name) <TAB> <TAB> build_status = self._get_build_status(job_name, build_number) <TAB> <TAB> if build_status == ""built"": <TAB> <TAB> <TAB> self._download_job_artifact(job_name, build_number, version) <TAB> <TAB> else: <TAB> <TAB> <TAB> print(""Build for {} is not fininished"".format(job_name)) <TAB> <TAB> <TAB> print(""\tRun 'build' action to check status of {}"".format(job_name))",true,"if build_status == ""built"" :","if build_status == ""built"" :",0.75,0.0
"def update_metadata(self): <TAB> for attrname in dir(self): <TAB> <TAB> if attrname.startswith(""__""): <TAB> <TAB> <TAB> continue <TAB> <TAB> attrvalue = getattr(self, attrname, None) <TAB> <TAB> if attrvalue == 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> if attrname == ""salt_version"": <TAB> <TAB> <TAB> attrname = ""version"" <TAB> <TAB> if hasattr(self.metadata, ""set_{0}"".format(attrname)): <TAB> <TAB> <TAB> getattr(self.metadata, ""set_{0}"".format(attrname))(attrvalue) <TAB> <TAB> elif hasattr(self.metadata, attrname): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> setattr(self.metadata, attrname, attrvalue) <TAB> <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> <TAB> pass",true,"if attrname . startswith ( ""__"" ) :","if attrname . startswith ( ""__"" ) :",0.75,0.0
"def check_heuristic_in_sql(): <TAB> heurs = set() <TAB> excluded = [""Equal assembly or pseudo-code"", ""All or most attributes""] <TAB> for heur in HEURISTICS: <TAB> <TAB> name = heur[""name""] <TAB> <TAB> if name in excluded: <TAB> <TAB> <TAB> continue <TAB> <TAB> sql = heur[""sql""] <TAB> <TAB> if sql.lower().find(name.lower()) == -1: <TAB> <TAB> <TAB> print((""SQL command not correctly associated to %s"" % repr(name))) <TAB> <TAB> <TAB> print(sql) <TAB> <TAB> <TAB> assert sql.find(name) != -1 <TAB> <TAB> heurs.add(name) <TAB> print(""Heuristics:"") <TAB> import pprint <TAB> pprint.pprint(heurs)",true,if sql . lower ( ) . find ( name . lower ( ) ) == - 1 :,if sql . lower ( ) . find ( name . lower ( ) ) == - 1 :,1.0,0.0
def gettext(rv): <TAB> for child in rv.childNodes: <TAB> <TAB> if child.nodeType == child.TEXT_NODE: <TAB> <TAB> <TAB> yield child.nodeValue <TAB> <TAB> if child.nodeType == child.ELEMENT_NODE: <TAB> <TAB> <TAB> for item in gettext(child): <TAB> <TAB> <TAB> <TAB> yield item,true,if child . nodeType == child . TEXT_NODE :,if child . nodeType == child . TEXT_NODE :,1.0,0.0
"def update(self): <TAB> """"""Update properties over dbus."""""" <TAB> self._check_dbus() <TAB> _LOGGER.info(""Updating service information"") <TAB> self._services.clear() <TAB> try: <TAB> <TAB> systemd_units = await self.sys_dbus.systemd.list_units() <TAB> <TAB> for service_data in systemd_units[0]: <TAB> <TAB> <TAB> if not service_data[0].endswith("".service"") or service_data[2] != ""loaded"": <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self._services.add(ServiceInfo.read_from(service_data)) <TAB> except (HassioError, IndexError): <TAB> <TAB> _LOGGER.warning(""Can't update host service information!"")",true,"if not service_data [ 0 ] . endswith ( "".service"" ) or service_data [ 2 ] != ""loaded"" :","if not service_data [ 0 ] . endswith ( "".service"" ) or service_data [ 2 ] != ""loaded"" :",1.0,0.0
"def filtercomments(source): <TAB> """"""NOT USED: strips trailing comments and put them at the top."""""" <TAB> trailing_comments = [] <TAB> comment = True <TAB> while comment: <TAB> <TAB> if re.search(r""^\s*\/\*"", source): <TAB> <TAB> <TAB> comment = source[0, source.index(""*/"") + 2] <TAB> <TAB> elif re.search(r""^\s*\/\/"", source): <TAB> <TAB> <TAB> comment = re.search(r""^\s*\/\/"", source).group(0) <TAB> <TAB> else: <TAB> <TAB> <TAB> comment = None <TAB> <TAB> if comment: <TAB> <TAB> <TAB> source = re.sub(r""^\s+"", """", source[len(comment) :]) <TAB> <TAB> <TAB> trailing_comments.append(comment) <TAB> return ""\n"".join(trailing_comments) + source",false,"if re . search ( r""^\s*\/\*"" , source ) :","elif re . search ( r""^\s*\/\/"" , source ) :",0.25,0.0
"def _getSourceStamp_sync(self, ssid): <TAB> if ssid in self.sourcestamps: <TAB> <TAB> ssdict = self.sourcestamps[ssid].copy() <TAB> <TAB> ssdict[""ssid""] = ssid <TAB> <TAB> patchid = ssdict[""patchid""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ssdict.update(self.patches[patchid]) <TAB> <TAB> <TAB> ssdict[""patchid""] = patchid <TAB> <TAB> else: <TAB> <TAB> <TAB> ssdict[""patch_body""] = None <TAB> <TAB> <TAB> ssdict[""patch_level""] = None <TAB> <TAB> <TAB> ssdict[""patch_subdir""] = None <TAB> <TAB> <TAB> ssdict[""patch_author""] = None <TAB> <TAB> <TAB> ssdict[""patch_comment""] = None <TAB> <TAB> return ssdict <TAB> else: <TAB> <TAB> return None",true,if patchid :,if patchid :,0.53,0.0
"def parseImpl(self, instring, loc, doActions=True): <TAB> try: <TAB> <TAB> loc, tokens = self.expr._parse(instring, loc, doActions, callPreParse=False) <TAB> except (ParseException, IndexError): <TAB> <TAB> if self.defaultValue is not self.__optionalNotMatched: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> tokens = ParseResults([self.defaultValue]) <TAB> <TAB> <TAB> <TAB> tokens[self.expr.resultsName] = self.defaultValue <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> tokens = [self.defaultValue] <TAB> <TAB> else: <TAB> <TAB> <TAB> tokens = [] <TAB> return loc, tokens",true,if self . expr . resultsName :,if self . expr . resultsName :,0.75,0.0
"def _find_exceptions(): <TAB> for _name, obj in iteritems(globals()): <TAB> <TAB> try: <TAB> <TAB> <TAB> is_http_exception = issubclass(obj, HTTPException) <TAB> <TAB> except TypeError: <TAB> <TAB> <TAB> is_http_exception = False <TAB> <TAB> if not is_http_exception or obj.code is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> __all__.append(obj.__name__) <TAB> <TAB> old_obj = default_exceptions.get(obj.code, None) <TAB> <TAB> if old_obj is not None and issubclass(obj, old_obj): <TAB> <TAB> <TAB> continue <TAB> <TAB> default_exceptions[obj.code] = obj",true,"if old_obj is not None and issubclass ( obj , old_obj ) :","if old_obj is not None and issubclass ( obj , old_obj ) :",0.75,0.0
"def generator(self, data): <TAB> for (proc_as, key_buf_ptr) in data: <TAB> <TAB> key_buf = proc_as.read(key_buf_ptr, 24) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> key = """".join(""%02X"" % ord(k) for k in key_buf) <TAB> <TAB> yield ( <TAB> <TAB> <TAB> 0, <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> str(key), <TAB> <TAB> <TAB> ], <TAB> <TAB> )",true,if not key_buf :,if not key_buf :,0.75,0.0
"def calculateEnableMargins(self): <TAB> self.cnc.resetEnableMargins() <TAB> for block in self.blocks: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> CNC.vars[""xmin""] = min(CNC.vars[""xmin""], block.xmin) <TAB> <TAB> <TAB> CNC.vars[""ymin""] = min(CNC.vars[""ymin""], block.ymin) <TAB> <TAB> <TAB> CNC.vars[""zmin""] = min(CNC.vars[""zmin""], block.zmin) <TAB> <TAB> <TAB> CNC.vars[""xmax""] = max(CNC.vars[""xmax""], block.xmax) <TAB> <TAB> <TAB> CNC.vars[""ymax""] = max(CNC.vars[""ymax""], block.ymax) <TAB> <TAB> <TAB> CNC.vars[""zmax""] = max(CNC.vars[""zmax""], block.zmax)",false,if block . enable :,if block . xmin and block . ymin :,0.27,0.0
"def __init__(self, client, job_id, callback=None): <TAB> self.client = client <TAB> self.job_id = job_id <TAB> # If a job event has been received already then we must set an Event <TAB> # to wait for this job to finish. <TAB> # Otherwise we create a new stub for the job with the Event for when <TAB> # the job event arrives to use existing event. <TAB> with client._jobs_lock: <TAB> <TAB> job = client._jobs.get(job_id) <TAB> <TAB> self.event = None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.event = job.get(""__ready"") <TAB> <TAB> if self.event is None: <TAB> <TAB> <TAB> self.event = job[""__ready""] = Event() <TAB> <TAB> job[""__callback""] = callback",false,if job :,if job is not None :,0.09,0.0
"def asset(*paths): <TAB> for path in paths: <TAB> <TAB> fspath = www_root + ""/assets/"" + path <TAB> <TAB> etag = """" <TAB> <TAB> try: <TAB> <TAB> <TAB> if env.cache_static: <TAB> <TAB> <TAB> <TAB> etag = asset_etag(fspath) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> os.stat(fspath) <TAB> <TAB> except FileNotFoundError as e: <TAB> <TAB> <TAB> if path == paths[-1]: <TAB> <TAB> <TAB> <TAB> if not os.path.exists(fspath + "".spt""): <TAB> <TAB> <TAB> <TAB> <TAB> tell_sentry(e, {}) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> tell_sentry(e, {}) <TAB> <TAB> return asset_url + path + (etag and ""?etag="" + etag)",false,"if not os . path . exists ( fspath + "".spt"" ) :",if path == paths [ - 1 ] :,0.01,0.0
"def set_conf(): <TAB> """"""Collapse all object_trail config into cherrypy.request.config."""""" <TAB> base = cherrypy.config.copy() <TAB> # Note that we merge the config from each node <TAB> # even if that node was None. <TAB> for name, obj, conf, segleft in object_trail: <TAB> <TAB> base.update(conf) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> base[""tools.staticdir.section""] = ""/"" + ""/"".join( <TAB> <TAB> <TAB> <TAB> fullpath[0 : fullpath_len - segleft] <TAB> <TAB> <TAB> ) <TAB> return base",false,"if ""tools.staticdir.dir"" in conf :",if segleft :,0.04,0.0
"def __init__(self): <TAB> self.setLayers(None, None) <TAB> self.interface = None <TAB> self.event_callbacks = {} <TAB> self.__stack = None <TAB> self.lock = threading.Lock() <TAB> members = inspect.getmembers(self, predicate=inspect.ismethod) <TAB> for m in members: <TAB> <TAB> if hasattr(m[1], ""event_callback""): <TAB> <TAB> <TAB> fname = m[0] <TAB> <TAB> <TAB> fn = m[1] <TAB> <TAB> <TAB> self.event_callbacks[fn.event_callback] = getattr(self, fname)",true,"if hasattr ( m [ 1 ] , ""event_callback"" ) :","if hasattr ( m [ 1 ] , ""event_callback"" ) :",0.75,0.0
def multi_dev_generator(self): <TAB> for data in self._data_loader(): <TAB> <TAB> if len(self._tail_data) < self._base_number: <TAB> <TAB> <TAB> self._tail_data += data <TAB> <TAB> if len(self._tail_data) == self._base_number: <TAB> <TAB> <TAB> yield self._tail_data <TAB> <TAB> <TAB> self._tail_data = [],false,if len ( self . _tail_data ) < self . _base_number :,if len ( self . _tail_data ) == self . _base_number :,0.87,0.0
"def replace_field_to_value(layout, cb): <TAB> for i, lo in enumerate(layout.fields): <TAB> <TAB> if isinstance(lo, Field) or issubclass(lo.__class__, Field): <TAB> <TAB> <TAB> layout.fields[i] = ShowField( <TAB> <TAB> <TAB> <TAB> cb, *lo.fields, attrs=lo.attrs, wrapper_class=lo.wrapper_class <TAB> <TAB> <TAB> ) <TAB> <TAB> elif isinstance(lo, basestring): <TAB> <TAB> <TAB> layout.fields[i] = ShowField(cb, lo) <TAB> <TAB> elif hasattr(lo, ""get_field_names""): <TAB> <TAB> <TAB> replace_field_to_value(lo, cb)",false,"elif hasattr ( lo , ""get_field_names"" ) :","elif isinstance ( lo , basestring ) :",0.17,0.0
"def function_out(*args, **kwargs): <TAB> try: <TAB> <TAB> return function_in(*args, **kwargs) <TAB> except dbus.exceptions.DBusException as e: <TAB> <TAB> if e.get_dbus_name() == DBUS_UNKNOWN_METHOD: <TAB> <TAB> <TAB> raise ItemNotFoundException(""Item does not exist!"") <TAB> <TAB> if e.get_dbus_name() == DBUS_NO_SUCH_OBJECT: <TAB> <TAB> <TAB> raise ItemNotFoundException(e.get_dbus_message()) <TAB> <TAB> if e.get_dbus_name() in (DBUS_NO_REPLY, DBUS_NOT_SUPPORTED): <TAB> <TAB> <TAB> raise SecretServiceNotAvailableException(e.get_dbus_message()) <TAB> <TAB> raise",false,"if e . get_dbus_name ( ) in ( DBUS_NO_REPLY , DBUS_NOT_SUPPORTED ) :",if e . get_dbus_name ( ) == DBUS_UNKNOWN_METHOD :,0.28,0.0
"def results_iter(self): <TAB> if self.connection.ops.oracle: <TAB> <TAB> from django.db.models.fields import DateTimeField <TAB> <TAB> fields = [DateTimeField()] <TAB> else: <TAB> <TAB> needs_string_cast = self.connection.features.needs_datetime_string_cast <TAB> offset = len(self.query.extra_select) <TAB> for rows in self.execute_sql(MULTI): <TAB> <TAB> for row in rows: <TAB> <TAB> <TAB> date = row[offset] <TAB> <TAB> <TAB> if self.connection.ops.oracle: <TAB> <TAB> <TAB> <TAB> date = self.resolve_columns(row, fields)[offset] <TAB> <TAB> <TAB> elif needs_string_cast: <TAB> <TAB> <TAB> <TAB> date = typecast_timestamp(str(date)) <TAB> <TAB> <TAB> yield date",true,elif needs_string_cast :,elif needs_string_cast :,0.51,0.0
"def handle_label(self, path, **options): <TAB> verbosity = int(options.get(""verbosity"", 1)) <TAB> result = finders.find(path, all=options[""all""]) <TAB> path = smart_unicode(path) <TAB> if result: <TAB> <TAB> if not isinstance(result, (list, tuple)): <TAB> <TAB> <TAB> result = [result] <TAB> <TAB> output = u""\n  "".join( <TAB> <TAB> <TAB> (smart_unicode(os.path.realpath(path)) for path in result) <TAB> <TAB> ) <TAB> <TAB> self.stdout.write(smart_str(u""Found '%s' here:\n  %s\n"" % (path, output))) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.stderr.write(smart_str(""No matching file found for '%s'.\n"" % path))",false,if verbosity >= 1 :,if verbosity < 1 :,0.33,0.0
"def name(self): <TAB> """"""Get the enumeration name of this storage class."""""" <TAB> if self._name_map is None: <TAB> <TAB> self._name_map = {} <TAB> <TAB> for key, value in list(StorageClass.__dict__.items()): <TAB> <TAB> <TAB> if isinstance(value, StorageClass): <TAB> <TAB> <TAB> <TAB> self._name_map[value] = key <TAB> return self._name_map[self]",true,"if isinstance ( value , StorageClass ) :","if isinstance ( value , StorageClass ) :",0.75,0.0
"def index(self, value): <TAB> if self._growing: <TAB> <TAB> if self._start <= value < self._stop: <TAB> <TAB> <TAB> q, r = divmod(value - self._start, self._step) <TAB> <TAB> <TAB> if r == self._zero: <TAB> <TAB> <TAB> <TAB> return int(q) <TAB> else: <TAB> <TAB> if self._start >= value > self._stop: <TAB> <TAB> <TAB> q, r = divmod(self._start - value, -self._step) <TAB> <TAB> <TAB> if r == self._zero: <TAB> <TAB> <TAB> <TAB> return int(q) <TAB> raise ValueError(""{} is not in numeric range"".format(value))",false,if self . _start >= value > self . _stop :,if r == self . _zero :,0.07,0.0
"def extract_cookie(cookie_header, cookie_name): <TAB> inx = cookie_header.find(cookie_name) <TAB> if inx >= 0: <TAB> <TAB> end_inx = cookie_header.find("";"", inx) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> value = cookie_header[inx:end_inx] <TAB> <TAB> else: <TAB> <TAB> <TAB> value = cookie_header[inx:] <TAB> <TAB> return value <TAB> return """"",false,if end_inx > 0 :,if end_inx >= 0 :,0.33,0.0
"def get_size(self, shape_info): <TAB> # The size is the data, that have constant size. <TAB> state = np.random.RandomState().get_state() <TAB> size = 0 <TAB> for elem in state: <TAB> <TAB> if isinstance(elem, str): <TAB> <TAB> <TAB> size += len(elem) <TAB> <TAB> elif isinstance(elem, np.ndarray): <TAB> <TAB> <TAB> size += elem.size * elem.itemsize <TAB> <TAB> elif isinstance(elem, int): <TAB> <TAB> <TAB> size += np.dtype(""int"").itemsize <TAB> <TAB> elif isinstance(elem, float): <TAB> <TAB> <TAB> size += np.dtype(""float"").itemsize <TAB> <TAB> else: <TAB> <TAB> <TAB> raise NotImplementedError() <TAB> return size",true,"elif isinstance ( elem , np . ndarray ) :","elif isinstance ( elem , np . ndarray ) :",0.75,0.0
"def createFields(self): <TAB> size = self.size / 8 <TAB> if size > 2: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield UInt8(self, ""cs"", ""10ms units, values from 0 to 199"") <TAB> <TAB> yield Bits(self, ""2sec"", 5, ""seconds/2"") <TAB> <TAB> yield Bits(self, ""min"", 6, ""minutes"") <TAB> <TAB> yield Bits(self, ""hour"", 5, ""hours"") <TAB> yield Bits(self, ""day"", 5, ""(1-31)"") <TAB> yield Bits(self, ""month"", 4, ""(1-12)"") <TAB> yield Bits(self, ""year"", 7, ""(0 = 1980, 127 = 2107)"")",false,if size > 4 :,if size == 1 :,0.31,0.0
"def detect(get_page): <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS: <TAB> <TAB> page, headers, code = get_page(get=vector) <TAB> <TAB> retval = ( <TAB> <TAB> <TAB> re.search( <TAB> <TAB> <TAB> <TAB> r""incap_ses|visid_incap"", headers.get(HTTP_HEADER.SET_COOKIE, """"), re.I <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB> retval |= re.search(r""Incapsula"", headers.get(""X-CDN"", """"), re.I) is not None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> return retval",true,if retval :,if retval :,0.53,0.0
"def _get_order_information(self, node_id, timeout=1200, check_interval=5): <TAB> mask = { <TAB> <TAB> ""billingItem"": """", <TAB> <TAB> ""powerState"": """", <TAB> <TAB> ""operatingSystem"": {""passwords"": """"}, <TAB> <TAB> ""provisionDate"": """", <TAB> } <TAB> for i in range(0, timeout, check_interval): <TAB> <TAB> res = self.connection.request( <TAB> <TAB> <TAB> ""SoftLayer_Virtual_Guest"", ""getObject"", id=node_id, object_mask=mask <TAB> <TAB> ).object <TAB> <TAB> if res.get(""provisionDate"", None): <TAB> <TAB> <TAB> return res <TAB> <TAB> time.sleep(check_interval) <TAB> raise SoftLayerException(""Timeout on getting node details"")",true,"if res . get ( ""provisionDate"" , None ) :","if res . get ( ""provisionDate"" , None ) :",0.75,0.0
"def _process_param_change(self, msg): <TAB> msg = super(Select, self)._process_param_change(msg) <TAB> labels, values = self.labels, self.values <TAB> if ""value"" in msg: <TAB> <TAB> msg[""value""] = [ <TAB> <TAB> <TAB> labels[indexOf(v, values)] for v in msg[""value""] if isIn(v, values) <TAB> <TAB> ] <TAB> if ""options"" in msg: <TAB> <TAB> msg[""options""] = labels <TAB> <TAB> if any(not isIn(v, values) for v in self.value): <TAB> <TAB> <TAB> self.value = [v for v in self.value if isIn(v, values)] <TAB> return msg",true,"if any ( not isIn ( v , values ) for v in self . value ) :","if any ( not isIn ( v , values ) for v in self . value ) :",1.0,0.0
"def get_object_from_name(self, name, check_symlinks=True): <TAB> if not name: <TAB> <TAB> return None <TAB> name = name.rstrip(""\\"") <TAB> for a, o in self.objects.items(): <TAB> <TAB> if not o.name: <TAB> <TAB> <TAB> continue <TAB> <TAB> if o.name.lower() == name.lower(): <TAB> <TAB> <TAB> return o <TAB> if check_symlinks: <TAB> <TAB> m = [sl[1] for sl in self.symlinks if name.lower() == sl[0].lower()] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> name = m[0] <TAB> <TAB> return self.get_object_from_name(name, False)",false,if m :,if len ( m ) == 1 :,0.05,0.0
"def run(self): <TAB> for k, v in iteritems(self.objs): <TAB> <TAB> if k.startswith(""_""): <TAB> <TAB> <TAB> continue <TAB> <TAB> if v[""_class""] == ""User"": <TAB> <TAB> <TAB> if v[""email""] == """": <TAB> <TAB> <TAB> <TAB> v[""email""] = None <TAB> <TAB> <TAB> if v[""ip""] == ""0.0.0.0"": <TAB> <TAB> <TAB> <TAB> v[""ip""] = None <TAB> return self.objs",false,"if k . startswith ( ""_"" ) :","if v [ ""ip"" ] == ""0.0.0.0"" :",0.02,0.0
"def _providers(self, descriptor): <TAB> res = [] <TAB> for _md in self.metadata.values(): <TAB> <TAB> for ent_id, ent_desc in _md.items(): <TAB> <TAB> <TAB> if descriptor in ent_desc: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> # print(""duplicated entity_id: %s"" % res) <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> res.append(ent_id) <TAB> return res",false,if ent_id in res :,if res :,0.07,0.0
"def test_add_participant(self): <TAB> async with self.chat_client: <TAB> <TAB> await self._create_thread() <TAB> <TAB> async with self.chat_thread_client: <TAB> <TAB> <TAB> share_history_time = datetime.utcnow() <TAB> <TAB> <TAB> share_history_time = share_history_time.replace(tzinfo=TZ_UTC) <TAB> <TAB> <TAB> new_participant = ChatThreadParticipant( <TAB> <TAB> <TAB> <TAB> user=self.new_user, <TAB> <TAB> <TAB> <TAB> display_name=""name"", <TAB> <TAB> <TAB> <TAB> share_history_time=share_history_time, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> await self.chat_thread_client.add_participant(new_participant) <TAB> <TAB> if not self.is_playback(): <TAB> <TAB> <TAB> await self.chat_client.delete_chat_thread(self.thread_id)",true,if not self . is_playback ( ) :,if not self . is_playback ( ) :,0.75,0.0
"def url(regex, view, kwargs=None, name=None, prefix=""""): <TAB> if isinstance(view, (list, tuple)): <TAB> <TAB> # For include(...) processing. <TAB> <TAB> urlconf_module, app_name, namespace = view <TAB> <TAB> return RegexURLResolver( <TAB> <TAB> <TAB> regex, urlconf_module, kwargs, app_name=app_name, namespace=namespace <TAB> <TAB> ) <TAB> else: <TAB> <TAB> if isinstance(view, basestring): <TAB> <TAB> <TAB> if not view: <TAB> <TAB> <TAB> <TAB> raise ImproperlyConfigured( <TAB> <TAB> <TAB> <TAB> <TAB> ""Empty URL pattern view name not permitted (for pattern %r)"" % regex <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> view = prefix + ""."" + view <TAB> <TAB> return RegexURLPattern(regex, view, kwargs, name)",true,if prefix :,if prefix :,0.53,0.0
"def tx(): <TAB> # Sync receiver ready to avoid loss of first packets <TAB> while not sub_ready.ready(): <TAB> <TAB> pub.send(b""test BEGIN"") <TAB> <TAB> eventlet.sleep(0.005) <TAB> for i in range(1, 101): <TAB> <TAB> msg = ""test {0}"".format(i).encode() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> pub.send(msg) <TAB> <TAB> else: <TAB> <TAB> <TAB> pub.send(b""test LAST"") <TAB> <TAB> <TAB> sub_last.wait() <TAB> <TAB> # XXX: putting a real delay of 1ms here fixes sporadic failures on Travis <TAB> <TAB> # just yield eventlet.sleep(0) doesn't cut it <TAB> <TAB> eventlet.sleep(0.001) <TAB> pub.send(b""done DONE"")",false,if i != 50 :,if i % 2 == 0 :,0.14,0.0
"def remove_tmp_snapshot_file(self, files): <TAB> for filepath in files: <TAB> <TAB> path = Path(filepath) <TAB> <TAB> if path.is_dir() and path.exists(): <TAB> <TAB> <TAB> shutil.rmtree(path) <TAB> <TAB> elif path.is_file() and path.exists(): <TAB> <TAB> <TAB> path.unlink()",false,elif path . is_file ( ) and path . exists ( ) :,if path . is_dir ( ) and path . exists ( ) :,0.73,0.0
"def f(view, s): <TAB> if mode == modes.INTERNAL_NORMAL: <TAB> <TAB> if count == 1: <TAB> <TAB> <TAB> if view.line(s.b).size() > 0: <TAB> <TAB> <TAB> <TAB> eol = view.line(s.b).b <TAB> <TAB> <TAB> <TAB> return R(s.b, eol) <TAB> <TAB> <TAB> return s <TAB> return s",true,if view . line ( s . b ) . size ( ) > 0 :,if view . line ( s . b ) . size ( ) > 0 :,0.75,0.0
"def get_ids(self, **kwargs): <TAB> id = [] <TAB> if ""id"" in kwargs: <TAB> <TAB> id = kwargs[""id""] <TAB> <TAB> # Coerce ids to list <TAB> <TAB> if not isinstance(id, list): <TAB> <TAB> <TAB> id = id.split("","") <TAB> <TAB> # Ensure ids are integers <TAB> <TAB> try: <TAB> <TAB> <TAB> id = list(map(int, id)) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> decorators.error(""Invalid id"") <TAB> return id",true,"if not isinstance ( id , list ) :","if not isinstance ( id , list ) :",0.75,0.0
"def param_value(self): <TAB> # This is part of the ""handle quoted extended parameters"" hack. <TAB> for token in self: <TAB> <TAB> if token.token_type == ""value"": <TAB> <TAB> <TAB> return token.stripped_value <TAB> <TAB> if token.token_type == ""quoted-string"": <TAB> <TAB> <TAB> for token in token: <TAB> <TAB> <TAB> <TAB> if token.token_type == ""bare-quoted-string"": <TAB> <TAB> <TAB> <TAB> <TAB> for token in token: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if token.token_type == ""value"": <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return token.stripped_value <TAB> return """"",true,"if token . token_type == ""value"" :","if token . token_type == ""value"" :",0.75,0.0
"def get_all_start_methods(self): <TAB> if sys.platform == ""win32"": <TAB> <TAB> return [""spawn""] <TAB> else: <TAB> <TAB> methods = [""spawn"", ""fork""] if sys.platform == ""darwin"" else [""fork"", ""spawn""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> methods.append(""forkserver"") <TAB> <TAB> return methods",false,if reduction . HAVE_SEND_HANDLE :,"if ""forkserver"" in self . config :",0.03,0.0
"def _process_watch(self, watched_event): <TAB> logger.debug(""process_watch: %r"", watched_event) <TAB> with handle_exception(self._tree._error_listeners): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> assert self._parent is None, ""unexpected CREATED on non-root"" <TAB> <TAB> <TAB> self.on_created() <TAB> <TAB> elif watched_event.type == EventType.DELETED: <TAB> <TAB> <TAB> self.on_deleted() <TAB> <TAB> elif watched_event.type == EventType.CHANGED: <TAB> <TAB> <TAB> self._refresh_data() <TAB> <TAB> elif watched_event.type == EventType.CHILD: <TAB> <TAB> <TAB> self._refresh_children()",true,if watched_event . type == EventType . CREATED :,if watched_event . type == EventType . CREATED :,0.75,0.0
"def assert_open(self, sock, *rest): <TAB> if isinstance(sock, fd_types): <TAB> <TAB> self.__assert_fd_open(sock) <TAB> else: <TAB> <TAB> fileno = sock.fileno() <TAB> <TAB> assert isinstance(fileno, fd_types), fileno <TAB> <TAB> sockname = sock.getsockname() <TAB> <TAB> assert isinstance(sockname, tuple), sockname <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.__assert_fd_open(fileno) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._assert_sock_open(sock) <TAB> if rest: <TAB> <TAB> self.assert_open(rest[0], *rest[1:])",false,if not WIN :,if fileno :,0.05,0.0
"def detype(self): <TAB> """"""De-types the instance, allowing it to be exported to the environment."""""" <TAB> style = self.style <TAB> if self._detyped is None: <TAB> <TAB> self._detyped = "":"".join( <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> key <TAB> <TAB> <TAB> <TAB> + ""="" <TAB> <TAB> <TAB> <TAB> + "";"".join( <TAB> <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> LsColors.target_value <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if key in self._targets <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> else ansi_color_name_to_escape_code(v, cmap=style) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> for v in val <TAB> <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> for key, val in sorted(self._d.items()) <TAB> <TAB> <TAB> ] <TAB> <TAB> ) <TAB> return self._detyped",true,if key in self . _targets,if key in self . _targets,0.75,0.0
"def gather_metrics(dry_run=False): <TAB> today = datetime.date.today() <TAB> first = today.replace(day=1) <TAB> last_month = first - datetime.timedelta(days=1) <TAB> filename = ""form_types_{}.csv"".format(last_month.strftime(""%Y-%m"")) <TAB> with connection.cursor() as cursor: <TAB> <TAB> cursor.execute(REGISTRATION_METRICS_SQL) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for row in cursor.fetchall(): <TAB> <TAB> <TAB> <TAB> logger.info(encode_row(row)) <TAB> <TAB> else: <TAB> <TAB> <TAB> write_raw_data(cursor=cursor, filename=filename)",true,if dry_run :,if dry_run :,0.53,0.0
"def cat(tensors, dim=0): <TAB> assert isinstance(tensors, list), ""input to cat must be a list"" <TAB> if len(tensors) == 1: <TAB> <TAB> return tensors[0] <TAB> from .autograd_cryptensor import AutogradCrypTensor <TAB> if any(isinstance(t, AutogradCrypTensor) for t in tensors): <TAB> <TAB> if not isinstance(tensors[0], AutogradCrypTensor): <TAB> <TAB> <TAB> tensors[0] = AutogradCrypTensor(tensors[0], requires_grad=False) <TAB> <TAB> return tensors[0].cat(*tensors[1:], dim=dim) <TAB> else: <TAB> <TAB> return get_default_backend().cat(tensors, dim=dim)",true,"if not isinstance ( tensors [ 0 ] , AutogradCrypTensor ) :","if not isinstance ( tensors [ 0 ] , AutogradCrypTensor ) :",0.75,0.0
"def is_installed(self, dlc_title="""") -> bool: <TAB> installed = False <TAB> if dlc_title: <TAB> <TAB> dlc_version = self.get_dlc_info(""version"", dlc_title) <TAB> <TAB> installed = True if dlc_version else False <TAB> <TAB> # Start: Code for compatibility with minigalaxy 1.0 <TAB> <TAB> if not installed: <TAB> <TAB> <TAB> status = self.legacy_get_dlc_status(dlc_title) <TAB> <TAB> <TAB> installed = True if status in [""installed"", ""updatable""] else False <TAB> <TAB> # End: Code for compatibility with minigalaxy 1.0 <TAB> else: <TAB> <TAB> if self.install_dir and os.path.exists(self.install_dir): <TAB> <TAB> <TAB> installed = True <TAB> return installed",true,if self . install_dir and os . path . exists ( self . install_dir ) :,if self . install_dir and os . path . exists ( self . install_dir ) :,0.75,0.0
"def on_copy(self): <TAB> source_objects = self.__getSelection() <TAB> for source in source_objects: <TAB> <TAB> if isinstance(source, model.Phrase): <TAB> <TAB> <TAB> new_obj = model.Phrase("""", """") <TAB> <TAB> else: <TAB> <TAB> <TAB> new_obj = model.Script("""", """") <TAB> <TAB> new_obj.copy(source) <TAB> <TAB> self.cutCopiedItems.append(new_obj)",true,"if isinstance ( source , model . Phrase ) :","if isinstance ( source , model . Phrase ) :",0.75,0.0
"def FetchFn(type_name): <TAB> """"""Fetches all hunt results of a given type."""""" <TAB> offset = 0 <TAB> while True: <TAB> <TAB> results = data_store.REL_DB.ReadHuntResults( <TAB> <TAB> <TAB> hunt_id, offset=offset, count=self._RESULTS_PAGE_SIZE, with_type=type_name <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> for r in results: <TAB> <TAB> <TAB> msg = r.AsLegacyGrrMessage() <TAB> <TAB> <TAB> msg.source_urn = source_urn <TAB> <TAB> <TAB> yield msg <TAB> <TAB> offset += self._RESULTS_PAGE_SIZE",true,if not results :,if not results :,0.75,0.0
"def get_blob_type_declaration_sql(self, column): <TAB> length = column.get(""length"") <TAB> if length: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ""TINYBLOB"" <TAB> <TAB> if length <= self.LENGTH_LIMIT_BLOB: <TAB> <TAB> <TAB> return ""BLOB"" <TAB> <TAB> if length <= self.LENGTH_LIMIT_MEDIUMBLOB: <TAB> <TAB> <TAB> return ""MEDIUMBLOB"" <TAB> return ""LONGBLOB""",true,if length <= self . LENGTH_LIMIT_TINYBLOB :,if length <= self . LENGTH_LIMIT_TINYBLOB :,0.75,0.0
"def decode(cls, data): <TAB> while data: <TAB> <TAB> ( <TAB> <TAB> <TAB> length, <TAB> <TAB> <TAB> atype, <TAB> <TAB> ) = unpack(cls.Header.PACK, data[: cls.Header.LEN]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise AttributesError(""Buffer underrun %d < %d"" % (len(data), length)) <TAB> <TAB> payload = data[cls.Header.LEN : length] <TAB> <TAB> yield atype, payload <TAB> <TAB> data = data[int((length + 3) / 4) * 4 :]",false,if len ( data ) < length :,if length < 0 :,0.02,0.0
"def test_join_diffs(db, series_of_diffs, expected): <TAB> diffs = [] <TAB> for changes in series_of_diffs: <TAB> <TAB> tracker = DBDiffTracker() <TAB> <TAB> for key, val in changes.items(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> del tracker[key] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> tracker[key] = val <TAB> <TAB> diffs.append(tracker.diff()) <TAB> DBDiff.join(diffs).apply_to(db) <TAB> assert db == expected",true,if val is None :,if val is None :,0.75,0.0
"def ant_map(m): <TAB> tmp = ""rows %s\ncols %s\n"" % (len(m), len(m[0])) <TAB> players = {} <TAB> for row in m: <TAB> <TAB> tmp += ""m "" <TAB> <TAB> for col in row: <TAB> <TAB> <TAB> if col == LAND: <TAB> <TAB> <TAB> <TAB> tmp += ""."" <TAB> <TAB> <TAB> elif col == BARRIER: <TAB> <TAB> <TAB> <TAB> tmp += ""%"" <TAB> <TAB> <TAB> elif col == FOOD: <TAB> <TAB> <TAB> <TAB> tmp += ""*"" <TAB> <TAB> <TAB> elif col == UNSEEN: <TAB> <TAB> <TAB> <TAB> tmp += ""?"" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> players[col] = True <TAB> <TAB> <TAB> <TAB> tmp += chr(col + 97) <TAB> <TAB> tmp += ""\n"" <TAB> tmp = (""players %s\n"" % len(players)) + tmp <TAB> return tmp",false,elif col == UNSEEN :,elif col == FOOD :,0.64,0.0
"def _report_error(self, completion_routine, response=None, message=None): <TAB> if response: <TAB> <TAB> # Only include the text in case of error. <TAB> <TAB> if not response.ok: <TAB> <TAB> <TAB> status = location.Status(response.status_code, response.text) <TAB> <TAB> else: <TAB> <TAB> <TAB> status = location.Status(response.status_code) <TAB> else: <TAB> <TAB> status = location.Status(500, message) <TAB> if response is None or not response.ok: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return completion_routine(status) <TAB> <TAB> raise IOError(response.text) <TAB> else: <TAB> <TAB> if completion_routine: <TAB> <TAB> <TAB> completion_routine(status) <TAB> return location.Status(200, response.content)",true,if completion_routine :,if completion_routine :,0.53,0.0
"def _generate_examples(self, src_path=None, tgt_path=None, replace_unk=None): <TAB> """"""Yields examples."""""" <TAB> with tf.io.gfile.GFile(src_path) as f_d, tf.io.gfile.GFile(tgt_path) as f_s: <TAB> <TAB> for i, (doc_text, sum_text) in enumerate(zip(f_d, f_s)): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> yield i, { <TAB> <TAB> <TAB> <TAB> <TAB> _DOCUMENT: doc_text.strip().replace("""", ""UNK""), <TAB> <TAB> <TAB> <TAB> <TAB> _SUMMARY: sum_text.strip().replace("""", ""UNK""), <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> yield i, {_DOCUMENT: doc_text.strip(), _SUMMARY: sum_text.strip()}",true,if replace_unk :,if replace_unk :,0.53,0.0
"def escape(text, newline=False): <TAB> """"""Escape special html characters."""""" <TAB> if isinstance(text, str): <TAB> <TAB> if ""&"" in text: <TAB> <TAB> <TAB> text = text.replace(""&"", ""&amp;"") <TAB> <TAB> if "">"" in text: <TAB> <TAB> <TAB> text = text.replace("">"", ""&gt;"") <TAB> <TAB> if ""<"" in text: <TAB> <TAB> <TAB> text = text.replace(""<"", ""&lt;"") <TAB> <TAB> if '""' in text: <TAB> <TAB> <TAB> text = text.replace('""', ""&quot;"") <TAB> <TAB> if ""'"" in text: <TAB> <TAB> <TAB> text = text.replace(""'"", ""&quot;"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if ""\n"" in text: <TAB> <TAB> <TAB> <TAB> text = text.replace(""\n"", ""<br>"") <TAB> return text",true,if newline :,if newline :,0.53,0.0
"def _handle_url_click(self, event): <TAB> url = _extract_click_text(self.info_text, event, ""url"") <TAB> if url is not None: <TAB> <TAB> if url.startswith(""http:"") or url.startswith(""https:""): <TAB> <TAB> <TAB> import webbrowser <TAB> <TAB> <TAB> webbrowser.open(url) <TAB> <TAB> elif os.path.sep in url: <TAB> <TAB> <TAB> os.makedirs(url, exist_ok=True) <TAB> <TAB> <TAB> open_path_in_system_file_manager(url) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._start_show_package_info(url)",false,"if url . startswith ( ""http:"" ) or url . startswith ( ""https:"" ) :",elif os . path . sep in url :,0.01,0.0
"def SConsignFile(self, name="".sconsign"", dbm_module=None): <TAB> if name is not None: <TAB> <TAB> name = self.subst(name) <TAB> <TAB> if not os.path.isabs(name): <TAB> <TAB> <TAB> name = os.path.join(str(self.fs.SConstruct_dir), name) <TAB> if name: <TAB> <TAB> name = os.path.normpath(name) <TAB> <TAB> sconsign_dir = os.path.dirname(name) <TAB> <TAB> if sconsign_dir and not os.path.exists(sconsign_dir): <TAB> <TAB> <TAB> self.Execute(SCons.Defaults.Mkdir(sconsign_dir)) <TAB> SCons.SConsign.File(name, dbm_module)",false,if not os . path . isabs ( name ) :,if sconsign_dir and not os . path . exists ( sconsign_dir ) :,0.32,0.0
"def on_train_start(self, trainer: Trainer, pl_module: LightningModule) -> None: <TAB> super().on_train_start(trainer, pl_module) <TAB> submodule_dict = dict(pl_module.named_modules()) <TAB> self._hook_handles = [] <TAB> for name in self._get_submodule_names(pl_module): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> rank_zero_warn( <TAB> <TAB> <TAB> <TAB> f""{name} is not a valid identifier for a submodule in {pl_module.__class__.__name__},"" <TAB> <TAB> <TAB> <TAB> "" skipping this key."" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> handle = self._register_hook(name, submodule_dict[name]) <TAB> <TAB> self._hook_handles.append(handle)",true,if name not in submodule_dict :,if name not in submodule_dict :,0.75,0.0
"def validate_configuration(self, configuration: Optional[ExpectationConfiguration]): <TAB> super().validate_configuration(configuration) <TAB> if configuration is None: <TAB> <TAB> configuration = self.configuration <TAB> try: <TAB> <TAB> assert ""value_set"" in configuration.kwargs, ""value_set is required"" <TAB> <TAB> assert isinstance( <TAB> <TAB> <TAB> configuration.kwargs[""value_set""], (list, set, dict) <TAB> <TAB> ), ""value_set must be a list or a set"" <TAB> <TAB> if isinstance(configuration.kwargs[""value_set""], dict): <TAB> <TAB> <TAB> assert ( <TAB> <TAB> <TAB> <TAB> ""$PARAMETER"" in configuration.kwargs[""value_set""] <TAB> <TAB> <TAB> ), 'Evaluation Parameter dict for value_set kwarg must have ""$PARAMETER"" key.' <TAB> except AssertionError as e: <TAB> <TAB> raise InvalidExpectationConfigurationError(str(e)) <TAB> return True",true,"if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :","if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :",0.75,0.0
"def check_refcounts(expected, timeout=10): <TAB> start = time.time() <TAB> while True: <TAB> <TAB> try: <TAB> <TAB> <TAB> _check_refcounts(expected) <TAB> <TAB> <TAB> break <TAB> <TAB> except AssertionError as e: <TAB> <TAB> <TAB> if time.time() - start > timeout: <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> time.sleep(0.1)",true,if time . time ( ) - start > timeout :,if time . time ( ) - start > timeout :,1.0,0.0
"def pickline(file, key, casefold=1): <TAB> try: <TAB> <TAB> f = open(file, ""r"") <TAB> except IOError: <TAB> <TAB> return None <TAB> pat = re.escape(key) + "":"" <TAB> prog = re.compile(pat, casefold and re.IGNORECASE) <TAB> while 1: <TAB> <TAB> line = f.readline() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> if prog.match(line): <TAB> <TAB> <TAB> text = line[len(key) + 1 :] <TAB> <TAB> <TAB> while 1: <TAB> <TAB> <TAB> <TAB> line = f.readline() <TAB> <TAB> <TAB> <TAB> if not line or not line[0].isspace(): <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> text = text + line <TAB> <TAB> <TAB> return text.strip() <TAB> return None",true,if not line :,if not line :,0.75,0.0
"def _is_perf_file(file_path): <TAB> f = get_file(file_path) <TAB> for line in f: <TAB> <TAB> if line[0] == ""#"": <TAB> <TAB> <TAB> continue <TAB> <TAB> r = event_regexp.search(line) <TAB> <TAB> if r: <TAB> <TAB> <TAB> f.close() <TAB> <TAB> <TAB> return True <TAB> <TAB> f.close() <TAB> <TAB> return False",true,"if line [ 0 ] == ""#"" :","if line [ 0 ] == ""#"" :",0.75,0.0
"def link_pantsrefs(soups, precomputed): <TAB> """"""Transorm soups: <a pantsref=""foo""> becomes <a href=""../foo_page.html#foo"">"""""" <TAB> for (page, soup) in soups.items(): <TAB> <TAB> for a in soup.find_all(""a""): <TAB> <TAB> <TAB> if not a.has_attr(""pantsref""): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> pantsref = a[""pantsref""] <TAB> <TAB> <TAB> if pantsref not in precomputed.pantsref: <TAB> <TAB> <TAB> <TAB> raise TaskError( <TAB> <TAB> <TAB> <TAB> <TAB> f'Page {page} has pantsref ""{pantsref}"" and I cannot find pantsmark for it' <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> a[""href""] = rel_href(page, precomputed.pantsref[pantsref])",true,"if not a . has_attr ( ""pantsref"" ) :","if not a . has_attr ( ""pantsref"" ) :",0.75,0.0
"def __init__(self, querylist=None): <TAB> self.query_id = -1 <TAB> if querylist is None: <TAB> <TAB> self.querylist = [] <TAB> else: <TAB> <TAB> self.querylist = querylist <TAB> <TAB> for query in self.querylist: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.query_id = query.query_id <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> if self.query_id != query.query_id: <TAB> <TAB> <TAB> <TAB> <TAB> raise ValueError(""query in list must be same query_id"")",false,if self . query_id == - 1 :,if query . query_id is not None :,0.04,0.0
"def _draw_number( <TAB> screen, x_offset, y_offset, number, token=Token.Clock, transparent=False ): <TAB> ""Write number at position."" <TAB> fg = Char("" "", token) <TAB> bg = Char("" "", Token) <TAB> for y, row in enumerate(_numbers[number]): <TAB> <TAB> screen_row = screen.data_buffer[y + y_offset] <TAB> <TAB> for x, n in enumerate(row): <TAB> <TAB> <TAB> if n == ""#"": <TAB> <TAB> <TAB> <TAB> screen_row[x + x_offset] = fg <TAB> <TAB> <TAB> elif not transparent: <TAB> <TAB> <TAB> <TAB> screen_row[x + x_offset] = bg",false,"if n == ""#"" :",elif not transparent :,0.03,0.0
"def init(self): <TAB> self.sock.setblocking(True) <TAB> if self.parser is None: <TAB> <TAB> # wrap the socket if needed <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.sock = ssl.wrap_socket( <TAB> <TAB> <TAB> <TAB> self.sock, server_side=True, **self.cfg.ssl_options <TAB> <TAB> <TAB> ) <TAB> <TAB> # initialize the parser <TAB> <TAB> self.parser = http.RequestParser(self.cfg, self.sock)",false,if self . cfg . is_ssl :,if self . cfg . ssl_options :,0.57,0.0
"def intersect_face(pt): <TAB> # todo: rewrite! inefficient! <TAB> nonlocal vis_faces2D <TAB> for f, vs in vis_faces2D: <TAB> <TAB> v0 = vs[0] <TAB> <TAB> for v1, v2 in iter_pairs(vs[1:], False): <TAB> <TAB> <TAB> if intersect_point_tri_2d(pt, v0, v1, v2): <TAB> <TAB> <TAB> <TAB> return f <TAB> return None",true,"if intersect_point_tri_2d ( pt , v0 , v1 , v2 ) :","if intersect_point_tri_2d ( pt , v0 , v1 , v2 ) :",0.75,0.0
"def IMPORTFROM(self, node): <TAB> if node.module == ""__future__"": <TAB> <TAB> if not self.futuresAllowed: <TAB> <TAB> <TAB> self.report(messages.LateFutureImport, node, [n.name for n in node.names]) <TAB> else: <TAB> <TAB> self.futuresAllowed = False <TAB> for alias in node.names: <TAB> <TAB> if alias.name == ""*"": <TAB> <TAB> <TAB> self.scope.importStarred = True <TAB> <TAB> <TAB> self.report(messages.ImportStarUsed, node, node.module) <TAB> <TAB> <TAB> continue <TAB> <TAB> name = alias.asname or alias.name <TAB> <TAB> importation = Importation(name, node) <TAB> <TAB> if node.module == ""__future__"": <TAB> <TAB> <TAB> importation.used = (self.scope, node) <TAB> <TAB> self.addBinding(node, importation)",true,"if alias . name == ""*"" :","if alias . name == ""*"" :",0.75,0.0
"def PyObject_Bytes(obj): <TAB> if type(obj) == bytes: <TAB> <TAB> return obj <TAB> if hasattr(obj, ""__bytes__""): <TAB> <TAB> res = obj.__bytes__() <TAB> <TAB> if not isinstance(res, bytes): <TAB> <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> <TAB> ""__bytes__ returned non-bytes (type %s)"" % type(res).__name__ <TAB> <TAB> <TAB> ) <TAB> return PyBytes_FromObject(obj)",true,"if not isinstance ( res , bytes ) :","if not isinstance ( res , bytes ) :",0.75,0.0
"def on_bt_search_clicked(self, widget): <TAB> if self.current_provider is None: <TAB> <TAB> return <TAB> query = self.en_query.get_text() <TAB> @self.obtain_podcasts_with <TAB> def load_data(): <TAB> <TAB> if self.current_provider.kind == directory.Provider.PROVIDER_SEARCH: <TAB> <TAB> <TAB> return self.current_provider.on_search(query) <TAB> <TAB> elif self.current_provider.kind == directory.Provider.PROVIDER_URL: <TAB> <TAB> <TAB> return self.current_provider.on_url(query) <TAB> <TAB> elif self.current_provider.kind == directory.Provider.PROVIDER_FILE: <TAB> <TAB> <TAB> return self.current_provider.on_file(query)",false,elif self . current_provider . kind == directory . Provider . PROVIDER_FILE :,elif self . current_provider . kind == directory . Provider . PROVIDER_URL :,0.67,0.0
"def remove(self, name): <TAB> for s in [self.__storage(self.__category), self.__storage(None)]: <TAB> <TAB> for i, b in enumerate(s): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> del s[i] <TAB> <TAB> <TAB> <TAB> if b.persistent: <TAB> <TAB> <TAB> <TAB> <TAB> self.__save() <TAB> <TAB> <TAB> <TAB> return <TAB> raise KeyError(name)",true,if b . name == name :,if b . name == name :,1.0,0.0
"def _wrapper(data, axis=None, keepdims=False): <TAB> if not keepdims: <TAB> <TAB> return func(data, axis=axis) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> axis = axis if isinstance(axis, int) else axis[0] <TAB> <TAB> <TAB> out_shape = list(data.shape) <TAB> <TAB> <TAB> out_shape[axis] = 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> out_shape = [1 for _ in range(len(data.shape))] <TAB> <TAB> return func(data, axis=axis).reshape(out_shape)",true,if axis is not None :,if axis is not None :,0.75,0.0
"def authn_info(self): <TAB> res = [] <TAB> for astat in self.assertion.authn_statement: <TAB> <TAB> context = astat.authn_context <TAB> <TAB> try: <TAB> <TAB> <TAB> authn_instant = astat.authn_instant <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> authn_instant = """" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> aclass = context.authn_context_class_ref.text <TAB> <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> <TAB> aclass = """" <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> authn_auth = [a.text for a in context.authenticating_authority] <TAB> <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> <TAB> authn_auth = [] <TAB> <TAB> <TAB> res.append((aclass, authn_auth, authn_instant)) <TAB> return res",true,if context :,if context :,0.53,0.0
"def _persist_metadata(self, dirname, filename): <TAB> metadata_path = ""{0}/{1}.json"".format(dirname, filename) <TAB> if self.media_metadata or self.comments or self.include_location: <TAB> <TAB> if self.posts: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.merge_json({""GraphImages"": self.posts}, metadata_path) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.save_json({""GraphImages"": self.posts}, metadata_path) <TAB> <TAB> if self.stories: <TAB> <TAB> <TAB> if self.latest: <TAB> <TAB> <TAB> <TAB> self.merge_json({""GraphStories"": self.stories}, metadata_path) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.save_json({""GraphStories"": self.stories}, metadata_path)",true,if self . latest :,if self . latest :,0.75,0.0
"def update_record_image_detail(input_image_record, updated_image_detail, session=None): <TAB> if not session: <TAB> <TAB> session = db.Session <TAB> image_record = {} <TAB> image_record.update(input_image_record) <TAB> image_record.pop(""created_at"", None) <TAB> image_record.pop(""last_updated"", None) <TAB> if image_record[""image_type""] == ""docker"": <TAB> <TAB> for tag_record in updated_image_detail: <TAB> <TAB> <TAB> if tag_record not in image_record[""image_detail""]: <TAB> <TAB> <TAB> <TAB> image_record[""image_detail""].append(tag_record) <TAB> <TAB> <TAB> <TAB> return update_record(image_record, session=session) <TAB> return image_record",true,"if tag_record not in image_record [ ""image_detail"" ] :","if tag_record not in image_record [ ""image_detail"" ] :",0.75,0.0
"def backup(self): <TAB> for ds in [(""activedirectory"", ""AD""), (""ldap"", ""LDAP""), (""nis"", ""NIS"")]: <TAB> <TAB> if (self.middleware.call_sync(f""{ds[0]}.config""))[""enable""]: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> ds_cache = self.middleware.call_sync(""cache.get"", f""{ds[1]}_cache"") <TAB> <TAB> <TAB> <TAB> with open(f""/var/db/system/.{ds[1]}_cache_backup"", ""wb"") as f: <TAB> <TAB> <TAB> <TAB> <TAB> pickle.dump(ds_cache, f) <TAB> <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> <TAB> self.logger.debug(""No cache exists for directory service [%s]."", ds[0])",true,"if ( self . middleware . call_sync ( f""{ds[0]}.config"" ) ) [ ""enable"" ] :","if ( self . middleware . call_sync ( f""{ds[0]}.config"" ) ) [ ""enable"" ] :",0.75,0.0
"def parse_setup_cfg(self): <TAB> # type: () -> Dict[STRING_TYPE, Any] <TAB> if self.setup_cfg is not None and self.setup_cfg.exists(): <TAB> <TAB> contents = self.setup_cfg.read_text() <TAB> <TAB> base_dir = self.setup_cfg.absolute().parent.as_posix() <TAB> <TAB> try: <TAB> <TAB> <TAB> parsed = setuptools_parse_setup_cfg(self.setup_cfg.as_posix()) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> if six.PY2: <TAB> <TAB> <TAB> <TAB> contents = self.setup_cfg.read_bytes() <TAB> <TAB> <TAB> parsed = parse_setup_cfg(contents, base_dir) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return {} <TAB> <TAB> return parsed <TAB> return {}",false,if not parsed :,if parsed is None :,0.05,0.0
"def parts(): <TAB> for l in lists.leaves: <TAB> <TAB> head_name = l.get_head_name() <TAB> <TAB> if head_name == ""System`List"": <TAB> <TAB> <TAB> yield l.leaves <TAB> <TAB> elif head_name != ""System`Missing"": <TAB> <TAB> <TAB> raise MessageException(""Catenate"", ""invrp"", l)",false,"if head_name == ""System`List"" :","elif head_name != ""System`Missing"" :",0.03,0.0
"def _get_callback_and_order(self, hook): <TAB> if callable(hook): <TAB> <TAB> return hook, None <TAB> elif isinstance(hook, tuple) and len(hook) == 2: <TAB> <TAB> callback, order = hook <TAB> <TAB> # test that callback is a callable <TAB> <TAB> if not callable(callback): <TAB> <TAB> <TAB> raise ValueError(""Hook callback is not a callable"") <TAB> <TAB> # test that number is an int <TAB> <TAB> try: <TAB> <TAB> <TAB> int(order) <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> raise ValueError(""Hook order is not a number"") <TAB> <TAB> return callback, order <TAB> else: <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> ""Invalid hook definition, neither a callable nor a 2-tuple (callback, order): {!r}"".format( <TAB> <TAB> <TAB> <TAB> hook <TAB> <TAB> <TAB> ) <TAB> <TAB> )",true,if not callable ( callback ) :,if not callable ( callback ) :,0.75,0.0
"def _resize_masks(self, results): <TAB> """"""Resize masks with ``results['scale']``"""""" <TAB> for key in results.get(""mask_fields"", []): <TAB> <TAB> if results[key] is None: <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> results[key] = results[key].rescale(results[""scale""]) <TAB> <TAB> else: <TAB> <TAB> <TAB> results[key] = results[key].resize(results[""img_shape""][:2])",false,if self . keep_ratio :,"if ""scale"" in results :",0.03,0.0
"def getDataMax(self): <TAB> result = -Double.MAX_VALUE <TAB> nCurves = self.chart.getNCurves() <TAB> for i in range(nCurves): <TAB> <TAB> c = self.getSystemCurve(i) <TAB> <TAB> if not c.isVisible(): <TAB> <TAB> <TAB> continue <TAB> <TAB> if c.getYAxis() == Y_AXIS: <TAB> <TAB> <TAB> nPoints = c.getNPoints() <TAB> <TAB> <TAB> for j in range(nPoints): <TAB> <TAB> <TAB> <TAB> result = self.maxIgnoreNaNAndMaxValue(result, c.getPoint(j).getY()) <TAB> if result == -Double.MAX_VALUE: <TAB> <TAB> return Double.NaN <TAB> return result",true,if c . getYAxis ( ) == Y_AXIS :,if c . getYAxis ( ) == Y_AXIS :,0.75,0.0
"def _check_token(self): <TAB> if settings.app.sso_client_cache and self.server_auth_token: <TAB> <TAB> doc = self.sso_client_cache_collection.find_one( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> ""user_id"": self.user.id, <TAB> <TAB> <TAB> <TAB> ""server_id"": self.server.id, <TAB> <TAB> <TAB> <TAB> ""device_id"": self.device_id, <TAB> <TAB> <TAB> <TAB> ""device_name"": self.device_name, <TAB> <TAB> <TAB> <TAB> ""auth_token"": self.server_auth_token, <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.has_token = True",true,if doc :,if doc :,0.53,0.0
"def parse_header(plyfile, ext): <TAB> # Variables <TAB> line = [] <TAB> properties = [] <TAB> num_points = None <TAB> while b""end_header"" not in line and line != b"""": <TAB> <TAB> line = plyfile.readline() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> line = line.split() <TAB> <TAB> <TAB> num_points = int(line[2]) <TAB> <TAB> elif b""property"" in line: <TAB> <TAB> <TAB> line = line.split() <TAB> <TAB> <TAB> properties.append((line[2].decode(), ext + ply_dtypes[line[1]])) <TAB> return num_points, properties",false,"if b""element"" in line :","if b""num_points"" in line :",0.39,0.0
"def __codeanalysis_settings_changed(self, current_finfo): <TAB> if self.data: <TAB> <TAB> run_pyflakes, run_pep8 = self.pyflakes_enabled, self.pep8_enabled <TAB> <TAB> for finfo in self.data: <TAB> <TAB> <TAB> self.__update_editor_margins(finfo.editor) <TAB> <TAB> <TAB> finfo.cleanup_analysis_results() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if current_finfo is not finfo: <TAB> <TAB> <TAB> <TAB> <TAB> finfo.run_code_analysis(run_pyflakes, run_pep8)",false,if ( run_pyflakes or run_pep8 ) and current_finfo is not None :,if run_pyflakes and run_pep8 :,0.12,0.0
"def __modules(self): <TAB> raw_output = self.__module_avail_output().decode(""utf-8"") <TAB> for line in StringIO(raw_output): <TAB> <TAB> line = line and line.strip() <TAB> <TAB> if not line or line.startswith(""-""): <TAB> <TAB> <TAB> continue <TAB> <TAB> line_modules = line.split() <TAB> <TAB> for module in line_modules: <TAB> <TAB> <TAB> if module.endswith(self.default_indicator): <TAB> <TAB> <TAB> <TAB> module = module[0 : -len(self.default_indicator)].strip() <TAB> <TAB> <TAB> module_parts = module.split(""/"") <TAB> <TAB> <TAB> module_version = None <TAB> <TAB> <TAB> if len(module_parts) == 2: <TAB> <TAB> <TAB> <TAB> module_version = module_parts[1] <TAB> <TAB> <TAB> module_name = module_parts[0] <TAB> <TAB> <TAB> yield module_name, module_version",false,"if not line or line . startswith ( ""-"" ) :",if module . endswith ( self . default_indicator ) :,0.03,0.0
"def _set_trailing_size(self, size): <TAB> if self.is_free(): <TAB> <TAB> next_chunk = self.next_chunk() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.state.memory.store(next_chunk.base, size, self.state.arch.bytes)",false,if next_chunk is not None :,if next_chunk . base != - 1 :,0.04,0.0
"def _execute_for_all_tables(self, app, bind, operation, skip_tables=False): <TAB> app = self.get_app(app) <TAB> if bind == ""__all__"": <TAB> <TAB> binds = [None] + list(app.config.get(""SQLALCHEMY_BINDS"") or ()) <TAB> elif isinstance(bind, string_types) or bind is None: <TAB> <TAB> binds = [bind] <TAB> else: <TAB> <TAB> binds = bind <TAB> for bind in binds: <TAB> <TAB> extra = {} <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tables = self.get_tables_for_bind(bind) <TAB> <TAB> <TAB> extra[""tables""] = tables <TAB> <TAB> op = getattr(self.Model.metadata, operation) <TAB> <TAB> op(bind=self.get_engine(app, bind), **extra)",false,if not skip_tables :,if skip_tables :,0.1,0.0
"def getFileName(): <TAB> extension = "".json"" <TAB> file = ""%s-stats"" % self.clusterName <TAB> counter = 0 <TAB> while True: <TAB> <TAB> suffix = str(counter).zfill(3) + extension <TAB> <TAB> fullName = os.path.join(self.statsPath, file + suffix) <TAB> <TAB> if not os.path.exists(fullName): <TAB> <TAB> <TAB> return fullName <TAB> <TAB> counter += 1",true,if not os . path . exists ( fullName ) :,if not os . path . exists ( fullName ) :,0.75,0.0
def logic(): <TAB> # direction <TAB> if goRight == ACTIVE: <TAB> <TAB> dir.next = DirType.RIGHT <TAB> <TAB> run.next = True <TAB> elif goLeft == ACTIVE: <TAB> <TAB> dir.next = DirType.LEFT <TAB> <TAB> run.next = True <TAB> # stop <TAB> if stop == ACTIVE: <TAB> <TAB> run.next = False <TAB> # counter action <TAB> if run: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> q.next[4:1] = q[3:] <TAB> <TAB> <TAB> q.next[0] = not q[3] <TAB> <TAB> else: <TAB> <TAB> <TAB> q.next[3:] = q[4:1] <TAB> <TAB> <TAB> q.next[3] = not q[0],false,if dir == DirType . LEFT :,if q :,0.02,0.0
"def test_broadcast(self): <TAB> """"""Test example broadcast functionality."""""" <TAB> self.create_lang_connection(""1000000000"", ""en"") <TAB> self.create_lang_connection(""1000000001"", ""en"") <TAB> self.create_lang_connection(""1000000002"", ""en"") <TAB> self.create_lang_connection(""1000000003"", ""es"") <TAB> self.create_lang_connection(""1000000004"", ""es"") <TAB> app.lang_broadcast() <TAB> self.assertEqual(2, len(self.outbound)) <TAB> for message in self.outbound: <TAB> <TAB> if message.text == ""hello"": <TAB> <TAB> <TAB> self.assertEqual(3, len(message.connections)) <TAB> <TAB> elif message.text == ""hola"": <TAB> <TAB> <TAB> self.assertEqual(2, len(message.connections))",true,"elif message . text == ""hola"" :","elif message . text == ""hola"" :",1.0,0.0
"def get_ovf_env(dirname): <TAB> env_names = (""ovf-env.xml"", ""ovf_env.xml"", ""OVF_ENV.XML"", ""OVF-ENV.XML"") <TAB> for fname in env_names: <TAB> <TAB> full_fn = os.path.join(dirname, fname) <TAB> <TAB> if os.path.isfile(full_fn): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> contents = util.load_file(full_fn) <TAB> <TAB> <TAB> <TAB> return (fname, contents) <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> util.logexc(LOG, ""Failed loading ovf file %s"", full_fn) <TAB> return (None, False)",true,if os . path . isfile ( full_fn ) :,if os . path . isfile ( full_fn ) :,0.75,0.0
"def _calc_offsets_children(self, offset, is_last): <TAB> if self.elems: <TAB> <TAB> elem_last = self.elems[-1] <TAB> <TAB> for elem in self.elems: <TAB> <TAB> <TAB> offset = elem._calc_offsets(offset, (elem is elem_last)) <TAB> <TAB> offset += _BLOCK_SENTINEL_LENGTH <TAB> elif not self.props or self.id in _ELEMS_ID_ALWAYS_BLOCK_SENTINEL: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> offset += _BLOCK_SENTINEL_LENGTH <TAB> return offset",false,if not is_last :,if is_last :,0.1,0.0
"def publish_state(cls, payload, state): <TAB> try: <TAB> <TAB> if isinstance(payload, LiveActionDB): <TAB> <TAB> <TAB> if state == action_constants.LIVEACTION_STATUS_REQUESTED: <TAB> <TAB> <TAB> <TAB> cls.process(payload) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> worker.get_worker().process(payload) <TAB> except Exception: <TAB> <TAB> traceback.print_exc() <TAB> <TAB> print(payload)",true,"if isinstance ( payload , LiveActionDB ) :","if isinstance ( payload , LiveActionDB ) :",0.75,0.0
"def log_predictive_density(self, x_test, y_test, Y_metadata=None): <TAB> if isinstance(x_test, list): <TAB> <TAB> x_test, y_test, ind = util.multioutput.build_XY(x_test, y_test) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> Y_metadata = {""output_index"": ind, ""trials"": np.ones(ind.shape)} <TAB> return super(MultioutputGP, self).log_predictive_density(x_test, y_test, Y_metadata)",true,if Y_metadata is None :,if Y_metadata is None :,0.75,0.0
"def minimalBases(classes): <TAB> """"""Reduce a list of base classes to its ordered minimum equivalent"""""" <TAB> if not __python3:  # pragma: no cover <TAB> <TAB> classes = [c for c in classes if c is not ClassType] <TAB> candidates = [] <TAB> for m in classes: <TAB> <TAB> for n in classes: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> # m has no subclasses in 'classes' <TAB> <TAB> <TAB> if m in candidates: <TAB> <TAB> <TAB> <TAB> candidates.remove(m)  # ensure that we're later in the list <TAB> <TAB> <TAB> candidates.append(m) <TAB> return candidates",false,"if issubclass ( n , m ) and m is not n :",if n is not ClassType :,0.14,0.0
"def apply(self, operations, rotations=None, **kwargs): <TAB> rotations = rotations or [] <TAB> # apply the circuit operations <TAB> for i, operation in enumerate(operations): <TAB> <TAB> if i > 0 and isinstance(operation, (QubitStateVector, BasisState)): <TAB> <TAB> <TAB> raise DeviceError( <TAB> <TAB> <TAB> <TAB> ""Operation {} cannot be used after other Operations have already been applied "" <TAB> <TAB> <TAB> <TAB> ""on a {} device."".format(operation.name, self.short_name) <TAB> <TAB> <TAB> ) <TAB> for operation in operations: <TAB> <TAB> self._apply_operation(operation) <TAB> # store the pre-rotated state <TAB> self._pre_rotated_state = self._state <TAB> # apply the circuit rotations <TAB> for operation in rotations: <TAB> <TAB> self._apply_operation(operation)",true,"if i > 0 and isinstance ( operation , ( QubitStateVector , BasisState ) ) :","if i > 0 and isinstance ( operation , ( QubitStateVector , BasisState ) ) :",0.75,0.0
"def __str__(self): <TAB> txt = str(self._called) <TAB> if self.call_gas or self.call_value: <TAB> <TAB> gas = f""gas: {self.call_gas}"" if self.call_gas else """" <TAB> <TAB> value = f""value: {self.call_value}"" if self.call_value else """" <TAB> <TAB> salt = f""salt: {self.call_salt}"" if self.call_salt else """" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> options = [gas, value, salt] <TAB> <TAB> <TAB> txt += ""{"" + "","".join([o for o in options if o != """"]) + ""}"" <TAB> return txt + ""("" + "","".join([str(a) for a in self._arguments]) + "")""",false,if gas or value or salt :,if gas and value and salt :,0.3,0.0
"def pop(self): <TAB> """"""Pop a nonterminal.  (Internal)"""""" <TAB> popdfa, popstate, popnode = self.stack.pop() <TAB> newnode = self.convert(self.grammar, popnode) <TAB> if newnode is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> dfa, state, node = self.stack[-1] <TAB> <TAB> <TAB> node.children.append(newnode) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.rootnode = newnode",true,if self . stack :,if self . stack :,0.75,0.0
"def pollpacket(self, wait): <TAB> self._stage0() <TAB> if len(self.buffer) < self.bufneed: <TAB> <TAB> r, w, x = select.select([self.sock.fileno()], [], [], wait) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> try: <TAB> <TAB> <TAB> s = self.sock.recv(BUFSIZE) <TAB> <TAB> except socket.error: <TAB> <TAB> <TAB> raise EOFError <TAB> <TAB> if len(s) == 0: <TAB> <TAB> <TAB> raise EOFError <TAB> <TAB> self.buffer += s <TAB> <TAB> self._stage0() <TAB> return self._stage1()",false,if len ( r ) == 0 :,if r == 0 or w == 0 :,0.07,0.0
"def increaseToolReach(self): <TAB> if self.draggingFace is not None: <TAB> <TAB> d = (1, -1)[self.draggingFace & 1] <TAB> <TAB> if self.draggingFace >> 1 != 1:  # xxxxx y <TAB> <TAB> <TAB> d = -d <TAB> <TAB> self.draggingY += d <TAB> <TAB> x, y, z = self.editor.mainViewport.cameraPosition <TAB> <TAB> pos = [x, y, z] <TAB> <TAB> pos[self.draggingFace >> 1] += d <TAB> <TAB> self.editor.mainViewport.cameraPosition = tuple(pos) <TAB> else: <TAB> <TAB> self.cloneCameraDistance = self.editor._incrementReach(self.cloneCameraDistance) <TAB> return True",true,if self . draggingFace >> 1 != 1 :,if self . draggingFace >> 1 != 1 :,0.75,0.0
"def selectionToChunks(self, remove=False, add=False): <TAB> box = self.selectionBox() <TAB> if box: <TAB> <TAB> if box == self.level.bounds: <TAB> <TAB> <TAB> self.selectedChunks = set(self.level.allChunks) <TAB> <TAB> <TAB> return <TAB> <TAB> selectedChunks = self.selectedChunks <TAB> <TAB> boxedChunks = set(box.chunkPositions) <TAB> <TAB> if boxedChunks.issubset(selectedChunks): <TAB> <TAB> <TAB> remove = True <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> selectedChunks.difference_update(boxedChunks) <TAB> <TAB> else: <TAB> <TAB> <TAB> selectedChunks.update(boxedChunks) <TAB> self.selectionTool.selectNone()",false,if remove and not add :,if add :,0.05,0.0
"def __init__(self, *args, **kwargs): <TAB> super(ProjectForm, self).__init__(*args, **kwargs) <TAB> if self.instance.id: <TAB> <TAB> if Store.objects.filter(translation_project__project=self.instance).count(): <TAB> <TAB> <TAB> self.fields[""localfiletype""].widget.attrs[""disabled""] = True <TAB> <TAB> <TAB> self.fields[""localfiletype""].required = False <TAB> <TAB> if ( <TAB> <TAB> <TAB> self.instance.treestyle != ""auto"" <TAB> <TAB> <TAB> and self.instance.translationproject_set.count() <TAB> <TAB> <TAB> and self.instance.treestyle == self.instance._detect_treestyle() <TAB> <TAB> ): <TAB> <TAB> <TAB> self.fields[""treestyle""].widget.attrs[""disabled""] = True <TAB> <TAB> <TAB> self.fields[""treestyle""].required = False",true,if Store . objects . filter ( translation_project__project = self . instance ) . count ( ) :,if Store . objects . filter ( translation_project__project = self . instance ) . count ( ) :,1.0,0.0
"def _infer_return_type(*args): <TAB> """"""Look at the type of all args and divine their implied return type."""""" <TAB> return_type = None <TAB> for arg in args: <TAB> <TAB> if arg is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance(arg, bytes): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."") <TAB> <TAB> <TAB> return_type = bytes <TAB> <TAB> else: <TAB> <TAB> <TAB> if return_type is bytes: <TAB> <TAB> <TAB> <TAB> raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."") <TAB> <TAB> <TAB> return_type = str <TAB> if return_type is None: <TAB> <TAB> return str  # tempfile APIs return a str by default. <TAB> return return_type",false,if return_type is str :,if return_type is bytes :,0.39,0.0
"def deleteDuplicates(gadgets, callback=None): <TAB> toReturn = [] <TAB> inst = set() <TAB> count = 0 <TAB> added = False <TAB> len_gadgets = len(gadgets) <TAB> for i, gadget in enumerate(gadgets): <TAB> <TAB> inst.add(gadget._gadget) <TAB> <TAB> if len(inst) > count: <TAB> <TAB> <TAB> count = len(inst) <TAB> <TAB> <TAB> toReturn.append(gadget) <TAB> <TAB> <TAB> added = True <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> callback(gadget, added, float(i + 1) / (len_gadgets)) <TAB> <TAB> <TAB> added = False <TAB> return toReturn",true,if callback :,if callback :,0.53,0.0
"def send_all(self, data: bytes): <TAB> with self._conflict_detector: <TAB> <TAB> if self._handle_holder.closed: <TAB> <TAB> <TAB> raise _core.ClosedResourceError(""this pipe is already closed"") <TAB> <TAB> if not data: <TAB> <TAB> <TAB> await _core.checkpoint() <TAB> <TAB> <TAB> return <TAB> <TAB> try: <TAB> <TAB> <TAB> written = await _core.write_overlapped(self._handle_holder.handle, data) <TAB> <TAB> except BrokenPipeError as ex: <TAB> <TAB> <TAB> raise _core.BrokenResourceError from ex <TAB> <TAB> # By my reading of MSDN, this assert is guaranteed to pass so long <TAB> <TAB> # as the pipe isn't in nonblocking mode, but... let's just <TAB> <TAB> # double-check. <TAB> <TAB> assert written == len(data)",true,if self . _handle_holder . closed :,if self . _handle_holder . closed :,0.75,0.0
"def setup_parameter_node(self, param_node): <TAB> if param_node.bl_idname == ""SvNumberNode"": <TAB> <TAB> if self.use_prop or self.get_prop_name(): <TAB> <TAB> <TAB> value = self.sv_get()[0][0] <TAB> <TAB> <TAB> print(""V"", value) <TAB> <TAB> <TAB> if isinstance(value, int): <TAB> <TAB> <TAB> <TAB> param_node.selected_mode = ""int"" <TAB> <TAB> <TAB> <TAB> param_node.int_ = value <TAB> <TAB> <TAB> elif isinstance(value, float): <TAB> <TAB> <TAB> <TAB> param_node.selected_mode = ""float"" <TAB> <TAB> <TAB> <TAB> param_node.float_ = value",true,if self . use_prop or self . get_prop_name ( ) :,if self . use_prop or self . get_prop_name ( ) :,0.75,0.0
"def collect_active_inst_idx_list(inst_beams, word_prob, inst_idx_to_position_map): <TAB> active_inst_idx_list = [] <TAB> for inst_idx, inst_position in inst_idx_to_position_map.items(): <TAB> <TAB> is_inst_complete = inst_beams[inst_idx].advance(word_prob[inst_position]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> active_inst_idx_list += [inst_idx] <TAB> return active_inst_idx_list",false,if not is_inst_complete :,if is_inst_complete :,0.1,0.0
"def compare_member_req_resp_without_key(self, request, response): <TAB> for user_response in resp_json(response)[""data""]: <TAB> <TAB> for user_request in request: <TAB> <TAB> <TAB> if user_request[""user_id""] == user_response[""user_id""]: <TAB> <TAB> <TAB> <TAB> assert user_request[""role""] == user_response[""role""]",true,"if user_request [ ""user_id"" ] == user_response [ ""user_id"" ] :","if user_request [ ""user_id"" ] == user_response [ ""user_id"" ] :",0.75,0.0
"def __init__(self, dir): <TAB> self.module_names = set() <TAB> for name in os.listdir(dir): <TAB> <TAB> if name.endswith("".py""): <TAB> <TAB> <TAB> self.module_names.add(name[:-3]) <TAB> <TAB> elif ""."" not in name: <TAB> <TAB> <TAB> self.module_names.add(name)",true,"elif ""."" not in name :","elif ""."" not in name :",0.75,0.0
"def _read_filter(self, data): <TAB> if data: <TAB> <TAB> if self.expected_inner_sha256: <TAB> <TAB> <TAB> self.inner_sha.update(data) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.inner_md5.update(data) <TAB> return data",false,if self . expected_inner_md5sum :,if self . expected_inner_md5 :,0.39,0.0
"def _p_basicstr_content(s, content=_basicstr_re): <TAB> res = [] <TAB> while True: <TAB> <TAB> res.append(s.expect_re(content).group(0)) <TAB> <TAB> if not s.consume(""\\""): <TAB> <TAB> <TAB> break <TAB> <TAB> if s.consume_re(_newline_esc_re): <TAB> <TAB> <TAB> pass <TAB> <TAB> elif s.consume_re(_short_uni_re) or s.consume_re(_long_uni_re): <TAB> <TAB> <TAB> res.append(_chr(int(s.last().group(1), 16))) <TAB> <TAB> else: <TAB> <TAB> <TAB> s.expect_re(_escapes_re) <TAB> <TAB> <TAB> res.append(_escapes[s.last().group(0)]) <TAB> return """".join(res)",false,"if not s . consume ( ""\\"" ) :",if s . consume_re ( _newline_esc_re ) :,0.04,0.0
"def process_response(self, request, response): <TAB> if ( <TAB> <TAB> response.status_code == 404 <TAB> <TAB> and request.path_info.endswith(""/"") <TAB> <TAB> and not is_valid_path(request.path_info) <TAB> <TAB> and is_valid_path(request.path_info[:-1]) <TAB> ): <TAB> <TAB> # Use request.path because we munged app/locale in path_info. <TAB> <TAB> newurl = request.path[:-1] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> with safe_query_string(request): <TAB> <TAB> <TAB> <TAB> newurl += ""?"" + request.META.get(""QUERY_STRING"", """") <TAB> <TAB> return HttpResponsePermanentRedirect(newurl) <TAB> else: <TAB> <TAB> return response",false,if request . GET :,if request . query_string :,0.39,0.0
"def convertDict(obj): <TAB> obj = dict(obj) <TAB> for k, v in obj.items(): <TAB> <TAB> del obj[k] <TAB> <TAB> if not (isinstance(k, str) or isinstance(k, unicode)): <TAB> <TAB> <TAB> k = dumps(k) <TAB> <TAB> <TAB> # Keep track of which keys need to be decoded when loading. <TAB> <TAB> <TAB> if Types.KEYS not in obj: <TAB> <TAB> <TAB> <TAB> obj[Types.KEYS] = [] <TAB> <TAB> <TAB> obj[Types.KEYS].append(k) <TAB> <TAB> obj[k] = convertObjects(v) <TAB> return obj",true,"if not ( isinstance ( k , str ) or isinstance ( k , unicode ) ) :","if not ( isinstance ( k , str ) or isinstance ( k , unicode ) ) :",1.0,0.0
"def __repr__(self): <TAB> if self._in_repr: <TAB> <TAB> return ""<recursion>"" <TAB> try: <TAB> <TAB> self._in_repr = True <TAB> <TAB> if self.is_computed(): <TAB> <TAB> <TAB> status = ""computed, "" <TAB> <TAB> <TAB> if self.error() is None: <TAB> <TAB> <TAB> <TAB> if self.value() is self: <TAB> <TAB> <TAB> <TAB> <TAB> status += ""= self"" <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> status += ""= "" + repr(self.value()) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> status += ""error = "" + repr(self.error()) <TAB> <TAB> else: <TAB> <TAB> <TAB> status = ""isn't computed"" <TAB> <TAB> return ""%s (%s)"" % (type(self), status) <TAB> finally: <TAB> <TAB> self._in_repr = False",true,if self . is_computed ( ) :,if self . is_computed ( ) :,0.75,0.0
"def allocate_network(ipv=""ipv4""): <TAB> global dtcd_uuid <TAB> global network_pool <TAB> global allocations <TAB> network = None <TAB> try: <TAB> <TAB> cx = httplib.HTTPConnection(""localhost:7623"") <TAB> <TAB> cx.request(""POST"", ""/v1/network/%s/"" % ipv, body=dtcd_uuid) <TAB> <TAB> resp = cx.getresponse() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> network = netaddr.IPNetwork(resp.read().decode(""utf-8"")) <TAB> <TAB> cx.close() <TAB> except Exception: <TAB> <TAB> pass <TAB> if network is None: <TAB> <TAB> network = network_pool[ipv].pop() <TAB> <TAB> allocations[network] = True <TAB> return network",false,if resp . status == 200 :,if resp :,0.04,0.0
"def change_args_to_dict(string): <TAB> if string is None: <TAB> <TAB> return None <TAB> ans = [] <TAB> strings = string.split(""\n"") <TAB> ind = 1 <TAB> start = 0 <TAB> while ind <= len(strings): <TAB> <TAB> if ind < len(strings) and strings[ind].startswith("" ""): <TAB> <TAB> <TAB> ind += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> if start < ind: <TAB> <TAB> <TAB> <TAB> ans.append(""\n"".join(strings[start:ind])) <TAB> <TAB> <TAB> start = ind <TAB> <TAB> <TAB> ind += 1 <TAB> d = {} <TAB> for line in ans: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> lines = line.split("":"") <TAB> <TAB> <TAB> d[lines[0]] = lines[1].strip() <TAB> return d",false,"if "":"" in line and len ( line ) > 0 :","if "":"" in line :",0.1,0.0
"def kill_members(members, sig, hosts=nodes): <TAB> for member in sorted(members): <TAB> <TAB> try: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> print(""killing %s"" % member) <TAB> <TAB> <TAB> proc = hosts[member][""proc""] <TAB> <TAB> <TAB> # Not sure if cygwin makes sense here... <TAB> <TAB> <TAB> if sys.platform in (""win32"", ""cygwin""): <TAB> <TAB> <TAB> <TAB> os.kill(proc.pid, signal.CTRL_C_EVENT) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> os.kill(proc.pid, sig) <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> if ha_tools_debug: <TAB> <TAB> <TAB> <TAB> print(""%s already dead?"" % member)",true,if ha_tools_debug :,if ha_tools_debug :,0.53,0.0
"def check(self): <TAB> for path in self.paths: <TAB> <TAB> response = self.http_request( <TAB> <TAB> <TAB> method=""GET"", <TAB> <TAB> <TAB> path=path, <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if any( <TAB> <TAB> <TAB> map( <TAB> <TAB> <TAB> <TAB> lambda x: x in response.text, <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> ""report.db.server.name"", <TAB> <TAB> <TAB> <TAB> <TAB> ""report.db.server.sa.pass"", <TAB> <TAB> <TAB> <TAB> <TAB> ""report.db.server.user.pass"", <TAB> <TAB> <TAB> <TAB> ], <TAB> <TAB> <TAB> ) <TAB> <TAB> ): <TAB> <TAB> <TAB> self.valid = path <TAB> <TAB> <TAB> return True  # target is vulnerable <TAB> return False  # target not vulnerable",true,if response is None :,if response is None :,0.75,0.0
"def get_to_download_runs_ids(session, headers): <TAB> last_date = 0 <TAB> result = [] <TAB> while 1: <TAB> <TAB> r = session.get(RUN_DATA_API.format(last_date=last_date), headers=headers) <TAB> <TAB> if r.ok: <TAB> <TAB> <TAB> run_logs = r.json()[""data""][""records""] <TAB> <TAB> <TAB> result.extend([i[""logs""][0][""stats""][""id""] for i in run_logs]) <TAB> <TAB> <TAB> last_date = r.json()[""data""][""lastTimestamp""] <TAB> <TAB> <TAB> since_time = datetime.utcfromtimestamp(last_date / 1000) <TAB> <TAB> <TAB> print(f""pares keep ids data since {since_time}"") <TAB> <TAB> <TAB> time.sleep(1)  # spider rule <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> return result",false,if not last_date :,if since_time > last_date :,0.08,0.0
"def button_press_cb(self, tdw, event): <TAB> self._update_zone_and_cursors(tdw, event.x, event.y) <TAB> if self._zone in (_EditZone.CREATE_FRAME, _EditZone.REMOVE_FRAME): <TAB> <TAB> button = event.button <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._click_info = (button, self._zone) <TAB> <TAB> <TAB> return False <TAB> return super(FrameEditMode, self).button_press_cb(tdw, event)",false,if button == 1 and event . type == Gdk . EventType . BUTTON_PRESS :,if button :,0.04,0.0
"def first_timestep(): <TAB> assignment = self.has_previous.assign( <TAB> <TAB> value=tf_util.constant(value=True, dtype=""bool""), read_value=False <TAB> ) <TAB> with tf.control_dependencies(control_inputs=(assignment,)): <TAB> <TAB> if self.concatenate: <TAB> <TAB> <TAB> current = x <TAB> <TAB> else: <TAB> <TAB> <TAB> current = tf.expand_dims(input=x, axis=(self.axis + 1)) <TAB> <TAB> multiples = tuple( <TAB> <TAB> <TAB> self.length if dims == self.axis + 1 else 1 <TAB> <TAB> <TAB> for dims in range(self.output_spec().rank + 1) <TAB> <TAB> ) <TAB> <TAB> return tf.tile(input=current, multiples=multiples)",true,if self . concatenate :,if self . concatenate :,0.75,0.0
"def main() -> None: <TAB> onefuzz = Onefuzz() <TAB> jobs = onefuzz.jobs.list() <TAB> for job in jobs: <TAB> <TAB> print( <TAB> <TAB> <TAB> ""job:"", <TAB> <TAB> <TAB> str(job.job_id)[:8], <TAB> <TAB> <TAB> "":"".join([job.config.project, job.config.name, job.config.build]), <TAB> <TAB> ) <TAB> <TAB> for task in onefuzz.tasks.list(job_id=job.job_id): <TAB> <TAB> <TAB> if task.state in [""stopped"", ""stopping""]: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> print( <TAB> <TAB> <TAB> <TAB> "" <TAB>"", <TAB> <TAB> <TAB> <TAB> str(task.task_id)[:8], <TAB> <TAB> <TAB> <TAB> task.config.task.type, <TAB> <TAB> <TAB> <TAB> task.config.task.target_exe, <TAB> <TAB> <TAB> )",true,"if task . state in [ ""stopped"" , ""stopping"" ] :","if task . state in [ ""stopped"" , ""stopping"" ] :",0.75,0.0
"def update_stack(self, full_name, template_url, parameters, tags): <TAB> """"""Updates an existing stack in CloudFormation."""""" <TAB> try: <TAB> <TAB> logger.info(""Attempting to update stack %s."", full_name) <TAB> <TAB> self.conn.cloudformation.update_stack( <TAB> <TAB> <TAB> full_name, <TAB> <TAB> <TAB> template_url=template_url, <TAB> <TAB> <TAB> parameters=parameters, <TAB> <TAB> <TAB> tags=tags, <TAB> <TAB> <TAB> capabilities=[""CAPABILITY_IAM""], <TAB> <TAB> ) <TAB> <TAB> return SUBMITTED <TAB> except BotoServerError as e: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> logger.info(""Stack %s did not change, not updating."", full_name) <TAB> <TAB> <TAB> return SKIPPED <TAB> <TAB> raise",false,"if ""No updates are to be performed."" in e . message :",if e . status_code == 404 :,0.02,0.0
"def header_tag_files(env, files, legal_header, script_files=False): <TAB> """"""Apply the legal_header to the list of files"""""" <TAB> try: <TAB> <TAB> import apply_legal_header <TAB> except: <TAB> <TAB> xbc.cdie(""XED ERROR: mfile.py could not find scripts directory"") <TAB> for g in files: <TAB> <TAB> print(""G: "", g) <TAB> <TAB> for f in mbuild.glob(g): <TAB> <TAB> <TAB> print(""F: "", f) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> apply_legal_header.apply_header_to_data_file(legal_header, f) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> apply_legal_header.apply_header_to_source_file(legal_header, f)",true,if script_files :,if script_files :,0.53,0.0
"def cleanDataCmd(cmd): <TAB> newcmd = ""AbracadabrA ** <?php "" <TAB> if cmd[:6] != ""php://"": <TAB> <TAB> if reverseConn not in cmd: <TAB> <TAB> <TAB> cmds = cmd.split(""&"") <TAB> <TAB> <TAB> for c in cmds: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> newcmd += ""system('%s');"" % c <TAB> <TAB> else: <TAB> <TAB> <TAB> b64cmd = base64.b64encode(cmd) <TAB> <TAB> <TAB> newcmd += ""system(base64_decode('%s'));"" % b64cmd <TAB> else: <TAB> <TAB> newcmd += cmd[6:] <TAB> newcmd += ""?> **"" <TAB> return newcmd",false,if len ( c ) > 0 :,if c :,0.02,0.0
"def test_form(self): <TAB> n_qubits = 6 <TAB> random_operator = get_fermion_operator(random_interaction_operator(n_qubits)) <TAB> chemist_operator = chemist_ordered(random_operator) <TAB> for term, _ in chemist_operator.terms.items(): <TAB> <TAB> if len(term) == 2 or not len(term): <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> self.assertTrue(term[0][1]) <TAB> <TAB> <TAB> self.assertTrue(term[2][1]) <TAB> <TAB> <TAB> self.assertFalse(term[1][1]) <TAB> <TAB> <TAB> self.assertFalse(term[3][1]) <TAB> <TAB> <TAB> self.assertTrue(term[0][0] > term[2][0]) <TAB> <TAB> <TAB> self.assertTrue(term[1][0] > term[3][0])",true,if len ( term ) == 2 or not len ( term ) :,if len ( term ) == 2 or not len ( term ) :,1.0,0.0
"def do(server, handler, config, modargs): <TAB> data = [] <TAB> clients = server.get_clients(handler.default_filter) <TAB> if not clients: <TAB> <TAB> return <TAB> for client in clients: <TAB> <TAB> tags = config.tags(client.node()) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tags.remove(*modargs.remove) <TAB> <TAB> if modargs.add: <TAB> <TAB> <TAB> tags.add(*modargs.add) <TAB> <TAB> data.append({""ID"": client.node(), ""TAGS"": tags}) <TAB> config.save(project=modargs.write_project, user=modargs.write_user) <TAB> handler.display(Table(data))",true,if modargs . remove :,if modargs . remove :,0.75,0.0
"def validate(self): <TAB> if self.data.get(""state"") == ""enabled"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise PolicyValidationError( <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> ""redshift logging enablement requires `bucket` "" <TAB> <TAB> <TAB> <TAB> <TAB> ""and `prefix` specification on %s"" % (self.manager.data,) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return self",true,"if ""bucket"" not in self . data :","if ""bucket"" not in self . data :",0.75,0.0
"def renumber(self, x1, y1, x2, y2, dx, dy): <TAB> out = [] <TAB> for part in re.split(""(\w+)"", self.formula): <TAB> <TAB> m = re.match(""^([A-Z]+)([1-9][0-9]*)$"", part) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> sx, sy = m.groups() <TAB> <TAB> <TAB> x = colname2num(sx) <TAB> <TAB> <TAB> y = int(sy) <TAB> <TAB> <TAB> if x1 <= x <= x2 and y1 <= y <= y2: <TAB> <TAB> <TAB> <TAB> part = cellname(x + dx, y + dy) <TAB> <TAB> out.append(part) <TAB> return FormulaCell("""".join(out), self.fmt, self.alignment)",false,if m is not None :,if m :,0.05,0.0
"def update_sysconfig_file(fn, adjustments, allow_empty=False): <TAB> if not adjustments: <TAB> <TAB> return <TAB> (exists, contents) = read_sysconfig_file(fn) <TAB> updated_am = 0 <TAB> for (k, v) in adjustments.items(): <TAB> <TAB> if v is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> v = str(v) <TAB> <TAB> if len(v) == 0 and not allow_empty: <TAB> <TAB> <TAB> continue <TAB> <TAB> contents[k] = v <TAB> <TAB> updated_am += 1 <TAB> if updated_am: <TAB> <TAB> lines = [ <TAB> <TAB> <TAB> str(contents), <TAB> <TAB> ] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> lines.insert(0, util.make_header()) <TAB> <TAB> util.write_file(fn, ""\n"".join(lines) + ""\n"", 0o644)",false,if not exists :,if exists :,0.1,0.0
"def getElement(self, aboutUri, namespace, name): <TAB> for desc in self.rdfRoot.getElementsByTagNameNS(RDF_NAMESPACE, ""Description""): <TAB> <TAB> if desc.getAttributeNS(RDF_NAMESPACE, ""about"") == aboutUri: <TAB> <TAB> <TAB> attr = desc.getAttributeNodeNS(namespace, name) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> yield attr <TAB> <TAB> <TAB> for element in desc.getElementsByTagNameNS(namespace, name): <TAB> <TAB> <TAB> <TAB> yield element",false,if attr != None :,if attr :,0.07,0.0
"def get_store_name_from_connection_string(connection_string): <TAB> if is_valid_connection_string(connection_string): <TAB> <TAB> segments = dict(seg.split(""="", 1) for seg in connection_string.split("";"")) <TAB> <TAB> endpoint = segments.get(""Endpoint"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return endpoint.split(""//"")[1].split(""."")[0] <TAB> return None",true,if endpoint :,if endpoint :,0.53,0.0
"def insertLoopTemplate(self, layout): <TAB> col = layout.column(align=True) <TAB> for socket in self.activeNode.outputs: <TAB> <TAB> if not socket.hide and isList(socket.bl_idname): <TAB> <TAB> <TAB> props = col.operator( <TAB> <TAB> <TAB> <TAB> ""an.insert_loop_for_iterator"", <TAB> <TAB> <TAB> <TAB> text=""Loop through {}"".format(repr(socket.getDisplayedName())), <TAB> <TAB> <TAB> <TAB> icon=""MOD_ARRAY"", <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> props.nodeIdentifier = self.activeNode.identifier <TAB> <TAB> <TAB> props.socketIndex = socket.getIndex()",true,if not socket . hide and isList ( socket . bl_idname ) :,if not socket . hide and isList ( socket . bl_idname ) :,1.0,0.0
"def do_task(self, task): <TAB> self.running_task += 1 <TAB> result = yield gen.Task(self.fetcher.fetch, task) <TAB> type, task, response = result.args <TAB> self.processor.on_task(task, response) <TAB> # do with message <TAB> while not self.processor.inqueue.empty(): <TAB> <TAB> _task, _response = self.processor.inqueue.get() <TAB> <TAB> self.processor.on_task(_task, _response) <TAB> # do with results <TAB> while not self.processor.result_queue.empty(): <TAB> <TAB> _task, _result = self.processor.result_queue.get() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.result_worker.on_result(_task, _result) <TAB> self.running_task -= 1",false,if self . result_worker :,if _result :,0.04,0.0
"def _parse_config_result(data): <TAB> command_list = "" ; "".join([x.strip() for x in data[0]]) <TAB> config_result = data[1] <TAB> if isinstance(config_result, list): <TAB> <TAB> result = """" <TAB> <TAB> if isinstance(config_result[0], dict): <TAB> <TAB> <TAB> for key in config_result[0]: <TAB> <TAB> <TAB> <TAB> result += config_result[0][key] <TAB> <TAB> <TAB> config_result = result <TAB> <TAB> else: <TAB> <TAB> <TAB> config_result = config_result[0] <TAB> return [command_list, config_result]",true,"if isinstance ( config_result [ 0 ] , dict ) :","if isinstance ( config_result [ 0 ] , dict ) :",0.75,0.0
"def load_api_handler(self, mod_name): <TAB> for name, hdl in API_HANDLERS: <TAB> <TAB> name = name.lower() <TAB> <TAB> if mod_name and name == mod_name.lower(): <TAB> <TAB> <TAB> handler = self.mods.get(name) <TAB> <TAB> <TAB> if not handler: <TAB> <TAB> <TAB> <TAB> handler = hdl(self.emu) <TAB> <TAB> <TAB> <TAB> self.mods.update({name: handler}) <TAB> <TAB> <TAB> return handler <TAB> return None",true,if mod_name and name == mod_name . lower ( ) :,if mod_name and name == mod_name . lower ( ) :,0.75,0.0
def heal(self): <TAB> if not self.doctors: <TAB> <TAB> return <TAB> proc_ids = self._get_process_ids() <TAB> for proc_id in proc_ids: <TAB> <TAB> # get proc every time for latest state <TAB> <TAB> proc = PipelineProcess.objects.get(id=proc_id) <TAB> <TAB> if not proc.is_alive or proc.is_frozen: <TAB> <TAB> <TAB> continue <TAB> <TAB> for dr in self.doctors: <TAB> <TAB> <TAB> if dr.confirm(proc): <TAB> <TAB> <TAB> <TAB> dr.cure(proc) <TAB> <TAB> <TAB> <TAB> break,true,if dr . confirm ( proc ) :,if dr . confirm ( proc ) :,0.75,0.0
"def __new__(cls, *args, **kwargs): <TAB> if len(args) == 1: <TAB> <TAB> if len(kwargs): <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""You can either use {} with one positional argument or with keyword arguments, not both."".format( <TAB> <TAB> <TAB> <TAB> <TAB> cls.__name__ <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> if not args[0]: <TAB> <TAB> <TAB> return super().__new__(cls) <TAB> <TAB> if isinstance(args[0], cls): <TAB> <TAB> <TAB> return cls <TAB> return super().__new__(cls, *args, **kwargs)",false,if not args [ 0 ] :,"if isinstance ( args [ 0 ] , cls ) :",0.18,0.0
"def __lt__(self, other): <TAB> # 0: clock 1: timestamp 3: process id <TAB> try: <TAB> <TAB> A, B = self[0], other[0] <TAB> <TAB> # uses logical clock value first <TAB> <TAB><IF-STMT>  # use logical clock if available <TAB> <TAB> <TAB> if A == B:  # equal clocks use lower process id <TAB> <TAB> <TAB> <TAB> return self[2] < other[2] <TAB> <TAB> <TAB> return A < B <TAB> <TAB> return self[1] < other[1]  # ... or use timestamp <TAB> except IndexError: <TAB> <TAB> return NotImplemented",false,if A and B :,if A is not None :,0.06,0.0
"def _get_client(rp_mapping, resource_provider): <TAB> for key, value in rp_mapping.items(): <TAB> <TAB> if str.lower(key) == str.lower(resource_provider): <TAB> <TAB> <TAB> if isinstance(value, dict): <TAB> <TAB> <TAB> <TAB> return GeneralPrivateEndpointClient( <TAB> <TAB> <TAB> <TAB> <TAB> key, <TAB> <TAB> <TAB> <TAB> <TAB> value[""api_version""], <TAB> <TAB> <TAB> <TAB> <TAB> value[""support_list_or_not""], <TAB> <TAB> <TAB> <TAB> <TAB> value[""resource_get_api_version""], <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return value() <TAB> raise CLIError( <TAB> <TAB> ""Resource type must be one of {}"".format("", "".join(rp_mapping.keys())) <TAB> )",true,"if isinstance ( value , dict ) :","if isinstance ( value , dict ) :",0.75,0.0
"def test_progressbar_format_pos(runner, pos, length): <TAB> with _create_progress(length, length_known=length != 0, pos=pos) as progress: <TAB> <TAB> result = progress.format_pos() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> assert result == f""{pos}/{length}"" <TAB> <TAB> else: <TAB> <TAB> <TAB> assert result == str(pos)",false,if progress . length_known :,if length :,0.04,0.0
"def optimize(self, graph: Graph): <TAB> MAX_TEXTURE_SIZE = config.WEBGL_MAX_TEXTURE_SIZE <TAB> flag_changed = False <TAB> for v in traverse.listup_variables(graph): <TAB> <TAB> if not Placeholder.check_resolved(v.size): <TAB> <TAB> <TAB> continue <TAB> <TAB> height, width = TextureShape.get(v) <TAB> <TAB> if height <= MAX_TEXTURE_SIZE and width <= MAX_TEXTURE_SIZE: <TAB> <TAB> <TAB> continue <TAB> <TAB> if not v.has_attribute(SplitTarget): <TAB> <TAB> <TAB> flag_changed = True <TAB> <TAB> <TAB> v.attributes.add(SplitTarget()) <TAB> return graph, flag_changed",false,if not v . has_attribute ( SplitTarget ) :,if not Placeholder . check_resolved ( v . size ) :,0.1,0.0
"def ant_map(m): <TAB> tmp = ""rows %s\ncols %s\n"" % (len(m), len(m[0])) <TAB> players = {} <TAB> for row in m: <TAB> <TAB> tmp += ""m "" <TAB> <TAB> for col in row: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> tmp += ""."" <TAB> <TAB> <TAB> elif col == BARRIER: <TAB> <TAB> <TAB> <TAB> tmp += ""%"" <TAB> <TAB> <TAB> elif col == FOOD: <TAB> <TAB> <TAB> <TAB> tmp += ""*"" <TAB> <TAB> <TAB> elif col == UNSEEN: <TAB> <TAB> <TAB> <TAB> tmp += ""?"" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> players[col] = True <TAB> <TAB> <TAB> <TAB> tmp += chr(col + 97) <TAB> <TAB> tmp += ""\n"" <TAB> tmp = (""players %s\n"" % len(players)) + tmp <TAB> return tmp",false,if col == LAND :,if col == SCREEN :,0.39,0.0
"def reset(self): <TAB> logger.debug(""Arctic.reset()"") <TAB> with self._lock: <TAB> <TAB> if self.__conn is not None: <TAB> <TAB> <TAB> self.__conn.close() <TAB> <TAB> <TAB> self.__conn = None <TAB> <TAB> for _, l in self._library_cache.items(): <TAB> <TAB> <TAB> if hasattr(l, ""_reset"") and callable(l._reset): <TAB> <TAB> <TAB> <TAB> logger.debug(""Library reset() %s"" % l) <TAB> <TAB> <TAB> <TAB> l._reset()  # the existence of _reset() is not guaranteed/enforced, it also triggers re-auth",true,"if hasattr ( l , ""_reset"" ) and callable ( l . _reset ) :","if hasattr ( l , ""_reset"" ) and callable ( l . _reset ) :",1.0,0.0
"def add_cand_to_check(cands): <TAB> for cand in cands: <TAB> <TAB> x = cand.creator <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if x not in fan_out: <TAB> <TAB> <TAB> # `len(fan_out)` is in order to avoid comparing `x` <TAB> <TAB> <TAB> heapq.heappush(cand_funcs, (-x.rank, len(fan_out), x)) <TAB> <TAB> fan_out[x] += 1",true,if x is None :,if x is None :,0.75,0.0
"def on_task_modify(self, task, config): <TAB> for entry in task.entries: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> size = entry[""torrent""].size / 1024 / 1024 <TAB> <TAB> <TAB> log.debug(""%s size: %s MB"" % (entry[""title""], size)) <TAB> <TAB> <TAB> entry[""content_size""] = size",true,"if ""torrent"" in entry :","if ""torrent"" in entry :",0.75,0.0
"def get_measurements(self, pipeline, object_name, category): <TAB> if self.get_categories(pipeline, object_name) == [category]: <TAB> <TAB> results = [] <TAB> <TAB> if self.do_corr_and_slope: <TAB> <TAB> <TAB> if object_name == ""Image"": <TAB> <TAB> <TAB> <TAB> results += [""Correlation"", ""Slope""] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> results += [""Correlation""] <TAB> <TAB> if self.do_overlap: <TAB> <TAB> <TAB> results += [""Overlap"", ""K""] <TAB> <TAB> if self.do_manders: <TAB> <TAB> <TAB> results += [""Manders""] <TAB> <TAB> if self.do_rwc: <TAB> <TAB> <TAB> results += [""RWC""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> results += [""Costes""] <TAB> <TAB> return results <TAB> return []",true,if self . do_costes :,if self . do_costes :,0.75,0.0
"def create_root(cls, site=None, title=""Root"", request=None, **kwargs): <TAB> if not site: <TAB> <TAB> site = Site.objects.get_current() <TAB> root_nodes = cls.objects.root_nodes().filter(site=site) <TAB> if not root_nodes: <TAB> <TAB> article = Article() <TAB> <TAB> revision = ArticleRevision(title=title, **kwargs) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> revision.set_from_request(request) <TAB> <TAB> article.add_revision(revision, save=True) <TAB> <TAB> article.save() <TAB> <TAB> root = cls.objects.create(site=site, article=article) <TAB> <TAB> article.add_object_relation(root) <TAB> else: <TAB> <TAB> root = root_nodes[0] <TAB> return root",true,if request :,if request :,0.53,0.0
"def get(self, key): <TAB> filename = self._get_filename(key) <TAB> try: <TAB> <TAB> with open(filename, ""rb"") as f: <TAB> <TAB> <TAB> pickle_time = pickle.load(f) <TAB> <TAB> <TAB> if pickle_time == 0 or pickle_time >= time(): <TAB> <TAB> <TAB> <TAB> return pickle.load(f) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> os.remove(filename) <TAB> <TAB> <TAB> <TAB> return None <TAB> except (IOError, OSError, pickle.PickleError): <TAB> <TAB> return None",true,if pickle_time == 0 or pickle_time >= time ( ) :,if pickle_time == 0 or pickle_time >= time ( ) :,1.0,0.0
"def build_message(self, options, target): <TAB> message = multipart.MIMEMultipart() <TAB> for name, value in list(options.items()): <TAB> <TAB> if name == ""EMAIL_BODY"": <TAB> <TAB> <TAB> self.add_body(message, value) <TAB> <TAB> elif name == ""EMAIL_ATTACHMENT"": <TAB> <TAB> <TAB> self.add_attachment(message, value) <TAB> <TAB> else:  # From, To, Subject, etc. <TAB> <TAB> <TAB> self.set_option(message, name, value, target) <TAB> return message",false,"if name == ""EMAIL_BODY"" :","elif name == ""EMAIL_ATTACHMENT"" :",0.06,0.0
"def updateVar(name, data, mode=None): <TAB> if mode: <TAB> <TAB> if mode == ""append"": <TAB> <TAB> <TAB> core.config.globalVariables[name].append(data) <TAB> <TAB> elif mode == ""add"": <TAB> <TAB> <TAB> core.config.globalVariables[name].add(data) <TAB> else: <TAB> <TAB> core.config.globalVariables[name] = data",false,"if mode == ""append"" :","elif mode == ""add"" :",0.06,0.0
"def insert_errors( <TAB> el, <TAB> errors, <TAB> form_id=None, <TAB> form_index=None, <TAB> error_class=""error"", <TAB> error_creator=default_error_creator, ): <TAB> el = _find_form(el, form_id=form_id, form_index=form_index) <TAB> for name, error in errors.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> for error_el, message in _find_elements_for_name(el, name, error): <TAB> <TAB> <TAB> assert isinstance(message, (basestring, type(None), ElementBase)), ( <TAB> <TAB> <TAB> <TAB> ""Bad message: %r"" % message <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> _insert_error(error_el, message, error_class, error_creator)",false,if error is None :,if name in el :,0.28,0.0
"def read(self, item, recursive=False, sort=False): <TAB> item = _normalize_path(item) <TAB> if item in self._store: <TAB> <TAB> if item in self._expire_time and self._expire_time[item] < datetime.now(): <TAB> <TAB> <TAB> del self._store[item] <TAB> <TAB> <TAB> raise KeyError(item) <TAB> <TAB> return PathResult(item, value=self._store[item]) <TAB> else: <TAB> <TAB> return self._read_dir(item, recursive=recursive, sort=sort)",true,if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) :,if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) :,0.75,0.0
"def _stash_splitter(states): <TAB> keep, split = [], [] <TAB> if state_func is not None: <TAB> <TAB> for s in states: <TAB> <TAB> <TAB> ns = state_func(s) <TAB> <TAB> <TAB> if isinstance(ns, SimState): <TAB> <TAB> <TAB> <TAB> split.append(ns) <TAB> <TAB> <TAB> elif isinstance(ns, (list, tuple, set)): <TAB> <TAB> <TAB> <TAB> split.extend(ns) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> split.append(s) <TAB> if stash_func is not None: <TAB> <TAB> split = stash_func(states) <TAB> if to_stash is not stash: <TAB> <TAB> keep = states <TAB> return keep, split",true,"elif isinstance ( ns , ( list , tuple , set ) ) :","elif isinstance ( ns , ( list , tuple , set ) ) :",0.75,0.0
"def run(self): <TAB> while self.runflag: <TAB> <TAB> if time() - self.last > 5 and self.qsize() > 0: <TAB> <TAB> <TAB> with self.lock: <TAB> <TAB> <TAB> <TAB> tasks = list(self.queue) <TAB> <TAB> <TAB> <TAB> self.queue.clear() <TAB> <TAB> <TAB> while len(tasks) > 0: <TAB> <TAB> <TAB> <TAB> pathname, remotepath = tasks.pop(0) <TAB> <TAB> <TAB> <TAB> self.bcloud_app.upload_page.add_bg_task(pathname, remotepath) <TAB> <TAB> <TAB> self.last = time() <TAB> <TAB> else: <TAB> <TAB> <TAB> sleep(1)",true,if time ( ) - self . last > 5 and self . qsize ( ) > 0 :,if time ( ) - self . last > 5 and self . qsize ( ) > 0 :,1.0,0.0
"def _append_patch(self, patch_dir, patch_files): <TAB> for patch in patch_files: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tmp = patch <TAB> <TAB> <TAB> patch = {} <TAB> <TAB> <TAB> for key in tmp.keys(): <TAB> <TAB> <TAB> <TAB> patch[os.path.join(patch_dir, key)] = tmp[key] <TAB> <TAB> <TAB> self.patches.append(patch) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.patches.append(os.path.join(patch_dir, patch))",false,if type ( patch ) is dict :,if type ( patch ) == dict :,0.42,0.0
"def __remote_port(self): <TAB> port = 22 <TAB> if self.git_has_remote: <TAB> <TAB> m = re.match(r""^(.*?)?@([^/:]*):?([0-9]+)?"", self.git_remote.url) <TAB> <TAB> if m: <TAB> <TAB> <TAB> if m.group(3): <TAB> <TAB> <TAB> <TAB> port = m.group(3) <TAB> return int(port)",true,if m . group ( 3 ) :,if m . group ( 3 ) :,0.75,0.0
"def _create_or_get_helper(self, infer_mode: Optional[bool] = None, **kwargs) -> Helper: <TAB> # Prefer creating a new helper when at least one kwarg is specified. <TAB> prefer_new = len(kwargs) > 0 <TAB> kwargs.update(infer_mode=infer_mode) <TAB> is_training = not infer_mode if infer_mode is not None else self.training <TAB> helper = self._train_helper if is_training else self._infer_helper <TAB> if prefer_new or helper is None: <TAB> <TAB> helper = self.create_helper(**kwargs) <TAB> <TAB> if is_training and self._train_helper is None: <TAB> <TAB> <TAB> self._train_helper = helper <TAB> <TAB> elif not is_training and self._infer_helper is None: <TAB> <TAB> <TAB> self._infer_helper = helper <TAB> return helper",false,if is_training and self . _train_helper is None :,elif not is_training and self . _infer_helper is None :,0.37,0.0
"def flushChangeClassifications(self, schedulerid, less_than=None): <TAB> if less_than is not None: <TAB> <TAB> classifications = self.classifications.setdefault(schedulerid, {}) <TAB> <TAB> for changeid in list(classifications): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> del classifications[changeid] <TAB> else: <TAB> <TAB> self.classifications[schedulerid] = {} <TAB> return defer.succeed(None)",true,if changeid < less_than :,if changeid < less_than :,0.75,0.0
"def pid_from_name(name): <TAB> processes = [] <TAB> for pid in os.listdir(""/proc""): <TAB> <TAB> try: <TAB> <TAB> <TAB> pid = int(pid) <TAB> <TAB> <TAB> pname, cmdline = SunProcess._name_args(pid) <TAB> <TAB> <TAB> if name in pname: <TAB> <TAB> <TAB> <TAB> return pid <TAB> <TAB> <TAB> if name in cmdline.split("" "", 1)[0]: <TAB> <TAB> <TAB> <TAB> return pid <TAB> <TAB> except: <TAB> <TAB> <TAB> pass <TAB> raise ProcessException(""No process with such name: %s"" % name)",true,"if name in cmdline . split ( "" "" , 1 ) [ 0 ] :","if name in cmdline . split ( "" "" , 1 ) [ 0 ] :",0.75,0.0
"def spew(): <TAB> seenUID = False <TAB> start() <TAB> for part in query: <TAB> <TAB> if part.type == ""uid"": <TAB> <TAB> <TAB> seenUID = True <TAB> <TAB> if part.type == ""body"": <TAB> <TAB> <TAB> yield self.spew_body(part, id, msg, write, flush) <TAB> <TAB> else: <TAB> <TAB> <TAB> f = getattr(self, ""spew_"" + part.type) <TAB> <TAB> <TAB> yield f(id, msg, write, flush) <TAB> <TAB> if part is not query[-1]: <TAB> <TAB> <TAB> space() <TAB> if uid and not seenUID: <TAB> <TAB> space() <TAB> <TAB> yield self.spew_uid(id, msg, write, flush) <TAB> finish() <TAB> flush()",false,"if part . type == ""uid"" :",if part is not query [ - 1 ] :,0.03,0.0
"def rx(): <TAB> while True: <TAB> <TAB> rx_i = rep.recv() <TAB> <TAB> if rx_i == b""1000"": <TAB> <TAB> <TAB> rep.send(b""done"") <TAB> <TAB> <TAB> break <TAB> <TAB> rep.send(b""i"")",true,"if rx_i == b""1000"" :","if rx_i == b""1000"" :",0.75,0.0
"def test_search_incorrect_base_exception_1(self): <TAB> self.connection_1c.bind() <TAB> try: <TAB> <TAB> result = self.connection_1c.search( <TAB> <TAB> <TAB> ""o=nonexistant"", ""(cn=*)"", search_scope=SUBTREE, attributes=[""cn"", ""sn""] <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> _, result = self.connection_1c.get_response(result) <TAB> <TAB> self.fail(""exception not raised"") <TAB> except LDAPNoSuchObjectResult: <TAB> <TAB> pass",false,if not self . connection_1c . strategy . sync :,if not self . connection_1c . is_active :,0.28,0.0
"def value_from_datadict(self, data, files, prefix): <TAB> count = int(data[""%s-count"" % prefix]) <TAB> values_with_indexes = [] <TAB> for i in range(0, count): <TAB> <TAB> if data[""%s-%d-deleted"" % (prefix, i)]: <TAB> <TAB> <TAB> continue <TAB> <TAB> values_with_indexes.append( <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> int(data[""%s-%d-order"" % (prefix, i)]), <TAB> <TAB> <TAB> <TAB> self.child_block.value_from_datadict( <TAB> <TAB> <TAB> <TAB> <TAB> data, files, ""%s-%d-value"" % (prefix, i) <TAB> <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> values_with_indexes.sort() <TAB> return [v for (i, v) in values_with_indexes]",true,"if data [ ""%s-%d-deleted"" % ( prefix , i ) ] :","if data [ ""%s-%d-deleted"" % ( prefix , i ) ] :",0.75,0.0
"def _ensure_header_written(self, datasize): <TAB> if not self._headerwritten: <TAB> <TAB> if not self._nchannels: <TAB> <TAB> <TAB> raise Error(""# channels not specified"") <TAB> <TAB> if not self._sampwidth: <TAB> <TAB> <TAB> raise Error(""sample width not specified"") <TAB> <TAB> if not self._framerate: <TAB> <TAB> <TAB> raise Error(""sampling rate not specified"") <TAB> <TAB> self._write_header(datasize)",true,if not self . _framerate :,if not self . _framerate :,0.75,0.0
def wait_til_ready(cls): <TAB> while True: <TAB> <TAB> now = time.time() <TAB> <TAB> next_iteration = now // 1.0 + 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> await cls._clock.run_til(next_iteration) <TAB> <TAB> await asyncio.sleep(1.0),false,if cls . connector . ready :,if next_iteration == 0 :,0.02,0.0
"def lookup_actions(self, resp): <TAB> actions = {} <TAB> for action, conditions in self.actions.items(): <TAB> <TAB> for condition, opts in conditions: <TAB> <TAB> <TAB> for key, val in condition: <TAB> <TAB> <TAB> <TAB> if key[-1] == ""!"": <TAB> <TAB> <TAB> <TAB> <TAB> if resp.match(key[:-1], val): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> if not resp.match(key, val): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> actions[action] = opts <TAB> return actions",false,"if key [ - 1 ] == ""!"" :","if resp . match ( key [ : - 1 ] , val ) :",0.06,0.0
"def close(self, wait=True, abort=False): <TAB> """"""Close the socket connection."""""" <TAB> if not self.closed and not self.closing: <TAB> <TAB> self.closing = True <TAB> <TAB> self.server._trigger_event(""disconnect"", self.sid, run_async=False) <TAB> <TAB> if not abort: <TAB> <TAB> <TAB> self.send(packet.Packet(packet.CLOSE)) <TAB> <TAB> self.closed = True <TAB> <TAB> self.queue.put(None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.queue.join()",true,if wait :,if wait :,0.53,0.0
"def model_parse(self): <TAB> for name, submodel in self.model.named_modules(): <TAB> <TAB> for op_type in SUPPORTED_OP_TYPE: <TAB> <TAB> <TAB> if isinstance(submodel, op_type): <TAB> <TAB> <TAB> <TAB> self.target_layer[name] = submodel <TAB> <TAB> <TAB> <TAB> self.already_pruned[name] = 0",true,"if isinstance ( submodel , op_type ) :","if isinstance ( submodel , op_type ) :",0.75,0.0
"def pack_identifier(self): <TAB> """"""Return a combined identifier for the whole pack if this has more than one episode."""""" <TAB> # Currently only supports ep mode <TAB> if self.id_type == ""ep"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ""S%02dE%02d-E%02d"" % ( <TAB> <TAB> <TAB> <TAB> self.season, <TAB> <TAB> <TAB> <TAB> self.episode, <TAB> <TAB> <TAB> <TAB> self.episode + self.episodes - 1, <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> return self.identifier <TAB> else: <TAB> <TAB> return self.identifier",false,if self . episodes > 1 :,if self . episodes :,0.23,0.0
"def on_data(res): <TAB> if terminate.is_set(): <TAB> <TAB> return <TAB> if args.strings and not args.no_content: <TAB> <TAB> if type(res) == tuple: <TAB> <TAB> <TAB> f, v = res <TAB> <TAB> <TAB> if type(f) == unicode: <TAB> <TAB> <TAB> <TAB> f = f.encode(""utf-8"") <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> v = v.encode(""utf-8"") <TAB> <TAB> <TAB> self.success(""{}: {}"".format(f, v)) <TAB> <TAB> elif not args.content_only: <TAB> <TAB> <TAB> self.success(res) <TAB> else: <TAB> <TAB> self.success(res)",true,if type ( v ) == unicode :,if type ( v ) == unicode :,0.75,0.0
"def _enable_contours_changed(self, value): <TAB> """"""Turns on and off the contours."""""" <TAB> if self.module_manager is None: <TAB> <TAB> return <TAB> if value: <TAB> <TAB> self.actor.inputs = [self.contour] <TAB> <TAB> if self.contour.filled_contours: <TAB> <TAB> <TAB> self.actor.mapper.scalar_mode = ""use_cell_data"" <TAB> else: <TAB> <TAB> self.actor.inputs = [self.grid_plane] <TAB> <TAB> self.actor.mapper.scalar_mode = ""default"" <TAB> self.render()",true,if self . contour . filled_contours :,if self . contour . filled_contours :,0.75,0.0
"def _apply_abs_paths(data, script_dir): <TAB> for flag_data in data.values(): <TAB> <TAB> if not isinstance(flag_data, dict): <TAB> <TAB> <TAB> continue <TAB> <TAB> default = flag_data.get(""default"") <TAB> <TAB> if ( <TAB> <TAB> <TAB> not default <TAB> <TAB> <TAB> or not isinstance(default, six.string_types) <TAB> <TAB> <TAB> or os.path.sep not in default <TAB> <TAB> ): <TAB> <TAB> <TAB> continue <TAB> <TAB> abs_path = os.path.join(script_dir, default) <TAB> <TAB> if os.path.exists(abs_path): <TAB> <TAB> <TAB> flag_data[""default""] = abs_path",false,"if not isinstance ( flag_data , dict ) :",if os . path . exists ( abs_path ) :,0.03,0.0
"def button_release(self, mapper): <TAB> self.pressed = False <TAB> if self.waiting_task and self.active is None and not self.action: <TAB> <TAB> # In HoldModifier, button released before timeout <TAB> <TAB> mapper.cancel_task(self.waiting_task) <TAB> <TAB> self.waiting_task = None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.normalaction.button_press(mapper) <TAB> <TAB> <TAB> mapper.schedule(0.02, self.normalaction.button_release) <TAB> elif self.active: <TAB> <TAB> # Released held button <TAB> <TAB> self.active.button_release(mapper) <TAB> <TAB> self.active = None",true,if self . normalaction :,if self . normalaction :,0.75,0.0
"def goToPrevMarkedHeadline(self, event=None): <TAB> """"""Select the next marked node."""""" <TAB> c = self <TAB> p = c.p <TAB> if not p: <TAB> <TAB> return <TAB> p.moveToThreadBack() <TAB> wrapped = False <TAB> while 1: <TAB> <TAB> if p and p.isMarked(): <TAB> <TAB> <TAB> break <TAB> <TAB> elif p: <TAB> <TAB> <TAB> p.moveToThreadBack() <TAB> <TAB> elif wrapped: <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> wrapped = True <TAB> <TAB> <TAB> p = c.rootPosition() <TAB> if not p: <TAB> <TAB> g.blue(""done"") <TAB> c.treeSelectHelper(p)  # Sets focus.",false,elif p :,elif wrapped :,0.31,0.0
"def status(self, name, error=""No matching script logs found""): <TAB> with self.script_lock: <TAB> <TAB> if self.script_running and self.script_running[1] == name: <TAB> <TAB> <TAB> return self.script_running[1:] <TAB> <TAB> elif self.script_last and self.script_last[1] == name: <TAB> <TAB> <TAB> return self.script_last[1:] <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(error)",true,elif self . script_last and self . script_last [ 1 ] == name :,elif self . script_last and self . script_last [ 1 ] == name :,1.0,0.0
"def _stderr_supports_color(): <TAB> try: <TAB> <TAB> if hasattr(sys.stderr, ""isatty"") and sys.stderr.isatty(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> curses.setupterm() <TAB> <TAB> <TAB> <TAB> if curses.tigetnum(""colors"") > 0: <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> elif colorama: <TAB> <TAB> <TAB> <TAB> if sys.stderr is getattr( <TAB> <TAB> <TAB> <TAB> <TAB> colorama.initialise, ""wrapped_stderr"", object() <TAB> <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> except Exception: <TAB> <TAB> # Very broad exception handling because it's always better to <TAB> <TAB> # fall back to non-colored logs than to break at startup. <TAB> <TAB> pass <TAB> return False",true,if curses :,if curses :,0.53,0.0
"def main(): <TAB> configFilename = ""twitterbot.ini"" <TAB> if sys.argv[1:]: <TAB> <TAB> configFilename = sys.argv[1] <TAB> try: <TAB> <TAB> if not os.path.exists(configFilename): <TAB> <TAB> <TAB> raise Exception() <TAB> <TAB> load_config(configFilename) <TAB> except Exception as e: <TAB> <TAB> print(""Error while loading ini file %s"" % (configFilename), file=sys.stderr) <TAB> <TAB> print(e, file=sys.stderr) <TAB> <TAB> print(__doc__, file=sys.stderr) <TAB> <TAB> sys.exit(1) <TAB> bot = TwitterBot(configFilename) <TAB> return bot.run()",true,if not os . path . exists ( configFilename ) :,if not os . path . exists ( configFilename ) :,0.75,0.0
def safe_to_kill(request): <TAB> if os.path.exists(DRAIN_FILE): <TAB> <TAB> with open(DRAIN_FILE) as f: <TAB> <TAB> <TAB> dt = datetime.datetime.fromtimestamp(float(f.read())) <TAB> <TAB> <TAB> delta = datetime.datetime.now() - dt <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return Response(status_int=200) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return Response(status_int=400) <TAB> else: <TAB> <TAB> return Response(status_int=400),false,if delta . seconds > 2 :,if delta < 0 :,0.04,0.0
"def get_class_name(item): <TAB> class_name, module_name = None, None <TAB> for parent in reversed(item.listchain()): <TAB> <TAB> if isinstance(parent, pytest.Class): <TAB> <TAB> <TAB> class_name = parent.name <TAB> <TAB> elif isinstance(parent, pytest.Module): <TAB> <TAB> <TAB> module_name = parent.module.__name__ <TAB> <TAB> <TAB> break <TAB> # heuristic: <TAB> # - better to group gpu and task tests, since tests from those modules <TAB> #   are likely to share caching more <TAB> # - split up the rest by class name because slow tests tend to be in <TAB> #   the same module <TAB> if class_name and "".tasks."" not in module_name: <TAB> <TAB> return ""{}.{}"".format(module_name, class_name) <TAB> else: <TAB> <TAB> return module_name",false,"if isinstance ( parent , pytest . Class ) :","elif isinstance ( parent , pytest . Module ) :",0.28,0.0
"def getAllFitsLite(): <TAB> fits = eos.db.getFitListLite() <TAB> shipMap = {f.shipID: None for f in fits} <TAB> for shipID in shipMap: <TAB> <TAB> ship = eos.db.getItem(shipID) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> shipMap[shipID] = (ship.name, ship.getShortName()) <TAB> fitsToPurge = set() <TAB> for fit in fits: <TAB> <TAB> try: <TAB> <TAB> <TAB> fit.shipName, fit.shipNameShort = shipMap[fit.shipID] <TAB> <TAB> except (KeyError, TypeError): <TAB> <TAB> <TAB> fitsToPurge.add(fit) <TAB> for fit in fitsToPurge: <TAB> <TAB> fits.remove(fit) <TAB> return fits",false,if ship is not None :,if ship :,0.05,0.0
"def _process(self, event_data): <TAB> self.machine.callbacks(self.machine.prepare_event, event_data) <TAB> _LOGGER.debug( <TAB> <TAB> ""%sExecuted machine preparation callbacks before conditions."", self.machine.name <TAB> ) <TAB> try: <TAB> <TAB> for trans in self.transitions[event_data.state.name]: <TAB> <TAB> <TAB> event_data.transition = trans <TAB> <TAB> <TAB> if trans.execute(event_data): <TAB> <TAB> <TAB> <TAB> event_data.result = True <TAB> <TAB> <TAB> <TAB> break <TAB> except Exception as err: <TAB> <TAB> event_data.error = err <TAB> <TAB> raise <TAB> finally: <TAB> <TAB> self.machine.callbacks(self.machine.finalize_event, event_data) <TAB> <TAB> _LOGGER.debug(""%sExecuted machine finalize callbacks"", self.machine.name) <TAB> return event_data.result",true,if trans . execute ( event_data ) :,if trans . execute ( event_data ) :,0.75,0.0
"def fetch_comments(self, force=False, limit=None): <TAB> comments = [] <TAB> if (force is True) or (self.badges[""comments""] > 0): <TAB> <TAB> query_params = {""filter"": ""commentCard,copyCommentCard""} <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> query_params[""limit""] = limit <TAB> <TAB> comments = self.client.fetch_json( <TAB> <TAB> <TAB> ""/cards/"" + self.id + ""/actions"", query_params=query_params <TAB> <TAB> ) <TAB> <TAB> return sorted(comments, key=lambda comment: comment[""date""]) <TAB> return comments",true,if limit is not None :,if limit is not None :,0.75,0.0
"def get_changed(self): <TAB> if self._is_expression(): <TAB> <TAB> result = self._get_node_text(self.ast) <TAB> <TAB> if result == self.source: <TAB> <TAB> <TAB> return None <TAB> <TAB> return result <TAB> else: <TAB> <TAB> collector = codeanalyze.ChangeCollector(self.source) <TAB> <TAB> last_end = -1 <TAB> <TAB> for match in self.matches: <TAB> <TAB> <TAB> start, end = match.get_region() <TAB> <TAB> <TAB> if start < last_end: <TAB> <TAB> <TAB> <TAB> if not self._is_expression(): <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> last_end = end <TAB> <TAB> <TAB> replacement = self._get_matched_text(match) <TAB> <TAB> <TAB> collector.add_change(start, end, replacement) <TAB> <TAB> return collector.get_changed()",true,if not self . _is_expression ( ) :,if not self . _is_expression ( ) :,0.75,0.0
"def _replace_home(x): <TAB> if xp.ON_WINDOWS: <TAB> <TAB> home = ( <TAB> <TAB> <TAB> builtins.__xonsh__.env[""HOMEDRIVE""] + builtins.__xonsh__.env[""HOMEPATH""][0] <TAB> <TAB> ) <TAB> <TAB> if x.startswith(home): <TAB> <TAB> <TAB> x = x.replace(home, ""~"", 1) <TAB> <TAB> if builtins.__xonsh__.env.get(""FORCE_POSIX_PATHS""): <TAB> <TAB> <TAB> x = x.replace(os.sep, os.altsep) <TAB> <TAB> return x <TAB> else: <TAB> <TAB> home = builtins.__xonsh__.env[""HOME""] <TAB> <TAB> if x.startswith(home): <TAB> <TAB> <TAB> x = x.replace(home, ""~"", 1) <TAB> <TAB> return x",true,if x . startswith ( home ) :,if x . startswith ( home ) :,0.75,0.0
"def project_review(plans): <TAB> for plan in plans: <TAB> <TAB> print(""Inspecting {} plan"".format(plan)) <TAB> <TAB> branches = get_branches_from_plan(plan) <TAB> <TAB> for branch in branches: <TAB> <TAB> <TAB> build_results = get_results_from_branch(branch) <TAB> <TAB> <TAB> for build in build_results: <TAB> <TAB> <TAB> <TAB> build_key = build.get(""buildResultKey"") or None <TAB> <TAB> <TAB> <TAB> print(""Inspecting build - {}"".format(build_key)) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> for status in STATUS_CLEANED_RESULTS: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> remove_build_result(build_key=build_key, status=status)",true,if build_key :,if build_key :,0.53,0.0
"def _check_for_batch_clashes(xs): <TAB> """"""Check that batch names do not overlap with sample names."""""" <TAB> names = set([x[""description""] for x in xs]) <TAB> dups = set([]) <TAB> for x in xs: <TAB> <TAB> batches = tz.get_in((""metadata"", ""batch""), x) <TAB> <TAB> if batches: <TAB> <TAB> <TAB> if not isinstance(batches, (list, tuple)): <TAB> <TAB> <TAB> <TAB> batches = [batches] <TAB> <TAB> <TAB> for batch in batches: <TAB> <TAB> <TAB> <TAB> if batch in names: <TAB> <TAB> <TAB> <TAB> <TAB> dups.add(batch) <TAB> if len(dups) > 0: <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> ""Batch names must be unique from sample descriptions.\n"" <TAB> <TAB> <TAB> ""Clashing batch names: %s"" % sorted(list(dups)) <TAB> <TAB> )",true,"if not isinstance ( batches , ( list , tuple ) ) :","if not isinstance ( batches , ( list , tuple ) ) :",0.75,0.0
"def _check_signal(self): <TAB> """"""Checks if a signal was received and issues a message."""""" <TAB> proc_signal = getattr(self.proc, ""signal"", None) <TAB> if proc_signal is None: <TAB> <TAB> return <TAB> sig, core = proc_signal <TAB> sig_str = SIGNAL_MESSAGES.get(sig) <TAB> if sig_str: <TAB> <TAB> if core: <TAB> <TAB> <TAB> sig_str += "" (core dumped)"" <TAB> <TAB> print(sig_str, file=sys.stderr) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.errors += sig_str + ""\n""",false,if self . errors is not None :,if self . errors :,0.23,0.0
"def loadLabelFile(self, labelpath): <TAB> labeldict = {} <TAB> if not os.path.exists(labelpath): <TAB> <TAB> f = open(labelpath, ""w"", encoding=""utf-8"") <TAB> else: <TAB> <TAB> with open(labelpath, ""r"", encoding=""utf-8"") as f: <TAB> <TAB> <TAB> data = f.readlines() <TAB> <TAB> <TAB> for each in data: <TAB> <TAB> <TAB> <TAB> file, label = each.split(""\t"") <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> label = label.replace(""false"", ""False"") <TAB> <TAB> <TAB> <TAB> <TAB> label = label.replace(""true"", ""True"") <TAB> <TAB> <TAB> <TAB> <TAB> labeldict[file] = eval(label) <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> labeldict[file] = [] <TAB> return labeldict",false,if label :,"if ""false"" in label :",0.1,0.0
"def exists_col_to_many(self, select_columns: List[str]) -> bool: <TAB> for column in select_columns: <TAB> <TAB> if is_column_dotted(column): <TAB> <TAB> <TAB> root_relation = get_column_root_relation(column) <TAB> <TAB> <TAB> if self.is_relation_many_to_many( <TAB> <TAB> <TAB> <TAB> root_relation <TAB> <TAB> <TAB> ) or self.is_relation_one_to_many(root_relation): <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",true,if is_column_dotted ( column ) :,if is_column_dotted ( column ) :,0.75,0.0
"def check_sequence_matches(seq, template): <TAB> i = 0 <TAB> for pattern in template: <TAB> <TAB> if not isinstance(pattern, set): <TAB> <TAB> <TAB> pattern = {pattern} <TAB> <TAB> got = set(seq[i : i + len(pattern)]) <TAB> <TAB> assert got == pattern <TAB> <TAB> i += len(got)",true,"if not isinstance ( pattern , set ) :","if not isinstance ( pattern , set ) :",0.75,0.0
"def load_modules( <TAB> to_load, load, attr, modules_dict, excluded_aliases, loading_message=None ): <TAB> if loading_message: <TAB> <TAB> print(loading_message) <TAB> for name in to_load: <TAB> <TAB> module = load(name) <TAB> <TAB> if module is None or not hasattr(module, attr): <TAB> <TAB> <TAB> continue <TAB> <TAB> cls = getattr(module, attr) <TAB> <TAB> if hasattr(cls, ""initialize"") and not cls.initialize(): <TAB> <TAB> <TAB> continue <TAB> <TAB> if hasattr(module, ""aliases""): <TAB> <TAB> <TAB> for alias in module.aliases(): <TAB> <TAB> <TAB> <TAB> if alias not in excluded_aliases: <TAB> <TAB> <TAB> <TAB> <TAB> modules_dict[alias] = module <TAB> <TAB> else: <TAB> <TAB> <TAB> modules_dict[name] = module <TAB> if loading_message: <TAB> <TAB> print()",true,"if hasattr ( module , ""aliases"" ) :","if hasattr ( module , ""aliases"" ) :",0.75,0.0
"def result(): <TAB> # ""global"" does not work here... <TAB> R, V = rays, virtual_rays <TAB> if V is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> V = normalize_rays(V, lattice) <TAB> <TAB> if check: <TAB> <TAB> <TAB> R = PointCollection(V, lattice) <TAB> <TAB> <TAB> V = PointCollection(V, lattice) <TAB> <TAB> <TAB> d = lattice.dimension() <TAB> <TAB> <TAB> if len(V) != d - R.dim() or (R + V).dim() != d: <TAB> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> <TAB> ""virtual rays must be linearly "" <TAB> <TAB> <TAB> <TAB> <TAB> ""independent and with other rays span the ambient space."" <TAB> <TAB> <TAB> <TAB> ) <TAB> return RationalPolyhedralFan(cones, R, lattice, is_complete, V)",true,if normalize :,if normalize :,0.53,0.0
"def communicate(self, _input=None, _timeout=None) -> Tuple[bytes, bytes]: <TAB> if parse_args().print_commands: <TAB> <TAB> if self.args != get_sudo_refresh_command(): <TAB> <TAB> <TAB> print_stderr( <TAB> <TAB> <TAB> <TAB> color_line(""=> "", 14) + "" "".join(str(arg) for arg in self.args) <TAB> <TAB> <TAB> ) <TAB> stdout, stderr = super().communicate(_input, _timeout) <TAB> self.stdout_text = stdout.decode(""utf-8"") if stdout else None <TAB> self.stderr_text = stderr.decode(""utf-8"") if stderr else None <TAB> return stdout, stderr",true,if self . args != get_sudo_refresh_command ( ) :,if self . args != get_sudo_refresh_command ( ) :,0.75,0.0
"def convert(data): <TAB> result = [] <TAB> for d in data: <TAB> <TAB> # noinspection PyCompatibility <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result.append((d[0], None, d[1])) <TAB> <TAB> elif isinstance(d, basestring): <TAB> <TAB> <TAB> result.append(d) <TAB> return result",true,"if isinstance ( d , tuple ) and len ( d ) == 2 :","if isinstance ( d , tuple ) and len ( d ) == 2 :",1.0,0.0
"def validate(self, value): <TAB> try: <TAB> <TAB> value = [ <TAB> <TAB> <TAB> datetime.datetime.strptime(range, ""%Y-%m-%d %H:%M:%S"") <TAB> <TAB> <TAB> for range in value.split("" to "") <TAB> <TAB> ] <TAB> <TAB> if (len(value) == 2) and (value[0] <= value[1]): <TAB> <TAB> <TAB> return True <TAB> <TAB> else: <TAB> <TAB> <TAB> return False <TAB> except ValueError: <TAB> <TAB> return False",true,if ( len ( value ) == 2 ) and ( value [ 0 ] <= value [ 1 ] ) :,if ( len ( value ) == 2 ) and ( value [ 0 ] <= value [ 1 ] ) :,1.0,0.0
"def rmdir(dirname): <TAB> if dirname[-1] == os.sep: <TAB> <TAB> dirname = dirname[:-1] <TAB> if os.path.islink(dirname): <TAB> <TAB> return  # do not clear link - we can get out of dir <TAB> for f in os.listdir(dirname): <TAB> <TAB> if f in (""."", ""..""): <TAB> <TAB> <TAB> continue <TAB> <TAB> path = dirname + os.sep + f <TAB> <TAB> if os.path.isdir(path): <TAB> <TAB> <TAB> rmdir(path) <TAB> <TAB> else: <TAB> <TAB> <TAB> os.unlink(path) <TAB> os.rmdir(dirname)",true,if os . path . isdir ( path ) :,if os . path . isdir ( path ) :,1.0,0.0
"def onCompletion(self, text): <TAB> res = [] <TAB> for l in text.split(""\n""): <TAB> <TAB> if not l: <TAB> <TAB> <TAB> continue <TAB> <TAB> l = l.split("":"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> res.append([l[0].strip(), l[1].strip()]) <TAB> self.panel.setSlides(res)",true,if len ( l ) != 2 :,if len ( l ) != 2 :,0.75,0.0
"def pytest_collection_modifyitems(items): <TAB> for item in items: <TAB> <TAB> if item.nodeid.startswith(""tests/infer""): <TAB> <TAB> <TAB> if ""stage"" not in item.keywords: <TAB> <TAB> <TAB> <TAB> item.add_marker(pytest.mark.stage(""unit"")) <TAB> <TAB> <TAB> if ""init"" not in item.keywords: <TAB> <TAB> <TAB> <TAB> item.add_marker(pytest.mark.init(rng_seed=123))",true,"if item . nodeid . startswith ( ""tests/infer"" ) :","if item . nodeid . startswith ( ""tests/infer"" ) :",0.75,0.0
"def build_message(self, options, target): <TAB> message = multipart.MIMEMultipart() <TAB> for name, value in list(options.items()): <TAB> <TAB> if name == ""EMAIL_BODY"": <TAB> <TAB> <TAB> self.add_body(message, value) <TAB> <TAB> elif name == ""EMAIL_ATTACHMENT"": <TAB> <TAB> <TAB> self.add_attachment(message, value) <TAB> <TAB> else:  # From, To, Subject, etc. <TAB> <TAB> <TAB> self.set_option(message, name, value, target) <TAB> return message",true,"elif name == ""EMAIL_ATTACHMENT"" :","elif name == ""EMAIL_ATTACHMENT"" :",1.0,0.0
"def extend_with_zeroes(b): <TAB> try: <TAB> <TAB> for x in b: <TAB> <TAB> <TAB> x = to_constant(x) <TAB> <TAB> <TAB> if isinstance(x, int): <TAB> <TAB> <TAB> <TAB> yield (x) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> yield (0) <TAB> <TAB> for _ in range(32): <TAB> <TAB> <TAB> yield (0) <TAB> except Exception as e: <TAB> <TAB> return",true,"if isinstance ( x , int ) :","if isinstance ( x , int ) :",0.75,0.0
"def _start_cluster(*, cleanup_atexit=True): <TAB> global _default_cluster <TAB> if _default_cluster is None: <TAB> <TAB> cluster_addr = os.environ.get(""EDGEDB_TEST_CLUSTER_ADDR"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> conn_spec = json.loads(cluster_addr) <TAB> <TAB> <TAB> _default_cluster = edgedb_cluster.RunningCluster(**conn_spec) <TAB> <TAB> else: <TAB> <TAB> <TAB> data_dir = os.environ.get(""EDGEDB_TEST_DATA_DIR"") <TAB> <TAB> <TAB> _default_cluster = _init_cluster( <TAB> <TAB> <TAB> <TAB> data_dir=data_dir, cleanup_atexit=cleanup_atexit <TAB> <TAB> <TAB> ) <TAB> return _default_cluster",true,if cluster_addr :,if cluster_addr :,0.53,0.0
"def preprocess_raw_enwik9(input_filename, output_filename): <TAB> with open(input_filename, ""r"") as f1: <TAB> <TAB> with open(output_filename, ""w"") as f2: <TAB> <TAB> <TAB> while True: <TAB> <TAB> <TAB> <TAB> line = f1.readline() <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> line = list(enwik9_norm_transform([line]))[0] <TAB> <TAB> <TAB> <TAB> if line != "" "" and line != """": <TAB> <TAB> <TAB> <TAB> <TAB> if line[0] == "" "": <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> line = line[1:] <TAB> <TAB> <TAB> <TAB> <TAB> f2.writelines(line + ""\n"")",true,if not line :,if not line :,0.75,0.0
"def is_entirely_italic(line): <TAB> style = subs.styles.get(line.style, SSAStyle.DEFAULT_STYLE) <TAB> for fragment, sty in parse_tags(line.text, style, subs.styles): <TAB> <TAB> fragment = fragment.replace(r""\h"", "" "") <TAB> <TAB> fragment = fragment.replace(r""\n"", ""\n"") <TAB> <TAB> fragment = fragment.replace(r""\N"", ""\n"") <TAB> <TAB> if not sty.italic and fragment and not fragment.isspace(): <TAB> <TAB> <TAB> return False <TAB> return True",true,if not sty . italic and fragment and not fragment . isspace ( ) :,if not sty . italic and fragment and not fragment . isspace ( ) :,1.0,0.0
def __get_all_nodes(self): <TAB> nodes = [] <TAB> next_level = [self.__tree.get_root()] <TAB> while len(next_level) != 0: <TAB> <TAB> cur_level = next_level <TAB> <TAB> nodes += next_level <TAB> <TAB> next_level = [] <TAB> <TAB> for cur_node in cur_level: <TAB> <TAB> <TAB> children = cur_node.get_children() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> next_level += children <TAB> return nodes,false,if children is not None :,if children :,0.05,0.0
"def _openvpn_stdout(self): <TAB> while True: <TAB> <TAB> line = self.process.stdout.readline() <TAB> <TAB> if not line: <TAB> <TAB> <TAB> if self.process.poll() is not None or self.is_interrupted(): <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> time.sleep(0.05) <TAB> <TAB> <TAB> continue <TAB> <TAB> yield <TAB> <TAB> try: <TAB> <TAB> <TAB> self.server.output.push_output(line) <TAB> <TAB> except: <TAB> <TAB> <TAB> logger.exception( <TAB> <TAB> <TAB> <TAB> ""Failed to push vpn output"", <TAB> <TAB> <TAB> <TAB> ""server"", <TAB> <TAB> <TAB> <TAB> server_id=self.server.id, <TAB> <TAB> <TAB> ) <TAB> <TAB> yield",true,if self . process . poll ( ) is not None or self . is_interrupted ( ) :,if self . process . poll ( ) is not None or self . is_interrupted ( ) :,1.0,0.0
"def payment_received_handler(event): <TAB> if isinstance(event.message.action, types.MessageActionPaymentSentMe): <TAB> <TAB> payment: types.MessageActionPaymentSentMe = event.message.action <TAB> <TAB> # do something after payment was received <TAB> <TAB> if payment.payload.decode(""UTF-8"") == ""product A"": <TAB> <TAB> <TAB> await bot.send_message( <TAB> <TAB> <TAB> <TAB> event.message.from_id, ""Thank you for buying product A!"" <TAB> <TAB> <TAB> ) <TAB> <TAB> elif payment.payload.decode(""UTF-8"") == ""product B"": <TAB> <TAB> <TAB> await bot.send_message( <TAB> <TAB> <TAB> <TAB> event.message.from_id, ""Thank you for buying product B!"" <TAB> <TAB> <TAB> ) <TAB> <TAB> raise events.StopPropagation",true,"elif payment . payload . decode ( ""UTF-8"" ) == ""product B"" :","elif payment . payload . decode ( ""UTF-8"" ) == ""product B"" :",0.75,0.0
"def spaces_after(token, prev, next, min=-1, max=-1, min_desc=None, max_desc=None): <TAB> if next is not None and token.end_mark.line == next.start_mark.line: <TAB> <TAB> spaces = next.start_mark.pointer - token.end_mark.pointer <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return LintProblem( <TAB> <TAB> <TAB> <TAB> token.start_mark.line + 1, next.start_mark.column, max_desc <TAB> <TAB> <TAB> ) <TAB> <TAB> elif min != -1 and spaces < min: <TAB> <TAB> <TAB> return LintProblem( <TAB> <TAB> <TAB> <TAB> token.start_mark.line + 1, next.start_mark.column + 1, min_desc <TAB> <TAB> <TAB> )",true,if max != - 1 and spaces > max :,if max != - 1 and spaces > max :,1.0,0.0
"def seek_to_block(self, pos): <TAB> baseofs = 0 <TAB> ofs = 0 <TAB> for b in self.blocks: <TAB> <TAB> if ofs + b.uncompressed_size > pos: <TAB> <TAB> <TAB> self.current_block = b <TAB> <TAB> <TAB> break <TAB> <TAB> baseofs += b.compressed_size <TAB> <TAB> ofs += b.uncompressed_size <TAB> else: <TAB> <TAB> self.current_block = None <TAB> <TAB> self.current_stream = BytesIO(b"""") <TAB> <TAB> return <TAB> self.current_block_start = ofs <TAB> self.stream.seek(self.basepos + baseofs) <TAB> buf = BytesIO(self.stream.read(self.current_block.compressed_size)) <TAB> self.current_stream = self.current_block.decompress(buf)",true,if ofs + b . uncompressed_size > pos :,if ofs + b . uncompressed_size > pos :,0.75,0.0
"def rewrite_hunks(hunks): <TAB> # type: (List[Hunk]) -> Iterator[Hunk] <TAB> # Assumes `hunks` are sorted, and from the same file <TAB> deltas = (hunk.b_length - hunk.a_length for hunk in hunks) <TAB> offsets = accumulate(deltas, initial=0) <TAB> for hunk, offset in zip(hunks, offsets): <TAB> <TAB> new_b = hunk.a_start + offset <TAB> <TAB> if hunk_of_additions_only(hunk): <TAB> <TAB> <TAB> new_b += 1 <TAB> <TAB> elif hunk_of_removals_only(hunk): <TAB> <TAB> <TAB> new_b -= 1 <TAB> <TAB> yield hunk._replace(b_start=new_b)",true,elif hunk_of_removals_only ( hunk ) :,elif hunk_of_removals_only ( hunk ) :,0.75,0.0
"def do_query(data, q): <TAB> ret = [] <TAB> if not q: <TAB> <TAB> return ret <TAB> qkey = q[0] <TAB> for key, value in iterate(data): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if key == qkey: <TAB> <TAB> <TAB> <TAB> ret.append(value) <TAB> <TAB> <TAB> elif is_iterable(value): <TAB> <TAB> <TAB> <TAB> ret.extend(do_query(value, q)) <TAB> <TAB> else: <TAB> <TAB> <TAB> if not is_iterable(value): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if key == qkey: <TAB> <TAB> <TAB> <TAB> ret.extend(do_query(value, q[1:])) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> ret.extend(do_query(value, q)) <TAB> return ret",false,if len ( q ) == 1 :,if value is not None :,0.02,0.0
"def get_url(token, base_url): <TAB> """"""Parse an <url> token."""""" <TAB> if token.type == ""url"": <TAB> <TAB> return _get_url_tuple(token.value, base_url) <TAB> elif token.type == ""function"": <TAB> <TAB> if token.name == ""attr"": <TAB> <TAB> <TAB> return check_attr_function(token, ""url"") <TAB> <TAB> elif token.name == ""url"" and len(token.arguments) in (1, 2): <TAB> <TAB> <TAB> # Ignore url modifiers <TAB> <TAB> <TAB> # See https://drafts.csswg.org/css-values-3/#urls <TAB> <TAB> <TAB> return _get_url_tuple(token.arguments[0].value, base_url)",false,"elif token . name == ""url"" and len ( token . arguments ) in ( 1 , 2 ) :","if token . name == ""attr"" :",0.05,0.0
"def read(self, count): <TAB> if self.closed: <TAB> <TAB> return self.upstream.read(count) <TAB> try: <TAB> <TAB> while len(self.upstream) < count: <TAB> <TAB> <TAB> if self.buf_in or self._poll_read(10): <TAB> <TAB> <TAB> <TAB> with self.buf_in: <TAB> <TAB> <TAB> <TAB> <TAB> self.transport.downstream_recv(self.buf_in) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> return self.upstream.read(count) <TAB> except: <TAB> <TAB> logger.debug(traceback.format_exc())",true,if self . buf_in or self . _poll_read ( 10 ) :,if self . buf_in or self . _poll_read ( 10 ) :,0.75,0.0
"def get_timestamp_for_block( <TAB> self, block_hash: HexBytes, max_tries: Optional[int] = 10 ) -> int: <TAB> counter = 0 <TAB> block: AttributeDict = None <TAB> if block_hash in self._block_cache.keys(): <TAB> <TAB> block = self._block_cache.get(block_hash) <TAB> else: <TAB> <TAB> while block is None: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise ValueError(f""Block hash {block_hash.hex()} does not exist."") <TAB> <TAB> <TAB> counter += 1 <TAB> <TAB> <TAB> block = self._block_cache.get(block_hash) <TAB> <TAB> <TAB> await asyncio.sleep(0.5) <TAB> return block.get(""timestamp"")",false,if counter == max_tries :,if counter >= max_tries :,0.33,0.0
"def reader(): <TAB> batch_out = [] <TAB> for video_name in self.video_list: <TAB> <TAB> video_idx = self.video_list.index(video_name) <TAB> <TAB> video_feat = self.load_file(video_name) <TAB> <TAB> batch_out.append((video_feat, video_idx)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield batch_out <TAB> <TAB> <TAB> batch_out = []",true,if len ( batch_out ) == self . batch_size :,if len ( batch_out ) == self . batch_size :,0.75,0.0
"def cleanup(): <TAB> gscript.message(_(""Erasing temporary files..."")) <TAB> for temp_map, maptype in temp_maps: <TAB> <TAB> if gscript.find_file(temp_map, element=maptype)[""name""]: <TAB> <TAB> <TAB> gscript.run_command( <TAB> <TAB> <TAB> <TAB> ""g.remove"", flags=""f"", type=maptype, name=temp_map, quiet=True <TAB> <TAB> <TAB> )",true,"if gscript . find_file ( temp_map , element = maptype ) [ ""name"" ] :","if gscript . find_file ( temp_map , element = maptype ) [ ""name"" ] :",1.0,0.0
"def run(self): <TAB> while True: <TAB> <TAB> try: <TAB> <TAB> <TAB> with DelayedKeyboardInterrupt(): <TAB> <TAB> <TAB> <TAB> raw_inputs = self._parent_task_queue.get() <TAB> <TAB> <TAB> <TAB> if self._has_stop_signal(raw_inputs): <TAB> <TAB> <TAB> <TAB> <TAB> self._rq.put(raw_inputs, block=True) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> if self._flow_type == BATCH: <TAB> <TAB> <TAB> <TAB> <TAB> self._rq.put(raw_inputs, block=True) <TAB> <TAB> <TAB> <TAB> elif self._flow_type == REALTIME: <TAB> <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self._rq.put(raw_inputs, block=False) <TAB> <TAB> <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> except KeyboardInterrupt: <TAB> <TAB> <TAB> continue",true,if self . _has_stop_signal ( raw_inputs ) :,if self . _has_stop_signal ( raw_inputs ) :,0.75,0.0
"def handle_sent(self, elt): <TAB> sent = [] <TAB> for child in elt: <TAB> <TAB> if child.tag in (""mw"", ""hi"", ""corr"", ""trunc""): <TAB> <TAB> <TAB> sent += [self.handle_word(w) for w in child] <TAB> <TAB> elif child.tag in (""w"", ""c""): <TAB> <TAB> <TAB> sent.append(self.handle_word(child)) <TAB> <TAB> elif child.tag not in self.tags_to_ignore: <TAB> <TAB> <TAB> raise ValueError(""Unexpected element %s"" % child.tag) <TAB> return BNCSentence(elt.attrib[""n""], sent)",true,"elif child . tag in ( ""w"" , ""c"" ) :","elif child . tag in ( ""w"" , ""c"" ) :",0.75,0.0
"def bind_subscribers_to_graphql_type(self, graphql_type): <TAB> for field, subscriber in self._subscribers.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError(""Field %s is not defined on type %s"" % (field, self.name)) <TAB> <TAB> graphql_type.fields[field].subscribe = subscriber",true,if field not in graphql_type . fields :,if field not in graphql_type . fields :,0.75,0.0
"def _get_from_json(self, *, name, version): <TAB> url = urljoin(self.url, posixpath.join(name, str(version), ""json"")) <TAB> async with aiohttp_session(auth=self.auth) as session: <TAB> <TAB> async with session.get(url) as response: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise PackageNotFoundError(package=name, url=url) <TAB> <TAB> <TAB> response.raise_for_status() <TAB> <TAB> <TAB> response = await response.json() <TAB> dist = response[""info""][""requires_dist""] or [] <TAB> if dist: <TAB> <TAB> return dist <TAB> # If no requires_dist then package metadata can be broken. <TAB> # Let's check distribution files. <TAB> return await self._get_from_files(response[""urls""])",false,if response . status == 404 :,if response is None :,0.04,0.0
"def is_active(self): <TAB> if not self.pk: <TAB> <TAB> log_level = get_setting(""LOG_MISSING_SWITCHES"") <TAB> <TAB> if log_level: <TAB> <TAB> <TAB> logger.log(log_level, ""Switch %s not found"", self.name) <TAB> <TAB> if get_setting(""CREATE_MISSING_SWITCHES""): <TAB> <TAB> <TAB> switch, _created = Switch.objects.get_or_create( <TAB> <TAB> <TAB> <TAB> name=self.name, defaults={""active"": get_setting(""SWITCH_DEFAULT"")} <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> cache = get_cache() <TAB> <TAB> <TAB> cache.set(self._cache_key(self.name), switch) <TAB> <TAB> return get_setting(""SWITCH_DEFAULT"") <TAB> return self.active",true,"if get_setting ( ""CREATE_MISSING_SWITCHES"" ) :","if get_setting ( ""CREATE_MISSING_SWITCHES"" ) :",0.75,0.0
"def add_requirements(self, requirements): <TAB> if self._legacy: <TAB> <TAB> self._legacy.add_requirements(requirements) <TAB> else: <TAB> <TAB> run_requires = self._data.setdefault(""run_requires"", []) <TAB> <TAB> always = None <TAB> <TAB> for entry in run_requires: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> always = entry <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if always is None: <TAB> <TAB> <TAB> always = {""requires"": requirements} <TAB> <TAB> <TAB> run_requires.insert(0, always) <TAB> <TAB> else: <TAB> <TAB> <TAB> rset = set(always[""requires""]) | set(requirements) <TAB> <TAB> <TAB> always[""requires""] = sorted(rset)",false,"if ""environment"" not in entry and ""extra"" not in entry :",if entry . requires == requirements :,0.01,0.0
"def display_failures_for_single_test(result: TestResult) -> None: <TAB> """"""Display a failure for a single method / endpoint."""""" <TAB> display_subsection(result) <TAB> checks = _get_unique_failures(result.checks) <TAB> for idx, check in enumerate(checks, 1): <TAB> <TAB> message: Optional[str] <TAB> <TAB> if check.message: <TAB> <TAB> <TAB> message = f""{idx}. {check.message}"" <TAB> <TAB> else: <TAB> <TAB> <TAB> message = None <TAB> <TAB> example = cast(Case, check.example)  # filtered in `_get_unique_failures` <TAB> <TAB> display_example(example, check.name, message, result.seed) <TAB> <TAB> # Display every time except the last check <TAB> <TAB> if idx != len(checks): <TAB> <TAB> <TAB> click.echo(""\n"")",true,if idx != len ( checks ) :,if idx != len ( checks ) :,0.75,0.0
"def __call__(self, frame: FrameType, event: str, arg: Any) -> ""CallTracer"": <TAB> code = frame.f_code <TAB> if ( <TAB> <TAB> event not in SUPPORTED_EVENTS <TAB> <TAB> or code.co_name == ""trace_types"" <TAB> <TAB> or self.should_trace <TAB> <TAB> and not self.should_trace(code) <TAB> ): <TAB> <TAB> return self <TAB> try: <TAB> <TAB> if event == EVENT_CALL: <TAB> <TAB> <TAB> self.handle_call(frame) <TAB> <TAB> elif event == EVENT_RETURN: <TAB> <TAB> <TAB> self.handle_return(frame, arg) <TAB> <TAB> else: <TAB> <TAB> <TAB> logger.error(""Cannot handle event %s"", event) <TAB> except Exception: <TAB> <TAB> logger.exception(""Failed collecting trace"") <TAB> return self",true,elif event == EVENT_RETURN :,elif event == EVENT_RETURN :,1.0,0.0
"def get_maps(test): <TAB> pages = set() <TAB> for addr in test[""pre""][""memory""].keys(): <TAB> <TAB> pages.add(addr >> 12) <TAB> for addr in test[""pos""][""memory""].keys(): <TAB> <TAB> pages.add(addr >> 12) <TAB> maps = [] <TAB> for p in sorted(pages): <TAB> <TAB> if len(maps) > 0 and maps[-1][0] + maps[-1][1] == p << 12: <TAB> <TAB> <TAB> maps[-1] = (maps[-1][0], maps[-1][1] + 0x1000) <TAB> <TAB> else: <TAB> <TAB> <TAB> maps.append((p << 12, 0x1000)) <TAB> return maps",true,if len ( maps ) > 0 and maps [ - 1 ] [ 0 ] + maps [ - 1 ] [ 1 ] == p << 12 :,if len ( maps ) > 0 and maps [ - 1 ] [ 0 ] + maps [ - 1 ] [ 1 ] == p << 12 :,1.0,0.0
"def process_rotate_aes_key(self): <TAB> if hasattr(self.options, ""rotate_aes_key"") and isinstance( <TAB> <TAB> self.options.rotate_aes_key, six.string_types <TAB> ): <TAB> <TAB> if self.options.rotate_aes_key.lower() == ""true"": <TAB> <TAB> <TAB> self.options.rotate_aes_key = True <TAB> <TAB> elif self.options.rotate_aes_key.lower() == ""false"": <TAB> <TAB> <TAB> self.options.rotate_aes_key = False",false,"if self . options . rotate_aes_key . lower ( ) == ""true"" :","elif self . options . rotate_aes_key . lower ( ) == ""false"" :",0.36,0.0
"def apply_figure(self, figure): <TAB> super(legend_text_legend, self).apply_figure(figure) <TAB> properties = self.properties.copy() <TAB> with suppress(KeyError): <TAB> <TAB> del properties[""margin""] <TAB> with suppress(KeyError): <TAB> <TAB> texts = figure._themeable[""legend_text_legend""] <TAB> <TAB> for text in texts: <TAB> <TAB> <TAB> if not hasattr(text, ""_x""):  # textarea <TAB> <TAB> <TAB> <TAB> text = text._text <TAB> <TAB> <TAB> text.set(**properties)",true,"if not hasattr ( text , ""_x"" ) :","if not hasattr ( text , ""_x"" ) :",0.75,0.0
"def tearDown(self): <TAB> for i in range(len(self.tree) - 1, -1, -1): <TAB> <TAB> s = os.path.join(self.root, self.tree[i]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> os.rmdir(s) <TAB> <TAB> else: <TAB> <TAB> <TAB> os.remove(s) <TAB> os.rmdir(self.root)",false,"if not ""."" in s :",if i == 0 :,0.03,0.0
"def _get_id(self, type, id): <TAB> fields = id.split("":"") <TAB> if len(fields) >= 3: <TAB> <TAB> if type != fields[-2]: <TAB> <TAB> <TAB> logger.warning( <TAB> <TAB> <TAB> <TAB> ""Expected id of type %s but found type %s %s"", type, fields[-2], id <TAB> <TAB> <TAB> ) <TAB> <TAB> return fields[-1] <TAB> fields = id.split(""/"") <TAB> if len(fields) >= 3: <TAB> <TAB> itype = fields[-2] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> logger.warning( <TAB> <TAB> <TAB> <TAB> ""Expected id of type %s but found type %s %s"", type, itype, id <TAB> <TAB> <TAB> ) <TAB> <TAB> return fields[-1].split(""?"")[0] <TAB> return id",false,if type != itype :,if itype != itype :,0.39,0.0
"def candidates() -> Generator[""Symbol"", None, None]: <TAB> s = self <TAB> if Symbol.debug_lookup: <TAB> <TAB> Symbol.debug_print(""searching in self:"") <TAB> <TAB> print(s.to_string(Symbol.debug_indent + 1), end="""") <TAB> while True: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield s <TAB> <TAB> if recurseInAnon: <TAB> <TAB> <TAB> yield from s.children_recurse_anon <TAB> <TAB> else: <TAB> <TAB> <TAB> yield from s._children <TAB> <TAB> if s.siblingAbove is None: <TAB> <TAB> <TAB> break <TAB> <TAB> s = s.siblingAbove <TAB> <TAB> if Symbol.debug_lookup: <TAB> <TAB> <TAB> Symbol.debug_print(""searching in sibling:"") <TAB> <TAB> <TAB> print(s.to_string(Symbol.debug_indent + 1), end="""")",false,if matchSelf :,if s . parentAbove is None :,0.05,0.0
"def records(account_id): <TAB> """"""Fetch locks data"""""" <TAB> s = boto3.Session() <TAB> table = s.resource(""dynamodb"").Table(""Sphere11.Dev.ResourceLocks"") <TAB> results = table.scan() <TAB> for r in results[""Items""]: <TAB> <TAB> if ""LockDate"" in r: <TAB> <TAB> <TAB> r[""LockDate""] = datetime.fromtimestamp(r[""LockDate""]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> r[""RevisionDate""] = datetime.fromtimestamp(r[""RevisionDate""]) <TAB> print(tabulate.tabulate(results[""Items""], headers=""keys"", tablefmt=""fancy_grid""))",true,"if ""RevisionDate"" in r :","if ""RevisionDate"" in r :",0.75,0.0
"def _handle_errors(errors): <TAB> """"""Log out and possibly reraise errors during import."""""" <TAB> if not errors: <TAB> <TAB> return <TAB> log_all = True  # pylint: disable=unused-variable <TAB> err_msg = ""T2T: skipped importing {num_missing} data_generators modules."" <TAB> print(err_msg.format(num_missing=len(errors))) <TAB> for module, err in errors: <TAB> <TAB> err_str = str(err) <TAB> <TAB> if log_all: <TAB> <TAB> <TAB> print(""Did not import module: %s; Cause: %s"" % (module, err_str)) <TAB> <TAB> if not _is_import_err_msg(err_str, module): <TAB> <TAB> <TAB> print(""From module %s"" % module) <TAB> <TAB> <TAB> raise err",true,"if not _is_import_err_msg ( err_str , module ) :","if not _is_import_err_msg ( err_str , module ) :",0.75,0.0
"def find_needle(self, tree, focused=None): <TAB> if isinstance(tree, list): <TAB> <TAB> for el in tree: <TAB> <TAB> <TAB> res = self.find_needle(el, focused) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return res <TAB> elif isinstance(tree, dict): <TAB> <TAB> nodes = tree.get(""nodes"", []) + tree.get(""floating_nodes"", []) <TAB> <TAB> if focused: <TAB> <TAB> <TAB> for node in nodes: <TAB> <TAB> <TAB> <TAB> if node[""id""] == focused[""id""]: <TAB> <TAB> <TAB> <TAB> <TAB> return tree <TAB> <TAB> elif tree[""focused""]: <TAB> <TAB> <TAB> return tree <TAB> <TAB> return self.find_needle(nodes, focused) <TAB> return {}",true,if res :,if res :,0.53,0.0
"def available_datasets(self): <TAB> """"""Automatically determine datasets provided by this file"""""" <TAB> res = self.resolution <TAB> coordinates = [""pixel_longitude"", ""pixel_latitude""] <TAB> for var_name, val in self.file_content.items(): <TAB> <TAB> if isinstance(val, netCDF4.Variable): <TAB> <TAB> <TAB> ds_info = { <TAB> <TAB> <TAB> <TAB> ""file_type"": self.filetype_info[""file_type""], <TAB> <TAB> <TAB> <TAB> ""resolution"": res, <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> ds_info[""coordinates""] = coordinates <TAB> <TAB> <TAB> yield DatasetID(name=var_name, resolution=res), ds_info",false,if not self . is_geo :,if coordinates :,0.11,0.0
"def get_subkeys(self, key): <TAB> # TODO: once we revamp the registry emulation, <TAB> # make this better <TAB> parent_path = key.get_path() <TAB> subkeys = [] <TAB> for k in self.keys: <TAB> <TAB> test_path = k.get_path() <TAB> <TAB> if test_path.lower().startswith(parent_path.lower()): <TAB> <TAB> <TAB> sub = test_path[len(parent_path) :] <TAB> <TAB> <TAB> if sub.startswith(""\\""): <TAB> <TAB> <TAB> <TAB> sub = sub[1:] <TAB> <TAB> <TAB> end_slash = sub.find(""\\"") <TAB> <TAB> <TAB> if end_slash >= 0: <TAB> <TAB> <TAB> <TAB> sub = sub[:end_slash] <TAB> <TAB> <TAB> if not sub: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> subkeys.append(sub) <TAB> return subkeys",false,if test_path . lower ( ) . startswith ( parent_path . lower ( ) ) :,"if sub . startswith ( ""\\"" ) :",0.04,0.0
"def default(self, o): <TAB> try: <TAB> <TAB> if type(o) == datetime.datetime: <TAB> <TAB> <TAB> return str(o) <TAB> <TAB> else: <TAB> <TAB> <TAB> # remove unwanted attributes from the provider object during conversion to json <TAB> <TAB> <TAB> if hasattr(o, ""profile""): <TAB> <TAB> <TAB> <TAB> del o.profile <TAB> <TAB> <TAB> if hasattr(o, ""credentials""): <TAB> <TAB> <TAB> <TAB> del o.credentials <TAB> <TAB> <TAB> if hasattr(o, ""metadata_path""): <TAB> <TAB> <TAB> <TAB> del o.metadata_path <TAB> <TAB> <TAB> if hasattr(o, ""services_config""): <TAB> <TAB> <TAB> <TAB> del o.services_config <TAB> <TAB> <TAB> return vars(o) <TAB> except Exception as e: <TAB> <TAB> return str(o)",false,"if hasattr ( o , ""credentials"" ) :","if hasattr ( o , ""metadata_path"" ) :",0.55,0.0
"def submit(self, fn, *args, **kwargs): <TAB> with self._shutdown_lock: <TAB> <TAB> if self._shutdown: <TAB> <TAB> <TAB> raise RuntimeError(""cannot schedule new futures after shutdown"") <TAB> <TAB> f = _base.Future() <TAB> <TAB> w = _WorkItem(f, fn, args, kwargs) <TAB> <TAB> self._work_queue.put(w) <TAB> <TAB> self._adjust_thread_count() <TAB> <TAB> return f",true,if self . _shutdown :,if self . _shutdown :,0.75,0.0
"def __viewerKeyPress(viewer, event): <TAB> view = viewer.view() <TAB> if not isinstance(view, GafferSceneUI.SceneView): <TAB> <TAB> return False <TAB> if event == __editSourceKeyPress: <TAB> <TAB> selectedPath = __sceneViewSelectedPath(view) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> __editSourceNode(view.getContext(), view[""in""], selectedPath) <TAB> <TAB> return True <TAB> elif event == __editTweaksKeyPress: <TAB> <TAB> selectedPath = __sceneViewSelectedPath(view) <TAB> <TAB> if selectedPath is not None: <TAB> <TAB> <TAB> __editTweaksNode(view.getContext(), view[""in""], selectedPath) <TAB> <TAB> return True",true,if selectedPath is not None :,if selectedPath is not None :,0.75,0.0
"def _split_to_option_groups_and_paths(self, args): <TAB> opt_groups = [] <TAB> current = [] <TAB> for arg in args: <TAB> <TAB> if arg.replace(""-"", """") == """" and len(arg) >= 3: <TAB> <TAB> <TAB> opts = self._arg_parser.parse_args(current)[0] <TAB> <TAB> <TAB> opt_groups.append(opts) <TAB> <TAB> <TAB> current = [] <TAB> <TAB> else: <TAB> <TAB> <TAB> current.append(arg) <TAB> if opt_groups: <TAB> <TAB> return opt_groups, current <TAB> raise ValueError(""Nothing to split"")",true,"if arg . replace ( ""-"" , """" ) == """" and len ( arg ) >= 3 :","if arg . replace ( ""-"" , """" ) == """" and len ( arg ) >= 3 :",1.0,0.0
"def _on_change(self): <TAB> changed = False <TAB> self.save() <TAB> for key, value in self.data.items(): <TAB> <TAB> if isinstance(value, bool): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if isinstance(value, int): <TAB> <TAB> <TAB> if value != 1: <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> elif value is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> elif len(value) != 0: <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> break <TAB> self._reset_button.disabled = not changed",false,if value :,if value != 1 :,0.1,0.0
"def wait_for_child(pid, timeout=1.0): <TAB> deadline = mitogen.core.now() + timeout <TAB> while timeout < mitogen.core.now(): <TAB> <TAB> try: <TAB> <TAB> <TAB> target_pid, status = os.waitpid(pid, os.WNOHANG) <TAB> <TAB> <TAB> if target_pid == pid: <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> e = sys.exc_info()[1] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> time.sleep(0.05) <TAB> assert False, ""wait_for_child() timed out""",false,if e . args [ 0 ] == errno . ECHILD :,if e . errno == errno . EINTR :,0.18,0.0
"def _get_os_version_lsb_release(): <TAB> try: <TAB> <TAB> output = subprocess.check_output(""lsb_release -sri"", shell=True) <TAB> <TAB> lines = output.strip().split() <TAB> <TAB> name, version = lines <TAB> <TAB> if version.lower() == ""rolling"": <TAB> <TAB> <TAB> version = """" <TAB> <TAB> return name, version <TAB> except: <TAB> <TAB> return _get_os_version_uname()",true,"if version . lower ( ) == ""rolling"" :","if version . lower ( ) == ""rolling"" :",0.75,0.0
"def _check_snapshot_status_healthy(self, snapshot_uuid): <TAB> status = """" <TAB> try: <TAB> <TAB> while True: <TAB> <TAB> <TAB> status, locked = self._get_snapshot_status(snapshot_uuid) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> eventlet.sleep(2) <TAB> except Exception: <TAB> <TAB> with excutils.save_and_reraise_exception(): <TAB> <TAB> <TAB> LOG.exception(""Failed to get snapshot status. [%s]"", snapshot_uuid) <TAB> LOG.debug( <TAB> <TAB> ""Lun [%(snapshot)s], status [%(status)s]."", <TAB> <TAB> {""snapshot"": snapshot_uuid, ""status"": status}, <TAB> ) <TAB> return status == ""Healthy""",false,if not locked :,"if status == ""Healthy"" and locked :",0.19,0.0
"def CountButtons(self): <TAB> """"""Returns the number of visible buttons in the docked pane."""""" <TAB> n = 0 <TAB> if self.HasCaption() or self.HasCaptionLeft(): <TAB> <TAB> if isinstance(wx.GetTopLevelParent(self.window), AuiFloatingFrame): <TAB> <TAB> <TAB> return 1 <TAB> <TAB> if self.HasCloseButton(): <TAB> <TAB> <TAB> n += 1 <TAB> <TAB> if self.HasMaximizeButton(): <TAB> <TAB> <TAB> n += 1 <TAB> <TAB> if self.HasMinimizeButton(): <TAB> <TAB> <TAB> n += 1 <TAB> <TAB> if self.HasPinButton(): <TAB> <TAB> <TAB> n += 1 <TAB> return n",true,if self . HasCloseButton ( ) :,if self . HasCloseButton ( ) :,0.75,0.0
"def _url_encode_impl(obj, charset, encode_keys, sort, key): <TAB> from .datastructures import iter_multi_items <TAB> iterable = iter_multi_items(obj) <TAB> if sort: <TAB> <TAB> iterable = sorted(iterable, key=key) <TAB> for key, value in iterable: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not isinstance(key, bytes): <TAB> <TAB> <TAB> key = text_type(key).encode(charset) <TAB> <TAB> if not isinstance(value, bytes): <TAB> <TAB> <TAB> value = text_type(value).encode(charset) <TAB> <TAB> yield _fast_url_quote_plus(key) + ""="" + _fast_url_quote_plus(value)",false,if value is None :,if not value :,0.04,0.0
"def get_response(self, exc_fmt=None): <TAB> self.callback = None <TAB> if __debug__: <TAB> <TAB> self.parent._log(3, ""%s:%s.ready.wait"" % (self.name, self.tag)) <TAB> self.ready.wait() <TAB> if self.aborted is not None: <TAB> <TAB> typ, val = self.aborted <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> exc_fmt = ""%s - %%s"" % typ <TAB> <TAB> raise typ(exc_fmt % str(val)) <TAB> return self.response",true,if exc_fmt is None :,if exc_fmt is None :,0.75,0.0
"def extract_items(self): <TAB> responses = self.fetch() <TAB> items = [] <TAB> for response in responses: <TAB> <TAB> page_key = response.meta.get(""page_key"") or response.url <TAB> <TAB> item = {""key"": page_key, ""items"": None, ""templates"": None} <TAB> <TAB> extracted_items = [ <TAB> <TAB> <TAB> dict(i) for i in self.spider.parse(response) if not isinstance(i, Request) <TAB> <TAB> ] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> item[""items""] = extracted_items <TAB> <TAB> <TAB> item[""templates""] = [ <TAB> <TAB> <TAB> <TAB> i[""_template""] for i in extracted_items if i.get(""_template"") <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> items.append(item) <TAB> return items",true,if extracted_items :,if extracted_items :,0.53,0.0
"def fit_one(self, x): <TAB> for i, xi in x.items(): <TAB> <TAB> if self.with_centering: <TAB> <TAB> <TAB> self.median[i].update(xi) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.iqr[i].update(xi) <TAB> return self",false,if self . with_scaling :,if self . with_iqr :,0.39,0.0
"def find_word_bounds(self, text, index, allowed_chars): <TAB> right = left = index <TAB> done = False <TAB> while not done: <TAB> <TAB> if left == 0: <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self.word_boundary_char(text[left - 1]): <TAB> <TAB> <TAB> left -= 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> done = True <TAB> done = False <TAB> while not done: <TAB> <TAB> if right == len(text): <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self.word_boundary_char(text[right]): <TAB> <TAB> <TAB> right += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> done = True <TAB> return left, right",false,elif not self . word_boundary_char ( text [ left - 1 ] ) :,elif not self . word_boundary_char ( text [ right - 1 ] ) :,0.64,0.0
"def _validate_duplicate_detection_history_time_window(namespace): <TAB> if namespace.duplicate_detection_history_time_window: <TAB> <TAB> if iso8601pattern.match(namespace.duplicate_detection_history_time_window): <TAB> <TAB> <TAB> pass <TAB> <TAB> elif timedeltapattern.match(namespace.duplicate_detection_history_time_window): <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> raise CLIError( <TAB> <TAB> <TAB> <TAB> ""--duplicate-detection-history-time-window Value Error : {0} value is not in ISO 8601 timespan / duration format. e.g. PT10M for duration of 10 min or 00:10:00 for duration of 10 min"".format( <TAB> <TAB> <TAB> <TAB> <TAB> namespace.duplicate_detection_history_time_window <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> )",true,elif timedeltapattern . match ( namespace . duplicate_detection_history_time_window ) :,elif timedeltapattern . match ( namespace . duplicate_detection_history_time_window ) :,0.75,0.0
"def get_subkeys(self, key): <TAB> # TODO: once we revamp the registry emulation, <TAB> # make this better <TAB> parent_path = key.get_path() <TAB> subkeys = [] <TAB> for k in self.keys: <TAB> <TAB> test_path = k.get_path() <TAB> <TAB> if test_path.lower().startswith(parent_path.lower()): <TAB> <TAB> <TAB> sub = test_path[len(parent_path) :] <TAB> <TAB> <TAB> if sub.startswith(""\\""): <TAB> <TAB> <TAB> <TAB> sub = sub[1:] <TAB> <TAB> <TAB> end_slash = sub.find(""\\"") <TAB> <TAB> <TAB> if end_slash >= 0: <TAB> <TAB> <TAB> <TAB> sub = sub[:end_slash] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> subkeys.append(sub) <TAB> return subkeys",false,if not sub :,"if sub == ""\\"" :",0.05,0.0
"def generator(self, data): <TAB> if self._config.SILENT: <TAB> <TAB> silent_vars = self._get_silent_vars() <TAB> for task in data: <TAB> <TAB> for var, val in task.environment_variables(): <TAB> <TAB> <TAB> if self._config.SILENT: <TAB> <TAB> <TAB> <TAB> if var in silent_vars: <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> 0, <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> int(task.UniqueProcessId), <TAB> <TAB> <TAB> <TAB> <TAB> str(task.ImageFileName), <TAB> <TAB> <TAB> <TAB> <TAB> Address(task.Peb.ProcessParameters.Environment), <TAB> <TAB> <TAB> <TAB> <TAB> str(var), <TAB> <TAB> <TAB> <TAB> <TAB> str(val), <TAB> <TAB> <TAB> <TAB> ], <TAB> <TAB> <TAB> )",false,if self . _config . SILENT :,if self . _config . SLENT :,0.57,0.0
"def start_requests(self): <TAB> if self.fail_before_yield: <TAB> <TAB> 1 / 0 <TAB> for s in range(100): <TAB> <TAB> qargs = {""total"": 10, ""seed"": s} <TAB> <TAB> url = self.mockserver.url(""/follow?%s"") % urlencode(qargs, doseq=1) <TAB> <TAB> yield Request(url, meta={""seed"": s}) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> 2 / 0 <TAB> assert self.seedsseen, ""All start requests consumed before any download happened""",false,if self . fail_yielding :,if self . fail_before_yield :,0.39,0.0
"def populateGridlines(self): <TAB> cTicks = self.getSystemCurve(self.ticksId) <TAB> cGridlines = self.getSystemCurve(self.gridlinesId) <TAB> cGridlines.clearPoints() <TAB> nTicks = cTicks.getNPoints() <TAB> for iTick in range(nTicks): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> p = cTicks.getPoint(iTick) <TAB> <TAB> <TAB> cGridlines.addPoint(p.getX(), p.getY())",false,if self . hasGridlines and ( iTick % self . ticksPerGridline ) == 0 :,if iTick not in cGridlines :,0.01,0.0
"def handle_before_events(request, event_list): <TAB> if not event_list: <TAB> <TAB> return """" <TAB> if not hasattr(event_list, ""__iter__""): <TAB> <TAB> project = event_list.project <TAB> <TAB> event_list = [event_list] <TAB> else: <TAB> <TAB> projects = set(e.project for e in event_list) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> project = projects.pop() <TAB> <TAB> else: <TAB> <TAB> <TAB> project = None <TAB> for plugin in plugins.for_project(project): <TAB> <TAB> safe_execute(plugin.before_events, request, event_list) <TAB> return """"",false,if len ( projects ) == 1 :,if projects :,0.02,0.0
"def handle_parse_result(self, ctx, opts, args): <TAB> if self.name in opts: <TAB> <TAB> if self.mutually_exclusive.intersection(opts): <TAB> <TAB> <TAB> self._raise_exclusive_error() <TAB> <TAB> if self.multiple and len(set(opts[self.name])) > 1: <TAB> <TAB> <TAB> self._raise_exclusive_error() <TAB> return super(MutuallyExclusiveOption, self).handle_parse_result(ctx, opts, args)",false,if self . mutually_exclusive . intersection ( opts ) :,if self . multiple and len ( set ( opts [ self . name ] ) ) > 1 :,0.1,0.0
"def current_word(cursor_offset, line): <TAB> """"""the object.attribute.attribute just before or under the cursor"""""" <TAB> pos = cursor_offset <TAB> start = pos <TAB> end = pos <TAB> word = None <TAB> for m in current_word_re.finditer(line): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> start = m.start(1) <TAB> <TAB> <TAB> end = m.end(1) <TAB> <TAB> <TAB> word = m.group(1) <TAB> if word is None: <TAB> <TAB> return None <TAB> return LinePart(start, end, word)",false,if m . start ( 1 ) < pos and m . end ( 1 ) >= pos :,if m :,0.01,0.0
"def query_to_script_path(path, query): <TAB> if path != ""*"": <TAB> <TAB> script = os.path.join(path, query.split("" "")[0]) <TAB> <TAB> if not os.path.exists(script): <TAB> <TAB> <TAB> raise IOError(""Script '{}' not found in script directory"".format(query)) <TAB> <TAB> return os.path.join(path, query).split("" "") <TAB> return query",true,if not os . path . exists ( script ) :,if not os . path . exists ( script ) :,0.75,0.0
"def expand(self, pbegin): <TAB> # TODO(b/151921205): we have to do an identity map for unmodified <TAB> # PCollections below because otherwise we get an error from beam. <TAB> identity_map = ""Identity"" >> beam.Map(lambda x: x) <TAB> if self._dataset_key.is_flattened_dataset_key(): <TAB> <TAB> if self._flat_pcollection: <TAB> <TAB> <TAB> return self._flat_pcollection | identity_map <TAB> <TAB> else: <TAB> <TAB> <TAB> return list( <TAB> <TAB> <TAB> <TAB> self._pcollection_dict.values() <TAB> <TAB> <TAB> ) | ""FlattenAnalysisInputs"" >> beam.Flatten(pipeline=pbegin.pipeline) <TAB> else: <TAB> <TAB> return self._pcollection_dict[self._dataset_key] | identity_map",true,if self . _flat_pcollection :,if self . _flat_pcollection :,0.75,0.0
"def processCoords(coords): <TAB> newcoords = deque() <TAB> for (x, y, z) in coords: <TAB> <TAB> for _dir, offsets in faceDirections: <TAB> <TAB> <TAB> if _dir == FaceYIncreasing: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> dx, dy, dz = offsets <TAB> <TAB> <TAB> p = (x + dx, y + dy, z + dz) <TAB> <TAB> <TAB> if p not in box: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> nx, ny, nz = p <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> level.setBlockAt(nx, ny, nz, waterID) <TAB> <TAB> <TAB> <TAB> newcoords.append(p) <TAB> return newcoords",false,"if level . blockAt ( nx , ny , nz ) == 0 :",if nx != ny and nz != nz :,0.01,0.0
"def delete_byfilter(userId, remove=True, session=None, **dbfilter): <TAB> if not session: <TAB> <TAB> session = db.Session <TAB> ret = False <TAB> results = session.query(ObjectStorageMetadata).filter_by(**dbfilter) <TAB> if results: <TAB> <TAB> for result in results: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> session.delete(result) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> result.update( <TAB> <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""record_state_key"": ""to_delete"", <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""record_state_val"": str(time.time()), <TAB> <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ret = True <TAB> return ret",true,if remove :,if remove :,0.53,0.0
"def fields(self, fields): <TAB> fields_xml = """" <TAB> for field in fields: <TAB> <TAB> field_dict = DEFAULT_FIELD.copy() <TAB> <TAB> field_dict.update(field) <TAB> <TAB> if self.unique_key_field == field[""name""]: <TAB> <TAB> <TAB> field_dict[""required""] = ""true"" <TAB> <TAB> fields_xml += FIELD_XML_TEMPLATE % field_dict + ""\n"" <TAB> self.xml = force_unicode( <TAB> <TAB> force_unicode(self.xml).replace( <TAB> <TAB> <TAB> u""<!-- REPLACE FIELDS -->"", force_unicode(fields_xml) <TAB> <TAB> ) <TAB> )",true,"if self . unique_key_field == field [ ""name"" ] :","if self . unique_key_field == field [ ""name"" ] :",0.75,0.0
"def get_all_users(self, access_token, timeout=None): <TAB> if timeout is None: <TAB> <TAB> timeout = DEFAULT_TIMEOUT <TAB> headers = self.retrieve_header(access_token) <TAB> try: <TAB> <TAB> response = await self.standard_request( <TAB> <TAB> <TAB> ""get"", ""/walkoff/api/users"", timeout=DEFAULT_TIMEOUT, headers=headers <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> resp = await response.json() <TAB> <TAB> <TAB> return resp, ""Success"" <TAB> <TAB> else: <TAB> <TAB> <TAB> return ""Invalid Credentials"" <TAB> except asyncio.CancelledError: <TAB> <TAB> return False, ""TimedOut""",false,if response . status == 200 :,if response :,0.04,0.0
"def set_val(): <TAB> idx = 0 <TAB> for idx in range(0, len(model)): <TAB> <TAB> row = model[idx] <TAB> <TAB> if value and row[0] == value: <TAB> <TAB> <TAB> break <TAB> <TAB> if idx == len(os_widget.get_model()) - 1: <TAB> <TAB> <TAB> idx = -1 <TAB> os_widget.set_active(idx) <TAB> if idx == -1: <TAB> <TAB> os_widget.set_active(0) <TAB> if idx >= 0: <TAB> <TAB> return row[1] <TAB> if self.show_all_os: <TAB> <TAB> return None",true,if idx == len ( os_widget . get_model ( ) ) - 1 :,if idx == len ( os_widget . get_model ( ) ) - 1 :,0.75,0.0
"def translate_module_name(module: str, relative: int) -> Tuple[str, int]: <TAB> for pkg in VENDOR_PACKAGES: <TAB> <TAB> for alt in ""six.moves"", ""six"": <TAB> <TAB> <TAB> substr = ""{}.{}"".format(pkg, alt) <TAB> <TAB> <TAB> if module.endswith(""."" + substr) or (module == substr and relative): <TAB> <TAB> <TAB> <TAB> return alt, 0 <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return alt + ""."" + module.partition(""."" + substr + ""."")[2], 0 <TAB> return module, relative",false,"if ""."" + substr + ""."" in module :",if substr in module :,0.07,0.0
"def escape(m): <TAB> all, tail = m.group(0, 1) <TAB> assert all.startswith(""\\"") <TAB> esc = simple_escapes.get(tail) <TAB> if esc is not None: <TAB> <TAB> return esc <TAB> if tail.startswith(""x""): <TAB> <TAB> hexes = tail[1:] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError(""invalid hex string escape ('\\%s')"" % tail) <TAB> <TAB> try: <TAB> <TAB> <TAB> i = int(hexes, 16) <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> raise ValueError(""invalid hex string escape ('\\%s')"" % tail) <TAB> else: <TAB> <TAB> try: <TAB> <TAB> <TAB> i = int(tail, 8) <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> raise ValueError(""invalid octal string escape ('\\%s')"" % tail) <TAB> return chr(i)",false,if len ( hexes ) < 2 :,if len ( hexes ) != 16 :,0.52,0.0
"def __get_k8s_container_name(self, job_wrapper): <TAB> # These must follow a specific regex for Kubernetes. <TAB> raw_id = job_wrapper.job_destination.id <TAB> if isinstance(raw_id, str): <TAB> <TAB> cleaned_id = re.sub(""[^-a-z0-9]"", ""-"", raw_id) <TAB> <TAB> if cleaned_id.startswith(""-"") or cleaned_id.endswith(""-""): <TAB> <TAB> <TAB> cleaned_id = ""x%sx"" % cleaned_id <TAB> <TAB> return cleaned_id <TAB> return ""job-container""",true,"if cleaned_id . startswith ( ""-"" ) or cleaned_id . endswith ( ""-"" ) :","if cleaned_id . startswith ( ""-"" ) or cleaned_id . endswith ( ""-"" ) :",1.0,0.0
"def _power_exact(y, xc, yc, xe): <TAB> yc, ye = y.int, y.exp <TAB> while yc % 10 == 0: <TAB> <TAB> yc //= 10 <TAB> <TAB> ye += 1 <TAB> if xc == 1: <TAB> <TAB> xe *= yc <TAB> <TAB> while xe % 10 == 0: <TAB> <TAB> <TAB> xe //= 10 <TAB> <TAB> <TAB> ye += 1 <TAB> <TAB> if ye < 0: <TAB> <TAB> <TAB> return None <TAB> <TAB> exponent = xe * 10 ** ye <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> xc = exponent <TAB> <TAB> else: <TAB> <TAB> <TAB> xc = 0 <TAB> <TAB> return 5",false,if y and xe :,if xc == 1 :,0.03,0.0
"def lpush(key, *vals, **kwargs): <TAB> ttl = kwargs.get(""ttl"") <TAB> cap = kwargs.get(""cap"") <TAB> if not ttl and not cap: <TAB> <TAB> _client.lpush(key, *vals) <TAB> else: <TAB> <TAB> pipe = _client.pipeline() <TAB> <TAB> pipe.lpush(key, *vals) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> pipe.ltrim(key, 0, cap) <TAB> <TAB> if ttl: <TAB> <TAB> <TAB> pipe.expire(key, ttl) <TAB> <TAB> pipe.execute()",true,if cap :,if cap :,0.53,0.0
"def render_headers(self) -> bytes: <TAB> if not hasattr(self, ""_headers""): <TAB> <TAB> parts = [ <TAB> <TAB> <TAB> b""Content-Disposition: form-data; "", <TAB> <TAB> <TAB> format_form_param(""name"", self.name), <TAB> <TAB> ] <TAB> <TAB> if self.filename: <TAB> <TAB> <TAB> filename = format_form_param(""filename"", self.filename) <TAB> <TAB> <TAB> parts.extend([b""; "", filename]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> content_type = self.content_type.encode() <TAB> <TAB> <TAB> parts.extend([b""\r\nContent-Type: "", content_type]) <TAB> <TAB> parts.append(b""\r\n\r\n"") <TAB> <TAB> self._headers = b"""".join(parts) <TAB> return self._headers",false,if self . content_type is not None :,if self . content_type :,0.23,0.0
"def validate_custom_field_data(field_type: int, field_data: ProfileFieldData) -> None: <TAB> try: <TAB> <TAB> if field_type == CustomProfileField.CHOICE: <TAB> <TAB> <TAB> # Choice type field must have at least have one choice <TAB> <TAB> <TAB> if len(field_data) < 1: <TAB> <TAB> <TAB> <TAB> raise JsonableError(_(""Field must have at least one choice."")) <TAB> <TAB> <TAB> validate_choice_field_data(field_data) <TAB> <TAB> elif field_type == CustomProfileField.EXTERNAL_ACCOUNT: <TAB> <TAB> <TAB> validate_external_account_field_data(field_data) <TAB> except ValidationError as error: <TAB> <TAB> raise JsonableError(error.message)",false,if field_type == CustomProfileField . CHOICE :,elif field_type == CustomProfileField . EXTERNAL_ACCOUNT :,0.29,0.0
"def get_data(self, path): <TAB> """"""Gross hack to contort loader to deal w/ load_*()'s bad API."""""" <TAB> if self.file and path == self.path: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> file = self.file <TAB> <TAB> else: <TAB> <TAB> <TAB> self.file = file = open(self.path, ""r"") <TAB> <TAB> with file: <TAB> <TAB> <TAB> # Technically should be returning bytes, but <TAB> <TAB> <TAB> # SourceLoader.get_code() just passed what is returned to <TAB> <TAB> <TAB> # compile() which can handle str. And converting to bytes would <TAB> <TAB> <TAB> # require figuring out the encoding to decode to and <TAB> <TAB> <TAB> # tokenize.detect_encoding() only accepts bytes. <TAB> <TAB> <TAB> return file.read() <TAB> else: <TAB> <TAB> return super().get_data(path)",false,if not self . file . closed :,if self . file :,0.08,0.0
"def handle_read(self): <TAB> """"""Called when there is data waiting to be read."""""" <TAB> try: <TAB> <TAB> chunk = self.recv(self.ac_in_buffer_size) <TAB> except RetryError: <TAB> <TAB> pass <TAB> except socket.error: <TAB> <TAB> self.handle_error() <TAB> else: <TAB> <TAB> self.tot_bytes_received += len(chunk) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.transfer_finished = True <TAB> <TAB> <TAB> # self.close()  # <-- asyncore.recv() already do that... <TAB> <TAB> <TAB> return <TAB> <TAB> if self._data_wrapper is not None: <TAB> <TAB> <TAB> chunk = self._data_wrapper(chunk) <TAB> <TAB> try: <TAB> <TAB> <TAB> self.file_obj.write(chunk) <TAB> <TAB> except OSError as err: <TAB> <TAB> <TAB> raise _FileReadWriteError(err)",false,if not chunk :,if self . tot_bytes_received >= self . transfer_size :,0.03,0.0
"def _swig_extract_dependency_files(self, src): <TAB> dep = [] <TAB> for line in open(src): <TAB> <TAB> if line.startswith(""#include"") or line.startswith(""%include""): <TAB> <TAB> <TAB> line = line.split("" "")[1].strip(""""""'""\r\n"""""") <TAB> <TAB> <TAB> if not (""<"" in line or line in dep): <TAB> <TAB> <TAB> <TAB> dep.append(line) <TAB> return [i for i in dep if os.path.exists(i)]",true,"if line . startswith ( ""#include"" ) or line . startswith ( ""%include"" ) :","if line . startswith ( ""#include"" ) or line . startswith ( ""%include"" ) :",1.0,0.0
"def buffer(self, lines, scroll_end=True, scroll_if_editing=False): <TAB> ""Add data to be displayed in the buffer."" <TAB> self.values.extend(lines) <TAB> if scroll_end: <TAB> <TAB> if not self.editing: <TAB> <TAB> <TAB> self.start_display_at = len(self.values) - len(self._my_widgets) <TAB> <TAB> elif scroll_if_editing: <TAB> <TAB> <TAB> self.start_display_at = len(self.values) - len(self._my_widgets)",true,elif scroll_if_editing :,elif scroll_if_editing :,0.51,0.0
"def test_getline(self): <TAB> with tokenize.open(self.file_name) as fp: <TAB> <TAB> for index, line in enumerate(fp): <TAB> <TAB> <TAB> if not line.endswith(""\n""): <TAB> <TAB> <TAB> <TAB> line += ""\n"" <TAB> <TAB> <TAB> cached_line = linecache.getline(self.file_name, index + 1) <TAB> <TAB> <TAB> self.assertEqual(line, cached_line)",true,"if not line . endswith ( ""\n"" ) :","if not line . endswith ( ""\n"" ) :",0.75,0.0
"def selectRow(self, rowNumber, highlight=None): <TAB> if rowNumber == ""h"": <TAB> <TAB> rowNumber = 0 <TAB> else: <TAB> <TAB> rowNumber = int(rowNumber) + 1 <TAB> if 1 > rowNumber >= len(self.cells) + 1: <TAB> <TAB> raise Exception(""Invalid row number."") <TAB> else: <TAB> <TAB> selected = self.cells[rowNumber][0].selected <TAB> <TAB> for cell in self.cells[rowNumber]: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if selected: <TAB> <TAB> <TAB> <TAB> <TAB> cell.deselect() <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> cell.select() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> if highlight: <TAB> <TAB> <TAB> <TAB> <TAB> cell.mouseEnter() <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> cell.mouseLeave()",false,if highlight is None :,if cell . selected :,0.03,0.0
"def put(self, session): <TAB> with sess_lock: <TAB> <TAB> self.parent.put(session) <TAB> <TAB> # Do not store the session if skip paths <TAB> <TAB> for sp in self.skip_paths: <TAB> <TAB> <TAB> if request.path.startswith(sp): <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> if session.sid in self._cache: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> del self._cache[session.sid] <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> self._cache[session.sid] = session <TAB> self._normalize()",false,if session . sid in self . _cache :,if request . path . startswith ( sp ) :,0.02,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB> if tt == 10: <TAB> <TAB> <TAB> length = d.getVarInt32() <TAB> <TAB> <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB> <TAB> <TAB> d.skip(length) <TAB> <TAB> <TAB> self.add_status().TryMerge(tmp) <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.add_doc_id(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0: <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 18 :,if tt == 18 :,0.75,0.0
"def extract(self, zip): <TAB> max_nb = maxNbFile(self) <TAB> for index, field in enumerate(zip.array(""file"")): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.warning( <TAB> <TAB> <TAB> <TAB> ""ZIP archive contains many files, but only first %s files are processed"" <TAB> <TAB> <TAB> <TAB> % max_nb <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> break <TAB> <TAB> self.processFile(field)",false,if max_nb is not None and max_nb <= index :,if index > max_nb :,0.02,0.0
"def get_norm(norm, out_channels): <TAB> if isinstance(norm, str): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> norm = { <TAB> <TAB> <TAB> ""BN"": BatchNorm2d, <TAB> <TAB> <TAB> ""GN"": lambda channels: nn.GroupNorm(32, channels), <TAB> <TAB> <TAB> ""nnSyncBN"": nn.SyncBatchNorm,  # keep for debugging <TAB> <TAB> <TAB> """": lambda x: x, <TAB> <TAB> }[norm] <TAB> return norm(out_channels)",true,if len ( norm ) == 0 :,if len ( norm ) == 0 :,0.75,0.0
"def execute(self): <TAB> if self._dirty or not self._qr: <TAB> <TAB> model_class = self.model_class <TAB> <TAB> query_meta = self.get_query_meta() <TAB> <TAB> if self._tuples: <TAB> <TAB> <TAB> ResultWrapper = TuplesQueryResultWrapper <TAB> <TAB> elif self._dicts: <TAB> <TAB> <TAB> ResultWrapper = DictQueryResultWrapper <TAB> <TAB> elif self._naive or not self._joins or self.verify_naive(): <TAB> <TAB> <TAB> ResultWrapper = NaiveQueryResultWrapper <TAB> <TAB> elif self._aggregate_rows: <TAB> <TAB> <TAB> ResultWrapper = AggregateQueryResultWrapper <TAB> <TAB> else: <TAB> <TAB> <TAB> ResultWrapper = ModelQueryResultWrapper <TAB> <TAB> self._qr = ResultWrapper(model_class, self._execute(), query_meta) <TAB> <TAB> self._dirty = False <TAB> <TAB> return self._qr <TAB> else: <TAB> <TAB> return self._qr",true,elif self . _aggregate_rows :,elif self . _aggregate_rows :,0.75,0.0
"def emitIpToDomainsData(self, data, event): <TAB> self.emitRawRirData(data, event) <TAB> domains = data.get(""domains"") <TAB> if isinstance(domains, list): <TAB> <TAB> for domain in domains: <TAB> <TAB> <TAB> if self.checkForStop(): <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> domain = domain.strip() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.emitHostname(domain, event)",true,if domain :,if domain :,0.53,0.0
"def delete(self): <TAB> from weblate.trans.models import Change, Suggestion, Vote <TAB> fast_deletes = [] <TAB> for item in self.fast_deletes: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> fast_deletes.append(Vote.objects.filter(suggestion__in=item)) <TAB> <TAB> <TAB> fast_deletes.append(Change.objects.filter(suggestion__in=item)) <TAB> <TAB> fast_deletes.append(item) <TAB> self.fast_deletes = fast_deletes <TAB> return super().delete()",false,if item . model is Suggestion :,if item not in fast_deletes :,0.09,0.0
"def token(self): <TAB> if not self._token: <TAB> <TAB> try: <TAB> <TAB> <TAB> cookie_token = self.state[""request""].headers.cookie[CSRF_TOKEN].value <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> cookie_token = """" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._token = cookie_token <TAB> <TAB> else: <TAB> <TAB> <TAB> self._token = get_random_string(TOKEN_LENGTH) <TAB> return self._token",false,if len ( cookie_token ) == TOKEN_LENGTH :,if cookie_token :,0.02,0.0
"def get_logs(last_file=None, last_time=None): <TAB> try: <TAB> <TAB> response = client.get_logs(last_file=last_file, last_time=last_time) <TAB> <TAB> get_logs_streamer( <TAB> <TAB> <TAB> show_timestamp=not hide_time, <TAB> <TAB> <TAB> all_containers=all_containers, <TAB> <TAB> <TAB> all_info=all_info, <TAB> <TAB> )(response) <TAB> <TAB> return response <TAB> except (ApiException, HTTPError) as e: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> handle_cli_error( <TAB> <TAB> <TAB> <TAB> e, <TAB> <TAB> <TAB> <TAB> message=""Could not get logs for run `{}`."".format(client.run_uuid), <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> sys.exit(1)",false,if not follow :,if client . debug :,0.04,0.0
"def update(self, targets): <TAB> Section.update(self, targets) <TAB> outputNames = set() <TAB> for target in targets: <TAB> <TAB> g = target.globals() <TAB> <TAB> outputNames.update([k for k in g.keys() if k.startswith(""output:"")]) <TAB> rows = [] <TAB> outputNames = sorted(outputNames) <TAB> for outputName in outputNames: <TAB> <TAB> row = self.__rows.get(outputName) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> row = _OutputRow(outputName) <TAB> <TAB> <TAB> self.__rows[outputName] = row <TAB> <TAB> row.update(targets) <TAB> <TAB> row.setAlternate(len(rows) % 2) <TAB> <TAB> rows.append(row) <TAB> self._mainColumn()[:] = rows",true,if row is None :,if row is None :,0.75,0.0
"def getBranches(self): <TAB> returned = [] <TAB> for git_branch_line in self._executeGitCommandAssertSuccess(""branch"").stdout: <TAB> <TAB> if git_branch_line.startswith(""*""): <TAB> <TAB> <TAB> git_branch_line = git_branch_line[1:] <TAB> <TAB> git_branch_line = git_branch_line.strip() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> alias_name, aliased = git_branch_line.split(BRANCH_ALIAS_MARKER) <TAB> <TAB> <TAB> returned.append(branch.LocalBranchAlias(self, alias_name, aliased)) <TAB> <TAB> else: <TAB> <TAB> <TAB> returned.append(branch.LocalBranch(self, git_branch_line)) <TAB> return returned",true,if BRANCH_ALIAS_MARKER in git_branch_line :,if BRANCH_ALIAS_MARKER in git_branch_line :,0.75,0.0
"def has_bad_headers(self): <TAB> headers = [self.sender, self.reply_to] + self.recipients <TAB> for header in headers: <TAB> <TAB> if _has_newline(header): <TAB> <TAB> <TAB> return True <TAB> if self.subject: <TAB> <TAB> if _has_newline(self.subject): <TAB> <TAB> <TAB> for linenum, line in enumerate(self.subject.split(""\r\n"")): <TAB> <TAB> <TAB> <TAB> if not line: <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if linenum > 0 and line[0] not in ""\t "": <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if _has_newline(line): <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if len(line.strip()) == 0: <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",false,"if linenum > 0 and line [ 0 ] not in ""\t "" :","if linenum > 0 and line [ 0 ] not in ""\t"" :",0.64,0.0
"def resolve_references(self, note, reflist): <TAB> assert len(note[""ids""]) == 1 <TAB> id = note[""ids""][0] <TAB> for ref in reflist: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> ref.delattr(""refname"") <TAB> <TAB> ref[""refid""] = id <TAB> <TAB> assert len(ref[""ids""]) == 1 <TAB> <TAB> note.add_backref(ref[""ids""][0]) <TAB> <TAB> ref.resolved = 1 <TAB> note.resolved = 1",true,if ref . resolved :,if ref . resolved :,0.75,0.0
"def pickPath(self, color): <TAB> self.path[color] = () <TAB> currentPos = self.starts[color] <TAB> while True: <TAB> <TAB> minDist = None <TAB> <TAB> minGuide = None <TAB> <TAB> for guide in self.guides[color]: <TAB> <TAB> <TAB> guideDist = dist(currentPos, guide) <TAB> <TAB> <TAB> if minDist == None or guideDist < minDist: <TAB> <TAB> <TAB> <TAB> minDist = guideDist <TAB> <TAB> <TAB> <TAB> minGuide = guide <TAB> <TAB> if dist(currentPos, self.ends[color]) == 1: <TAB> <TAB> <TAB> return <TAB> <TAB> if minGuide == None: <TAB> <TAB> <TAB> return <TAB> <TAB> self.path[color] = self.path[color] + (minGuide,) <TAB> <TAB> currentPos = minGuide <TAB> <TAB> self.guides[color].remove(minGuide)",true,"if dist ( currentPos , self . ends [ color ] ) == 1 :","if dist ( currentPos , self . ends [ color ] ) == 1 :",0.75,0.0
"def __hierarchyViewKeyPress(hierarchyView, event): <TAB> if event == __editSourceKeyPress: <TAB> <TAB> selectedPath = __hierarchyViewSelectedPath(hierarchyView) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> __editSourceNode( <TAB> <TAB> <TAB> <TAB> hierarchyView.getContext(), hierarchyView.scene(), selectedPath <TAB> <TAB> <TAB> ) <TAB> <TAB> return True <TAB> elif event == __editTweaksKeyPress: <TAB> <TAB> selectedPath = __hierarchyViewSelectedPath(hierarchyView) <TAB> <TAB> if selectedPath is not None: <TAB> <TAB> <TAB> __editTweaksNode( <TAB> <TAB> <TAB> <TAB> hierarchyView.getContext(), hierarchyView.scene(), selectedPath <TAB> <TAB> <TAB> ) <TAB> <TAB> return True",true,if selectedPath is not None :,if selectedPath is not None :,0.75,0.0
"def getSubsegments(self): <TAB> for num, localdata in self.lfh.LocalData: <TAB> <TAB> for bucket, seginfo in localdata.SegmentInfo: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield Win32Subsegment(self.trace, self.heap, seginfo.ActiveSubsegment)",false,if seginfo . ActiveSubsegment == 0 :,if num == bucket :,0.02,0.0
"def test_full_hd_bluray(self): <TAB> cur_test = ""full_hd_bluray"" <TAB> cur_qual = common.Quality.FULLHDBLURAY <TAB> for name, tests in iteritems(self.test_cases): <TAB> <TAB> for test in tests: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.assertEqual(cur_qual, common.Quality.name_quality(test)) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.assertNotEqual(cur_qual, common.Quality.name_quality(test))",true,if name == cur_test :,if name == cur_test :,0.75,0.0
"def calc(self, arg): <TAB> op = arg[""op""] <TAB> if op == ""C"": <TAB> <TAB> self.clear() <TAB> <TAB> return str(self.current) <TAB> num = decimal.Decimal(arg[""num""]) <TAB> if self.op: <TAB> <TAB> if self.op == ""+"": <TAB> <TAB> <TAB> self.current += num <TAB> <TAB> elif self.op == ""-"": <TAB> <TAB> <TAB> self.current -= num <TAB> <TAB> elif self.op == ""*"": <TAB> <TAB> <TAB> self.current *= num <TAB> <TAB> elif self.op == ""/"": <TAB> <TAB> <TAB> self.current /= num <TAB> <TAB> self.op = op <TAB> else: <TAB> <TAB> self.op = op <TAB> <TAB> self.current = num <TAB> res = str(self.current) <TAB> if op == ""="": <TAB> <TAB> self.clear() <TAB> return res",true,"elif self . op == ""/"" :","elif self . op == ""/"" :",1.0,0.0
"def strip_export_type(path): <TAB> matched = re.search(r""#([a-zA-Z0-9\-]+\\+[a-zA-Z0-9\-]+)?$"", path.encode(""utf-8"")) <TAB> mime_type = None <TAB> if matched: <TAB> <TAB> fragment = matched.group(0) <TAB> <TAB> mime_type = matched.group(1) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> mime_type = mime_type.replace(""+"", ""/"") <TAB> <TAB> path = path[: -len(fragment)] <TAB> return (path, mime_type)",false,if mime_type is not None :,if mime_type :,0.05,0.0
"def _save_as_module(file, data, binary=False): <TAB> if not data: <TAB> <TAB> return <TAB> with open(file, ""w"") as f: <TAB> <TAB> f.write(""DATA="") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> f.write('""') <TAB> <TAB> <TAB> f.write(base64.b64encode(data).decode(""ascii"")) <TAB> <TAB> <TAB> f.write('""') <TAB> <TAB> else: <TAB> <TAB> <TAB> f.write(str(data).replace(""\\\\"", ""\\"")) <TAB> <TAB> f.flush()",true,if binary :,if binary :,0.53,0.0
"def ProcessStringLiteral(self): <TAB> if self._lastToken == None or self._lastToken.type == self.OpenBrace: <TAB> <TAB> text = super(JavaScriptBaseLexer, self).text <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if len(self._scopeStrictModes) > 0: <TAB> <TAB> <TAB> <TAB> self._scopeStrictModes.pop() <TAB> <TAB> <TAB> self._useStrictCurrent = True <TAB> <TAB> <TAB> self._scopeStrictModes.append(self._useStrictCurrent)",false,"if text == '""use strict""' or text == ""'use strict'"" :",if text :,0.02,0.0
"def run(self, ttl=None): <TAB> self.zeroconf = zeroconf.Zeroconf() <TAB> zeroconf.ServiceBrowser(self.zeroconf, self.domain, MDNSHandler(self)) <TAB> if ttl: <TAB> <TAB> gobject.timeout_add(ttl * 1000, self.shutdown) <TAB> self.__running = True <TAB> self.__mainloop = gobject.MainLoop() <TAB> context = self.__mainloop.get_context() <TAB> while self.__running: <TAB> <TAB> try: <TAB> <TAB> <TAB> if context.pending(): <TAB> <TAB> <TAB> <TAB> context.iteration(True) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> time.sleep(0.1) <TAB> <TAB> except KeyboardInterrupt: <TAB> <TAB> <TAB> break <TAB> self.zeroconf.close() <TAB> logger.debug(""MDNSListener.run() quit"")",true,if context . pending ( ) :,if context . pending ( ) :,0.75,0.0
"def topology_change_notify(self, port_state): <TAB> notice = False <TAB> if port_state is PORT_STATE_FORWARD: <TAB> <TAB> for port in self.ports.values(): <TAB> <TAB> <TAB> if port.role is DESIGNATED_PORT: <TAB> <TAB> <TAB> <TAB> notice = True <TAB> <TAB> <TAB> <TAB> break <TAB> else: <TAB> <TAB> notice = True <TAB> if notice: <TAB> <TAB> self.send_event(EventTopologyChange(self.dp)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._transmit_tc_bpdu() <TAB> <TAB> else: <TAB> <TAB> <TAB> self._transmit_tcn_bpdu()",false,if self . is_root_bridge :,if port_state is PORT_STATE_FORWARD :,0.03,0.0
def close_open_fds(keep=None):  # noqa <TAB> keep = [maybe_fileno(f) for f in (keep or []) if maybe_fileno(f) is not None] <TAB> for fd in reversed(range(get_fdmax(default=2048))): <TAB> <TAB> if fd not in keep: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> os.close(fd) <TAB> <TAB> <TAB> except OSError as exc: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise,false,if exc . errno != errno . EBADF :,if exc . errno != errno . EEXIST :,0.88,0.0
"def collect_attributes(options, node, master_list): <TAB> """"""Collect all attributes"""""" <TAB> for ii in node.instructions: <TAB> <TAB> if field_check(ii, ""attributes""): <TAB> <TAB> <TAB> s = getattr(ii, ""attributes"") <TAB> <TAB> <TAB> if isinstance(s, list): <TAB> <TAB> <TAB> <TAB> for x in s: <TAB> <TAB> <TAB> <TAB> <TAB> if x not in master_list: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> master_list.append(x) <TAB> <TAB> <TAB> elif s != None and s not in master_list: <TAB> <TAB> <TAB> <TAB> master_list.append(s) <TAB> for nxt in node.next.values(): <TAB> <TAB> collect_attributes(options, nxt, master_list)",false,elif s != None and s not in master_list :,"if field_check ( ii , ""attributes"" ) :",0.01,0.0
"def remove_test_run_directories(expiry_time: int = 60 * 60) -> int: <TAB> removed = 0 <TAB> directories = glob.glob(os.path.join(UUID_VAR_DIR, ""test-backend"", ""run_*"")) <TAB> for test_run in directories: <TAB> <TAB> if round(time.time()) - os.path.getmtime(test_run) > expiry_time: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> shutil.rmtree(test_run) <TAB> <TAB> <TAB> <TAB> removed += 1 <TAB> <TAB> <TAB> except FileNotFoundError: <TAB> <TAB> <TAB> <TAB> pass <TAB> return removed",true,if round ( time . time ( ) ) - os . path . getmtime ( test_run ) > expiry_time :,if round ( time . time ( ) ) - os . path . getmtime ( test_run ) > expiry_time :,1.0,0.0
"def read_work_titles(fields): <TAB> found = [] <TAB> if ""240"" in fields: <TAB> <TAB> for line in fields[""240""]: <TAB> <TAB> <TAB> title = join_subfield_values(line, [""a"", ""m"", ""n"", ""p"", ""r""]) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> found.append(title) <TAB> if ""130"" in fields: <TAB> <TAB> for line in fields[""130""]: <TAB> <TAB> <TAB> title = "" "".join(get_lower_subfields(line)) <TAB> <TAB> <TAB> if title not in found: <TAB> <TAB> <TAB> <TAB> found.append(title) <TAB> return {""work_titles"": found} if found else {}",true,if title not in found :,if title not in found :,0.75,0.0
"def _process_v1_msg(prot, msg): <TAB> header = None <TAB> body = msg[1] <TAB> if not isinstance(body, (binary_type, mmap, memoryview)): <TAB> <TAB> raise ValidationError(body, ""Body must be a bytestream."") <TAB> if len(msg) > 2: <TAB> <TAB> header = msg[2] <TAB> <TAB> if not isinstance(header, dict): <TAB> <TAB> <TAB> raise ValidationError(header, ""Header must be a dict."") <TAB> <TAB> for k, v in header.items(): <TAB> <TAB> <TAB> header[k] = msgpack.unpackb(v) <TAB> ctx = MessagePackMethodContext(prot, MessagePackMethodContext.SERVER) <TAB> ctx.in_string = [body] <TAB> ctx.transport.in_header = header <TAB> return ctx",true,"if not isinstance ( header , dict ) :","if not isinstance ( header , dict ) :",0.75,0.0
"def find(self, node): <TAB> typename = type(node).__name__ <TAB> method = getattr(self, ""find_{}"".format(typename), None) <TAB> if method is None: <TAB> <TAB> fields = getattr(node, ""_fields"", None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> for field in fields: <TAB> <TAB> <TAB> value = getattr(node, field) <TAB> <TAB> <TAB> for result in self.find(value): <TAB> <TAB> <TAB> <TAB> yield result <TAB> else: <TAB> <TAB> for result in method(node): <TAB> <TAB> <TAB> yield result",true,if fields is None :,if fields is None :,0.75,0.0
"def _str_param_list(self, name): <TAB> out = [] <TAB> if self[name]: <TAB> <TAB> out += self._str_header(name) <TAB> <TAB> for param in self[name]: <TAB> <TAB> <TAB> parts = [] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> parts.append(param.name) <TAB> <TAB> <TAB> if param.type: <TAB> <TAB> <TAB> <TAB> parts.append(param.type) <TAB> <TAB> <TAB> out += ["" : "".join(parts)] <TAB> <TAB> <TAB> if param.desc and """".join(param.desc).strip(): <TAB> <TAB> <TAB> <TAB> out += self._str_indent(param.desc) <TAB> <TAB> out += [""""] <TAB> return out",true,if param . name :,if param . name :,0.75,0.0
"def _get_image(self, image_list, source): <TAB> if source.startswith(""wx""): <TAB> <TAB> img = wx.ArtProvider_GetBitmap(source, wx.ART_OTHER, _SIZE) <TAB> else: <TAB> <TAB> path = os.path.join(_BASE, source) <TAB> <TAB> if source.endswith(""gif""): <TAB> <TAB> <TAB> img = wx.Image(path, wx.BITMAP_TYPE_GIF).ConvertToBitmap() <TAB> <TAB> else: <TAB> <TAB> <TAB> img = wx.Image(path, wx.BITMAP_TYPE_PNG).ConvertToBitmap() <TAB> return image_list.Add(img)",true,"if source . endswith ( ""gif"" ) :","if source . endswith ( ""gif"" ) :",0.75,0.0
"def change_opacity_function(self, new_f): <TAB> self.opacity_function = new_f <TAB> dr = self.radius / self.num_levels <TAB> sectors = [] <TAB> for submob in self.submobjects: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> sectors.append(submob) <TAB> for (r, submob) in zip(np.arange(0, self.radius, dr), sectors): <TAB> <TAB> if type(submob) != AnnularSector: <TAB> <TAB> <TAB> # it's the shadow, don't dim it <TAB> <TAB> <TAB> continue <TAB> <TAB> alpha = self.opacity_function(r) <TAB> <TAB> submob.set_fill(opacity=alpha)",false,if type ( submob ) == AnnularSector :,if type ( submob ) == Sector :,0.61,0.0
"def _sqlite_post_configure_engine(url, engine, follower_ident): <TAB> from sqlalchemy import event <TAB> @event.listens_for(engine, ""connect"") <TAB> def connect(dbapi_connection, connection_record): <TAB> <TAB> # use file DBs in all cases, memory acts kind of strangely <TAB> <TAB> # as an attached <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> dbapi_connection.execute('ATTACH DATABASE ""test_schema.db"" AS test_schema') <TAB> <TAB> else: <TAB> <TAB> <TAB> dbapi_connection.execute( <TAB> <TAB> <TAB> <TAB> 'ATTACH DATABASE ""%s_test_schema.db"" AS test_schema' % follower_ident <TAB> <TAB> <TAB> )",false,if not follower_ident :,"if follower_ident == """" :",0.05,0.0
"def apply_conf_file(fn, conf_filename): <TAB> for env in LSF_CONF_ENV: <TAB> <TAB> conf_file = get_conf_file(conf_filename, env) <TAB> <TAB> if conf_file: <TAB> <TAB> <TAB> with open(conf_file) as conf_handle: <TAB> <TAB> <TAB> <TAB> value = fn(conf_handle) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return value <TAB> return None",false,if value :,if value is not None :,0.09,0.0
"def test_call_extern_c_fn(self): <TAB> global memcmp <TAB> memcmp = cffi_support.ExternCFunction( <TAB> <TAB> ""memcmp"", <TAB> <TAB> (""int memcmp ( const uint8_t * ptr1, "" ""const uint8_t * ptr2, size_t num )""), <TAB> ) <TAB> @udf(BooleanVal(FunctionContext, StringVal, StringVal)) <TAB> def fn(context, a, b): <TAB> <TAB> if a.is_null != b.is_null: <TAB> <TAB> <TAB> return False <TAB> <TAB> if a is None: <TAB> <TAB> <TAB> return True <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> if a.ptr == b.ptr: <TAB> <TAB> <TAB> return True <TAB> <TAB> return memcmp(a.ptr, b.ptr, a.len) == 0",false,if len ( a ) != b . len :,if a . len != b . len :,0.52,0.0
"def _get_initialized_app(app): <TAB> """"""Returns a reference to an initialized App instance."""""" <TAB> if app is None: <TAB> <TAB> return firebase_admin.get_app() <TAB> if isinstance(app, firebase_admin.App): <TAB> <TAB> initialized_app = firebase_admin.get_app(app.name) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""Illegal app argument. App instance not "" <TAB> <TAB> <TAB> <TAB> ""initialized via the firebase module."" <TAB> <TAB> <TAB> ) <TAB> <TAB> return app <TAB> raise ValueError( <TAB> <TAB> ""Illegal app argument. Argument must be of type "" <TAB> <TAB> ' firebase_admin.App, but given ""{0}"".'.format(type(app)) <TAB> )",false,if app is not initialized_app :,if initialized_app is None :,0.13,0.0
def compiled_query(self): <TAB><IF-STMT> <TAB> <TAB> self.lazy_init_lock_.acquire() <TAB> <TAB> try: <TAB> <TAB> <TAB> if self.compiled_query_ is None: <TAB> <TAB> <TAB> <TAB> self.compiled_query_ = CompiledQuery() <TAB> <TAB> finally: <TAB> <TAB> <TAB> self.lazy_init_lock_.release() <TAB> return self.compiled_query_,true,if self . compiled_query_ is None :,if self . compiled_query_ is None :,0.75,0.0
"def clean_subevent(event, subevent): <TAB> if event.has_subevents: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValidationError(_(""Subevent cannot be null for event series."")) <TAB> <TAB> if event != subevent.event: <TAB> <TAB> <TAB> raise ValidationError(_(""The subevent does not belong to this event."")) <TAB> else: <TAB> <TAB> if subevent: <TAB> <TAB> <TAB> raise ValidationError(_(""The subevent does not belong to this event.""))",false,if not subevent :,if subevent :,0.1,0.0
"def get_blob_type_declaration_sql(self, column): <TAB> length = column.get(""length"") <TAB> if length: <TAB> <TAB> if length <= self.LENGTH_LIMIT_TINYBLOB: <TAB> <TAB> <TAB> return ""TINYBLOB"" <TAB> <TAB> if length <= self.LENGTH_LIMIT_BLOB: <TAB> <TAB> <TAB> return ""BLOB"" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ""MEDIUMBLOB"" <TAB> return ""LONGBLOB""",true,if length <= self . LENGTH_LIMIT_MEDIUMBLOB :,if length <= self . LENGTH_LIMIT_MEDIUMBLOB :,0.75,0.0
"def decompress(self, data): <TAB> if not data: <TAB> <TAB> return data <TAB> if not self._first_try: <TAB> <TAB> return self._obj.decompress(data) <TAB> self._data += data <TAB> try: <TAB> <TAB> decompressed = self._obj.decompress(data) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._first_try = False <TAB> <TAB> <TAB> self._data = None <TAB> <TAB> return decompressed <TAB> except zlib.error: <TAB> <TAB> self._first_try = False <TAB> <TAB> self._obj = zlib.decompressobj(-zlib.MAX_WBITS) <TAB> <TAB> try: <TAB> <TAB> <TAB> return self.decompress(self._data) <TAB> <TAB> finally: <TAB> <TAB> <TAB> self._data = None",false,if decompressed :,if decompressed is None :,0.1,0.0
"def _record_event(self, path, fsevent_handle, filename, events, error): <TAB> with self.lock: <TAB> <TAB> self.events[path].append(events) <TAB> <TAB> if events | pyuv.fs.UV_RENAME: <TAB> <TAB> <TAB> if not os.path.exists(path): <TAB> <TAB> <TAB> <TAB> self.watches.pop(path).close()",true,if not os . path . exists ( path ) :,if not os . path . exists ( path ) :,1.0,0.0
"def __init__(self, duration, batch_shape, event_shape, validate_args=None): <TAB> if duration is None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # Infer duration from event_shape. <TAB> <TAB> <TAB> duration = event_shape[0] <TAB> elif duration != event_shape[0]: <TAB> <TAB> if event_shape[0] != 1: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""duration, event_shape mismatch: {} vs {}"".format(duration, event_shape) <TAB> <TAB> <TAB> ) <TAB> <TAB> # Infer event_shape from duration. <TAB> <TAB> event_shape = torch.Size((duration,) + event_shape[1:]) <TAB> self._duration = duration <TAB> super().__init__(batch_shape, event_shape, validate_args)",false,if event_shape [ 0 ] != 1 :,if len ( event_shape ) == 1 :,0.04,0.0
"def _CheckPrerequisites(self): <TAB> """"""Exits if any of the prerequisites is not met."""""" <TAB> if not FLAGS.kubectl: <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> ""Please provide path to kubectl tool using --kubectl "" ""flag. Exiting."" <TAB> <TAB> ) <TAB> if not FLAGS.kubeconfig: <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> ""Please provide path to kubeconfig using --kubeconfig "" ""flag. Exiting."" <TAB> <TAB> ) <TAB> if self.disk_specs and self.disk_specs[0].disk_type == disk.STANDARD: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> ""Please provide a list of Ceph Monitors using "" ""--ceph_monitors flag."" <TAB> <TAB> <TAB> )",false,if not FLAGS . ceph_monitors :,if not FLAGS . Ceph_monitors :,0.52,0.0
"def invalidateDependentSlices(self, iFirstCurve): <TAB> # only user defined curve can have slice dependency relationships <TAB> if self.isSystemCurveIndex(iFirstCurve): <TAB> <TAB> return <TAB> nCurves = self.getNCurves() <TAB> for i in range(iFirstCurve, nCurves): <TAB> <TAB> c = self.getSystemCurve(i) <TAB> <TAB> if isinstance(c.getSymbol().getSymbolType(), SymbolType.PieSliceSymbolType): <TAB> <TAB> <TAB> c.invalidate() <TAB> <TAB> elif i == iFirstCurve: <TAB> <TAB> <TAB> # if first curve isn't a slice, <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> # there are no dependent slices",true,"if isinstance ( c . getSymbol ( ) . getSymbolType ( ) , SymbolType . PieSliceSymbolType ) :","if isinstance ( c . getSymbol ( ) . getSymbolType ( ) , SymbolType . PieSliceSymbolType ) :",0.75,0.0
"def find_backwards(self, offset): <TAB> try: <TAB> <TAB> for _, token_type, token_value in reversed(self.tokens[self.offset : offset]): <TAB> <TAB> <TAB> if token_type in (""comment"", ""linecomment""): <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> prefix, comment = token_value.split(None, 1) <TAB> <TAB> <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return [comment.rstrip()] <TAB> <TAB> return [] <TAB> finally: <TAB> <TAB> self.offset = offset",false,if prefix in self . comment_tags :,if prefix :,0.04,0.0
"def parse_column_definitions(self, elem): <TAB> for column_elem in elem.findall(""column""): <TAB> <TAB> name = column_elem.get(""name"", None) <TAB> <TAB> assert name is not None, ""Required 'name' attribute missing from column def"" <TAB> <TAB> index = column_elem.get(""index"", None) <TAB> <TAB> assert index is not None, ""Required 'index' attribute missing from column def"" <TAB> <TAB> index = int(index) <TAB> <TAB> self.columns[name] = index <TAB> <TAB> if index > self.largest_index: <TAB> <TAB> <TAB> self.largest_index = index <TAB> assert ""value"" in self.columns, ""Required 'value' column missing from column def"" <TAB> if ""name"" not in self.columns: <TAB> <TAB> self.columns[""name""] = self.columns[""value""]",true,if index > self . largest_index :,if index > self . largest_index :,0.75,0.0
"def __find_smallest(self): <TAB> """"""Find the smallest uncovered value in the matrix."""""" <TAB> minval = sys.maxsize <TAB> for i in range(self.n): <TAB> <TAB> for j in range(self.n): <TAB> <TAB> <TAB> if (not self.row_covered[i]) and (not self.col_covered[j]): <TAB> <TAB> <TAB> <TAB> if minval > self.C[i][j]: <TAB> <TAB> <TAB> <TAB> <TAB> minval = self.C[i][j] <TAB> return minval",true,if minval > self . C [ i ] [ j ] :,if minval > self . C [ i ] [ j ] :,0.75,0.0
"def includes_tools_for_display_in_tool_panel(self): <TAB> if self.includes_tools: <TAB> <TAB> tool_dicts = self.metadata[""tools""] <TAB> <TAB> for tool_dict in tool_dicts: <TAB> <TAB> <TAB> if tool_dict.get(""add_to_tool_panel"", True): <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",true,"if tool_dict . get ( ""add_to_tool_panel"" , True ) :","if tool_dict . get ( ""add_to_tool_panel"" , True ) :",0.75,0.0
"def commit(self, notify=False): <TAB> if self.editing: <TAB> <TAB> text = self._text <TAB> <TAB> if text: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> value = self.type(text) <TAB> <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> value = self.clamp_value(value) <TAB> <TAB> else: <TAB> <TAB> <TAB> value = self.empty <TAB> <TAB> <TAB> if value is NotImplemented: <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> self.value = value <TAB> <TAB> self.insertion_point = None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.change_text(unicode(value)) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._text = unicode(value) <TAB> <TAB> self.editing = False <TAB> else: <TAB> <TAB> self.insertion_point = None",true,if notify :,if notify :,0.53,0.0
"def GeneratePageMetatadata(self, task): <TAB> address_space = self.session.GetParameter(""default_address_space"") <TAB> for vma in task.mm.mmap.walk_list(""vm_next""): <TAB> <TAB> start = vma.vm_start <TAB> <TAB> end = vma.vm_end <TAB> <TAB> # Skip the entire region. <TAB> <TAB> if end < self.plugin_args.start: <TAB> <TAB> <TAB> continue <TAB> <TAB> # Done. <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> for vaddr in utils.xrange(start, end, 0x1000): <TAB> <TAB> <TAB> if self.plugin_args.start <= vaddr <= self.plugin_args.end: <TAB> <TAB> <TAB> <TAB> yield vaddr, self._CreateMetadata(address_space.describe_vtop(vaddr))",false,if start > self . plugin_args . end :,if start >= self . plugin_args . end :,0.58,0.0
"def _check_for_duplicate_host_entries(self, task_entries): <TAB> non_host_statuses = ( <TAB> <TAB> models.HostQueueEntry.Status.PARSING, <TAB> <TAB> models.HostQueueEntry.Status.ARCHIVING, <TAB> ) <TAB> for task_entry in task_entries: <TAB> <TAB> using_host = ( <TAB> <TAB> <TAB> task_entry.host is not None and task_entry.status not in non_host_statuses <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._assert_host_has_no_agent(task_entry)",true,if using_host :,if using_host :,0.53,0.0
"def get_biggest_wall_time(jsons): <TAB> lowest_wall = None <TAB> for j in jsons: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> lowest_wall = j[""wall_time""] <TAB> <TAB> if lowest_wall < j[""wall_time""]: <TAB> <TAB> <TAB> lowest_wall = j[""wall_time""] <TAB> return lowest_wall",true,if lowest_wall is None :,if lowest_wall is None :,0.75,0.0
"def log_change_report(self, old_value, new_value, include_details=False): <TAB> from octoprint.util import map_boolean <TAB> with self._check_mutex: <TAB> <TAB> self._logger.info( <TAB> <TAB> <TAB> ""Connectivity changed from {} to {}"".format( <TAB> <TAB> <TAB> <TAB> map_boolean(old_value, ""online"", ""offline""), <TAB> <TAB> <TAB> <TAB> map_boolean(new_value, ""online"", ""offline""), <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.log_details()",true,if include_details :,if include_details :,0.53,0.0
"def _include_block(self, value, context=None): <TAB> if hasattr(value, ""render_as_block""): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> new_context = context.get_all() <TAB> <TAB> else: <TAB> <TAB> <TAB> new_context = {} <TAB> <TAB> return jinja2.Markup(value.render_as_block(context=new_context)) <TAB> return jinja2.Markup(value)",true,if context :,if context :,0.53,0.0
"def __lt__(self, other): <TAB> # 0: clock 1: timestamp 3: process id <TAB> try: <TAB> <TAB> A, B = self[0], other[0] <TAB> <TAB> # uses logical clock value first <TAB> <TAB> if A and B:  # use logical clock if available <TAB> <TAB> <TAB><IF-STMT>  # equal clocks use lower process id <TAB> <TAB> <TAB> <TAB> return self[2] < other[2] <TAB> <TAB> <TAB> return A < B <TAB> <TAB> return self[1] < other[1]  # ... or use timestamp <TAB> except IndexError: <TAB> <TAB> return NotImplemented",true,if A == B :,if A == B :,0.75,0.0
"def _get_port(): <TAB> while True: <TAB> <TAB> port = 20000 + random.randint(1, 9999) <TAB> <TAB> for i in range(5): <TAB> <TAB> <TAB> sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) <TAB> <TAB> <TAB> result = sock.connect_ex((""127.0.0.1"", port)) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> else: <TAB> <TAB> <TAB> return port",true,if result == 0 :,if result == 0 :,0.75,0.0
"def fetch_all(self, api_client, fetchstatuslogger, q, targets): <TAB> self.fetchstatuslogger = fetchstatuslogger <TAB> if targets != None: <TAB> <TAB> # Ensure targets is a tuple <TAB> <TAB> if type(targets) != list and type(targets) != tuple: <TAB> <TAB> <TAB> targets = tuple( <TAB> <TAB> <TAB> <TAB> targets, <TAB> <TAB> <TAB> ) <TAB> <TAB> elif type(targets) != tuple: <TAB> <TAB> <TAB> targets = tuple(targets) <TAB> for target in targets: <TAB> <TAB> self._fetch_targets(api_client, q, target)",true,elif type ( targets ) != tuple :,elif type ( targets ) != tuple :,0.75,0.0
"def migrate_node_facts(facts): <TAB> """"""Migrate facts from various roles into node"""""" <TAB> params = { <TAB> <TAB> ""common"": (""dns_ip""), <TAB> } <TAB> if ""node"" not in facts: <TAB> <TAB> facts[""node""] = {} <TAB> # pylint: disable=consider-iterating-dictionary <TAB> for role in params.keys(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for param in params[role]: <TAB> <TAB> <TAB> <TAB> if param in facts[role]: <TAB> <TAB> <TAB> <TAB> <TAB> facts[""node""][param] = facts[role].pop(param) <TAB> return facts",true,if role in facts :,if role in facts :,0.75,0.0
"def build_dimension_param(self, dimension, params): <TAB> prefix = ""Dimensions.member"" <TAB> i = 0 <TAB> for dim_name in dimension: <TAB> <TAB> dim_value = dimension[dim_name] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if isinstance(dim_value, six.string_types): <TAB> <TAB> <TAB> <TAB> dim_value = [dim_value] <TAB> <TAB> <TAB> for value in dim_value: <TAB> <TAB> <TAB> <TAB> params[""%s.%d.Name"" % (prefix, i + 1)] = dim_name <TAB> <TAB> <TAB> <TAB> params[""%s.%d.Value"" % (prefix, i + 1)] = value <TAB> <TAB> <TAB> <TAB> i += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> params[""%s.%d.Name"" % (prefix, i + 1)] = dim_name <TAB> <TAB> <TAB> i += 1",true,if dim_value :,if dim_value :,0.53,0.0
"def add_if_unique(self, issuer, use, keys): <TAB> if use in self.issuer_keys[issuer] and self.issuer_keys[issuer][use]: <TAB> <TAB> for typ, key in keys: <TAB> <TAB> <TAB> flag = 1 <TAB> <TAB> <TAB> for _typ, _key in self.issuer_keys[issuer][use]: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> flag = 0 <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if flag: <TAB> <TAB> <TAB> <TAB> self.issuer_keys[issuer][use].append((typ, key)) <TAB> else: <TAB> <TAB> self.issuer_keys[issuer][use] = keys",false,if _typ == typ and key is _key :,if typ == _key :,0.03,0.0
"def run(self): <TAB> while True: <TAB> <TAB> message = self.in_queue.get() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.reset() <TAB> <TAB> elif message == EXIT: <TAB> <TAB> <TAB> return <TAB> <TAB> else: <TAB> <TAB> <TAB> index, transaction = message <TAB> <TAB> <TAB> self.results_queue.put((index, self.validate(transaction)))",true,if message == RESET :,if message == RESET :,0.75,0.0
"def __run(self): <TAB> threads = self.parameters()[""threads""].getTypedValue() <TAB> with IECore.tbb_global_control( <TAB> <TAB> IECore.tbb_global_control.parameter.max_allowed_parallelism, <TAB> <TAB> IECore.hardwareConcurrency() if threads == 0 else threads, <TAB> ): <TAB> <TAB> self._executeStartupFiles(self.root().getName()) <TAB> <TAB> # Append DEBUG message with process information to all messages <TAB> <TAB> defaultMessageHandler = IECore.MessageHandler.getDefaultHandler() <TAB> <TAB> if not isinstance(defaultMessageHandler, Gaffer.ProcessMessageHandler): <TAB> <TAB> <TAB> IECore.MessageHandler.setDefaultHandler( <TAB> <TAB> <TAB> <TAB> Gaffer.ProcessMessageHandler(defaultMessageHandler) <TAB> <TAB> <TAB> ) <TAB> <TAB> return self._run(self.parameters().getValidatedValue())",true,"if not isinstance ( defaultMessageHandler , Gaffer . ProcessMessageHandler ) :","if not isinstance ( defaultMessageHandler , Gaffer . ProcessMessageHandler ) :",0.75,0.0
"def adjust_uri(self, uri, relativeto): <TAB> """"""Adjust the given ``uri`` based on the given relative URI."""""" <TAB> key = (uri, relativeto) <TAB> if key in self._uri_cache: <TAB> <TAB> return self._uri_cache[key] <TAB> if uri[0] != ""/"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> v = self._uri_cache[key] = posixpath.join( <TAB> <TAB> <TAB> <TAB> posixpath.dirname(relativeto), uri <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> v = self._uri_cache[key] = ""/"" + uri <TAB> else: <TAB> <TAB> v = self._uri_cache[key] = uri <TAB> return v",false,if relativeto is not None :,if relativeto :,0.05,0.0
"def decoder(s): <TAB> r = [] <TAB> decode = [] <TAB> for c in s: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> decode.append(""&"") <TAB> <TAB> elif c == ""-"" and decode: <TAB> <TAB> <TAB> if len(decode) == 1: <TAB> <TAB> <TAB> <TAB> r.append(""&"") <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> r.append(modified_unbase64("""".join(decode[1:]))) <TAB> <TAB> <TAB> decode = [] <TAB> <TAB> elif decode: <TAB> <TAB> <TAB> decode.append(c) <TAB> <TAB> else: <TAB> <TAB> <TAB> r.append(c) <TAB> if decode: <TAB> <TAB> r.append(modified_unbase64("""".join(decode[1:]))) <TAB> bin_str = """".join(r) <TAB> return (bin_str, len(s))",false,"if c == ""&"" and not decode :","if c == ""+"" and decode :",0.18,0.0
"def _process_file(self, content): <TAB> args = [] <TAB> for line in content.splitlines(): <TAB> <TAB> line = line.strip() <TAB> <TAB> if line.startswith(""-""): <TAB> <TAB> <TAB> args.extend(self._split_option(line)) <TAB> <TAB> elif line and not line.startswith(""#""): <TAB> <TAB> <TAB> args.append(line) <TAB> return args",true,"elif line and not line . startswith ( ""#"" ) :","elif line and not line . startswith ( ""#"" ) :",1.0,0.0
"def _method_events_callback(self, values): <TAB> try: <TAB> <TAB> previous_echoed = ( <TAB> <TAB> <TAB> values[""child_result_list""][-1].decode().split(""\n"")[-2].strip() <TAB> <TAB> ) <TAB> <TAB> if previous_echoed.endswith(""foo1""): <TAB> <TAB> <TAB> return ""echo foo2\n"" <TAB> <TAB> elif previous_echoed.endswith(""foo2""): <TAB> <TAB> <TAB> return ""echo foo3\n"" <TAB> <TAB> elif previous_echoed.endswith(""foo3""): <TAB> <TAB> <TAB> return ""exit\n"" <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception(""Unexpected output {0!r}"".format(previous_echoed)) <TAB> except IndexError: <TAB> <TAB> return ""echo foo1\n""",true,"elif previous_echoed . endswith ( ""foo3"" ) :","elif previous_echoed . endswith ( ""foo3"" ) :",0.75,0.0
"def __delete_hook(self, rpc): <TAB> try: <TAB> <TAB> rpc.check_success() <TAB> except apiproxy_errors.Error: <TAB> <TAB> return None <TAB> result = [] <TAB> for status in rpc.response.delete_status_list(): <TAB> <TAB> if status == MemcacheDeleteResponse.DELETED: <TAB> <TAB> <TAB> result.append(DELETE_SUCCESSFUL) <TAB> <TAB> elif status == MemcacheDeleteResponse.NOT_FOUND: <TAB> <TAB> <TAB> result.append(DELETE_ITEM_MISSING) <TAB> <TAB> else: <TAB> <TAB> <TAB> result.append(DELETE_NETWORK_FAILURE) <TAB> return result",false,if status == MemcacheDeleteResponse . DELETED :,elif status == MemcacheDeleteResponse . NOT_FOUND :,0.29,0.0
"def __createRandom(plug): <TAB> node = plug.node() <TAB> parentNode = node.ancestor(Gaffer.Node) <TAB> with Gaffer.UndoScope(node.scriptNode()): <TAB> <TAB> randomNode = Gaffer.Random() <TAB> <TAB> parentNode.addChild(randomNode) <TAB> <TAB> if isinstance(plug, (Gaffer.FloatPlug, Gaffer.IntPlug)): <TAB> <TAB> <TAB> plug.setInput(randomNode[""outFloat""]) <TAB> <TAB> elif isinstance(plug, Gaffer.Color3fPlug): <TAB> <TAB> <TAB> plug.setInput(randomNode[""outColor""]) <TAB> GafferUI.NodeEditor.acquire(randomNode)",false,"if isinstance ( plug , ( Gaffer . FloatPlug , Gaffer . IntPlug ) ) :","elif isinstance ( plug , Gaffer . Color3fPlug ) :",0.11,0.0
"def escapeentities(self, line): <TAB> ""Escape all Unicode characters to HTML entities."" <TAB> result = """" <TAB> pos = TextPosition(line) <TAB> while not pos.finished(): <TAB> <TAB> if ord(pos.current()) > 128: <TAB> <TAB> <TAB> codepoint = hex(ord(pos.current())) <TAB> <TAB> <TAB> if codepoint == ""0xd835"": <TAB> <TAB> <TAB> <TAB> codepoint = hex(ord(pos.next()) + 0xF800) <TAB> <TAB> <TAB> result += ""&#"" + codepoint[1:] + "";"" <TAB> <TAB> else: <TAB> <TAB> <TAB> result += pos.current() <TAB> <TAB> pos.skipcurrent() <TAB> return result",true,"if codepoint == ""0xd835"" :","if codepoint == ""0xd835"" :",0.75,0.0
def get_and_set_all_aliases(self): <TAB> all_aliases = [] <TAB> for page in self.pages: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> all_aliases.extend(page.relations.aliases_norm) <TAB> <TAB> if page.relations.aliases is not None: <TAB> <TAB> <TAB> all_aliases.extend(page.relations.aliases) <TAB> return set(all_aliases),true,if page . relations . aliases_norm is not None :,if page . relations . aliases_norm is not None :,0.75,0.0
"def _list_cases(suite): <TAB> for test in suite: <TAB> <TAB> if isinstance(test, unittest.TestSuite): <TAB> <TAB> <TAB> _list_cases(test) <TAB> <TAB> elif isinstance(test, unittest.TestCase): <TAB> <TAB> <TAB> if support.match_test(test): <TAB> <TAB> <TAB> <TAB> print(test.id())",false,"if isinstance ( test , unittest . TestSuite ) :",if support . match_test ( test ) :,0.04,0.0
"def get_next_requests(self, max_n_requests, **kwargs): <TAB> next_pages = [] <TAB> partitions = set(kwargs.pop(""partitions"", [])) <TAB> for partition_id in range(0, self.queue_partitions): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> results = self.queue.get_next_requests(max_n_requests, partition_id) <TAB> <TAB> next_pages.extend(results) <TAB> <TAB> self.logger.debug( <TAB> <TAB> <TAB> ""Got %d requests for partition id %d"", len(results), partition_id <TAB> <TAB> ) <TAB> return next_pages",false,if partition_id not in partitions :,if partition_id in partitions :,0.23,0.0
"def __iter__(self): <TAB> if (self.query is not None) and sqlite.is_read_only_query(self.query): <TAB> <TAB> cur = self.connection.cursor() <TAB> <TAB> results = cur.execute(self.query) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield [col[0] for col in cur.description] <TAB> <TAB> for i, row in enumerate(results): <TAB> <TAB> <TAB> if i >= self.limit: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> yield [val for val in row] <TAB> else: <TAB> <TAB> yield",false,if self . headers :,if results :,0.04,0.0
"def rollback(self): <TAB> for operation, values in self.current_transaction_state[::-1]: <TAB> <TAB> if operation == ""insert"": <TAB> <TAB> <TAB> values.remove() <TAB> <TAB> elif operation == ""update"": <TAB> <TAB> <TAB> old_value, new_value = values <TAB> <TAB> <TAB> if new_value.full_filename != old_value.full_filename: <TAB> <TAB> <TAB> <TAB> os.unlink(new_value.full_filename) <TAB> <TAB> <TAB> old_value.write() <TAB> self._post_xact_cleanup()",false,"elif operation == ""update"" :","if operation == ""insert"" :",0.06,0.0
"def index(self, value): <TAB> if self._growing: <TAB> <TAB> if self._start <= value < self._stop: <TAB> <TAB> <TAB> q, r = divmod(value - self._start, self._step) <TAB> <TAB> <TAB> if r == self._zero: <TAB> <TAB> <TAB> <TAB> return int(q) <TAB> else: <TAB> <TAB> if self._start >= value > self._stop: <TAB> <TAB> <TAB> q, r = divmod(self._start - value, -self._step) <TAB> <TAB> <TAB> if r == self._zero: <TAB> <TAB> <TAB> <TAB> return int(q) <TAB> raise ValueError(""{} is not in numeric range"".format(value))",true,if r == self . _zero :,if r == self . _zero :,0.75,0.0
"def validate_name_and_description(body, check_length=True): <TAB> for attribute in [""name"", ""description"", ""display_name"", ""display_description""]: <TAB> <TAB> value = body.get(attribute) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if isinstance(value, six.string_types): <TAB> <TAB> <TAB> <TAB> body[attribute] = value.strip() <TAB> <TAB> <TAB> if check_length: <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> utils.check_string_length( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> body[attribute], attribute, min_length=0, max_length=255 <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> except exception.InvalidInput as error: <TAB> <TAB> <TAB> <TAB> <TAB> raise webob.exc.HTTPBadRequest(explanation=error.msg)",false,if value is not None :,if value :,0.05,0.0
"def printWiki(): <TAB> firstHeading = False <TAB> for m in protocol: <TAB> <TAB> if m[0] == """": <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> output(""|}"") <TAB> <TAB> <TAB> __printWikiHeader(m[1], m[2]) <TAB> <TAB> <TAB> firstHeading = True <TAB> <TAB> else: <TAB> <TAB> <TAB> output(""|-"") <TAB> <TAB> <TAB> output( <TAB> <TAB> <TAB> <TAB> '| <span style=""white-space:nowrap;""><tt>' <TAB> <TAB> <TAB> <TAB> + m[0] <TAB> <TAB> <TAB> <TAB> + ""</tt></span> || || "" <TAB> <TAB> <TAB> <TAB> + m[1] <TAB> <TAB> <TAB> ) <TAB> output(""|}"")",true,if firstHeading :,if firstHeading :,0.53,0.0
"def _get_platforms(data): <TAB> platform_list = [] <TAB> for item in data: <TAB> <TAB> if item.startswith(""PlatformEdit.html?""): <TAB> <TAB> <TAB> parameter_list = item.split(""PlatformEdit.html?"", 1)[1].split(""&"") <TAB> <TAB> <TAB> for parameter in parameter_list: <TAB> <TAB> <TAB> <TAB> if parameter.startswith(""platformName""): <TAB> <TAB> <TAB> <TAB> <TAB> platform_list.append(parameter.split(""="")[1]) <TAB> return platform_list",true,"if parameter . startswith ( ""platformName"" ) :","if parameter . startswith ( ""platformName"" ) :",0.75,0.0
"def find_scintilla_constants(f): <TAB> lexers = [] <TAB> states = [] <TAB> for name in f.order: <TAB> <TAB> v = f.features[name] <TAB> <TAB> if v[""Category""] != ""Deprecated"": <TAB> <TAB> <TAB> if v[""FeatureType""] == ""val"": <TAB> <TAB> <TAB> <TAB> if name.startswith(""SCE_""): <TAB> <TAB> <TAB> <TAB> <TAB> states.append((name, v[""Value""])) <TAB> <TAB> <TAB> <TAB> elif name.startswith(""SCLEX_""): <TAB> <TAB> <TAB> <TAB> <TAB> lexers.append((name, v[""Value""])) <TAB> return (lexers, states)",false,"if name . startswith ( ""SCE_"" ) :","if v [ ""FeatureType"" ] == ""val"" :",0.02,0.0
"def get_operation_ast(document_ast, operation_name=None): <TAB> operation = None <TAB> for definition in document_ast.definitions: <TAB> <TAB> if isinstance(definition, ast.OperationDefinition): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB> <TAB> <TAB> <TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB> <TAB> <TAB> <TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB> <TAB> <TAB> <TAB> if operation: <TAB> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> <TAB> operation = definition <TAB> <TAB> <TAB> elif definition.name and definition.name.value == operation_name: <TAB> <TAB> <TAB> <TAB> return definition <TAB> return operation",false,if not operation_name :,if operation_name is None :,0.05,0.0
"def _insertNewItemAtParent(self, targetIndex): <TAB> if not self.isContainer(targetIndex): <TAB> <TAB> return <TAB> elif not self.isContainerOpen(targetIndex): <TAB> <TAB> uri = self._rows[targetIndex].uri <TAB> <TAB> modelNode = self.getNodeForURI(uri) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> modelNode.markForRefreshing() <TAB> <TAB> return <TAB> self.refreshView(targetIndex)",true,if modelNode :,if modelNode :,0.53,0.0
"def _get_trace(self, model, guide, args, kwargs): <TAB> model_trace, guide_trace = super()._get_trace(model, guide, args, kwargs) <TAB> # Mark all sample sites with require_backward to gather enumerated <TAB> # sites and adjust cond_indep_stack of all sample sites. <TAB> for node in model_trace.nodes.values(): <TAB> <TAB> if node[""type""] == ""sample"" and not node[""is_observed""]: <TAB> <TAB> <TAB> log_prob = node[""packed""][""unscaled_log_prob""] <TAB> <TAB> <TAB> require_backward(log_prob) <TAB> self._saved_state = model, model_trace, guide_trace, args, kwargs <TAB> return model_trace, guide_trace",true,"if node [ ""type"" ] == ""sample"" and not node [ ""is_observed"" ] :","if node [ ""type"" ] == ""sample"" and not node [ ""is_observed"" ] :",1.0,0.0
"def _url_encode_impl(obj, charset, encode_keys, sort, key): <TAB> from .datastructures import iter_multi_items <TAB> iterable = iter_multi_items(obj) <TAB> if sort: <TAB> <TAB> iterable = sorted(iterable, key=key) <TAB> for key, value in iterable: <TAB> <TAB> if value is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> if not isinstance(key, bytes): <TAB> <TAB> <TAB> key = text_type(key).encode(charset) <TAB> <TAB> if not isinstance(value, bytes): <TAB> <TAB> <TAB> value = text_type(value).encode(charset) <TAB> <TAB> yield _fast_url_quote_plus(key) + ""="" + _fast_url_quote_plus(value)",false,"if not isinstance ( value , bytes ) :","if not isinstance ( key , bytes ) :",0.55,0.0
"def handle_parse_result(self, ctx, opts, args): <TAB> with augment_usage_errors(ctx, param=self): <TAB> <TAB> value = self.consume_value(ctx, opts) <TAB> <TAB> try: <TAB> <TAB> <TAB> value = self.full_process_value(ctx, value) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> value = None <TAB> <TAB> if self.callback is not None: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> value = invoke_param_callback(self.callback, ctx, self, value) <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> if not ctx.resilient_parsing: <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> if self.expose_value: <TAB> <TAB> ctx.params[self.name] = value <TAB> return value, args",true,if not ctx . resilient_parsing :,if not ctx . resilient_parsing :,0.75,0.0
"def word_pattern(pattern, str): <TAB> dict = {} <TAB> set_value = set() <TAB> list_str = str.split() <TAB> if len(list_str) != len(pattern): <TAB> <TAB> return False <TAB> for i in range(len(pattern)): <TAB> <TAB> if pattern[i] not in dict: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> dict[pattern[i]] = list_str[i] <TAB> <TAB> <TAB> set_value.add(list_str[i]) <TAB> <TAB> else: <TAB> <TAB> <TAB> if dict[pattern[i]] != list_str[i]: <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",false,if list_str [ i ] in set_value :,if set_value :,0.03,0.0
"def create(self, path, wipe=False): <TAB> # type: (Text, bool) -> bool <TAB> _path = self.validatepath(path) <TAB> with ftp_errors(self, path): <TAB> <TAB> if wipe or not self.isfile(path): <TAB> <TAB> <TAB> empty_file = io.BytesIO() <TAB> <TAB> <TAB> self.ftp.storbinary( <TAB> <TAB> <TAB> <TAB> str(""STOR "") + _encode(_path, self.ftp.encoding), empty_file <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return True <TAB> return False",true,if wipe or not self . isfile ( path ) :,if wipe or not self . isfile ( path ) :,0.75,0.0
"def build_output_for_item(self, item): <TAB> output = [] <TAB> for field in self.fields: <TAB> <TAB> values = self._get_item(item, field) <TAB> <TAB> if not isinstance(values, list): <TAB> <TAB> <TAB> values = [values] <TAB> <TAB> for value in values: <TAB> <TAB> <TAB> if value: <TAB> <TAB> <TAB> <TAB> output.append(self.build_output_for_single_value(value)) <TAB> return """".join(output)",true,"if not isinstance ( values , list ) :","if not isinstance ( values , list ) :",0.75,0.0
"def get_resource_public_actions(resource_class): <TAB> resource_class_members = inspect.getmembers(resource_class) <TAB> resource_methods = {} <TAB> for name, member in resource_class_members: <TAB> <TAB> if not name.startswith(""_""): <TAB> <TAB> <TAB> if not name[0].isupper(): <TAB> <TAB> <TAB> <TAB> if not name.startswith(""wait_until""): <TAB> <TAB> <TAB> <TAB> <TAB> if is_resource_action(member): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> resource_methods[name] = member <TAB> return resource_methods",false,"if not name . startswith ( ""wait_until"" ) :",if is_resource_action ( member ) :,0.03,0.0
"def get_command(cls): <TAB> ifconfig_cmd = ""ifconfig"" <TAB> for path in [""/sbin"", ""/usr/sbin"", ""/bin"", ""/usr/bin""]: <TAB> <TAB> if os.path.exists(os.path.join(path, ifconfig_cmd)): <TAB> <TAB> <TAB> ifconfig_cmd = os.path.join(path, ifconfig_cmd) <TAB> <TAB> <TAB> break <TAB> ifconfig_cmd = ifconfig_cmd + "" -a"" <TAB> return ifconfig_cmd",true,"if os . path . exists ( os . path . join ( path , ifconfig_cmd ) ) :","if os . path . exists ( os . path . join ( path , ifconfig_cmd ) ) :",1.0,0.0
"def main(): <TAB> base_dir = os.path.join(os.path.split(__file__)[0], "".."", "".."") <TAB> for path in PATHS: <TAB> <TAB> path = os.path.join(base_dir, path) <TAB> <TAB> for root, _, files in os.walk(path): <TAB> <TAB> <TAB> for file in files: <TAB> <TAB> <TAB> <TAB> extension = os.path.splitext(file)[1] <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> path = os.path.join(root, file) <TAB> <TAB> <TAB> <TAB> <TAB> validate_header(path)",false,if extension in EXTENSIONS :,if extension in HEADERS :,0.39,0.0
"def auth_login(request): <TAB> form = RegistrationForm(request.POST or None) <TAB> if form.is_valid(): <TAB> <TAB> authed_user = authenticate( <TAB> <TAB> <TAB> username=form.cleaned_data[""username""], <TAB> <TAB> <TAB> password=form.cleaned_data[""password""], <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> login(request, authed_user) <TAB> <TAB> <TAB> return HttpResponse(""Success"") <TAB> raise Http404",true,if authed_user :,if authed_user :,0.53,0.0
"def set(self, _key, _new_login=True): <TAB> with self.lock: <TAB> <TAB> user = self.users.get(current_user.id, None) <TAB> <TAB> if user is None: <TAB> <TAB> <TAB> self.users[current_user.id] = dict(session_count=1, key=_key) <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> user[""session_count""] += 1 <TAB> <TAB> <TAB> user[""key""] = _key",true,if _new_login :,if _new_login :,0.53,0.0
"def fetch(self, fingerprints): <TAB> to_fetch = [f for f in fingerprints if f not in self._cache] <TAB> self._logger.debug(""cache size %s"" % len(self._cache)) <TAB> self._logger.debug(""to fetch %d from %d"" % (len(to_fetch), len(fingerprints))) <TAB> [self._redis_pipeline.hgetall(key) for key in to_fetch] <TAB> responses = self._redis_pipeline.execute() <TAB> for index, key in enumerate(to_fetch): <TAB> <TAB> response = responses[index] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._cache[key] = response[FIELD_STATE] <TAB> <TAB> else: <TAB> <TAB> <TAB> self._cache[key] = self.NOT_CRAWLED",false,if len ( response ) > 0 and FIELD_STATE in response :,if FIELD_STATE in response :,0.16,0.0
"def _append_to_io_queue(self, data, stream_name): <TAB> # Make sure ANSI CSI codes and object links are stored as separate events <TAB> # TODO: try to complete previously submitted incomplete code <TAB> parts = re.split(OUTPUT_SPLIT_REGEX, data) <TAB> for part in parts: <TAB> <TAB> if part:  # split may produce empty string in the beginning or start <TAB> <TAB> <TAB> # split the data so that very long lines separated <TAB> <TAB> <TAB> for block in re.split( <TAB> <TAB> <TAB> <TAB> ""(.{%d,})"" % (self._get_squeeze_threshold() + 1), part <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self._queued_io_events.append((block, stream_name))",true,if block :,if block :,0.53,0.0
"def find_file_at_path_with_indexes(self, path, url): <TAB> if url.endswith(""/""): <TAB> <TAB> path = os.path.join(path, self.index_file) <TAB> <TAB> return self.get_static_file(path, url) <TAB> elif url.endswith(""/"" + self.index_file): <TAB> <TAB> if os.path.isfile(path): <TAB> <TAB> <TAB> return self.redirect(url, url[: -len(self.index_file)]) <TAB> else: <TAB> <TAB> try: <TAB> <TAB> <TAB> return self.get_static_file(path, url) <TAB> <TAB> except IsDirectoryError: <TAB> <TAB> <TAB> if os.path.isfile(os.path.join(path, self.index_file)): <TAB> <TAB> <TAB> <TAB> return self.redirect(url, url + ""/"") <TAB> raise MissingFileError(path)",false,if os . path . isfile ( path ) :,"if os . path . isfile ( os . path . join ( path , self . index_file ) ) :",0.57,0.0
"def module_list(target, fast): <TAB> """"""Find the list of modules to be compiled"""""" <TAB> modules = [] <TAB> native = native_modules(target) <TAB> basedir = os.path.join(ouroboros_repo_folder(), ""ouroboros"") <TAB> for name in os.listdir(basedir): <TAB> <TAB> module_name, ext = os.path.splitext(name) <TAB> <TAB> if ext == "".py"" or ext == """" and os.path.isdir(os.path.join(basedir, name)): <TAB> <TAB> <TAB> if module_name not in IGNORE_MODULES and module_name not in native: <TAB> <TAB> <TAB> <TAB> if not (fast and module_name in KNOWN_PROBLEM_MODULES): <TAB> <TAB> <TAB> <TAB> <TAB> modules.append(module_name) <TAB> return set(modules)",false,if not ( fast and module_name in KNOWN_PROBLEM_MODULES ) :,"if ext == "".py"" or ext == """" and os . path . isdir ( os . path . join ( basedir , name ) ) :",0.02,0.0
"def housenumber(self): <TAB> if self.address: <TAB> <TAB> expression = r""\d+"" <TAB> <TAB> pattern = re.compile(expression) <TAB> <TAB> match = pattern.search(self.address) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return int(match.group(0))",true,if match :,if match :,0.53,0.0
"def get_pip_version(import_path=BASE_IMPORT_PATH): <TAB> try: <TAB> <TAB> pip = importlib.import_module(import_path) <TAB> except ImportError: <TAB> <TAB> if import_path != ""pip"": <TAB> <TAB> <TAB> return get_pip_version(import_path=""pip"") <TAB> <TAB> else: <TAB> <TAB> <TAB> import subprocess <TAB> <TAB> <TAB> version = subprocess.check_output([""pip"", ""--version""]) <TAB> <TAB> <TAB> if version: <TAB> <TAB> <TAB> <TAB> version = version.decode(""utf-8"").split()[1] <TAB> <TAB> <TAB> <TAB> return version <TAB> <TAB> <TAB> return ""0.0.0"" <TAB> version = getattr(pip, ""__version__"", None) <TAB> return version",true,"if import_path != ""pip"" :","if import_path != ""pip"" :",0.75,0.0
"def __animate_progress(self): <TAB> """"""Change the status message, mostly used to animate progress."""""" <TAB> while True: <TAB> <TAB> sleep_time = ThreadPool.PROGRESS_IDLE_DELAY <TAB> <TAB> with self.__progress_lock: <TAB> <TAB> <TAB> if not self.__progress_status: <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool.PROGRESS_IDLE_DELAY <TAB> <TAB> <TAB> elif self.__show_animation: <TAB> <TAB> <TAB> <TAB> self.__progress_status.update_progress(self.__current_operation_name) <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool.PROGRESS_UPDATE_DELAY <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.__progress_status.show_as_ready() <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool.PROGRESS_IDLE_DELAY <TAB> <TAB> # Allow some time for progress status to be updated. <TAB> <TAB> time.sleep(sleep_time)",true,elif self . __show_animation :,elif self . __show_animation :,0.75,0.0
"def range_key_names(self): <TAB> keys = [self.range_key_attr] <TAB> for index in self.global_indexes: <TAB> <TAB> range_key = None <TAB> <TAB> for key in index.schema: <TAB> <TAB> <TAB> if key[""KeyType""] == ""RANGE"": <TAB> <TAB> <TAB> <TAB> range_key = keys.append(key[""AttributeName""]) <TAB> <TAB> keys.append(range_key) <TAB> return keys",true,"if key [ ""KeyType"" ] == ""RANGE"" :","if key [ ""KeyType"" ] == ""RANGE"" :",0.75,0.0
"def run(self): <TAB> dist = self.distribution <TAB> commands = dist.command_options.keys() <TAB> settings = {} <TAB> for cmd in commands: <TAB> <TAB> if cmd == ""saveopts"": <TAB> <TAB> <TAB> continue  # don't save our own options! <TAB> <TAB> for opt, (src, val) in dist.get_option_dict(cmd).items(): <TAB> <TAB> <TAB> if src == ""command line"": <TAB> <TAB> <TAB> <TAB> settings.setdefault(cmd, {})[opt] = val <TAB> edit_config(self.filename, settings, self.dry_run)",true,"if src == ""command line"" :","if src == ""command line"" :",0.75,0.0
"def parse_move(self, node): <TAB> old, new = """", """" <TAB> for child in node: <TAB> <TAB> tag, text = child.tag, child.text <TAB> <TAB> text = text.strip() if text else None <TAB> <TAB> if tag == ""Old"" and text: <TAB> <TAB> <TAB> old = text <TAB> <TAB> elif tag == ""New"" and text: <TAB> <TAB> <TAB> new = text <TAB> return Move(old, new)",true,"elif tag == ""New"" and text :","elif tag == ""New"" and text :",1.0,0.0
"def __codeanalysis_settings_changed(self, current_finfo): <TAB> if self.data: <TAB> <TAB> run_pyflakes, run_pep8 = self.pyflakes_enabled, self.pep8_enabled <TAB> <TAB> for finfo in self.data: <TAB> <TAB> <TAB> self.__update_editor_margins(finfo.editor) <TAB> <TAB> <TAB> finfo.cleanup_analysis_results() <TAB> <TAB> <TAB> if (run_pyflakes or run_pep8) and current_finfo is not None: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> finfo.run_code_analysis(run_pyflakes, run_pep8)",false,if current_finfo is not finfo :,if run_pyflakes and run_pep8 :,0.13,0.0
"def tchg(var, width): <TAB> ""Convert time string to given length"" <TAB> ret = ""%2dh%02d"" % (var / 60, var % 60) <TAB><IF-STMT> <TAB> <TAB> ret = ""%2dh"" % (var / 60) <TAB> <TAB> if len(ret) > width: <TAB> <TAB> <TAB> ret = ""%2dd"" % (var / 60 / 24) <TAB> <TAB> <TAB> if len(ret) > width: <TAB> <TAB> <TAB> <TAB> ret = ""%2dw"" % (var / 60 / 24 / 7) <TAB> return ret",true,if len ( ret ) > width :,if len ( ret ) > width :,0.75,0.0
"def spider_log_activity(self, messages): <TAB> for i in range(0, messages): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.sp_sl_p.send( <TAB> <TAB> <TAB> <TAB> sha1(str(randint(1, 1000))), <TAB> <TAB> <TAB> <TAB> b""http://helloworld.com/way/to/the/sun/"" + b""0"", <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.sp_sl_p.send( <TAB> <TAB> <TAB> <TAB> sha1(str(randint(1, 1000))), b""http://way.to.the.sun"" + b""0"" <TAB> <TAB> <TAB> ) <TAB> self.sp_sl_p.flush()",false,if i % 2 == 0 :,if i == messages - 1 :,0.04,0.0
"def decode_serial(self, offset): <TAB> serialnum = ( <TAB> <TAB> (self.cache[offset + 3] << 24) <TAB> <TAB> + (self.cache[offset + 2] << 16) <TAB> <TAB> + (self.cache[offset + 1] << 8) <TAB> <TAB> + self.cache[offset] <TAB> ) <TAB> serialstr = """" <TAB> is_alnum = True <TAB> for i in range(4): <TAB> <TAB> if not chr(self.cache[offset + 3 - i]).isalnum(): <TAB> <TAB> <TAB> is_alnum = False <TAB> <TAB> <TAB> break <TAB> <TAB> serialstr += chr(self.cache[offset + 3 - i]) <TAB> serial = serialstr if is_alnum else str(serialnum) <TAB> self.ann_field(offset, offset + 3, ""Serial "" + serial)",true,if not chr ( self . cache [ offset + 3 - i ] ) . isalnum ( ) :,if not chr ( self . cache [ offset + 3 - i ] ) . isalnum ( ) :,0.75,0.0
def gettext(rv): <TAB> for child in rv.childNodes: <TAB> <TAB> if child.nodeType == child.TEXT_NODE: <TAB> <TAB> <TAB> yield child.nodeValue <TAB> <TAB> if child.nodeType == child.ELEMENT_NODE: <TAB> <TAB> <TAB> for item in gettext(child): <TAB> <TAB> <TAB> <TAB> yield item,false,if child . nodeType == child . ELEMENT_NODE :,if child . nodeType == child . TEXT_NODE :,0.88,0.0
"def determine_block_hints(self, text): <TAB> hints = """" <TAB> if text: <TAB> <TAB> if text[0] in "" \n\x85\u2028\u2029"": <TAB> <TAB> <TAB> hints += str(self.best_indent) <TAB> <TAB> if text[-1] not in ""\n\x85\u2028\u2029"": <TAB> <TAB> <TAB> hints += ""-"" <TAB> <TAB> elif len(text) == 1 or text[-2] in ""\n\x85\u2028\u2029"": <TAB> <TAB> <TAB> hints += ""+"" <TAB> return hints",false,"elif len ( text ) == 1 or text [ - 2 ] in ""\n\x85\u2028\u2029"" :","if text [ - 1 ] not in ""\n\x85\u2028\u2029"" :",0.05,0.0
"def _infer_return_type(*args): <TAB> """"""Look at the type of all args and divine their implied return type."""""" <TAB> return_type = None <TAB> for arg in args: <TAB> <TAB> if arg is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance(arg, bytes): <TAB> <TAB> <TAB> if return_type is str: <TAB> <TAB> <TAB> <TAB> raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."") <TAB> <TAB> <TAB> return_type = bytes <TAB> <TAB> else: <TAB> <TAB> <TAB> if return_type is bytes: <TAB> <TAB> <TAB> <TAB> raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."") <TAB> <TAB> <TAB> return_type = str <TAB> if return_type is None: <TAB> <TAB> return str  # tempfile APIs return a str by default. <TAB> return return_type",true,"if isinstance ( arg , bytes ) :","if isinstance ( arg , bytes ) :",0.75,0.0
"def as_iconbitmap(cls, rkey): <TAB> """"""Get image path for use in iconbitmap property"""""" <TAB> img = None <TAB> if rkey in cls._stock: <TAB> <TAB> data = cls._stock[rkey] <TAB> <TAB> if data[""type""] not in (""stock"", ""data"", ""image""): <TAB> <TAB> <TAB> fpath = data[""filename""] <TAB> <TAB> <TAB> fname = os.path.basename(fpath) <TAB> <TAB> <TAB> name, file_ext = os.path.splitext(fname) <TAB> <TAB> <TAB> file_ext = str(file_ext).lower() <TAB> <TAB> <TAB> if file_ext in TK_BITMAP_FORMATS: <TAB> <TAB> <TAB> <TAB> img = BITMAP_TEMPLATE.format(fpath) <TAB> return img",true,"if data [ ""type"" ] not in ( ""stock"" , ""data"" , ""image"" ) :","if data [ ""type"" ] not in ( ""stock"" , ""data"" , ""image"" ) :",0.75,0.0
"def anonymize_ip(ip): <TAB> if ip: <TAB> <TAB> match = RE_FIRST_THREE_OCTETS_OF_IP.findall(str(ip)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ""%s%s"" % (match[0][0], ""0"") <TAB> return """"",true,if match :,if match :,0.53,0.0
"def serialize_tail(self): <TAB> msg = bytearray() <TAB> for v in self.info: <TAB> <TAB> if v[""type""] == BMP_TERM_TYPE_STRING: <TAB> <TAB> <TAB> value = v[""value""].encode(""utf-8"") <TAB> <TAB> elif v[""type""] == BMP_TERM_TYPE_REASON: <TAB> <TAB> <TAB> value = struct.pack(""!H"", v[""value""]) <TAB> <TAB> v[""len""] = len(value) <TAB> <TAB> msg += struct.pack(self._TLV_PACK_STR, v[""type""], v[""len""]) <TAB> <TAB> msg += value <TAB> return msg",false,"if v [ ""type"" ] == BMP_TERM_TYPE_STRING :","elif v [ ""type"" ] == BMP_TERM_TYPE_REASON :",0.26,0.0
"def get_django_comment(text: str, i: int) -> str: <TAB> end = i + 4 <TAB> unclosed_end = 0 <TAB> while end <= len(text): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return text[i:end] <TAB> <TAB> if not unclosed_end and text[end] == ""<"": <TAB> <TAB> <TAB> unclosed_end = end <TAB> <TAB> end += 1 <TAB> raise TokenizationException(""Unclosed comment"", text[i:unclosed_end])",false,"if text [ end - 2 : end ] == ""#}"" :","if text [ end - 2 : end ] == "" "" :",0.9,0.0
"def ComboBoxDroppedHeightTest(windows): <TAB> ""Check if each combobox height is the same as the reference"" <TAB> bugs = [] <TAB> for win in windows: <TAB> <TAB> if not win.ref: <TAB> <TAB> <TAB> continue <TAB> <TAB> if win.Class() != ""ComboBox"" or win.ref.Class() != ""ComboBox"": <TAB> <TAB> <TAB> continue <TAB> <TAB> if win.DroppedRect().height() != win.ref.DroppedRect().height(): <TAB> <TAB> <TAB> bugs.append( <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> win, <TAB> <TAB> <TAB> <TAB> <TAB> ], <TAB> <TAB> <TAB> <TAB> <TAB> {}, <TAB> <TAB> <TAB> <TAB> <TAB> testname, <TAB> <TAB> <TAB> <TAB> <TAB> 0, <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return bugs",false,if win . DroppedRect ( ) . height ( ) != win . ref . DroppedRect ( ) . height ( ) :,"if win . Class ( ) != ""ComboBox"" or win . ref . Class ( ) != ""ComboBox"" :",0.29,0.0
"def testBadModeArgument(self): <TAB> # verify that we get a sensible error message for bad mode argument <TAB> bad_mode = ""qwerty"" <TAB> try: <TAB> <TAB> f = self.open(TESTFN, bad_mode) <TAB> except ValueError as msg: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> s = str(msg) <TAB> <TAB> <TAB> if TESTFN in s or bad_mode not in s: <TAB> <TAB> <TAB> <TAB> self.fail(""bad error message for invalid mode: %s"" % s) <TAB> <TAB> # if msg.args[0] == 0, we're probably on Windows where there may be <TAB> <TAB> # no obvious way to discover why open() failed. <TAB> else: <TAB> <TAB> f.close() <TAB> <TAB> self.fail(""no error for invalid mode: %s"" % bad_mode)",false,if msg . args [ 0 ] != 0 :,if msg . args [ 0 ] == 0 :,0.6,0.0
"def command_group_expired(self, command_group_name): <TAB> try: <TAB> <TAB> deprecate_info = self._command_loader.command_group_table[ <TAB> <TAB> <TAB> command_group_name <TAB> <TAB> ].group_kwargs.get(""deprecate_info"", None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return deprecate_info.expired() <TAB> except AttributeError: <TAB> <TAB> # Items with only token presence in the command table will not have any data. They can't be expired. <TAB> <TAB> pass <TAB> return False",true,if deprecate_info :,if deprecate_info :,0.53,0.0
"def test_non_uniform_probabilities_over_elements(self): <TAB> param = iap.Choice([0, 1], p=[0.25, 0.75]) <TAB> samples = param.draw_samples((10000,)) <TAB> unique, counts = np.unique(samples, return_counts=True) <TAB> assert len(unique) == 2 <TAB> for val, count in zip(unique, counts): <TAB> <TAB> if val == 0: <TAB> <TAB> <TAB> assert 2500 - 500 < count < 2500 + 500 <TAB> <TAB> elif val == 1: <TAB> <TAB> <TAB> assert 7500 - 500 < count < 7500 + 500 <TAB> <TAB> else: <TAB> <TAB> <TAB> assert False",true,elif val == 1 :,elif val == 1 :,1.0,0.0
"def get_labels(directory): <TAB> cache = get_labels.__cache <TAB> if directory not in cache: <TAB> <TAB> l = {} <TAB> <TAB> for t in get_visual_configs(directory)[0][LABEL_SECTION]: <TAB> <TAB> <TAB> if t.storage_form() in l: <TAB> <TAB> <TAB> <TAB> Messager.warning( <TAB> <TAB> <TAB> <TAB> <TAB> ""In configuration, labels for '%s' defined more than once. Only using the last set."" <TAB> <TAB> <TAB> <TAB> <TAB> % t.storage_form(), <TAB> <TAB> <TAB> <TAB> <TAB> -1, <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> # first is storage for, rest are labels. <TAB> <TAB> <TAB> l[t.storage_form()] = t.terms[1:] <TAB> <TAB> cache[directory] = l <TAB> return cache[directory]",true,if t . storage_form ( ) in l :,if t . storage_form ( ) in l :,0.75,0.0
"def try_split(self, split_text: List[str]): <TAB> ret = [] <TAB> for i in split_text: <TAB> <TAB> if len(i) == 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> val = int(i, 2) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> ret.append(val) <TAB> if len(ret) != 0: <TAB> <TAB> ret = bytes(ret) <TAB> <TAB> logger.debug(f""binary successful, returning {ret.__repr__()}"") <TAB> <TAB> return ret",false,if val > 255 or val < 0 :,if val == 0 :,0.04,0.0
"def setCellValue(self, row_idx, col, value): <TAB> assert col.id == ""repls-marked"" <TAB> with self._lock: <TAB> <TAB> rgroup = self.events[row_idx] <TAB> <TAB> if not isinstance(rgroup, findlib2.ReplaceHitGroup): <TAB> <TAB> <TAB> return <TAB> <TAB> rgroup._marked = value == ""true"" and True or False <TAB> if self._tree: <TAB> <TAB> self._tree.invalidateCell(row_idx, col)",true,"if not isinstance ( rgroup , findlib2 . ReplaceHitGroup ) :","if not isinstance ( rgroup , findlib2 . ReplaceHitGroup ) :",0.75,0.0
"def create(cls, settlement_manager, resource_id): <TAB> """"""Create a production chain that can produce the given resource."""""" <TAB> resource_producer = {} <TAB> for abstract_building in AbstractBuilding.buildings.values(): <TAB> <TAB> for resource, production_line in abstract_building.lines.items(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> resource_producer[resource] = [] <TAB> <TAB> <TAB> resource_producer[resource].append((production_line, abstract_building)) <TAB> return ProductionChain(settlement_manager, resource_id, resource_producer)",true,if resource not in resource_producer :,if resource not in resource_producer :,0.75,0.0
def get_all_partition_sets(self): <TAB> partition_sets = [] <TAB> if self.partitions_handle: <TAB> <TAB> partition_sets.extend(self.partitions_handle.get_partition_sets()) <TAB> if self.scheduler_handle: <TAB> <TAB> partition_sets.extend( <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> schedule_def.get_partition_set() <TAB> <TAB> <TAB> <TAB> for schedule_def in self.scheduler_handle.all_schedule_defs() <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ] <TAB> <TAB> ) <TAB> return partition_sets,false,"if isinstance ( schedule_def , PartitionScheduleDefinition )",if schedule_def . partition_set is not None,0.02,0.0
"def _sendDatapointsNow(self, datapoints): <TAB> metrics = {} <TAB> payload_pb = Payload() <TAB> for metric, datapoint in datapoints: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> metric_pb = payload_pb.metrics.add() <TAB> <TAB> <TAB> metric_pb.metric = metric <TAB> <TAB> <TAB> metrics[metric] = metric_pb <TAB> <TAB> else: <TAB> <TAB> <TAB> metric_pb = metrics[metric] <TAB> <TAB> point_pb = metric_pb.points.add() <TAB> <TAB> point_pb.timestamp = int(datapoint[0]) <TAB> <TAB> point_pb.value = datapoint[1] <TAB> self.sendString(payload_pb.SerializeToString())",true,if metric not in metrics :,if metric not in metrics :,0.75,0.0
"def execute(self): <TAB> if self._dirty or not self._qr: <TAB> <TAB> model_class = self.model_class <TAB> <TAB> query_meta = self.get_query_meta() <TAB> <TAB> if self._tuples: <TAB> <TAB> <TAB> ResultWrapper = TuplesQueryResultWrapper <TAB> <TAB> elif self._dicts: <TAB> <TAB> <TAB> ResultWrapper = DictQueryResultWrapper <TAB> <TAB> elif self._naive or not self._joins or self.verify_naive(): <TAB> <TAB> <TAB> ResultWrapper = NaiveQueryResultWrapper <TAB> <TAB> elif self._aggregate_rows: <TAB> <TAB> <TAB> ResultWrapper = AggregateQueryResultWrapper <TAB> <TAB> else: <TAB> <TAB> <TAB> ResultWrapper = ModelQueryResultWrapper <TAB> <TAB> self._qr = ResultWrapper(model_class, self._execute(), query_meta) <TAB> <TAB> self._dirty = False <TAB> <TAB> return self._qr <TAB> else: <TAB> <TAB> return self._qr",false,elif self . _dicts :,elif self . _aggregate_rows :,0.39,0.0
"def get_metrics(): <TAB> classifier, feature_labels = load_classifier() <TAB> available_metrics = ImgageMetrics.get_metric_classes() <TAB> # todo review: DONE IN DOCS <TAB> #  effective_metrics isn't used after filling it with values <TAB> #  in the loops below <TAB> effective_metrics = [] <TAB> for metric in available_metrics: <TAB> <TAB> for label in feature_labels: <TAB> <TAB> <TAB> for label_part in metric.get_labels(): <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> effective_metrics.append(metric) <TAB> return (classifier, feature_labels, available_metrics)",false,if label_part == label and metric not in effective_metrics :,if label_part not in effective_metrics :,0.16,0.0
"def test_nic_names(self): <TAB> p = subprocess.Popen([""ipconfig"", ""/all""], stdout=subprocess.PIPE) <TAB> out = p.communicate()[0] <TAB> if PY3: <TAB> <TAB> out = str(out, sys.stdout.encoding) <TAB> nics = psutil.net_io_counters(pernic=True).keys() <TAB> for nic in nics: <TAB> <TAB> if ""pseudo-interface"" in nic.replace("" "", ""-"").lower(): <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.fail(""%r nic wasn't found in 'ipconfig /all' output"" % nic)",false,if nic not in out :,if out not in nic :,0.31,0.0
"def convert_with_key(self, key, value, replace=True): <TAB> result = self.configurator.convert(value) <TAB> # If the converted value is different, save for next time <TAB> if value is not result: <TAB> <TAB> if replace: <TAB> <TAB> <TAB> self[key] = result <TAB> <TAB> if type(result) in (ConvertingDict, ConvertingList, ConvertingTuple): <TAB> <TAB> <TAB> result.parent = self <TAB> <TAB> <TAB> result.key = key <TAB> return result",true,"if type ( result ) in ( ConvertingDict , ConvertingList , ConvertingTuple ) :","if type ( result ) in ( ConvertingDict , ConvertingList , ConvertingTuple ) :",0.75,0.0
"def _EvaluateFile(self, test_list, file): <TAB> (name, ext) = os.path.splitext(file) <TAB> if ext == "".cc"" or ext == "".cpp"" or ext == "".c"": <TAB> <TAB> if re.search(""_test$|_test_$|_unittest$|_unittest_$|^test_|Tests$"", name): <TAB> <TAB> <TAB> logger.SilentLog(""Found native test file %s"" % file) <TAB> <TAB> <TAB> test_list.append(name)",false,"if re . search ( ""_test$|_test_$|_unittest$|_unittest_$|^test_|Tests$"" , name ) :","if re . search ( ""_test$|_test_$|_unittest_$|^test_|Tests$"" , name ) :",0.58,0.0
"def leading_whitespace(self, inputstring): <TAB> """"""Get leading whitespace."""""" <TAB> leading_ws = [] <TAB> for i, c in enumerate(inputstring): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> leading_ws.append(c) <TAB> <TAB> else: <TAB> <TAB> <TAB> break <TAB> <TAB> if self.indchar is None: <TAB> <TAB> <TAB> self.indchar = c <TAB> <TAB> elif c != self.indchar: <TAB> <TAB> <TAB> self.strict_err_or_warn(""found mixing of tabs and spaces"", inputstring, i) <TAB> return """".join(leading_ws)",false,if c in legal_indent_chars :,if c in self . leading_spaces :,0.12,0.0
"def ident_values(self): <TAB> value = self._ident_values <TAB> if value is False: <TAB> <TAB> value = None <TAB> <TAB> # XXX: how will this interact with orig_prefix ? <TAB> <TAB> # <TAB>  not exposing attrs for now if orig_prefix is set. <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> wrapped = self.wrapped <TAB> <TAB> <TAB> idents = getattr(wrapped, ""ident_values"", None) <TAB> <TAB> <TAB> if idents: <TAB> <TAB> <TAB> <TAB> value = [self._wrap_hash(ident) for ident in idents] <TAB> <TAB> <TAB> ##else: <TAB> <TAB> <TAB> ## <TAB>ident = self.ident <TAB> <TAB> <TAB> ## <TAB>if ident is not None: <TAB> <TAB> <TAB> ## <TAB> <TAB>value = [ident] <TAB> <TAB> self._ident_values = value <TAB> return value",false,if not self . orig_prefix :,if self . wrapped is not None :,0.05,0.0
"def _available_symbols(self, scoperef, expr): <TAB> cplns = [] <TAB> found_names = set() <TAB> while scoperef: <TAB> <TAB> elem = self._elem_from_scoperef(scoperef) <TAB> <TAB> for child in elem: <TAB> <TAB> <TAB> name = child.get(""name"", """") <TAB> <TAB> <TAB> if name.startswith(expr): <TAB> <TAB> <TAB> <TAB> if name not in found_names: <TAB> <TAB> <TAB> <TAB> <TAB> found_names.add(name) <TAB> <TAB> <TAB> <TAB> <TAB> ilk = child.get(""ilk"") or child.tag <TAB> <TAB> <TAB> <TAB> <TAB> cplns.append((ilk, name)) <TAB> <TAB> scoperef = self.parent_scoperef_from_scoperef(scoperef) <TAB> <TAB> if not scoperef: <TAB> <TAB> <TAB> break <TAB> return sorted(cplns, key=operator.itemgetter(1))",true,if name . startswith ( expr ) :,if name . startswith ( expr ) :,0.75,0.0
"def pid_from_name(name): <TAB> # quick and dirty, works with all linux not depending on ps output <TAB> for pid in os.listdir(""/proc""): <TAB> <TAB> try: <TAB> <TAB> <TAB> int(pid) <TAB> <TAB> except: <TAB> <TAB> <TAB> continue <TAB> <TAB> pname = """" <TAB> <TAB> with open(""/proc/%s/cmdline"" % pid, ""r"") as f: <TAB> <TAB> <TAB> pname = f.read() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return int(pid) <TAB> raise ProcessException(""No process with such name: %s"" % name)",false,if name in pname :,if pname == name :,0.04,0.0
"def touch(self): <TAB> if not self.exists(): <TAB> <TAB> try: <TAB> <TAB> <TAB> self.parent().touch() <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> pass <TAB> <TAB> node = self._fs.touch(self.pathnames, {}) <TAB> <TAB> if not node.isdir: <TAB> <TAB> <TAB> raise AssertionError(""Not a folder: %s"" % self.path) <TAB> <TAB> if self.watcher: <TAB> <TAB> <TAB> self.watcher.emit(""created"", self)",true,if not node . isdir :,if not node . isdir :,0.75,0.0
"def setUp(self): <TAB> BaseTestCase.setUp(self) <TAB> self.rawData = [] <TAB> self.dataByKey = {} <TAB> for i in range(1, 11): <TAB> <TAB> stringCol = ""String %d"" % i <TAB> <TAB> fixedCharCol = (""Fixed Char %d"" % i).ljust(40) <TAB> <TAB> rawCol = ""Raw %d"" % i <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> nullableCol = ""Nullable %d"" % i <TAB> <TAB> else: <TAB> <TAB> <TAB> nullableCol = None <TAB> <TAB> dataTuple = (i, stringCol, rawCol, fixedCharCol, nullableCol) <TAB> <TAB> self.rawData.append(dataTuple) <TAB> <TAB> self.dataByKey[i] = dataTuple",true,if i % 2 :,if i % 2 :,0.75,0.0
"def GenerateVector(self, hits, vector, level): <TAB> """"""Generate possible hit vectors which match the rules."""""" <TAB> for item in hits.get(level, []): <TAB> <TAB> if vector: <TAB> <TAB> <TAB> if item < vector[-1]: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if item > self.max_separation + vector[-1]: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> new_vector = vector + [item] <TAB> <TAB> if level + 1 == len(hits): <TAB> <TAB> <TAB> yield new_vector <TAB> <TAB> elif level + 1 < len(hits): <TAB> <TAB> <TAB> for result in self.GenerateVector(hits, new_vector, level + 1): <TAB> <TAB> <TAB> <TAB> yield result",false,if level + 1 == len ( hits ) :,if item > self . max_separation + vector [ - 1 ] :,0.01,0.0
"def __repr__(self): <TAB> attrs = [] <TAB> for k in self.keydata: <TAB> <TAB> if k == ""p"": <TAB> <TAB> <TAB> attrs.append(""p(%d)"" % (self.size() + 1,)) <TAB> <TAB> elif hasattr(self.key, k): <TAB> <TAB> <TAB> attrs.append(k) <TAB> if self.has_private(): <TAB> <TAB> attrs.append(""private"") <TAB> return ""<%s @0x%x %s>"" % (self.__class__.__name__, id(self), "","".join(attrs))",false,"if k == ""p"" :","elif hasattr ( self . key , k ) :",0.02,0.0
"def autoload(self): <TAB> if self._app.config.THEME == ""auto"": <TAB> <TAB> if sys.platform == ""darwin"": <TAB> <TAB> <TAB> if get_osx_theme() == 1: <TAB> <TAB> <TAB> <TAB> theme = DARK <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> theme = LIGHT <TAB> <TAB> else: <TAB> <TAB> <TAB> theme = self.guess_system_theme() <TAB> <TAB> <TAB> if theme == Dark: <TAB> <TAB> <TAB> <TAB> theme = MacOSDark <TAB> else:  # user settings have highest priority <TAB> <TAB> theme = self._app.config.THEME <TAB> self.load_theme(theme)",true,"if sys . platform == ""darwin"" :","if sys . platform == ""darwin"" :",0.75,0.0
"def _get_matching_bracket(self, s, pos): <TAB> if s[pos] != ""{"": <TAB> <TAB> return None <TAB> end = len(s) <TAB> depth = 1 <TAB> pos += 1 <TAB> while pos != end: <TAB> <TAB> c = s[pos] <TAB> <TAB> if c == ""{"": <TAB> <TAB> <TAB> depth += 1 <TAB> <TAB> elif c == ""}"": <TAB> <TAB> <TAB> depth -= 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> pos += 1 <TAB> if pos < end and s[pos] == ""}"": <TAB> <TAB> return pos <TAB> return None",true,if depth == 0 :,if depth == 0 :,0.75,0.0
"def update_meter(self, output, target, meters={""accuracy""}): <TAB> output = self.__to_tensor(output) <TAB> target = self.__to_tensor(target) <TAB> for meter in meters: <TAB> <TAB> if meter not in self.meter.keys(): <TAB> <TAB> <TAB> self.__addmeter(meter) <TAB> <TAB> if meter in [""ap"", ""map"", ""confusion""]: <TAB> <TAB> <TAB> target_th = self._ver2tensor(target) <TAB> <TAB> <TAB> self.meter[meter].add(output, target_th) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.meter[meter].add(output, target)",false,if meter not in self . meter . keys ( ) :,"if meter in [ ""ap"" , ""map"" , ""confusion"" ] :",0.02,0.0
"def _reinit_optimizers_with_oss(self): <TAB> optimizers = self.lightning_module.trainer.optimizers <TAB> for x, optimizer in enumerate(optimizers): <TAB> <TAB> if is_lightning_optimizer(optimizer): <TAB> <TAB> <TAB> optimizer = optimizer._optimizer <TAB> <TAB> if not isinstance(optimizer, OSS): <TAB> <TAB> <TAB> optim_class = type(optimizer) <TAB> <TAB> <TAB> zero_optimizer = OSS( <TAB> <TAB> <TAB> <TAB> params=optimizer.param_groups, optim=optim_class, **optimizer.defaults <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> optimizers[x] = zero_optimizer <TAB> <TAB> <TAB> del optimizer <TAB> trainer = self.lightning_module.trainer <TAB> trainer.optimizers = optimizers <TAB> trainer.convert_to_lightning_optimizers()",false,"if not isinstance ( optimizer , OSS ) :",if is_lightning_optimizer ( optimizer ) :,0.04,0.0
"def OnSelChanged(self, event): <TAB> self.item = event.GetItem() <TAB> if self.item: <TAB> <TAB> self.log.write(""OnSelChanged: %s"" % self.GetItemText(self.item)) <TAB> <TAB> if wx.Platform == ""__WXMSW__"": <TAB> <TAB> <TAB> self.log.write( <TAB> <TAB> <TAB> <TAB> "", BoundingRect: %s\n"" % self.GetBoundingRect(self.item, True) <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.log.write(""\n"") <TAB> event.Skip()",true,"if wx . Platform == ""__WXMSW__"" :","if wx . Platform == ""__WXMSW__"" :",0.75,0.0
"def parse_batch(args): <TAB> errmsg = ""Invalid batch definition: batch entry has to be defined as RULE=BATCH/BATCHES (with integers BATCH <= BATCHES, BATCH >= 1)."" <TAB> if args.batch is not None: <TAB> <TAB> rule, batchdef = parse_key_value_arg(args.batch, errmsg=errmsg) <TAB> <TAB> try: <TAB> <TAB> <TAB> batch, batches = batchdef.split(""/"") <TAB> <TAB> <TAB> batch = int(batch) <TAB> <TAB> <TAB> batches = int(batches) <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> raise ValueError(errmsg) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError(errmsg) <TAB> <TAB> return Batch(rule, batch, batches) <TAB> return None",false,if batch > batches or batch < 1 :,if len ( batches ) != 2 :,0.02,0.0
"def get_foreign_key_columns(self, engine, table_name): <TAB> foreign_keys = set() <TAB> table = db_utils.get_table(engine, table_name) <TAB> inspector = reflection.Inspector.from_engine(engine) <TAB> for column_dict in inspector.get_columns(table_name): <TAB> <TAB> column_name = column_dict[""name""] <TAB> <TAB> column = getattr(table.c, column_name) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> foreign_keys.add(column_name) <TAB> return foreign_keys",false,if column . foreign_keys :,if column . foreign_key :,0.39,0.0
"def update(self, t): <TAB> l = int(t * self.nr_of_tiles) <TAB> for i in range(self.nr_of_tiles): <TAB> <TAB> t = self.tiles_order[i] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.turn_off_tile(t) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.turn_on_tile(t)",false,if i < l :,if t < l :,0.39,0.0
"def read(self, amt=None): <TAB> # the _rbuf test is only in this first if for speed.  It's not <TAB> # logically necessary <TAB> if self._rbuf and not amt is None: <TAB> <TAB> L = len(self._rbuf) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> amt -= L <TAB> <TAB> else: <TAB> <TAB> <TAB> s = self._rbuf[:amt] <TAB> <TAB> <TAB> self._rbuf = self._rbuf[amt:] <TAB> <TAB> <TAB> return s <TAB> s = self._rbuf + self._raw_read(amt) <TAB> self._rbuf = b"""" <TAB> return s",false,if amt > L :,if L > 0 :,0.04,0.0
"def draw_menu_button(self, context, layout, node, text): <TAB> if ( <TAB> <TAB> hasattr(node.id_data, ""sv_show_socket_menus"") <TAB> <TAB> and node.id_data.sv_show_socket_menus <TAB> ): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> layout.menu(""SV_MT_SocketOptionsMenu"", text="""", icon=""TRIA_DOWN"")",false,if self . is_output or self . is_linked or not self . use_prop :,if text :,0.03,0.0
"def __enter__(self): <TAB> with DB.connection_context(): <TAB> <TAB> session_record = SessionRecord() <TAB> <TAB> session_record.f_session_id = self._session_id <TAB> <TAB> session_record.f_engine_name = self._engine_name <TAB> <TAB> session_record.f_engine_type = EngineType.STORAGE <TAB> <TAB> # TODO: engine address <TAB> <TAB> session_record.f_engine_address = {} <TAB> <TAB> session_record.f_create_time = current_timestamp() <TAB> <TAB> rows = session_record.save(force_insert=True) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise Exception(f""create session record {self._session_id} failed"") <TAB> <TAB> LOGGER.debug(f""save session {self._session_id} record"") <TAB> self.create() <TAB> return self",false,if rows != 1 :,if not rows :,0.04,0.0
"def tearDown(self): <TAB> """"""Shutdown the server."""""" <TAB> try: <TAB> <TAB> if self.server: <TAB> <TAB> <TAB> self.server.stop(2.0) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.root_logger.removeHandler(self.sl_hdlr) <TAB> <TAB> <TAB> self.sl_hdlr.close() <TAB> finally: <TAB> <TAB> BaseTest.tearDown(self)",false,if self . sl_hdlr :,if self . root_logger :,0.39,0.0
"def _dec_device(self, srcdev, dstdev): <TAB> if srcdev: <TAB> <TAB> self.srcdevs[srcdev] -= 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> del self.srcdevs[srcdev] <TAB> <TAB> self._set_limits(""read"", self.srcdevs) <TAB> if dstdev: <TAB> <TAB> self.dstdevs[dstdev] -= 1 <TAB> <TAB> if self.dstdevs[dstdev] == 0: <TAB> <TAB> <TAB> del self.dstdevs[dstdev] <TAB> <TAB> self._set_limits(""write"", self.dstdevs)",true,if self . srcdevs [ srcdev ] == 0 :,if self . srcdevs [ srcdev ] == 0 :,0.75,0.0
"def array_for(self, i): <TAB> if 0 <= i < self._cnt: <TAB> <TAB> if i >= self.tailoff(): <TAB> <TAB> <TAB> return self._tail <TAB> <TAB> node = self._root <TAB> <TAB> level = self._shift <TAB> <TAB> while level > 0: <TAB> <TAB> <TAB> assert isinstance(node, Node) <TAB> <TAB> <TAB> node = node._array[(i >> level) & 0x01F] <TAB> <TAB> <TAB> level -= 5 <TAB> <TAB> return node._array <TAB> affirm(False, u""Index out of Range"")",true,if i >= self . tailoff ( ) :,if i >= self . tailoff ( ) :,0.75,0.0
"def convert_tensor(self, offsets, sizes): <TAB> results = [] <TAB> for b, batch in enumerate(offsets): <TAB> <TAB> utterances = [] <TAB> <TAB> for p, utt in enumerate(batch): <TAB> <TAB> <TAB> size = sizes[b][p] <TAB> <TAB> <TAB> if sizes[b][p] > 0: <TAB> <TAB> <TAB> <TAB> utterances.append(utt[0:size]) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> utterances.append(torch.tensor([], dtype=torch.int)) <TAB> <TAB> results.append(utterances) <TAB> return results",true,if sizes [ b ] [ p ] > 0 :,if sizes [ b ] [ p ] > 0 :,0.75,0.0
"def _predict_proba(self, X, preprocess=True): <TAB> if preprocess: <TAB> <TAB> X = self.preprocess(X) <TAB> if self.problem_type == REGRESSION: <TAB> <TAB> return self.model.predict(X) <TAB> y_pred_proba = self.model.predict_proba(X) <TAB> if self.problem_type == BINARY: <TAB> <TAB> if len(y_pred_proba.shape) == 1: <TAB> <TAB> <TAB> return y_pred_proba <TAB> <TAB> elif y_pred_proba.shape[1] > 1: <TAB> <TAB> <TAB> return y_pred_proba[:, 1] <TAB> <TAB> else: <TAB> <TAB> <TAB> return y_pred_proba <TAB> elif y_pred_proba.shape[1] > 2: <TAB> <TAB> return y_pred_proba <TAB> else: <TAB> <TAB> return y_pred_proba[:, 1]",false,elif y_pred_proba . shape [ 1 ] > 1 :,elif y_pred_proba . shape [ 1 ] > 2 :,0.64,0.0
"def timeout(self): <TAB> now = ptime.time() <TAB> dt = now - self.lastPlayTime <TAB> if dt < 0: <TAB> <TAB> return <TAB> n = int(self.playRate * dt) <TAB> if n != 0: <TAB> <TAB> self.lastPlayTime += float(n) / self.playRate <TAB> <TAB> if self.currentIndex + n > self.image.shape[self.axes[""t""]]: <TAB> <TAB> <TAB> self.play(0) <TAB> <TAB> self.jumpFrames(n)",true,"if self . currentIndex + n > self . image . shape [ self . axes [ ""t"" ] ] :","if self . currentIndex + n > self . image . shape [ self . axes [ ""t"" ] ] :",1.0,0.0
"def __init__(self, data, weights=None, ddof=0): <TAB> self.data = np.asarray(data) <TAB> if weights is None: <TAB> <TAB> self.weights = np.ones(self.data.shape[0]) <TAB> else: <TAB> <TAB> self.weights = np.asarray(weights).astype(float) <TAB> <TAB> # TODO: why squeeze? <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.weights = self.weights.squeeze() <TAB> self.ddof = ddof",false,if len ( self . weights . shape ) > 1 and len ( self . weights ) > 1 :,if ddof is not None :,0.06,0.0
"def writerow(self, row): <TAB> unicode_row = [] <TAB> for col in row: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> unicode_row.append(col.encode(""utf-8"").strip()) <TAB> <TAB> else: <TAB> <TAB> <TAB> unicode_row.append(col) <TAB> self.writer.writerow(unicode_row) <TAB> # Fetch UTF-8 output from the queue ... <TAB> data = self.queue.getvalue() <TAB> data = data.decode(""utf-8"") <TAB> # ... and reencode it into the target encoding <TAB> data = self.encoder.encode(data) <TAB> # write to the target stream <TAB> self.stream.write(data) <TAB> # empty queue <TAB> self.queue.truncate(0)",false,if type ( col ) == str or type ( col ) == unicode :,if six . PY2 :,0.01,0.0
"def __init__(self, choices, allow_blank=False, **kwargs): <TAB> self.choiceset = choices <TAB> self.allow_blank = allow_blank <TAB> self._choices = dict() <TAB> # Unpack grouped choices <TAB> for k, v in choices: <TAB> <TAB> if type(v) in [list, tuple]: <TAB> <TAB> <TAB> for k2, v2 in v: <TAB> <TAB> <TAB> <TAB> self._choices[k2] = v2 <TAB> <TAB> else: <TAB> <TAB> <TAB> self._choices[k] = v <TAB> super().__init__(**kwargs)",true,"if type ( v ) in [ list , tuple ] :","if type ( v ) in [ list , tuple ] :",0.75,0.0
"def simp_ext(_, expr): <TAB> if expr.op.startswith(""zeroExt_""): <TAB> <TAB> arg = expr.args[0] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return arg <TAB> <TAB> return ExprCompose(arg, ExprInt(0, expr.size - arg.size)) <TAB> if expr.op.startswith(""signExt_""): <TAB> <TAB> arg = expr.args[0] <TAB> <TAB> add_size = expr.size - arg.size <TAB> <TAB> new_expr = ExprCompose( <TAB> <TAB> <TAB> arg, <TAB> <TAB> <TAB> ExprCond( <TAB> <TAB> <TAB> <TAB> arg.msb(), ExprInt(size2mask(add_size), add_size), ExprInt(0, add_size) <TAB> <TAB> <TAB> ), <TAB> <TAB> ) <TAB> <TAB> return new_expr <TAB> return expr",false,if expr . size == arg . size :,if arg . size == 0 :,0.16,0.0
"def mark_differences(value: str, compare_against: str): <TAB> result = [] <TAB> for i, char in enumerate(value): <TAB> <TAB> try: <TAB> <TAB> <TAB> if char != compare_against[i]: <TAB> <TAB> <TAB> <TAB> result.append('<font color=""red"">{}</font>'.format(char)) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> result.append(char) <TAB> <TAB> except IndexError: <TAB> <TAB> <TAB> result.append(char) <TAB> return """".join(result)",true,if char != compare_against [ i ] :,if char != compare_against [ i ] :,0.75,0.0
"def run_query(self, query, user): <TAB> url = ""%s%s"" % (self.base_url, ""&"".join(query.split(""\n""))) <TAB> error = None <TAB> data = None <TAB> try: <TAB> <TAB> response = requests.get(url, auth=self.auth, verify=self.verify) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> data = _transform_result(response) <TAB> <TAB> else: <TAB> <TAB> <TAB> error = ""Failed getting results (%d)"" % response.status_code <TAB> except Exception as ex: <TAB> <TAB> data = None <TAB> <TAB> error = str(ex) <TAB> return data, error",false,if response . status_code == 200 :,if user :,0.02,0.0
"def on_enter(self): <TAB> """"""Fired when mouse enter the bbox of the widget."""""" <TAB> if hasattr(self, ""md_bg_color"") and self.focus_behavior: <TAB> <TAB> if hasattr(self, ""theme_cls"") and not self.focus_color: <TAB> <TAB> <TAB> self.md_bg_color = self.theme_cls.bg_normal <TAB> <TAB> else: <TAB> <TAB> <TAB> if not self.focus_color: <TAB> <TAB> <TAB> <TAB> self.md_bg_color = App.get_running_app().theme_cls.bg_normal <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.md_bg_color = self.focus_color",true,"if hasattr ( self , ""theme_cls"" ) and not self . focus_color :","if hasattr ( self , ""theme_cls"" ) and not self . focus_color :",1.0,0.0
"def tearDown(self): <TAB> if not self.is_playback(): <TAB> <TAB> try: <TAB> <TAB> <TAB> if self.hosted_service_name is not None: <TAB> <TAB> <TAB> <TAB> self.sms.delete_hosted_service(self.hosted_service_name) <TAB> <TAB> except: <TAB> <TAB> <TAB> pass <TAB> <TAB> try: <TAB> <TAB> <TAB> if self.storage_account_name is not None: <TAB> <TAB> <TAB> <TAB> self.sms.delete_storage_account(self.storage_account_name) <TAB> <TAB> except: <TAB> <TAB> <TAB> pass <TAB> <TAB> try: <TAB> <TAB> <TAB> self.sms.delete_affinity_group(self.affinity_group_name) <TAB> <TAB> except: <TAB> <TAB> <TAB> pass <TAB> return super(LegacyMgmtAffinityGroupTest, self).tearDown()",true,if self . hosted_service_name is not None :,if self . hosted_service_name is not None :,0.75,0.0
"def name2cp(k): <TAB> if k == ""apos"": <TAB> <TAB> return ord(""'"") <TAB> if hasattr(htmlentitydefs, ""name2codepoint""):  # requires Python 2.3 <TAB> <TAB> return htmlentitydefs.name2codepoint[k] <TAB> else: <TAB> <TAB> k = htmlentitydefs.entitydefs[k] <TAB> <TAB> if k.startswith(""&#"") and k.endswith("";""): <TAB> <TAB> <TAB> return int(k[2:-1])  # not in latin-1 <TAB> <TAB> return ord(codecs.latin_1_decode(k)[0])",false,"if k . startswith ( ""&#"" ) and k . endswith ( "";"" ) :","if k . startswith ( ""&"" ) and k . endswith ( "";"" ) :",0.9,0.0
"def _para_set(self, params, part): <TAB> if len(params) == 0: <TAB> <TAB> result = suggest([i.get_name() for i in self._options], part) <TAB> <TAB> return result <TAB> elif len(params) == 1: <TAB> <TAB> paramName = params[0] <TAB> <TAB> if paramName not in self._options: <TAB> <TAB> <TAB> return [] <TAB> <TAB> opt = self._options[paramName] <TAB> <TAB> paramType = opt.get_type() <TAB> <TAB> if paramType == ""boolean"": <TAB> <TAB> <TAB> values = [opt.get_default_value() == ""True"" and ""False"" or ""True""] <TAB> <TAB> else: <TAB> <TAB> <TAB> values = self._memory[paramName] <TAB> <TAB> return suggest(values, part) <TAB> else: <TAB> <TAB> return []",true,"if paramType == ""boolean"" :","if paramType == ""boolean"" :",0.75,0.0
"def hexcmp(x, y): <TAB> try: <TAB> <TAB> a = int(x, 16) <TAB> <TAB> b = int(y, 16) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return -1 <TAB> <TAB> if a > b: <TAB> <TAB> <TAB> return 1 <TAB> <TAB> return 0 <TAB> except: <TAB> <TAB> return cmp(x, y)",true,if a < b :,if a < b :,0.75,0.0
"def execute(self, statement, arguments=None): <TAB> while True: <TAB> <TAB> try: <TAB> <TAB> <TAB> if arguments: <TAB> <TAB> <TAB> <TAB> self.cursor.execute(statement, arguments) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.cursor.execute(statement) <TAB> <TAB> except sqlite3.OperationalError as ex: <TAB> <TAB> <TAB> if ""locked"" not in getSafeExString(ex): <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> else: <TAB> <TAB> <TAB> break <TAB> if statement.lstrip().upper().startswith(""SELECT""): <TAB> <TAB> return self.cursor.fetchall()",false,"if ""locked"" not in getSafeExString ( ex ) :","if statement . lstrip ( ) . upper ( ) . startswith ( ""SELECT"" ) :",0.02,0.0
"def _test_forever(self, tests): <TAB> while True: <TAB> <TAB> for test_name in tests: <TAB> <TAB> <TAB> yield test_name <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> if self.ns.fail_env_changed and self.environment_changed: <TAB> <TAB> <TAB> <TAB> return",false,if self . bad :,if self . ns . fail_tests and self . test_tests :,0.27,0.0
"def removeUser(self, username): <TAB> hideFromOSD = not constants.SHOW_DIFFERENT_ROOM_OSD <TAB> if username in self._users: <TAB> <TAB> user = self._users[username] <TAB> <TAB> if user.room: <TAB> <TAB> <TAB> if self.isRoomSame(user.room): <TAB> <TAB> <TAB> <TAB> hideFromOSD = not constants.SHOW_SAME_ROOM_OSD <TAB> if username in self._users: <TAB> <TAB> self._users.pop(username) <TAB> <TAB> message = getMessage(""left-notification"").format(username) <TAB> <TAB> self.ui.showMessage(message, hideFromOSD) <TAB> <TAB> self._client.lastLeftTime = time.time() <TAB> <TAB> self._client.lastLeftUser = username <TAB> self.userListChange()",true,if self . isRoomSame ( user . room ) :,if self . isRoomSame ( user . room ) :,0.75,0.0
"def AutoTest(): <TAB> with open(sys.argv[1], ""rb"") as f: <TAB> <TAB> for line in f.read().split(b""\n""): <TAB> <TAB> <TAB> line = BYTES2SYSTEMSTR(line.strip()) <TAB> <TAB> <TAB> if not line: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> elif line.startswith(""#""): <TAB> <TAB> <TAB> <TAB> print(line) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> print("">>> "" + line) <TAB> <TAB> <TAB> <TAB> os.system(line) <TAB> <TAB> <TAB> <TAB> sys.stdout.write(""\npress enter to continue..."") <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> input() <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> raw_input() <TAB> <TAB> <TAB> <TAB> sys.stdout.write(""\n"")",false,if PY3 :,if input :,0.32,0.0
"def get_first_field(layout, clz): <TAB> for layout_object in layout.fields: <TAB> <TAB> if issubclass(layout_object.__class__, clz): <TAB> <TAB> <TAB> return layout_object <TAB> <TAB> elif hasattr(layout_object, ""get_field_names""): <TAB> <TAB> <TAB> gf = get_first_field(layout_object, clz) <TAB> <TAB> <TAB> if gf: <TAB> <TAB> <TAB> <TAB> return gf",false,"if issubclass ( layout_object . __class__ , clz ) :","elif hasattr ( layout_object , ""get_field_names"" ) :",0.03,0.0
"def sanitize_event_keys(kwargs, valid_keys): <TAB> # Sanity check: Don't honor keys that we don't recognize. <TAB> for key in list(kwargs.keys()): <TAB> <TAB> if key not in valid_keys: <TAB> <TAB> <TAB> kwargs.pop(key) <TAB> # Truncate certain values over 1k <TAB> for key in [""play"", ""role"", ""task"", ""playbook""]: <TAB> <TAB> if isinstance(kwargs.get(""event_data"", {}).get(key), str): <TAB> <TAB> <TAB> if len(kwargs[""event_data""][key]) > 1024: <TAB> <TAB> <TAB> <TAB> kwargs[""event_data""][key] = Truncator(kwargs[""event_data""][key]).chars( <TAB> <TAB> <TAB> <TAB> <TAB> 1024 <TAB> <TAB> <TAB> <TAB> )",false,"if len ( kwargs [ ""event_data"" ] [ key ] ) > 1024 :","if isinstance ( kwargs . get ( ""event_data"" , { } ) . get ( key ) , str ) :",0.02,0.0
"def visit_productionlist(self, node): <TAB> self.new_state() <TAB> names = [] <TAB> for production in node: <TAB> <TAB> names.append(production[""tokenname""]) <TAB> maxlen = max(len(name) for name in names) <TAB> for production in node: <TAB> <TAB> if production[""tokenname""]: <TAB> <TAB> <TAB> self.add_text(production[""tokenname""].ljust(maxlen) + "" ::="") <TAB> <TAB> <TAB> lastname = production[""tokenname""] <TAB> <TAB> else: <TAB> <TAB> <TAB> self.add_text(""%s <TAB>"" % ("" "" * len(lastname))) <TAB> <TAB> self.add_text(production.astext() + self.nl) <TAB> self.end_state(wrap=False) <TAB> raise nodes.SkipNode",true,"if production [ ""tokenname"" ] :","if production [ ""tokenname"" ] :",0.75,0.0
"def uuid(self): <TAB> if not getattr(self, ""_uuid"", None): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._uuid = self.repository._kp_uuid( <TAB> <TAB> <TAB> <TAB> self.path <TAB> <TAB> <TAB> )  # Use repository UUID (even if None) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._uuid = str(uuid.uuid4()) <TAB> return self._uuid",false,if self . repository is not None :,if self . repository :,0.23,0.0
"def remove(self, values): <TAB> if not isinstance(values, (list, tuple, set)): <TAB> <TAB> values = [values] <TAB> for v in values: <TAB> <TAB> v = str(v) <TAB> <TAB> if isinstance(self._definition, dict): <TAB> <TAB> <TAB> self._definition.pop(v, None) <TAB> <TAB> elif self._definition == ""ANY"": <TAB> <TAB> <TAB> if v == ""ANY"": <TAB> <TAB> <TAB> <TAB> self._definition = [] <TAB> <TAB> elif v in self._definition: <TAB> <TAB> <TAB> self._definition.remove(v) <TAB> if ( <TAB> <TAB> self._value is not None <TAB> <TAB> and self._value not in self._definition <TAB> <TAB> and self._not_any() <TAB> ): <TAB> <TAB> raise ConanException(bad_value_msg(self._name, self._value, self.values_range))",true,"if isinstance ( self . _definition , dict ) :","if isinstance ( self . _definition , dict ) :",0.75,0.0
"def make(self): <TAB> pygments_dir = join(self.dir, ""externals"", ""pygments"") <TAB> if exists(pygments_dir): <TAB> <TAB> run_in_dir(""hg pull"", pygments_dir, self.log.info) <TAB> <TAB> run_in_dir(""hg update"", pygments_dir, self.log.info) <TAB> else: <TAB> <TAB> if not exists(dirname(pygments_dir)): <TAB> <TAB> <TAB> os.makedirs(dirname(pygments_dir)) <TAB> <TAB> run_in_dir( <TAB> <TAB> <TAB> ""hg clone http://dev.pocoo.org/hg/pygments-main %s"" <TAB> <TAB> <TAB> % basename(pygments_dir), <TAB> <TAB> <TAB> dirname(pygments_dir), <TAB> <TAB> <TAB> self.log.info, <TAB> <TAB> )",true,if not exists ( dirname ( pygments_dir ) ) :,if not exists ( dirname ( pygments_dir ) ) :,0.75,0.0
def set_field(self): <TAB> i = 0 <TAB> for string in self.display_string: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.config[self.field + str(i)] = self.conversion_fn(self.str[i]) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.config[self.field + str(i)] = self.str[i] <TAB> <TAB> i = i + 1,false,if self . conversion_fn :,if string == self . conversion_fn :,0.37,0.0
"def cleanup(self): <TAB> with self.lock: <TAB> <TAB> for proc in self.processes: <TAB> <TAB> <TAB> if proc.is_alive(): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> proc.join() <TAB> <TAB> <TAB> self.processes.remove(proc) <TAB> <TAB> <TAB> log.debug(""Subprocess %s cleaned up"", proc.name)",true,if proc . is_alive ( ) :,if proc . is_alive ( ) :,0.75,0.0
"def setup(self, gen): <TAB> Node.setup(self, gen) <TAB> for c in self.children: <TAB> <TAB> c.setup(gen) <TAB> if not self.accepts_epsilon: <TAB> <TAB> # If it's not already accepting epsilon, it might now do so. <TAB> <TAB> for c in self.children: <TAB> <TAB> <TAB> # any non-epsilon means all is non-epsilon <TAB> <TAB> <TAB> if not c.accepts_epsilon: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> self.accepts_epsilon = 1 <TAB> <TAB> <TAB> gen.changed()",true,if not c . accepts_epsilon :,if not c . accepts_epsilon :,0.75,0.0
"def __call__(self, message): <TAB> with self._lock: <TAB> <TAB> self._pending_ack += 1 <TAB> <TAB> self.max_pending_ack = max(self.max_pending_ack, self._pending_ack) <TAB> <TAB> self.seen_message_ids.append(int(message.attributes[""seq_num""])) <TAB> time.sleep(self._processing_time) <TAB> with self._lock: <TAB> <TAB> self._pending_ack -= 1 <TAB> <TAB> message.ack() <TAB> <TAB> self.completed_calls += 1 <TAB> <TAB> if self.completed_calls >= self._resolve_at_msg_count: <TAB> <TAB> <TAB> if not self.done_future.done(): <TAB> <TAB> <TAB> <TAB> self.done_future.set_result(None)",false,if not self . done_future . done ( ) :,if self . completed_calls >= self . _resolve_at_msg_count :,0.03,0.0
"def build_canned_image_list(path): <TAB> layers_path = get_bitbake_var(""BBLAYERS"") <TAB> canned_wks_layer_dirs = [] <TAB> if layers_path is not None: <TAB> <TAB> for layer_path in layers_path.split(): <TAB> <TAB> <TAB> for wks_path in (WIC_DIR, SCRIPTS_CANNED_IMAGE_DIR): <TAB> <TAB> <TAB> <TAB> cpath = os.path.join(layer_path, wks_path) <TAB> <TAB> <TAB> <TAB> if os.path.isdir(cpath): <TAB> <TAB> <TAB> <TAB> <TAB> canned_wks_layer_dirs.append(cpath) <TAB> cpath = os.path.join(path, CANNED_IMAGE_DIR) <TAB> canned_wks_layer_dirs.append(cpath) <TAB> return canned_wks_layer_dirs",true,if os . path . isdir ( cpath ) :,if os . path . isdir ( cpath ) :,0.75,0.0
"def _recv_loop(self) -> None: <TAB> async with self._ws as connection: <TAB> <TAB> self._connected = True <TAB> <TAB> self.connection = connection <TAB> <TAB> while self._connected: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> resp = await self.connection.recv() <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> await self._on_message(resp) <TAB> <TAB> <TAB> except (websockets.ConnectionClosed, ConnectionResetError): <TAB> <TAB> <TAB> <TAB> logger.info(""connection closed"") <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> await asyncio.sleep(0) <TAB> if self._connected: <TAB> <TAB> self._loop.create_task(self.dispose())",true,if resp :,if resp :,0.53,0.0
"def _get_between(content, start, end=None): <TAB> should_yield = False <TAB> for line in content.split(""\n""): <TAB> <TAB> if start in line: <TAB> <TAB> <TAB> should_yield = True <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> if should_yield and line: <TAB> <TAB> <TAB> yield line.strip().split("" "")[0]",false,if end and end in line :,if end and line == end :,0.26,0.0
"def handle_parse_result(self, ctx, opts, args): <TAB> if self.name in opts: <TAB> <TAB> if self.mutually_exclusive.intersection(opts): <TAB> <TAB> <TAB> self._raise_exclusive_error() <TAB> <TAB> if self.multiple and len(set(opts[self.name])) > 1: <TAB> <TAB> <TAB> self._raise_exclusive_error() <TAB> return super(MutuallyExclusiveOption, self).handle_parse_result(ctx, opts, args)",true,if self . multiple and len ( set ( opts [ self . name ] ) ) > 1 :,if self . multiple and len ( set ( opts [ self . name ] ) ) > 1 :,0.75,0.0
"def write(self, s): <TAB> if self.interactive: <TAB> <TAB> if isinstance(self.active_mode, deluge.ui.console.modes.cmdline.CmdLine): <TAB> <TAB> <TAB> self.active_mode.write(s) <TAB> <TAB> else: <TAB> <TAB> <TAB> component.get(""CmdLine"").add_line(s, False) <TAB> <TAB> <TAB> self.events.append(s) <TAB> else: <TAB> <TAB> print(colors.strip_colors(s))",true,"if isinstance ( self . active_mode , deluge . ui . console . modes . cmdline . CmdLine ) :","if isinstance ( self . active_mode , deluge . ui . console . modes . cmdline . CmdLine ) :",0.75,0.0
"def findfiles(path): <TAB> files = [] <TAB> for name in os.listdir(path): <TAB> <TAB> # ignore hidden files/dirs and other unwanted files <TAB> <TAB> if name.startswith(""."") or name == ""lastsnap.jpg"": <TAB> <TAB> <TAB> continue <TAB> <TAB> pathname = os.path.join(path, name) <TAB> <TAB> st = os.lstat(pathname) <TAB> <TAB> mode = st.st_mode <TAB> <TAB> if stat.S_ISDIR(mode): <TAB> <TAB> <TAB> files.extend(findfiles(pathname)) <TAB> <TAB> elif stat.S_ISREG(mode): <TAB> <TAB> <TAB> files.append((pathname, name, st)) <TAB> return files",true,if stat . S_ISDIR ( mode ) :,if stat . S_ISDIR ( mode ) :,0.75,0.0
"def _get_documented_completions(self, table, startswith=None): <TAB> names = [] <TAB> for key, command in table.items(): <TAB> <TAB> if getattr(command, ""_UNDOCUMENTED"", False): <TAB> <TAB> <TAB> # Don't tab complete undocumented commands/params <TAB> <TAB> <TAB> continue <TAB> <TAB> if startswith is not None and not key.startswith(startswith): <TAB> <TAB> <TAB> continue <TAB> <TAB> if getattr(command, ""positional_arg"", False): <TAB> <TAB> <TAB> continue <TAB> <TAB> names.append(key) <TAB> return names",false,"if getattr ( command , ""positional_arg"" , False ) :",if startswith is not None and not key . startswith ( startswith ) :,0.02,0.0
"def fix_newlines(lines): <TAB> """"""Convert newlines to unix."""""" <TAB> for i, line in enumerate(lines): <TAB> <TAB> if line.endswith(""\r\n""): <TAB> <TAB> <TAB> lines[i] = line[:-2] + ""\n"" <TAB> <TAB> elif line.endswith(""\r""): <TAB> <TAB> <TAB> lines[i] = line[:-1] + ""\n""",false,"if line . endswith ( ""\r\n"" ) :","elif line . endswith ( ""\r"" ) :",0.2,0.0
"def GeneratePageMetatadata(self, task): <TAB> address_space = self.session.GetParameter(""default_address_space"") <TAB> for vma in task.mm.mmap.walk_list(""vm_next""): <TAB> <TAB> start = vma.vm_start <TAB> <TAB> end = vma.vm_end <TAB> <TAB> # Skip the entire region. <TAB> <TAB> if end < self.plugin_args.start: <TAB> <TAB> <TAB> continue <TAB> <TAB> # Done. <TAB> <TAB> if start > self.plugin_args.end: <TAB> <TAB> <TAB> break <TAB> <TAB> for vaddr in utils.xrange(start, end, 0x1000): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> yield vaddr, self._CreateMetadata(address_space.describe_vtop(vaddr))",false,if self . plugin_args . start <= vaddr <= self . plugin_args . end :,if vaddr :,0.01,0.0
"def get_shape_at_node(self, node, assumptions): <TAB> for k, v in assumptions.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return v <TAB> if node.inputs: <TAB> <TAB> return node.container.shape( <TAB> <TAB> <TAB> input_shapes=[ <TAB> <TAB> <TAB> <TAB> self.get_shape_at_node(input_node, assumptions) <TAB> <TAB> <TAB> <TAB> for input_node in node.inputs <TAB> <TAB> <TAB> ] <TAB> <TAB> ) <TAB> else: <TAB> <TAB> return node.container.shape(None)",false,if k in node . names :,"if k == ""shape"" and v is not None :",0.03,0.0
"def fix_doc(self, doc): <TAB> type = doc.get(""type"", {}).get(""key"") <TAB> if type == ""/type/work"": <TAB> <TAB> if doc.get(""authors""): <TAB> <TAB> <TAB> # some record got empty author records because of an error <TAB> <TAB> <TAB> # temporary hack to fix <TAB> <TAB> <TAB> doc[""authors""] = [ <TAB> <TAB> <TAB> <TAB> a for a in doc[""authors""] if ""author"" in a and ""key"" in a[""author""] <TAB> <TAB> <TAB> ] <TAB> elif type == ""/type/edition"": <TAB> <TAB> # get rid of title_prefix. <TAB> <TAB> if ""title_prefix"" in doc: <TAB> <TAB> <TAB> title = doc[""title_prefix""].strip() + "" "" + doc.get(""title"", """") <TAB> <TAB> <TAB> doc[""title""] = title.strip() <TAB> <TAB> <TAB> del doc[""title_prefix""] <TAB> return doc",true,"if doc . get ( ""authors"" ) :","if doc . get ( ""authors"" ) :",0.75,0.0
"def modify_column(self, column: List[Optional[""Cell""]]): <TAB> for i in range(len(column)): <TAB> <TAB> gate = column[i] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> elif isinstance(gate, ParityControlCell): <TAB> <TAB> <TAB> # The first parity control to modify the column must merge all <TAB> <TAB> <TAB> # of the other parity controls into itself. <TAB> <TAB> <TAB> column[i] = None <TAB> <TAB> <TAB> self._basis_change += gate._basis_change <TAB> <TAB> <TAB> self.qubits += gate.qubits <TAB> <TAB> elif gate is not None: <TAB> <TAB> <TAB> column[i] = gate.controlled_by(self.qubits[0])",false,if gate is self :,if gate is None :,0.39,0.0
"def onSync(self, auto=False, reload=True): <TAB> if not auto or ( <TAB> <TAB> self.pm.profile[""syncKey""] and self.pm.profile[""autoSync""] and not self.safeMode <TAB> ): <TAB> <TAB> from aqt.sync import SyncManager <TAB> <TAB> if not self.unloadCollection(): <TAB> <TAB> <TAB> return <TAB> <TAB> # set a sync state so the refresh timer doesn't fire while deck <TAB> <TAB> # unloaded <TAB> <TAB> self.state = ""sync"" <TAB> <TAB> self.syncer = SyncManager(self, self.pm) <TAB> <TAB> self.syncer.sync() <TAB> if reload: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.loadCollection()",false,if not self . col :,if self . loaded :,0.05,0.0
"def _has_url_match(self, match, request_url): <TAB> url = match[""url""] <TAB> if _is_string(url): <TAB> <TAB> if match[""match_querystring""]: <TAB> <TAB> <TAB> return self._has_strict_url_match(url, request_url) <TAB> <TAB> else: <TAB> <TAB> <TAB> url_without_qs = request_url.split(""?"", 1)[0] <TAB> <TAB> <TAB> return url == url_without_qs <TAB> elif isinstance(url, re._pattern_type) and url.match(request_url): <TAB> <TAB> return True <TAB> else: <TAB> <TAB> return False",true,"if match [ ""match_querystring"" ] :","if match [ ""match_querystring"" ] :",0.75,0.0
"def pool_image(self, image): <TAB> if self.count < self.pool_size: <TAB> <TAB> self.pool.append(image) <TAB> <TAB> self.count += 1 <TAB> <TAB> return image <TAB> else: <TAB> <TAB> p = random.random() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> random_id = random.randint(0, self.pool_size - 1) <TAB> <TAB> <TAB> temp = self.pool[random_id] <TAB> <TAB> <TAB> self.pool[random_id] = image <TAB> <TAB> <TAB> return temp <TAB> <TAB> else: <TAB> <TAB> <TAB> return image",false,if p > 0.5 :,if p < self . pool_size :,0.05,0.0
"def get_target_dimensions(self): <TAB> width, height = self.engine.size <TAB> for operation in self.operations: <TAB> <TAB> if operation[""type""] == ""crop"": <TAB> <TAB> <TAB> width = operation[""right""] - operation[""left""] <TAB> <TAB> <TAB> height = operation[""bottom""] - operation[""top""] <TAB> <TAB> if operation[""type""] == ""resize"": <TAB> <TAB> <TAB> width = operation[""width""] <TAB> <TAB> <TAB> height = operation[""height""] <TAB> return (width, height)",true,"if operation [ ""type"" ] == ""crop"" :","if operation [ ""type"" ] == ""crop"" :",0.75,0.0
"def validate_matrix(matrix): <TAB> if not matrix: <TAB> <TAB> return None <TAB> for key, value in matrix.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> ""`{}` defines a non uniform distribution, "" <TAB> <TAB> <TAB> <TAB> ""and it cannot be used with bayesian optimization."".format(key) <TAB> <TAB> <TAB> ) <TAB> return matrix",false,if value . is_distribution and not value . is_uniform :,if value is not None :,0.1,0.0
"def scm_to_conandata(self): <TAB> try: <TAB> <TAB> scm_to_conandata = get_env(""CONAN_SCM_TO_CONANDATA"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> scm_to_conandata = self.get_item(""general.scm_to_conandata"") <TAB> <TAB> return scm_to_conandata.lower() in (""1"", ""true"") <TAB> except ConanException: <TAB> <TAB> return False",false,if scm_to_conandata is None :,if not scm_to_conandata :,0.04,0.0
"def _link_vrf_table(self, vrf_table, rt_list): <TAB> route_family = vrf_table.route_family <TAB> for rt in rt_list: <TAB> <TAB> rt_rf_id = rt + "":"" + str(route_family) <TAB> <TAB> table_set = self._tables_for_rt.get(rt_rf_id) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> table_set = set() <TAB> <TAB> <TAB> self._tables_for_rt[rt_rf_id] = table_set <TAB> <TAB> table_set.add(vrf_table) <TAB> <TAB> LOG.debug(""Added VrfTable %s to import RT table list: %s"", vrf_table, rt)",true,if table_set is None :,if table_set is None :,0.75,0.0
"def add_tags( <TAB> self, cve_results: Dict[str, Dict[str, Dict[str, str]]], file_object: FileObject ): <TAB> # results structure: {'component': {'cve_id': {'score2': '6.4', 'score3': 'N/A'}}} <TAB> for component in cve_results: <TAB> <TAB> for cve_id in cve_results[component]: <TAB> <TAB> <TAB> entry = cve_results[component][cve_id] <TAB> <TAB> <TAB> if self._entry_has_critical_rating(entry): <TAB> <TAB> <TAB> <TAB> self.add_analysis_tag( <TAB> <TAB> <TAB> <TAB> <TAB> file_object, ""CVE"", ""critical CVE"", TagColor.RED, True <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return",true,if self . _entry_has_critical_rating ( entry ) :,if self . _entry_has_critical_rating ( entry ) :,0.75,0.0
"def _validate(self): <TAB> try: <TAB> <TAB> super(CustomClassifier, self)._validate() <TAB> except UnsupportedDataType: <TAB> <TAB> if self.dtype in FACTOR_DTYPES: <TAB> <TAB> <TAB> raise UnsupportedDataType( <TAB> <TAB> <TAB> <TAB> typename=type(self).__name__, <TAB> <TAB> <TAB> <TAB> dtype=self.dtype, <TAB> <TAB> <TAB> <TAB> hint=""Did you mean to create a CustomFactor?"", <TAB> <TAB> <TAB> ) <TAB> <TAB> elif self.dtype in FILTER_DTYPES: <TAB> <TAB> <TAB> raise UnsupportedDataType( <TAB> <TAB> <TAB> <TAB> typename=type(self).__name__, <TAB> <TAB> <TAB> <TAB> dtype=self.dtype, <TAB> <TAB> <TAB> <TAB> hint=""Did you mean to create a CustomFilter?"", <TAB> <TAB> <TAB> ) <TAB> <TAB> raise",true,elif self . dtype in FILTER_DTYPES :,elif self . dtype in FILTER_DTYPES :,0.75,0.0
"def formatMessage(self, record): <TAB> recordcopy = copy(record) <TAB> levelname = recordcopy.levelname <TAB> seperator = "" "" * (8 - len(recordcopy.levelname)) <TAB> if self.use_colors: <TAB> <TAB> levelname = self.color_level_name(levelname, recordcopy.levelno) <TAB> <TAB> if ""color_message"" in recordcopy.__dict__: <TAB> <TAB> <TAB> recordcopy.msg = recordcopy.__dict__[""color_message""] <TAB> <TAB> <TAB> recordcopy.__dict__[""message""] = recordcopy.getMessage() <TAB> recordcopy.__dict__[""levelprefix""] = levelname + "":"" + seperator <TAB> return super().formatMessage(recordcopy)",true,"if ""color_message"" in recordcopy . __dict__ :","if ""color_message"" in recordcopy . __dict__ :",0.75,0.0
"def dumpregs(self): <TAB> for reg in ( <TAB> <TAB> list(self.regs.retaddr) <TAB> <TAB> + list(self.regs.misc) <TAB> <TAB> + list(self.regs.common) <TAB> <TAB> + list(self.regs.flags) <TAB> ): <TAB> <TAB> enum = self.get_reg_enum(reg) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> debug(""# Could not dump register %r"" % reg) <TAB> <TAB> <TAB> continue <TAB> <TAB> name = ""U.x86_const.UC_X86_REG_%s"" % reg.upper() <TAB> <TAB> value = self.uc.reg_read(enum) <TAB> <TAB> debug(""uc.reg_read(%(name)s) ==> %(value)x"" % locals())",false,if not reg or enum is None :,if enum is None :,0.19,0.0
"def filter(self, lexer, stream): <TAB> current_type = None <TAB> current_value = None <TAB> for ttype, value in stream: <TAB> <TAB> if ttype is current_type: <TAB> <TAB> <TAB> current_value += value <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> yield current_type, current_value <TAB> <TAB> <TAB> current_type = ttype <TAB> <TAB> <TAB> current_value = value <TAB> if current_type is not None: <TAB> <TAB> yield current_type, current_value",true,if current_type is not None :,if current_type is not None :,0.75,0.0
"def _get_between(content, start, end=None): <TAB> should_yield = False <TAB> for line in content.split(""\n""): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> should_yield = True <TAB> <TAB> <TAB> continue <TAB> <TAB> if end and end in line: <TAB> <TAB> <TAB> return <TAB> <TAB> if should_yield and line: <TAB> <TAB> <TAB> yield line.strip().split("" "")[0]",false,if start in line :,if start and start in line :,0.43,0.0
"def parse_git_config(path): <TAB> """"""Parse git config file."""""" <TAB> config = dict() <TAB> section = None <TAB> with open(os.path.join(path, ""config""), ""r"") as f: <TAB> <TAB> for line in f: <TAB> <TAB> <TAB> line = line.strip() <TAB> <TAB> <TAB> if line.startswith(""[""): <TAB> <TAB> <TAB> <TAB> section = line[1:-1].strip() <TAB> <TAB> <TAB> <TAB> config[section] = dict() <TAB> <TAB> <TAB> elif section: <TAB> <TAB> <TAB> <TAB> key, value = line.replace("" "", """").split(""="") <TAB> <TAB> <TAB> <TAB> config[section][key] = value <TAB> return config",true,elif section :,elif section :,0.51,0.0
"def test_has_arg(fn, name, accept_all, expected): <TAB> if isinstance(fn, str): <TAB> <TAB> context = dict() <TAB> <TAB> try: <TAB> <TAB> <TAB> exec(""def {}: pass"".format(fn), context) <TAB> <TAB> except SyntaxError: <TAB> <TAB> <TAB> if sys.version_info >= (3,): <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> pytest.skip(""Function is not compatible with Python 2"") <TAB> <TAB> # Sometimes exec adds builtins to the context <TAB> <TAB> context.pop(""__builtins__"", None) <TAB> <TAB> (fn,) = context.values() <TAB> assert has_arg(fn, name, accept_all) is expected",true,"if sys . version_info >= ( 3 , ) :","if sys . version_info >= ( 3 , ) :",0.75,0.0
"def ObjectExpression(self, properties, **kwargs): <TAB> data = [] <TAB> for prop in properties: <TAB> <TAB> self.emit(prop[""value""]) <TAB> <TAB> if prop[""computed""]: <TAB> <TAB> <TAB> raise NotImplementedError( <TAB> <TAB> <TAB> <TAB> ""ECMA 5.1 does not support computed object properties!"" <TAB> <TAB> <TAB> ) <TAB> <TAB> data.append((to_key(prop[""key""]), prop[""kind""][0])) <TAB> self.emit(""LOAD_OBJECT"", tuple(data))",true,"if prop [ ""computed"" ] :","if prop [ ""computed"" ] :",0.75,0.0
"def run(self): <TAB> for domain, locale, po in self.locales: <TAB> <TAB> if self.inplace: <TAB> <TAB> <TAB> path = os.path.join(""locale"", locale, ""LC_MESSAGES"") <TAB> <TAB> else: <TAB> <TAB> <TAB> path = os.path.join(self.build_dir, locale, ""LC_MESSAGES"") <TAB> <TAB> mo = os.path.join(path, ""%s.mo"" % domain) <TAB> <TAB> self.mkpath(path) <TAB> <TAB> self.spawn([""msgfmt"", ""-o"", mo, po])",true,if self . inplace :,if self . inplace :,0.75,0.0
"def _compute_map(self, first_byte, second_byte=None): <TAB> if first_byte != 0x0F: <TAB> <TAB> return ""XED_ILD_MAP0"" <TAB> else: <TAB> <TAB> if second_byte == None: <TAB> <TAB> <TAB> return ""XED_ILD_MAP1"" <TAB> <TAB> if second_byte == 0x38: <TAB> <TAB> <TAB> return ""XED_ILD_MAP2"" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ""XED_ILD_MAP3"" <TAB> <TAB> if second_byte == 0x0F and self.amd_enabled: <TAB> <TAB> <TAB> return ""XED_ILD_MAPAMD"" <TAB> die(""Unhandled escape {} / map {} bytes"".format(first_byte, second_byte))",false,if second_byte == 0x3A :,if first_byte == 0x0F and self . dflt_enabled :,0.11,0.0
"def parse_tag(self): <TAB> buf = [] <TAB> escaped = False <TAB> for c in self.get_next_chars(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> buf.append(c) <TAB> <TAB> elif c == ""\\"": <TAB> <TAB> <TAB> escaped = True <TAB> <TAB> elif c == "">"": <TAB> <TAB> <TAB> return """".join(buf) <TAB> <TAB> else: <TAB> <TAB> <TAB> buf.append(c) <TAB> raise Exception(""Unclosed tag "" + """".join(buf))",true,if escaped :,if escaped :,0.53,0.0
"def print_pairs(attrs=None, offset_y=0): <TAB> fmt = "" ({0}:{1}) "" <TAB> fmt_len = len(fmt) <TAB> for bg, fg in get_fg_bg(): <TAB> <TAB> try: <TAB> <TAB> <TAB> color = curses.color_pair(pair_number(fg, bg)) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> for attr in attrs: <TAB> <TAB> <TAB> <TAB> <TAB> color |= attr <TAB> <TAB> <TAB> screen.addstr(offset_y + bg, fg * fmt_len, fmt.format(fg, bg), color) <TAB> <TAB> <TAB> pass <TAB> <TAB> except curses.error: <TAB> <TAB> <TAB> pass",false,if not attrs is None :,if attrs is not None :,0.32,0.0
"def _impl(inputs, input_types): <TAB> data = inputs[0] <TAB> axis = None <TAB> keepdims = False <TAB> if len(inputs) > 2:  # default, torch have only data, axis=None, keepdims=False <TAB> <TAB> if isinstance(inputs[1], int): <TAB> <TAB> <TAB> axis = int(inputs[1]) <TAB> <TAB> elif _is_int_seq(inputs[1]): <TAB> <TAB> <TAB> axis = inputs[1] <TAB> <TAB> else: <TAB> <TAB> <TAB> axis = list(_infer_shape(inputs[1])) <TAB> <TAB> keepdims = bool(inputs[2]) <TAB> return get_relay_op(name)(data, axis=axis, keepdims=keepdims)",true,"if isinstance ( inputs [ 1 ] , int ) :","if isinstance ( inputs [ 1 ] , int ) :",0.75,0.0
"def run(self, args, **kwargs): <TAB> # Filtering options <TAB> if args.trace_tag: <TAB> <TAB> kwargs[""trace_tag""] = args.trace_tag <TAB> if args.trigger_instance: <TAB> <TAB> kwargs[""trigger_instance""] = args.trigger_instance <TAB> if args.execution: <TAB> <TAB> kwargs[""execution""] = args.execution <TAB> if args.rule: <TAB> <TAB> kwargs[""rule""] = args.rule <TAB> if args.sort_order: <TAB> <TAB> if args.sort_order in [""asc"", ""ascending""]: <TAB> <TAB> <TAB> kwargs[""sort_asc""] = True <TAB> <TAB> elif args.sort_order in [""desc"", ""descending""]: <TAB> <TAB> <TAB> kwargs[""sort_desc""] = True <TAB> return self.manager.query_with_count(limit=args.last, **kwargs)",false,"if args . sort_order in [ ""asc"" , ""ascending"" ] :","elif args . sort_order in [ ""desc"" , ""descending"" ] :",0.2,0.0
def retaddr(): <TAB> sp = pwndbg.regs.sp <TAB> stack = pwndbg.vmmap.find(sp) <TAB> # Enumerate all return addresses <TAB> frame = gdb.newest_frame() <TAB> addresses = [] <TAB> while frame: <TAB> <TAB> addresses.append(frame.pc()) <TAB> <TAB> frame = frame.older() <TAB> # Find all of them on the stack <TAB> start = stack.vaddr <TAB> stop = start + stack.memsz <TAB> while addresses and start < sp < stop: <TAB> <TAB> value = pwndbg.memory.u(sp) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> index = addresses.index(value) <TAB> <TAB> <TAB> del addresses[:index] <TAB> <TAB> <TAB> print(pwndbg.chain.format(sp)) <TAB> <TAB> sp += pwndbg.arch.ptrsize,true,if value in addresses :,if value in addresses :,0.75,0.0
"def update_from_dictio(self, dictio_item): <TAB> for index, dictio_payload in enumerate(dictio_item, 1): <TAB> <TAB> fuzz_payload = None <TAB> <TAB> for fuzz_payload in self.payloads[index]: <TAB> <TAB> <TAB> fuzz_payload.content = dictio_payload.content <TAB> <TAB> <TAB> fuzz_payload.type = dictio_payload.type <TAB> <TAB> # payload generated not used in seed but in filters <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.add( <TAB> <TAB> <TAB> <TAB> {""full_marker"": None, ""word"": None, ""index"": index, ""field"": None}, <TAB> <TAB> <TAB> <TAB> dictio_item[index - 1], <TAB> <TAB> <TAB> )",true,if fuzz_payload is None :,if fuzz_payload is None :,0.75,0.0
"def check_expected(result, expected, contains=False): <TAB> if sys.version_info[0] >= 3: <TAB> <TAB> if isinstance(result, str): <TAB> <TAB> <TAB> result = result.encode(""ascii"") <TAB> <TAB> if isinstance(expected, str): <TAB> <TAB> <TAB> expected = expected.encode(""ascii"") <TAB> resultlines = result.splitlines() <TAB> expectedlines = expected.splitlines() <TAB> if len(resultlines) != len(expectedlines): <TAB> <TAB> return False <TAB> for rline, eline in zip(resultlines, expectedlines): <TAB> <TAB> if contains: <TAB> <TAB> <TAB> if eline not in rline: <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> else: <TAB> <TAB> <TAB> if not rline.endswith(eline): <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",true,"if isinstance ( result , str ) :","if isinstance ( result , str ) :",0.75,0.0
"def execute_sql(self, sql, params=None, commit=True): <TAB> try: <TAB> <TAB> cursor = super(RetryOperationalError, self).execute_sql(sql, params, commit) <TAB> except OperationalError: <TAB> <TAB> if not self.is_closed(): <TAB> <TAB> <TAB> self.close() <TAB> <TAB> with __exception_wrapper__: <TAB> <TAB> <TAB> cursor = self.cursor() <TAB> <TAB> <TAB> cursor.execute(sql, params or ()) <TAB> <TAB> <TAB> if commit and not self.in_transaction(): <TAB> <TAB> <TAB> <TAB> self.commit() <TAB> return cursor",true,if commit and not self . in_transaction ( ) :,if commit and not self . in_transaction ( ) :,0.75,0.0
"def get_operation_ast(document_ast, operation_name=None): <TAB> operation = None <TAB> for definition in document_ast.definitions: <TAB> <TAB> if isinstance(definition, ast.OperationDefinition): <TAB> <TAB> <TAB> if not operation_name: <TAB> <TAB> <TAB> <TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB> <TAB> <TAB> <TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB> <TAB> <TAB> <TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> <TAB> operation = definition <TAB> <TAB> <TAB> elif definition.name and definition.name.value == operation_name: <TAB> <TAB> <TAB> <TAB> return definition <TAB> return operation",false,if operation :,if definition . name and definition . name . value == operation_name :,0.04,0.0
"def removeTrailingWs(self, aList): <TAB> i = 0 <TAB> while i < len(aList): <TAB> <TAB> if self.is_ws(aList[i]): <TAB> <TAB> <TAB> j = i <TAB> <TAB> <TAB> i = self.skip_ws(aList, i) <TAB> <TAB> <TAB> assert j < i <TAB> <TAB> <TAB> if i >= len(aList) or aList[i] == ""\n"": <TAB> <TAB> <TAB> <TAB> # print ""removing trailing ws:"", `i-j` <TAB> <TAB> <TAB> <TAB> del aList[j:i] <TAB> <TAB> <TAB> <TAB> i = j <TAB> <TAB> else: <TAB> <TAB> <TAB> i += 1",false,"if i >= len ( aList ) or aList [ i ] == ""\n"" :",if self . is_ws ( aList [ i ] ) :,0.11,0.0
"def _process_filter(self, query, host_state): <TAB> """"""Recursively parse the query structure."""""" <TAB> if not query: <TAB> <TAB> return True <TAB> cmd = query[0] <TAB> method = self.commands[cmd] <TAB> cooked_args = [] <TAB> for arg in query[1:]: <TAB> <TAB> if isinstance(arg, list): <TAB> <TAB> <TAB> arg = self._process_filter(arg, host_state) <TAB> <TAB> elif isinstance(arg, basestring): <TAB> <TAB> <TAB> arg = self._parse_string(arg, host_state) <TAB> <TAB> if arg is not None: <TAB> <TAB> <TAB> cooked_args.append(arg) <TAB> result = method(self, cooked_args) <TAB> return result",false,"if isinstance ( arg , list ) :","elif isinstance ( arg , basestring ) :",0.2,0.0
"def handle_sent(self, elt): <TAB> sent = [] <TAB> for child in elt: <TAB> <TAB> if child.tag in (""mw"", ""hi"", ""corr"", ""trunc""): <TAB> <TAB> <TAB> sent += [self.handle_word(w) for w in child] <TAB> <TAB> elif child.tag in (""w"", ""c""): <TAB> <TAB> <TAB> sent.append(self.handle_word(child)) <TAB> <TAB> elif child.tag not in self.tags_to_ignore: <TAB> <TAB> <TAB> raise ValueError(""Unexpected element %s"" % child.tag) <TAB> return BNCSentence(elt.attrib[""n""], sent)",false,elif child . tag not in self . tags_to_ignore :,"elif child . tag in ( ""w"" , ""c"" ) :",0.14,0.0
"def get_display_price( <TAB> base: Union[TaxedMoney, TaxedMoneyRange], display_gross: bool = False ) -> Money: <TAB> """"""Return the price amount that should be displayed based on settings."""""" <TAB> if not display_gross: <TAB> <TAB> display_gross = display_gross_prices() <TAB> if isinstance(base, TaxedMoneyRange): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> base = MoneyRange(start=base.start.gross, stop=base.stop.gross) <TAB> <TAB> else: <TAB> <TAB> <TAB> base = MoneyRange(start=base.start.net, stop=base.stop.net) <TAB> if isinstance(base, TaxedMoney): <TAB> <TAB> base = base.gross if display_gross else base.net <TAB> return base",false,if display_gross :,if base . start . gross and base . stop . gross :,0.04,0.0
"def check_classes(self, node): <TAB> if isinstance(node, nodes.Element): <TAB> <TAB> for class_value in node[""classes""][:]: <TAB> <TAB> <TAB> if class_value in self.strip_classes: <TAB> <TAB> <TAB> <TAB> node[""classes""].remove(class_value) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return 1",false,if class_value in self . strip_elements :,if class_value in self . strip_classes :,0.57,0.0
"def validate(outfile=sys.stdout, silent_success=False): <TAB> ""Validates all installed models."" <TAB> try: <TAB> <TAB> num_errors = get_validation_errors(outfile) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> outfile.write( <TAB> <TAB> <TAB> ""%s error%s found.\n"" % (num_errors, num_errors != 1 and ""s"" or """") <TAB> <TAB> ) <TAB> except ImproperlyConfigured: <TAB> <TAB> outfile.write(""Skipping validation because things aren't configured properly."")",false,if silent_success and num_errors == 0 :,if silent_success :,0.04,0.0
"def check_basename_conflicts(self, targets): <TAB> """"""Apps' basenames are used as bundle directory names. Ensure they are all unique."""""" <TAB> basename_seen = {} <TAB> for target in targets: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise self.BasenameConflictError( <TAB> <TAB> <TAB> <TAB> ""Basename must be unique, found two targets use "" <TAB> <TAB> <TAB> <TAB> ""the same basename: {}'\n\t{} and \n\t{}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> target.basename, <TAB> <TAB> <TAB> <TAB> <TAB> basename_seen[target.basename].address.spec, <TAB> <TAB> <TAB> <TAB> <TAB> target.address.spec, <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> basename_seen[target.basename] = target",true,if target . basename in basename_seen :,if target . basename in basename_seen :,0.75,0.0
"def __init__(self, api_version_str): <TAB> try: <TAB> <TAB> self.latest = self.preview = False <TAB> <TAB> self.yyyy = self.mm = self.dd = None <TAB> <TAB> if api_version_str == ""latest"": <TAB> <TAB> <TAB> self.latest = True <TAB> <TAB> else: <TAB> <TAB> <TAB> if ""preview"" in api_version_str: <TAB> <TAB> <TAB> <TAB> self.preview = True <TAB> <TAB> <TAB> parts = api_version_str.split(""-"") <TAB> <TAB> <TAB> self.yyyy = int(parts[0]) <TAB> <TAB> <TAB> self.mm = int(parts[1]) <TAB> <TAB> <TAB> self.dd = int(parts[2]) <TAB> except (ValueError, TypeError): <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> ""The API version {} is not in a "" ""supported format"".format(api_version_str) <TAB> <TAB> )",true,"if api_version_str == ""latest"" :","if api_version_str == ""latest"" :",0.75,0.0
"def _osp2ec(self, bytes): <TAB> compressed = self._from_bytes(bytes) <TAB> y = compressed >> self._bits <TAB> x = compressed & (1 << self._bits) - 1 <TAB> if x == 0: <TAB> <TAB> y = self._curve.b <TAB> else: <TAB> <TAB> result = self.sqrtp( <TAB> <TAB> <TAB> x ** 3 + self._curve.a * x + self._curve.b, self._curve.field.p <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> y = result[0] <TAB> <TAB> elif len(result) == 2: <TAB> <TAB> <TAB> y1, y2 = result <TAB> <TAB> <TAB> y = y1 if (y1 & 1 == y) else y2 <TAB> <TAB> else: <TAB> <TAB> <TAB> return None <TAB> return ec.Point(self._curve, x, y)",true,if len ( result ) == 1 :,if len ( result ) == 1 :,0.75,0.0
"def _visit_import_alike(self, node: Union[cst.Import, cst.ImportFrom]) -> bool: <TAB> names = node.names <TAB> if isinstance(names, cst.ImportStar): <TAB> <TAB> return False <TAB> # make sure node.names is Sequence[ImportAlias] <TAB> for name in names: <TAB> <TAB> self.provider.set_metadata(name, self.scope) <TAB> <TAB> asname = name.asname <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> name_values = _gen_dotted_names(cst.ensure_type(asname.name, cst.Name)) <TAB> <TAB> else: <TAB> <TAB> <TAB> name_values = _gen_dotted_names(name.name) <TAB> <TAB> for name_value, _ in name_values: <TAB> <TAB> <TAB> self.scope.record_assignment(name_value, node) <TAB> return False",false,if asname is not None :,if asname :,0.05,0.0
"def test_sanity_no_unmatched_parentheses(CorpusType: Type[ColumnCorpus]): <TAB> corpus = CorpusType() <TAB> unbalanced_entities = [] <TAB> for sentence in corpus.get_all_sentences(): <TAB> <TAB> entities = sentence.get_spans(""ner"") <TAB> <TAB> for entity in entities: <TAB> <TAB> <TAB> entity_text = """".join(t.text for t in entity.tokens) <TAB> <TAB> <TAB> if not has_balanced_parantheses(entity_text): <TAB> <TAB> <TAB> <TAB> unbalanced_entities.append(entity_text) <TAB> assert unbalanced_entities == []",true,if not has_balanced_parantheses ( entity_text ) :,if not has_balanced_parantheses ( entity_text ) :,0.75,0.0
"def _learn_rate_adjust(self): <TAB> if self.learn_rate_decays == 1.0: <TAB> <TAB> return <TAB> learn_rate_decays = self._vp(self.learn_rate_decays) <TAB> learn_rate_minimums = self._vp(self.learn_rate_minimums) <TAB> for index, decay in enumerate(learn_rate_decays): <TAB> <TAB> new_learn_rate = self.net_.learnRates[index] * decay <TAB> <TAB> if new_learn_rate >= learn_rate_minimums[index]: <TAB> <TAB> <TAB> self.net_.learnRates[index] = new_learn_rate <TAB> if self.verbose >= 2: <TAB> <TAB> print(""Learn rates: {}"".format(self.net_.learnRates))",true,if new_learn_rate >= learn_rate_minimums [ index ] :,if new_learn_rate >= learn_rate_minimums [ index ] :,0.75,0.0
"def set_attr_from_xmp_tag(self, attr, xmp_tags, tags, cast=None): <TAB> v = self.get_xmp_tag(xmp_tags, tags) <TAB> if v is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> setattr(self, attr, v) <TAB> <TAB> else: <TAB> <TAB> <TAB> # Handle fractions <TAB> <TAB> <TAB> if (cast == float or cast == int) and ""/"" in v: <TAB> <TAB> <TAB> <TAB> v = self.try_parse_fraction(v) <TAB> <TAB> <TAB> setattr(self, attr, cast(v))",true,if cast is None :,if cast is None :,0.75,0.0
"def _merge_scientific_float_tokens(tokens: Iterable[str]) -> List[str]: <TAB> tokens = list(tokens) <TAB> i = 0 <TAB> while ""e"" in tokens[i + 1 :]: <TAB> <TAB> i = tokens.index(""e"", i + 1) <TAB> <TAB> s = i - 1 <TAB> <TAB> e = i + 1 <TAB> <TAB> if not re.match(""[0-9]"", str(tokens[s])): <TAB> <TAB> <TAB> continue <TAB> <TAB> if re.match(""[+-]"", str(tokens[e])): <TAB> <TAB> <TAB> e += 1 <TAB> <TAB> if re.match(""[0-9]"", str(tokens[e])): <TAB> <TAB> <TAB> e += 1 <TAB> <TAB> <TAB> tokens[s:e] = ["""".join(tokens[s:e])] <TAB> <TAB> <TAB> i -= 1 <TAB> return tokens",false,"if not re . match ( ""[0-9]"" , str ( tokens [ s ] ) ) :","if re . match ( ""[+-]"" , str ( tokens [ e ] ) ) :",0.35,0.0
"def anypython(request): <TAB> name = request.param <TAB> executable = getexecutable(name) <TAB> if executable is None: <TAB> <TAB> if sys.platform == ""win32"": <TAB> <TAB> <TAB> executable = winpymap.get(name, None) <TAB> <TAB> <TAB> if executable: <TAB> <TAB> <TAB> <TAB> executable = py.path.local(executable) <TAB> <TAB> <TAB> <TAB> if executable.check(): <TAB> <TAB> <TAB> <TAB> <TAB> return executable <TAB> <TAB> pytest.skip(""no suitable %s found"" % (name,)) <TAB> return executable",false,"if sys . platform == ""win32"" :",if executable . check ( ) :,0.02,0.0
"def set_meta(self, dataset, overwrite=True, **kwd): <TAB> super().set_meta(dataset, overwrite=overwrite, **kwd) <TAB> try: <TAB> <TAB> if dataset and tarfile.is_tarfile(dataset.file_name): <TAB> <TAB> <TAB> with tarfile.open(dataset.file_name, ""r"") as temptar: <TAB> <TAB> <TAB> <TAB> dataset.metadata.fast5_count = sum( <TAB> <TAB> <TAB> <TAB> <TAB> 1 for f in temptar if f.name.endswith("".fast5"") <TAB> <TAB> <TAB> <TAB> ) <TAB> except Exception as e: <TAB> <TAB> log.warning(""%s, set_meta Exception: %s"", self, e)",true,if dataset and tarfile . is_tarfile ( dataset . file_name ) :,if dataset and tarfile . is_tarfile ( dataset . file_name ) :,0.75,0.0
"def run(self): <TAB> for k in list(iterkeys(self.objs)): <TAB> <TAB> if k.startswith(""_""): <TAB> <TAB> <TAB> continue <TAB> <TAB> v = self.objs[k] <TAB> <TAB> if v[""_class""] == ""User"": <TAB> <TAB> <TAB> self.split_user(k, v) <TAB> <TAB> elif v[""_class""] in [ <TAB> <TAB> <TAB> ""Message"", <TAB> <TAB> <TAB> ""PrintJob"", <TAB> <TAB> <TAB> ""Question"", <TAB> <TAB> <TAB> ""Submission"", <TAB> <TAB> <TAB> ""UserTest"", <TAB> <TAB> ]: <TAB> <TAB> <TAB> v[""participation""] = v[""user""] <TAB> <TAB> <TAB> del v[""user""] <TAB> return self.objs",true,"if k . startswith ( ""_"" ) :","if k . startswith ( ""_"" ) :",0.75,0.0
"def _findInTree(t, n): <TAB> ret = [] <TAB> if type(t) is dict: <TAB> <TAB> if ""_name"" in t and t[""_name""] == n: <TAB> <TAB> <TAB> ret.append(t) <TAB> <TAB> for k, v in t.items(): <TAB> <TAB> <TAB> ret += _findInTree(v, n) <TAB> if type(t) is list: <TAB> <TAB> for v in t: <TAB> <TAB> <TAB> ret += _findInTree(v, n) <TAB> return ret",true,"if ""_name"" in t and t [ ""_name"" ] == n :","if ""_name"" in t and t [ ""_name"" ] == n :",1.0,0.0
"def parseArrayPattern(self): <TAB> node = Node() <TAB> elements = [] <TAB> self.expect(""["") <TAB> while not self.match(""]""): <TAB> <TAB> if self.match("",""): <TAB> <TAB> <TAB> self.lex() <TAB> <TAB> <TAB> elements.append(null) <TAB> <TAB> else: <TAB> <TAB> <TAB> if self.match(""...""): <TAB> <TAB> <TAB> <TAB> restNode = Node() <TAB> <TAB> <TAB> <TAB> self.lex() <TAB> <TAB> <TAB> <TAB> rest = self.parseVariableIdentifier() <TAB> <TAB> <TAB> <TAB> elements.append(restNode.finishRestElement(rest)) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> elements.append(self.parsePatternWithDefault()) <TAB> <TAB> <TAB> if not self.match(""]""): <TAB> <TAB> <TAB> <TAB> self.expect("","") <TAB> self.expect(""]"") <TAB> return node.finishArrayPattern(elements)",true,"if self . match ( "","" ) :","if self . match ( "","" ) :",0.75,0.0
"def _set_log_writer(self): <TAB> if self.config[""logging""]: <TAB> <TAB> config = self.config[""log_writer_config""] <TAB> <TAB> if config[""writer""] == ""json"": <TAB> <TAB> <TAB> self.log_writer = LogWriter(**config) <TAB> <TAB> elif config[""writer""] == ""tensorboard"": <TAB> <TAB> <TAB> self.log_writer = TensorBoardWriter(**config) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(f""Unrecognized writer option: {config['writer']}"") <TAB> else: <TAB> <TAB> self.log_writer = None",true,"if config [ ""writer"" ] == ""json"" :","if config [ ""writer"" ] == ""json"" :",0.75,0.0
"def _parse(self, contents): <TAB> entries = [] <TAB> hostnames_found = set() <TAB> for line in contents.splitlines(): <TAB> <TAB> if not len(line.strip()): <TAB> <TAB> <TAB> entries.append((""blank"", [line])) <TAB> <TAB> <TAB> continue <TAB> <TAB> (head, tail) = chop_comment(line.strip(), ""#"") <TAB> <TAB> if not len(head): <TAB> <TAB> <TAB> entries.append((""all_comment"", [line])) <TAB> <TAB> <TAB> continue <TAB> <TAB> entries.append((""hostname"", [head, tail])) <TAB> <TAB> hostnames_found.add(head) <TAB> if len(hostnames_found) > 1: <TAB> <TAB> raise IOError(""Multiple hostnames (%s) found!"" % (hostnames_found)) <TAB> return entries",true,if not len ( line . strip ( ) ) :,if not len ( line . strip ( ) ) :,0.75,0.0
"def get_all_values(self, project): <TAB> if isinstance(project, models.Model): <TAB> <TAB> project_id = project.id <TAB> else: <TAB> <TAB> project_id = project <TAB> if project_id not in self.__cache: <TAB> <TAB> cache_key = self._make_key(project_id) <TAB> <TAB> result = cache.get(cache_key) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result = self.reload_cache(project_id) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.__cache[project_id] = result <TAB> return self.__cache.get(project_id, {})",true,if result is None :,if result is None :,0.75,0.0
"def needed_libraries(self): <TAB> for cmd in self.load_commands_of_type(0xC):  # LC_LOAD_DYLIB <TAB> <TAB> tname = self._get_typename(""dylib_command"") <TAB> <TAB> dylib_command = cmd.cast(tname) <TAB> <TAB> name_addr = cmd.obj_offset + dylib_command.name <TAB> <TAB> dylib_name = self.obj_vm.read(name_addr, 256) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> idx = dylib_name.find(""\x00"") <TAB> <TAB> <TAB> if idx != -1: <TAB> <TAB> <TAB> <TAB> dylib_name = dylib_name[:idx] <TAB> <TAB> <TAB> yield dylib_name",true,if dylib_name :,if dylib_name :,0.53,0.0
"def compress(self, data_list): <TAB> warn_untested() <TAB> if data_list: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> error = self.error_messages[""invalid_year""] <TAB> <TAB> <TAB> raise forms.ValidationError(error) <TAB> <TAB> if data_list[0] in forms.fields.EMPTY_VALUES: <TAB> <TAB> <TAB> error = self.error_messages[""invalid_month""] <TAB> <TAB> <TAB> raise forms.ValidationError(error) <TAB> <TAB> year = int(data_list[1]) <TAB> <TAB> month = int(data_list[0]) <TAB> <TAB> # find last day of the month <TAB> <TAB> day = monthrange(year, month)[1] <TAB> <TAB> return date(year, month, day) <TAB> return None",true,if data_list [ 1 ] in forms . fields . EMPTY_VALUES :,if data_list [ 1 ] in forms . fields . EMPTY_VALUES :,0.75,0.0
"def put(self, obj, block=True, timeout=None): <TAB> assert not self._closed <TAB> if not self._sem.acquire(block, timeout): <TAB> <TAB> raise Full <TAB> with self._notempty: <TAB> <TAB> with self._cond: <TAB> <TAB> <TAB> if self._thread is None: <TAB> <TAB> <TAB> <TAB> self._start_thread() <TAB> <TAB> <TAB> self._buffer.append(obj) <TAB> <TAB> <TAB> self._unfinished_tasks.release() <TAB> <TAB> <TAB> self._notempty.notify()",true,if self . _thread is None :,if self . _thread is None :,0.75,0.0
"def has_module(self, module, version): <TAB> has_module = False <TAB> for directory in self.directories: <TAB> <TAB> module_directory = join(directory, module) <TAB> <TAB> has_module_directory = isdir(module_directory) <TAB> <TAB> if not version: <TAB> <TAB> <TAB> has_module = has_module_directory or exists( <TAB> <TAB> <TAB> <TAB> module_directory <TAB> <TAB> <TAB> )  # could be a bare modulefile <TAB> <TAB> else: <TAB> <TAB> <TAB> modulefile = join(module_directory, version) <TAB> <TAB> <TAB> has_modulefile = exists(modulefile) <TAB> <TAB> <TAB> has_module = has_module_directory and has_modulefile <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> return has_module",true,if has_module :,if has_module :,0.53,0.0
"def expanduser(path): <TAB> if path[:1] == ""~"": <TAB> <TAB> c = path[1:2] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return gethome() <TAB> <TAB> if c == os.sep: <TAB> <TAB> <TAB> return asPyString(File(gethome(), path[2:]).getPath()) <TAB> return path",false,if not c :,if c == os . sep :,0.04,0.0
"def mock_touch(self, bearer, version=None, revision=None, **kwargs): <TAB> if version: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> return self.versions[int(version) - 1] <TAB> <TAB> <TAB> except (IndexError, ValueError): <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> else: <TAB> <TAB> <TAB> return None <TAB> return file_models.FileVersion()",false,if self . versions :,if revision :,0.04,0.0
"def _get_field_value(self, test, key, match): <TAB> if test.ver == ofproto_v1_0.OFP_VERSION: <TAB> <TAB> members = inspect.getmembers(match) <TAB> <TAB> for member in members: <TAB> <TAB> <TAB> if member[0] == key: <TAB> <TAB> <TAB> <TAB> field_value = member[1] <TAB> <TAB> <TAB> elif member[0] == ""wildcards"": <TAB> <TAB> <TAB> <TAB> wildcards = member[1] <TAB> <TAB> if key == ""nw_src"": <TAB> <TAB> <TAB> field_value = test.nw_src_to_str(wildcards, field_value) <TAB> <TAB> elif key == ""nw_dst"": <TAB> <TAB> <TAB> field_value = test.nw_dst_to_str(wildcards, field_value) <TAB> else: <TAB> <TAB> field_value = match[key] <TAB> return field_value",true,"elif member [ 0 ] == ""wildcards"" :","elif member [ 0 ] == ""wildcards"" :",1.0,0.0
"def check_expected(result, expected, contains=False): <TAB> if sys.version_info[0] >= 3: <TAB> <TAB> if isinstance(result, str): <TAB> <TAB> <TAB> result = result.encode(""ascii"") <TAB> <TAB> if isinstance(expected, str): <TAB> <TAB> <TAB> expected = expected.encode(""ascii"") <TAB> resultlines = result.splitlines() <TAB> expectedlines = expected.splitlines() <TAB> if len(resultlines) != len(expectedlines): <TAB> <TAB> return False <TAB> for rline, eline in zip(resultlines, expectedlines): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if eline not in rline: <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> else: <TAB> <TAB> <TAB> if not rline.endswith(eline): <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",true,if contains :,if contains :,0.53,0.0
"def OnKeyUp(self, event): <TAB> if self._properties.modifiable: <TAB> <TAB> if event.GetKeyCode() == wx.WXK_ESCAPE: <TAB> <TAB> <TAB> self._cancel_editing() <TAB> <TAB> elif event.GetKeyCode() == wx.WXK_RETURN: <TAB> <TAB> <TAB> self._update_value() <TAB> <TAB> elif event.GetKeyCode() == wx.WXK_DELETE: <TAB> <TAB> <TAB> self.SetValue("""") <TAB> if event.GetKeyCode() != wx.WXK_RETURN: <TAB> <TAB> # Don't send skip event if enter key is pressed <TAB> <TAB> # On some platforms this event is sent too late and causes crash <TAB> <TAB> event.Skip()",true,elif event . GetKeyCode ( ) == wx . WXK_RETURN :,elif event . GetKeyCode ( ) == wx . WXK_RETURN :,0.75,0.0
"def load_modules( <TAB> to_load, load, attr, modules_dict, excluded_aliases, loading_message=None ): <TAB> if loading_message: <TAB> <TAB> print(loading_message) <TAB> for name in to_load: <TAB> <TAB> module = load(name) <TAB> <TAB> if module is None or not hasattr(module, attr): <TAB> <TAB> <TAB> continue <TAB> <TAB> cls = getattr(module, attr) <TAB> <TAB> if hasattr(cls, ""initialize"") and not cls.initialize(): <TAB> <TAB> <TAB> continue <TAB> <TAB> if hasattr(module, ""aliases""): <TAB> <TAB> <TAB> for alias in module.aliases(): <TAB> <TAB> <TAB> <TAB> if alias not in excluded_aliases: <TAB> <TAB> <TAB> <TAB> <TAB> modules_dict[alias] = module <TAB> <TAB> else: <TAB> <TAB> <TAB> modules_dict[name] = module <TAB> if loading_message: <TAB> <TAB> print()",false,"if module is None or not hasattr ( module , attr ) :","if hasattr ( module , ""aliases"" ) :",0.12,0.0
def eventIterator(): <TAB> while True: <TAB> <TAB> yield eventmodule.wait() <TAB> <TAB> while True: <TAB> <TAB> <TAB> event = eventmodule.poll() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> yield event,false,if event . type == NOEVENT :,if event is None :,0.04,0.0
"def _get_state_without_padding(self, state_with_padding, padding): <TAB> lean_state = {} <TAB> for key, value in state_with_padding.items(): <TAB> <TAB> if torch.is_tensor(value): <TAB> <TAB> <TAB> lean_length = value.numel() - padding <TAB> <TAB> <TAB> lean_state[key] = value[:lean_length] <TAB> <TAB> else: <TAB> <TAB> <TAB> lean_state[key] = value <TAB> return lean_state",true,if torch . is_tensor ( value ) :,if torch . is_tensor ( value ) :,0.75,0.0
"def _get_validate(data): <TAB> """"""Retrieve items to validate, from single samples or from combined joint calls."""""" <TAB> if data.get(""vrn_file"") and tz.get_in([""config"", ""algorithm"", ""validate""], data): <TAB> <TAB> return utils.deepish_copy(data) <TAB> elif ""group_orig"" in data: <TAB> <TAB> for sub in multi.get_orig_items(data): <TAB> <TAB> <TAB> if ""validate"" in sub[""config""][""algorithm""]: <TAB> <TAB> <TAB> <TAB> sub_val = utils.deepish_copy(sub) <TAB> <TAB> <TAB> <TAB> sub_val[""vrn_file""] = data[""vrn_file""] <TAB> <TAB> <TAB> <TAB> return sub_val <TAB> return None",true,"if ""validate"" in sub [ ""config"" ] [ ""algorithm"" ] :","if ""validate"" in sub [ ""config"" ] [ ""algorithm"" ] :",0.75,0.0
"def OnPopup(self, form, popup_handle): <TAB> for num, action_name, menu_name, shortcut in self.actions: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ida_kernwin.attach_action_to_popup(form, popup_handle, None) <TAB> <TAB> else: <TAB> <TAB> <TAB> handler = command_handler_t(self, num, 2) <TAB> <TAB> <TAB> desc = ida_kernwin.action_desc_t(action_name, menu_name, handler, shortcut) <TAB> <TAB> <TAB> ida_kernwin.attach_dynamic_action_to_popup(form, popup_handle, desc)",false,if menu_name is None :,if num == 0 :,0.03,0.0
"def show(self, indent=0): <TAB> """"""Pretty print this structure."""""" <TAB> if indent == 0: <TAB> <TAB> print(""struct {}"".format(self.name)) <TAB> for field in self.fields: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> offset = ""0x??"" <TAB> <TAB> else: <TAB> <TAB> <TAB> offset = ""0x{:02x}"".format(field.offset) <TAB> <TAB> print(""{}+{} {} {}"".format("" "" * indent, offset, field.name, field.type)) <TAB> <TAB> if isinstance(field.type, Structure): <TAB> <TAB> <TAB> field.type.show(indent + 1)",true,if field . offset is None :,if field . offset is None :,0.75,0.0
"def get_operation_ast(document_ast, operation_name=None): <TAB> operation = None <TAB> for definition in document_ast.definitions: <TAB> <TAB> if isinstance(definition, ast.OperationDefinition): <TAB> <TAB> <TAB> if not operation_name: <TAB> <TAB> <TAB> <TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB> <TAB> <TAB> <TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB> <TAB> <TAB> <TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB> <TAB> <TAB> <TAB> if operation: <TAB> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> <TAB> operation = definition <TAB> <TAB> <TAB> elif definition.name and definition.name.value == operation_name: <TAB> <TAB> <TAB> <TAB> return definition <TAB> return operation",false,"if isinstance ( definition , ast . OperationDefinition ) :",elif definition . name and definition . name . value == operation_name :,0.01,0.0
"def getSubMenu(self, callingWindow, context, mainItem, selection, rootMenu, i, pitem): <TAB> msw = True if ""wxMSW"" in wx.PlatformInfo else False <TAB> self.context = context <TAB> self.abilityIds = {} <TAB> sub = wx.Menu() <TAB> for ability in self.fighter.abilities: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> menuItem = self.addAbility(rootMenu if msw else sub, ability) <TAB> <TAB> sub.Append(menuItem) <TAB> <TAB> menuItem.Check(ability.active) <TAB> return sub",false,if not ability . effect . isImplemented :,if ability . active :,0.04,0.0
"def consume(self, event: Dict[str, Any]) -> None: <TAB> with self.lock: <TAB> <TAB> logging.debug(""Received missedmessage_emails event: %s"", event) <TAB> <TAB> # When we process an event, just put it into the queue and ensure we have a timer going. <TAB> <TAB> user_profile_id = event[""user_profile_id""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.batch_start_by_recipient[user_profile_id] = time.time() <TAB> <TAB> self.events_by_recipient[user_profile_id].append(event) <TAB> <TAB> self.ensure_timer()",true,if user_profile_id not in self . batch_start_by_recipient :,if user_profile_id not in self . batch_start_by_recipient :,0.75,0.0
"def __init__(self, start_enabled=False, use_hardware=True): <TAB> self._use_hardware = use_hardware <TAB> if use_hardware: <TAB> <TAB> self._button = Button(BUTTON_GPIO_PIN) <TAB> <TAB> self._enabled = start_enabled <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._button.when_pressed = self._enable",false,if not start_enabled :,if start_enabled :,0.1,0.0
"def execute(cls, ctx, op: ""DataFrameGroupByAgg""): <TAB> try: <TAB> <TAB> pd.set_option(""mode.use_inf_as_na"", op.use_inf_as_na) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> cls._execute_map(ctx, op) <TAB> <TAB> elif op.stage == OperandStage.combine: <TAB> <TAB> <TAB> cls._execute_combine(ctx, op) <TAB> <TAB> elif op.stage == OperandStage.agg: <TAB> <TAB> <TAB> cls._execute_agg(ctx, op) <TAB> <TAB> else:  # pragma: no cover <TAB> <TAB> <TAB> raise ValueError(""Aggregation operand not executable"") <TAB> finally: <TAB> <TAB> pd.reset_option(""mode.use_inf_as_na"")",true,if op . stage == OperandStage . map :,if op . stage == OperandStage . map :,0.75,0.0
"def load_package(name, path): <TAB> if os.path.isdir(path): <TAB> <TAB> extensions = machinery.SOURCE_SUFFIXES[:] + machinery.BYTECODE_SUFFIXES[:] <TAB> <TAB> for extension in extensions: <TAB> <TAB> <TAB> init_path = os.path.join(path, ""__init__"" + extension) <TAB> <TAB> <TAB> if os.path.exists(init_path): <TAB> <TAB> <TAB> <TAB> path = init_path <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""{!r} is not a package"".format(path)) <TAB> spec = util.spec_from_file_location(name, path, submodule_search_locations=[]) <TAB> if name in sys.modules: <TAB> <TAB> return _exec(spec, sys.modules[name]) <TAB> else: <TAB> <TAB> return _load(spec)",true,if os . path . exists ( init_path ) :,if os . path . exists ( init_path ) :,0.75,0.0
"def setup(level=None): <TAB> from pipeline.logging import pipeline_logger as logger <TAB> from pipeline.log.handlers import EngineLogHandler <TAB> if level in set(logging._levelToName.values()): <TAB> <TAB> logger.setLevel(level) <TAB> logging._acquireLock() <TAB> try: <TAB> <TAB> for hdl in logger.handlers: <TAB> <TAB> <TAB> if isinstance(hdl, EngineLogHandler): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> hdl = EngineLogHandler() <TAB> <TAB> <TAB> hdl.setLevel(logger.level) <TAB> <TAB> <TAB> logger.addHandler(hdl) <TAB> finally: <TAB> <TAB> logging._releaseLock()",true,"if isinstance ( hdl , EngineLogHandler ) :","if isinstance ( hdl , EngineLogHandler ) :",0.75,0.0
"def find_approximant(x): <TAB> c = 1e-4 <TAB> it = sympy.ntheory.continued_fraction_convergents( <TAB> <TAB> sympy.ntheory.continued_fraction_iterator(x) <TAB> ) <TAB> for i in it: <TAB> <TAB> p, q = i.as_numer_denom() <TAB> <TAB> tol = c / q ** 2 <TAB> <TAB> if abs(i - x) <= tol: <TAB> <TAB> <TAB> return i <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> return x",false,if tol < machine_epsilon :,if p < tol :,0.29,0.0
"def resolve( <TAB> self, debug: bool = False, silent: bool = False, level: Optional[int] = None ) -> bool: <TAB> if silent: <TAB> <TAB> spinner = nullcontext(type(""Mock"", (), {})) <TAB> else: <TAB> <TAB> spinner = yaspin(text=""resolving..."") <TAB> with spinner as spinner: <TAB> <TAB> while True: <TAB> <TAB> <TAB> resolved = self._resolve( <TAB> <TAB> <TAB> <TAB> debug=debug, silent=silent, level=level, spinner=spinner <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self.graph.clear()  # remove unused deps from graph <TAB> <TAB> <TAB> return resolved",false,if resolved is None :,if resolved is False :,0.39,0.0
"def canonicalize_instruction_name(instr): <TAB> name = instr.insn_name().upper() <TAB> # XXX bypass a capstone bug that incorrectly labels some insns as mov <TAB> if name == ""MOV"": <TAB> <TAB> if instr.mnemonic.startswith(""lsr""): <TAB> <TAB> <TAB> return ""LSR"" <TAB> <TAB> elif instr.mnemonic.startswith(""lsl""): <TAB> <TAB> <TAB> return ""LSL"" <TAB> <TAB> elif instr.mnemonic.startswith(""asr""): <TAB> <TAB> <TAB> return ""ASR"" <TAB> return OP_NAME_MAP.get(name, name)",false,"if instr . mnemonic . startswith ( ""lsr"" ) :","elif instr . mnemonic . startswith ( ""asr"" ) :",0.28,0.0
"def run_all(rule_list, defined_variables, defined_actions, stop_on_first_trigger=False): <TAB> rule_was_triggered = False <TAB> for rule in rule_list: <TAB> <TAB> result = run(rule, defined_variables, defined_actions) <TAB> <TAB> if result: <TAB> <TAB> <TAB> rule_was_triggered = True <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> return rule_was_triggered",true,if stop_on_first_trigger :,if stop_on_first_trigger :,0.53,0.0
"def get_filters(self, request): <TAB> filter_specs = [] <TAB> if self.lookup_opts.admin.list_filter and not self.opts.one_to_one_field: <TAB> <TAB> filter_fields = [ <TAB> <TAB> <TAB> self.lookup_opts.get_field(field_name) <TAB> <TAB> <TAB> for field_name in self.lookup_opts.admin.list_filter <TAB> <TAB> ] <TAB> <TAB> for f in filter_fields: <TAB> <TAB> <TAB> spec = FilterSpec.create(f, request, self.params, self.model) <TAB> <TAB> <TAB> if spec and spec.has_output(): <TAB> <TAB> <TAB> <TAB> filter_specs.append(spec) <TAB> return filter_specs, bool(filter_specs)",true,if spec and spec . has_output ( ) :,if spec and spec . has_output ( ) :,0.75,0.0
"def get_type(type_ref): <TAB> kind = type_ref.get(""kind"") <TAB> if kind == TypeKind.LIST: <TAB> <TAB> item_ref = type_ref.get(""ofType"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise Exception(""Decorated type deeper than introspection query."") <TAB> <TAB> return GraphQLList(get_type(item_ref)) <TAB> elif kind == TypeKind.NON_NULL: <TAB> <TAB> nullable_ref = type_ref.get(""ofType"") <TAB> <TAB> if not nullable_ref: <TAB> <TAB> <TAB> raise Exception(""Decorated type deeper than introspection query."") <TAB> <TAB> return GraphQLNonNull(get_type(nullable_ref)) <TAB> return get_named_type(type_ref[""name""])",true,if not item_ref :,if not item_ref :,0.75,0.0
"def _1_0_cloud_ips_cip_jsjc5_map(self, method, url, body, headers): <TAB> if method == ""POST"": <TAB> <TAB> body = json.loads(body) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return self.test_response(httplib.ACCEPTED, """") <TAB> <TAB> else: <TAB> <TAB> <TAB> data = '{""error_name"":""bad destination"", ""errors"": [""Bad destination""]}' <TAB> <TAB> <TAB> return self.test_response(httplib.BAD_REQUEST, data)",false,"if ""destination"" in body :","if ""error_name"" in body :",0.39,0.0
"def _get_prefixed_values(data, prefix): <TAB> """"""Collect lines which start with prefix; with trimming"""""" <TAB> matches = [] <TAB> for line in data.splitlines(): <TAB> <TAB> line = line.strip() <TAB> <TAB> if line.startswith(prefix): <TAB> <TAB> <TAB> match = line[len(prefix) :] <TAB> <TAB> <TAB> match = match.strip() <TAB> <TAB> <TAB> matches.append(match) <TAB> return matches",true,if line . startswith ( prefix ) :,if line . startswith ( prefix ) :,0.75,0.0
"def _power_exact(y, xc, yc, xe): <TAB> yc, ye = y.int, y.exp <TAB> while yc % 10 == 0: <TAB> <TAB> yc //= 10 <TAB> <TAB> ye += 1 <TAB> if xc == 1: <TAB> <TAB> xe *= yc <TAB> <TAB> while xe % 10 == 0: <TAB> <TAB> <TAB> xe //= 10 <TAB> <TAB> <TAB> ye += 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> exponent = xe * 10 ** ye <TAB> <TAB> if y and xe: <TAB> <TAB> <TAB> xc = exponent <TAB> <TAB> else: <TAB> <TAB> <TAB> xc = 0 <TAB> <TAB> return 5",false,if ye < 0 :,if ye == 0 :,0.33,0.0
"def init(self, view, items=None): <TAB> selections = [] <TAB> if view.sel(): <TAB> <TAB> for region in view.sel(): <TAB> <TAB> <TAB> selections.append(view.substr(region)) <TAB> values = [] <TAB> for idx, index in enumerate(map(int, items)): <TAB> <TAB> if idx >= len(selections): <TAB> <TAB> <TAB> break <TAB> <TAB> i = index - 1 <TAB> <TAB> if i >= 0 and i < len(selections): <TAB> <TAB> <TAB> values.append(selections[i]) <TAB> <TAB> else: <TAB> <TAB> <TAB> values.append(None) <TAB> # fill up <TAB> for idx, value in enumerate(selections): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> values.append(value) <TAB> self.stack = values",false,if len ( values ) + 1 < idx :,if idx == index :,0.01,0.0
"def toggleFactorReload(self, value=None): <TAB> self.serviceFittingOptions[""useGlobalForceReload""] = ( <TAB> <TAB> value <TAB> <TAB> if value is not None <TAB> <TAB> else not self.serviceFittingOptions[""useGlobalForceReload""] <TAB> ) <TAB> fitIDs = set() <TAB> for fit in set(self._loadedFits): <TAB> <TAB> if fit is None: <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> fit.factorReload = self.serviceFittingOptions[""useGlobalForceReload""] <TAB> <TAB> <TAB> fit.clearFactorReloadDependentData() <TAB> <TAB> <TAB> fitIDs.add(fit.ID) <TAB> return fitIDs",false,if fit . calculated :,if fit . factorReload is None :,0.2,0.0
"def init_weights(self): <TAB> """"""Initialize model weights."""""" <TAB> for m in self.predict_layers.modules(): <TAB> <TAB> if isinstance(m, nn.Conv2d): <TAB> <TAB> <TAB> kaiming_init(m) <TAB> <TAB> elif isinstance(m, nn.BatchNorm2d): <TAB> <TAB> <TAB> constant_init(m, 1) <TAB> <TAB> elif isinstance(m, nn.Linear): <TAB> <TAB> <TAB> normal_init(m, std=0.01)",true,"elif isinstance ( m , nn . BatchNorm2d ) :","elif isinstance ( m , nn . BatchNorm2d ) :",0.75,0.0
"def _unzip_file(self, filepath, ext): <TAB> try: <TAB> <TAB> if ext == "".zip"": <TAB> <TAB> <TAB> zf = zipfile.ZipFile(filepath) <TAB> <TAB> <TAB> zf.extractall(os.path.dirname(filepath)) <TAB> <TAB> <TAB> zf.close() <TAB> <TAB> elif ext == "".tar"": <TAB> <TAB> <TAB> tf = tarfile.open(filepath) <TAB> <TAB> <TAB> tf.extractall(os.path.dirname(filepath)) <TAB> <TAB> <TAB> tf.close() <TAB> except Exception as e: <TAB> <TAB> raise ValueError(""Error reading file %r!\n%s"" % (filepath, e))",false,"if ext == "".zip"" :","elif ext == "".tar"" :",0.06,0.0
"def add_multiple_tasks(data, parent): <TAB> data = json.loads(data) <TAB> new_doc = { <TAB> <TAB> ""doctype"": ""Task"", <TAB> <TAB> ""parent_task"": parent if parent != ""All Tasks"" else """", <TAB> } <TAB> new_doc[""project""] = frappe.db.get_value(""Task"", {""name"": parent}, ""project"") or """" <TAB> for d in data: <TAB> <TAB> if not d.get(""subject""): <TAB> <TAB> <TAB> continue <TAB> <TAB> new_doc[""subject""] = d.get(""subject"") <TAB> <TAB> new_task = frappe.get_doc(new_doc) <TAB> <TAB> new_task.insert()",true,"if not d . get ( ""subject"" ) :","if not d . get ( ""subject"" ) :",0.75,0.0
"def filterSimilarKeywords(keyword, kwdsIterator): <TAB> """"""Return a sorted list of keywords similar to the one given."""""" <TAB> seenDict = {} <TAB> kwdSndx = soundex(keyword.encode(""ascii"", ""ignore"")) <TAB> matches = [] <TAB> matchesappend = matches.append <TAB> checkContained = False <TAB> if len(keyword) > 4: <TAB> <TAB> checkContained = True <TAB> for movieID, key in kwdsIterator: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> seenDict[key] = None <TAB> <TAB> if checkContained and keyword in key: <TAB> <TAB> <TAB> matchesappend(key) <TAB> <TAB> <TAB> continue <TAB> <TAB> if kwdSndx == soundex(key.encode(""ascii"", ""ignore"")): <TAB> <TAB> <TAB> matchesappend(key) <TAB> return _sortKeywords(keyword, matches)",true,if key in seenDict :,if key in seenDict :,0.75,0.0
"def visit_If(self, node): <TAB> self.newline() <TAB> self.write(""if "") <TAB> self.visit(node.test) <TAB> self.write("":"") <TAB> self.body(node.body) <TAB> while True: <TAB> <TAB> else_ = node.orelse <TAB> <TAB> if len(else_) == 1 and isinstance(else_[0], If): <TAB> <TAB> <TAB> node = else_[0] <TAB> <TAB> <TAB> self.newline() <TAB> <TAB> <TAB> self.write(""elif "") <TAB> <TAB> <TAB> self.visit(node.test) <TAB> <TAB> <TAB> self.write("":"") <TAB> <TAB> <TAB> self.body(node.body) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.newline() <TAB> <TAB> <TAB> self.write(""else:"") <TAB> <TAB> <TAB> self.body(else_) <TAB> <TAB> <TAB> break",true,"if len ( else_ ) == 1 and isinstance ( else_ [ 0 ] , If ) :","if len ( else_ ) == 1 and isinstance ( else_ [ 0 ] , If ) :",1.0,0.0
"def _eyeLinkHardwareAndSoftwareVersion(self): <TAB> try: <TAB> <TAB> tracker_software_ver = 0 <TAB> <TAB> eyelink_ver = self._eyelink.getTrackerVersion() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tvstr = self._eyelink.getTrackerVersionString() <TAB> <TAB> <TAB> vindex = tvstr.find(""EYELINK CL"") <TAB> <TAB> <TAB> tracker_software_ver = int( <TAB> <TAB> <TAB> <TAB> float(tvstr[(vindex + len(""EYELINK CL"")) :].strip()) <TAB> <TAB> <TAB> ) <TAB> <TAB> return eyelink_ver, tracker_software_ver <TAB> except Exception: <TAB> <TAB> print2err(""EYELINK Error during _eyeLinkHardwareAndSoftwareVersion:"") <TAB> <TAB> printExceptionDetailsToStdErr() <TAB> <TAB> return EyeTrackerConstants.EYETRACKER_ERROR",false,if eyelink_ver == 3 :,if eyelink_ver is not None :,0.06,0.0
"def execute(self, context): <TAB> for monad in context.blend_data.node_groups: <TAB> <TAB> if monad.bl_idname == ""SverchGroupTreeType"": <TAB> <TAB> <TAB> if not getattr(bpy.types, monad.cls_bl_idname, None): <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> monad.update_cls() <TAB> <TAB> <TAB> <TAB> except Exception as err: <TAB> <TAB> <TAB> <TAB> <TAB> print(err) <TAB> <TAB> <TAB> <TAB> <TAB> print(""{} group class could not be created"".format(monad.name)) <TAB> return {""FINISHED""}",false,"if not getattr ( bpy . types , monad . cls_bl_idname , None ) :","if monad . bl_idname == ""SverchGroupTreeType"" :",0.02,0.0
"def word_pattern(pattern, str): <TAB> dict = {} <TAB> set_value = set() <TAB> list_str = str.split() <TAB> if len(list_str) != len(pattern): <TAB> <TAB> return False <TAB> for i in range(len(pattern)): <TAB> <TAB> if pattern[i] not in dict: <TAB> <TAB> <TAB> if list_str[i] in set_value: <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> dict[pattern[i]] = list_str[i] <TAB> <TAB> <TAB> set_value.add(list_str[i]) <TAB> <TAB> else: <TAB> <TAB> <TAB> if dict[pattern[i]] != list_str[i]: <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",true,if dict [ pattern [ i ] ] != list_str [ i ] :,if dict [ pattern [ i ] ] != list_str [ i ] :,1.0,0.0
"def decorator_handle(tokens): <TAB> """"""Process decorators."""""" <TAB> defs = [] <TAB> decorates = [] <TAB> for i, tok in enumerate(tokens): <TAB> <TAB> if ""simple"" in tok and len(tok) == 1: <TAB> <TAB> <TAB> decorates.append(""@"" + tok[0]) <TAB> <TAB> elif ""test"" in tok and len(tok) == 1: <TAB> <TAB> <TAB> varname = decorator_var + ""_"" + str(i) <TAB> <TAB> <TAB> defs.append(varname + "" = "" + tok[0]) <TAB> <TAB> <TAB> decorates.append(""@"" + varname) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise CoconutInternalException(""invalid decorator tokens"", tok) <TAB> return ""\n"".join(defs + decorates) + ""\n""",true,"elif ""test"" in tok and len ( tok ) == 1 :","elif ""test"" in tok and len ( tok ) == 1 :",1.0,0.0
"def wait_impl(self, cpid): <TAB> for i in range(10): <TAB> <TAB> # wait3() shouldn't hang, but some of the buildbots seem to hang <TAB> <TAB> # in the forking tests.  This is an attempt to fix the problem. <TAB> <TAB> spid, status, rusage = os.wait3(os.WNOHANG) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> time.sleep(1.0) <TAB> self.assertEqual(spid, cpid) <TAB> self.assertEqual(status, 0, ""cause = %d, exit = %d"" % (status & 0xFF, status >> 8)) <TAB> self.assertTrue(rusage)",false,if spid == cpid :,if rusage == 0 :,0.04,0.0
"def test_non_uniform_probabilities_over_elements(self): <TAB> param = iap.Choice([0, 1], p=[0.25, 0.75]) <TAB> samples = param.draw_samples((10000,)) <TAB> unique, counts = np.unique(samples, return_counts=True) <TAB> assert len(unique) == 2 <TAB> for val, count in zip(unique, counts): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> assert 2500 - 500 < count < 2500 + 500 <TAB> <TAB> elif val == 1: <TAB> <TAB> <TAB> assert 7500 - 500 < count < 7500 + 500 <TAB> <TAB> else: <TAB> <TAB> <TAB> assert False",true,if val == 0 :,if val == 0 :,0.75,0.0
"def dispatch_return(self, frame, arg): <TAB> if self.stop_here(frame) or frame == self.returnframe: <TAB> <TAB> # Ignore return events in generator except when stepping. <TAB> <TAB> if self.stopframe and frame.f_code.co_flags & CO_GENERATOR: <TAB> <TAB> <TAB> return self.trace_dispatch <TAB> <TAB> try: <TAB> <TAB> <TAB> self.frame_returning = frame <TAB> <TAB> <TAB> self.user_return(frame, arg) <TAB> <TAB> finally: <TAB> <TAB> <TAB> self.frame_returning = None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise BdbQuit <TAB> <TAB> # The user issued a 'next' or 'until' command. <TAB> <TAB> if self.stopframe is frame and self.stoplineno != -1: <TAB> <TAB> <TAB> self._set_stopinfo(None, None) <TAB> return self.trace_dispatch",true,if self . quitting :,if self . quitting :,0.75,0.0
"def mouse(self, button, mods, x, y): <TAB> if button == 1: <TAB> <TAB> for i in range(4): <TAB> <TAB> <TAB> if hypot(x - self.coords[i][0], y - self.coords[i][1]) < 4: <TAB> <TAB> <TAB> <TAB> self.hit = i <TAB> elif button == -1: <TAB> <TAB> self.hit = None <TAB> elif self.hit != None: <TAB> <TAB> self.coords[self.hit] = (x, y) <TAB> <TAB> self.view.dirty()",false,"if hypot ( x - self . coords [ i ] [ 0 ] , y - self . coords [ i ] [ 1 ] ) < 4 :",elif button == - 1 :,0.04,0.0
"def __init__(self, *commands): <TAB> self.all_cmds = list( <TAB> <TAB> map(lambda cmd: cmd[0] if isinstance(cmd, list) else cmd, commands) <TAB> ) <TAB> for command in commands: <TAB> <TAB> self.cmd = command if isinstance(command, list) else [command] <TAB> <TAB> self.cmd_path = pwndbg.which.which(self.cmd[0]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break",true,if self . cmd_path :,if self . cmd_path :,0.75,0.0
"def _recv_obj(self, suppress_error=False): <TAB> """"""Receive a (picklable) object"""""" <TAB> if self.conn.closed: <TAB> <TAB> raise OSError(""handle is closed"") <TAB> try: <TAB> <TAB> buf = self.conn.recv_bytes() <TAB> except (ConnectionError, EOFError) as e: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> logger.debug(""receive has failed"", exc_info=e) <TAB> <TAB> try: <TAB> <TAB> <TAB> self._set_remote_close_cause(e) <TAB> <TAB> <TAB> raise PipeShutdownError() <TAB> <TAB> finally: <TAB> <TAB> <TAB> self._close() <TAB> obj = RemoteObjectUnpickler.loads(buf, self) <TAB> logger.debug(""received %r"", obj) <TAB> return obj",true,if suppress_error :,if suppress_error :,0.53,0.0
"def act(self, obs): <TAB> with chainer.no_backprop_mode(): <TAB> <TAB> batch_obs = self.batch_states([obs], self.xp, self.phi) <TAB> <TAB> action_distrib = self.model(batch_obs) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return chainer.cuda.to_cpu(action_distrib.most_probable.array)[0] <TAB> <TAB> else: <TAB> <TAB> <TAB> return chainer.cuda.to_cpu(action_distrib.sample().array)[0]",false,if self . act_deterministically :,if self . use_cuda :,0.39,0.0
"def _classify(nodes_by_level): <TAB> missing, invalid, downloads = [], [], [] <TAB> for level in nodes_by_level: <TAB> <TAB> for node in level: <TAB> <TAB> <TAB> if node.binary == BINARY_MISSING: <TAB> <TAB> <TAB> <TAB> missing.append(node) <TAB> <TAB> <TAB> elif node.binary == BINARY_INVALID: <TAB> <TAB> <TAB> <TAB> invalid.append(node) <TAB> <TAB> <TAB> elif node.binary in (BINARY_UPDATE, BINARY_DOWNLOAD): <TAB> <TAB> <TAB> <TAB> downloads.append(node) <TAB> return missing, invalid, downloads",true,"elif node . binary in ( BINARY_UPDATE , BINARY_DOWNLOAD ) :","elif node . binary in ( BINARY_UPDATE , BINARY_DOWNLOAD ) :",0.75,0.0
"def persist(self, *_): <TAB> for key, obj in self._objects.items(): <TAB> <TAB> try: <TAB> <TAB> <TAB> state = obj.get_state() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> md5 = hashlib.md5(state).hexdigest() <TAB> <TAB> <TAB> if self._last_state.get(key) == md5: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self._persist_provider.store(key, state) <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> system_log.exception(""PersistHelper.persist fail"") <TAB> <TAB> else: <TAB> <TAB> <TAB> self._last_state[key] = md5",false,if not state :,if state is None :,0.05,0.0
"def enter(self, doc, **kwds): <TAB> """"""Enters the mode, arranging for necessary grabs ASAP"""""" <TAB> super(ColorPickMode, self).enter(doc, **kwds) <TAB> if self._started_from_key_press: <TAB> <TAB> # Pick now using the last recorded event position <TAB> <TAB> doc = self.doc <TAB> <TAB> tdw = self.doc.tdw <TAB> <TAB> t, x, y = doc.get_last_event_info(tdw) <TAB> <TAB> if None not in (x, y): <TAB> <TAB> <TAB> self._pick_color_mode(tdw, x, y, self._pickmode) <TAB> <TAB> # Start the drag when possible <TAB> <TAB> self._start_drag_on_next_motion_event = True <TAB> <TAB> self._needs_drag_start = True",true,"if None not in ( x , y ) :","if None not in ( x , y ) :",0.75,0.0
"def on_profiles_loaded(self, profiles): <TAB> cb = self.builder.get_object(""cbProfile"") <TAB> model = cb.get_model() <TAB> model.clear() <TAB> for f in profiles: <TAB> <TAB> name = f.get_basename() <TAB> <TAB> if name.endswith("".mod""): <TAB> <TAB> <TAB> continue <TAB> <TAB> if name.endswith("".sccprofile""): <TAB> <TAB> <TAB> name = name[0:-11] <TAB> <TAB> model.append((name, f, None)) <TAB> cb.set_active(0)",false,"if name . endswith ( "".mod"" ) :","if name . endswith ( "".sccprofile"" ) :",0.55,0.0
"def subprocess_post_check( <TAB> completed_process: subprocess.CompletedProcess, raise_error: bool = True ) -> None: <TAB> if completed_process.returncode: <TAB> <TAB> if completed_process.stdout is not None: <TAB> <TAB> <TAB> print(completed_process.stdout, file=sys.stdout, end="""") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(completed_process.stderr, file=sys.stderr, end="""") <TAB> <TAB> if raise_error: <TAB> <TAB> <TAB> raise PipxError( <TAB> <TAB> <TAB> <TAB> f""{' '.join([str(x) for x in completed_process.args])!r} failed"" <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> logger.info(f""{' '.join(completed_process.args)!r} failed"")",true,if completed_process . stderr is not None :,if completed_process . stderr is not None :,0.75,0.0
"def test_connect( <TAB> ipaddr, port, device, partition, method, path, headers=None, query_string=None ): <TAB> if path == ""/a"": <TAB> <TAB> for k, v in headers.iteritems(): <TAB> <TAB> <TAB> if k.lower() == test_header.lower() and v == test_value: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> test_errors.append(""%s: %s not in %s"" % (test_header, test_value, headers))",true,if k . lower ( ) == test_header . lower ( ) and v == test_value :,if k . lower ( ) == test_header . lower ( ) and v == test_value :,1.0,0.0
"def test_stat_result_pickle(self): <TAB> result = os.stat(self.fname) <TAB> for proto in range(pickle.HIGHEST_PROTOCOL + 1): <TAB> <TAB> p = pickle.dumps(result, proto) <TAB> <TAB> self.assertIn(b""stat_result"", p) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.assertIn(b""cos\nstat_result\n"", p) <TAB> <TAB> unpickled = pickle.loads(p) <TAB> <TAB> self.assertEqual(result, unpickled)",false,if proto < 4 :,if proto == pickle . HIGHEST_PROTOCOL :,0.05,0.0
"def run_sql(sql): <TAB> table = sql.split("" "")[5] <TAB> logger.info(""Updating table {}"".format(table)) <TAB> with transaction.atomic(): <TAB> <TAB> with connection.cursor() as cursor: <TAB> <TAB> <TAB> cursor.execute(sql) <TAB> <TAB> <TAB> rows = cursor.fetchall() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise Exception(""Sentry notification that {} is migrated"".format(table))",true,if not rows :,if not rows :,0.75,0.0
"def countbox(self): <TAB> self.box = [1000, 1000, -1000, -1000] <TAB> for x, y in self.body: <TAB> <TAB> if x < self.box[0]: <TAB> <TAB> <TAB> self.box[0] = x <TAB> <TAB> if x > self.box[2]: <TAB> <TAB> <TAB> self.box[2] = x <TAB> <TAB> if y < self.box[1]: <TAB> <TAB> <TAB> self.box[1] = y <TAB> <TAB> if y > self.box[3]: <TAB> <TAB> <TAB> self.box[3] = y",false,if x > self . box [ 2 ] :,if y < self . box [ 1 ] :,0.41,0.0
"def _packageFocusOutViaKeyPress(self, row, column, txt): <TAB> if txt: <TAB> <TAB> self._set_current_cell(row + 1, column) <TAB> else: <TAB> <TAB> widget = self.cellWidget(row + 1, column) <TAB> <TAB> if widget and isinstance(widget, PackageSelectWidget): <TAB> <TAB> <TAB> self._delete_cell(row, column) <TAB> <TAB> new_request = self.get_request() <TAB> <TAB> self.context_model.set_request(new_request) <TAB> <TAB> self._update_request_column(column, self.context_model)",true,"if widget and isinstance ( widget , PackageSelectWidget ) :","if widget and isinstance ( widget , PackageSelectWidget ) :",0.75,0.0
"def parse_bash_set_output(output): <TAB> """"""Parse Bash-like 'set' output"""""" <TAB> if not sys.platform.startswith(""win""): <TAB> <TAB> # Replace ""\""-continued lines in *Linux* environment dumps. <TAB> <TAB> # Cannot do this on Windows because a ""\"" at the end of the <TAB> <TAB> # line does not imply a continuation. <TAB> <TAB> output = output.replace(""\\\n"", """") <TAB> environ = {} <TAB> for line in output.splitlines(0): <TAB> <TAB> line = line.rstrip() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue  # skip black lines <TAB> <TAB> item = _ParseBashEnvStr(line) <TAB> <TAB> if item: <TAB> <TAB> <TAB> environ[item[0]] = item[1] <TAB> return environ",true,if not line :,if not line :,0.75,0.0
"def _get(self, domain): <TAB> with self.lock: <TAB> <TAB> try: <TAB> <TAB> <TAB> record = self.cache[domain] <TAB> <TAB> <TAB> time_now = time.time() <TAB> <TAB> <TAB> if time_now - record[""update""] > self.ttl: <TAB> <TAB> <TAB> <TAB> record = None <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> record = None <TAB> <TAB> if not record: <TAB> <TAB> <TAB> record = {""r"": ""unknown"", ""dns"": {}, ""g"": 1, ""query_count"": 0} <TAB> <TAB> # self.cache[domain] = record <TAB> <TAB> return record",true,"if time_now - record [ ""update"" ] > self . ttl :","if time_now - record [ ""update"" ] > self . ttl :",0.75,0.0
"def test_filehash(self): <TAB> """"""tests the hashes of the files in data/"""""" <TAB> fp = self.get_data_path() <TAB> for fn in os.listdir(fp): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # file used for something else <TAB> <TAB> <TAB> continue <TAB> <TAB> expected_hash = fn <TAB> <TAB> fullp = os.path.join(fp, fn) <TAB> <TAB> output = self.run_command(""sha1sum "" + fullp, exitcode=0) <TAB> <TAB> result = output.split("" "")[0] <TAB> <TAB> self.assertEqual(result, expected_hash)",false,"if ""."" in fn :","if fn == "".py"" or fn == "".py"" :",0.03,0.0
"def test_new_vs_reference_code_stream_read_during_iter(read_idx, read_len, bytecode): <TAB> reference = SlowCodeStream(bytecode) <TAB> latest = CodeStream(bytecode) <TAB> for index, (actual, expected) in enumerate(zip(latest, reference)): <TAB> <TAB> assert actual == expected <TAB> <TAB> if index == read_idx: <TAB> <TAB> <TAB> readout_actual = latest.read(read_len) <TAB> <TAB> <TAB> readout_expected = reference.read(read_len) <TAB> <TAB> <TAB> assert readout_expected == readout_actual <TAB> <TAB> if reference.program_counter >= len(reference): <TAB> <TAB> <TAB> assert latest.program_counter >= len(reference) <TAB> <TAB> else: <TAB> <TAB> <TAB> assert latest.program_counter == reference.program_counter",true,if reference . program_counter >= len ( reference ) :,if reference . program_counter >= len ( reference ) :,1.0,0.0
"def setup_logging(): <TAB> try: <TAB> <TAB> logconfig = config.get(""logging_config_file"") <TAB> <TAB> if logconfig and os.path.exists(logconfig): <TAB> <TAB> <TAB> logging.config.fileConfig(logconfig, disable_existing_loggers=False) <TAB> <TAB> logger.info(""logging initialized"") <TAB> <TAB> logger.debug(""debug"") <TAB> except Exception as e: <TAB> <TAB> print(""Unable to set logging configuration:"", str(e), file=sys.stderr) <TAB> <TAB> raise",true,if logconfig and os . path . exists ( logconfig ) :,if logconfig and os . path . exists ( logconfig ) :,0.75,0.0
"def all_words(filename): <TAB> start_char = True <TAB> for c in characters(filename): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> word = """" <TAB> <TAB> <TAB> if c.isalnum(): <TAB> <TAB> <TAB> <TAB> # We found the start of a word <TAB> <TAB> <TAB> <TAB> word = c.lower() <TAB> <TAB> <TAB> <TAB> start_char = False <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> if c.isalnum(): <TAB> <TAB> <TAB> <TAB> word += c.lower() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> # We found end of word, emit it <TAB> <TAB> <TAB> <TAB> start_char = True <TAB> <TAB> <TAB> <TAB> yield word",false,if start_char == True :,if start_char :,0.07,0.0
"def _get_nonce(self, url, new_nonce_url): <TAB> if not self._nonces: <TAB> <TAB> logger.debug(""Requesting fresh nonce"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> response = self.head(url) <TAB> <TAB> else: <TAB> <TAB> <TAB> # request a new nonce from the acme newNonce endpoint <TAB> <TAB> <TAB> response = self._check_response(self.head(new_nonce_url), content_type=None) <TAB> <TAB> self._add_nonce(response) <TAB> return self._nonces.pop()",false,if new_nonce_url is None :,if url :,0.04,0.0
"def paragraph_is_fully_commented(lines, comment, main_language): <TAB> """"""Is the paragraph fully commented?"""""" <TAB> for i, line in enumerate(lines): <TAB> <TAB> if line.startswith(comment): <TAB> <TAB> <TAB> if line[len(comment) :].lstrip().startswith(comment): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if is_magic(line, main_language): <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> continue <TAB> <TAB> return i > 0 and _BLANK_LINE.match(line) <TAB> return True",true,if line [ len ( comment ) : ] . lstrip ( ) . startswith ( comment ) :,if line [ len ( comment ) : ] . lstrip ( ) . startswith ( comment ) :,1.0,0.0
"def gvariant_args(args: List[Any]) -> str: <TAB> """"""Convert args into gvariant."""""" <TAB> gvariant = """" <TAB> for arg in args: <TAB> <TAB> if isinstance(arg, bool): <TAB> <TAB> <TAB> gvariant += "" {}"".format(str(arg).lower()) <TAB> <TAB> elif isinstance(arg, (int, float)): <TAB> <TAB> <TAB> gvariant += f"" {arg}"" <TAB> <TAB> elif isinstance(arg, str): <TAB> <TAB> <TAB> gvariant += f' ""{arg}""' <TAB> <TAB> else: <TAB> <TAB> <TAB> gvariant += f"" {arg!s}"" <TAB> return gvariant.lstrip()",false,"elif isinstance ( arg , ( int , float ) ) :","elif isinstance ( arg , str ) :",0.24,0.0
"def _SkipGroup(buffer, pos, end): <TAB> """"""Skip sub-group.  Returns the new position."""""" <TAB> while 1: <TAB> <TAB> (tag_bytes, pos) = ReadTag(buffer, pos) <TAB> <TAB> new_pos = SkipField(buffer, pos, end, tag_bytes) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return pos <TAB> <TAB> pos = new_pos",true,if new_pos == - 1 :,if new_pos == - 1 :,0.75,0.0
"def update_participants(self, refresh=True): <TAB> for participant in list(self.participants_dict): <TAB> <TAB> if participant is None or participant == self.simulator_config.broadcast_part: <TAB> <TAB> <TAB> continue <TAB> <TAB> self.removeItem(self.participants_dict[participant]) <TAB> <TAB> self.participant_items.remove(self.participants_dict[participant]) <TAB> <TAB> del self.participants_dict[participant] <TAB> for participant in self.simulator_config.participants: <TAB> <TAB> if participant in self.participants_dict: <TAB> <TAB> <TAB> self.participants_dict[participant].refresh() <TAB> <TAB> else: <TAB> <TAB> <TAB> self.insert_participant(participant) <TAB> if refresh: <TAB> <TAB> self.update_view()",false,if participant in self . participants_dict :,if participant is None or participant == self . simulator_config . broadcast_part :,0.21,0.0
"def feature_reddit(layer_data, graph): <TAB> feature = {} <TAB> times = {} <TAB> indxs = {} <TAB> for _type in layer_data: <TAB> <TAB> if len(layer_data[_type]) == 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> idxs = np.array(list(layer_data[_type].keys())) <TAB> <TAB> tims = np.array(list(layer_data[_type].values()))[:, 1] <TAB> <TAB> feature[_type] = np.array( <TAB> <TAB> <TAB> list(graph.node_feature[_type].loc[idxs, ""emb""]), dtype=np.float <TAB> <TAB> ) <TAB> <TAB> times[_type] = tims <TAB> <TAB> indxs[_type] = idxs <TAB> <TAB> if _type == ""def"": <TAB> <TAB> <TAB> attr = feature[_type] <TAB> return feature, times, indxs, attr",false,"if _type == ""def"" :",if len ( layer_data [ _type ] ) == 0 :,0.03,0.0
"def _get_sort_map(tags): <TAB> """"""See TAG_TO_SORT"""""" <TAB> tts = {} <TAB> for name, tag in tags.items(): <TAB> <TAB> if tag.has_sort: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> tts[name] = ""%ssort"" % name <TAB> <TAB> <TAB> if tag.internal: <TAB> <TAB> <TAB> <TAB> tts[""~%s"" % name] = ""~%ssort"" % name <TAB> return tts",false,if tag . user :,if tag . internal :,0.39,0.0
"def max_radius(iterator): <TAB> radius_result = dict() <TAB> for k, v in iterator: <TAB> <TAB> if v[0] not in radius_result: <TAB> <TAB> <TAB> radius_result[v[0]] = v[1] <TAB> <TAB> elif v[1] >= radius_result[v[0]]: <TAB> <TAB> <TAB> radius_result[v[0]] = v[1] <TAB> return radius_result",true,elif v [ 1 ] >= radius_result [ v [ 0 ] ] :,elif v [ 1 ] >= radius_result [ v [ 0 ] ] :,0.75,0.0
"def run(self): <TAB> pwd_found = [] <TAB> if constant.user_dpapi and constant.user_dpapi.unlocked: <TAB> <TAB> main_vault_directory = os.path.join( <TAB> <TAB> <TAB> constant.profile[""APPDATA""], u"".."", u""Local"", u""Microsoft"", u""Vault"" <TAB> <TAB> ) <TAB> <TAB> if os.path.exists(main_vault_directory): <TAB> <TAB> <TAB> for vault_directory in os.listdir(main_vault_directory): <TAB> <TAB> <TAB> <TAB> cred = constant.user_dpapi.decrypt_vault( <TAB> <TAB> <TAB> <TAB> <TAB> os.path.join(main_vault_directory, vault_directory) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> pwd_found.append(cred) <TAB> return pwd_found",true,if cred :,if cred :,0.53,0.0
"def disconnect_sync(self, connection, close_connection=False): <TAB> key = id(connection) <TAB> ts = self.in_use.pop(key) <TAB> if close_connection: <TAB> <TAB> self.connections_map.pop(key) <TAB> <TAB> self._connection_close_sync(connection) <TAB> else: <TAB> <TAB> if self.stale_timeout and self.is_stale(ts): <TAB> <TAB> <TAB> self.connections_map.pop(key) <TAB> <TAB> <TAB> self._connection_close_sync(connection) <TAB> <TAB> else: <TAB> <TAB> <TAB> with self._lock_sync: <TAB> <TAB> <TAB> <TAB> heapq.heappush(self.connections_sync, (ts, key))",true,if self . stale_timeout and self . is_stale ( ts ) :,if self . stale_timeout and self . is_stale ( ts ) :,0.75,0.0
"def _populate_tree(self, element, d): <TAB> """"""Populates an etree with attributes & elements, given a dict."""""" <TAB> for k, v in d.iteritems(): <TAB> <TAB> if isinstance(v, dict): <TAB> <TAB> <TAB> self._populate_dict(element, k, v) <TAB> <TAB> elif isinstance(v, list): <TAB> <TAB> <TAB> self._populate_list(element, k, v) <TAB> <TAB> elif isinstance(v, bool): <TAB> <TAB> <TAB> self._populate_bool(element, k, v) <TAB> <TAB> elif isinstance(v, basestring): <TAB> <TAB> <TAB> self._populate_str(element, k, v) <TAB> <TAB> elif type(v) in [int, float, long, complex]: <TAB> <TAB> <TAB> self._populate_number(element, k, v)",false,"elif type ( v ) in [ int , float , long , complex ] :","elif isinstance ( v , basestring ) :",0.06,0.0
"def readframes(self, nframes): <TAB> if self._ssnd_seek_needed: <TAB> <TAB> self._ssnd_chunk.seek(0) <TAB> <TAB> dummy = self._ssnd_chunk.read(8) <TAB> <TAB> pos = self._soundpos * self._framesize <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._ssnd_chunk.seek(pos + 8) <TAB> <TAB> self._ssnd_seek_needed = 0 <TAB> if nframes == 0: <TAB> <TAB> return """" <TAB> data = self._ssnd_chunk.read(nframes * self._framesize) <TAB> if self._convert and data: <TAB> <TAB> data = self._convert(data) <TAB> self._soundpos = self._soundpos + len(data) / (self._nchannels * self._sampwidth) <TAB> return data",true,if pos :,if pos :,0.53,0.0
"def target_glob(tgt, hosts): <TAB> ret = {} <TAB> for host in hosts: <TAB> <TAB> if fnmatch.fnmatch(tgt, host): <TAB> <TAB> <TAB> ret[host] = copy.deepcopy(__opts__.get(""roster_defaults"", {})) <TAB> <TAB> <TAB> ret[host].update({""host"": host}) <TAB> <TAB> <TAB> if __opts__.get(""ssh_user""): <TAB> <TAB> <TAB> <TAB> ret[host].update({""user"": __opts__[""ssh_user""]}) <TAB> return ret",true,"if fnmatch . fnmatch ( tgt , host ) :","if fnmatch . fnmatch ( tgt , host ) :",1.0,0.0
"def get_attribute_value(self, nodeid, attr): <TAB> with self._lock: <TAB> <TAB> self.logger.debug(""get attr val: %s %s"", nodeid, attr) <TAB> <TAB> if nodeid not in self._nodes: <TAB> <TAB> <TAB> dv = ua.DataValue() <TAB> <TAB> <TAB> dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadNodeIdUnknown) <TAB> <TAB> <TAB> return dv <TAB> <TAB> node = self._nodes[nodeid] <TAB> <TAB> if attr not in node.attributes: <TAB> <TAB> <TAB> dv = ua.DataValue() <TAB> <TAB> <TAB> dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadAttributeIdInvalid) <TAB> <TAB> <TAB> return dv <TAB> <TAB> attval = node.attributes[attr] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return attval.value_callback() <TAB> <TAB> return attval.value",true,if attval . value_callback :,if attval . value_callback :,0.75,0.0
"def remove_property(self, key):  # type: (str) -> None <TAB> with self.secure() as config: <TAB> <TAB> keys = key.split(""."") <TAB> <TAB> current_config = config <TAB> <TAB> for i, key in enumerate(keys): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> if i == len(keys) - 1: <TAB> <TAB> <TAB> <TAB> del current_config[key] <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> current_config = current_config[key]",true,if key not in current_config :,if key not in current_config :,0.75,0.0
"def _class_browser(parent):  # Wrapper for htest <TAB> try: <TAB> <TAB> file = __file__ <TAB> except NameError: <TAB> <TAB> file = sys.argv[0] <TAB> <TAB> if sys.argv[1:]: <TAB> <TAB> <TAB> file = sys.argv[1] <TAB> <TAB> else: <TAB> <TAB> <TAB> file = sys.argv[0] <TAB> dir, file = os.path.split(file) <TAB> name = os.path.splitext(file)[0] <TAB> flist = PyShell.PyShellFileList(parent) <TAB> global file_open <TAB> file_open = flist.open <TAB> ClassBrowser(flist, name, [dir], _htest=True)",true,if sys . argv [ 1 : ] :,if sys . argv [ 1 : ] :,0.75,0.0
"def get_only_text_part(self, msg): <TAB> count = 0 <TAB> only_text_part = None <TAB> for part in msg.walk(): <TAB> <TAB> if part.is_multipart(): <TAB> <TAB> <TAB> continue <TAB> <TAB> count += 1 <TAB> <TAB> mimetype = part.get_content_type() or ""text/plain"" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> else: <TAB> <TAB> <TAB> only_text_part = part <TAB> return only_text_part",false,"if mimetype != ""text/plain"" or count != 1 :",if mimetype not in self . allowed_text_types :,0.08,0.0
"def should_keep_alive(commit_msg): <TAB> result = False <TAB> ci = get_current_ci() or """" <TAB> for line in commit_msg.splitlines(): <TAB> <TAB> parts = line.strip(""# "").split("":"", 1) <TAB> <TAB> (key, val) = parts if len(parts) > 1 else (parts[0], """") <TAB> <TAB> if key == ""CI_KEEP_ALIVE"": <TAB> <TAB> <TAB> ci_names = val.replace("","", "" "").lower().split() if val else [] <TAB> <TAB> <TAB> if len(ci_names) == 0 or ci.lower() in ci_names: <TAB> <TAB> <TAB> <TAB> result = True <TAB> return result",false,if len ( ci_names ) == 0 or ci . lower ( ) in ci_names :,"if key == ""CI_KEEP_ALIVE"" :",0.01,0.0
"def _calc_block_io(self, blkio): <TAB> """"""Calculate block IO stats."""""" <TAB> for stats in blkio[""io_service_bytes_recursive""]: <TAB> <TAB> if stats[""op""] == ""Read"": <TAB> <TAB> <TAB> self._blk_read += stats[""value""] <TAB> <TAB> elif stats[""op""] == ""Write"": <TAB> <TAB> <TAB> self._blk_write += stats[""value""]",false,"elif stats [ ""op"" ] == ""Write"" :","if stats [ ""op"" ] == ""Read"" :",0.27,0.0
"def value_to_db_datetime(self, value): <TAB> if value is None: <TAB> <TAB> return None <TAB> # Oracle doesn't support tz-aware datetimes <TAB> if timezone.is_aware(value): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> value = value.astimezone(timezone.utc).replace(tzinfo=None) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""Oracle backend does not support timezone-aware datetimes when USE_TZ is False."" <TAB> <TAB> <TAB> ) <TAB> return six.text_type(value)",true,if settings . USE_TZ :,if settings . USE_TZ :,0.75,0.0
"def load_state_dict(self, state_dict): <TAB> for module_name, module_state_dict in state_dict.items(): <TAB> <TAB> if module_name in self.module_pool: <TAB> <TAB> <TAB> if self.config[""dataparallel""]: <TAB> <TAB> <TAB> <TAB> self.module_pool[module_name].module.load_state_dict(module_state_dict) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.module_pool[module_name].load_state_dict(module_state_dict) <TAB> <TAB> else: <TAB> <TAB> <TAB> logging.info(f""Missing {module_name} in module_pool, skip it.."")",true,"if self . config [ ""dataparallel"" ] :","if self . config [ ""dataparallel"" ] :",0.75,0.0
"def _unpack_scales(scales, vidxs): <TAB> scaleData = [None, None, None] <TAB> for i in range(3): <TAB> <TAB> if i >= min(len(scales), len(vidxs) // 2): <TAB> <TAB> <TAB> break <TAB> <TAB> scale = scales[i] <TAB> <TAB> if not math.isnan(scale): <TAB> <TAB> <TAB> vidx1, vidx2 = vidxs[i * 2], vidxs[i * 2 + 1] <TAB> <TAB> <TAB> scaleData[i] = (int(vidx1), int(vidx2), float(scale)) <TAB> return scaleData",false,if not math . isnan ( scale ) :,"if i >= min ( len ( scales ) , len ( vidxs ) // 2 ) :",0.02,0.0
"def __init__(self, factors, contrast_matrices, num_columns): <TAB> self.factors = tuple(factors) <TAB> factor_set = frozenset(factors) <TAB> if not isinstance(contrast_matrices, dict): <TAB> <TAB> raise ValueError(""contrast_matrices must be dict"") <TAB> for factor, contrast_matrix in six.iteritems(contrast_matrices): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError(""Unexpected factor in contrast_matrices dict"") <TAB> <TAB> if not isinstance(contrast_matrix, ContrastMatrix): <TAB> <TAB> <TAB> raise ValueError(""Expected a ContrastMatrix, not %r"" % (contrast_matrix,)) <TAB> self.contrast_matrices = contrast_matrices <TAB> if not isinstance(num_columns, six.integer_types): <TAB> <TAB> raise ValueError(""num_columns must be an integer"") <TAB> self.num_columns = num_columns",true,if factor not in factor_set :,if factor not in factor_set :,0.75,0.0
"def app(scope, receive, send): <TAB> while True: <TAB> <TAB> message = await receive() <TAB> <TAB> if message[""type""] == ""websocket.connect"": <TAB> <TAB> <TAB> await send({""type"": ""websocket.accept""}) <TAB> <TAB> elif message[""type""] == ""websocket.receive"": <TAB> <TAB> <TAB> pass <TAB> <TAB> elif message[""type""] == ""websocket.disconnect"": <TAB> <TAB> <TAB> break",false,"if message [ ""type"" ] == ""websocket.connect"" :","elif message [ ""type"" ] == ""websocket.receive"" :",0.26,0.0
"def value__set(self, value): <TAB> for i, (option, checked) in enumerate(self.options): <TAB> <TAB> if option == str(value): <TAB> <TAB> <TAB> self.selectedIndex = i <TAB> <TAB> <TAB> break <TAB> else: <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> ""Option %r not found (from %s)"" <TAB> <TAB> <TAB> % (value, "", "".join([repr(o) for o, c in self.options])) <TAB> <TAB> )",true,if option == str ( value ) :,if option == str ( value ) :,0.75,0.0
"def init_links(self): <TAB> links = LinkCallback.find_links(self) <TAB> callbacks = [] <TAB> for link, src_plot, tgt_plot in links: <TAB> <TAB> cb = Link._callbacks[""bokeh""][type(link)] <TAB> <TAB> if src_plot is None or (link._requires_target and tgt_plot is None): <TAB> <TAB> <TAB> continue <TAB> <TAB> callbacks.append(cb(self.root, link, src_plot, tgt_plot)) <TAB> return callbacks",true,if src_plot is None or ( link . _requires_target and tgt_plot is None ) :,if src_plot is None or ( link . _requires_target and tgt_plot is None ) :,1.0,0.0
"def _validate_scalar_extensions(self) -> List[str]: <TAB> errors = [] <TAB> for extension in [ <TAB> <TAB> x for x in self.extensions if isinstance(x, GraphQLScalarTypeExtension) <TAB> ]: <TAB> <TAB> extended = self.type_definitions.get(extension.name) <TAB> <TAB> ext_errors = _validate_extension( <TAB> <TAB> <TAB> extended, extension.name, GraphQLScalarType, ""SCALAR"" <TAB> <TAB> ) <TAB> <TAB> errors.extend(ext_errors) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> errors.extend(_validate_extension_directives(extension, extended, ""SCALAR"")) <TAB> return errors",false,if not ext_errors :,if extension . directives :,0.04,0.0
"def copy_tcltk(src, dest, symlink): <TAB> """"""copy tcl/tk libraries on Windows (issue #93)"""""" <TAB> for libversion in ""8.5"", ""8.6"": <TAB> <TAB> for libname in ""tcl"", ""tk"": <TAB> <TAB> <TAB> srcdir = join(src, ""tcl"", libname + libversion) <TAB> <TAB> <TAB> destdir = join(dest, ""tcl"", libname + libversion) <TAB> <TAB> <TAB> # Only copy the dirs from the above combinations that exist <TAB> <TAB> <TAB> if os.path.exists(srcdir) and not os.path.exists(destdir): <TAB> <TAB> <TAB> <TAB> copyfileordir(srcdir, destdir, symlink)",true,if os . path . exists ( srcdir ) and not os . path . exists ( destdir ) :,if os . path . exists ( srcdir ) and not os . path . exists ( destdir ) :,1.0,0.0
"def parse(self, response): <TAB> try: <TAB> <TAB> content = response.content.decode(""utf-8"", ""ignore"") <TAB> <TAB> content = json.loads(content, strict=False) <TAB> except: <TAB> <TAB> self.logger.error(""Fail to parse the response in json format"") <TAB> <TAB> return <TAB> for item in content[""data""]: <TAB> <TAB> if ""objURL"" in item: <TAB> <TAB> <TAB> img_url = self._decode_url(item[""objURL""]) <TAB> <TAB> elif ""hoverURL"" in item: <TAB> <TAB> <TAB> img_url = item[""hoverURL""] <TAB> <TAB> else: <TAB> <TAB> <TAB> continue <TAB> <TAB> yield dict(file_url=img_url)",true,"elif ""hoverURL"" in item :","elif ""hoverURL"" in item :",0.75,0.0
"def check_and_reload(self): <TAB> # Check if tables have been modified, if so reload <TAB> for table_name, table_version in self._table_versions.items(): <TAB> <TAB> table = self.app.tool_data_tables.get(table_name, None) <TAB> <TAB> if table is not None and not table.is_current_version(table_version): <TAB> <TAB> <TAB> return self.reload_genomes()",true,if table is not None and not table . is_current_version ( table_version ) :,if table is not None and not table . is_current_version ( table_version ) :,0.75,0.0
"def _get_query_defaults(self, query_defns): <TAB> defaults = {} <TAB> for k, v in query_defns.items(): <TAB> <TAB> try: <TAB> <TAB> <TAB> if v[""schema""][""type""] == ""object"": <TAB> <TAB> <TAB> <TAB> defaults[k] = self._get_default_obj(v[""schema""]) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> defaults[k] = v[""schema""][""default""] <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> pass <TAB> return defaults",true,"if v [ ""schema"" ] [ ""type"" ] == ""object"" :","if v [ ""schema"" ] [ ""type"" ] == ""object"" :",0.75,0.0
"def ftp_login(host, port, username=None, password=None, anonymous=False): <TAB> ret = False <TAB> try: <TAB> <TAB> ftp = ftplib.FTP() <TAB> <TAB> ftp.connect(host, port, timeout=6) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ftp.login() <TAB> <TAB> else: <TAB> <TAB> <TAB> ftp.login(username, password) <TAB> <TAB> ret = True <TAB> <TAB> ftp.quit() <TAB> except Exception: <TAB> <TAB> pass <TAB> return ret",true,if anonymous :,if anonymous :,0.53,0.0
"def _getVolumeScalar(self): <TAB> if self._volumeScalar is not None: <TAB> <TAB> return self._volumeScalar <TAB> # use default <TAB> elif self._value in dynamicStrToScalar: <TAB> <TAB> return dynamicStrToScalar[self._value] <TAB> else: <TAB> <TAB> thisDynamic = self._value <TAB> <TAB> # ignore leading s like in sf <TAB> <TAB> if ""s"" in thisDynamic: <TAB> <TAB> <TAB> thisDynamic = thisDynamic[1:] <TAB> <TAB> # ignore closing z like in fz <TAB> <TAB> if thisDynamic[-1] == ""z"": <TAB> <TAB> <TAB> thisDynamic = thisDynamic[:-1] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return dynamicStrToScalar[thisDynamic] <TAB> <TAB> else: <TAB> <TAB> <TAB> return dynamicStrToScalar[None]",true,if thisDynamic in dynamicStrToScalar :,if thisDynamic in dynamicStrToScalar :,0.75,0.0
"def processCoords(coords): <TAB> newcoords = deque() <TAB> for (x, y, z) in coords: <TAB> <TAB> for _dir, offsets in faceDirections: <TAB> <TAB> <TAB> if _dir == FaceYIncreasing: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> dx, dy, dz = offsets <TAB> <TAB> <TAB> p = (x + dx, y + dy, z + dz) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> nx, ny, nz = p <TAB> <TAB> <TAB> if level.blockAt(nx, ny, nz) == 0: <TAB> <TAB> <TAB> <TAB> level.setBlockAt(nx, ny, nz, waterID) <TAB> <TAB> <TAB> <TAB> newcoords.append(p) <TAB> return newcoords",false,if p not in box :,if p is None :,0.05,0.0
"def _set_property(self, target_widget, pname, value): <TAB> if pname == ""text"": <TAB> <TAB> wstate = str(target_widget[""state""]) <TAB> <TAB> if wstate != ""normal"": <TAB> <TAB> <TAB> # change state temporarily <TAB> <TAB> <TAB> target_widget[""state""] = ""normal"" <TAB> <TAB> target_widget.delete(""0"", tk.END) <TAB> <TAB> target_widget.insert(""0"", value) <TAB> <TAB> target_widget[""state""] = wstate <TAB> else: <TAB> <TAB> super(EntryBaseBO, self)._set_property(target_widget, pname, value)",true,"if wstate != ""normal"" :","if wstate != ""normal"" :",0.75,0.0
"def teardown(): <TAB> try: <TAB> <TAB> time.sleep(1) <TAB> except KeyboardInterrupt: <TAB> <TAB> return <TAB> while launchers: <TAB> <TAB> p = launchers.pop() <TAB> <TAB> if p.poll() is None: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> p.stop() <TAB> <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> <TAB> print(e) <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> if p.poll() is None: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> time.sleep(0.25) <TAB> <TAB> <TAB> except KeyboardInterrupt: <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> if p.poll() is None: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> print(""cleaning up test process..."") <TAB> <TAB> <TAB> <TAB> p.signal(SIGKILL) <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> print(""couldn't shutdown process: "", p)",true,if p . poll ( ) is None :,if p . poll ( ) is None :,0.75,0.0
"def checkAndRemoveDuplicate(self, node): <TAB> for bucket in self.buckets: <TAB> <TAB> for n in bucket.getNodes(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.removeContact(n)",false,"if ( n . ip , n . port ) == ( node . ip , node . port ) and n . id != node . id :",if n . node == node :,0.13,0.0
"def toString(): <TAB> flags = u"""" <TAB> try: <TAB> <TAB> if this.glob: <TAB> <TAB> <TAB> flags += u""g"" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> flags += u""i"" <TAB> <TAB> if this.multiline: <TAB> <TAB> <TAB> flags += u""m"" <TAB> except: <TAB> <TAB> pass <TAB> v = this.value if this.value else ""(?:)"" <TAB> return u""/%s/"" % v + flags",false,if this . ignore_case :,if this . is_glob :,0.4,0.0
"def import_submodules(package_name): <TAB> package = sys.modules[package_name] <TAB> results = {} <TAB> for loader, name, is_pkg in pkgutil.iter_modules(package.__path__): <TAB> <TAB> full_name = package_name + ""."" + name <TAB> <TAB> module = importlib.import_module(full_name) <TAB> <TAB> setattr(sys.modules[__name__], name, module) <TAB> <TAB> results[full_name] = module <TAB> <TAB> if is_pkg: <TAB> <TAB> <TAB> valid_pkg = import_submodules(full_name) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> results.update(valid_pkg) <TAB> return results",true,if valid_pkg :,if valid_pkg :,0.53,0.0
"def _call(self, cmd): <TAB> what = cmd[""command""] <TAB> if what == ""list"": <TAB> <TAB> name = cmd[""properties""].get(""name"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return {""watchers"": [""one"", ""two"", ""three""]} <TAB> <TAB> return {""pids"": [123, 456]} <TAB> elif what == ""dstats"": <TAB> <TAB> return {""info"": {""pid"": 789}} <TAB> elif what == ""listsockets"": <TAB> <TAB> return { <TAB> <TAB> <TAB> ""status"": ""ok"", <TAB> <TAB> <TAB> ""sockets"": [{""path"": self._unix, ""fd"": 5, ""name"": ""XXXX"", ""backlog"": 2048}], <TAB> <TAB> <TAB> ""time"": 1369647058.967524, <TAB> <TAB> } <TAB> raise NotImplementedError(cmd)",true,if name is None :,if name is None :,0.75,0.0
"def select(self): <TAB> e = xlib.XEvent() <TAB> while xlib.XPending(self._display): <TAB> <TAB> xlib.XNextEvent(self._display, e) <TAB> <TAB> # Key events are filtered by the xlib window event <TAB> <TAB> # handler so they get a shot at the prefiltered event. <TAB> <TAB> if e.xany.type not in (xlib.KeyPress, xlib.KeyRelease): <TAB> <TAB> <TAB> if xlib.XFilterEvent(e, e.xany.window): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> dispatch = self._window_map[e.xany.window] <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> continue <TAB> <TAB> dispatch(e)",true,"if xlib . XFilterEvent ( e , e . xany . window ) :","if xlib . XFilterEvent ( e , e . xany . window ) :",1.0,0.0
"def translate(self, line): <TAB> parsed = self.RE_LINE_PARSER.match(line) <TAB> if parsed: <TAB> <TAB> value = parsed.group(3) <TAB> <TAB> stage = parsed.group(1) <TAB> <TAB> if stage == ""send"":  # query string is rendered here <TAB> <TAB> <TAB> return ""\n# HTTP Request:\n"" + self.stripslashes(value) <TAB> <TAB> elif stage == ""reply"": <TAB> <TAB> <TAB> return ""\n\n# HTTP Response:\n"" + self.stripslashes(value) <TAB> <TAB> elif stage == ""header"": <TAB> <TAB> <TAB> return value + ""\n"" <TAB> <TAB> else: <TAB> <TAB> <TAB> return value <TAB> return line",false,"if stage == ""send"" :","elif stage == ""header"" :",0.06,0.0
"def toString(): <TAB> flags = u"""" <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> flags += u""g"" <TAB> <TAB> if this.ignore_case: <TAB> <TAB> <TAB> flags += u""i"" <TAB> <TAB> if this.multiline: <TAB> <TAB> <TAB> flags += u""m"" <TAB> except: <TAB> <TAB> pass <TAB> v = this.value if this.value else ""(?:)"" <TAB> return u""/%s/"" % v + flags",false,if this . glob :,if this . regex :,0.4,0.0
"def __exit__(self, *exc_info): <TAB> super(WarningsChecker, self).__exit__(*exc_info) <TAB> # only check if we're not currently handling an exception <TAB> if all(a is None for a in exc_info): <TAB> <TAB> if self.expected_warning is not None: <TAB> <TAB> <TAB> if not any(r.category in self.expected_warning for r in self): <TAB> <TAB> <TAB> <TAB> __tracebackhide__ = True <TAB> <TAB> <TAB> <TAB> pytest.fail(""DID NOT WARN"")",true,if not any ( r . category in self . expected_warning for r in self ) :,if not any ( r . category in self . expected_warning for r in self ) :,1.0,0.0
"def run(self): <TAB> for k, v in iteritems(self.objs): <TAB> <TAB> if k.startswith(""_""): <TAB> <TAB> <TAB> continue <TAB> <TAB> if v[""_class""] == ""User"": <TAB> <TAB> <TAB> if v[""email""] == """": <TAB> <TAB> <TAB> <TAB> v[""email""] = None <TAB> <TAB> <TAB> if v[""ip""] == ""0.0.0.0"": <TAB> <TAB> <TAB> <TAB> v[""ip""] = None <TAB> return self.objs",false,"if v [ ""_class"" ] == ""User"" :","if v [ ""ip"" ] == ""0.0.0.0"" :",0.34,0.0
"def list_stuff(self, upto=10, start_after=-1): <TAB> for i in range(upto): <TAB> <TAB> if i <= start_after: <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.count += 1 <TAB> <TAB> <TAB> raise TemporaryProblem <TAB> <TAB> if i == 7 and self.count < 4: <TAB> <TAB> <TAB> self.count += 1 <TAB> <TAB> <TAB> raise TemporaryProblem <TAB> <TAB> yield i",false,if i == 2 and self . count < 1 :,if i == 5 and self . count < 4 :,0.49,0.0
"def check(self): <TAB> tcp_client = self.tcp_create() <TAB> if tcp_client.connect(): <TAB> <TAB> tcp_client.send(b""ABCDE"") <TAB> <TAB> response = tcp_client.recv(5) <TAB> <TAB> tcp_client.close() <TAB> <TAB> if response: <TAB> <TAB> <TAB> if response.startswith(b""MMcS""): <TAB> <TAB> <TAB> <TAB> self.endianness = "">""  # BE <TAB> <TAB> <TAB> elif response.startswith(b""ScMM""): <TAB> <TAB> <TAB> <TAB> self.endianness = ""<""  # LE <TAB> <TAB> <TAB> return True  # target is vulnerable <TAB> return False  # target is not vulnerable",true,"if response . startswith ( b""MMcS"" ) :","if response . startswith ( b""MMcS"" ) :",0.75,0.0
"def copy_tree(self, src_dir, dst_dir, skip_variables=False): <TAB> for src_root, _, files in os.walk(src_dir): <TAB> <TAB> if src_root != src_dir: <TAB> <TAB> <TAB> rel_root = os.path.relpath(src_root, src_dir) <TAB> <TAB> else: <TAB> <TAB> <TAB> rel_root = """" <TAB> <TAB> if skip_variables and rel_root.startswith(""variables""): <TAB> <TAB> <TAB> continue <TAB> <TAB> dst_root = os.path.join(dst_dir, rel_root) <TAB> <TAB> if not os.path.exists(dst_root): <TAB> <TAB> <TAB> os.makedirs(dst_root) <TAB> <TAB> for f in files: <TAB> <TAB> <TAB> shutil.copy(os.path.join(src_root, f), os.path.join(dst_root, f))",false,if not os . path . exists ( dst_root ) :,"if skip_variables and rel_root . startswith ( ""variables"" ) :",0.03,0.0
"def _set_hostport(self, host, port): <TAB> if port is None: <TAB> <TAB> i = host.rfind("":"") <TAB> <TAB> j = host.rfind(""]"")  # ipv6 addresses have [...] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> port = int(host[i + 1 :]) <TAB> <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> <TAB> raise InvalidURL(""nonnumeric port: '%s'"" % host[i + 1 :]) <TAB> <TAB> <TAB> host = host[:i] <TAB> <TAB> else: <TAB> <TAB> <TAB> port = self.default_port <TAB> <TAB> if host and host[0] == ""["" and host[-1] == ""]"": <TAB> <TAB> <TAB> host = host[1:-1] <TAB> self.host = host <TAB> self.port = port",false,if i > j :,if i != j :,0.33,0.0
"def _get_field_value(self, test, key, match): <TAB> if test.ver == ofproto_v1_0.OFP_VERSION: <TAB> <TAB> members = inspect.getmembers(match) <TAB> <TAB> for member in members: <TAB> <TAB> <TAB> if member[0] == key: <TAB> <TAB> <TAB> <TAB> field_value = member[1] <TAB> <TAB> <TAB> elif member[0] == ""wildcards"": <TAB> <TAB> <TAB> <TAB> wildcards = member[1] <TAB> <TAB> if key == ""nw_src"": <TAB> <TAB> <TAB> field_value = test.nw_src_to_str(wildcards, field_value) <TAB> <TAB> elif key == ""nw_dst"": <TAB> <TAB> <TAB> field_value = test.nw_dst_to_str(wildcards, field_value) <TAB> else: <TAB> <TAB> field_value = match[key] <TAB> return field_value",false,"if key == ""nw_src"" :","elif member [ 0 ] == ""wildcards"" :",0.02,0.0
"def _clear_storage(): <TAB> """"""Clear old files from storage."""""" <TAB> hacs = get_hacs() <TAB> storagefiles = [""hacs""] <TAB> for s_f in storagefiles: <TAB> <TAB> path = f""{hacs.core.config_path}/.storage/{s_f}"" <TAB> <TAB> if os.path.isfile(path): <TAB> <TAB> <TAB> hacs.log.info(f""Cleaning up old storage file {path}"") <TAB> <TAB> <TAB> os.remove(path)",true,if os . path . isfile ( path ) :,if os . path . isfile ( path ) :,1.0,0.0
"def action_delete(self, ids): <TAB> try: <TAB> <TAB> count = 0 <TAB> <TAB> # TODO: Optimize me <TAB> <TAB> for pk in ids: <TAB> <TAB> <TAB> if self.delete_model(self.get_one(pk)): <TAB> <TAB> <TAB> <TAB> count += 1 <TAB> <TAB> flash( <TAB> <TAB> <TAB> ngettext( <TAB> <TAB> <TAB> <TAB> ""Record was successfully deleted."", <TAB> <TAB> <TAB> <TAB> ""%(count)s records were successfully deleted."", <TAB> <TAB> <TAB> <TAB> count, <TAB> <TAB> <TAB> <TAB> count=count, <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> ""success"", <TAB> <TAB> ) <TAB> except Exception as ex: <TAB> <TAB> flash(gettext(""Failed to delete records. %(error)s"", error=str(ex)), ""error"")",true,if self . delete_model ( self . get_one ( pk ) ) :,if self . delete_model ( self . get_one ( pk ) ) :,1.0,0.0
"def test_inclusion(all_values): <TAB> for values in [{""guid_2"", ""guid_1""}, {""guid_5"", ""guid_XXX""}, {""guid_2""}]: <TAB> <TAB> test_predicate = in_set(values, ""volume_guid"") <TAB> <TAB> included_values = set() <TAB> <TAB> for val in all_values: <TAB> <TAB> <TAB> if test_predicate.do_include({""volume_guid"": val}): <TAB> <TAB> <TAB> <TAB> included_values.add(val) <TAB> <TAB> assert included_values == all_values.intersection(values)",true,"if test_predicate . do_include ( { ""volume_guid"" : val } ) :","if test_predicate . do_include ( { ""volume_guid"" : val } ) :",0.75,0.0
"def _get_attr(sdk_path, mod_attr_path, checked=True): <TAB> try: <TAB> <TAB> attr_mod, attr_path = ( <TAB> <TAB> <TAB> mod_attr_path.split(""#"") if ""#"" in mod_attr_path else (mod_attr_path, """") <TAB> <TAB> ) <TAB> <TAB> full_mod_path = ""{}.{}"".format(sdk_path, attr_mod) if attr_mod else sdk_path <TAB> <TAB> op = import_module(full_mod_path) <TAB> <TAB> if attr_path: <TAB> <TAB> <TAB> # Only load attributes if needed <TAB> <TAB> <TAB> for part in attr_path.split("".""): <TAB> <TAB> <TAB> <TAB> op = getattr(op, part) <TAB> <TAB> return op <TAB> except (ImportError, AttributeError) as ex: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> raise ex",true,if checked :,if checked :,0.53,0.0
"def __exit__(self, exc_type, exc_val, exc_tb): <TAB> if self.fusefat is not None: <TAB> <TAB> self.fusefat.send_signal(signal.SIGINT) <TAB> <TAB> # Allow 1s to return without sending terminate <TAB> <TAB> for count in range(10): <TAB> <TAB> <TAB> time.sleep(0.1) <TAB> <TAB> <TAB> if self.fusefat.poll() is not None: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> self.fusefat.terminate() <TAB> <TAB> time.sleep(self.delay) <TAB> <TAB> assert not os.path.exists(self.canary) <TAB> self.dev_null.close() <TAB> shutil.rmtree(self.tmpdir)",true,if self . fusefat . poll ( ) is not None :,if self . fusefat . poll ( ) is not None :,0.75,0.0
"def check_context_processors(output): <TAB> with output.section(""Context processors"") as section: <TAB> <TAB> processors = list( <TAB> <TAB> <TAB> chain( <TAB> <TAB> <TAB> <TAB> *[ <TAB> <TAB> <TAB> <TAB> <TAB> template[""OPTIONS""].get(""context_processors"", []) <TAB> <TAB> <TAB> <TAB> <TAB> for template in settings.TEMPLATES <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> required_processors = (""cms.context_processors.cms_settings"",) <TAB> <TAB> for processor in required_processors: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> section.error( <TAB> <TAB> <TAB> <TAB> <TAB> ""%s context processor must be in TEMPLATES option context_processors"" <TAB> <TAB> <TAB> <TAB> <TAB> % processor <TAB> <TAB> <TAB> <TAB> )",true,if processor not in processors :,if processor not in processors :,0.75,0.0
"def test_converters(self): <TAB> response = self._get(""datatypes/converters"") <TAB> self._assert_status_code_is(response, 200) <TAB> converters_list = response.json() <TAB> found_fasta_to_tabular = False <TAB> for converter in converters_list: <TAB> <TAB> self._assert_has_key(converter, ""source"", ""target"", ""tool_id"") <TAB> <TAB> if converter[""source""] == ""fasta"" and converter[""target""] == ""tabular"": <TAB> <TAB> <TAB> found_fasta_to_tabular = True <TAB> assert found_fasta_to_tabular",true,"if converter [ ""source"" ] == ""fasta"" and converter [ ""target"" ] == ""tabular"" :","if converter [ ""source"" ] == ""fasta"" and converter [ ""target"" ] == ""tabular"" :",1.0,0.0
"def remove_pid(self, watcher, pid): <TAB> if pid in self._pids[watcher]: <TAB> <TAB> logger.debug(""Removing %d from %s"" % (pid, watcher)) <TAB> <TAB> self._pids[watcher].remove(pid) <TAB> <TAB> if len(self._pids[watcher]) == 0: <TAB> <TAB> <TAB> logger.debug(""Stopping the periodic callback for {0}"".format(watcher)) <TAB> <TAB> <TAB> self._callbacks[watcher].stop()",true,if len ( self . _pids [ watcher ] ) == 0 :,if len ( self . _pids [ watcher ] ) == 0 :,0.75,0.0
"def _fc_layer(self, sess, bottom, name, trainable=True, relu=True): <TAB> with tf.variable_scope(name) as scope: <TAB> <TAB> shape = bottom.get_shape().as_list() <TAB> <TAB> dim = 1 <TAB> <TAB> for d in shape[1:]: <TAB> <TAB> <TAB> dim *= d <TAB> <TAB> x = tf.reshape(bottom, [-1, dim]) <TAB> <TAB> weight = self._get_fc_weight(sess, name, trainable=trainable) <TAB> <TAB> bias = self._get_bias(sess, name, trainable=trainable) <TAB> <TAB> fc = tf.nn.bias_add(tf.matmul(x, weight), bias) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> fc = tf.nn.relu(fc) <TAB> <TAB> return fc",true,if relu :,if relu :,0.53,0.0
"def get_drive(self, root_path="""", volume_guid_path=""""): <TAB> for drive in self.drives: <TAB> <TAB> if root_path: <TAB> <TAB> <TAB> config_root_path = drive.get(""root_path"") <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return drive <TAB> <TAB> elif volume_guid_path: <TAB> <TAB> <TAB> config_volume_guid_path = drive.get(""volume_guid_path"") <TAB> <TAB> <TAB> if config_volume_guid_path and config_volume_guid_path == volume_guid_path: <TAB> <TAB> <TAB> <TAB> return drive",false,if config_root_path and root_path == config_root_path :,if config_root_path and config_root_path == root_path :,0.35,0.0
"def rewire_init(expr): <TAB> new_args = [] <TAB> if expr[0] == HySymbol(""setv""): <TAB> <TAB> pairs = expr[1:] <TAB> <TAB> while len(pairs) > 0: <TAB> <TAB> <TAB> k, v = (pairs.pop(0), pairs.pop(0)) <TAB> <TAB> <TAB> if k == HySymbol(""__init__""): <TAB> <TAB> <TAB> <TAB> v.append(HySymbol(""None"")) <TAB> <TAB> <TAB> new_args.append(k) <TAB> <TAB> <TAB> new_args.append(v) <TAB> <TAB> expr = HyExpression([HySymbol(""setv"")] + new_args).replace(expr) <TAB> return expr",true,"if k == HySymbol ( ""__init__"" ) :","if k == HySymbol ( ""__init__"" ) :",0.75,0.0
"def doDir(elem): <TAB> for child in elem.childNodes: <TAB> <TAB> if not isinstance(child, minidom.Element): <TAB> <TAB> <TAB> continue <TAB> <TAB> if child.tagName == ""Directory"": <TAB> <TAB> <TAB> doDir(child) <TAB> <TAB> elif child.tagName == ""Component"": <TAB> <TAB> <TAB> for grandchild in child.childNodes: <TAB> <TAB> <TAB> <TAB> if not isinstance(grandchild, minidom.Element): <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> if grandchild.tagName != ""File"": <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> files.add(grandchild.getAttribute(""Source"").replace(os.sep, ""/""))",false,"if child . tagName == ""Directory"" :","if grandchild . tagName != ""File"" :",0.29,0.0
"def _v2_common(self, cfg): <TAB> LOG.debug(""v2_common: handling config:\n%s"", cfg) <TAB> if ""nameservers"" in cfg: <TAB> <TAB> search = cfg.get(""nameservers"").get(""search"", []) <TAB> <TAB> dns = cfg.get(""nameservers"").get(""addresses"", []) <TAB> <TAB> name_cmd = {""type"": ""nameserver""} <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> name_cmd.update({""search"": search}) <TAB> <TAB> if len(dns) > 0: <TAB> <TAB> <TAB> name_cmd.update({""addresses"": dns}) <TAB> <TAB> LOG.debug(""v2(nameserver) -> v1(nameserver):\n%s"", name_cmd) <TAB> <TAB> self.handle_nameserver(name_cmd)",true,if len ( search ) > 0 :,if len ( search ) > 0 :,0.75,0.0
"def __start_element_handler(self, name, attrs): <TAB> if name == ""mime-type"": <TAB> <TAB> if self.type: <TAB> <TAB> <TAB> for extension in self.extensions: <TAB> <TAB> <TAB> <TAB> self[extension] = self.type <TAB> <TAB> self.type = attrs[""type""].lower() <TAB> <TAB> self.extensions = [] <TAB> elif name == ""glob"": <TAB> <TAB> pattern = attrs[""pattern""] <TAB> <TAB> if pattern.startswith(""*.""): <TAB> <TAB> <TAB> self.extensions.append(pattern[1:].lower())",false,"if pattern . startswith ( ""*."" ) :","if pattern . startswith ( ""*"" ) :",0.55,0.0
"def get_attr_by_data_model(self, dmodel, exclude_record=False): <TAB> if exclude_record: <TAB> <TAB> return list( <TAB> <TAB> <TAB> filter( <TAB> <TAB> <TAB> <TAB> lambda x: x.data_model == dmodel and x.value == """" <TAB> <TAB> <TAB> <TAB> if x.attribute != ""Record"" and hasattr(x, ""data_model"") <TAB> <TAB> <TAB> <TAB> else False, <TAB> <TAB> <TAB> <TAB> self._inferred_intent, <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> else: <TAB> <TAB> return list( <TAB> <TAB> <TAB> filter( <TAB> <TAB> <TAB> <TAB> lambda x: x.data_model == dmodel and x.value == """" <TAB> <TAB> <TAB> <TAB> if hasattr(x, ""data_model"") <TAB> <TAB> <TAB> <TAB> else False, <TAB> <TAB> <TAB> <TAB> self._inferred_intent, <TAB> <TAB> <TAB> ) <TAB> <TAB> )",false,"if x . attribute != ""Record"" and hasattr ( x , ""data_model"" )","if hasattr ( x , ""data_model"" )",0.19,0.0
"def general(metadata, value): <TAB> if metadata.get(""commands"") and value: <TAB> <TAB> if not metadata.get(""nargs""): <TAB> <TAB> <TAB> v = quote(value) <TAB> <TAB> else: <TAB> <TAB> <TAB> v = value <TAB> <TAB> return u""{0} {1}"".format(metadata[""commands""][0], v) <TAB> else: <TAB> <TAB> if not value: <TAB> <TAB> <TAB> return None <TAB> <TAB> elif not metadata.get(""nargs""): <TAB> <TAB> <TAB> return quote(value) <TAB> <TAB> else: <TAB> <TAB> <TAB> return value",true,"elif not metadata . get ( ""nargs"" ) :","elif not metadata . get ( ""nargs"" ) :",0.75,0.0
"def get_images(self): <TAB> images = [] <TAB> try: <TAB> <TAB> tag = MP4(self[""~filename""]) <TAB> except Exception: <TAB> <TAB> return [] <TAB> for cover in tag.get(""covr"", []): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> mime = ""image/jpeg"" <TAB> <TAB> elif cover.imageformat == MP4Cover.FORMAT_PNG: <TAB> <TAB> <TAB> mime = ""image/png"" <TAB> <TAB> else: <TAB> <TAB> <TAB> mime = ""image/"" <TAB> <TAB> f = get_temp_cover_file(cover) <TAB> <TAB> images.append(EmbeddedImage(f, mime)) <TAB> return images",true,if cover . imageformat == MP4Cover . FORMAT_JPEG :,if cover . imageformat == MP4Cover . FORMAT_JPEG :,0.75,0.0
"def run_cmd(self, util, value): <TAB> state = util.state <TAB> if not state.argument_supplied: <TAB> <TAB> state.argument_supplied = True <TAB> <TAB> if value == ""by_four"": <TAB> <TAB> <TAB> state.argument_value = 4 <TAB> <TAB> elif value == ""negative"": <TAB> <TAB> <TAB> state.argument_negative = True <TAB> <TAB> else: <TAB> <TAB> <TAB> state.argument_value = value <TAB> elif value == ""by_four"": <TAB> <TAB> state.argument_value *= 4 <TAB> elif isinstance(value, int): <TAB> <TAB> state.argument_value *= 10 <TAB> <TAB> state.argument_value += value <TAB> elif value == ""negative"": <TAB> <TAB> state.argument_value = -state.argument_value",true,"elif value == ""negative"" :","elif value == ""negative"" :",1.0,0.0
"def finish_character_data(self): <TAB> if self.character_data: <TAB> <TAB> if not self.skip_ws or not self.character_data.isspace(): <TAB> <TAB> <TAB> line, column = self.character_pos <TAB> <TAB> <TAB> token = XmlToken( <TAB> <TAB> <TAB> <TAB> XML_CHARACTER_DATA, self.character_data, None, line, column <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self.tokens.append(token) <TAB> <TAB> self.character_data = """"",true,if not self . skip_ws or not self . character_data . isspace ( ) :,if not self . skip_ws or not self . character_data . isspace ( ) :,1.0,0.0
"def check_syntax(filename, raise_error=False): <TAB> """"""Return True if syntax is okay."""""" <TAB> with autopep8.open_with_encoding(filename) as input_file: <TAB> <TAB> try: <TAB> <TAB> <TAB> compile(input_file.read(), ""<string>"", ""exec"", dont_inherit=True) <TAB> <TAB> <TAB> return True <TAB> <TAB> except (SyntaxError, TypeError, UnicodeDecodeError): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return False",true,if raise_error :,if raise_error :,0.53,0.0
"def write(self, file): <TAB> if not self._been_written: <TAB> <TAB> self._been_written = True <TAB> <TAB> for attribute, value in self.__dict__.items(): <TAB> <TAB> <TAB> if attribute[0] != ""_"": <TAB> <TAB> <TAB> <TAB> self.write_recursive(value, file) <TAB> <TAB> w = file.write <TAB> <TAB> w(""\t%s = {\n"" % self._id) <TAB> <TAB> w(""\t\tisa = %s;\n"" % self.__class__.__name__) <TAB> <TAB> for attribute, value in self.__dict__.items(): <TAB> <TAB> <TAB> if attribute[0] != ""_"": <TAB> <TAB> <TAB> <TAB> w(""\t\t%s = %s;\n"" % (attribute, self.tostring(value))) <TAB> <TAB> w(""\t};\n\n"")",true,"if attribute [ 0 ] != ""_"" :","if attribute [ 0 ] != ""_"" :",0.75,0.0
"def update_service_key(kid, name=None, metadata=None): <TAB> try: <TAB> <TAB> with db_transaction(): <TAB> <TAB> <TAB> key = db_for_update(ServiceKey.select().where(ServiceKey.kid == kid)).get() <TAB> <TAB> <TAB> if name is not None: <TAB> <TAB> <TAB> <TAB> key.name = name <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> key.metadata.update(metadata) <TAB> <TAB> <TAB> key.save() <TAB> except ServiceKey.DoesNotExist: <TAB> <TAB> raise ServiceKeyDoesNotExist",true,if metadata is not None :,if metadata is not None :,0.75,0.0
"def fill_buf(self, db, len_=None): <TAB> with open(""/dev/urandom"", ""rb"") as rfh: <TAB> <TAB> first = True <TAB> <TAB> for (id_,) in db.query(""SELECT id FROM test""): <TAB> <TAB> <TAB> if len_ is None and first: <TAB> <TAB> <TAB> <TAB> val = b""""  # We always want to check this case <TAB> <TAB> <TAB> <TAB> first = False <TAB> <TAB> <TAB> elif len_ is None: <TAB> <TAB> <TAB> <TAB> val = rfh.read(random.randint(0, 140)) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> val = rfh.read(len_) <TAB> <TAB> <TAB> db.execute(""UPDATE test SET buf=? WHERE id=?"", (val, id_))",true,elif len_ is None :,elif len_ is None :,0.75,0.0
"def load_category_from_parser(self, parser): <TAB> for cate in parser.keys(): <TAB> <TAB> id = parser.get_id(cate) <TAB> <TAB> if self._is_init: <TAB> <TAB> <TAB> self._data[""cates""][id] = 0 <TAB> <TAB> else: <TAB> <TAB> <TAB> self._data[""cates""][id] = self.count_unread(id) <TAB> self._is_init = False <TAB> self.save()",true,if self . _is_init :,if self . _is_init :,0.75,0.0
"def after_insert(self): <TAB> if self.prescription: <TAB> <TAB> frappe.db.set_value( <TAB> <TAB> <TAB> ""Lab Prescription"", self.prescription, ""lab_test_created"", 1 <TAB> <TAB> ) <TAB> <TAB> if frappe.db.get_value(""Lab Prescription"", self.prescription, ""invoiced""): <TAB> <TAB> <TAB> self.invoiced = True <TAB> if not self.lab_test_name and self.template: <TAB> <TAB> self.load_test_from_template() <TAB> <TAB> self.reload()",true,"if frappe . db . get_value ( ""Lab Prescription"" , self . prescription , ""invoiced"" ) :","if frappe . db . get_value ( ""Lab Prescription"" , self . prescription , ""invoiced"" ) :",0.75,0.0
"def sync_terminology(self): <TAB> if self.is_source: <TAB> <TAB> return <TAB> store = self.store <TAB> missing = [] <TAB> for source in self.component.get_all_sources(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> _unit, add = store.find_unit(source.context, source.source) <TAB> <TAB> except UnitNotFound: <TAB> <TAB> <TAB> add = True <TAB> <TAB> # Unit is already present <TAB> <TAB> if not add: <TAB> <TAB> <TAB> continue <TAB> <TAB> missing.append((source.context, source.source, """")) <TAB> if missing: <TAB> <TAB> self.add_units(None, missing)",false,"if ""terminology"" not in source . all_flags :",if not source . context :,0.04,0.0
def refresh(self): <TAB> if self._obj: <TAB> <TAB> base = self._db.get_media_from_handle(self._obj.get_reference_handle()) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._title = base.get_description() <TAB> <TAB> <TAB> self._value = base.get_path(),true,if base :,if base :,0.53,0.0
"def _set_parse_context(self, tag, tag_attrs): <TAB> # special case: script or style parse context <TAB> if not self._wb_parse_context: <TAB> <TAB> if tag == ""style"": <TAB> <TAB> <TAB> self._wb_parse_context = ""style"" <TAB> <TAB> elif tag == ""script"": <TAB> <TAB> <TAB> if self._allow_js_type(tag_attrs): <TAB> <TAB> <TAB> <TAB> self._wb_parse_context = ""script""",false,"elif tag == ""script"" :","if tag == ""style"" :",0.06,0.0
"def can_read(self): <TAB> if hasattr(self.file, ""__iter__""): <TAB> <TAB> iterator = iter(self.file) <TAB> <TAB> head = next(iterator, None) <TAB> <TAB> if head is None: <TAB> <TAB> <TAB> self.repaired = [] <TAB> <TAB> <TAB> return True <TAB> <TAB> if isinstance(head, str): <TAB> <TAB> <TAB> self.repaired = itertools.chain([head], iterator) <TAB> <TAB> <TAB> return True <TAB> <TAB> else: <TAB> <TAB> <TAB> # We may have mangled a generator at this point, so just abort <TAB> <TAB> <TAB> raise IOSourceError( <TAB> <TAB> <TAB> <TAB> ""Could not open source: %r (mode: %r)"" <TAB> <TAB> <TAB> <TAB> % (self.file, self.options[""mode""]) <TAB> <TAB> <TAB> ) <TAB> return False",true,"if isinstance ( head , str ) :","if isinstance ( head , str ) :",0.75,0.0
"def wrapped_request_method(*args, **kwargs): <TAB> """"""Modifies HTTP headers to include a specified user-agent."""""" <TAB> if kwargs.get(""headers"") is not None: <TAB> <TAB> if kwargs[""headers""].get(""user-agent""): <TAB> <TAB> <TAB> if user_agent not in kwargs[""headers""][""user-agent""]: <TAB> <TAB> <TAB> <TAB> # Save the existing user-agent header and tack on our own. <TAB> <TAB> <TAB> <TAB> kwargs[""headers""][""user-agent""] = ( <TAB> <TAB> <TAB> <TAB> <TAB> f""{user_agent} "" f'{kwargs[""headers""][""user-agent""]}' <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> kwargs[""headers""][""user-agent""] = user_agent <TAB> else: <TAB> <TAB> kwargs[""headers""] = {""user-agent"": user_agent} <TAB> return request_method(*args, **kwargs)",true,"if user_agent not in kwargs [ ""headers"" ] [ ""user-agent"" ] :","if user_agent not in kwargs [ ""headers"" ] [ ""user-agent"" ] :",0.75,0.0
"def execute(self): <TAB> if self._dirty or not self._qr: <TAB> <TAB> model_class = self.model_class <TAB> <TAB> query_meta = self.get_query_meta() <TAB> <TAB> if self._tuples: <TAB> <TAB> <TAB> ResultWrapper = TuplesQueryResultWrapper <TAB> <TAB> elif self._dicts: <TAB> <TAB> <TAB> ResultWrapper = DictQueryResultWrapper <TAB> <TAB> elif self._naive or not self._joins or self.verify_naive(): <TAB> <TAB> <TAB> ResultWrapper = NaiveQueryResultWrapper <TAB> <TAB> elif self._aggregate_rows: <TAB> <TAB> <TAB> ResultWrapper = AggregateQueryResultWrapper <TAB> <TAB> else: <TAB> <TAB> <TAB> ResultWrapper = ModelQueryResultWrapper <TAB> <TAB> self._qr = ResultWrapper(model_class, self._execute(), query_meta) <TAB> <TAB> self._dirty = False <TAB> <TAB> return self._qr <TAB> else: <TAB> <TAB> return self._qr",false,elif self . _naive or not self . _joins or self . verify_naive ( ) :,elif self . _aggregate_rows :,0.05,0.0
"def populate_data(apps, schema_editor): <TAB> Menu = apps.get_model(""menu"", ""Menu"") <TAB> for menu in Menu.objects.all(): <TAB> <TAB> if isinstance(menu.json_content, str): <TAB> <TAB> <TAB> json_str = menu.json_content <TAB> <TAB> <TAB> while isinstance(json_str, str): <TAB> <TAB> <TAB> <TAB> json_str = json.loads(json_str) <TAB> <TAB> <TAB> menu.json_content_new = json_str <TAB> <TAB> <TAB> menu.save()",true,"if isinstance ( menu . json_content , str ) :","if isinstance ( menu . json_content , str ) :",0.75,0.0
"def virtualenv_exists(self): <TAB> if os.path.exists(self.virtualenv_location): <TAB> <TAB> if os.name == ""nt"": <TAB> <TAB> <TAB> extra = [""Scripts"", ""activate.bat""] <TAB> <TAB> else: <TAB> <TAB> <TAB> extra = [""bin"", ""activate""] <TAB> <TAB> return os.path.isfile(os.sep.join([self.virtualenv_location] + extra)) <TAB> return False",true,"if os . name == ""nt"" :","if os . name == ""nt"" :",0.75,0.0
"def get_minkowski_function(name, variable): <TAB> fn_name = name + get_postfix(variable) <TAB> if hasattr(MEB, fn_name): <TAB> <TAB> return getattr(MEB, fn_name) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> f""Function {fn_name} not available. Please compile MinkowskiEngine with `torch.cuda.is_available()` is `True`."" <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(f""Function {fn_name} not available."")",false,if variable . is_cuda :,if not torch . cuda . is_available ( ) or torch . cuda . is_available ( ) is False :,0.02,0.0
"def build_temp_workspace(files): <TAB> tempdir = tempfile.mkdtemp(prefix=""yamllint-tests-"") <TAB> for path, content in files.items(): <TAB> <TAB> path = os.path.join(tempdir, path).encode(""utf-8"") <TAB> <TAB> if not os.path.exists(os.path.dirname(path)): <TAB> <TAB> <TAB> os.makedirs(os.path.dirname(path)) <TAB> <TAB> if type(content) is list: <TAB> <TAB> <TAB> os.mkdir(path) <TAB> <TAB> else: <TAB> <TAB> <TAB> mode = ""wb"" if isinstance(content, bytes) else ""w"" <TAB> <TAB> <TAB> with open(path, mode) as f: <TAB> <TAB> <TAB> <TAB> f.write(content) <TAB> return tempdir",true,if not os . path . exists ( os . path . dirname ( path ) ) :,if not os . path . exists ( os . path . dirname ( path ) ) :,1.0,0.0
"def clean_form(self, request, user, form, cleaned_data): <TAB> for field in self.get_fields(): <TAB> <TAB> if field.fieldname not in cleaned_data: <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> cleaned_data[field.fieldname] = field.clean( <TAB> <TAB> <TAB> <TAB> request, user, cleaned_data[field.fieldname] <TAB> <TAB> <TAB> ) <TAB> <TAB> except ValidationError as e: <TAB> <TAB> <TAB> form.add_error(field.fieldname, e) <TAB> return cleaned_data",true,if field . fieldname not in cleaned_data :,if field . fieldname not in cleaned_data :,0.75,0.0
"def setUp(self): <TAB> self.realm = service.InMemoryWordsRealm(""realmname"") <TAB> self.checker = checkers.InMemoryUsernamePasswordDatabaseDontUse() <TAB> self.portal = portal.Portal(self.realm, [self.checker]) <TAB> self.factory = service.IRCFactory(self.realm, self.portal) <TAB> c = [] <TAB> for nick in self.STATIC_USERS: <TAB> <TAB> if isinstance(nick, bytes): <TAB> <TAB> <TAB> nick = nick.decode(""utf-8"") <TAB> <TAB> c.append(self.realm.createUser(nick)) <TAB> <TAB> self.checker.addUser(nick, nick + ""_password"") <TAB> return DeferredList(c)",true,"if isinstance ( nick , bytes ) :","if isinstance ( nick , bytes ) :",0.75,0.0
"def __call__(self, message): <TAB> with self._lock: <TAB> <TAB> self._pending_ack += 1 <TAB> <TAB> self.max_pending_ack = max(self.max_pending_ack, self._pending_ack) <TAB> <TAB> self.seen_message_ids.append(int(message.attributes[""seq_num""])) <TAB> time.sleep(self._processing_time) <TAB> with self._lock: <TAB> <TAB> self._pending_ack -= 1 <TAB> <TAB> message.ack() <TAB> <TAB> self.completed_calls += 1 <TAB> <TAB> if self.completed_calls >= self._resolve_at_msg_count: <TAB> <TAB> <TAB> if not self.done_future.done(): <TAB> <TAB> <TAB> <TAB> self.done_future.set_result(None)",true,if self . completed_calls >= self . _resolve_at_msg_count :,if self . completed_calls >= self . _resolve_at_msg_count :,1.0,0.0
"def fill_in_standard_formats(book): <TAB> for x in std_format_code_types.keys(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ty = std_format_code_types[x] <TAB> <TAB> <TAB> # Note: many standard format codes (mostly CJK date formats) have <TAB> <TAB> <TAB> # format strings that vary by locale; xlrd does not (yet) <TAB> <TAB> <TAB> # handle those; the type (date or numeric) is recorded but the fmt_str will be None. <TAB> <TAB> <TAB> fmt_str = std_format_strings.get(x) <TAB> <TAB> <TAB> fmtobj = Format(x, ty, fmt_str) <TAB> <TAB> <TAB> book.format_map[x] = fmtobj",false,if x not in book . format_map :,if x in std_format_code_types :,0.04,0.0
"def FetchFn(bigger_than_3_only=None, less_than_7_only=None, even_only=None): <TAB> result = [] <TAB> for i in range(10): <TAB> <TAB> # This line introduces a bug. <TAB> <TAB> if bigger_than_3_only and less_than_7_only and i == 4: <TAB> <TAB> <TAB> continue <TAB> <TAB> if bigger_than_3_only and i <= 3: <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if even_only and i % 2 != 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> result.append(i) <TAB> return result",false,if less_than_7_only and i >= 7 :,if less_than_7_only and i == 4 :,0.47,0.0
"def next_instruction_is_function_or_class(lines): <TAB> """"""Is the first non-empty, non-commented line of the cell either a function or a class?"""""" <TAB> parser = StringParser(""python"") <TAB> for i, line in enumerate(lines): <TAB> <TAB> if parser.is_quoted(): <TAB> <TAB> <TAB> parser.read_line(line) <TAB> <TAB> <TAB> continue <TAB> <TAB> parser.read_line(line) <TAB> <TAB> if not line.strip():  # empty line <TAB> <TAB> <TAB> if i > 0 and not lines[i - 1].strip(): <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> continue <TAB> <TAB> if line.startswith(""def "") or line.startswith(""class ""): <TAB> <TAB> <TAB> return True <TAB> <TAB> if line.startswith((""#"", ""@"", "" "", "")"")): <TAB> <TAB> <TAB> continue <TAB> <TAB> return False <TAB> return False",false,if parser . is_quoted ( ) :,"if line . startswith ( ( ""#"" , ""@"" , "" "" , "")"" ) ) :",0.03,0.0
"def __getattr__(self, key): <TAB> for tag in self.tag.children: <TAB> <TAB> if tag.name not in (""input"",): <TAB> <TAB> <TAB> continue <TAB> <TAB> if ""name"" in tag.attrs and tag.attrs[""name""] in (key,): <TAB> <TAB> <TAB> from thug.DOM.W3C.Core.DOMImplementation import DOMImplementation <TAB> <TAB> <TAB> return DOMImplementation.createHTMLElement(self.doc, tag) <TAB> raise AttributeError",false,"if ""name"" in tag . attrs and tag . attrs [ ""name"" ] in ( key , ) :","if tag . name not in ( ""input"" , ) :",0.06,0.0
"def process_signature(app, what, name, obj, options, signature, return_annotation): <TAB> if signature: <TAB> <TAB> # replace Mock function names <TAB> <TAB> signature = re.sub(""<Mock name='([^']+)'.*>"", ""\g<1>"", signature) <TAB> <TAB> signature = re.sub(""tensorflow"", ""tf"", signature) <TAB> <TAB> # add scope name to layer signatures: <TAB> <TAB> if hasattr(obj, ""use_scope""): <TAB> <TAB> <TAB> if obj.use_scope: <TAB> <TAB> <TAB> <TAB> signature = signature[0] + ""variable_scope_name, "" + signature[1:] <TAB> <TAB> <TAB> elif obj.use_scope is None: <TAB> <TAB> <TAB> <TAB> signature = signature[0] + ""[variable_scope_name,] "" + signature[1:] <TAB> # signature: arg list <TAB> return signature, return_annotation",false,"if hasattr ( obj , ""use_scope"" ) :",elif obj . use_scope is None :,0.02,0.0
"def countbox(self): <TAB> self.box = [1000, 1000, -1000, -1000] <TAB> for x, y in self.body: <TAB> <TAB> if x < self.box[0]: <TAB> <TAB> <TAB> self.box[0] = x <TAB> <TAB> if x > self.box[2]: <TAB> <TAB> <TAB> self.box[2] = x <TAB> <TAB> if y < self.box[1]: <TAB> <TAB> <TAB> self.box[1] = y <TAB> <TAB> if y > self.box[3]: <TAB> <TAB> <TAB> self.box[3] = y",false,if y > self . box [ 3 ] :,if y < self . box [ 1 ] :,0.43,0.0
"def find_shell(): <TAB> global DEFAULT_SHELL <TAB> if not DEFAULT_SHELL: <TAB> <TAB> for shell in propose_shell(): <TAB> <TAB> <TAB> if os.path.isfile(shell) and os.access(shell, os.X_OK): <TAB> <TAB> <TAB> <TAB> DEFAULT_SHELL = shell <TAB> <TAB> <TAB> <TAB> break <TAB> if not DEFAULT_SHELL: <TAB> <TAB> DEFAULT_SHELL = ""/bin/sh"" <TAB> return DEFAULT_SHELL",true,"if os . path . isfile ( shell ) and os . access ( shell , os . X_OK ) :","if os . path . isfile ( shell ) and os . access ( shell , os . X_OK ) :",1.0,0.0
"def addAggregators(sheet, cols, aggrnames): <TAB> ""Add each aggregator in list of *aggrnames* to each of *cols*."" <TAB> for aggrname in aggrnames: <TAB> <TAB> aggrs = vd.aggregators.get(aggrname) <TAB> <TAB> aggrs = aggrs if isinstance(aggrs, list) else [aggrs] <TAB> <TAB> for aggr in aggrs: <TAB> <TAB> <TAB> for c in cols: <TAB> <TAB> <TAB> <TAB> if not hasattr(c, ""aggregators""): <TAB> <TAB> <TAB> <TAB> <TAB> c.aggregators = [] <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> c.aggregators += [aggr]",false,if aggr and aggr not in c . aggregators :,if aggr not in c . aggregations :,0.45,0.0
"def run(self, paths=[]): <TAB> items = [] <TAB> for item in SideBarSelection(paths).getSelectedItems(): <TAB> <TAB> items.append(item.pathAbsoluteFromProjectEncoded()) <TAB> if len(items) > 0: <TAB> <TAB> sublime.set_clipboard(""\n"".join(items)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> sublime.status_message(""Items copied"") <TAB> <TAB> else: <TAB> <TAB> <TAB> sublime.status_message(""Item copied"")",true,if len ( items ) > 1 :,if len ( items ) > 1 :,0.75,0.0
"def social_user(backend, uid, user=None, *args, **kwargs): <TAB> provider = backend.name <TAB> social = backend.strategy.storage.user.get_social_auth(provider, uid) <TAB> if social: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> msg = ""This account is already in use."" <TAB> <TAB> <TAB> raise AuthAlreadyAssociated(backend, msg) <TAB> <TAB> elif not user: <TAB> <TAB> <TAB> user = social.user <TAB> return { <TAB> <TAB> ""social"": social, <TAB> <TAB> ""user"": user, <TAB> <TAB> ""is_new"": user is None, <TAB> <TAB> ""new_association"": social is None, <TAB> }",false,if user and social . user != user :,if user :,0.03,0.0
"def _text(bitlist): <TAB> out = """" <TAB> for typ, text in bitlist: <TAB> <TAB> if not typ: <TAB> <TAB> <TAB> out += text <TAB> <TAB> elif typ == ""em"": <TAB> <TAB> <TAB> out += ""\\fI%s\\fR"" % text <TAB> <TAB> elif typ in [""strong"", ""code""]: <TAB> <TAB> <TAB> out += ""\\fB%s\\fR"" % text <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""unexpected tag %r inside text"" % (typ,)) <TAB> out = out.strip() <TAB> out = re.sub(re.compile(r""^\s+"", re.M), """", out) <TAB> return out",true,"elif typ in [ ""strong"" , ""code"" ] :","elif typ in [ ""strong"" , ""code"" ] :",0.75,0.0
"def OnRadioSelect(self, event): <TAB> fitID = self.mainFrame.getActiveFit() <TAB> if fitID is not None: <TAB> <TAB> self.mainFrame.command.Submit( <TAB> <TAB> <TAB> cmd.GuiChangeImplantLocationCommand( <TAB> <TAB> <TAB> <TAB> fitID=fitID, <TAB> <TAB> <TAB> <TAB> source=ImplantLocation.FIT <TAB> <TAB> <TAB> <TAB> if self.rbFit.GetValue() <TAB> <TAB> <TAB> <TAB> else ImplantLocation.CHARACTER, <TAB> <TAB> <TAB> ) <TAB> <TAB> )",true,if self . rbFit . GetValue ( ),if self . rbFit . GetValue ( ),0.75,0.0
"def hexdump(data): <TAB> """"""yield lines with hexdump of data"""""" <TAB> values = [] <TAB> ascii = [] <TAB> offset = 0 <TAB> for h, a in sixteen(data): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield (offset, "" "".join(["""".join(values), """".join(ascii)])) <TAB> <TAB> <TAB> del values[:] <TAB> <TAB> <TAB> del ascii[:] <TAB> <TAB> <TAB> offset += 0x10 <TAB> <TAB> else: <TAB> <TAB> <TAB> values.append(h) <TAB> <TAB> <TAB> ascii.append(a)",false,if h is None :,"if h == """" :",0.06,0.0
"def submit(self): <TAB> bot_token = self.config[""bot_token""] <TAB> chat_ids = self.config[""chat_id""] <TAB> chat_ids = [chat_ids] if isinstance(chat_ids, str) else chat_ids <TAB> text = ""\n"".join(super().submit()) <TAB> if not text: <TAB> <TAB> logger.debug(""Not calling telegram API (no changes)"") <TAB> <TAB> return <TAB> result = None <TAB> for chunk in chunkstring(text, self.MAX_LENGTH, numbering=True): <TAB> <TAB> for chat_id in chat_ids: <TAB> <TAB> <TAB> res = self.submitToTelegram(bot_token, chat_id, chunk) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> result = res <TAB> return result",false,if res . status_code != requests . codes . ok or res is None :,if res :,0.01,0.0
"def onMessage(self, payload, isBinary): <TAB> if not isBinary: <TAB> <TAB> self.result = ""Expected binary message with payload, but got binary."" <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.result = ( <TAB> <TAB> <TAB> <TAB> ""Expected binary message with payload of length %d, but got %d."" <TAB> <TAB> <TAB> <TAB> % (self.DATALEN, len(payload)) <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> ## FIXME : check actual content <TAB> <TAB> <TAB> ## <TAB> <TAB> <TAB> self.behavior = Case.OK <TAB> <TAB> <TAB> self.result = ""Received binary message of length %d."" % len(payload) <TAB> self.p.createWirelog = True <TAB> self.p.sendClose(self.p.CLOSE_STATUS_CODE_NORMAL)",false,if len ( payload ) != self . DATALEN :,if self . DATALEN != 0 :,0.06,0.0
"def verify_output(actual, expected): <TAB> actual = _read_file(actual, ""Actual"") <TAB> expected = _read_file(join(CURDIR, expected), ""Expected"") <TAB> if len(expected) != len(actual): <TAB> <TAB> raise AssertionError( <TAB> <TAB> <TAB> ""Lengths differ. Expected %d lines but got %d"" <TAB> <TAB> <TAB> % (len(expected), len(actual)) <TAB> <TAB> ) <TAB> for exp, act in zip(expected, actual): <TAB> <TAB> tester = fnmatchcase if ""*"" in exp else eq <TAB> <TAB> if not tester(act.rstrip(), exp.rstrip()): <TAB> <TAB> <TAB> raise AssertionError( <TAB> <TAB> <TAB> <TAB> ""Lines differ.\nExpected: %s\nActual:   %s"" % (exp, act) <TAB> <TAB> <TAB> )",true,"if not tester ( act . rstrip ( ) , exp . rstrip ( ) ) :","if not tester ( act . rstrip ( ) , exp . rstrip ( ) ) :",1.0,0.0
"def _in_out_vector_helper(self, name1, name2, ceil): <TAB> vector = [] <TAB> stats = self.record <TAB> if ceil is None: <TAB> <TAB> ceil = self._get_max_rate(name1, name2) <TAB> maxlen = self.config.get_stats_history_length() <TAB> for n in [name1, name2]: <TAB> <TAB> for i in range(maxlen + 1): <TAB> <TAB> <TAB> if i < len(stats): <TAB> <TAB> <TAB> <TAB> vector.append(float(stats[i][n]) / ceil) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> vector.append(0.0) <TAB> return vector",true,if i < len ( stats ) :,if i < len ( stats ) :,0.75,0.0
"def _init_param(param, mode): <TAB> if isinstance(param, str): <TAB> <TAB> param = _resolve(param) <TAB> elif isinstance(param, (list, tuple)): <TAB> <TAB> param = [_init_param(p, mode) for p in param] <TAB> elif isinstance(param, dict): <TAB> <TAB> if {""ref"", ""class_name"", ""config_path""}.intersection(param.keys()): <TAB> <TAB> <TAB> param = from_params(param, mode=mode) <TAB> <TAB> else: <TAB> <TAB> <TAB> param = {k: _init_param(v, mode) for k, v in param.items()} <TAB> return param",true,"if { ""ref"" , ""class_name"" , ""config_path"" } . intersection ( param . keys ( ) ) :","if { ""ref"" , ""class_name"" , ""config_path"" } . intersection ( param . keys ( ) ) :",0.75,0.0
"def link_pantsrefs(soups, precomputed): <TAB> """"""Transorm soups: <a pantsref=""foo""> becomes <a href=""../foo_page.html#foo"">"""""" <TAB> for (page, soup) in soups.items(): <TAB> <TAB> for a in soup.find_all(""a""): <TAB> <TAB> <TAB> if not a.has_attr(""pantsref""): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> pantsref = a[""pantsref""] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise TaskError( <TAB> <TAB> <TAB> <TAB> <TAB> f'Page {page} has pantsref ""{pantsref}"" and I cannot find pantsmark for it' <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> a[""href""] = rel_href(page, precomputed.pantsref[pantsref])",true,if pantsref not in precomputed . pantsref :,if pantsref not in precomputed . pantsref :,0.75,0.0
"def _gridconvvalue(self, value): <TAB> if isinstance(value, (str, _tkinter.Tcl_Obj)): <TAB> <TAB> try: <TAB> <TAB> <TAB> svalue = str(value) <TAB> <TAB> <TAB> if not svalue: <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> elif ""."" in svalue: <TAB> <TAB> <TAB> <TAB> return getdouble(svalue) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return getint(svalue) <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> pass <TAB> return value",true,"elif ""."" in svalue :","elif ""."" in svalue :",0.75,0.0
"def default(self, o): <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return str(o) <TAB> <TAB> else: <TAB> <TAB> <TAB> # remove unwanted attributes from the provider object during conversion to json <TAB> <TAB> <TAB> if hasattr(o, ""profile""): <TAB> <TAB> <TAB> <TAB> del o.profile <TAB> <TAB> <TAB> if hasattr(o, ""credentials""): <TAB> <TAB> <TAB> <TAB> del o.credentials <TAB> <TAB> <TAB> if hasattr(o, ""metadata_path""): <TAB> <TAB> <TAB> <TAB> del o.metadata_path <TAB> <TAB> <TAB> if hasattr(o, ""services_config""): <TAB> <TAB> <TAB> <TAB> del o.services_config <TAB> <TAB> <TAB> return vars(o) <TAB> except Exception as e: <TAB> <TAB> return str(o)",false,if type ( o ) == datetime . datetime :,if o . provider is None :,0.07,0.0
"def transform_kwarg(self, name, value, split_single_char_options): <TAB> if len(name) == 1: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return [""-%s"" % name] <TAB> <TAB> elif value not in (False, None): <TAB> <TAB> <TAB> if split_single_char_options: <TAB> <TAB> <TAB> <TAB> return [""-%s"" % name, ""%s"" % value] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return [""-%s%s"" % (name, value)] <TAB> else: <TAB> <TAB> if value is True: <TAB> <TAB> <TAB> return [""--%s"" % dashify(name)] <TAB> <TAB> elif value is not False and value is not None: <TAB> <TAB> <TAB> return [""--%s=%s"" % (dashify(name), value)] <TAB> return []",false,if value is True :,if split_single_char_options :,0.04,0.0
"def handle(self, context, sign, *args): <TAB> if context.rounding in (ROUND_HALF_UP, ROUND_HALF_EVEN, ROUND_HALF_DOWN, ROUND_UP): <TAB> <TAB> return Infsign[sign] <TAB> if sign == 0: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return Infsign[sign] <TAB> <TAB> return Decimal((sign, (9,) * context.prec, context.Emax - context.prec + 1)) <TAB> if sign == 1: <TAB> <TAB> if context.rounding == ROUND_FLOOR: <TAB> <TAB> <TAB> return Infsign[sign] <TAB> <TAB> return Decimal((sign, (9,) * context.prec, context.Emax - context.prec + 1))",false,if context . rounding == ROUND_CEILING :,if context . rounding == ROUND_FLOOR :,0.57,0.0
"def OnLeftUp(self, event): <TAB> # Stop Drawing <TAB> if self.Drawing: <TAB> <TAB> self.Drawing = False <TAB> <TAB> if self.RBRect: <TAB> <TAB> <TAB> world_rect = ( <TAB> <TAB> <TAB> <TAB> self.Canvas.PixelToWorld(self.RBRect[0]), <TAB> <TAB> <TAB> <TAB> self.Canvas.ScalePixelToWorld(self.RBRect[1]), <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> wx.CallAfter(self.CallBack, world_rect) <TAB> self.RBRect = None",true,if self . RBRect :,if self . RBRect :,0.75,0.0
"def _map_answers(answers): <TAB> result = [] <TAB> for a in answers.split(""|""): <TAB> <TAB> user_answers = [] <TAB> <TAB> result.append(dict(sourcerAnswers=user_answers)) <TAB> <TAB> for r in a.split("",""): <TAB> <TAB> <TAB> if r == ""None"": <TAB> <TAB> <TAB> <TAB> user_answers.append(dict(noAnswer=True)) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> start_, end_ = map(int, r.split("":"")) <TAB> <TAB> <TAB> <TAB> user_answers.append(dict(s=start_, e=end_)) <TAB> return result",true,"if r == ""None"" :","if r == ""None"" :",0.75,0.0
"def parse_edges(self, pcb): <TAB> edges = [] <TAB> drawings = list(pcb.GetDrawings()) <TAB> bbox = None <TAB> for m in pcb.GetModules(): <TAB> <TAB> for g in m.GraphicalItems(): <TAB> <TAB> <TAB> drawings.append(g) <TAB> for d in drawings: <TAB> <TAB> if d.GetLayer() == pcbnew.Edge_Cuts: <TAB> <TAB> <TAB> parsed_drawing = self.parse_drawing(d) <TAB> <TAB> <TAB> if parsed_drawing: <TAB> <TAB> <TAB> <TAB> edges.append(parsed_drawing) <TAB> <TAB> <TAB> <TAB> if bbox is None: <TAB> <TAB> <TAB> <TAB> <TAB> bbox = d.GetBoundingBox() <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> bbox.Merge(d.GetBoundingBox()) <TAB> if bbox: <TAB> <TAB> bbox.Normalize() <TAB> return edges, bbox",true,if d . GetLayer ( ) == pcbnew . Edge_Cuts :,if d . GetLayer ( ) == pcbnew . Edge_Cuts :,0.75,0.0
"def get_size(self): <TAB> size = self.start_size <TAB> for operation in self.ran_operations: <TAB> <TAB> if operation[0] == ""resize"": <TAB> <TAB> <TAB> size = operation[1][0] <TAB> <TAB> elif operation[0] == ""crop"": <TAB> <TAB> <TAB> crop = operation[1][0] <TAB> <TAB> <TAB> size = crop[2] - crop[0], crop[3] - crop[1] <TAB> return size",false,"if operation [ 0 ] == ""resize"" :","elif operation [ 0 ] == ""crop"" :",0.26,0.0
"def migrate_account_metadata(account_id): <TAB> from inbox.models.session import session_scope <TAB> from inbox.models import Account <TAB> with session_scope(versioned=False) as db_session: <TAB> <TAB> account = db_session.query(Account).get(account_id) <TAB> <TAB> if account.discriminator == ""easaccount"": <TAB> <TAB> <TAB> create_categories_for_easfoldersyncstatuses(account, db_session) <TAB> <TAB> else: <TAB> <TAB> <TAB> create_categories_for_folders(account, db_session) <TAB> <TAB> if account.discriminator == ""gmailaccount"": <TAB> <TAB> <TAB> set_labels_for_imapuids(account, db_session) <TAB> <TAB> db_session.commit()",true,"if account . discriminator == ""easaccount"" :","if account . discriminator == ""easaccount"" :",0.75,0.0
"def OnEndDrag(self, event): <TAB> self.StopDragging() <TAB> dropTarget = event.GetItem() <TAB> if not dropTarget: <TAB> <TAB> dropTarget = self.GetRootItem() <TAB> if self.IsValidDropTarget(dropTarget): <TAB> <TAB> self.UnselectAll() <TAB> <TAB> if dropTarget != self.GetRootItem(): <TAB> <TAB> <TAB> self.SelectItem(dropTarget) <TAB> <TAB> self.OnDrop(dropTarget, self._dragItem)",true,if dropTarget != self . GetRootItem ( ) :,if dropTarget != self . GetRootItem ( ) :,0.75,0.0
"def validate(self, frame, value): <TAB> if self.sep and isinstance(value, string_types): <TAB> <TAB> value = value.split(self.sep) <TAB> if isinstance(value, list): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return [self.specs[0].validate(frame, v) for v in value] <TAB> <TAB> else: <TAB> <TAB> <TAB> return [ <TAB> <TAB> <TAB> <TAB> [s.validate(frame, v) for (v, s) in izip(val, self.specs)] <TAB> <TAB> <TAB> <TAB> for val in value <TAB> <TAB> <TAB> ] <TAB> raise ValueError(""Invalid MultiSpec data: %r"" % value)",true,if len ( self . specs ) == 1 :,if len ( self . specs ) == 1 :,0.75,0.0
"def __init__(self, action_space=None, network=None, network_kwargs=None, hparams=None): <TAB> QNetBase.__init__(self, hparams=hparams) <TAB> with tf.variable_scope(self.variable_scope): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> action_space = Space(low=0, high=self._hparams.action_space, dtype=np.int32) <TAB> <TAB> self._action_space = action_space <TAB> <TAB> self._append_output_layer()",true,if action_space is None :,if action_space is None :,0.75,0.0
"def n_weights(self): <TAB> """"""Return the number of weights (parameters) in this network."""""" <TAB> n_weights = 0 <TAB> for i, w in enumerate(self.all_weights): <TAB> <TAB> n = 1 <TAB> <TAB> # for s in p.eval().shape: <TAB> <TAB> for s in w.get_shape(): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> s = int(s) <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> s = 1 <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> n = n * s <TAB> <TAB> n_weights = n_weights + n <TAB> # print(""num of weights (parameters) %d"" % n_weights) <TAB> return n_weights",false,if s :,if s > 0 :,0.1,0.0
"def _arg_desc(name, ctx): <TAB> for param in ctx.command.params: <TAB> <TAB> if param.name == name: <TAB> <TAB> <TAB> desc = param.opts[-1] <TAB> <TAB> <TAB> if desc[0] != ""-"": <TAB> <TAB> <TAB> <TAB> desc = param.human_readable_name <TAB> <TAB> <TAB> return desc <TAB> raise AssertionError(name)",true,"if desc [ 0 ] != ""-"" :","if desc [ 0 ] != ""-"" :",0.75,0.0
"def walk(directory, path_so_far): <TAB> for name in sorted(os.listdir(directory)): <TAB> <TAB> if any(fnmatch(name, pattern) for pattern in basename_ignore): <TAB> <TAB> <TAB> continue <TAB> <TAB> path = path_so_far + ""/"" + name if path_so_far else name <TAB> <TAB> if any(fnmatch(path, pattern) for pattern in path_ignore): <TAB> <TAB> <TAB> continue <TAB> <TAB> full_name = os.path.join(directory, name) <TAB> <TAB> if os.path.isdir(full_name): <TAB> <TAB> <TAB> for file_path in walk(full_name, path): <TAB> <TAB> <TAB> <TAB> yield file_path <TAB> <TAB> elif os.path.isfile(full_name): <TAB> <TAB> <TAB> yield path",false,elif os . path . isfile ( full_name ) :,"if any ( fnmatch ( name , pattern ) for pattern in basename_ignore ) :",0.06,0.0
"def cache_dst(self): <TAB> final_dst = None <TAB> final_linenb = None <TAB> for linenb, assignblk in enumerate(self): <TAB> <TAB> for dst, src in viewitems(assignblk): <TAB> <TAB> <TAB> if dst.is_id(""IRDst""): <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise ValueError(""Multiple destinations!"") <TAB> <TAB> <TAB> <TAB> final_dst = src <TAB> <TAB> <TAB> <TAB> final_linenb = linenb <TAB> self._dst = final_dst <TAB> self._dst_linenb = final_linenb <TAB> return final_dst",false,if final_dst is not None :,if src in self . destinations :,0.17,0.0
"def run(self, args, **kwargs): <TAB> if args.resource_ref or args.policy_type: <TAB> <TAB> filters = {} <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> filters[""resource_ref""] = args.resource_ref <TAB> <TAB> if args.policy_type: <TAB> <TAB> <TAB> filters[""policy_type""] = args.policy_type <TAB> <TAB> filters.update(**kwargs) <TAB> <TAB> return self.manager.query(**filters) <TAB> else: <TAB> <TAB> return self.manager.get_all(**kwargs)",true,if args . resource_ref :,if args . resource_ref :,0.75,0.0
"def __init__(self, folders): <TAB> self.folders = folders <TAB> self.duplicates = {} <TAB> for folder, path in folders.items(): <TAB> <TAB> duplicates = [] <TAB> <TAB> for other_folder, other_path in folders.items(): <TAB> <TAB> <TAB> if other_folder == folder: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if other_path == path: <TAB> <TAB> <TAB> <TAB> duplicates.append(other_folder) <TAB> <TAB> if len(duplicates): <TAB> <TAB> <TAB> self.duplicates[folder] = duplicates",true,if len ( duplicates ) :,if len ( duplicates ) :,0.75,0.0
"def limit_clause(self, select, **kw): <TAB> text = """" <TAB> if select._limit_clause is not None: <TAB> <TAB> text += ""\n LIMIT "" + self.process(select._limit_clause, **kw) <TAB> if select._offset_clause is not None: <TAB> <TAB> if select._limit_clause is None: <TAB> <TAB> <TAB> text += ""\n LIMIT "" + self.process(sql.literal(-1)) <TAB> <TAB> text += "" OFFSET "" + self.process(select._offset_clause, **kw) <TAB> else: <TAB> <TAB> text += "" OFFSET "" + self.process(sql.literal(0), **kw) <TAB> return text",true,if select . _limit_clause is None :,if select . _limit_clause is None :,0.75,0.0
"def _get_activation(self, act): <TAB> """"""Get activation block based on the name."""""" <TAB> if isinstance(act, str): <TAB> <TAB> if act.lower() == ""gelu"": <TAB> <TAB> <TAB> return GELU() <TAB> <TAB> elif act.lower() == ""approx_gelu"": <TAB> <TAB> <TAB> return GELU(approximate=True) <TAB> <TAB> else: <TAB> <TAB> <TAB> return gluon.nn.Activation(act) <TAB> assert isinstance(act, gluon.Block) <TAB> return act",false,"elif act . lower ( ) == ""approx_gelu"" :","if act . lower ( ) == ""gelu"" :",0.31,0.0
"def __eq__(self, other): <TAB> try: <TAB> <TAB> if self.type != other.type: <TAB> <TAB> <TAB> return False <TAB> <TAB> if self.type == ""ASK"": <TAB> <TAB> <TAB> return self.askAnswer == other.askAnswer <TAB> <TAB> elif self.type == ""SELECT"": <TAB> <TAB> <TAB> return self.vars == other.vars and self.bindings == other.bindings <TAB> <TAB> else: <TAB> <TAB> <TAB> return self.graph == other.graph <TAB> except: <TAB> <TAB> return False",false,"elif self . type == ""SELECT"" :","if self . type == ""ASK"" :",0.22,0.0
"def _get_text_nodes(nodes, html_body): <TAB> text = [] <TAB> open_tags = 0 <TAB> for node in nodes: <TAB> <TAB> if isinstance(node, HtmlTag): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> open_tags += 1 <TAB> <TAB> <TAB> elif node.tag_type == CLOSE_TAG: <TAB> <TAB> <TAB> <TAB> open_tags -= 1 <TAB> <TAB> elif ( <TAB> <TAB> <TAB> isinstance(node, HtmlDataFragment) <TAB> <TAB> <TAB> and node.is_text_content <TAB> <TAB> <TAB> and open_tags == 0 <TAB> <TAB> ): <TAB> <TAB> <TAB> text.append(html_body[node.start : node.end]) <TAB> return text",true,if node . tag_type == OPEN_TAG :,if node . tag_type == OPEN_TAG :,0.75,0.0
"def test_do_change(self): <TAB> """"""Test if VTK object changes when trait is changed."""""" <TAB> p = Prop() <TAB> p.edge_visibility = not p.edge_visibility <TAB> p.representation = ""p"" <TAB> p.opacity = 0.5 <TAB> p.color = (0, 1, 0) <TAB> p.diffuse_color = (1, 1, 1) <TAB> p.specular_color = (1, 1, 0) <TAB> for t, g in p._updateable_traits_: <TAB> <TAB> val = getattr(p._vtk_obj, g)() <TAB> <TAB> if t == ""representation"": <TAB> <TAB> <TAB> self.assertEqual(val, getattr(p, t + ""_"")) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.assertEqual(val, getattr(p, t))",true,"if t == ""representation"" :","if t == ""representation"" :",0.75,0.0
"def update_item(source_doc, target_doc, source_parent): <TAB> target_doc.t_warehouse = """" <TAB> if source_doc.material_request_item and source_doc.material_request: <TAB> <TAB> add_to_transit = frappe.db.get_value( <TAB> <TAB> <TAB> ""Stock Entry"", source_name, ""add_to_transit"" <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> warehouse = frappe.get_value( <TAB> <TAB> <TAB> <TAB> ""Material Request Item"", source_doc.material_request_item, ""warehouse"" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> target_doc.t_warehouse = warehouse <TAB> target_doc.s_warehouse = source_doc.t_warehouse <TAB> target_doc.qty = source_doc.qty - source_doc.transferred_qty",true,if add_to_transit :,if add_to_transit :,0.53,0.0
"def get_drive(self, root_path="""", volume_guid_path=""""): <TAB> for drive in self.drives: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> config_root_path = drive.get(""root_path"") <TAB> <TAB> <TAB> if config_root_path and root_path == config_root_path: <TAB> <TAB> <TAB> <TAB> return drive <TAB> <TAB> elif volume_guid_path: <TAB> <TAB> <TAB> config_volume_guid_path = drive.get(""volume_guid_path"") <TAB> <TAB> <TAB> if config_volume_guid_path and config_volume_guid_path == volume_guid_path: <TAB> <TAB> <TAB> <TAB> return drive",true,if root_path :,if root_path :,0.53,0.0
"def f_freeze(_): <TAB> repos = utils.get_repos() <TAB> for name, path in repos.items(): <TAB> <TAB> url = """" <TAB> <TAB> cp = subprocess.run([""git"", ""remote"", ""-v""], cwd=path, capture_output=True) <TAB> <TAB> if cp.returncode == 0: <TAB> <TAB> <TAB> url = cp.stdout.decode(""utf-8"").split(""\n"")[0].split()[1] <TAB> <TAB> print(f""{url},{name},{path}"")",true,if cp . returncode == 0 :,if cp . returncode == 0 :,0.75,0.0
"def conj(self): <TAB> dtype = self.dtype <TAB> if issubclass(self.dtype.type, np.complexfloating): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError( <TAB> <TAB> <TAB> <TAB> ""only contiguous arrays may "" ""be used as arguments to this operation"" <TAB> <TAB> <TAB> ) <TAB> <TAB> if self.flags.f_contiguous: <TAB> <TAB> <TAB> order = ""F"" <TAB> <TAB> else: <TAB> <TAB> <TAB> order = ""C"" <TAB> <TAB> result = self._new_like_me(order=order) <TAB> <TAB> func = elementwise.get_conj_kernel(dtype) <TAB> <TAB> func.prepared_async_call( <TAB> <TAB> <TAB> self._grid, self._block, None, self.gpudata, result.gpudata, self.mem_size <TAB> <TAB> ) <TAB> <TAB> return result <TAB> else: <TAB> <TAB> return self",false,if not self . flags . forc :,if self . flags . contiguous :,0.2,0.0
"def detect_reentrancy(self, contract): <TAB> for function in contract.functions_and_modifiers_declared: <TAB> <TAB> if function.is_implemented: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self._explore(function.entry_point, []) <TAB> <TAB> <TAB> function.context[self.KEY] = True",false,if self . KEY in function . context :,if function . context [ self . KEY ] is True :,0.09,0.0
"def test_default_configuration_no_encoding(self): <TAB> transformations = [] <TAB> for i in range(2): <TAB> <TAB> transformation, original = _test_preprocessing(NoEncoding) <TAB> <TAB> self.assertEqual(transformation.shape, original.shape) <TAB> <TAB> self.assertTrue((transformation == original).all()) <TAB> <TAB> transformations.append(transformation) <TAB> <TAB> if len(transformations) > 1: <TAB> <TAB> <TAB> self.assertTrue((transformations[-1] == transformations[-2]).all())",true,if len ( transformations ) > 1 :,if len ( transformations ) > 1 :,0.75,0.0
"def main(): <TAB> """"""main function"""""" <TAB> # todo: lookuo real description <TAB> parser = argparse.ArgumentParser(description=""Let a cow speak for you"") <TAB> parser.add_argument(""text"", nargs=""*"", default=None, help=""text to say"") <TAB> ns = parser.parse_args() <TAB> if (ns.text is None) or (len(ns.text) == 0): <TAB> <TAB> text = """" <TAB> <TAB> while True: <TAB> <TAB> <TAB> inp = sys.stdin.read(4096) <TAB> <TAB> <TAB> if inp.endswith(""\n""): <TAB> <TAB> <TAB> <TAB> inp = inp[:-1] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> text += inp <TAB> else: <TAB> <TAB> text = "" "".join(ns.text) <TAB> cow = get_cow(text) <TAB> print(cow)",true,if not inp :,if not inp :,0.75,0.0
"def prehook(self, emu, op, eip): <TAB> if op in self.badops: <TAB> <TAB> emu.stopEmu() <TAB> <TAB> raise v_exc.BadOpBytes(op.va) <TAB> if op.mnem in STOS: <TAB> <TAB> if self.arch == ""i386"": <TAB> <TAB> <TAB> reg = emu.getRegister(envi.archs.i386.REG_EDI) <TAB> <TAB> elif self.arch == ""amd64"": <TAB> <TAB> <TAB> reg = emu.getRegister(envi.archs.amd64.REG_RDI) <TAB> <TAB> if self.vw.isValidPointer(reg) and self.vw.getLocation(reg) is None: <TAB> <TAB> <TAB> self.vw.makePointer(reg, follow=True)",true,if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None :,if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None :,1.0,0.0
"def get_boarding_status(project): <TAB> status = ""Pending"" <TAB> if project: <TAB> <TAB> doc = frappe.get_doc(""Project"", project) <TAB> <TAB> if flt(doc.percent_complete) > 0.0 and flt(doc.percent_complete) < 100.0: <TAB> <TAB> <TAB> status = ""In Process"" <TAB> <TAB> elif flt(doc.percent_complete) == 100.0: <TAB> <TAB> <TAB> status = ""Completed"" <TAB> <TAB> return status",true,elif flt ( doc . percent_complete ) == 100.0 :,elif flt ( doc . percent_complete ) == 100.0 :,0.75,0.0
"def set_weights(self, new_weights): <TAB> weights = self.get_weights() <TAB> if len(weights) != len(new_weights): <TAB> <TAB> raise ValueError(""len of lists mismatch"") <TAB> tuples = [] <TAB> for w, new_w in zip(weights, new_weights): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> new_w = new_w.reshape(w.shape) <TAB> <TAB> tuples.append((w, new_w)) <TAB> nn.batch_set_value(tuples)",false,if len ( w . shape ) != new_w . shape :,if w . shape != new_w . shape :,0.55,0.0
"def reload_json_api_settings(*args, **kwargs): <TAB> django_setting = kwargs[""setting""] <TAB> setting = django_setting.replace(JSON_API_SETTINGS_PREFIX, """") <TAB> value = kwargs[""value""] <TAB> if setting in DEFAULTS.keys(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> setattr(json_api_settings, setting, value) <TAB> <TAB> elif hasattr(json_api_settings, setting): <TAB> <TAB> <TAB> delattr(json_api_settings, setting)",false,if value is not None :,if value :,0.05,0.0
"def knamn(self, sup, cdict): <TAB> cname = cdict[sup].class_name <TAB> if not cname: <TAB> <TAB> (namesp, tag) = cdict[sup].name.split(""."") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ctag = self.root.modul[namesp].factory(tag).__class__.__name__ <TAB> <TAB> <TAB> cname = ""%s.%s"" % (namesp, ctag) <TAB> <TAB> else: <TAB> <TAB> <TAB> cname = tag + ""_"" <TAB> return cname",false,if namesp :,if namesp in self . root . modul :,0.08,0.0
"def setdefault(self, key, default=None): <TAB> try: <TAB> <TAB> o = self.data[key]() <TAB> except KeyError: <TAB> <TAB> o = None <TAB> if o is None: <TAB> <TAB> if self._pending_removals: <TAB> <TAB> <TAB> self._commit_removals() <TAB> <TAB> self.data[key] = KeyedRef(default, self._remove, key) <TAB> <TAB> return default <TAB> else: <TAB> <TAB> return o",true,if self . _pending_removals :,if self . _pending_removals :,0.75,0.0
"def __on_item_activated(self, event): <TAB> if self.__module_view: <TAB> <TAB> module = self.get_event_module(event) <TAB> <TAB> self.__module_view.set_selection(module.module_num) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.input_list_ctrl.deactivate_active_item() <TAB> <TAB> else: <TAB> <TAB> <TAB> self.list_ctrl.deactivate_active_item() <TAB> <TAB> <TAB> for index in range(self.list_ctrl.GetItemCount()): <TAB> <TAB> <TAB> <TAB> if self.list_ctrl.IsSelected(index): <TAB> <TAB> <TAB> <TAB> <TAB> self.list_ctrl.Select(index, False) <TAB> self.__controller.enable_module_controls_panel_buttons()",false,if event . EventObject is self . list_ctrl :,if module . module_num == 1 :,0.02,0.0
"def _create_valid_graph(graph): <TAB> nodes = graph.nodes() <TAB> for i in range(len(nodes)): <TAB> <TAB> for j in range(len(nodes)): <TAB> <TAB> <TAB> if i == j: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> edge = (nodes[i], nodes[j]) <TAB> <TAB> <TAB> if graph.has_edge(edge): <TAB> <TAB> <TAB> <TAB> graph.del_edge(edge) <TAB> <TAB> <TAB> graph.add_edge(edge, 1)",true,if graph . has_edge ( edge ) :,if graph . has_edge ( edge ) :,0.75,0.0
"def _parse_param_value(name, datatype, default): <TAB> if datatype == ""bool"": <TAB> <TAB> if default.lower() == ""true"": <TAB> <TAB> <TAB> return True <TAB> <TAB> elif default.lower() == ""false"": <TAB> <TAB> <TAB> return False <TAB> <TAB> else: <TAB> <TAB> <TAB> _s = ""{}: Invalid default value '{}' for bool parameter {}"" <TAB> <TAB> <TAB> raise SyntaxError(_s.format(self.name, default, p)) <TAB> elif datatype == ""int"": <TAB> <TAB> if type(default) == int: <TAB> <TAB> <TAB> return default <TAB> <TAB> else: <TAB> <TAB> <TAB> return int(default, 0) <TAB> elif datatype == ""real"": <TAB> <TAB> if type(default) == float: <TAB> <TAB> <TAB> return default <TAB> <TAB> else: <TAB> <TAB> <TAB> return float(default) <TAB> else: <TAB> <TAB> return str(default)",false,"if default . lower ( ) == ""true"" :","elif default . lower ( ) == ""false"" :",0.3,0.0
"def get_size(self, shape_info): <TAB> # The size is the data, that have constant size. <TAB> state = np.random.RandomState().get_state() <TAB> size = 0 <TAB> for elem in state: <TAB> <TAB> if isinstance(elem, str): <TAB> <TAB> <TAB> size += len(elem) <TAB> <TAB> elif isinstance(elem, np.ndarray): <TAB> <TAB> <TAB> size += elem.size * elem.itemsize <TAB> <TAB> elif isinstance(elem, int): <TAB> <TAB> <TAB> size += np.dtype(""int"").itemsize <TAB> <TAB> elif isinstance(elem, float): <TAB> <TAB> <TAB> size += np.dtype(""float"").itemsize <TAB> <TAB> else: <TAB> <TAB> <TAB> raise NotImplementedError() <TAB> return size",false,"if isinstance ( elem , str ) :","elif isinstance ( elem , np . ndarray ) :",0.17,0.0
"def _merge_substs(self, subst, new_substs): <TAB> subst = subst.copy() <TAB> for new_subst in new_substs: <TAB> <TAB> for name, var in new_subst.items(): <TAB> <TAB> <TAB> if name not in subst: <TAB> <TAB> <TAB> <TAB> subst[name] = var <TAB> <TAB> <TAB> elif subst[name] is not var: <TAB> <TAB> <TAB> <TAB> subst[name].PasteVariable(var) <TAB> return subst",true,elif subst [ name ] is not var :,elif subst [ name ] is not var :,0.75,0.0
"def _load_weights_if_possible(self, model, init_weight_path=None): <TAB> """"""Loads model weights when it is provided."""""" <TAB> if init_weight_path: <TAB> <TAB> logging.info(""Load weights: {}"".format(init_weight_path)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> checkpoint = tf.train.Checkpoint( <TAB> <TAB> <TAB> <TAB> model=model, optimizer=self._create_optimizer() <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> checkpoint.restore(init_weight_path) <TAB> <TAB> else: <TAB> <TAB> <TAB> model.load_weights(init_weight_path) <TAB> else: <TAB> <TAB> logging.info(""Weights not loaded from path:{}"".format(init_weight_path))",false,if self . use_tpu :,if self . use_checkpoint :,0.39,0.0
"def _cleanup_inactive_receivexlogs(self, site): <TAB> if site in self.receivexlogs: <TAB> <TAB> if not self.receivexlogs[site].running: <TAB> <TAB> <TAB> if self.receivexlogs[site].is_alive(): <TAB> <TAB> <TAB> <TAB> self.receivexlogs[site].join() <TAB> <TAB> <TAB> del self.receivexlogs[site]",false,if self . receivexlogs [ site ] . is_alive ( ) :,if self . receiptexlogs [ site ] . is_alive ( ) :,0.62,0.0
"def get_asset(self, path): <TAB> """"""Loads an asset by path."""""" <TAB> clean_path = cleanup_path(path).strip(""/"") <TAB> nodes = [self.asset_root] + self.theme_asset_roots <TAB> for node in nodes: <TAB> <TAB> for piece in clean_path.split(""/""): <TAB> <TAB> <TAB> node = node.get_child(piece) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if node is not None: <TAB> <TAB> <TAB> return node <TAB> return None",true,if node is None :,if node is None :,0.75,0.0
"def palindromic_substrings(s): <TAB> if not s: <TAB> <TAB> return [[]] <TAB> results = [] <TAB> for i in range(len(s), 0, -1): <TAB> <TAB> sub = s[:i] <TAB> <TAB> if sub == sub[::-1]: <TAB> <TAB> <TAB> for rest in palindromic_substrings(s[i:]): <TAB> <TAB> <TAB> <TAB> results.append([sub] + rest) <TAB> return results",false,if sub == sub [ : : - 1 ] :,if sub == sub [ :: - 1 ] :,0.55,0.0
"def debug_tree(tree): <TAB> l = [] <TAB> for elt in tree: <TAB> <TAB> if isinstance(elt, (int, long)): <TAB> <TAB> <TAB> l.append(_names.get(elt, elt)) <TAB> <TAB> elif isinstance(elt, str): <TAB> <TAB> <TAB> l.append(elt) <TAB> <TAB> else: <TAB> <TAB> <TAB> l.append(debug_tree(elt)) <TAB> return l",false,"if isinstance ( elt , ( int , long ) ) :","elif isinstance ( elt , str ) :",0.12,0.0
"def shared_username(account): <TAB> username = os.environ.get(""SHARED_USERNAME"", ""PKKid"") <TAB> for user in account.users(): <TAB> <TAB> if user.title.lower() == username.lower(): <TAB> <TAB> <TAB> return username <TAB> <TAB> elif ( <TAB> <TAB> <TAB> user.username <TAB> <TAB> <TAB> and user.email <TAB> <TAB> <TAB> and user.id <TAB> <TAB> <TAB> and username.lower() <TAB> <TAB> <TAB> in (user.username.lower(), user.email.lower(), str(user.id)) <TAB> <TAB> ): <TAB> <TAB> <TAB> return username <TAB> pytest.skip(""Shared user %s wasn`t found in your MyPlex account"" % username)",true,if user . title . lower ( ) == username . lower ( ) :,if user . title . lower ( ) == username . lower ( ) :,1.0,0.0
"def process_schema_element(self, e): <TAB> if e.name is None: <TAB> <TAB> return <TAB> self.debug1(""adding element: %s"", e.name) <TAB> t = self.get_type(e.type) <TAB> if t: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> del self.pending_elements[e.name] <TAB> <TAB> self.retval[self.tns].elements[e.name] = e <TAB> else: <TAB> <TAB> self.pending_elements[e.name] = e",true,if e . name in self . pending_elements :,if e . name in self . pending_elements :,0.75,0.0
"def __setitem__(self, key, value): <TAB> with self._lock: <TAB> <TAB> try: <TAB> <TAB> <TAB> link = self._get_link_and_move_to_front_of_ll(key) <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self._set_key_and_add_to_front_of_ll(key, value) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> evicted = self._set_key_and_evict_last_in_ll(key, value) <TAB> <TAB> <TAB> <TAB> super(LRI, self).__delitem__(evicted) <TAB> <TAB> <TAB> super(LRI, self).__setitem__(key, value) <TAB> <TAB> else: <TAB> <TAB> <TAB> link[VALUE] = value",false,if len ( self ) < self . max_size :,if LINK_KEY_AND_ADD_TO_front_of_ll :,0.01,0.0
"def __delattr__(self, name): <TAB> if name == ""__dict__"": <TAB> <TAB> raise AttributeError( <TAB> <TAB> <TAB> ""%r object attribute '__dict__' is read-only"" % self.__class__.__name__ <TAB> <TAB> ) <TAB> if name in self._local_type_vars: <TAB> <TAB> if name in self._local_type_del_descriptors: <TAB> <TAB> <TAB> # A data descriptor, like a property or a slot. <TAB> <TAB> <TAB> type_attr = getattr(self._local_type, name, _marker) <TAB> <TAB> <TAB> type(type_attr).__delete__(type_attr, self) <TAB> <TAB> <TAB> return <TAB> # Otherwise it goes directly in the dict <TAB> # Begin inlined function _get_dict() <TAB> dct = _local_get_dict(self) <TAB> try: <TAB> <TAB> del dct[name] <TAB> except KeyError: <TAB> <TAB> raise AttributeError(name)",true,if name in self . _local_type_del_descriptors :,if name in self . _local_type_del_descriptors :,0.75,0.0
"def update_participants(self, refresh=True): <TAB> for participant in list(self.participants_dict): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> self.removeItem(self.participants_dict[participant]) <TAB> <TAB> self.participant_items.remove(self.participants_dict[participant]) <TAB> <TAB> del self.participants_dict[participant] <TAB> for participant in self.simulator_config.participants: <TAB> <TAB> if participant in self.participants_dict: <TAB> <TAB> <TAB> self.participants_dict[participant].refresh() <TAB> <TAB> else: <TAB> <TAB> <TAB> self.insert_participant(participant) <TAB> if refresh: <TAB> <TAB> self.update_view()",false,if participant is None or participant == self . simulator_config . broadcast_part :,if participant in self . participant_items :,0.19,0.0
"def insert_bigger_b_add(node): <TAB> if node.op == theano.tensor.add: <TAB> <TAB> inputs = list(node.inputs) <TAB> <TAB> if inputs[-1].owner is None: <TAB> <TAB> <TAB> inputs[-1] = theano.tensor.concatenate((inputs[-1], inputs[-1])) <TAB> <TAB> <TAB> return [node.op(*inputs)] <TAB> return False",true,if inputs [ - 1 ] . owner is None :,if inputs [ - 1 ] . owner is None :,0.75,0.0
"def _activate_cancel_status(self, cancel_status): <TAB> if self._cancel_status is not None: <TAB> <TAB> self._cancel_status._tasks.remove(self) <TAB> self._cancel_status = cancel_status <TAB> if self._cancel_status is not None: <TAB> <TAB> self._cancel_status._tasks.add(self) <TAB> <TAB> if self._cancel_status.effectively_cancelled: <TAB> <TAB> <TAB> self._attempt_delivery_of_any_pending_cancel()",true,if self . _cancel_status . effectively_cancelled :,if self . _cancel_status . effectively_cancelled :,0.75,0.0
"def writeLibraryGeometry(fp, meshes, config, shapes=None): <TAB> progress = Progress(len(meshes), None) <TAB> fp.write(""\n  <library_geometries>\n"") <TAB> for mIdx, mesh in enumerate(meshes): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> shape = None <TAB> <TAB> else: <TAB> <TAB> <TAB> shape = shapes[mIdx] <TAB> <TAB> writeGeometry(fp, mesh, config, shape) <TAB> <TAB> progress.step() <TAB> fp.write(""  </library_geometries>\n"")",true,if shapes is None :,if shapes is None :,0.75,0.0
"def init_module_config(module_json, config, config_path=default_config_path): <TAB> if ""config"" in module_json[""meta""]: <TAB> <TAB> if module_json[""meta""][""config""]: <TAB> <TAB> <TAB> if module_json[""name""] not in config: <TAB> <TAB> <TAB> <TAB> config.add_section(module_json[""name""]) <TAB> <TAB> <TAB> for config_var in module_json[""meta""][""config""]: <TAB> <TAB> <TAB> <TAB> if config_var not in config[module_json[""name""]]: <TAB> <TAB> <TAB> <TAB> <TAB> config.set(module_json[""name""], config_var, """") <TAB> return config",false,"if config_var not in config [ module_json [ ""name"" ] ] :","if module_json [ ""meta"" ] [ ""config"" ] :",0.03,0.0
"def get_const_defines(flags, prefix=""""): <TAB> defs = [] <TAB> for k, v in globals().items(): <TAB> <TAB> if isinstance(v, int): <TAB> <TAB> <TAB> if v & flags: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> if k.startswith(prefix): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> defs.append(k) <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> defs.append(k) <TAB> return defs",true,if prefix :,if prefix :,0.53,0.0
"def __init__(self, source, encoding=DEFAULT_ENCODING): <TAB> self.data = {} <TAB> with open(source, encoding=encoding) as file_: <TAB> <TAB> for line in file_: <TAB> <TAB> <TAB> line = line.strip() <TAB> <TAB> <TAB> if not line or line.startswith(""#"") or ""="" not in line: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> k, v = line.split(""="", 1) <TAB> <TAB> <TAB> k = k.strip() <TAB> <TAB> <TAB> v = v.strip() <TAB> <TAB> <TAB> if len(v) >= 2 and ( <TAB> <TAB> <TAB> <TAB> (v[0] == ""'"" and v[-1] == ""'"") or (v[0] == '""' and v[-1] == '""') <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> v = v.strip(""'\"""") <TAB> <TAB> <TAB> self.data[k] = v",false,"if not line or line . startswith ( ""#"" ) or ""="" not in line :","if len ( v ) >= 2 and ( ( v [ 0 ] == ""'"" and v [ - 1 ] == ""'"" ) or ""="" not in line ) :",0.38,0.0
"def __detect_console_logger(self): <TAB> logger = self.log <TAB> while logger: <TAB> <TAB> for handler in logger.handlers[:]: <TAB> <TAB> <TAB> if isinstance(handler, StreamHandler): <TAB> <TAB> <TAB> <TAB> if handler.stream in (sys.stdout, sys.stderr): <TAB> <TAB> <TAB> <TAB> <TAB> self.logger_handlers.append(handler) <TAB> <TAB> if logger.root == logger: <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> logger = logger.root",true,"if isinstance ( handler , StreamHandler ) :","if isinstance ( handler , StreamHandler ) :",0.75,0.0
"def check_heuristic_in_sql(): <TAB> heurs = set() <TAB> excluded = [""Equal assembly or pseudo-code"", ""All or most attributes""] <TAB> for heur in HEURISTICS: <TAB> <TAB> name = heur[""name""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> sql = heur[""sql""] <TAB> <TAB> if sql.lower().find(name.lower()) == -1: <TAB> <TAB> <TAB> print((""SQL command not correctly associated to %s"" % repr(name))) <TAB> <TAB> <TAB> print(sql) <TAB> <TAB> <TAB> assert sql.find(name) != -1 <TAB> <TAB> heurs.add(name) <TAB> print(""Heuristics:"") <TAB> import pprint <TAB> pprint.pprint(heurs)",true,if name in excluded :,if name in excluded :,0.75,0.0
"def read(self, size=-1): <TAB> buf = bytearray() <TAB> while size != 0 and self.cursor < self.maxpos: <TAB> <TAB> if not self.in_current_block(self.cursor): <TAB> <TAB> <TAB> self.seek_to_block(self.cursor) <TAB> <TAB> part = self.current_stream.read(size) <TAB> <TAB> if size > 0: <TAB> <TAB> <TAB> if len(part) == 0: <TAB> <TAB> <TAB> <TAB> raise EOFError() <TAB> <TAB> <TAB> size -= len(part) <TAB> <TAB> self.cursor += len(part) <TAB> <TAB> buf += part <TAB> return bytes(buf)",true,if not self . in_current_block ( self . cursor ) :,if not self . in_current_block ( self . cursor ) :,1.0,0.0
"def get_project_dir(env): <TAB> project_file = workon_home / env / "".project"" <TAB> if project_file.exists(): <TAB> <TAB> with project_file.open() as f: <TAB> <TAB> <TAB> project_dir = f.readline().strip() <TAB> <TAB> <TAB> if os.path.exists(project_dir): <TAB> <TAB> <TAB> <TAB> return project_dir <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> err( <TAB> <TAB> <TAB> <TAB> <TAB> ""Corrupted or outdated:"", <TAB> <TAB> <TAB> <TAB> <TAB> project_file, <TAB> <TAB> <TAB> <TAB> <TAB> ""\nDirectory"", <TAB> <TAB> <TAB> <TAB> <TAB> project_dir, <TAB> <TAB> <TAB> <TAB> <TAB> ""doesn't exist."", <TAB> <TAB> <TAB> <TAB> )",true,if os . path . exists ( project_dir ) :,if os . path . exists ( project_dir ) :,0.75,0.0
"def _cache_mem(curr_out, prev_mem, mem_len, reuse_len=None): <TAB> """"""cache hidden states into memory."""""" <TAB> if mem_len is None or mem_len == 0: <TAB> <TAB> return None <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> curr_out = curr_out[:reuse_len] <TAB> <TAB> if prev_mem is None: <TAB> <TAB> <TAB> new_mem = curr_out[-mem_len:] <TAB> <TAB> else: <TAB> <TAB> <TAB> new_mem = tf.concat([prev_mem, curr_out], 0)[-mem_len:] <TAB> return tf.keras.backend.stop_gradient(new_mem)",false,if reuse_len is not None and reuse_len > 0 :,if reuse_len is not None :,0.39,0.0
"def cleanup_channel(self, to_cleanup): <TAB> public_key, id_ = to_cleanup <TAB> # TODO: Maybe run it threaded? <TAB> try: <TAB> <TAB> with db_session: <TAB> <TAB> <TAB> channel = self.session.mds.ChannelMetadata.get_for_update( <TAB> <TAB> <TAB> <TAB> public_key=public_key, id_=id_ <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> channel.local_version = 0 <TAB> <TAB> <TAB> channel.contents.delete(bulk=True) <TAB> except Exception as e: <TAB> <TAB> self._logger.warning(""Exception while cleaning unsubscribed channel: %"", str(e))",false,if not channel :,if channel is None :,0.05,0.0
"def best_image(width, height): <TAB> # A heuristic for finding closest sized image to required size. <TAB> image = images[0] <TAB> for img in images: <TAB> <TAB> if img.width == width and img.height == height: <TAB> <TAB> <TAB> # Exact match always used <TAB> <TAB> <TAB> return img <TAB> <TAB> elif img.width >= width and img.width * img.height > image.width * image.height: <TAB> <TAB> <TAB> # At least wide enough, and largest area <TAB> <TAB> <TAB> image = img <TAB> return image",true,elif img . width >= width and img . width * img . height > image . width * image . height :,elif img . width >= width and img . width * img . height > image . width * image . height :,1.0,0.0
"def add_peer_to_blob(self, contact: ""KademliaPeer"", key: bytes) -> None: <TAB> now = self.loop.time() <TAB> if key in self._data_store: <TAB> <TAB> current = list(filter(lambda x: x[0] == contact, self._data_store[key])) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._data_store[key][self._data_store[key].index(current[0])] = ( <TAB> <TAB> <TAB> <TAB> contact, <TAB> <TAB> <TAB> <TAB> now, <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._data_store[key].append((contact, now)) <TAB> else: <TAB> <TAB> self._data_store[key] = [(contact, now)]",false,if len ( current ) > 0 :,if current :,0.02,0.0
"def dump(self): <TAB> self.ql.log.info(""[*] Dumping object: %s"" % (self.sf_name)) <TAB> for field in self._fields_: <TAB> <TAB> if isinstance(getattr(self, field[0]), POINTER64): <TAB> <TAB> <TAB> self.ql.log.info(""%s: 0x%x"" % (field[0], getattr(self, field[0]).value)) <TAB> <TAB> elif isinstance(getattr(self, field[0]), int): <TAB> <TAB> <TAB> self.ql.log.info(""%s: %d"" % (field[0], getattr(self, field[0]))) <TAB> <TAB> elif isinstance(getattr(self, field[0]), bytes): <TAB> <TAB> <TAB> self.ql.log.info(""%s: %s"" % (field[0], getattr(self, field[0]).decode()))",true,"elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) :","elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) :",0.75,0.0
"def GeneratePageMetatadata(self, task): <TAB> address_space = self.session.GetParameter(""default_address_space"") <TAB> for vma in task.mm.mmap.walk_list(""vm_next""): <TAB> <TAB> start = vma.vm_start <TAB> <TAB> end = vma.vm_end <TAB> <TAB> # Skip the entire region. <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Done. <TAB> <TAB> if start > self.plugin_args.end: <TAB> <TAB> <TAB> break <TAB> <TAB> for vaddr in utils.xrange(start, end, 0x1000): <TAB> <TAB> <TAB> if self.plugin_args.start <= vaddr <= self.plugin_args.end: <TAB> <TAB> <TAB> <TAB> yield vaddr, self._CreateMetadata(address_space.describe_vtop(vaddr))",false,if end < self . plugin_args . start :,if start == self . plugin_args . end :,0.43,0.0
"def _available_symbols(self, scoperef, expr): <TAB> cplns = [] <TAB> found_names = set() <TAB> while scoperef: <TAB> <TAB> elem = self._elem_from_scoperef(scoperef) <TAB> <TAB> for child in elem: <TAB> <TAB> <TAB> name = child.get(""name"", """") <TAB> <TAB> <TAB> if name.startswith(expr): <TAB> <TAB> <TAB> <TAB> if name not in found_names: <TAB> <TAB> <TAB> <TAB> <TAB> found_names.add(name) <TAB> <TAB> <TAB> <TAB> <TAB> ilk = child.get(""ilk"") or child.tag <TAB> <TAB> <TAB> <TAB> <TAB> cplns.append((ilk, name)) <TAB> <TAB> scoperef = self.parent_scoperef_from_scoperef(scoperef) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> return sorted(cplns, key=operator.itemgetter(1))",true,if not scoperef :,if not scoperef :,0.75,0.0
"def get_xenapi_host(self): <TAB> """"""Return the xenapi host on which nova-compute runs on."""""" <TAB> with self._get_session() as session: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return session.xenapi.host.get_by_uuid(self.host_uuid) <TAB> <TAB> else: <TAB> <TAB> <TAB> return session.xenapi.session.get_this_host(session.handle)",true,if self . host_uuid :,if self . host_uuid :,0.75,0.0
"def stream_docker_log(log_stream): <TAB> async for line in log_stream: <TAB> <TAB> if ""stream"" in line and line[""stream""].strip(): <TAB> <TAB> <TAB> logger.debug(line[""stream""].strip()) <TAB> <TAB> elif ""status"" in line: <TAB> <TAB> <TAB> logger.debug(line[""status""].strip()) <TAB> <TAB> elif ""error"" in line: <TAB> <TAB> <TAB> logger.error(line[""error""].strip()) <TAB> <TAB> <TAB> raise DockerBuildError",false,"if ""stream"" in line and line [ ""stream"" ] . strip ( ) :","elif ""error"" in line :",0.01,0.0
"def test_wildcard_import(): <TAB> bonobo = __import__(""bonobo"") <TAB> assert bonobo.__version__ <TAB> for name in dir(bonobo): <TAB> <TAB> # ignore attributes starting by underscores <TAB> <TAB> if name.startswith(""_""): <TAB> <TAB> <TAB> continue <TAB> <TAB> attr = getattr(bonobo, name) <TAB> <TAB> if inspect.ismodule(attr): <TAB> <TAB> <TAB> continue <TAB> <TAB> assert name in bonobo.__all__",false,"if name . startswith ( ""_"" ) :",if inspect . ismodule ( attr ) :,0.04,0.0
"def _coerce_to_bool(self, node, var, true_val=True): <TAB> """"""Coerce the values in a variable to bools."""""" <TAB> bool_var = self.program.NewVariable() <TAB> for b in var.bindings: <TAB> <TAB> v = b.data <TAB> <TAB> if isinstance(v, mixin.PythonConstant) and isinstance(v.pyval, bool): <TAB> <TAB> <TAB> const = v.pyval is true_val <TAB> <TAB> elif not compare.compatible_with(v, True): <TAB> <TAB> <TAB> const = not true_val <TAB> <TAB> elif not compare.compatible_with(v, False): <TAB> <TAB> <TAB> const = true_val <TAB> <TAB> else: <TAB> <TAB> <TAB> const = None <TAB> <TAB> bool_var.AddBinding(self.convert.bool_values[const], {b}, node) <TAB> return bool_var",false,"elif not compare . compatible_with ( v , True ) :","elif not compare . compatible_with ( v , False ) :",0.62,0.0
"def _parse_policies(self, policies_yaml): <TAB> for item in policies_yaml: <TAB> <TAB> id_ = required_key(item, ""id"") <TAB> <TAB> controls_ids = required_key(item, ""controls"") <TAB> <TAB> if not isinstance(controls_ids, list): <TAB> <TAB> <TAB> if controls_ids != ""all"": <TAB> <TAB> <TAB> <TAB> msg = ""Policy {id_} contains invalid controls list {controls}."".format( <TAB> <TAB> <TAB> <TAB> <TAB> id_=id_, controls=str(controls_ids) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> raise ValueError(msg) <TAB> <TAB> self.policies[id_] = controls_ids",false,"if controls_ids != ""all"" :","if not isinstance ( controls_ids , list ) :",0.03,0.0
"def pong(self, payload: Union[str, bytes] = """") -> None: <TAB> if self.trace_enabled and self.ping_pong_trace_enabled: <TAB> <TAB> if isinstance(payload, bytes): <TAB> <TAB> <TAB> payload = payload.decode(""utf-8"") <TAB> <TAB> self.logger.debug( <TAB> <TAB> <TAB> ""Sending a pong data frame "" <TAB> <TAB> <TAB> f""(session id: {self.session_id}, payload: {payload})"" <TAB> <TAB> ) <TAB> data = _build_data_frame_for_sending(payload, FrameHeader.OPCODE_PONG) <TAB> with self.sock_send_lock: <TAB> <TAB> self.sock.send(data)",true,"if isinstance ( payload , bytes ) :","if isinstance ( payload , bytes ) :",0.75,0.0
"def _extract_curve_feature_log(arg): <TAB> """"""extract sampled curve feature for log items"""""" <TAB> try: <TAB> <TAB> inp, res = arg <TAB> <TAB> config = inp.config <TAB> <TAB> with inp.target: <TAB> <TAB> <TAB> sch, args = inp.task.instantiate(config) <TAB> <TAB> fea = feature.get_buffer_curve_sample_flatten(sch, args, sample_n=20) <TAB> <TAB> x = np.concatenate((fea, list(config.get_other_option().values()))) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> y = inp.task.flop / np.mean(res.costs) <TAB> <TAB> else: <TAB> <TAB> <TAB> y = 0.0 <TAB> <TAB> return x, y <TAB> except Exception:  # pylint: disable=broad-except <TAB> <TAB> return None",false,if res . error_no == 0 :,if res . costs :,0.09,0.0
"def messageSourceStamps(self, source_stamps): <TAB> text = """" <TAB> for ss in source_stamps: <TAB> <TAB> source = """" <TAB> <TAB> if ss[""branch""]: <TAB> <TAB> <TAB> source += ""[branch %s] "" % ss[""branch""] <TAB> <TAB> if ss[""revision""]: <TAB> <TAB> <TAB> source += str(ss[""revision""]) <TAB> <TAB> else: <TAB> <TAB> <TAB> source += ""HEAD"" <TAB> <TAB> if ss[""patch""] is not None: <TAB> <TAB> <TAB> source += "" (plus patch)"" <TAB> <TAB> discriminator = """" <TAB> <TAB> if ss[""codebase""]: <TAB> <TAB> <TAB> discriminator = "" '%s'"" % ss[""codebase""] <TAB> <TAB> text += ""Build Source Stamp%s: %s\n"" % (discriminator, source) <TAB> return text",false,"if ss [ ""revision"" ] :","if ss [ ""branch"" ] :",0.38,0.0
"def find_repository(): <TAB> orig_path = path = os.path.realpath(""."") <TAB> drive, path = os.path.splitdrive(path) <TAB> while path: <TAB> <TAB> current_path = os.path.join(drive, path) <TAB> <TAB> current_repo = LocalRepository(current_path) <TAB> <TAB> if current_repo.isValid(): <TAB> <TAB> <TAB> return current_repo <TAB> <TAB> path, path_tail = os.path.split(current_path) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise CannotFindRepository(""Cannot find repository for %s"" % (orig_path,))",false,if not path_tail :,if path_tail != orig_path :,0.05,0.0
"def compute_indices(text: str, tokens): <TAB> indices = [] <TAB> for i, token in enumerate(tokens): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> current_index = indices[-1] + len(tokens[i - 1][0]) <TAB> <TAB> <TAB> indices.append(current_index + text[current_index:].find(token[0])) <TAB> <TAB> else: <TAB> <TAB> <TAB> indices.append(text.find(token[0])) <TAB> return indices",false,if 1 <= i :,if i > 0 :,0.04,0.0
"def _add_defaults_data_files(self): <TAB> # getting distribution.data_files <TAB> if self.distribution.has_data_files(): <TAB> <TAB> for item in self.distribution.data_files: <TAB> <TAB> <TAB> if isinstance(item, str): <TAB> <TAB> <TAB> <TAB> # plain file <TAB> <TAB> <TAB> <TAB> item = convert_path(item) <TAB> <TAB> <TAB> <TAB> if os.path.isfile(item): <TAB> <TAB> <TAB> <TAB> <TAB> self.filelist.append(item) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> # a (dirname, filenames) tuple <TAB> <TAB> <TAB> <TAB> dirname, filenames = item <TAB> <TAB> <TAB> <TAB> for f in filenames: <TAB> <TAB> <TAB> <TAB> <TAB> f = convert_path(f) <TAB> <TAB> <TAB> <TAB> <TAB> if os.path.isfile(f): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self.filelist.append(f)",false,if os . path . isfile ( item ) :,"if isinstance ( item , str ) :",0.03,0.0
"def libcxx_define(settings): <TAB> compiler = _base_compiler(settings) <TAB> libcxx = settings.get_safe(""compiler.libcxx"") <TAB> if not compiler or not libcxx: <TAB> <TAB> return """" <TAB> if str(compiler) in GCC_LIKE: <TAB> <TAB> if str(libcxx) == ""libstdc++"": <TAB> <TAB> <TAB> return ""_GLIBCXX_USE_CXX11_ABI=0"" <TAB> <TAB> elif str(libcxx) == ""libstdc++11"": <TAB> <TAB> <TAB> return ""_GLIBCXX_USE_CXX11_ABI=1"" <TAB> return """"",false,"if str ( libcxx ) == ""libstdc++"" :","elif str ( libcxx ) == ""libstdc++11"" :",0.26,0.0
"def _populate_tree(self, element, d): <TAB> """"""Populates an etree with attributes & elements, given a dict."""""" <TAB> for k, v in d.iteritems(): <TAB> <TAB> if isinstance(v, dict): <TAB> <TAB> <TAB> self._populate_dict(element, k, v) <TAB> <TAB> elif isinstance(v, list): <TAB> <TAB> <TAB> self._populate_list(element, k, v) <TAB> <TAB> elif isinstance(v, bool): <TAB> <TAB> <TAB> self._populate_bool(element, k, v) <TAB> <TAB> elif isinstance(v, basestring): <TAB> <TAB> <TAB> self._populate_str(element, k, v) <TAB> <TAB> elif type(v) in [int, float, long, complex]: <TAB> <TAB> <TAB> self._populate_number(element, k, v)",true,"elif isinstance ( v , basestring ) :","elif isinstance ( v , basestring ) :",0.75,0.0
"def test_seek(self): <TAB><IF-STMT> <TAB> <TAB> print(""create large file via seek (may be sparse file) ..."") <TAB> with self.open(TESTFN, ""wb"") as f: <TAB> <TAB> f.write(b""z"") <TAB> <TAB> f.seek(0) <TAB> <TAB> f.seek(size) <TAB> <TAB> f.write(b""a"") <TAB> <TAB> f.flush() <TAB> <TAB> if verbose: <TAB> <TAB> <TAB> print(""check file size with os.fstat"") <TAB> <TAB> self.assertEqual(os.fstat(f.fileno())[stat.ST_SIZE], size + 1)",true,if verbose :,if verbose :,0.53,0.0
"def serialize_review_url_field(self, obj, **kwargs): <TAB> if obj.review_ui: <TAB> <TAB> review_request = obj.get_review_request() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> local_site_name = review_request.local_site.name <TAB> <TAB> else: <TAB> <TAB> <TAB> local_site_name = None <TAB> <TAB> return local_site_reverse( <TAB> <TAB> <TAB> ""file-attachment"", <TAB> <TAB> <TAB> local_site_name=local_site_name, <TAB> <TAB> <TAB> kwargs={ <TAB> <TAB> <TAB> <TAB> ""review_request_id"": review_request.display_id, <TAB> <TAB> <TAB> <TAB> ""file_attachment_id"": obj.pk, <TAB> <TAB> <TAB> }, <TAB> <TAB> ) <TAB> return """"",false,if review_request . local_site_id :,if review_request . local_site :,0.39,0.0
"def on_item_down_clicked(self, button): <TAB> model = self.treeview.get_model() <TAB> for s in self._get_selected(): <TAB> <TAB><IF-STMT>  # XXX need model.swap <TAB> <TAB> <TAB> old = model.get_iter(s[0]) <TAB> <TAB> <TAB> iter = model.insert(s[0] + 2) <TAB> <TAB> <TAB> for i in range(3): <TAB> <TAB> <TAB> <TAB> model.set_value(iter, i, model.get_value(old, i)) <TAB> <TAB> <TAB> model.remove(old) <TAB> <TAB> <TAB> self.treeview.get_selection().select_iter(iter) <TAB> self._update_filter_string()",false,if s [ 0 ] < len ( model ) - 1 :,if s [ 0 ] == 1 :,0.2,0.0
"def writer(self): <TAB> """"""loop forever and copy socket->serial"""""" <TAB> while self.alive: <TAB> <TAB> try: <TAB> <TAB> <TAB> data = self.socket.recv(1024) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> self.serial.write(b"""".join(self.rfc2217.filter(data))) <TAB> <TAB> except socket.error as msg: <TAB> <TAB> <TAB> self.log.error(""{}"".format(msg)) <TAB> <TAB> <TAB> # probably got disconnected <TAB> <TAB> <TAB> break <TAB> self.stop()",true,if not data :,if not data :,0.75,0.0
"def __getitem__(self, key): <TAB> if key == 1: <TAB> <TAB> return self.get_value() <TAB> elif key == 0: <TAB> <TAB> return self.cell[0] <TAB> elif isinstance(key, slice): <TAB> <TAB> s = list(self.cell.__getitem__(key)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> s[s.index(self.cell[1])] = self.get_value() <TAB> <TAB> return s <TAB> else: <TAB> <TAB> raise IndexError(key)",false,if self . cell [ 1 ] in s :,if len ( s ) > 1 :,0.02,0.0
"def test_error_stream(environ, start_response): <TAB> writer = start_response(""200 OK"", []) <TAB> wsgi_errors = environ[""wsgi.errors""] <TAB> error_msg = None <TAB> for method in [ <TAB> <TAB> ""flush"", <TAB> <TAB> ""write"", <TAB> <TAB> ""writelines"", <TAB> ]: <TAB> <TAB> if not hasattr(wsgi_errors, method): <TAB> <TAB> <TAB> error_msg = ""wsgi.errors has no '%s' attr"" % method <TAB> <TAB> if not error_msg and not callable(getattr(wsgi_errors, method)): <TAB> <TAB> <TAB> error_msg = ""wsgi.errors.%s attr is not callable"" % method <TAB> <TAB> if error_msg: <TAB> <TAB> <TAB> break <TAB> return_msg = error_msg or ""success"" <TAB> writer(return_msg) <TAB> return []",true,"if not hasattr ( wsgi_errors , method ) :","if not hasattr ( wsgi_errors , method ) :",0.75,0.0
"def job_rule_modules(app): <TAB> rules_module_list = [] <TAB> for rules_module_name in __job_rule_module_names(app): <TAB> <TAB> rules_module = sys.modules.get(rules_module_name, None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # if using a non-default module, it's not imported until a JobRunnerMapper is instantiated when the first <TAB> <TAB> <TAB> # JobWrapper is created <TAB> <TAB> <TAB> rules_module = importlib.import_module(rules_module_name) <TAB> <TAB> rules_module_list.append(rules_module) <TAB> return rules_module_list",false,if not rules_module :,if rules_module is None :,0.05,0.0
"def discover_hdfstore(f): <TAB> d = dict() <TAB> for key in f.keys(): <TAB> <TAB> d2 = d <TAB> <TAB> key2 = key.lstrip(""/"") <TAB> <TAB> while ""/"" in key2: <TAB> <TAB> <TAB> group, key2 = key2.split(""/"", 1) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> d2[group] = dict() <TAB> <TAB> <TAB> d2 = d2[group] <TAB> <TAB> d2[key2] = f.get_storer(key) <TAB> return discover(d)",true,if group not in d2 :,if group not in d2 :,0.75,0.0
"def test_update_zone(self): <TAB> zone = self.driver.list_zones()[0] <TAB> updated_zone = self.driver.update_zone(zone=zone, domain="""", extra={""paused"": True}) <TAB> self.assertEqual(zone.id, updated_zone.id) <TAB> self.assertEqual(zone.domain, updated_zone.domain) <TAB> self.assertEqual(zone.type, updated_zone.type) <TAB> self.assertEqual(zone.ttl, updated_zone.ttl) <TAB> for key in set(zone.extra) | set(updated_zone.extra): <TAB> <TAB> if key in (""paused"", ""modified_on""): <TAB> <TAB> <TAB> self.assertNotEqual(zone.extra[key], updated_zone.extra[key]) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.assertEqual(zone.extra[key], updated_zone.extra[key])",true,"if key in ( ""paused"" , ""modified_on"" ) :","if key in ( ""paused"" , ""modified_on"" ) :",0.75,0.0
"def ESP(phrase): <TAB> for num, name in enumerate(devname): <TAB> <TAB> if name.lower() in phrase: <TAB> <TAB> <TAB> dev = devid[num] <TAB> <TAB> <TAB> if custom_action_keyword[""Dict""][""On""] in phrase: <TAB> <TAB> <TAB> <TAB> ctrl = ""=ON"" <TAB> <TAB> <TAB> <TAB> say(""Turning On "" + name) <TAB> <TAB> <TAB> elif custom_action_keyword[""Dict""][""Off""] in phrase: <TAB> <TAB> <TAB> <TAB> ctrl = ""=OFF"" <TAB> <TAB> <TAB> <TAB> say(""Turning Off "" + name) <TAB> <TAB> <TAB> rq = requests.head(""https://"" + ip + dev + ctrl, verify=False)",false,if name . lower ( ) in phrase :,"elif custom_action_keyword [ ""Dict"" ] [ ""Off"" ] in phrase :",0.05,0.0
"def filter_ports(self, dpid, in_port, nw_id, allow_nw_id_external=None): <TAB> assert nw_id != self.nw_id_unknown <TAB> ret = [] <TAB> for port in self.get_ports(dpid): <TAB> <TAB> nw_id_ = port.network_id <TAB> <TAB> if port.port_no == in_port: <TAB> <TAB> <TAB> continue <TAB> <TAB> if nw_id_ == nw_id: <TAB> <TAB> <TAB> ret.append(port.port_no) <TAB> <TAB> elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external: <TAB> <TAB> <TAB> ret.append(port.port_no) <TAB> return ret",true,elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external :,elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external :,1.0,0.0
"def tail(filename): <TAB> if os.path.isfile(filename): <TAB> <TAB> file = open(filename, ""r"") <TAB> <TAB> st_results = os.stat(filename) <TAB> <TAB> st_size = st_results[6] <TAB> <TAB> file.seek(st_size) <TAB> <TAB> while 1: <TAB> <TAB> <TAB> where = file.tell() <TAB> <TAB> <TAB> line = file.readline() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> time.sleep(1) <TAB> <TAB> <TAB> <TAB> file.seek(where) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> print( <TAB> <TAB> <TAB> <TAB> <TAB> line, <TAB> <TAB> <TAB> <TAB> )  # already has newline <TAB> else: <TAB> <TAB> print_error(""File not found, cannot tail."")",false,if not line :,"if line == """" :",0.05,0.0
"def proc_day_of_week(d): <TAB> if expanded[4][0] != ""*"": <TAB> <TAB> diff_day_of_week = nearest_diff_method(d.isoweekday() % 7, expanded[4], 7) <TAB> <TAB> if diff_day_of_week is not None and diff_day_of_week != 0: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> d += relativedelta(days=diff_day_of_week, hour=23, minute=59, second=59) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> d += relativedelta(days=diff_day_of_week, hour=0, minute=0, second=0) <TAB> <TAB> <TAB> return True, d <TAB> return False, d",false,if is_prev :,"if expanded [ 4 ] == ""*"" :",0.04,0.0
"def __call__(self): <TAB> """"""Run all check_* methods."""""" <TAB> if self.on: <TAB> <TAB> oldformatwarning = warnings.formatwarning <TAB> <TAB> warnings.formatwarning = self.formatwarning <TAB> <TAB> try: <TAB> <TAB> <TAB> for name in dir(self): <TAB> <TAB> <TAB> <TAB> if name.startswith(""check_""): <TAB> <TAB> <TAB> <TAB> <TAB> method = getattr(self, name) <TAB> <TAB> <TAB> <TAB> <TAB> if method and callable(method): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> method() <TAB> <TAB> finally: <TAB> <TAB> <TAB> warnings.formatwarning = oldformatwarning",false,if method and callable ( method ) :,"if name . startswith ( ""check_"" ) :",0.04,0.0
"def get(self, request, *args, **kwargs): <TAB> if self.revision: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> return send_file( <TAB> <TAB> <TAB> <TAB> <TAB> request, <TAB> <TAB> <TAB> <TAB> <TAB> self.revision.file.path, <TAB> <TAB> <TAB> <TAB> <TAB> self.revision.created, <TAB> <TAB> <TAB> <TAB> <TAB> self.attachment.original_filename, <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> return HttpResponseRedirect(self.revision.file.url) <TAB> raise Http404",false,if settings . USE_LOCAL_PATH :,if self . attachment :,0.29,0.0
"def _close(self): <TAB> super(Recording, self)._close() <TAB> if self._log_n is not None: <TAB> <TAB> for i in range(self.n): <TAB> <TAB> <TAB> if self._log_n[i] is not None: <TAB> <TAB> <TAB> <TAB> self._log_n[i].close() <TAB> <TAB> <TAB> <TAB> self._log_n[i] = None",true,if self . _log_n [ i ] is not None :,if self . _log_n [ i ] is not None :,0.75,0.0
"def addTags(self, rpcObjects=None): <TAB> hosts = self._getOnlyHostObjects(rpcObjects) <TAB> if hosts: <TAB> <TAB> title = ""Add Tags"" <TAB> <TAB> body = ""What tags should be added?\n\nUse a comma or space between each"" <TAB> <TAB> (tags, choice) = self.getText(title, body, """") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tags = str(tags).replace("" "", "","").split("","") <TAB> <TAB> <TAB> for host in hosts: <TAB> <TAB> <TAB> <TAB> self.cuebotCall( <TAB> <TAB> <TAB> <TAB> <TAB> host.addTags, ""Add Tags to %s Failed"" % host.data.name, tags <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self._update()",false,if choice :,if tags :,0.32,0.0
"def available_datasets(self): <TAB> """"""Automatically determine datasets provided by this file"""""" <TAB> res = self.resolution <TAB> coordinates = [""pixel_longitude"", ""pixel_latitude""] <TAB> for var_name, val in self.file_content.items(): <TAB> <TAB> if isinstance(val, netCDF4.Variable): <TAB> <TAB> <TAB> ds_info = { <TAB> <TAB> <TAB> <TAB> ""file_type"": self.filetype_info[""file_type""], <TAB> <TAB> <TAB> <TAB> ""resolution"": res, <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> if not self.is_geo: <TAB> <TAB> <TAB> <TAB> ds_info[""coordinates""] = coordinates <TAB> <TAB> <TAB> yield DatasetID(name=var_name, resolution=res), ds_info",true,"if isinstance ( val , netCDF4 . Variable ) :","if isinstance ( val , netCDF4 . Variable ) :",0.75,0.0
"def extract_from_file(fname: PathIsh) -> Iterator[Extraction]: <TAB> path = Path(fname) <TAB> fallback_dt = file_mtime(path) <TAB> p = Parser(path) <TAB> for r in p.walk(): <TAB> <TAB> if isinstance(r, Exception): <TAB> <TAB> <TAB> yield r <TAB> <TAB> else: <TAB> <TAB> <TAB> yield Visit( <TAB> <TAB> <TAB> <TAB> url=r.url, <TAB> <TAB> <TAB> <TAB> dt=fallback_dt, <TAB> <TAB> <TAB> <TAB> locator=Loc.file(fname),  # TODO line number <TAB> <TAB> <TAB> <TAB> context=r.context, <TAB> <TAB> <TAB> )",true,"if isinstance ( r , Exception ) :","if isinstance ( r , Exception ) :",0.75,0.0
"def init_module_config(module_json, config, config_path=default_config_path): <TAB> if ""config"" in module_json[""meta""]: <TAB> <TAB> if module_json[""meta""][""config""]: <TAB> <TAB> <TAB> if module_json[""name""] not in config: <TAB> <TAB> <TAB> <TAB> config.add_section(module_json[""name""]) <TAB> <TAB> <TAB> for config_var in module_json[""meta""][""config""]: <TAB> <TAB> <TAB> <TAB> if config_var not in config[module_json[""name""]]: <TAB> <TAB> <TAB> <TAB> <TAB> config.set(module_json[""name""], config_var, """") <TAB> return config",false,"if module_json [ ""name"" ] not in config :","if module_json [ ""meta"" ] [ ""config"" ] :",0.12,0.0
"def _create_entities(parsed_entities, sidx, eidx): <TAB> entities = [] <TAB> for k, vs in parsed_entities.items(): <TAB> <TAB> if not isinstance(vs, list): <TAB> <TAB> <TAB> vs = [vs] <TAB> <TAB> for value in vs: <TAB> <TAB> <TAB> entities.append( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> ""entity"": k, <TAB> <TAB> <TAB> <TAB> <TAB> ""start"": sidx, <TAB> <TAB> <TAB> <TAB> <TAB> ""end"": eidx,  # can't be more specific <TAB> <TAB> <TAB> <TAB> <TAB> ""value"": value, <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> return entities",true,"if not isinstance ( vs , list ) :","if not isinstance ( vs , list ) :",0.75,0.0
"def _telegram_upload_stream(self, stream, **kwargs): <TAB> """"""Perform upload defined in a stream."""""" <TAB> msg = None <TAB> try: <TAB> <TAB> stream.accept() <TAB> <TAB> msg = self._telegram_special_message( <TAB> <TAB> <TAB> chat_id=stream.identifier.id, <TAB> <TAB> <TAB> content=stream.raw, <TAB> <TAB> <TAB> msg_type=stream.stream_type, <TAB> <TAB> <TAB> **kwargs, <TAB> <TAB> ) <TAB> except Exception: <TAB> <TAB> log.exception(f""Upload of {stream.name} to {stream.identifier} failed."") <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> stream.error() <TAB> <TAB> else: <TAB> <TAB> <TAB> stream.success()",false,if msg is None :,if msg :,0.07,0.0
"def readlines(self, size=-1): <TAB> if self._nbr == self._size: <TAB> <TAB> return [] <TAB> # leave all additional logic to our readline method, we just check the size <TAB> out = [] <TAB> nbr = 0 <TAB> while True: <TAB> <TAB> line = self.readline() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> out.append(line) <TAB> <TAB> if size > -1: <TAB> <TAB> <TAB> nbr += len(line) <TAB> <TAB> <TAB> if nbr > size: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> # END handle size constraint <TAB> # END readline loop <TAB> return out",true,if not line :,if not line :,0.75,0.0
"def clean_permissions( <TAB> cls, <TAB> requestor: ""User"", <TAB> group: auth_models.Group, <TAB> errors: Dict[Optional[str], List[ValidationError]], <TAB> cleaned_input: dict, ): <TAB> field = ""add_permissions"" <TAB> permission_items = cleaned_input.get(field) <TAB> if permission_items: <TAB> <TAB> cleaned_input[field] = get_permissions(permission_items) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> cls.ensure_can_manage_permissions( <TAB> <TAB> <TAB> <TAB> requestor, errors, field, permission_items <TAB> <TAB> <TAB> )",false,if not requestor . is_superuser :,if not group . can_manage_permissions :,0.3,0.0
"def _bwd(subj=None, obj=None, seen=None): <TAB> seen.add(obj) <TAB> for s, o in evalPath(graph, (None, self.path, obj)): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield s, o <TAB> <TAB> if self.more: <TAB> <TAB> <TAB> if s in seen: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> for s2, o2 in _bwd(None, s, seen): <TAB> <TAB> <TAB> <TAB> yield s2, o",false,if not subj or subj == s :,if s in seen :,0.02,0.0
"def generate_data(self, request): <TAB> """"""Generate data for the widget."""""" <TAB> uptime = {} <TAB> cache_stats = get_cache_stats() <TAB> if cache_stats: <TAB> <TAB> for hosts, stats in cache_stats: <TAB> <TAB> <TAB> if stats[""uptime""] > 86400: <TAB> <TAB> <TAB> <TAB> uptime[""value""] = stats[""uptime""] / 60 / 60 / 24 <TAB> <TAB> <TAB> <TAB> uptime[""unit""] = _(""days"") <TAB> <TAB> <TAB> elif stats[""uptime""] > 3600: <TAB> <TAB> <TAB> <TAB> uptime[""value""] = stats[""uptime""] / 60 / 60 <TAB> <TAB> <TAB> <TAB> uptime[""unit""] = _(""hours"") <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> uptime[""value""] = stats[""uptime""] / 60 <TAB> <TAB> <TAB> <TAB> uptime[""unit""] = _(""minutes"") <TAB> return {""cache_stats"": cache_stats, ""uptime"": uptime}",false,"if stats [ ""uptime"" ] > 86400 :","elif stats [ ""uptime"" ] > 3600 :",0.26,0.0
def refresh(self): <TAB> if self._handle: <TAB> <TAB> source = self._db.get_repository_from_handle(self._handle) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._title = str(source.get_type()) <TAB> <TAB> <TAB> self._value = source.get_name(),true,if source :,if source :,0.53,0.0
"def _gridconvvalue(self, value): <TAB> if isinstance(value, (str, _tkinter.Tcl_Obj)): <TAB> <TAB> try: <TAB> <TAB> <TAB> svalue = str(value) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> elif ""."" in svalue: <TAB> <TAB> <TAB> <TAB> return getdouble(svalue) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return getint(svalue) <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> pass <TAB> return value",false,if not svalue :,if svalue is None :,0.05,0.0
"def parseGrants(self, tree): <TAB> for grant in tree.findall("".//Grant""): <TAB> <TAB> grantee = Grantee() <TAB> <TAB> g = grant.find("".//Grantee"") <TAB> <TAB> grantee.xsi_type = g.attrib[""{http://www.w3.org/2001/XMLSchema-instance}type""] <TAB> <TAB> grantee.permission = grant.find(""Permission"").text <TAB> <TAB> for el in g: <TAB> <TAB> <TAB> if el.tag == ""DisplayName"": <TAB> <TAB> <TAB> <TAB> grantee.display_name = el.text <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> grantee.tag = el.tag <TAB> <TAB> <TAB> <TAB> grantee.name = el.text <TAB> <TAB> self.grantees.append(grantee)",true,"if el . tag == ""DisplayName"" :","if el . tag == ""DisplayName"" :",0.75,0.0
"def __init__(self, name: Optional[str] = None, order: int = 0): <TAB> if name is None: <TAB> <TAB> if order == 0: <TAB> <TAB> <TAB> name = ""std_dev"" <TAB> <TAB> elif order == 1: <TAB> <TAB> <TAB> name = ""sample_std_dev"" <TAB> <TAB> else: <TAB> <TAB> <TAB> name = f""std_dev{order})"" <TAB> super().__init__(name=name, order=order) <TAB> self.order = order",true,elif order == 1 :,elif order == 1 :,1.0,0.0
"def _shouldRollover(self): <TAB> if self.maxBytes > 0:  # are we rolling over? <TAB> <TAB> try: <TAB> <TAB> <TAB> self.stream.seek(0, 2)  # due to non-posix-compliant Windows feature <TAB> <TAB> except IOError: <TAB> <TAB> <TAB> return True <TAB> <TAB> if self.stream.tell() >= self.maxBytes: <TAB> <TAB> <TAB> return True <TAB> <TAB> else: <TAB> <TAB> <TAB> self._degrade(False, ""Rotation done or not needed at this time"") <TAB> return False",false,if self . stream . tell ( ) >= self . maxBytes :,if self . stream . tell ( ) >= self . maxlen :,0.92,0.0
"def userfullname(): <TAB> """"""Get the user's full name."""""" <TAB> global _userfullname <TAB> if not _userfullname: <TAB> <TAB> uid = os.getuid() <TAB> <TAB> entry = pwd_from_uid(uid) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> _userfullname = entry[4].split("","")[0] or entry[0] <TAB> <TAB> if not _userfullname: <TAB> <TAB> <TAB> _userfullname = ""user%d"" % uid <TAB> return _userfullname",true,if entry :,if entry :,0.53,0.0
"def drop(self): <TAB> # mssql <TAB> sql = ""if object_id('%s') is not null drop table %s"" % (self.tname, self.tname) <TAB> try: <TAB> <TAB> self.execute(sql) <TAB> except Exception as e: <TAB> <TAB> self.conn.rollback() <TAB> <TAB> if ""syntax error"" not in str(e): <TAB> <TAB> <TAB> raise <TAB> <TAB> # sqlite <TAB> <TAB> sql = ""drop table if exists %s"" % self.tname <TAB> <TAB> self.execute(sql)",true,"if ""syntax error"" not in str ( e ) :","if ""syntax error"" not in str ( e ) :",0.75,0.0
"def _find_delimiter(f, block_size=2 ** 16): <TAB> delimiter = b""\n"" <TAB> if f.tell() == 0: <TAB> <TAB> return 0 <TAB> while True: <TAB> <TAB> b = f.read(block_size) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return f.tell() <TAB> <TAB> elif delimiter in b: <TAB> <TAB> <TAB> return f.tell() - len(b) + b.index(delimiter) + 1",true,if not b :,if not b :,0.75,0.0
"def _convert(container): <TAB> if _value_marker in container: <TAB> <TAB> force_list = False <TAB> <TAB> values = container.pop(_value_marker) <TAB> <TAB> if container.pop(_list_marker, False): <TAB> <TAB> <TAB> force_list = True <TAB> <TAB> <TAB> values.extend(_convert(x[1]) for x in sorted(container.items())) <TAB> <TAB> if not force_list and len(values) == 1: <TAB> <TAB> <TAB> values = values[0] <TAB> <TAB> if not container: <TAB> <TAB> <TAB> return values <TAB> <TAB> return _convert(container) <TAB> elif container.pop(_list_marker, False): <TAB> <TAB> return [_convert(x[1]) for x in sorted(container.items())] <TAB> return dict_cls((k, _convert(v)) for k, v in iteritems(container))",true,"if container . pop ( _list_marker , False ) :","if container . pop ( _list_marker , False ) :",0.75,0.0
"def fitting(self, value): <TAB> self._fitting = value <TAB> if self._fitting is not None: <TAB> <TAB> if not os.path.exists(dirname(self.checkpoint_path())): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> os.makedirs(dirname(self.checkpoint_path())) <TAB> <TAB> <TAB> except FileExistsError as ex: <TAB> <TAB> <TAB> <TAB> pass  # race to create <TAB> <TAB> if not os.path.exists(dirname(self.tensorboard_path())): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> os.makedirs(dirname(self.tensorboard_path())) <TAB> <TAB> <TAB> except FileExistsError as ex: <TAB> <TAB> <TAB> <TAB> pass  # race to create",true,if not os . path . exists ( dirname ( self . checkpoint_path ( ) ) ) :,if not os . path . exists ( dirname ( self . checkpoint_path ( ) ) ) :,0.75,0.0
"def _make_headers(self): <TAB> libraries = self._df.columns.to_list() <TAB> columns = [] <TAB> for library in libraries: <TAB> <TAB> version = self._package_versions[library] <TAB> <TAB> library_description = self._libraries_description.get(library) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> library += "" {}"".format(library_description) <TAB> <TAB> columns.append( <TAB> <TAB> <TAB> ""{library}<br><small>{version}</small>"".format( <TAB> <TAB> <TAB> <TAB> library=library, version=version <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> return [""""] + columns",true,if library_description :,if library_description :,0.53,0.0
"def plugin_on_song_ended(self, song, stopped): <TAB> if song is not None: <TAB> <TAB> poll = self.rating_box.poll_vote() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ups = int(song.get(""~#wins"") or 0) <TAB> <TAB> <TAB> downs = int(song.get(""~#losses"") or 0) <TAB> <TAB> <TAB> ups += poll[0] <TAB> <TAB> <TAB> downs += poll[1] <TAB> <TAB> <TAB> song[""~#wins""] = ups <TAB> <TAB> <TAB> song[""~#losses""] = downs <TAB> <TAB> <TAB> song[""~#rating""] = ups / max((ups + downs), 2) <TAB> <TAB> <TAB> # note: ^^^ Look into implementing w/ confidence intervals! <TAB> <TAB> <TAB> song[""~#score""] = ups - downs",false,if poll [ 0 ] >= 1 or poll [ 1 ] >= 1 :,if poll is not None :,0.05,0.0
"def submit(self, pig_script, params): <TAB> workflow = None <TAB> try: <TAB> <TAB> workflow = self._create_workflow(pig_script, params) <TAB> <TAB> mapping = dict( <TAB> <TAB> <TAB> [(param[""name""], param[""value""]) for param in workflow.get_parameters()] <TAB> <TAB> ) <TAB> <TAB> oozie_wf = _submit_workflow(self.user, self.fs, self.jt, workflow, mapping) <TAB> finally: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> workflow.delete(skip_trash=True) <TAB> return oozie_wf",true,if workflow :,if workflow :,0.53,0.0
"def test_parse(self): <TAB> correct = 0 <TAB> for example in EXAMPLES: <TAB> <TAB> try: <TAB> <TAB> <TAB> schema.parse(example.schema_string) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> correct += 1 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.fail(""Invalid schema was parsed: "" + example.schema_string) <TAB> <TAB> except: <TAB> <TAB> <TAB> if not example.valid: <TAB> <TAB> <TAB> <TAB> correct += 1 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.fail(""Valid schema failed to parse: "" + example.schema_string) <TAB> fail_msg = ""Parse behavior correct on %d out of %d schemas."" % ( <TAB> <TAB> correct, <TAB> <TAB> len(EXAMPLES), <TAB> ) <TAB> self.assertEqual(correct, len(EXAMPLES), fail_msg)",true,if example . valid :,if example . valid :,0.75,0.0
"def handle_sent(self, elt): <TAB> sent = [] <TAB> for child in elt: <TAB> <TAB> if child.tag in (""wf"", ""punc""): <TAB> <TAB> <TAB> itm = self.handle_word(child) <TAB> <TAB> <TAB> if self._unit == ""word"": <TAB> <TAB> <TAB> <TAB> sent.extend(itm) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> sent.append(itm) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""Unexpected element %s"" % child.tag) <TAB> return SemcorSentence(elt.attrib[""snum""], sent)",true,"if self . _unit == ""word"" :","if self . _unit == ""word"" :",0.75,0.0
"def _set_property(self, target_widget, pname, value): <TAB> if pname == ""text"": <TAB> <TAB> state = target_widget.cget(""state"") <TAB> <TAB> if state == tk.DISABLED: <TAB> <TAB> <TAB> target_widget.configure(state=tk.NORMAL) <TAB> <TAB> <TAB> target_widget.insert(""0.0"", value) <TAB> <TAB> <TAB> target_widget.configure(state=tk.DISABLED) <TAB> <TAB> else: <TAB> <TAB> <TAB> target_widget.insert(""0.0"", value) <TAB> else: <TAB> <TAB> super(TKText, self)._set_property(target_widget, pname, value)",true,if state == tk . DISABLED :,if state == tk . DISABLED :,0.75,0.0
"def get_vrf_tables(self, vrf_rf=None): <TAB> vrf_tables = {} <TAB> for (scope_id, table_id), table in self._tables.items(): <TAB> <TAB> if scope_id is None: <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> vrf_tables[(scope_id, table_id)] = table <TAB> return vrf_tables",false,if vrf_rf is not None and table_id != vrf_rf :,if vrf_rf is not None and table_rf not in vrf_rf :,0.46,0.0
"def new_f(self, *args, **kwargs): <TAB> for obj in f(self, *args, **kwargs): <TAB> <TAB> if self.protected == False: <TAB> <TAB> <TAB> if ""user"" in obj and obj[""user""][""protected""]: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> elif ""protected"" in obj and obj[""protected""]: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield obj",true,"elif ""protected"" in obj and obj [ ""protected"" ] :","elif ""protected"" in obj and obj [ ""protected"" ] :",1.0,0.0
"def draw(self, context): <TAB> col = self.layout.column() <TAB> col.operator(""node.sv_show_latest_commits"") <TAB> if context.scene.sv_new_version: <TAB> <TAB> col_alert = self.layout.column() <TAB> <TAB> col_alert.alert = True <TAB> <TAB> col_alert.operator(""node.sverchok_update_addon"", text=""Upgrade Sverchok addon"") <TAB> else: <TAB> <TAB> col.operator(""node.sverchok_check_for_upgrades_wsha"", text=""Check for updates"") <TAB> with sv_preferences() as prefs: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> col.operator(""node.sv_run_pydoc"")",false,if prefs . developer_mode :,if prefs . has_run :,0.39,0.0
"def generate_tag_1_data(ids): <TAB> if len(ids) != SAMPLE_NUM: <TAB> <TAB> raise ValueError(""len ids should equal to sample number"") <TAB> counter = 0 <TAB> for sample_i in range(SAMPLE_NUM): <TAB> <TAB> one_data = [ids[sample_i]] <TAB> <TAB> valid_set = [x for x in range(TAG_INTERVAL[0], TAG_INTERVAL[1])] <TAB> <TAB> features = np.random.choice(valid_set, FEATURE_NUM, replace=False) <TAB> <TAB> one_data += ["":"".join([x, ""1.0""]) for x in features] <TAB> <TAB> counter += 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(""generate data {}"".format(counter)) <TAB> <TAB> yield one_data",true,if counter % 10000 == 0 :,if counter % 10000 == 0 :,0.75,0.0
"def handle_api_languages(self, http_context): <TAB> mgr = PluginManager.get(aj.context) <TAB> languages = set() <TAB> for id in mgr: <TAB> <TAB> locale_dir = mgr.get_content_path(id, ""locale"") <TAB> <TAB> if os.path.isdir(locale_dir): <TAB> <TAB> <TAB> for lang in os.listdir(locale_dir): <TAB> <TAB> <TAB> <TAB> if lang != ""app.pot"": <TAB> <TAB> <TAB> <TAB> <TAB> languages.add(lang) <TAB> return sorted(list(languages))",true,if os . path . isdir ( locale_dir ) :,if os . path . isdir ( locale_dir ) :,0.75,0.0
"def update(self, t): <TAB> # direction right - up <TAB> for i in range(self.grid.x): <TAB> <TAB> for j in range(self.grid.y): <TAB> <TAB> <TAB> distance = self.test_func(i, j, t) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.turn_off_tile(i, j) <TAB> <TAB> <TAB> elif distance < 1: <TAB> <TAB> <TAB> <TAB> self.transform_tile(i, j, distance) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.turn_on_tile(i, j)",false,if distance == 0 :,if distance > 0 :,0.33,0.0
"def _handle_autocomplete_request_for_text(text): <TAB> if not hasattr(text, ""autocompleter""): <TAB> <TAB> if isinstance(text, (CodeViewText, ShellText)) and text.is_python_text(): <TAB> <TAB> <TAB> if isinstance(text, CodeViewText): <TAB> <TAB> <TAB> <TAB> text.autocompleter = Completer(text) <TAB> <TAB> <TAB> elif isinstance(text, ShellText): <TAB> <TAB> <TAB> <TAB> text.autocompleter = ShellCompleter(text) <TAB> <TAB> <TAB> text.bind(""<1>"", text.autocompleter.on_text_click) <TAB> <TAB> else: <TAB> <TAB> <TAB> return <TAB> text.autocompleter.handle_autocomplete_request()",false,"elif isinstance ( text , ShellText ) :","if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) :",0.23,0.0
"def test_create_repository(repo_name, expected_status, client): <TAB> with client_with_identity(""devtable"", client) as cl: <TAB> <TAB> body = { <TAB> <TAB> <TAB> ""namespace"": ""devtable"", <TAB> <TAB> <TAB> ""repository"": repo_name, <TAB> <TAB> <TAB> ""visibility"": ""public"", <TAB> <TAB> <TAB> ""description"": ""foo"", <TAB> <TAB> } <TAB> <TAB> result = conduct_api_call( <TAB> <TAB> <TAB> client, RepositoryList, ""post"", None, body, expected_code=expected_status <TAB> <TAB> ).json <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> assert result[""name""] == repo_name <TAB> <TAB> <TAB> assert ( <TAB> <TAB> <TAB> <TAB> model.repository.get_repository(""devtable"", repo_name).name == repo_name <TAB> <TAB> <TAB> )",false,if expected_status == 201 :,"if ""name"" in result :",0.03,0.0
"def _apply_filter(filter_item, filter_list): <TAB> for filter_method in filter_list: <TAB> <TAB> try: <TAB> <TAB> <TAB> if not filter_method(context, filter_item): <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> raise MessageException( <TAB> <TAB> <TAB> <TAB> ""Toolbox filter exception from '{}': {}."".format( <TAB> <TAB> <TAB> <TAB> <TAB> filter_method.__name__, unicodify(e) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return True",true,"if not filter_method ( context , filter_item ) :","if not filter_method ( context , filter_item ) :",0.75,0.0
"def printsumfp(fp, filename, out=sys.stdout): <TAB> m = md5() <TAB> try: <TAB> <TAB> while 1: <TAB> <TAB> <TAB> data = fp.read(bufsize) <TAB> <TAB> <TAB> if not data: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if isinstance(data, str): <TAB> <TAB> <TAB> <TAB> data = data.encode(fp.encoding) <TAB> <TAB> <TAB> m.update(data) <TAB> except IOError as msg: <TAB> <TAB> sys.stderr.write(""%s: I/O error: %s\n"" % (filename, msg)) <TAB> <TAB> return 1 <TAB> out.write(""%s %s\n"" % (m.hexdigest(), filename)) <TAB> return 0",true,"if isinstance ( data , str ) :","if isinstance ( data , str ) :",0.75,0.0
"def get_block_loc_keys(block): <TAB> """"""Extract loc_keys used by @block"""""" <TAB> symbols = set() <TAB> for instr in block.lines: <TAB> <TAB> if isinstance(instr, AsmRaw): <TAB> <TAB> <TAB> if isinstance(instr.raw, list): <TAB> <TAB> <TAB> <TAB> for expr in instr.raw: <TAB> <TAB> <TAB> <TAB> <TAB> symbols.update(get_expr_locs(expr)) <TAB> <TAB> else: <TAB> <TAB> <TAB> for arg in instr.args: <TAB> <TAB> <TAB> <TAB> symbols.update(get_expr_locs(arg)) <TAB> return symbols",true,"if isinstance ( instr , AsmRaw ) :","if isinstance ( instr , AsmRaw ) :",0.75,0.0
"def get_operations(cls, info, operations: List[ProductAttributeAssignInput]): <TAB> """"""Resolve all passed global ids into integer PKs of the Attribute type."""""" <TAB> product_attrs_pks = [] <TAB> variant_attrs_pks = [] <TAB> for operation in operations: <TAB> <TAB> pk = from_global_id_strict_type( <TAB> <TAB> <TAB> operation.id, only_type=Attribute, field=""operations"" <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> product_attrs_pks.append(pk) <TAB> <TAB> else: <TAB> <TAB> <TAB> variant_attrs_pks.append(pk) <TAB> return product_attrs_pks, variant_attrs_pks",false,if operation . type == ProductAttributeType . PRODUCT :,if operation . is_product :,0.13,0.0
"def _collect_manual_intervention_nodes(pipeline_tree): <TAB> for act in pipeline_tree[""activities""].values(): <TAB> <TAB> if act[""type""] == ""SubProcess"": <TAB> <TAB> <TAB> _collect_manual_intervention_nodes(act[""pipeline""]) <TAB> <TAB> elif act[""component""][""code""] in MANUAL_INTERVENTION_COMP_CODES: <TAB> <TAB> <TAB> manual_intervention_nodes.add(act[""id""])",true,"elif act [ ""component"" ] [ ""code"" ] in MANUAL_INTERVENTION_COMP_CODES :","elif act [ ""component"" ] [ ""code"" ] in MANUAL_INTERVENTION_COMP_CODES :",0.75,0.0
"def prompt_authorization(self, stacks: List[Stack]): <TAB> auth_required_per_resource = auth_per_resource(stacks) <TAB> for resource, authorization_required in auth_required_per_resource: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> auth_confirm = confirm( <TAB> <TAB> <TAB> <TAB> f""\t{self.start_bold}{resource} may not have authorization defined, Is this okay?{self.end_bold}"", <TAB> <TAB> <TAB> <TAB> default=False, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if not auth_confirm: <TAB> <TAB> <TAB> <TAB> raise GuidedDeployFailedError(msg=""Security Constraints Not Satisfied!"")",false,if not authorization_required :,if authorization_required :,0.1,0.0
"def get_cloud_credential(self): <TAB> """"""Return the credential which is directly tied to the inventory source type."""""" <TAB> credential = None <TAB> for cred in self.credentials.all(): <TAB> <TAB> if self.source in CLOUD_PROVIDERS: <TAB> <TAB> <TAB> if cred.kind == self.source.replace(""ec2"", ""aws""): <TAB> <TAB> <TAB> <TAB> credential = cred <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> # these need to be returned in the API credential field <TAB> <TAB> <TAB> if cred.credential_type.kind != ""vault"": <TAB> <TAB> <TAB> <TAB> credential = cred <TAB> <TAB> <TAB> <TAB> break <TAB> return credential",false,"if cred . kind == self . source . replace ( ""ec2"" , ""aws"" ) :","if cred . credential_type . kind != ""vault"" :",0.11,0.0
"def validate_party_details(self): <TAB> if self.party: <TAB> <TAB> if not frappe.db.exists(self.party_type, self.party): <TAB> <TAB> <TAB> frappe.throw(_(""Invalid {0}: {1}"").format(self.party_type, self.party)) <TAB> <TAB> if self.party_account and self.party_type in (""Customer"", ""Supplier""): <TAB> <TAB> <TAB> self.validate_account_type( <TAB> <TAB> <TAB> <TAB> self.party_account, [erpnext.get_party_account_type(self.party_type)] <TAB> <TAB> <TAB> )",true,"if self . party_account and self . party_type in ( ""Customer"" , ""Supplier"" ) :","if self . party_account and self . party_type in ( ""Customer"" , ""Supplier"" ) :",0.75,0.0
"def __iter__(self): <TAB> it = DiskHashMerger.__iter__(self) <TAB> direct_upstreams = self.direct_upstreams <TAB> for k, groups in it: <TAB> <TAB> t = list([[] for _ in range(self.size)]) <TAB> <TAB> for i, g in enumerate(groups): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if i in direct_upstreams: <TAB> <TAB> <TAB> <TAB> <TAB> t[i] = g <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> g.sort(key=itemgetter(0)) <TAB> <TAB> <TAB> <TAB> <TAB> g1 = [] <TAB> <TAB> <TAB> <TAB> <TAB> for _, vs in g: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> g1.extend(vs) <TAB> <TAB> <TAB> <TAB> <TAB> t[i] = g1 <TAB> <TAB> yield k, tuple(t)",true,if g :,if g :,0.53,0.0
"def _unpack_scales(scales, vidxs): <TAB> scaleData = [None, None, None] <TAB> for i in range(3): <TAB> <TAB> if i >= min(len(scales), len(vidxs) // 2): <TAB> <TAB> <TAB> break <TAB> <TAB> scale = scales[i] <TAB> <TAB> if not math.isnan(scale): <TAB> <TAB> <TAB> vidx1, vidx2 = vidxs[i * 2], vidxs[i * 2 + 1] <TAB> <TAB> <TAB> scaleData[i] = (int(vidx1), int(vidx2), float(scale)) <TAB> return scaleData",true,"if i >= min ( len ( scales ) , len ( vidxs ) // 2 ) :","if i >= min ( len ( scales ) , len ( vidxs ) // 2 ) :",1.0,0.0
"def _make_ext_obj(self, obj): <TAB> ext = self._get_ext_class(obj.objname)() <TAB> for name, val in obj.body: <TAB> <TAB> if not isinstance(val, list): <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> ""Error val should be a list, this is a python-opcua bug"", <TAB> <TAB> <TAB> <TAB> name, <TAB> <TAB> <TAB> <TAB> type(val), <TAB> <TAB> <TAB> <TAB> val, <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> for attname, v in val: <TAB> <TAB> <TAB> <TAB> self._set_attr(ext, attname, v) <TAB> return ext",true,"if not isinstance ( val , list ) :","if not isinstance ( val , list ) :",0.75,0.0
"def insertLine(self, refnum, linenum, line): <TAB> i = -1 <TAB> for i, row in enumerate(self.rows): <TAB> <TAB> if row[0] == linenum: <TAB> <TAB> <TAB> if row[refnum + 1] is None: <TAB> <TAB> <TAB> <TAB> row[refnum + 1] = line <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> # else keep looking <TAB> <TAB> elif row[0] > linenum: <TAB> <TAB> <TAB> break <TAB> self.rows.insert(i, self.newRow(linenum, refnum, line))",true,elif row [ 0 ] > linenum :,elif row [ 0 ] > linenum :,0.75,0.0
"def valid_localparts(strip_delimiters=False): <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS.split(""\n""): <TAB> <TAB> # strip line, skip over empty lines <TAB> <TAB> line = line.strip() <TAB> <TAB> if line == """": <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over comments or empty lines <TAB> <TAB> match = COMMENT.match(line) <TAB> <TAB> if match: <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over localparts with delimiters <TAB> <TAB> if strip_delimiters: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield line",false,"if "","" in line or "";"" in line :","if line == """" :",0.02,0.0
"def encodingChanged(self, idx): <TAB> encoding = str(self.mode_combo.currentText()) <TAB> validator = None <TAB> if encoding == ""hex"": <TAB> <TAB> # only clear the box if there are non-hex chars <TAB> <TAB> # before setting the validator. <TAB> <TAB> txt = str(self.data_edit.text()) <TAB> <TAB> if not all(c in string.hexdigits for c in txt): <TAB> <TAB> <TAB> self.data_edit.setText("""") <TAB> <TAB> regex = QtCore.QRegExp(""^[0-9A-Fa-f]+$"") <TAB> <TAB> validator = QtGui.QRegExpValidator(regex) <TAB> self.data_edit.setValidator(validator) <TAB> self.renderMemory()",true,if not all ( c in string . hexdigits for c in txt ) :,if not all ( c in string . hexdigits for c in txt ) :,1.0,0.0
"def _compare_single_run(self, compares_done): <TAB> try: <TAB> <TAB> compare_id, redo = self.in_queue.get( <TAB> <TAB> <TAB> timeout=float(self.config[""ExpertSettings""][""block_delay""]) <TAB> <TAB> ) <TAB> except Empty: <TAB> <TAB> pass <TAB> else: <TAB> <TAB> if self._decide_whether_to_process(compare_id, redo, compares_done): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.db_interface.delete_old_compare_result(compare_id) <TAB> <TAB> <TAB> compares_done.add(compare_id) <TAB> <TAB> <TAB> self._process_compare(compare_id) <TAB> <TAB> <TAB> if self.callback: <TAB> <TAB> <TAB> <TAB> self.callback()",false,if redo :,if compare_id not in compares_done :,0.05,0.0
"def _transform_bin(self, X: DataFrame): <TAB> if self._bin_map: <TAB> <TAB> if not self.inplace: <TAB> <TAB> <TAB> X = X.copy(deep=True) <TAB> <TAB> with pd.option_context(""mode.chained_assignment"", None): <TAB> <TAB> <TAB> # Pandas complains about SettingWithCopyWarning, but this should be valid. <TAB> <TAB> <TAB> for column in self._bin_map: <TAB> <TAB> <TAB> <TAB> X[column] = binning.bin_column( <TAB> <TAB> <TAB> <TAB> <TAB> series=X[column], <TAB> <TAB> <TAB> <TAB> <TAB> mapping=self._bin_map[column], <TAB> <TAB> <TAB> <TAB> <TAB> dtype=self._astype_map[column], <TAB> <TAB> <TAB> <TAB> ) <TAB> return X",true,if not self . inplace :,if not self . inplace :,0.75,0.0
"def escape(text, newline=False): <TAB> """"""Escape special html characters."""""" <TAB> if isinstance(text, str): <TAB> <TAB> if ""&"" in text: <TAB> <TAB> <TAB> text = text.replace(""&"", ""&amp;"") <TAB> <TAB> if "">"" in text: <TAB> <TAB> <TAB> text = text.replace("">"", ""&gt;"") <TAB> <TAB> if ""<"" in text: <TAB> <TAB> <TAB> text = text.replace(""<"", ""&lt;"") <TAB> <TAB> if '""' in text: <TAB> <TAB> <TAB> text = text.replace('""', ""&quot;"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> text = text.replace(""'"", ""&quot;"") <TAB> <TAB> if newline: <TAB> <TAB> <TAB> if ""\n"" in text: <TAB> <TAB> <TAB> <TAB> text = text.replace(""\n"", ""<br>"") <TAB> return text",false,"if ""'"" in text :","if '""' in text :",0.14,0.0
"def read(self): <TAB> """"""Reads the robots.txt URL and feeds it to the parser."""""" <TAB> try: <TAB> <TAB> f = urllib.request.urlopen(self.url) <TAB> except urllib.error.HTTPError as err: <TAB> <TAB> if err.code in (401, 403): <TAB> <TAB> <TAB> self.disallow_all = True <TAB> <TAB> elif err.code >= 400 and err.code < 500: <TAB> <TAB> <TAB> self.allow_all = True <TAB> else: <TAB> <TAB> raw = f.read() <TAB> <TAB> self.parse(raw.decode(""utf-8"").splitlines())",false,"if err . code in ( 401 , 403 ) :",elif err . code >= 400 and err . code < 500 :,0.04,0.0
"def post_create(self, user, billing=None): <TAB> from weblate.trans.models import Change <TAB> if billing: <TAB> <TAB> billing.projects.add(self) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.access_control = Project.ACCESS_PRIVATE <TAB> <TAB> else: <TAB> <TAB> <TAB> self.access_control = Project.ACCESS_PUBLIC <TAB> <TAB> self.save() <TAB> if not user.is_superuser: <TAB> <TAB> self.add_user(user, ""@Administration"") <TAB> Change.objects.create( <TAB> <TAB> action=Change.ACTION_CREATE_PROJECT, project=self, user=user, author=user <TAB> )",false,if billing . plan . change_access_control :,if user . is_superuser :,0.09,0.0
"def visitConst(self, node): <TAB> if self.documentable: <TAB> <TAB> if type(node.value) in (StringType, UnicodeType): <TAB> <TAB> <TAB> self.documentable.append(make_docstring(node.value, node.lineno)) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.documentable = None",true,"if type ( node . value ) in ( StringType , UnicodeType ) :","if type ( node . value ) in ( StringType , UnicodeType ) :",0.75,0.0
"def requires(self): <TAB> requires = copy.deepcopy(self._requires) <TAB> # Auto add dependencies when parameters reference the Ouptuts of <TAB> # another stack. <TAB> parameters = self.parameters <TAB> for value in parameters.values(): <TAB> <TAB> if isinstance(value, basestring) and ""::"" in value: <TAB> <TAB> <TAB> stack_name, _ = value.split(""::"") <TAB> <TAB> else: <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> requires.add(stack_name) <TAB> return requires",false,if stack_name not in requires :,if stack_name :,0.05,0.0
"def __load_protos(): <TAB> g = globals() <TAB> for k, v in g.items(): <TAB> <TAB> if k.startswith(""PPP_""): <TAB> <TAB> <TAB> name = k[4:] <TAB> <TAB> <TAB> modname = name.lower() <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> mod = __import__(modname, g, level=1) <TAB> <TAB> <TAB> <TAB> PPP.set_p(v, getattr(mod, name)) <TAB> <TAB> <TAB> except (ImportError, AttributeError): <TAB> <TAB> <TAB> <TAB> continue",true,"if k . startswith ( ""PPP_"" ) :","if k . startswith ( ""PPP_"" ) :",0.75,0.0
"def init_weights(self): <TAB> """"""Initialize model weights."""""" <TAB> for m in self.predict_layers.modules(): <TAB> <TAB> if isinstance(m, nn.Conv2d): <TAB> <TAB> <TAB> kaiming_init(m) <TAB> <TAB> elif isinstance(m, nn.BatchNorm2d): <TAB> <TAB> <TAB> constant_init(m, 1) <TAB> <TAB> elif isinstance(m, nn.Linear): <TAB> <TAB> <TAB> normal_init(m, std=0.01)",false,"elif isinstance ( m , nn . Linear ) :","elif isinstance ( m , nn . BatchNorm2d ) :",0.6,0.0
"def get_data(self): <TAB> """"""get all data from sockets"""""" <TAB> si = self.inputs <TAB> parameters = [] <TAB> for socket in si: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> parameters.append(socket.sv_get()) <TAB> <TAB> else: <TAB> <TAB> <TAB> parameters.append(socket.sv_get(default=[[]])) <TAB> return match_long_repeat(parameters)",false,if len ( socket . prop_name ) > 0 :,if socket . is_linked :,0.03,0.0
"def test_parse_query_params_comparable_field(self): <TAB> query_params = {""filter[int_field][gt]"": 42, ""filter[int_field][lte]"": 9000} <TAB> fields = self.view.parse_query_params(query_params) <TAB> for key, field_name in fields.items(): <TAB> <TAB> if field_name[""int_field""][""op""] == ""gt"": <TAB> <TAB> <TAB> assert_equal(field_name[""int_field""][""value""], 42) <TAB> <TAB> elif field_name[""int_field""][""op""] == ""lte"": <TAB> <TAB> <TAB> assert_equal(field_name[""int_field""][""value""], 9000) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.fail()",true,"elif field_name [ ""int_field"" ] [ ""op"" ] == ""lte"" :","elif field_name [ ""int_field"" ] [ ""op"" ] == ""lte"" :",1.0,0.0
"def _create_examples(self, lines, set_type): <TAB> """"""Creates examples for the training and dev sets."""""" <TAB> examples = [] <TAB> for (i, line) in enumerate(lines): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> guid = ""%s-%s"" % (set_type, i) <TAB> <TAB> text = line[0] <TAB> <TAB> bbox = line[1] <TAB> <TAB> label = line[2] <TAB> <TAB> examples.append( <TAB> <TAB> <TAB> DocExample(guid=guid, text_a=text, text_b=None, bbox=bbox, label=label) <TAB> <TAB> ) <TAB> return examples",true,if i == 0 :,if i == 0 :,0.75,0.0
"def _get_attr(sdk_path, mod_attr_path, checked=True): <TAB> try: <TAB> <TAB> attr_mod, attr_path = ( <TAB> <TAB> <TAB> mod_attr_path.split(""#"") if ""#"" in mod_attr_path else (mod_attr_path, """") <TAB> <TAB> ) <TAB> <TAB> full_mod_path = ""{}.{}"".format(sdk_path, attr_mod) if attr_mod else sdk_path <TAB> <TAB> op = import_module(full_mod_path) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # Only load attributes if needed <TAB> <TAB> <TAB> for part in attr_path.split("".""): <TAB> <TAB> <TAB> <TAB> op = getattr(op, part) <TAB> <TAB> return op <TAB> except (ImportError, AttributeError) as ex: <TAB> <TAB> if checked: <TAB> <TAB> <TAB> return None <TAB> <TAB> raise ex",true,if attr_path :,if attr_path :,0.53,0.0
"def _load_ui_modules(self, modules: Any) -> None: <TAB> if isinstance(modules, types.ModuleType): <TAB> <TAB> self._load_ui_modules(dict((n, getattr(modules, n)) for n in dir(modules))) <TAB> elif isinstance(modules, list): <TAB> <TAB> for m in modules: <TAB> <TAB> <TAB> self._load_ui_modules(m) <TAB> else: <TAB> <TAB> assert isinstance(modules, dict) <TAB> <TAB> for name, cls in modules.items(): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> if issubclass(cls, UIModule): <TAB> <TAB> <TAB> <TAB> <TAB> self.ui_modules[name] = cls <TAB> <TAB> <TAB> except TypeError: <TAB> <TAB> <TAB> <TAB> pass",true,"if issubclass ( cls , UIModule ) :","if issubclass ( cls , UIModule ) :",0.75,0.0
"def _remove_obsolete_leafs(input_dict): <TAB> if not isinstance(input_dict, dict): <TAB> <TAB> return <TAB> if input_dict[LEAF_MARKER]: <TAB> <TAB> bottom_leafs = input_dict[LEAF_MARKER] <TAB> <TAB> for leaf in bottom_leafs: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> input_dict[LEAF_MARKER].remove(leaf) <TAB> for subtree in input_dict.keys(): <TAB> <TAB> _remove_obsolete_leafs(input_dict[subtree])",true,if leaf in input_dict :,if leaf in input_dict :,0.75,0.0
"def decode(self, value, force=False): <TAB> ""Return a unicode string from the bytes-like representation"" <TAB> if self.decode_responses or force: <TAB> <TAB> if isinstance(value, memoryview): <TAB> <TAB> <TAB> value = value.tobytes() <TAB> <TAB> if isinstance(value, bytes): <TAB> <TAB> <TAB> value = value.decode(self.encoding, self.encoding_errors) <TAB> return value",true,"if isinstance ( value , memoryview ) :","if isinstance ( value , memoryview ) :",0.75,0.0
"def audit(self, directive): <TAB> value = _get_value(directive) <TAB> if not value: <TAB> <TAB> return <TAB> server_side = directive.name.startswith(""proxy_"") <TAB> for var in compile_script(value): <TAB> <TAB> char = """" <TAB> <TAB> if var.can_contain(""\n""): <TAB> <TAB> <TAB> char = ""\\n"" <TAB> <TAB> elif not server_side and var.can_contain(""\r""): <TAB> <TAB> <TAB> char = ""\\r"" <TAB> <TAB> else: <TAB> <TAB> <TAB> continue <TAB> <TAB> reason = 'At least variable ""${var}"" can contain ""{char}""'.format( <TAB> <TAB> <TAB> var=var.name, char=char <TAB> <TAB> ) <TAB> <TAB> self.add_issue(directive=[directive] + var.providers, reason=reason)",false,"if var . can_contain ( ""\n"" ) :","elif not server_side and var . can_contain ( ""\r"" ) :",0.35,0.0
"def checkFilename(filename):  # useful in case of drag and drop <TAB> while True: <TAB> <TAB> if filename[0] == ""'"": <TAB> <TAB> <TAB> filename = filename[1:] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> filename = filename[:-1] <TAB> <TAB> if os.path.exists(filename): <TAB> <TAB> <TAB> return filename <TAB> <TAB> filename = input( <TAB> <TAB> <TAB> ""[!] Cannot find '%s'.\n[*] Enter a valid name of the file containing the paths to test -> "" <TAB> <TAB> <TAB> % filename <TAB> <TAB> )",false,"if filename [ len ( filename ) - 1 ] == ""'"" :",if len ( filename ) > 1 :,0.22,0.0
"def findfiles(self, dir, base, rec): <TAB> try: <TAB> <TAB> names = os.listdir(dir or os.curdir) <TAB> except os.error as msg: <TAB> <TAB> print(msg) <TAB> <TAB> return [] <TAB> list = [] <TAB> subdirs = [] <TAB> for name in names: <TAB> <TAB> fn = os.path.join(dir, name) <TAB> <TAB> if os.path.isdir(fn): <TAB> <TAB> <TAB> subdirs.append(fn) <TAB> <TAB> else: <TAB> <TAB> <TAB> if fnmatch.fnmatch(name, base): <TAB> <TAB> <TAB> <TAB> list.append(fn) <TAB> if rec: <TAB> <TAB> for subdir in subdirs: <TAB> <TAB> <TAB> list.extend(self.findfiles(subdir, base, rec)) <TAB> return list",false,if os . path . isdir ( fn ) :,"if fnmatch . fnmatch ( name , base ) :",0.03,0.0
"def loop(handler, obj): <TAB> handler.response.write(""<table>"") <TAB> for k, v in obj.__dict__.items(): <TAB> <TAB> if not k in (""data"", ""gae_user"", ""credentials"", ""content"", ""config""): <TAB> <TAB> <TAB> style = ""color: red"" if not v else """" <TAB> <TAB> <TAB> handler.response.write( <TAB> <TAB> <TAB> <TAB> '<tr style=""{}""><td>{}:</td><td>{}</td></tr>'.format(style, k, v) <TAB> <TAB> <TAB> ) <TAB> handler.response.write(""</table>"")",true,"if not k in ( ""data"" , ""gae_user"" , ""credentials"" , ""content"" , ""config"" ) :","if not k in ( ""data"" , ""gae_user"" , ""credentials"" , ""content"" , ""config"" ) :",0.75,0.0
"def anypython(request): <TAB> name = request.param <TAB> executable = getexecutable(name) <TAB> if executable is None: <TAB> <TAB> if sys.platform == ""win32"": <TAB> <TAB> <TAB> executable = winpymap.get(name, None) <TAB> <TAB> <TAB> if executable: <TAB> <TAB> <TAB> <TAB> executable = py.path.local(executable) <TAB> <TAB> <TAB> <TAB> if executable.check(): <TAB> <TAB> <TAB> <TAB> <TAB> return executable <TAB> <TAB> pytest.skip(""no suitable %s found"" % (name,)) <TAB> return executable",true,if executable . check ( ) :,if executable . check ( ) :,0.75,0.0
"def __init__(self, socketpath=None): <TAB> if socketpath is None: <TAB> <TAB> if sys.platform == ""darwin"": <TAB> <TAB> <TAB> socketpath = ""/var/run/usbmuxd"" <TAB> <TAB> else: <TAB> <TAB> <TAB> socketpath = ""/var/run/usbmuxd"" <TAB> self.socketpath = socketpath <TAB> self.listener = MuxConnection(socketpath, BinaryProtocol) <TAB> try: <TAB> <TAB> self.listener.listen() <TAB> <TAB> self.version = 0 <TAB> <TAB> self.protoclass = BinaryProtocol <TAB> except MuxVersionError: <TAB> <TAB> self.listener = MuxConnection(socketpath, PlistProtocol) <TAB> <TAB> self.listener.listen() <TAB> <TAB> self.protoclass = PlistProtocol <TAB> <TAB> self.version = 1 <TAB> self.devices = self.listener.devices",true,"if sys . platform == ""darwin"" :","if sys . platform == ""darwin"" :",0.75,0.0
"def _validate_distinct_on_different_types_and_field_orders( <TAB> self, collection, query, expected_results, get_mock_result ): <TAB> self.count = 0 <TAB> self.get_mock_result = get_mock_result <TAB> query_iterable = collection.query_items(query, enable_cross_partition_query=True) <TAB> results = list(query_iterable) <TAB> for i in range(len(expected_results)): <TAB> <TAB> if isinstance(results[i], dict): <TAB> <TAB> <TAB> self.assertDictEqual(results[i], expected_results[i]) <TAB> <TAB> elif isinstance(results[i], list): <TAB> <TAB> <TAB> self.assertListEqual(results[i], expected_results[i]) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.assertEqual(results[i], expected_results[i]) <TAB> self.count = 0",false,"if isinstance ( results [ i ] , dict ) :","elif isinstance ( results [ i ] , list ) :",0.35,0.0
"def getRootId(self, id): <TAB> with self.connect() as cu: <TAB> <TAB> while True: <TAB> <TAB> <TAB> stmt = ""select parent_path_id from hierarchy where path_id = ?"" <TAB> <TAB> <TAB> cu.execute(stmt, (id,)) <TAB> <TAB> <TAB> parent_id = cu.fetchone()[0] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return id <TAB> <TAB> <TAB> id = parent_id",false,if parent_id is None or parent_id == id :,if parent_id == id :,0.24,0.0
"def add(self, path): <TAB> with self.get_lock(path): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.entries[path] = {} <TAB> <TAB> <TAB> self.entries[path][""lock""] = self.new_locks[path] <TAB> <TAB> <TAB> del self.new_locks[path] <TAB> <TAB> <TAB> self.lru.append(path)",false,if not path in self . entries :,if path not in self . entries :,0.54,0.0
"def _get_coordinates_for_dataset_key(self, dsid): <TAB> """"""Get the coordinate dataset keys for *dsid*."""""" <TAB> ds_info = self.ids[dsid] <TAB> cids = [] <TAB> for cinfo in ds_info.get(""coordinates"", []): <TAB> <TAB> if not isinstance(cinfo, dict): <TAB> <TAB> <TAB> cinfo = {""name"": cinfo} <TAB> <TAB> cinfo[""resolution""] = ds_info[""resolution""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> cinfo[""polarization""] = ds_info[""polarization""] <TAB> <TAB> cid = DatasetID(**cinfo) <TAB> <TAB> cids.append(self.get_dataset_key(cid)) <TAB> return cids",true,"if ""polarization"" in ds_info :","if ""polarization"" in ds_info :",0.75,0.0
"def build_from_gdobj(cls, gdobj, steal=False): <TAB> # Avoid calling cls.__init__ by first instanciating a placeholder, then <TAB> # overloading it __class__ to turn it into an instance of the right class <TAB> ret = BuiltinInitPlaceholder() <TAB> if steal: <TAB> <TAB> assert ffi.typeof(gdobj).kind == ""pointer"" <TAB> <TAB> ret._gd_ptr = gdobj <TAB> else: <TAB> <TAB> if ffi.typeof(gdobj).kind == ""pointer"": <TAB> <TAB> <TAB> ret._gd_ptr = cls._copy_gdobj(gdobj) <TAB> <TAB> else: <TAB> <TAB> <TAB> ret._gd_ptr = cls._copy_gdobj(ffi.addressof(gdobj)) <TAB> ret.__class__ = cls <TAB> return ret",true,"if ffi . typeof ( gdobj ) . kind == ""pointer"" :","if ffi . typeof ( gdobj ) . kind == ""pointer"" :",0.75,0.0
"def _listen_output(self): <TAB> ""NB! works in background thread"" <TAB> try: <TAB> <TAB> while True: <TAB> <TAB> <TAB> chars = self._proc.read(1) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> as_bytes = chars.encode(self.encoding) <TAB> <TAB> <TAB> <TAB> self._make_output_available(as_bytes) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self._error = ""EOF"" <TAB> <TAB> <TAB> <TAB> break <TAB> except Exception as e: <TAB> <TAB> self._error = str(e)",false,if len ( chars ) > 0 :,if chars :,0.02,0.0
"def result( <TAB> metrics: Dict[metric_types.MetricKey, Any] ) -> Dict[metric_types.AttributionsKey, Dict[Text, Union[float, np.ndarray]]]: <TAB> """"""Returns mean attributions."""""" <TAB> total_attributions = metrics[total_attributions_key] <TAB> weighted_count = metrics[weighted_example_count_key] <TAB> attributions = {} <TAB> for k, v in total_attributions.items(): <TAB> <TAB> if np.isclose(weighted_count, 0.0): <TAB> <TAB> <TAB> attributions[k] = float(""nan"") <TAB> <TAB> else: <TAB> <TAB> <TAB> attributions[k] = v / weighted_count <TAB> return {key: attributions}",true,"if np . isclose ( weighted_count , 0.0 ) :","if np . isclose ( weighted_count , 0.0 ) :",0.75,0.0
"def write_if_changed(path, data): <TAB> if isinstance(data, str): <TAB> <TAB> data = data.encode() <TAB> changed = False <TAB> with open(os.open(path, os.O_CREAT | os.O_RDWR), ""wb+"") as f: <TAB> <TAB> f.seek(0) <TAB> <TAB> current = f.read() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> f.seek(0) <TAB> <TAB> <TAB> f.write(data) <TAB> <TAB> <TAB> f.truncate() <TAB> <TAB> os.fsync(f) <TAB> return changed",true,if current != data :,if current != data :,0.75,0.0
"def detect_ssl_option(self): <TAB> for option in self.ssl_options(): <TAB> <TAB> if scan_argv(self.argv, option) is not None: <TAB> <TAB> <TAB> for other_option in self.ssl_options(): <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> if scan_argv(self.argv, other_option) is not None: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ConfigurationError( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""Cannot give both %s and %s"" % (option, other_option) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return option",false,if option != other_option :,if other_option in option :,0.04,0.0
"def _infer_return_type(*args): <TAB> """"""Look at the type of all args and divine their implied return type."""""" <TAB> return_type = None <TAB> for arg in args: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance(arg, bytes): <TAB> <TAB> <TAB> if return_type is str: <TAB> <TAB> <TAB> <TAB> raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."") <TAB> <TAB> <TAB> return_type = bytes <TAB> <TAB> else: <TAB> <TAB> <TAB> if return_type is bytes: <TAB> <TAB> <TAB> <TAB> raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."") <TAB> <TAB> <TAB> return_type = str <TAB> if return_type is None: <TAB> <TAB> return str  # tempfile APIs return a str by default. <TAB> return return_type",false,if arg is None :,if return_type is None :,0.39,0.0
"def _get_app(self, body=None): <TAB> app = self._app <TAB> if app is None: <TAB> <TAB> try: <TAB> <TAB> <TAB> tasks = self.tasks.tasks  # is a group <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> tasks = self.tasks <TAB> <TAB> if len(tasks): <TAB> <TAB> <TAB> app = tasks[0]._app <TAB> <TAB> if app is None and body is not None: <TAB> <TAB> <TAB> app = body._app <TAB> return app if app is not None else current_app",true,if len ( tasks ) :,if len ( tasks ) :,0.75,0.0
"def add_field(self, field): <TAB> self.remove_field(field.name) <TAB> self.fields[field.name] = field <TAB> self.columns[field.db_column] = field <TAB> self._sorted_field_list.insert(field) <TAB> self._update_field_lists() <TAB> if field.default is not None: <TAB> <TAB> self.defaults[field] = field.default <TAB> <TAB> if callable(field.default): <TAB> <TAB> <TAB> self._default_callables[field] = field.default <TAB> <TAB> <TAB> self._default_callable_list.append((field.name, field.default)) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._default_dict[field] = field.default <TAB> <TAB> <TAB> self._default_by_name[field.name] = field.default",true,if callable ( field . default ) :,if callable ( field . default ) :,0.75,0.0
"def _get_families(self): <TAB> families = [] <TAB> for name, ext in self._get_family_dirs(): <TAB> <TAB><IF-STMT>  # is a directory <TAB> <TAB> <TAB> family = self.get_resource( <TAB> <TAB> <TAB> <TAB> FileSystemPackageFamilyResource.key, location=self.location, name=name <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> family = self.get_resource( <TAB> <TAB> <TAB> <TAB> FileSystemCombinedPackageFamilyResource.key, <TAB> <TAB> <TAB> <TAB> location=self.location, <TAB> <TAB> <TAB> <TAB> name=name, <TAB> <TAB> <TAB> <TAB> ext=ext, <TAB> <TAB> <TAB> ) <TAB> <TAB> families.append(family) <TAB> return families",true,if ext is None :,if ext is None :,0.75,0.0
"def test(model, data_loader, device=None): <TAB> device = device or torch.device(""cpu"") <TAB> model.eval() <TAB> correct = 0 <TAB> total = 0 <TAB> with torch.no_grad(): <TAB> <TAB> for batch_idx, (data, target) in enumerate(data_loader): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> data, target = data.to(device), target.to(device) <TAB> <TAB> <TAB> outputs = model(data) <TAB> <TAB> <TAB> _, predicted = torch.max(outputs.data, 1) <TAB> <TAB> <TAB> total += target.size(0) <TAB> <TAB> <TAB> correct += (predicted == target).sum().item() <TAB> return correct / total",false,if batch_idx * len ( data ) > TEST_SIZE :,if batch_idx == 0 :,0.03,0.0
"def __animate_progress(self): <TAB> """"""Change the status message, mostly used to animate progress."""""" <TAB> while True: <TAB> <TAB> sleep_time = ThreadPool.PROGRESS_IDLE_DELAY <TAB> <TAB> with self.__progress_lock: <TAB> <TAB> <TAB> if not self.__progress_status: <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool.PROGRESS_IDLE_DELAY <TAB> <TAB> <TAB> elif self.__show_animation: <TAB> <TAB> <TAB> <TAB> self.__progress_status.update_progress(self.__current_operation_name) <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool.PROGRESS_UPDATE_DELAY <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.__progress_status.show_as_ready() <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool.PROGRESS_IDLE_DELAY <TAB> <TAB> # Allow some time for progress status to be updated. <TAB> <TAB> time.sleep(sleep_time)",false,if not self . __progress_status :,elif self . __show_animation :,0.3,0.0
"def _parse_subtitles(self, video_data, url_key): <TAB> subtitles = {} <TAB> for translation in video_data.get(""translations"", []): <TAB> <TAB> vtt_path = translation.get(url_key) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> lang = translation.get(""language_w3c"") or ISO639Utils.long2short( <TAB> <TAB> <TAB> translation[""language_medium""] <TAB> <TAB> ) <TAB> <TAB> subtitles.setdefault(lang, []).append( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> ""ext"": ""vtt"", <TAB> <TAB> <TAB> <TAB> ""url"": vtt_path, <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> return subtitles",false,if not vtt_path :,if vtt_path is None :,0.05,0.0
"def postprocess_message(self, msg): <TAB> if msg[""type""] == ""sample"" and msg[""value""] is not None: <TAB> <TAB> fn, value = msg[""fn""], msg[""value""] <TAB> <TAB> value_batch_ndims = jnp.ndim(value) - fn.event_dim <TAB> <TAB> fn_batch_ndim = len(fn.batch_shape) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> prepend_shapes = (1,) * (value_batch_ndims - fn_batch_ndim) <TAB> <TAB> <TAB> msg[""fn""] = tree_map( <TAB> <TAB> <TAB> <TAB> lambda x: jnp.reshape(x, prepend_shapes + jnp.shape(x)), fn <TAB> <TAB> <TAB> )",false,if fn_batch_ndim < value_batch_ndims :,if fn_batch_ndim > 0 :,0.06,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.set_filename(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0: <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 10 :,if tt == 10 :,0.75,0.0
"def createError(self, line, pos, description): <TAB> global ENABLE_PYIMPORT <TAB> msg = ""Line "" + unicode(line) + "": "" + unicode(description) <TAB> if ENABLE_JS2PY_ERRORS: <TAB> <TAB> if isinstance(ENABLE_JS2PY_ERRORS, bool): <TAB> <TAB> <TAB> import js2py.base <TAB> <TAB> <TAB> return js2py.base.MakeError(""SyntaxError"", msg) <TAB> <TAB> else: <TAB> <TAB> <TAB> return ENABLE_JS2PY_ERRORS(msg) <TAB> else: <TAB> <TAB> return JsSyntaxError(msg)",true,"if isinstance ( ENABLE_JS2PY_ERRORS , bool ) :","if isinstance ( ENABLE_JS2PY_ERRORS , bool ) :",0.75,0.0
"def extract(self, page, start_index=0, end_index=None): <TAB> items = [] <TAB> for extractor in self.extractors: <TAB> <TAB> extracted = extractor.extract( <TAB> <TAB> <TAB> page, start_index, end_index, self.template.ignored_regions <TAB> <TAB> ) <TAB> <TAB> for item in arg_to_iter(extracted): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if isinstance(item, (ItemProcessor, dict)): <TAB> <TAB> <TAB> <TAB> <TAB> item[u""_template""] = self.template.id <TAB> <TAB> <TAB> <TAB> items.append(item) <TAB> return items",false,if item :,if item is not None :,0.09,0.0
"def create_volume(self, volume): <TAB> """"""Create a volume."""""" <TAB> try: <TAB> <TAB> cmd = [""volume"", ""create"", volume[""name""], ""%sG"" % (volume[""size""])] <TAB> <TAB> if self.configuration.eqlx_pool != ""default"": <TAB> <TAB> <TAB> cmd.append(""pool"") <TAB> <TAB> <TAB> cmd.append(self.configuration.eqlx_pool) <TAB> <TAB> if self.configuration.san_thin_provision: <TAB> <TAB> <TAB> cmd.append(""thin-provision"") <TAB> <TAB> out = self._eql_execute(*cmd) <TAB> <TAB> self.add_multihost_access(volume) <TAB> <TAB> return self._get_volume_data(out) <TAB> except Exception: <TAB> <TAB> with excutils.save_and_reraise_exception(): <TAB> <TAB> <TAB> LOG.error('Failed to create volume ""%s"".', volume[""name""])",true,"if self . configuration . eqlx_pool != ""default"" :","if self . configuration . eqlx_pool != ""default"" :",0.75,0.0
"def clean(self): <TAB> # TODO: check for clashes if the random code is already taken <TAB> if not self.code: <TAB> <TAB> self.code = u""static-%s"" % uuid.uuid4() <TAB> if not self.site: <TAB> <TAB> placeholders = StaticPlaceholder.objects.filter( <TAB> <TAB> <TAB> code=self.code, site__isnull=True <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> placeholders = placeholders.exclude(pk=self.pk) <TAB> <TAB> if placeholders.exists(): <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> _(""A static placeholder with the same site and code already exists"") <TAB> <TAB> <TAB> )",true,if self . pk :,if self . pk :,0.75,0.0
"def spawnMenu(self, event): <TAB> clickedPos = self.getRowByAbs(event.Position) <TAB> self.ensureSelection(clickedPos) <TAB> selection = self.getSelectedBoosters() <TAB> mainBooster = None <TAB> if clickedPos != -1: <TAB> <TAB> try: <TAB> <TAB> <TAB> booster = self.boosters[clickedPos] <TAB> <TAB> except IndexError: <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> mainBooster = booster <TAB> itemContext = None if mainBooster is None else _t(""Booster"") <TAB> menu = ContextMenu.getMenu( <TAB> <TAB> self, <TAB> <TAB> mainBooster, <TAB> <TAB> selection, <TAB> <TAB> (""boosterItem"", itemContext), <TAB> <TAB> (""boosterItemMisc"", itemContext), <TAB> ) <TAB> if menu: <TAB> <TAB> self.PopupMenu(menu)",false,if booster in self . original :,if booster :,0.04,0.0
"def init_errorhandler(): <TAB> # http error handling <TAB> for ex in default_exceptions: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> app.register_error_handler(ex, error_http) <TAB> <TAB> elif ex == 500: <TAB> <TAB> <TAB> app.register_error_handler(ex, internal_error) <TAB> if services.ldap: <TAB> <TAB> # Only way of catching the LDAPException upon logging in with LDAP server down <TAB> <TAB> @app.errorhandler(services.ldap.LDAPException) <TAB> <TAB> def handle_exception(e): <TAB> <TAB> <TAB> log.debug(""LDAP server not accessible while trying to login to opds feed"") <TAB> <TAB> <TAB> return error_http(FailedDependency())",false,if ex < 500 :,if ex == 500 :,0.33,0.0
"def reloadCols(self): <TAB> self.columns = [] <TAB> for i, (name, fmt, *shape) in enumerate(self.npy.dtype.descr): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> t = anytype <TAB> <TAB> elif ""M"" in fmt: <TAB> <TAB> <TAB> self.addColumn(Column(name, type=date, getter=lambda c, r, i=i: str(r[i]))) <TAB> <TAB> <TAB> continue <TAB> <TAB> elif ""i"" in fmt: <TAB> <TAB> <TAB> t = int <TAB> <TAB> elif ""f"" in fmt: <TAB> <TAB> <TAB> t = float <TAB> <TAB> else: <TAB> <TAB> <TAB> t = anytype <TAB> <TAB> self.addColumn(ColumnItem(name, i, type=t))",false,if shape :,"if ""d"" in fmt :",0.05,0.0
"def Proc2(IntParIO): <TAB> IntLoc = IntParIO + 10 <TAB> while True: <TAB> <TAB> if Char1Glob == ""A"": <TAB> <TAB> <TAB> IntLoc = IntLoc - 1 <TAB> <TAB> <TAB> IntParIO = IntLoc - IntGlob <TAB> <TAB> <TAB> EnumLoc = Ident1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> return IntParIO",true,if EnumLoc == Ident1 :,if EnumLoc == Ident1 :,0.75,0.0
"def opengroup(self, name=None): <TAB> gid = self.groups <TAB> self.groupwidths.append(None) <TAB> if self.groups > MAXGROUPS: <TAB> <TAB> raise error(""too many groups"") <TAB> if name is not None: <TAB> <TAB> ogid = self.groupdict.get(name, None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise error( <TAB> <TAB> <TAB> <TAB> ""redefinition of group name %r as group %d; "" <TAB> <TAB> <TAB> <TAB> ""was group %d"" % (name, gid, ogid) <TAB> <TAB> <TAB> ) <TAB> <TAB> self.groupdict[name] = gid <TAB> return gid",true,if ogid is not None :,if ogid is not None :,0.75,0.0
"def __setattr__(self, name: str, val: Any): <TAB> if name.startswith(""COMPUTED_""): <TAB> <TAB> if name in self: <TAB> <TAB> <TAB> old_val = self[name] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> raise KeyError( <TAB> <TAB> <TAB> <TAB> ""Computed attributed '{}' already exists "" <TAB> <TAB> <TAB> <TAB> ""with a different value! old={}, new={}."".format(name, old_val, val) <TAB> <TAB> <TAB> ) <TAB> <TAB> self[name] = val <TAB> else: <TAB> <TAB> super().__setattr__(name, val)",false,if old_val == val :,if old_val != val :,0.33,0.0
"def get_all_function_symbols(self, module=""kernel""): <TAB> """"""Gets all the function tuples for the given module"""""" <TAB> ret = [] <TAB> symtable = self.type_map <TAB> if module in symtable: <TAB> <TAB> mod = symtable[module] <TAB> <TAB> for (addr, (name, _sym_types)) in mod.items(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> addr = addr + self.shift_address <TAB> <TAB> <TAB> ret.append([name, addr]) <TAB> else: <TAB> <TAB> debug.info(""All symbols requested for non-existent module %s"" % module) <TAB> return ret",false,if self . shift_address and addr :,if self . shift_address :,0.28,0.0
"def __call__(self, frame: FrameType, event: str, arg: Any) -> ""CallTracer"": <TAB> code = frame.f_code <TAB> if ( <TAB> <TAB> event not in SUPPORTED_EVENTS <TAB> <TAB> or code.co_name == ""trace_types"" <TAB> <TAB> or self.should_trace <TAB> <TAB> and not self.should_trace(code) <TAB> ): <TAB> <TAB> return self <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.handle_call(frame) <TAB> <TAB> elif event == EVENT_RETURN: <TAB> <TAB> <TAB> self.handle_return(frame, arg) <TAB> <TAB> else: <TAB> <TAB> <TAB> logger.error(""Cannot handle event %s"", event) <TAB> except Exception: <TAB> <TAB> logger.exception(""Failed collecting trace"") <TAB> return self",true,if event == EVENT_CALL :,if event == EVENT_CALL :,0.75,0.0
"def test_update_topic(self): <TAB> async with self.chat_client: <TAB> <TAB> await self._create_thread() <TAB> <TAB> topic = ""update topic"" <TAB> <TAB> async with self.chat_thread_client: <TAB> <TAB> <TAB> await self.chat_thread_client.update_topic(topic=topic) <TAB> <TAB> # delete chat threads <TAB> <TAB> if not self.is_playback(): <TAB> <TAB> <TAB> await self.chat_client.delete_chat_thread(self.thread_id)",true,if not self . is_playback ( ) :,if not self . is_playback ( ) :,0.75,0.0
"def render_observation(self): <TAB> x = self.read_head_position <TAB> label = ""Observation Grid <TAB>: "" <TAB> x_str = """" <TAB> for j in range(-1, self.rows + 1): <TAB> <TAB> if j != -1: <TAB> <TAB> <TAB> x_str += "" "" * len(label) <TAB> <TAB> for i in range(-2, self.input_width + 2): <TAB> <TAB> <TAB> if i == x[0] and j == x[1]: <TAB> <TAB> <TAB> <TAB> x_str += colorize(self._get_str_obs((i, j)), ""green"", highlight=True) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> x_str += self._get_str_obs((i, j)) <TAB> <TAB> x_str += ""\n"" <TAB> x_str = label + x_str <TAB> return x_str",true,if i == x [ 0 ] and j == x [ 1 ] :,if i == x [ 0 ] and j == x [ 1 ] :,1.0,0.0
"def build(opt): <TAB> dpath = os.path.join(opt[""datapath""], ""QA-ZRE"") <TAB> version = None <TAB> if not build_data.built(dpath, version_string=version): <TAB> <TAB> print(""[building data: "" + dpath + ""]"") <TAB> <TAB> if build_data.built(dpath): <TAB> <TAB> <TAB> # An older version exists, so remove these outdated files. <TAB> <TAB> <TAB> build_data.remove_dir(dpath) <TAB> <TAB> build_data.make_dir(dpath) <TAB> <TAB> # Download the data. <TAB> <TAB> for downloadable_file in RESOURCES: <TAB> <TAB> <TAB> downloadable_file.download_file(dpath) <TAB> <TAB> # Mark the data as built. <TAB> <TAB> build_data.mark_done(dpath, version_string=version)",true,if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,0.75,0.0
"def git_pull(args): <TAB> if len(args) <= 1: <TAB> <TAB> repo = _get_repo() <TAB> <TAB> _confirm_dangerous() <TAB> <TAB> url = args[0] if len(args) == 1 else repo.remotes.get(""origin"", """") <TAB> <TAB> if url in repo.remotes: <TAB> <TAB> <TAB> origin = url <TAB> <TAB> <TAB> url = repo.remotes.get(origin) <TAB> <TAB> if url: <TAB> <TAB> <TAB> repo.pull(origin_uri=url) <TAB> <TAB> else: <TAB> <TAB> <TAB> print(""No pull URL."") <TAB> else: <TAB> <TAB> print(command_help[""git pull""])",true,if url in repo . remotes :,if url in repo . remotes :,0.75,0.0
"def FindAndDelete(script, sig): <TAB> """"""Consensus critical, see FindAndDelete() in Satoshi codebase"""""" <TAB> r = b"""" <TAB> last_sop_idx = sop_idx = 0 <TAB> skip = True <TAB> for (opcode, data, sop_idx) in script.raw_iter(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> r += script[last_sop_idx:sop_idx] <TAB> <TAB> last_sop_idx = sop_idx <TAB> <TAB> if script[sop_idx : sop_idx + len(sig)] == sig: <TAB> <TAB> <TAB> skip = True <TAB> <TAB> else: <TAB> <TAB> <TAB> skip = False <TAB> if not skip: <TAB> <TAB> r += script[last_sop_idx:] <TAB> return CScript(r)",false,if not skip :,if opcode == 2 :,0.04,0.0
"def get_ip_info(ipaddress): <TAB> """"""Returns device information by IP address"""""" <TAB> result = {} <TAB> try: <TAB> <TAB> ip = IPAddress.objects.select_related().get(address=ipaddress) <TAB> except IPAddress.DoesNotExist: <TAB> <TAB> pass <TAB> else: <TAB> <TAB> if ip.venture is not None: <TAB> <TAB> <TAB> result[""venture_id""] = ip.venture.id <TAB> <TAB> if ip.device is not None: <TAB> <TAB> <TAB> result[""device_id""] = ip.device.id <TAB> <TAB> <TAB> if ip.device.venture is not None: <TAB> <TAB> <TAB> <TAB> result[""venture_id""] = ip.device.venture.id <TAB> return result",false,if ip . device . venture is not None :,if ip . device is not None :,0.41,0.0
"def restore(self, state): <TAB> """"""Restore the state of a mesh previously saved using save()"""""" <TAB> import pickle <TAB> state = pickle.loads(state) <TAB> for k in state: <TAB> <TAB> if isinstance(state[k], list): <TAB> <TAB> <TAB> if isinstance(state[k][0], QtGui.QVector3D): <TAB> <TAB> <TAB> <TAB> state[k] = [[v.x(), v.y(), v.z()] for v in state[k]] <TAB> <TAB> <TAB> state[k] = np.array(state[k]) <TAB> <TAB> setattr(self, k, state[k])",false,"if isinstance ( state [ k ] [ 0 ] , QtGui . QVector3D ) :","if isinstance ( state [ k ] , list ) :",0.25,0.0
"def get_extra_lines(tup): <TAB> ext_name, pyopencl_ver = tup <TAB> if ext_name is not None: <TAB> <TAB> if ext_name.startswith(""CL_""): <TAB> <TAB> <TAB> # capital letters -> CL version, not extension <TAB> <TAB> <TAB> yield """" <TAB> <TAB> <TAB> yield "" <TAB>Available with OpenCL %s."" % (ext_name[3:]) <TAB> <TAB> <TAB> yield """" <TAB> <TAB> else: <TAB> <TAB> <TAB> yield """" <TAB> <TAB> <TAB> yield "" <TAB>Available with the ``%s`` extension."" % ext_name <TAB> <TAB> <TAB> yield """" <TAB> if pyopencl_ver is not None: <TAB> <TAB> yield """" <TAB> <TAB> yield "" <TAB>.. versionadded:: %s"" % pyopencl_ver <TAB> <TAB> yield """"",true,"if ext_name . startswith ( ""CL_"" ) :","if ext_name . startswith ( ""CL_"" ) :",0.75,0.0
"def _gen_remote_uri( <TAB> fileobj: IO[bytes], <TAB> remote_uri: Optional[ParseResult], <TAB> remote_path_prefix: Optional[str], <TAB> remote_path_suffix: Optional[str], <TAB> sha256sum: Optional[str], ) -> ParseResult: <TAB> if remote_uri is None: <TAB> <TAB> assert remote_path_prefix is not None and remote_path_suffix is not None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> sha256sum = _hash_fileobj(fileobj) <TAB> <TAB> return urlparse( <TAB> <TAB> <TAB> os.path.join(remote_path_prefix, f""{sha256sum}{remote_path_suffix}"") <TAB> <TAB> ) <TAB> else: <TAB> <TAB> return remote_uri",true,if sha256sum is None :,if sha256sum is None :,0.75,0.0
"def queries(self): <TAB> if DEV: <TAB> <TAB> cmd = ShellCommand(""docker"", ""ps"", ""-qf"", ""name=%s"" % self.path.k8s) <TAB> <TAB> if not cmd.check(f""docker check for {self.path.k8s}""): <TAB> <TAB> <TAB> if not cmd.stdout.strip(): <TAB> <TAB> <TAB> <TAB> log_cmd = ShellCommand( <TAB> <TAB> <TAB> <TAB> <TAB> ""docker"", ""logs"", self.path.k8s, stderr=subprocess.STDOUT <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> if log_cmd.check(f""docker logs for {self.path.k8s}""): <TAB> <TAB> <TAB> <TAB> <TAB> print(cmd.stdout) <TAB> <TAB> <TAB> <TAB> pytest.exit(f""container failed to start for {self.path.k8s}"") <TAB> return ()",false,if not cmd . stdout . strip ( ) :,"if log_cmd . check ( f""docker logs for {self.path.k8s}"" ) :",0.03,0.0
"def get_range(self): <TAB> present = self.xml.find(""{%s}range"" % self.namespace) <TAB> if present is not None: <TAB> <TAB> attributes = present.attrib <TAB> <TAB> return_value = dict() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return_value[""minimum""] = attributes[""min""] <TAB> <TAB> if ""max"" in attributes: <TAB> <TAB> <TAB> return_value[""maximum""] = attributes[""max""] <TAB> <TAB> return return_value <TAB> return False",true,"if ""min"" in attributes :","if ""min"" in attributes :",0.75,0.0
"def _configuredOn(self, workerid, builderid=None, masterid=None): <TAB> cfg = [] <TAB> for cs in itervalues(self.configured): <TAB> <TAB> if cs[""workerid""] != workerid: <TAB> <TAB> <TAB> continue <TAB> <TAB> bid, mid = self.db.builders.builder_masters[cs[""buildermasterid""]] <TAB> <TAB> if builderid is not None and bid != builderid: <TAB> <TAB> <TAB> continue <TAB> <TAB> if masterid is not None and mid != masterid: <TAB> <TAB> <TAB> continue <TAB> <TAB> cfg.append({""builderid"": bid, ""masterid"": mid}) <TAB> return cfg",true,"if cs [ ""workerid"" ] != workerid :","if cs [ ""workerid"" ] != workerid :",0.75,0.0
"def __exit__(self, type, value, traceback): <TAB> try: <TAB> <TAB> if type is not None: <TAB> <TAB> <TAB> return self.exception_handler(type, value, traceback) <TAB> finally: <TAB> <TAB> final_contexts = _state.contexts <TAB> <TAB> _state.contexts = self.old_contexts <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise StackContextInconsistentError( <TAB> <TAB> <TAB> <TAB> ""stack_context inconsistency (may be caused by yield "" <TAB> <TAB> <TAB> <TAB> 'within a ""with StackContext"" block)' <TAB> <TAB> <TAB> ) <TAB> <TAB> # Break up a reference to itself to allow for faster GC on CPython. <TAB> <TAB> self.new_contexts = None",false,if final_contexts is not self . new_contexts :,if final_contexts :,0.07,0.0
"def del_(self, key): <TAB> initial_hash = hash_ = self.hash(key) <TAB> while True: <TAB> <TAB> if self._keys[hash_] is self._empty: <TAB> <TAB> <TAB> # That key was never assigned <TAB> <TAB> <TAB> return None <TAB> <TAB> elif self._keys[hash_] == key: <TAB> <TAB> <TAB> # key found, assign with deleted sentinel <TAB> <TAB> <TAB> self._keys[hash_] = self._deleted <TAB> <TAB> <TAB> self._values[hash_] = self._deleted <TAB> <TAB> <TAB> self._len -= 1 <TAB> <TAB> <TAB> return <TAB> <TAB> hash_ = self._rehash(hash_) <TAB> <TAB> if initial_hash == hash_: <TAB> <TAB> <TAB> # table is full and wrapped around <TAB> <TAB> <TAB> return None",false,if self . _keys [ hash_ ] is self . _empty :,elif self . _keys [ hash_ ] == key :,0.21,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.set_logout_url(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0: <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 10 :,if tt == 10 :,0.75,0.0
"def data_generator(): <TAB> i = 0 <TAB> max_batch_index = len(X_train) // batch_size <TAB> tot = 0 <TAB> while 1: <TAB> <TAB> if tot > 3 * len(X_train): <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> np.ones([batch_size, input_dim]) * np.nan, <TAB> <TAB> <TAB> <TAB> np.ones([batch_size, num_classes]) * np.nan, <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> X_train[i * batch_size : (i + 1) * batch_size], <TAB> <TAB> <TAB> <TAB> y_train[i * batch_size : (i + 1) * batch_size], <TAB> <TAB> <TAB> ) <TAB> <TAB> i += 1 <TAB> <TAB> tot += 1 <TAB> <TAB> i = i % max_batch_index",true,if tot > 3 * len ( X_train ) :,if tot > 3 * len ( X_train ) :,0.75,0.0
"def title(self): <TAB> ret = theme[""title""] <TAB> if isinstance(self.name, six.string_types): <TAB> <TAB> width = self.statwidth() <TAB> <TAB> return ( <TAB> <TAB> <TAB> ret + self.name[0:width].center(width).replace("" "", ""-"") + theme[""default""] <TAB> <TAB> ) <TAB> for i, name in enumerate(self.name): <TAB> <TAB> width = self.colwidth() <TAB> <TAB> ret = ret + name[0:width].center(width).replace("" "", ""-"") <TAB> <TAB> if i + 1 != len(self.vars): <TAB> <TAB> <TAB> if op.color: <TAB> <TAB> <TAB> <TAB> ret = ret + theme[""frame""] + char[""dash""] + theme[""title""] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> ret = ret + char[""space""] <TAB> return ret",true,if i + 1 != len ( self . vars ) :,if i + 1 != len ( self . vars ) :,0.75,0.0
"def get_container_from_dport(dport, docker_client): <TAB> for container in docker_client.containers(): <TAB> <TAB> try: <TAB> <TAB> <TAB> ports = container[""Ports""] <TAB> <TAB> <TAB> for port in ports: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> if port[""PublicPort""] == int(dport): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return container <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> print(ports) <TAB> <TAB> <TAB> pass",false,"if ""PublicPort"" in port :",if dport in port :,0.14,0.0
"def _get_parents_data(self, data): <TAB> parents = 0 <TAB> if data[COLUMN_PARENT]: <TAB> <TAB> family = self.db.get_family_from_handle(data[COLUMN_PARENT][0]) <TAB> <TAB> if family.get_father_handle(): <TAB> <TAB> <TAB> parents += 1 <TAB> <TAB> if family.get_mother_handle(): <TAB> <TAB> <TAB> parents += 1 <TAB> return parents",false,if family . get_mother_handle ( ) :,if family . get_father_handle ( ) :,0.39,0.0
"def wrapper(filename): <TAB> mtime = getmtime(filename) <TAB> with lock: <TAB> <TAB> if filename in cache: <TAB> <TAB> <TAB> old_mtime, result = cache.pop(filename) <TAB> <TAB> <TAB> if old_mtime == mtime: <TAB> <TAB> <TAB> <TAB> # Move to the end <TAB> <TAB> <TAB> <TAB> cache[filename] = old_mtime, result <TAB> <TAB> <TAB> <TAB> return result <TAB> result = function(filename) <TAB> with lock: <TAB> <TAB> cache[filename] = mtime, result  # at the end <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> cache.popitem(last=False) <TAB> return result",false,if len ( cache ) > max_size :,if filename in cache :,0.02,0.0
"def execute(cls, ctx, op: ""DataFrameGroupByAgg""): <TAB> try: <TAB> <TAB> pd.set_option(""mode.use_inf_as_na"", op.use_inf_as_na) <TAB> <TAB> if op.stage == OperandStage.map: <TAB> <TAB> <TAB> cls._execute_map(ctx, op) <TAB> <TAB> elif op.stage == OperandStage.combine: <TAB> <TAB> <TAB> cls._execute_combine(ctx, op) <TAB> <TAB> elif op.stage == OperandStage.agg: <TAB> <TAB> <TAB> cls._execute_agg(ctx, op) <TAB> <TAB> else:  # pragma: no cover <TAB> <TAB> <TAB> raise ValueError(""Aggregation operand not executable"") <TAB> finally: <TAB> <TAB> pd.reset_option(""mode.use_inf_as_na"")",false,elif op . stage == OperandStage . agg :,elif op . stage == OperandStage . combine :,0.63,0.0
"def FindAndDelete(script, sig): <TAB> """"""Consensus critical, see FindAndDelete() in Satoshi codebase"""""" <TAB> r = b"""" <TAB> last_sop_idx = sop_idx = 0 <TAB> skip = True <TAB> for (opcode, data, sop_idx) in script.raw_iter(): <TAB> <TAB> if not skip: <TAB> <TAB> <TAB> r += script[last_sop_idx:sop_idx] <TAB> <TAB> last_sop_idx = sop_idx <TAB> <TAB> if script[sop_idx : sop_idx + len(sig)] == sig: <TAB> <TAB> <TAB> skip = True <TAB> <TAB> else: <TAB> <TAB> <TAB> skip = False <TAB> if not skip: <TAB> <TAB> r += script[last_sop_idx:] <TAB> return CScript(r)",true,if script [ sop_idx : sop_idx + len ( sig ) ] == sig :,if script [ sop_idx : sop_idx + len ( sig ) ] == sig :,1.0,0.0
"def extractall(zip: typing.Any, path: str) -> NoneType: <TAB> for name in zip.namelist(): <TAB> <TAB> member = zip.getinfo(name) <TAB> <TAB> extracted_path = zip._extract_member(member, path, None) <TAB> <TAB> attr = member.external_attr >> 16 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> os.chmod(extracted_path, attr)",false,if attr != 0 :,if extracted_path is not None :,0.03,0.0
"def find_all_gyptest_files(directory): <TAB> result = [] <TAB> for root, dirs, files in os.walk(directory): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> dirs.remove("".svn"") <TAB> <TAB> result.extend([os.path.join(root, f) for f in files if is_test_name(f)]) <TAB> result.sort() <TAB> return result",true,"if "".svn"" in dirs :","if "".svn"" in dirs :",0.75,0.0
"def load(cls, storefile, template_store): <TAB> # Did we get file or filename? <TAB> if not hasattr(storefile, ""read""): <TAB> <TAB> storefile = open(storefile, ""rb"") <TAB> # Adjust store to have translations <TAB> store = cls.convertfile(storefile, template_store) <TAB> for unit in store.units: <TAB> <TAB> if unit.isheader(): <TAB> <TAB> <TAB> continue <TAB> <TAB> # HTML does this properly on loading, others need it <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> unit.target = unit.source <TAB> <TAB> <TAB> unit.rich_target = unit.rich_source <TAB> return store",false,if cls . needs_target_sync :,if unit . source :,0.29,0.0
"def postOptions(self): <TAB> _BasicOptions.postOptions(self) <TAB> if self[""jobs""]: <TAB> <TAB> conflicts = [""debug"", ""profile"", ""debug-stacktraces"", ""exitfirst""] <TAB> <TAB> for option in conflicts: <TAB> <TAB> <TAB> if self[option]: <TAB> <TAB> <TAB> <TAB> raise usage.UsageError( <TAB> <TAB> <TAB> <TAB> <TAB> ""You can't specify --%s when using --jobs"" % option <TAB> <TAB> <TAB> <TAB> ) <TAB> if self[""nopm""]: <TAB> <TAB> if not self[""debug""]: <TAB> <TAB> <TAB> raise usage.UsageError(""You must specify --debug when using "" ""--nopm "") <TAB> <TAB> failure.DO_POST_MORTEM = False",false,"if not self [ ""debug"" ] :",if self [ option ] :,0.05,0.0
"def filterTokenLocation(): <TAB> i = None <TAB> entry = None <TAB> token = None <TAB> tokens = [] <TAB> i = 0 <TAB> while 1: <TAB> <TAB> if not (i < len(extra.tokens)): <TAB> <TAB> <TAB> break <TAB> <TAB> entry = extra.tokens[i] <TAB> <TAB> token = jsdict( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> ""type"": entry.type, <TAB> <TAB> <TAB> <TAB> ""value"": entry.value, <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> <TAB> if extra.range: <TAB> <TAB> <TAB> token.range = entry.range <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> token.loc = entry.loc <TAB> <TAB> tokens.append(token) <TAB> <TAB> i += 1 <TAB> extra.tokens = tokens",true,if extra . loc :,if extra . loc :,0.75,0.0
"def on_rebalance_end(self) -> None: <TAB> """"""Call when rebalancing is done."""""" <TAB> self.rebalancing = False <TAB> if self._rebalancing_span: <TAB> <TAB> self._rebalancing_span.finish() <TAB> self._rebalancing_span = None <TAB> sensor_state = self._rebalancing_sensor_state <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.log.warning( <TAB> <TAB> <TAB> <TAB> ""Missing sensor state for rebalance #%s"", self.rebalancing_count <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.sensors.on_rebalance_end(self, sensor_state) <TAB> finally: <TAB> <TAB> self._rebalancing_sensor_state = None",false,if not sensor_state :,if sensor_state is None :,0.05,0.0
"def decorator(request, *args, **kwargs): <TAB> if CALENDAR_VIEW_PERM: <TAB> <TAB> user = request.user <TAB> <TAB> if not user: <TAB> <TAB> <TAB> return HttpResponseRedirect(settings.LOGIN_URL) <TAB> <TAB> occurrence, event, calendar = get_objects(request, **kwargs) <TAB> <TAB> if calendar: <TAB> <TAB> <TAB> allowed = CHECK_CALENDAR_PERM_FUNC(calendar, user) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return HttpResponseRedirect(settings.LOGIN_URL) <TAB> <TAB> <TAB> # all checks passed <TAB> <TAB> <TAB> return function(request, *args, **kwargs) <TAB> <TAB> return HttpResponseNotFound(""<h1>Page not found</h1>"") <TAB> return function(request, *args, **kwargs)",true,if not allowed :,if not allowed :,0.75,0.0
"def reduce_arguments(self, args): <TAB> assert isinstance(args, nodes.Arguments) <TAB> if args.incorrect_order(): <TAB> <TAB> raise InvalidArguments( <TAB> <TAB> <TAB> ""All keyword arguments must be after positional arguments."" <TAB> <TAB> ) <TAB> reduced_pos = [self.reduce_single(arg) for arg in args.arguments] <TAB> reduced_kw = {} <TAB> for key in args.kwargs.keys(): <TAB> <TAB> if not isinstance(key, str): <TAB> <TAB> <TAB> raise InvalidArguments(""Keyword argument name is not a string."") <TAB> <TAB> a = args.kwargs[key] <TAB> <TAB> reduced_kw[key] = self.reduce_single(a) <TAB> return (reduced_pos, reduced_kw)",true,"if not isinstance ( key , str ) :","if not isinstance ( key , str ) :",0.75,0.0
"def _encode(n, nbytes, little_endian=False): <TAB> retval = [] <TAB> n = long(n) <TAB> for i in range(nbytes): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> retval.append(chr(n & 0xFF)) <TAB> <TAB> else: <TAB> <TAB> <TAB> retval.insert(0, chr(n & 0xFF)) <TAB> <TAB> n >>= 8 <TAB> return """".join(retval)",true,if little_endian :,if little_endian :,0.53,0.0
"def copy_shell(self): <TAB> cls = self.__class__ <TAB> old_id = cls.id <TAB> new_i = cls()  # create a new group <TAB> new_i.id = self.id  # with the same id <TAB> cls.id = old_id  # Reset the Class counter <TAB> # Copy all properties <TAB> for prop in cls.properties: <TAB> <TAB> if prop is not ""members"": <TAB> <TAB> <TAB> if self.has(prop): <TAB> <TAB> <TAB> <TAB> val = getattr(self, prop) <TAB> <TAB> <TAB> <TAB> setattr(new_i, prop, val) <TAB> # but no members <TAB> new_i.members = [] <TAB> return new_i",false,if self . has ( prop ) :,"if prop is not ""members"" :",0.02,0.0
"def dataspec(config): <TAB> master = yield fakemaster.make_master() <TAB> data = connector.DataConnector() <TAB> data.setServiceParent(master) <TAB> if config[""out""] != ""--"": <TAB> <TAB> dirs = os.path.dirname(config[""out""]) <TAB> <TAB> if dirs and not os.path.exists(dirs): <TAB> <TAB> <TAB> os.makedirs(dirs) <TAB> <TAB> f = open(config[""out""], ""w"") <TAB> else: <TAB> <TAB> f = sys.stdout <TAB> if config[""global""] is not None: <TAB> <TAB> f.write(""window."" + config[""global""] + ""="") <TAB> f.write(json.dumps(data.allEndpoints(), indent=2)) <TAB> f.close() <TAB> defer.returnValue(0)",true,if dirs and not os . path . exists ( dirs ) :,if dirs and not os . path . exists ( dirs ) :,0.75,0.0
"def _parseSCDOCDC(self, src): <TAB> """"""[S|CDO|CDC]*"""""" <TAB> while 1: <TAB> <TAB> src = src.lstrip() <TAB> <TAB> if src.startswith(""<!--""): <TAB> <TAB> <TAB> src = src[4:] <TAB> <TAB> elif src.startswith(""-->""): <TAB> <TAB> <TAB> src = src[3:] <TAB> <TAB> else: <TAB> <TAB> <TAB> break <TAB> return src",false,"if src . startswith ( ""<!--"" ) :","if src . startswith ( ""<<!--"" ) :",0.55,0.0
"def command(filenames, dirnames, fix): <TAB> for filename in gather_files(dirnames, filenames): <TAB> <TAB> visitor = process_file(filename) <TAB> <TAB> if visitor.needs_fix(): <TAB> <TAB> <TAB> print(""%s: %s"" % (filename, visitor.get_stats())) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> print(""Fixing: %s"" % filename) <TAB> <TAB> <TAB> <TAB> fix_file(filename)",true,if fix :,if fix :,0.53,0.0
"def shutdown(self): <TAB> """"""Shutdown host system."""""" <TAB> self._check_dbus(MANAGER) <TAB> use_logind = self.sys_dbus.logind.is_connected <TAB> _LOGGER.info(""Initialize host power off %s"", ""logind"" if use_logind else ""systemd"") <TAB> try: <TAB> <TAB> await self.sys_core.shutdown() <TAB> finally: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> await self.sys_dbus.logind.power_off() <TAB> <TAB> else: <TAB> <TAB> <TAB> await self.sys_dbus.systemd.power_off()",true,if use_logind :,if use_logind :,0.53,0.0
"def _run_split_on_punc(self, text, never_split=None): <TAB> """"""Splits punctuation on a piece of text."""""" <TAB> if never_split is not None and text in never_split: <TAB> <TAB> return [text] <TAB> chars = list(text) <TAB> i = 0 <TAB> start_new_word = True <TAB> output = [] <TAB> while i < len(chars): <TAB> <TAB> char = chars[i] <TAB> <TAB> if _is_punctuation(char): <TAB> <TAB> <TAB> output.append([char]) <TAB> <TAB> <TAB> start_new_word = True <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> output.append([]) <TAB> <TAB> <TAB> start_new_word = False <TAB> <TAB> <TAB> output[-1].append(char) <TAB> <TAB> i += 1 <TAB> return ["""".join(x) for x in output]",true,if start_new_word :,if start_new_word :,0.53,0.0
"def _terminal_messenger(tp=""write"", msg="""", out=sys.stdout): <TAB> try: <TAB> <TAB> if tp == ""write"": <TAB> <TAB> <TAB> out.write(msg) <TAB> <TAB> elif tp == ""flush"": <TAB> <TAB> <TAB> out.flush() <TAB> <TAB> elif tp == ""write_flush"": <TAB> <TAB> <TAB> out.write(msg) <TAB> <TAB> <TAB> out.flush() <TAB> <TAB> elif tp == ""print"": <TAB> <TAB> <TAB> print(msg, file=out) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""Unsupported type: "" + tp) <TAB> except IOError as e: <TAB> <TAB> logger.critical(""{}: {}"".format(type(e).__name__, ucd(e))) <TAB> <TAB> pass",true,"elif tp == ""flush"" :","elif tp == ""flush"" :",1.0,0.0
"def checkClassDeclation(file): <TAB> localResult = [] <TAB> with open(file, ""rb"") as f: <TAB> <TAB> lineNumber = 0 <TAB> <TAB> for line in f: <TAB> <TAB> <TAB> m = re.search(""class\s+[^\(]*:"", line) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> localResult.append( <TAB> <TAB> <TAB> <TAB> <TAB> ""Old class definition found on {0}"".format(m.group()) <TAB> <TAB> <TAB> <TAB> ) <TAB> return localResult",true,if m :,if m :,0.53,0.0
"def _evaluate_local_single(self, iterator): <TAB> for batch in iterator: <TAB> <TAB> in_arrays = convert._call_converter(self.converter, batch, self.device) <TAB> <TAB> with function.no_backprop_mode(): <TAB> <TAB> <TAB> if isinstance(in_arrays, tuple): <TAB> <TAB> <TAB> <TAB> results = self.calc_local(*in_arrays) <TAB> <TAB> <TAB> elif isinstance(in_arrays, dict): <TAB> <TAB> <TAB> <TAB> results = self.calc_local(**in_arrays) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> results = self.calc_local(in_arrays) <TAB> <TAB> if self._progress_hook: <TAB> <TAB> <TAB> self._progress_hook(batch) <TAB> <TAB> yield results",false,"elif isinstance ( in_arrays , dict ) :","if isinstance ( in_arrays , tuple ) :",0.21,0.0
"def check_billing_view(user, permission, obj): <TAB> if hasattr(obj, ""all_projects""): <TAB> <TAB> if user.is_superuser or obj.owners.filter(pk=user.pk).exists(): <TAB> <TAB> <TAB> return True <TAB> <TAB> # This is a billing object <TAB> <TAB> return any(check_permission(user, permission, prj) for prj in obj.all_projects) <TAB> return check_permission(user, permission, obj)",true,if user . is_superuser or obj . owners . filter ( pk = user . pk ) . exists ( ) :,if user . is_superuser or obj . owners . filter ( pk = user . pk ) . exists ( ) :,1.0,0.0
"def ensure_output_spaces_contain_the_same_data(self, y, y_ensured): <TAB> stride = y.shape[1] <TAB> self.assertEqual(y.shape[0] * y.shape[1], y_ensured.shape[0]) <TAB> self.assertEqual(len(y_ensured.shape), 1) <TAB> for row in range(y.shape[0]): <TAB> <TAB> for column in range(y.shape[1]): <TAB> <TAB> <TAB> if sp.issparse(y): <TAB> <TAB> <TAB> <TAB> self.assertEqual(y[row, column], y_ensured[row * stride + column]) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.assertEqual(y[row][column], y_ensured[row * stride + column])",false,if sp . issparse ( y ) :,if sp . isparse ( y ) :,0.5,0.0
"def train( <TAB> self, <TAB> training_data: TrainingData, <TAB> config: Optional[RasaNLUModelConfig] = None, <TAB> **kwargs: Any, ) -> None: <TAB> """"""Tokenize all training data."""""" <TAB> for example in training_data.training_examples: <TAB> <TAB> for attribute in MESSAGE_ATTRIBUTES: <TAB> <TAB> <TAB> if example.get(attribute) is not None and not example.get(attribute) == """": <TAB> <TAB> <TAB> <TAB> if attribute in [INTENT, ACTION_NAME, INTENT_RESPONSE_KEY]: <TAB> <TAB> <TAB> <TAB> <TAB> tokens = self._split_name(example, attribute) <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> tokens = self.tokenize(example, attribute) <TAB> <TAB> <TAB> <TAB> example.set(TOKENS_NAMES[attribute], tokens)",false,"if attribute in [ INTENT , ACTION_NAME , INTENT_RESPONSE_KEY ] :","if example . get ( attribute ) is not None and not example . get ( attribute ) == """" :",0.14,0.0
"def refresh_token(self, strategy, *args, **kwargs): <TAB> token = self.extra_data.get(""refresh_token"") or self.extra_data.get(""access_token"") <TAB> backend = self.get_backend(strategy) <TAB> if token and backend and hasattr(backend, ""refresh_token""): <TAB> <TAB> backend = backend(strategy=strategy) <TAB> <TAB> response = backend.refresh_token(token, *args, **kwargs) <TAB> <TAB> extra_data = backend.extra_data(self, self.uid, response, self.extra_data) <TAB> <TAB> if self.set_extra_data(extra_data): <TAB> <TAB> <TAB> self.save()",true,if self . set_extra_data ( extra_data ) :,if self . set_extra_data ( extra_data ) :,0.75,0.0
"def _verify_environ(_collected_environ): <TAB> try: <TAB> <TAB> yield <TAB> finally: <TAB> <TAB> new_environ = dict(os.environ) <TAB> <TAB> current_test = new_environ.pop(""PYTEST_CURRENT_TEST"", None) <TAB> <TAB> old_environ = dict(_collected_environ) <TAB> <TAB> old_environ.pop(""PYTEST_CURRENT_TEST"", None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise DirtyTest( <TAB> <TAB> <TAB> <TAB> ""Left over environment variables"", <TAB> <TAB> <TAB> <TAB> current_test, <TAB> <TAB> <TAB> <TAB> _compare_eq_dict(new_environ, old_environ, verbose=2), <TAB> <TAB> <TAB> )",false,if new_environ != old_environ :,if current_test != old_test :,0.29,0.0
"def clean_len(self, line): <TAB> """"""Calculate wisible length of string"""""" <TAB> if isinstance(line, basestring): <TAB> <TAB> return len(self.screen.markup.clean_markup(line)) <TAB> elif isinstance(line, tuple) or isinstance(line, list): <TAB> <TAB> markups = self.screen.markup.get_markup_vars() <TAB> <TAB> length = 0 <TAB> <TAB> for i in line: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> length += len(i) <TAB> <TAB> return length",true,if i not in markups :,if i not in markups :,0.75,0.0
"def _build_merged_dataset_args(datasets): <TAB> merged_dataset_args = [] <TAB> for dataset in datasets: <TAB> <TAB> dataset_code_column = _parse_dataset_code(dataset) <TAB> <TAB> arg = dataset_code_column[""code""] <TAB> <TAB> column_index = dataset_code_column[""column_index""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> arg = (dataset_code_column[""code""], {""column_index"": [column_index]}) <TAB> <TAB> merged_dataset_args.append(arg) <TAB> return merged_dataset_args",false,if column_index is not None :,if column_index :,0.05,0.0
"def update_watch_data_table_paths(self): <TAB> if hasattr(self.tool_data_watcher, ""monitored_dirs""): <TAB> <TAB> for tool_data_table_path in self.tool_data_paths: <TAB> <TAB> <TAB> if tool_data_table_path not in self.tool_data_watcher.monitored_dirs: <TAB> <TAB> <TAB> <TAB> self.tool_data_watcher.watch_directory(tool_data_table_path)",true,if tool_data_table_path not in self . tool_data_watcher . monitored_dirs :,if tool_data_table_path not in self . tool_data_watcher . monitored_dirs :,0.75,0.0
"def getsource(obj): <TAB> """"""Wrapper around inspect.getsource"""""" <TAB> try: <TAB> <TAB> try: <TAB> <TAB> <TAB> src = encoding.to_unicode(inspect.getsource(obj)) <TAB> <TAB> except TypeError: <TAB> <TAB> <TAB> if hasattr(obj, ""__class__""): <TAB> <TAB> <TAB> <TAB> src = encoding.to_unicode(inspect.getsource(obj.__class__)) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> # Bindings like VTK or ITK require this case <TAB> <TAB> <TAB> <TAB> src = getdoc(obj) <TAB> <TAB> return src <TAB> except (TypeError, IOError): <TAB> <TAB> return",true,"if hasattr ( obj , ""__class__"" ) :","if hasattr ( obj , ""__class__"" ) :",0.75,0.0
"def __iter__(self): <TAB> for model in self.app_config.get_models(): <TAB> <TAB> admin_model = AdminModel(model, **self.options) <TAB> <TAB> for model_re in self.model_res: <TAB> <TAB> <TAB> if model_re.search(admin_model.name): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield admin_model",false,if self . model_res :,if admin_model . name in self . skip_models :,0.22,0.0
"def run(self): <TAB> while True: <TAB> <TAB> try: <TAB> <TAB> <TAB> with DelayedKeyboardInterrupt(): <TAB> <TAB> <TAB> <TAB> raw_inputs = self._parent_task_queue.get() <TAB> <TAB> <TAB> <TAB> if self._has_stop_signal(raw_inputs): <TAB> <TAB> <TAB> <TAB> <TAB> self._rq.put(raw_inputs, block=True) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> if self._flow_type == BATCH: <TAB> <TAB> <TAB> <TAB> <TAB> self._rq.put(raw_inputs, block=True) <TAB> <TAB> <TAB> <TAB> elif self._flow_type == REALTIME: <TAB> <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self._rq.put(raw_inputs, block=False) <TAB> <TAB> <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> except KeyboardInterrupt: <TAB> <TAB> <TAB> continue",false,elif self . _flow_type == REALTIME :,if self . _has_stop_signal ( raw_inputs ) :,0.04,0.0
"def dump(self): <TAB> self.ql.log.info(""[*] Dumping object: %s"" % (self.sf_name)) <TAB> for field in self._fields_: <TAB> <TAB> if isinstance(getattr(self, field[0]), POINTER64): <TAB> <TAB> <TAB> self.ql.log.info(""%s: 0x%x"" % (field[0], getattr(self, field[0]).value)) <TAB> <TAB> elif isinstance(getattr(self, field[0]), int): <TAB> <TAB> <TAB> self.ql.log.info(""%s: %d"" % (field[0], getattr(self, field[0]))) <TAB> <TAB> elif isinstance(getattr(self, field[0]), bytes): <TAB> <TAB> <TAB> self.ql.log.info(""%s: %s"" % (field[0], getattr(self, field[0]).decode()))",false,"if isinstance ( getattr ( self , field [ 0 ] ) , POINTER64 ) :","elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) :",0.48,0.0
"def validate_configuration(self, configuration: Optional[ExpectationConfiguration]): <TAB> """"""Validating that user has inputted a value set and that configuration has been initialized"""""" <TAB> super().validate_configuration(configuration) <TAB> try: <TAB> <TAB> assert ""value_set"" in configuration.kwargs, ""value_set is required"" <TAB> <TAB> assert isinstance( <TAB> <TAB> <TAB> configuration.kwargs[""value_set""], (list, set, dict) <TAB> <TAB> ), ""value_set must be a list or a set"" <TAB> <TAB> if isinstance(configuration.kwargs[""value_set""], dict): <TAB> <TAB> <TAB> assert ( <TAB> <TAB> <TAB> <TAB> ""$PARAMETER"" in configuration.kwargs[""value_set""] <TAB> <TAB> <TAB> ), 'Evaluation Parameter dict for value_set kwarg must have ""$PARAMETER"" key' <TAB> except AssertionError as e: <TAB> <TAB> raise InvalidExpectationConfigurationError(str(e)) <TAB> return True",true,"if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :","if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :",0.75,0.0
def test_one_dead_branch(): <TAB> with deterministic_PRNG(): <TAB> <TAB> seen = set() <TAB> <TAB> @run_to_buffer <TAB> <TAB> def x(data): <TAB> <TAB> <TAB> i = data.draw_bytes(1)[0] <TAB> <TAB> <TAB> if i > 0: <TAB> <TAB> <TAB> <TAB> data.mark_invalid() <TAB> <TAB> <TAB> i = data.draw_bytes(1)[0] <TAB> <TAB> <TAB> if len(seen) < 255: <TAB> <TAB> <TAB> <TAB> seen.add(i) <TAB> <TAB> <TAB> elif i not in seen: <TAB> <TAB> <TAB> <TAB> data.mark_interesting(),true,elif i not in seen :,elif i not in seen :,0.75,0.0
"def __on_item_activated(self, event): <TAB> if self.__module_view: <TAB> <TAB> module = self.get_event_module(event) <TAB> <TAB> self.__module_view.set_selection(module.module_num) <TAB> <TAB> if event.EventObject is self.list_ctrl: <TAB> <TAB> <TAB> self.input_list_ctrl.deactivate_active_item() <TAB> <TAB> else: <TAB> <TAB> <TAB> self.list_ctrl.deactivate_active_item() <TAB> <TAB> <TAB> for index in range(self.list_ctrl.GetItemCount()): <TAB> <TAB> <TAB> <TAB> if self.list_ctrl.IsSelected(index): <TAB> <TAB> <TAB> <TAB> <TAB> self.list_ctrl.Select(index, False) <TAB> self.__controller.enable_module_controls_panel_buttons()",true,if self . list_ctrl . IsSelected ( index ) :,if self . list_ctrl . IsSelected ( index ) :,0.75,0.0
"def prime(self, callback): <TAB><IF-STMT> <TAB> <TAB> # import pdb <TAB> <TAB> # pdb.set_trace() <TAB> <TAB> self.cbhdl = simulator.register_rwsynch_callback(callback, self) <TAB> <TAB> if self.cbhdl is None: <TAB> <TAB> <TAB> raise_error(self, ""Unable set up %s Trigger"" % (str(self))) <TAB> Trigger.prime(self)",true,if self . cbhdl is None :,if self . cbhdl is None :,0.75,0.0
"def fstab_configuration(middleware): <TAB> for command in ( <TAB> <TAB> [ <TAB> <TAB> <TAB> [""systemctl"", ""daemon-reload""], <TAB> <TAB> <TAB> [""systemctl"", ""restart"", ""local-fs.target""], <TAB> <TAB> ] <TAB> <TAB> if osc.IS_LINUX <TAB> <TAB> else [[""mount"", ""-uw"", ""/""]] <TAB> ): <TAB> <TAB> ret = subprocess.run(command, capture_output=True) <TAB> <TAB> if ret.returncode: <TAB> <TAB> <TAB> middleware.logger.debug( <TAB> <TAB> <TAB> <TAB> f'Failed to execute ""{"" "".join(command)}"": {ret.stderr.decode()}' <TAB> <TAB> <TAB> )",true,if ret . returncode :,if ret . returncode :,0.75,0.0
"def _generate_table(self, fromdesc, todesc, diffs): <TAB> if fromdesc or todesc: <TAB> <TAB> yield ( <TAB> <TAB> <TAB> simple_colorize(fromdesc, ""description""), <TAB> <TAB> <TAB> simple_colorize(todesc, ""description""), <TAB> <TAB> ) <TAB> for i, line in enumerate(diffs): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # mdiff yields None on separator lines; skip the bogus ones <TAB> <TAB> <TAB> # generated for the first line <TAB> <TAB> <TAB> if i > 0: <TAB> <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> <TAB> simple_colorize(""---"", ""separator""), <TAB> <TAB> <TAB> <TAB> <TAB> simple_colorize(""---"", ""separator""), <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> yield line",true,if line is None :,if line is None :,0.75,0.0
"def update_completion(self): <TAB> """"""Update completion model with exist tags"""""" <TAB> orig_text = self.widget.text() <TAB> text = "", "".join(orig_text.replace("", "", "","").split("","")[:-1]) <TAB> tags = [] <TAB> for tag in self.tags_list: <TAB> <TAB> if "","" in orig_text: <TAB> <TAB> <TAB> if orig_text[-1] not in ("","", "" ""): <TAB> <TAB> <TAB> <TAB> tags.append(""%s,%s"" % (text, tag)) <TAB> <TAB> <TAB> tags.append(""%s, %s"" % (text, tag)) <TAB> <TAB> else: <TAB> <TAB> <TAB> tags.append(tag) <TAB> if tags != self.completer_model.stringList(): <TAB> <TAB> self.completer_model.setStringList(tags)",false,"if orig_text [ - 1 ] not in ( "","" , "" "" ) :","if orig_text [ - 1 ] not in ( """" , "", "" , "" "" ) :",0.45,0.0
"def cart_number_checksum_validation(cls, number): <TAB> digits = [] <TAB> even = False <TAB> if not number.isdigit(): <TAB> <TAB> return False <TAB> for digit in reversed(number): <TAB> <TAB> digit = ord(digit) - ord(""0"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> digit *= 2 <TAB> <TAB> <TAB> if digit >= 10: <TAB> <TAB> <TAB> <TAB> digit = digit % 10 + digit // 10 <TAB> <TAB> digits.append(digit) <TAB> <TAB> even = not even <TAB> return sum(digits) % 10 == 0 if digits else False",true,if even :,if even :,0.53,0.0
"def __get_param_string__(params): <TAB> params_string = [] <TAB> for key in sorted(params.keys()): <TAB> <TAB> if ""REFUND"" in params[key] or ""|"" in params[key]: <TAB> <TAB> <TAB> return <TAB> <TAB> value = params[key] <TAB> <TAB> params_string.append("""" if value == ""null"" else str(value)) <TAB> return ""|"".join(params_string)",true,"if ""REFUND"" in params [ key ] or ""|"" in params [ key ] :","if ""REFUND"" in params [ key ] or ""|"" in params [ key ] :",1.0,0.0
"def _map_handlers(self, session, event_class, mapfn): <TAB> for event in DOC_EVENTS: <TAB> <TAB> event_handler_name = event.replace(""-"", ""_"") <TAB> <TAB> if hasattr(self, event_handler_name): <TAB> <TAB> <TAB> event_handler = getattr(self, event_handler_name) <TAB> <TAB> <TAB> format_string = DOC_EVENTS[event] <TAB> <TAB> <TAB> num_args = len(format_string.split(""."")) - 2 <TAB> <TAB> <TAB> format_args = (event_class,) + (""*"",) * num_args <TAB> <TAB> <TAB> event_string = event + format_string % format_args <TAB> <TAB> <TAB> unique_id = event_class + event_handler_name <TAB> <TAB> <TAB> mapfn(event_string, event_handler, unique_id)",true,"if hasattr ( self , event_handler_name ) :","if hasattr ( self , event_handler_name ) :",0.75,0.0
"def _create_param_lr(self, param_and_grad): <TAB> # create learning rate variable for every parameter <TAB> param = param_and_grad[0] <TAB> param_lr = param.optimize_attr[""learning_rate""] <TAB> if type(param_lr) == Variable: <TAB> <TAB> return param_lr <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return self._global_learning_rate() <TAB> <TAB> else: <TAB> <TAB> <TAB> with default_main_program()._lr_schedule_guard( <TAB> <TAB> <TAB> <TAB> is_with_opt=True <TAB> <TAB> <TAB> ), framework.name_scope(""scale_with_param_lr""): <TAB> <TAB> <TAB> <TAB> return self._global_learning_rate() * param_lr",false,if param_lr == 1.0 :,if param_lr is Variable :,0.06,0.0
"def __getitem__(self, key): <TAB> try: <TAB> <TAB> return self._clsmap[key] <TAB> except KeyError as e: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._mutex.acquire() <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> if not self.initialized: <TAB> <TAB> <TAB> <TAB> <TAB> self._init() <TAB> <TAB> <TAB> <TAB> <TAB> self.initialized = True <TAB> <TAB> <TAB> <TAB> return self._clsmap[key] <TAB> <TAB> <TAB> finally: <TAB> <TAB> <TAB> <TAB> self._mutex.release() <TAB> <TAB> raise e",true,if not self . initialized :,if not self . initialized :,0.75,0.0
"def save(self, force=False): <TAB> if not force: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> if time.time() - self.last_save_time < 10: <TAB> <TAB> <TAB> return <TAB> with self.lock: <TAB> <TAB> with open(self.file_path, ""w"") as fd: <TAB> <TAB> <TAB> for ip in self.cache: <TAB> <TAB> <TAB> <TAB> record = self.cache[ip] <TAB> <TAB> <TAB> <TAB> rule = record[""r""] <TAB> <TAB> <TAB> <TAB> connect_time = record[""c""] <TAB> <TAB> <TAB> <TAB> update_time = record[""update""] <TAB> <TAB> <TAB> <TAB> fd.write(""%s %s %d %d\n"" % (ip, rule, connect_time, update_time)) <TAB> self.last_save_time = time.time() <TAB> self.need_save = False",false,if not self . need_save :,if self . need_save :,0.28,0.0
"def pick(items, sel): <TAB> for x, s in zip(items, sel): <TAB> <TAB> if match(s): <TAB> <TAB> <TAB> yield x <TAB> <TAB> elif not x.is_atom() and not s.is_atom(): <TAB> <TAB> <TAB> yield x.restructure(x.head, pick(x.leaves, s.leaves), evaluation)",false,if match ( s ) :,elif not x . is_atom ( ) and not s . is_atom ( ) :,0.03,0.0
"def isValidFloat(config_param_name, value, constraints): <TAB> if isinstance(value, float): <TAB> <TAB> constraints.setdefault(""min"", MIN_VALID_FLOAT_VALUE) <TAB> <TAB> constraints.setdefault(""max"", MAX_VALID_FLOAT_VALUE) <TAB> <TAB> minv = float(constraints.get(""min"")) <TAB> <TAB> maxv = float(constraints.get(""max"")) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if value <= maxv: <TAB> <TAB> <TAB> <TAB> return value <TAB> raise FloatValueError(config_param_name, value, constraints)",true,if value >= minv :,if value >= minv :,0.75,0.0
"def get_files(d): <TAB> f = [] <TAB> for root, dirs, files in os.walk(d): <TAB> <TAB> for name in files: <TAB> <TAB> <TAB> if ""meta-environment"" in root or ""cross-canadian"" in root: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if ""do_build"" not in name and ""do_populate_sdk"" not in name: <TAB> <TAB> <TAB> <TAB> f.append(os.path.join(root, name)) <TAB> return f",false,"if ""qemux86copy-"" in root or ""qemux86-"" in root :","if ""meta-environment"" in root or ""cross-canadian"" in root :",0.6,0.0
"def __get_photo(self, person_or_marriage): <TAB> """"""returns the first photo in the media list or None"""""" <TAB> media_list = person_or_marriage.get_media_list() <TAB> for media_ref in media_list: <TAB> <TAB> media_handle = media_ref.get_reference_handle() <TAB> <TAB> media = self.database.get_media_from_handle(media_handle) <TAB> <TAB> mime_type = media.get_mime_type() <TAB> <TAB> if mime_type and mime_type.startswith(""image""): <TAB> <TAB> <TAB> return media <TAB> return None",true,"if mime_type and mime_type . startswith ( ""image"" ) :","if mime_type and mime_type . startswith ( ""image"" ) :",0.75,0.0
"def filter(this, args): <TAB> array = to_object(this, args.space) <TAB> callbackfn = get_arg(args, 0) <TAB> arr_len = js_arr_length(array) <TAB> if not is_callable(callbackfn): <TAB> <TAB> raise MakeError(""TypeError"", ""callbackfn must be a function"") <TAB> _this = get_arg(args, 1) <TAB> k = 0 <TAB> res = [] <TAB> while k < arr_len: <TAB> <TAB> if array.has_property(unicode(k)): <TAB> <TAB> <TAB> kValue = array.get(unicode(k)) <TAB> <TAB> <TAB> if to_boolean(callbackfn.call(_this, (kValue, float(k), array))): <TAB> <TAB> <TAB> <TAB> res.append(kValue) <TAB> <TAB> k += 1 <TAB> return args.space.ConstructArray(res)",true,"if to_boolean ( callbackfn . call ( _this , ( kValue , float ( k ) , array ) ) ) :","if to_boolean ( callbackfn . call ( _this , ( kValue , float ( k ) , array ) ) ) :",0.75,0.0
"def optimize(self, graph: Graph): <TAB> for v in graph.inputs: <TAB> <TAB> if not v.has_attribute(SplitTarget): <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> DumpGraph().optimize(graph) <TAB> <TAB> raise NotImplementedError( <TAB> <TAB> <TAB> f""Input Variable {v} is too large to handle in WebGL backend"" <TAB> <TAB> ) <TAB> return graph, False",false,if flags . DEBUG :,if v . size > self . batch_size :,0.11,0.0
"def detach_volume(self, volume): <TAB> # We need to find the node using this volume <TAB> for node in self.list_nodes(): <TAB> <TAB> if type(node.image) is not list: <TAB> <TAB> <TAB> # This node has only one associated image. It is not the one we <TAB> <TAB> <TAB> # are after. <TAB> <TAB> <TAB> continue <TAB> <TAB> for disk in node.image: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> # Node found. We can now detach the volume <TAB> <TAB> <TAB> <TAB> disk_id = disk.extra[""disk_id""] <TAB> <TAB> <TAB> <TAB> return self._do_detach_volume(node.id, disk_id) <TAB> return False",false,if disk . id == volume . id :,if disk . volume == volume :,0.39,0.0
"def Yield(value, level=1): <TAB> g = greenlet.getcurrent() <TAB> while level != 0: <TAB> <TAB> if not isinstance(g, genlet): <TAB> <TAB> <TAB> raise RuntimeError(""yield outside a genlet"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> g.parent.set_child(g) <TAB> <TAB> g = g.parent <TAB> <TAB> level -= 1 <TAB> g.switch(value)",false,if level > 1 :,if g . parent :,0.03,0.0
"def get_all_pipeline_nodes( <TAB> pipeline: pipeline_pb2.Pipeline, ) -> List[pipeline_pb2.PipelineNode]: <TAB> """"""Returns all pipeline nodes in the given pipeline."""""" <TAB> result = [] <TAB> for pipeline_or_node in pipeline.nodes: <TAB> <TAB> which = pipeline_or_node.WhichOneof(""node"") <TAB> <TAB> # TODO(goutham): Handle sub-pipelines. <TAB> <TAB> # TODO(goutham): Handle system nodes. <TAB> <TAB> if which == ""pipeline_node"": <TAB> <TAB> <TAB> result.append(pipeline_or_node.pipeline_node) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise NotImplementedError(""Only pipeline nodes supported."") <TAB> return result",true,"if which == ""pipeline_node"" :","if which == ""pipeline_node"" :",0.75,0.0
"def __init__(self, **settings): <TAB> default_settings = self.get_default_settings() <TAB> for name, value in default_settings.items(): <TAB> <TAB> if not hasattr(self, name): <TAB> <TAB> <TAB> setattr(self, name, value) <TAB> for name, value in settings.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ImproperlyConfigured( <TAB> <TAB> <TAB> <TAB> ""Invalid setting '{}' for {}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> name, <TAB> <TAB> <TAB> <TAB> <TAB> self.__class__.__name__, <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> setattr(self, name, value)",false,if name not in default_settings :,if value is None :,0.13,0.0
"def _check_choice(self): <TAB> if self.type == ""choice"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise OptionError(""must supply a list of choices for type 'choice'"", self) <TAB> <TAB> elif type(self.choices) not in (types.TupleType, types.ListType): <TAB> <TAB> <TAB> raise OptionError( <TAB> <TAB> <TAB> <TAB> ""choices must be a list of strings ('%s' supplied)"" <TAB> <TAB> <TAB> <TAB> % str(type(self.choices)).split(""'"")[1], <TAB> <TAB> <TAB> <TAB> self, <TAB> <TAB> <TAB> ) <TAB> elif self.choices is not None: <TAB> <TAB> raise OptionError(""must not supply choices for type %r"" % self.type, self)",true,if self . choices is None :,if self . choices is None :,0.75,0.0
"def prepare(self, size=None): <TAB> if _is_seekable(self.file): <TAB> <TAB> start_pos = self.file.tell() <TAB> <TAB> self.file.seek(0, 2) <TAB> <TAB> end_pos = self.file.tell() <TAB> <TAB> self.file.seek(start_pos) <TAB> <TAB> fsize = end_pos - start_pos <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.remain = fsize <TAB> <TAB> else: <TAB> <TAB> <TAB> self.remain = min(fsize, size) <TAB> return self.remain",true,if size is None :,if size is None :,0.75,0.0
"def _setSitemapTargets(): <TAB> if not conf.sitemapUrl: <TAB> <TAB> return <TAB> infoMsg = ""parsing sitemap '%s'"" % conf.sitemapUrl <TAB> logger.info(infoMsg) <TAB> found = False <TAB> for item in parseSitemap(conf.sitemapUrl): <TAB> <TAB> if re.match(r""[^ ]+\?(.+)"", item, re.I): <TAB> <TAB> <TAB> found = True <TAB> <TAB> <TAB> kb.targets.add((item.strip(), None, None, None, None)) <TAB> if not found and not conf.forms and not conf.crawlDepth: <TAB> <TAB> warnMsg = ""no usable links found (with GET parameters)"" <TAB> <TAB> logger.warn(warnMsg)",true,"if re . match ( r""[^ ]+\?(.+)"" , item , re . I ) :","if re . match ( r""[^ ]+\?(.+)"" , item , re . I ) :",1.0,0.0
"def test_CY_decomposition(self, tol): <TAB> """"""Tests that the decomposition of the CY gate is correct"""""" <TAB> op = qml.CY(wires=[0, 1]) <TAB> res = op.decomposition(op.wires) <TAB> mats = [] <TAB> for i in reversed(res): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> mats.append(np.kron(i.matrix, np.eye(2))) <TAB> <TAB> else: <TAB> <TAB> <TAB> mats.append(i.matrix) <TAB> decomposed_matrix = np.linalg.multi_dot(mats) <TAB> assert np.allclose(decomposed_matrix, op.matrix, atol=tol, rtol=0)",false,if len ( i . wires ) == 1 :,if i . matrix . shape [ 1 ] == 1 :,0.11,0.0
"def _line_ranges(statements, lines): <TAB> """"""Produce a list of ranges for `format_lines`."""""" <TAB> statements = sorted(statements) <TAB> lines = sorted(lines) <TAB> pairs = [] <TAB> start = None <TAB> lidx = 0 <TAB> for stmt in statements: <TAB> <TAB> if lidx >= len(lines): <TAB> <TAB> <TAB> break <TAB> <TAB> if stmt == lines[lidx]: <TAB> <TAB> <TAB> lidx += 1 <TAB> <TAB> <TAB> if not start: <TAB> <TAB> <TAB> <TAB> start = stmt <TAB> <TAB> <TAB> end = stmt <TAB> <TAB> elif start: <TAB> <TAB> <TAB> pairs.append((start, end)) <TAB> <TAB> <TAB> start = None <TAB> if start: <TAB> <TAB> pairs.append((start, end)) <TAB> return pairs",true,if stmt == lines [ lidx ] :,if stmt == lines [ lidx ] :,0.75,0.0
"def init_params(net): <TAB> """"""Init layer parameters."""""" <TAB> for module in net.modules(): <TAB> <TAB> if isinstance(module, nn.Conv2d): <TAB> <TAB> <TAB> init.kaiming_normal(module.weight, mode=""fan_out"") <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> init.constant(module.bias, 0) <TAB> <TAB> elif isinstance(module, nn.BatchNorm2d): <TAB> <TAB> <TAB> init.constant(module.weight, 1) <TAB> <TAB> <TAB> init.constant(module.bias, 0) <TAB> <TAB> elif isinstance(module, nn.Linear): <TAB> <TAB> <TAB> init.normal(module.weight, std=1e-3) <TAB> <TAB> <TAB> if module.bias: <TAB> <TAB> <TAB> <TAB> init.constant(module.bias, 0)",true,if module . bias :,if module . bias :,0.75,0.0
"def _get_directory_size_in_bytes(directory): <TAB> total = 0 <TAB> try: <TAB> <TAB> for entry in os.scandir(directory): <TAB> <TAB> <TAB> if entry.is_file(): <TAB> <TAB> <TAB> <TAB> # if it's a file, use stat() function <TAB> <TAB> <TAB> <TAB> total += entry.stat().st_size <TAB> <TAB> <TAB> elif entry.is_dir(): <TAB> <TAB> <TAB> <TAB> # if it's a directory, recursively call this function <TAB> <TAB> <TAB> <TAB> total += _get_directory_size_in_bytes(entry.path) <TAB> except NotADirectoryError: <TAB> <TAB> # if `directory` isn't a directory, get the file size then <TAB> <TAB> return os.path.getsize(directory) <TAB> except PermissionError: <TAB> <TAB> # if for whatever reason we can't open the folder, return 0 <TAB> <TAB> return 0 <TAB> return total",true,if entry . is_file ( ) :,if entry . is_file ( ) :,0.75,0.0
"def run_cmd(self, util, to, always_push_mark=False): <TAB> if to == ""bof"": <TAB> <TAB> util.push_mark_and_goto_position(0) <TAB> elif to == ""eof"": <TAB> <TAB> util.push_mark_and_goto_position(self.view.size()) <TAB> elif to in (""eow"", ""bow""): <TAB> <TAB> visible = self.view.visible_region() <TAB> <TAB> pos = visible.a if to == ""bow"" else visible.b <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> util.push_mark_and_goto_position(pos) <TAB> <TAB> else: <TAB> <TAB> <TAB> util.set_cursors([sublime.Region(pos)])",true,if always_push_mark :,if always_push_mark :,0.53,0.0
"def parse_results(cwd): <TAB> optimal_dd = None <TAB> optimal_measure = numpy.inf <TAB> for tup in tools.find_conf_files(cwd): <TAB> <TAB> dd = tup[1] <TAB> <TAB> if ""results.train_y_misclass"" in dd: <TAB> <TAB> <TAB> if dd[""results.train_y_misclass""] < optimal_measure: <TAB> <TAB> <TAB> <TAB> optimal_measure = dd[""results.train_y_misclass""] <TAB> <TAB> <TAB> <TAB> optimal_dd = dd <TAB> print(""Optimal results.train_y_misclass:"", str(optimal_measure)) <TAB> for key, value in optimal_dd.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(key + "": "" + str(value))",false,"if ""hyper_parameters"" in key :","if ""results.train_y_misclass"" in dd :",0.29,0.0
"def clean_vc_position(self): <TAB> vc_position = self.cleaned_data[""vc_position""] <TAB> if self.validate_vc_position: <TAB> <TAB> conflicting_members = Device.objects.filter( <TAB> <TAB> <TAB> virtual_chassis=self.instance.virtual_chassis, vc_position=vc_position <TAB> <TAB> ) <TAB> <TAB> if conflicting_members.exists(): <TAB> <TAB> <TAB> raise forms.ValidationError( <TAB> <TAB> <TAB> <TAB> ""A virtual chassis member already exists in position {}."".format( <TAB> <TAB> <TAB> <TAB> <TAB> vc_position <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return vc_position",true,if conflicting_members . exists ( ) :,if conflicting_members . exists ( ) :,0.75,0.0
"def cal_pads(auto_pad, pad_shape): <TAB> spatial_size = len(pad_shape) <TAB> pads = [0] * spatial_size * 2 <TAB> for i in range(spatial_size): <TAB> <TAB> if auto_pad == ""SAME_LOWER"": <TAB> <TAB> <TAB> pads[i + spatial_size] = pad_shape[i] // 2 <TAB> <TAB> <TAB> pads[i] = pad_shape[i] - pads[i + spatial_size] <TAB> <TAB> elif auto_pad == ""SAME_UPPER"": <TAB> <TAB> <TAB> pads[i] = pad_shape[i] // 2 <TAB> <TAB> <TAB> pads[i + spatial_size] = pad_shape[i] - pads[i] <TAB> return pads",true,"elif auto_pad == ""SAME_UPPER"" :","elif auto_pad == ""SAME_UPPER"" :",1.0,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> length = d.getVarInt32() <TAB> <TAB> <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB> <TAB> <TAB> d.skip(length) <TAB> <TAB> <TAB> self.add_presence_response().TryMerge(tmp) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0: <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 10 :,if tt == 10 :,0.75,0.0
"def test_cwl_rnaseq(self, install_test_files): <TAB> with install_cwl_test_files() as work_dir: <TAB> <TAB> with utils.chdir(os.path.join(work_dir, ""rnaseq"")): <TAB> <TAB> <TAB> if os.path.exists(""cromwell_work""): <TAB> <TAB> <TAB> <TAB> shutil.rmtree(""cromwell_work"") <TAB> <TAB> <TAB> subprocess.check_call( <TAB> <TAB> <TAB> <TAB> [""bcbio_vm.py"", ""cwlrun"", ""cromwell"", ""rnaseq-workflow""] <TAB> <TAB> <TAB> )",true,"if os . path . exists ( ""cromwell_work"" ) :","if os . path . exists ( ""cromwell_work"" ) :",0.75,0.0
"def files_per_version(self): <TAB> xpath = ""./files/file"" <TAB> files = self.root.findall(xpath) <TAB> versions = {} <TAB> for file in files: <TAB> <TAB> vfile = file.findall(""version"") <TAB> <TAB> for version in vfile: <TAB> <TAB> <TAB> nb = version.attrib[""nb""] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> versions[nb] = [] <TAB> <TAB> <TAB> versions[nb].append(file.attrib[""url""]) <TAB> return versions",false,if not nb in versions :,if nb not in versions :,0.22,0.0
"def value_to_db_datetime(self, value): <TAB> if value is None: <TAB> <TAB> return None <TAB> # SQLite doesn't support tz-aware datetimes <TAB> if timezone.is_aware(value): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> value = value.astimezone(timezone.utc).replace(tzinfo=None) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""SQLite backend does not support timezone-aware datetimes when USE_TZ is False."" <TAB> <TAB> <TAB> ) <TAB> return six.text_type(value)",true,if settings . USE_TZ :,if settings . USE_TZ :,0.75,0.0
"def _toplevelTryFunc(func, *args, status=status, **kwargs): <TAB> with ThreadProfiler(threading.current_thread()) as prof: <TAB> <TAB> t = threading.current_thread() <TAB> <TAB> t.name = func.__name__ <TAB> <TAB> try: <TAB> <TAB> <TAB> t.status = func(*args, **kwargs) <TAB> <TAB> except EscapeException as e:  # user aborted <TAB> <TAB> <TAB> t.status = ""aborted by user"" <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> status(""%s aborted"" % t.name, priority=2) <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> t.exception = e <TAB> <TAB> <TAB> t.status = ""exception"" <TAB> <TAB> <TAB> vd.exceptionCaught(e) <TAB> <TAB> if t.sheet: <TAB> <TAB> <TAB> t.sheet.currentThreads.remove(t)",true,if status :,if status :,0.53,0.0
"def ESP(phrase): <TAB> for num, name in enumerate(devname): <TAB> <TAB> if name.lower() in phrase: <TAB> <TAB> <TAB> dev = devid[num] <TAB> <TAB> <TAB> if custom_action_keyword[""Dict""][""On""] in phrase: <TAB> <TAB> <TAB> <TAB> ctrl = ""=ON"" <TAB> <TAB> <TAB> <TAB> say(""Turning On "" + name) <TAB> <TAB> <TAB> elif custom_action_keyword[""Dict""][""Off""] in phrase: <TAB> <TAB> <TAB> <TAB> ctrl = ""=OFF"" <TAB> <TAB> <TAB> <TAB> say(""Turning Off "" + name) <TAB> <TAB> <TAB> rq = requests.head(""https://"" + ip + dev + ctrl, verify=False)",false,"if custom_action_keyword [ ""Dict"" ] [ ""On"" ] in phrase :","elif custom_action_keyword [ ""Dict"" ] [ ""Off"" ] in phrase :",0.28,0.0
"def _table_schema(self, table): <TAB> rows = self.db.execute_sql(""PRAGMA table_info('%s')"" % table).fetchall() <TAB> # Build list of fields from table information <TAB> result = {} <TAB> for _, name, data_type, not_null, _, primary_key in rows: <TAB> <TAB> parts = [data_type] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> parts.append(""PRIMARY KEY"") <TAB> <TAB> if not_null: <TAB> <TAB> <TAB> parts.append(""NOT NULL"") <TAB> <TAB> result[name] = "" "".join(parts) <TAB> return result",true,if primary_key :,if primary_key :,0.53,0.0
"def _validate_forward_input(x, n_in): <TAB> if n_in != 1: <TAB> <TAB> if not isinstance(x, (tuple, list)): <TAB> <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> <TAB> f""Expected input to be a tuple or list; instead got {type(x)}."" <TAB> <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> f""Input tuple length ({len(x)}) does not equal required "" <TAB> <TAB> <TAB> <TAB> f""number of inputs ({n_in})."" <TAB> <TAB> <TAB> )",true,if len ( x ) != n_in :,if len ( x ) != n_in :,0.75,0.0
"def _table_reprfunc(self, row, col, val): <TAB> if self._table.column_names[col].endswith(""Size""): <TAB> <TAB> if isinstance(val, compat.string_types): <TAB> <TAB> <TAB> return ""  %s"" % val <TAB> <TAB> elif val < 1024 ** 2: <TAB> <TAB> <TAB> return ""  %.1f KB"" % (val / 1024.0 ** 1) <TAB> <TAB> elif val < 1024 ** 3: <TAB> <TAB> <TAB> return ""  %.1f MB"" % (val / 1024.0 ** 2) <TAB> <TAB> else: <TAB> <TAB> <TAB> return ""  %.1f GB"" % (val / 1024.0 ** 3) <TAB> if col in (0, """"): <TAB> <TAB> return str(val) <TAB> else: <TAB> <TAB> return ""  %s"" % val",false,elif val < 1024 ** 2 :,elif val < 1024 ** 3 :,0.57,0.0
"def get_path_name(self): <TAB> if self.is_root(): <TAB> <TAB> return ""@"" + self.name <TAB> else: <TAB> <TAB> parent_name = self.parent.get_path_name() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ""/"".join([parent_name, ""@"" + self.name]) <TAB> <TAB> else: <TAB> <TAB> <TAB> return ""@"" + self.name",true,if parent_name :,if parent_name :,0.53,0.0
"def parse(cls, api, json): <TAB> lst = List(api) <TAB> setattr(lst, ""_json"", json) <TAB> for k, v in json.items(): <TAB> <TAB> if k == ""user"": <TAB> <TAB> <TAB> setattr(lst, k, User.parse(api, v)) <TAB> <TAB> elif k == ""created_at"": <TAB> <TAB> <TAB> setattr(lst, k, parse_datetime(v)) <TAB> <TAB> else: <TAB> <TAB> <TAB> setattr(lst, k, v) <TAB> return lst",false,"if k == ""user"" :","elif k == ""created_at"" :",0.06,0.0
"def _bytecode_filenames(self, py_filenames): <TAB> bytecode_files = [] <TAB> for py_file in py_filenames: <TAB> <TAB> if not py_file.endswith("".py""): <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> bytecode_files.append(py_file + ""c"") <TAB> <TAB> if self.optimize > 0: <TAB> <TAB> <TAB> bytecode_files.append(py_file + ""o"") <TAB> return bytecode_files",false,if self . compile :,if self . optimize > 0 :,0.12,0.0
"def to_json_dict(self): <TAB> d = super().to_json_dict() <TAB> d[""bullet_list""] = RenderedContent.rendered_content_list_to_json(self.bullet_list) <TAB> if self.header is not None: <TAB> <TAB> if isinstance(self.header, RenderedContent): <TAB> <TAB> <TAB> d[""header""] = self.header.to_json_dict() <TAB> <TAB> else: <TAB> <TAB> <TAB> d[""header""] = self.header <TAB> if self.subheader is not None: <TAB> <TAB> if isinstance(self.subheader, RenderedContent): <TAB> <TAB> <TAB> d[""subheader""] = self.subheader.to_json_dict() <TAB> <TAB> else: <TAB> <TAB> <TAB> d[""subheader""] = self.subheader <TAB> return d",true,"if isinstance ( self . header , RenderedContent ) :","if isinstance ( self . header , RenderedContent ) :",0.75,0.0
"def makeSomeFiles(pathobj, dirdict): <TAB> pathdict = {} <TAB> for (key, value) in dirdict.items(): <TAB> <TAB> child = pathobj.child(key) <TAB> <TAB> if isinstance(value, bytes): <TAB> <TAB> <TAB> pathdict[key] = child <TAB> <TAB> <TAB> child.setContent(value) <TAB> <TAB> elif isinstance(value, dict): <TAB> <TAB> <TAB> child.createDirectory() <TAB> <TAB> <TAB> pathdict[key] = makeSomeFiles(child, value) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""only strings and dicts allowed as values"") <TAB> return pathdict",true,"elif isinstance ( value , dict ) :","elif isinstance ( value , dict ) :",0.75,0.0
"def Restore(self): <TAB> picker, obj = self._window, self._pObject <TAB> value = obj.RestoreValue(PERSIST_FILEDIRPICKER_PATH) <TAB> if value is not None: <TAB> <TAB> if issubclass(picker.__class__, wx.FileDialog): <TAB> <TAB> <TAB> if type(value) == list: <TAB> <TAB> <TAB> <TAB> value = value[-1] <TAB> <TAB> picker.SetPath(value) <TAB> <TAB> return True <TAB> return False",true,"if issubclass ( picker . __class__ , wx . FileDialog ) :","if issubclass ( picker . __class__ , wx . FileDialog ) :",0.75,0.0
"def recv(self, buffer_size): <TAB> try: <TAB> <TAB> return super(SSLConnection, self).recv(buffer_size) <TAB> except ssl.SSLError as err: <TAB> <TAB> if err.args[0] in (ssl.SSL_ERROR_WANT_READ, ssl.SSL_ERROR_WANT_WRITE): <TAB> <TAB> <TAB> return b"""" <TAB> <TAB> if err.args[0] in (ssl.SSL_ERROR_EOF, ssl.SSL_ERROR_ZERO_RETURN): <TAB> <TAB> <TAB> self.handle_close() <TAB> <TAB> <TAB> return b"""" <TAB> <TAB> raise",false,"if err . args [ 0 ] in ( ssl . SSL_ERROR_WANT_READ , ssl . SSL_ERROR_WANT_WRITE ) :","if err . args [ 0 ] in ( ssl . SSL_ERROR_EOF , ssl . SSL_ERROR_ZERO_RETURN ) :",0.85,0.0
"def IncrementErrorCount(self, category): <TAB> """"""Bumps the module's error statistic."""""" <TAB> self.error_count += 1 <TAB> if self.counting in (""toplevel"", ""detailed""): <TAB> <TAB> if self.counting != ""detailed"": <TAB> <TAB> <TAB> category = category.split(""/"")[0] <TAB> <TAB> if category not in self.errors_by_category: <TAB> <TAB> <TAB> self.errors_by_category[category] = 0 <TAB> <TAB> self.errors_by_category[category] += 1",true,"if self . counting != ""detailed"" :","if self . counting != ""detailed"" :",0.75,0.0
"def _get_y(self, data_inst): <TAB> if self.stratified: <TAB> <TAB> y = [v for i, v in data_inst.mapValues(lambda v: v.label).collect()] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> y = self.transform_regression_label(data_inst) <TAB> else: <TAB> <TAB> # make dummy y <TAB> <TAB> y = [0] * (data_inst.count()) <TAB> return y",false,if self . need_transform :,if self . transform_regression_label :,0.39,0.0
"def test_all_project_files(self): <TAB> if sys.platform.startswith(""win""): <TAB> <TAB> # XXX something with newlines goes wrong on Windows. <TAB> <TAB> return <TAB> for filepath in support.all_project_files(): <TAB> <TAB> with open(filepath, ""rb"") as fp: <TAB> <TAB> <TAB> encoding = tokenize.detect_encoding(fp.readline)[0] <TAB> <TAB> self.assertIsNotNone(encoding, ""can't detect encoding for %s"" % filepath) <TAB> <TAB> with open(filepath, ""r"") as fp: <TAB> <TAB> <TAB> source = fp.read() <TAB> <TAB> <TAB> source = source.decode(encoding) <TAB> <TAB> tree = driver.parse_string(source) <TAB> <TAB> new = unicode(tree) <TAB> <TAB> if diff(filepath, new, encoding): <TAB> <TAB> <TAB> self.fail(""Idempotency failed: %s"" % filepath)",true,"if diff ( filepath , new , encoding ) :","if diff ( filepath , new , encoding ) :",0.75,0.0
"def test_resource_arn_override_generator(self): <TAB> overrides = set() <TAB> for k, v in manager.resources.items(): <TAB> <TAB> arn_gen = bool(v.__dict__.get(""get_arns"") or v.__dict__.get(""generate_arn"")) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> overrides.add(k) <TAB> overrides = overrides.difference( <TAB> <TAB> { <TAB> <TAB> <TAB> ""account"", <TAB> <TAB> <TAB> ""s3"", <TAB> <TAB> <TAB> ""hostedzone"", <TAB> <TAB> <TAB> ""log-group"", <TAB> <TAB> <TAB> ""rest-api"", <TAB> <TAB> <TAB> ""redshift-snapshot"", <TAB> <TAB> <TAB> ""rest-stage"", <TAB> <TAB> } <TAB> ) <TAB> if overrides: <TAB> <TAB> raise ValueError(""unknown arn overrides in %s"" % ("", "".join(overrides)))",true,if arn_gen :,if arn_gen :,0.53,0.0
"def _check_dsl_runner(self) -> None: <TAB> """"""Checks if runner in dsl is Kubeflow V2 runner."""""" <TAB> with open(self.flags_dict[labels.PIPELINE_DSL_PATH], ""r"") as f: <TAB> <TAB> dsl_contents = f.read() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError(""KubeflowV2DagRunner not found in dsl."")",true,"if ""KubeflowV2DagRunner"" not in dsl_contents :","if ""KubeflowV2DagRunner"" not in dsl_contents :",0.75,0.0
"def create_warehouse(warehouse_name, properties=None, company=None): <TAB> if not company: <TAB> <TAB> company = ""_Test Company"" <TAB> warehouse_id = erpnext.encode_company_abbr(warehouse_name, company) <TAB> if not frappe.db.exists(""Warehouse"", warehouse_id): <TAB> <TAB> warehouse = frappe.new_doc(""Warehouse"") <TAB> <TAB> warehouse.warehouse_name = warehouse_name <TAB> <TAB> warehouse.parent_warehouse = ""All Warehouses - _TCUV"" <TAB> <TAB> warehouse.company = company <TAB> <TAB> warehouse.account = get_warehouse_account(warehouse_name, company) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> warehouse.update(properties) <TAB> <TAB> warehouse.save() <TAB> <TAB> return warehouse.name <TAB> else: <TAB> <TAB> return warehouse_id",true,if properties :,if properties :,0.53,0.0
"def _parse(self, contents): <TAB> entries = [] <TAB> hostnames_found = set() <TAB> for line in contents.splitlines(): <TAB> <TAB> if not len(line.strip()): <TAB> <TAB> <TAB> entries.append((""blank"", [line])) <TAB> <TAB> <TAB> continue <TAB> <TAB> (head, tail) = chop_comment(line.strip(), ""#"") <TAB> <TAB> if not len(head): <TAB> <TAB> <TAB> entries.append((""all_comment"", [line])) <TAB> <TAB> <TAB> continue <TAB> <TAB> entries.append((""hostname"", [head, tail])) <TAB> <TAB> hostnames_found.add(head) <TAB> if len(hostnames_found) > 1: <TAB> <TAB> raise IOError(""Multiple hostnames (%s) found!"" % (hostnames_found)) <TAB> return entries",false,if not len ( head ) :,if not len ( line . strip ( ) ) :,0.19,0.0
"def _get_omega(self): <TAB> if self._omega is None: <TAB> <TAB> n = self.get_drift_dim() // 2 <TAB> <TAB> omg = sympl.calc_omega(n) <TAB> <TAB> if self.oper_dtype == Qobj: <TAB> <TAB> <TAB> self._omega = Qobj(omg, dims=self.dyn_dims) <TAB> <TAB> <TAB> self._omega_qobj = self._omega <TAB> <TAB> elif self.oper_dtype == sp.csr_matrix: <TAB> <TAB> <TAB> self._omega = sp.csr_matrix(omg) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._omega = omg <TAB> return self._omega",false,elif self . oper_dtype == sp . csr_matrix :,elif self . operand_dtype == sp . csr_matrix :,0.55,0.0
"def get_in_inputs(key, data): <TAB> if isinstance(data, dict): <TAB> <TAB> for k, v in data.items(): <TAB> <TAB> <TAB> if k == key: <TAB> <TAB> <TAB> <TAB> return v <TAB> <TAB> <TAB> elif isinstance(v, (list, tuple, dict)): <TAB> <TAB> <TAB> <TAB> out = get_in_inputs(key, v) <TAB> <TAB> <TAB> <TAB> if out: <TAB> <TAB> <TAB> <TAB> <TAB> return out <TAB> elif isinstance(data, (list, tuple)): <TAB> <TAB> out = [get_in_inputs(key, x) for x in data] <TAB> <TAB> out = [x for x in out if x] <TAB> <TAB> if out: <TAB> <TAB> <TAB> return out[0]",true,"elif isinstance ( v , ( list , tuple , dict ) ) :","elif isinstance ( v , ( list , tuple , dict ) ) :",0.75,0.0
def visit_binary(binary): <TAB> if binary.operator == operators.eq: <TAB> <TAB> cols = util.column_set(chain(*[c.proxy_set for c in columns.difference(omit)])) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for c in reversed(columns): <TAB> <TAB> <TAB> <TAB> if c.shares_lineage(binary.right) and ( <TAB> <TAB> <TAB> <TAB> <TAB> not only_synonyms or c.name == binary.left.name <TAB> <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> <TAB> omit.add(c) <TAB> <TAB> <TAB> <TAB> <TAB> break,false,if binary . left in cols and binary . right in cols :,if not only_synonyms :,0.01,0.0
"def wait_tasks_or_abort(futures, timeout=60, kill_switch_ev=None): <TAB> try: <TAB> <TAB> LazySingletonTasksCoordinator.wait_tasks( <TAB> <TAB> <TAB> futures, return_when=FIRST_EXCEPTION, raise_exceptions=True <TAB> <TAB> ) <TAB> except Exception as e: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # Used when we want to keep both raise the exception and wait for all tasks to finish <TAB> <TAB> <TAB> kill_switch_ev.set() <TAB> <TAB> <TAB> LazySingletonTasksCoordinator.wait_tasks( <TAB> <TAB> <TAB> <TAB> futures, <TAB> <TAB> <TAB> <TAB> return_when=ALL_COMPLETED, <TAB> <TAB> <TAB> <TAB> raise_exceptions=False, <TAB> <TAB> <TAB> <TAB> timeout=timeout, <TAB> <TAB> <TAB> ) <TAB> <TAB> raise e",false,if kill_switch_ev is not None :,if kill_switch_ev :,0.05,0.0
"def is_valid(sample): <TAB> if sample is None: <TAB> <TAB> return False <TAB> if isinstance(sample, tuple): <TAB> <TAB> for s in sample: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> elif isinstance(s, np.ndarray) and s.size == 0: <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> elif isinstance(s, collections.abc.Sequence) and len(s) == 0: <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",true,if s is None :,if s is None :,0.75,0.0
"def setVaName(self, va, parent=None): <TAB> if parent is None: <TAB> <TAB> parent = self <TAB> curname = self.vw.getName(va) <TAB> if curname is None: <TAB> <TAB> curname = """" <TAB> name, ok = QInputDialog.getText(parent, ""Enter..."", ""Name"", text=curname) <TAB> if ok: <TAB> <TAB> name = str(name) <TAB> <TAB> if self.vw.vaByName(name): <TAB> <TAB> <TAB> raise Exception(""Duplicate Name: %s"" % name) <TAB> <TAB> self.vw.makeName(va, name)",true,if self . vw . vaByName ( name ) :,if self . vw . vaByName ( name ) :,0.75,0.0
"def generic_tag_compiler(params, defaults, name, node_class, parser, token): <TAB> ""Returns a template.Node subclass."" <TAB> bits = token.split_contents()[1:] <TAB> bmax = len(params) <TAB> def_len = defaults and len(defaults) or 0 <TAB> bmin = bmax - def_len <TAB> if len(bits) < bmin or len(bits) > bmax: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> message = ""%s takes %s arguments"" % (name, bmin) <TAB> <TAB> else: <TAB> <TAB> <TAB> message = ""%s takes between %s and %s arguments"" % (name, bmin, bmax) <TAB> <TAB> raise TemplateSyntaxError(message) <TAB> return node_class(bits)",false,if bmin == bmax :,if bmin < def_len :,0.06,0.0
"def extract_segmentation_mask(annotation): <TAB> poly_specs = annotation[DensePoseDataRelative.S_KEY] <TAB> if isinstance(poly_specs, torch.Tensor): <TAB> <TAB> # data is already given as mask tensors, no need to decode <TAB> <TAB> return poly_specs <TAB> import pycocotools.mask as mask_utils <TAB> segm = torch.zeros((DensePoseDataRelative.MASK_SIZE,) * 2, dtype=torch.float32) <TAB> for i in range(DensePoseDataRelative.N_BODY_PARTS): <TAB> <TAB> poly_i = poly_specs[i] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> mask_i = mask_utils.decode(poly_i) <TAB> <TAB> <TAB> segm[mask_i > 0] = i + 1 <TAB> return segm",false,if poly_i :,if poly_i . shape [ 0 ] == 0 :,0.08,0.0
"def module_list(target, fast): <TAB> """"""Find the list of modules to be compiled"""""" <TAB> modules = [] <TAB> native = native_modules(target) <TAB> basedir = os.path.join(ouroboros_repo_folder(), ""ouroboros"") <TAB> for name in os.listdir(basedir): <TAB> <TAB> module_name, ext = os.path.splitext(name) <TAB> <TAB> if ext == "".py"" or ext == """" and os.path.isdir(os.path.join(basedir, name)): <TAB> <TAB> <TAB> if module_name not in IGNORE_MODULES and module_name not in native: <TAB> <TAB> <TAB> <TAB> if not (fast and module_name in KNOWN_PROBLEM_MODULES): <TAB> <TAB> <TAB> <TAB> <TAB> modules.append(module_name) <TAB> return set(modules)",true,"if ext == "".py"" or ext == """" and os . path . isdir ( os . path . join ( basedir , name ) ) :","if ext == "".py"" or ext == """" and os . path . isdir ( os . path . join ( basedir , name ) ) :",1.0,0.0
"def filelist_from_patterns(pats, rootdir=None): <TAB> if rootdir is None: <TAB> <TAB> rootdir = ""."" <TAB> # filelist = [] <TAB> fileset = set([]) <TAB> lines = [line.strip() for line in pats] <TAB> for line in lines: <TAB> <TAB> pat = line[2:] <TAB> <TAB> newfiles = glob(osp.join(rootdir, pat)) <TAB> <TAB> if line.startswith(""+""): <TAB> <TAB> <TAB> fileset.update(newfiles) <TAB> <TAB> elif line.startswith(""-""): <TAB> <TAB> <TAB> fileset.difference_update(newfiles) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""line must start with + or -"") <TAB> filelist = list(fileset) <TAB> return filelist",false,"elif line . startswith ( ""-"" ) :","if line . startswith ( ""+"" ) :",0.21,0.0
"def get_upstream_statuses_events(self, upstream: Set) -> Dict[str, V1Statuses]: <TAB> statuses_by_refs = {u: [] for u in upstream} <TAB> events = self.events or []  # type: List[V1EventTrigger] <TAB> for e in events: <TAB> <TAB> entity_ref = contexts_refs.get_entity_ref(e.ref) <TAB> <TAB> if not entity_ref: <TAB> <TAB> <TAB> continue <TAB> <TAB> if entity_ref not in statuses_by_refs: <TAB> <TAB> <TAB> continue <TAB> <TAB> for kind in e.kinds: <TAB> <TAB> <TAB> status = V1EventKind.events_statuses_mapping.get(kind) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> statuses_by_refs[entity_ref].append(status) <TAB> return statuses_by_refs",true,if status :,if status :,0.53,0.0
"def __setitem__(self, key, value): <TAB> if isinstance(value, (tuple, list)): <TAB> <TAB> info, reference = value <TAB> <TAB> if info not in self._reverse_infos: <TAB> <TAB> <TAB> self._reverse_infos[info] = len(self._infos) <TAB> <TAB> <TAB> self._infos.append(info) <TAB> <TAB> if reference not in self._reverse_references: <TAB> <TAB> <TAB> self._reverse_references[reference] = len(self._references) <TAB> <TAB> <TAB> self._references.append(reference) <TAB> <TAB> self._trails[key] = ""%d,%d"" % ( <TAB> <TAB> <TAB> self._reverse_infos[info], <TAB> <TAB> <TAB> self._reverse_references[reference], <TAB> <TAB> ) <TAB> else: <TAB> <TAB> raise Exception(""unsupported type '%s'"" % type(value))",false,if info not in self . _reverse_infos :,if reference not in self . _reverse_references :,0.44,0.0
"def ChangeStyle(self, combos): <TAB> style = 0 <TAB> for combo in combos: <TAB> <TAB> if combo.GetValue() == 1: <TAB> <TAB> <TAB> if combo.GetLabel() == ""TR_VIRTUAL"": <TAB> <TAB> <TAB> <TAB> style = style | HTL.TR_VIRTUAL <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> style = style | eval(""wx."" + combo.GetLabel()) <TAB> <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> <TAB> style = style | eval(""HTL."" + combo.GetLabel()) <TAB> if self.GetAGWWindowStyleFlag() != style: <TAB> <TAB> self.SetAGWWindowStyleFlag(style)",false,if combo . GetValue ( ) == 1 :,"if combo . GetLabel ( ) == ""TR_VIRTUAL"" :",0.2,0.0
"def _parse_csrf(self, response): <TAB> for d in response: <TAB> <TAB> if d.startswith(""Set-Cookie:""): <TAB> <TAB> <TAB> for c in d.split("":"", 1)[1].split("";""): <TAB> <TAB> <TAB> <TAB> if c.strip().startswith(""CSRF-Token-""): <TAB> <TAB> <TAB> <TAB> <TAB> self._CSRFtoken = c.strip("" \r\n"") <TAB> <TAB> <TAB> <TAB> <TAB> log.verbose(""Got new cookie: %s"", self._CSRFtoken) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if self._CSRFtoken != None: <TAB> <TAB> <TAB> <TAB> break",true,"if c . strip ( ) . startswith ( ""CSRF-Token-"" ) :","if c . strip ( ) . startswith ( ""CSRF-Token-"" ) :",0.75,0.0
"def test_page_size_matching_max_returned_rows( <TAB> app_client_returned_rows_matches_page_size, ): <TAB> fetched = [] <TAB> path = ""/fixtures/no_primary_key.json"" <TAB> while path: <TAB> <TAB> response = app_client_returned_rows_matches_page_size.get(path) <TAB> <TAB> fetched.extend(response.json[""rows""]) <TAB> <TAB> assert len(response.json[""rows""]) in (1, 50) <TAB> <TAB> path = response.json[""next_url""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> path = path.replace(""http://localhost"", """") <TAB> assert 201 == len(fetched)",false,if path :,"if ""http://"" in path :",0.1,0.0
"def get_mapping_exception_message(mappings: List[Tuple[Text, Text]]): <TAB> """"""Return a message given a list of duplicates."""""" <TAB> message = """" <TAB> for name, action_name in mappings: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> message += ""\n"" <TAB> <TAB> message += ( <TAB> <TAB> <TAB> ""Intent '{}' is set to trigger action '{}', which is "" <TAB> <TAB> <TAB> ""not defined in the domain."".format(name, action_name) <TAB> <TAB> ) <TAB> return message",true,if message :,if message :,0.53,0.0
def cut(sentence): <TAB> sentence = strdecode(sentence) <TAB> blocks = re_han.split(sentence) <TAB> for blk in blocks: <TAB> <TAB> if re_han.match(blk): <TAB> <TAB> <TAB> for word in __cut(blk): <TAB> <TAB> <TAB> <TAB> if word not in Force_Split_Words: <TAB> <TAB> <TAB> <TAB> <TAB> yield word <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> for c in word: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield c <TAB> <TAB> else: <TAB> <TAB> <TAB> tmp = re_skip.split(blk) <TAB> <TAB> <TAB> for x in tmp: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> yield x,false,if x :,if x not in Force_Split_Words :,0.09,0.0
"def chop(expr, delta=10.0 ** (-10.0)): <TAB> if isinstance(expr, Real): <TAB> <TAB> if -delta < expr.get_float_value() < delta: <TAB> <TAB> <TAB> return Integer(0) <TAB> elif isinstance(expr, Complex) and expr.is_inexact(): <TAB> <TAB> real, imag = expr.real, expr.imag <TAB> <TAB> if -delta < real.get_float_value() < delta: <TAB> <TAB> <TAB> real = Integer(0) <TAB> <TAB> if -delta < imag.get_float_value() < delta: <TAB> <TAB> <TAB> imag = Integer(0) <TAB> <TAB> return Complex(real, imag) <TAB> elif isinstance(expr, Expression): <TAB> <TAB> return Expression(chop(expr.head), *[chop(leaf) for leaf in expr.leaves]) <TAB> return expr",false,if - delta < imag . get_float_value ( ) < delta :,if - delta < expr . get_float_value ( ) < delta :,0.87,0.0
"def make_row(self): <TAB> res = [] <TAB> for i in range(self.num_cols): <TAB> <TAB> t = sqlite3_column_type(self.stmnt, i) <TAB> <TAB> # print(""type"", t) <TAB> <TAB> if t == SQLITE_INTEGER: <TAB> <TAB> <TAB> res.append(sqlite3_column_int(self.stmnt, i)) <TAB> <TAB> elif t == SQLITE_FLOAT: <TAB> <TAB> <TAB> res.append(sqlite3_column_double(self.stmnt, i)) <TAB> <TAB> elif t == SQLITE_TEXT: <TAB> <TAB> <TAB> res.append(sqlite3_column_text(self.stmnt, i)) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise NotImplementedError <TAB> return tuple(res)",true,elif t == SQLITE_TEXT :,elif t == SQLITE_TEXT :,1.0,0.0
"def try_convert(self, string): <TAB> string = string.strip() <TAB> try: <TAB> <TAB> return int(string) <TAB> except: <TAB> <TAB> try: <TAB> <TAB> <TAB> return float(string) <TAB> <TAB> except: <TAB> <TAB> <TAB> if string == ""True"": <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> if string == ""False"": <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> return string",false,"if string == ""False"" :","if string == ""True"" :",0.39,0.0
"def configure_create_table_epilogue(store): <TAB> for val in ["""", "" ENGINE=InnoDB""]: <TAB> <TAB> store.config[""create_table_epilogue""] = val <TAB> <TAB> store._set_sql_flavour() <TAB> <TAB> if store._test_transaction(): <TAB> <TAB> <TAB> store.log.info(""create_table_epilogue='%s'"", val) <TAB> <TAB> <TAB> return <TAB> raise Exception(""Can not create a transactional table."")",true,if store . _test_transaction ( ) :,if store . _test_transaction ( ) :,0.75,0.0
"def _check_rule(self, match, target_dict, cred_dict): <TAB> """"""Recursively checks credentials based on the brains rules."""""" <TAB> try: <TAB> <TAB> new_match_list = self.rules[match] <TAB> except KeyError: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> new_match_list = (""rule:%s"" % self.default_rule,) <TAB> <TAB> else: <TAB> <TAB> <TAB> return False <TAB> return self.check(new_match_list, target_dict, cred_dict)",false,if self . default_rule and match != self . default_rule :,if self . default_rule :,0.24,0.0
"def get_civil_names(self): <TAB> congresspeople_ids = self.get_all_congresspeople_ids() <TAB> for i, congress_id in enumerate(congresspeople_ids): <TAB> <TAB> if not np.math.isnan(float(congress_id)): <TAB> <TAB> <TAB> percentage = i / self.total * 100 <TAB> <TAB> <TAB> msg = ""Processed {} out of {} ({:.2f}%)"" <TAB> <TAB> <TAB> print(msg.format(i, self.total, percentage), end=""\r"") <TAB> <TAB> <TAB> data = self.fetch_data_repository(congress_id) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> yield dict(data)",false,if data is not None :,if data :,0.05,0.0
"def parse_network_whitelist(self, network_whitelist_location): <TAB> networks = [] <TAB> with open(network_whitelist_location, ""r"") as text_file: <TAB> <TAB> for line in text_file: <TAB> <TAB> <TAB> line = line.strip().strip(""'"").strip('""') <TAB> <TAB> <TAB> if isIPv4(line) or isIPv6(line): <TAB> <TAB> <TAB> <TAB> networks.append(line) <TAB> return networks",true,if isIPv4 ( line ) or isIPv6 ( line ) :,if isIPv4 ( line ) or isIPv6 ( line ) :,1.0,0.0
"def _pick(self, cum): <TAB> if self._isleaf(): <TAB> <TAB> return self.bd[0], self.s <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return self.left._pick(cum) <TAB> <TAB> else: <TAB> <TAB> <TAB> return self.right._pick(cum - self.left.s)",true,if cum < self . left . s :,if cum < self . left . s :,0.75,0.0
"def serialize_content_range(value): <TAB> if isinstance(value, (tuple, list)): <TAB> <TAB> if len(value) not in (2, 3): <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""When setting content_range to a list/tuple, it must "" <TAB> <TAB> <TAB> <TAB> ""be length 2 or 3 (not %r)"" % value <TAB> <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> begin, end = value <TAB> <TAB> <TAB> length = None <TAB> <TAB> else: <TAB> <TAB> <TAB> begin, end, length = value <TAB> <TAB> value = ContentRange(begin, end, length) <TAB> value = str(value).strip() <TAB> if not value: <TAB> <TAB> return None <TAB> return value",true,if len ( value ) == 2 :,if len ( value ) == 2 :,0.75,0.0
"def make_index_fields(rec): <TAB> fields = {} <TAB> for k, v in rec.iteritems(): <TAB> <TAB> if k in (""lccn"", ""oclc"", ""isbn""): <TAB> <TAB> <TAB> fields[k] = v <TAB> <TAB> <TAB> continue <TAB> <TAB> if k == ""full_title"": <TAB> <TAB> <TAB> fields[""title""] = [read_short_title(v)] <TAB> return fields",true,"if k in ( ""lccn"" , ""oclc"" , ""isbn"" ) :","if k in ( ""lccn"" , ""oclc"" , ""isbn"" ) :",0.75,0.0
"def _sample_translation(reference, max_len): <TAB> translation = reference[:] <TAB> while np.random.uniform() < 0.8 and 1 < len(translation) < max_len: <TAB> <TAB> trans_len = len(translation) <TAB> <TAB> ind = np.random.randint(trans_len) <TAB> <TAB> action = np.random.choice(actions) <TAB> <TAB> if action == ""deletion"": <TAB> <TAB> <TAB> del translation[ind] <TAB> <TAB> elif action == ""replacement"": <TAB> <TAB> <TAB> ind_rep = np.random.randint(trans_len) <TAB> <TAB> <TAB> translation[ind] = translation[ind_rep] <TAB> <TAB> else: <TAB> <TAB> <TAB> ind_insert = np.random.randint(trans_len) <TAB> <TAB> <TAB> translation.insert(ind, translation[ind_insert]) <TAB> return translation",true,"elif action == ""replacement"" :","elif action == ""replacement"" :",1.0,0.0
"def __call__(self, text: str) -> str: <TAB> for t in self.cleaner_types: <TAB> <TAB> if t == ""tacotron"": <TAB> <TAB> <TAB> text = tacotron_cleaner.cleaners.custom_english_cleaners(text) <TAB> <TAB> elif t == ""jaconv"": <TAB> <TAB> <TAB> text = jaconv.normalize(text) <TAB> <TAB> elif t == ""vietnamese"": <TAB> <TAB> <TAB> if vietnamese_cleaners is None: <TAB> <TAB> <TAB> <TAB> raise RuntimeError(""Please install underthesea"") <TAB> <TAB> <TAB> text = vietnamese_cleaners.vietnamese_cleaner(text) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise RuntimeError(f""Not supported: type={t}"") <TAB> return text",false,"elif t == ""vietnamese"" :","elif t == ""jaconv"" :",0.64,0.0
"def hook_GetVariable(ql, address, params): <TAB> if params[""VariableName""] in ql.env: <TAB> <TAB> var = ql.env[params[""VariableName""]] <TAB> <TAB> read_len = read_int64(ql, params[""DataSize""]) <TAB> <TAB> if params[""Attributes""] != 0: <TAB> <TAB> <TAB> write_int64(ql, params[""Attributes""], 0) <TAB> <TAB> write_int64(ql, params[""DataSize""], len(var)) <TAB> <TAB> if read_len < len(var): <TAB> <TAB> <TAB> return EFI_BUFFER_TOO_SMALL <TAB> <TAB> if params[""Data""] != 0: <TAB> <TAB> <TAB> ql.mem.write(params[""Data""], var) <TAB> <TAB> return EFI_SUCCESS <TAB> return EFI_NOT_FOUND",false,"if params [ ""Attributes"" ] != 0 :",if read_len < len ( var ) :,0.02,0.0
"def test_setupapp(self, overrideRootMenu): <TAB> ""Call setupApp with each possible graphics type."" <TAB> root = self.root <TAB> flist = FileList(root) <TAB> for tktype in alltypes: <TAB> <TAB> with self.subTest(tktype=tktype): <TAB> <TAB> <TAB> macosx._tk_type = tktype <TAB> <TAB> <TAB> macosx.setupApp(root, flist) <TAB> <TAB> <TAB> if tktype in (""carbon"", ""cocoa""): <TAB> <TAB> <TAB> <TAB> self.assertTrue(overrideRootMenu.called) <TAB> <TAB> <TAB> overrideRootMenu.reset_mock()",true,"if tktype in ( ""carbon"" , ""cocoa"" ) :","if tktype in ( ""carbon"" , ""cocoa"" ) :",0.75,0.0
"def names(self, persistent=None): <TAB> u = set() <TAB> result = [] <TAB> for s in [ <TAB> <TAB> self.__storage(None), <TAB> <TAB> self.__storage(self.__category), <TAB> ]: <TAB> <TAB> for b in s: <TAB> <TAB> <TAB> if persistent is not None and b.persistent != persistent: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if b.name.startswith(""__""): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if b.name not in u: <TAB> <TAB> <TAB> <TAB> result.append(b.name) <TAB> <TAB> <TAB> <TAB> u.add(b.name) <TAB> return result",true,"if b . name . startswith ( ""__"" ) :","if b . name . startswith ( ""__"" ) :",0.75,0.0
"def _check_extra_specs(key, value=None): <TAB> extra_specs = diff.get(""extra_specs"") <TAB> specific_type = extra_specs.get(key) if extra_specs else None <TAB> old_type = None <TAB> new_type = None <TAB> if specific_type: <TAB> <TAB> old_type, new_type = specific_type <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> old_type = True if old_type and old_type.upper() == value else False <TAB> <TAB> <TAB> new_type = True if new_type and new_type.upper() == value else False <TAB> return old_type, new_type",false,if value :,if old_type and new_type :,0.05,0.0
"def _write_lock_file(self, repo, force=True):  # type: (Repository, bool) -> None <TAB> if force or (self._update and self._write_lock): <TAB> <TAB> updated_lock = self._locker.set_lock_data(self._package, repo.packages) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._io.write_line("""") <TAB> <TAB> <TAB> self._io.write_line(""<info>Writing lock file</>"")",true,if updated_lock :,if updated_lock :,0.53,0.0
"def process_message(self, msg): <TAB> if msg[""type""] == ""sample"": <TAB> <TAB> batch_shape = msg[""fn""].batch_shape <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> batch_shape = [1] * (-self.dim - len(batch_shape)) + list(batch_shape) <TAB> <TAB> <TAB> batch_shape[self.dim] = self.size <TAB> <TAB> <TAB> msg[""fn""] = msg[""fn""].expand(torch.Size(batch_shape))",false,if len ( batch_shape ) < - self . dim or batch_shape [ self . dim ] != self . size :,if len ( batch_shape ) < self . dim :,0.21,0.0
"def _test_reducibility(self): <TAB> # make a copy of the graph <TAB> graph = networkx.DiGraph(self._graph) <TAB> # preprocess: make it a super graph <TAB> self._make_supergraph(graph) <TAB> while True: <TAB> <TAB> changed = False <TAB> <TAB> # find a node with a back-edge, remove the edge (deleting the loop), and replace it with a MultiNode <TAB> <TAB> changed |= self._remove_self_loop(graph) <TAB> <TAB> # find a node that has only one predecessor, and merge it with its predecessor (replace them with a <TAB> <TAB> # MultiNode) <TAB> <TAB> changed |= self._merge_single_entry_node(graph) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # a fixed-point is reached <TAB> <TAB> <TAB> break",false,if not changed :,if changed :,0.1,0.0
"def __init__(self, roberta, num_classes=2, dropout=0.0, prefix=None, params=None): <TAB> super(RoBERTaClassifier, self).__init__(prefix=prefix, params=params) <TAB> self.roberta = roberta <TAB> self._units = roberta._units <TAB> with self.name_scope(): <TAB> <TAB> self.classifier = nn.HybridSequential(prefix=prefix) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.classifier.add(nn.Dropout(rate=dropout)) <TAB> <TAB> self.classifier.add(nn.Dense(units=self._units, activation=""tanh"")) <TAB> <TAB> if dropout: <TAB> <TAB> <TAB> self.classifier.add(nn.Dropout(rate=dropout)) <TAB> <TAB> self.classifier.add(nn.Dense(units=num_classes))",true,if dropout :,if dropout :,0.53,0.0
"def get_object_from_name(self, name, check_symlinks=True): <TAB> if not name: <TAB> <TAB> return None <TAB> name = name.rstrip(""\\"") <TAB> for a, o in self.objects.items(): <TAB> <TAB> if not o.name: <TAB> <TAB> <TAB> continue <TAB> <TAB> if o.name.lower() == name.lower(): <TAB> <TAB> <TAB> return o <TAB> if check_symlinks: <TAB> <TAB> m = [sl[1] for sl in self.symlinks if name.lower() == sl[0].lower()] <TAB> <TAB> if m: <TAB> <TAB> <TAB> name = m[0] <TAB> <TAB> return self.get_object_from_name(name, False)",true,if o . name . lower ( ) == name . lower ( ) :,if o . name . lower ( ) == name . lower ( ) :,1.0,0.0
"def __call__(self): <TAB> """"""Run all check_* methods."""""" <TAB> if self.on: <TAB> <TAB> oldformatwarning = warnings.formatwarning <TAB> <TAB> warnings.formatwarning = self.formatwarning <TAB> <TAB> try: <TAB> <TAB> <TAB> for name in dir(self): <TAB> <TAB> <TAB> <TAB> if name.startswith(""check_""): <TAB> <TAB> <TAB> <TAB> <TAB> method = getattr(self, name) <TAB> <TAB> <TAB> <TAB> <TAB> if method and callable(method): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> method() <TAB> <TAB> finally: <TAB> <TAB> <TAB> warnings.formatwarning = oldformatwarning",true,"if name . startswith ( ""check_"" ) :","if name . startswith ( ""check_"" ) :",0.75,0.0
"def __print__(self, defaults=False): <TAB> if defaults: <TAB> <TAB> print_func = str <TAB> else: <TAB> <TAB> print_func = repr <TAB> pieces = [] <TAB> default_values = self.__defaults__ <TAB> for k in self.__fields__: <TAB> <TAB> value = getattr(self, k) <TAB> <TAB> if not defaults and value == default_values[k]: <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance(value, basestring): <TAB> <TAB> <TAB> print_func = repr  # keep quotes around strings <TAB> <TAB> pieces.append(""%s=%s"" % (k, print_func(value))) <TAB> if pieces or self.__base__: <TAB> <TAB> return ""%s(%s)"" % (self.__class__.__name__, "", "".join(pieces)) <TAB> else: <TAB> <TAB> return """"",false,"if isinstance ( value , basestring ) :",if not defaults and value == default_values [ k ] :,0.02,0.0
"def apply(self, **kwargs: Any) -> None: <TAB> for node in self.document.traverse(nodes.target): <TAB> <TAB> if not node[""ids""]: <TAB> <TAB> <TAB> continue <TAB> <TAB> if ( <TAB> <TAB> <TAB> ""ismod"" in node <TAB> <TAB> <TAB> and node.parent.__class__ is nodes.section <TAB> <TAB> <TAB> and <TAB> <TAB> <TAB> # index 0 is the section title node <TAB> <TAB> <TAB> node.parent.index(node) == 1 <TAB> <TAB> ): <TAB> <TAB> <TAB> node.parent[""ids""][0:0] = node[""ids""] <TAB> <TAB> <TAB> node.parent.remove(node)",true,"if not node [ ""ids"" ] :","if not node [ ""ids"" ] :",0.75,0.0
"def add_special_token_2d( <TAB> values: List[List[int]], special_token: int = 0, use_first_value: bool = False ) -> List[List[int]]: <TAB> results = torch.jit.annotate(List[List[int]], []) <TAB> for value in values: <TAB> <TAB> result = torch.jit.annotate(List[int], []) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> special_token = value[0] <TAB> <TAB> result.append(special_token) <TAB> <TAB> result.extend(value) <TAB> <TAB> result.append(special_token) <TAB> <TAB> results.append(result) <TAB> return results",false,if use_first_value and len ( value ) > 0 :,if use_first_value :,0.02,0.0
"def test_import(self): <TAB> TIMEOUT = 5 <TAB> # Test for a deadlock when importing a module that runs the <TAB> # ThreadedResolver at import-time. See resolve_test.py for <TAB> # full explanation. <TAB> command = [sys.executable, ""-c"", ""import tornado.test.resolve_test_helper""] <TAB> start = time.time() <TAB> popen = Popen(command, preexec_fn=lambda: signal.alarm(TIMEOUT)) <TAB> while time.time() - start < TIMEOUT: <TAB> <TAB> return_code = popen.poll() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.assertEqual(0, return_code) <TAB> <TAB> <TAB> return  # Success. <TAB> <TAB> time.sleep(0.05) <TAB> self.fail(""import timed out"")",false,if return_code is not None :,if return_code != 0 :,0.05,0.0
"def find_item_for_key(self, e): <TAB> for item in self._items: <TAB> <TAB> if item.keycode == e.key and item.shift == e.shift and item.alt == e.alt: <TAB> <TAB> <TAB> focus = get_focus() <TAB> <TAB> <TAB> if self.command_is_enabled(item, focus): <TAB> <TAB> <TAB> <TAB> return self._items.index(item) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return -1 <TAB> return -1",true,"if self . command_is_enabled ( item , focus ) :","if self . command_is_enabled ( item , focus ) :",0.75,0.0
"def check_app_config_brackets(self): <TAB> for sn, app in cherrypy.tree.apps.items(): <TAB> <TAB> if not isinstance(app, cherrypy.Application): <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> for key in app.config.keys(): <TAB> <TAB> <TAB> if key.startswith(""["") or key.endswith(""]""): <TAB> <TAB> <TAB> <TAB> warnings.warn( <TAB> <TAB> <TAB> <TAB> <TAB> ""The application mounted at %r has config "" <TAB> <TAB> <TAB> <TAB> <TAB> ""section names with extraneous brackets: %r. "" <TAB> <TAB> <TAB> <TAB> <TAB> ""Config *files* need brackets; config *dicts* "" <TAB> <TAB> <TAB> <TAB> <TAB> ""(e.g. passed to tree.mount) do not."" % (sn, key) <TAB> <TAB> <TAB> <TAB> )",true,if not app . config :,if not app . config :,0.75,0.0
"def got_arbiter_module_type_defined(self, mod_type): <TAB> for a in self.arbiters: <TAB> <TAB> # Do like the linkify will do after.... <TAB> <TAB> for m in getattr(a, ""modules"", []): <TAB> <TAB> <TAB> # So look at what the arbiter try to call as module <TAB> <TAB> <TAB> m = m.strip() <TAB> <TAB> <TAB> # Ok, now look in modules... <TAB> <TAB> <TAB> for mod in self.modules: <TAB> <TAB> <TAB> <TAB> # try to see if this module is the good type <TAB> <TAB> <TAB> <TAB> if getattr(mod, ""module_type"", """").strip() == mod_type.strip(): <TAB> <TAB> <TAB> <TAB> <TAB> # if so, the good name? <TAB> <TAB> <TAB> <TAB> <TAB> if getattr(mod, ""module_name"", """").strip() == m: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",true,"if getattr ( mod , ""module_type"" , """" ) . strip ( ) == mod_type . strip ( ) :","if getattr ( mod , ""module_type"" , """" ) . strip ( ) == mod_type . strip ( ) :",1.0,0.0
"def write_config_to_file(self, folder, filename, config): <TAB> do_not_write = [""hyperparameter_search_space_updates""] <TAB> with open(os.path.join(folder, filename), ""w"") as f: <TAB> <TAB> f.write( <TAB> <TAB> <TAB> ""\n"".join( <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> (key + ""="" + str(value)) <TAB> <TAB> <TAB> <TAB> <TAB> for (key, value) in sorted(config.items(), key=lambda x: x[0]) <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> ) <TAB> <TAB> )",false,if not key in do_not_write,if key not in do_not_write,0.32,0.0
"def parsing(self, parsing):  # type: (bool) -> None <TAB> self._parsed = parsing <TAB> for k, v in self._body: <TAB> <TAB> if isinstance(v, Table): <TAB> <TAB> <TAB> v.value.parsing(parsing) <TAB> <TAB> elif isinstance(v, AoT): <TAB> <TAB> <TAB> for t in v.body: <TAB> <TAB> <TAB> <TAB> t.value.parsing(parsing)",false,"if isinstance ( v , Table ) :","elif isinstance ( v , AoT ) :",0.2,0.0
"def test_crashers_crash(self): <TAB> for fname in glob.glob(CRASHER_FILES): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Some ""crashers"" only trigger an exception rather than a <TAB> <TAB> # segfault. Consider that an acceptable outcome. <TAB> <TAB> if test.support.verbose: <TAB> <TAB> <TAB> print(""Checking crasher:"", fname) <TAB> <TAB> assert_python_failure(fname)",false,if os . path . basename ( fname ) in infinite_loops :,if fname in SKIPS :,0.01,0.0
"def __getitem__(self, k) -> ""SimMemView"": <TAB> if isinstance(k, slice): <TAB> <TAB> if k.step is not None: <TAB> <TAB> <TAB> raise ValueError(""Slices with strides are not supported"") <TAB> <TAB> elif k.start is None: <TAB> <TAB> <TAB> raise ValueError(""Must specify start index"") <TAB> <TAB> elif k.stop is not None: <TAB> <TAB> <TAB> raise ValueError(""Slices with stop index are not supported"") <TAB> <TAB> else: <TAB> <TAB> <TAB> addr = k.start <TAB> elif self._type is not None and self._type._can_refine_int: <TAB> <TAB> return self._type._refine(self, k) <TAB> else: <TAB> <TAB> addr = k <TAB> return self._deeper(addr=addr)",false,elif k . stop is not None :,elif k . stop is None :,0.44,0.0
"def get_lowest_wall_time(jsons): <TAB> lowest_wall = None <TAB> for j in jsons: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> lowest_wall = j[""wall_time""] <TAB> <TAB> if lowest_wall > j[""wall_time""]: <TAB> <TAB> <TAB> lowest_wall = j[""wall_time""] <TAB> return lowest_wall",true,if lowest_wall is None :,if lowest_wall is None :,0.75,0.0
"def extract_wav_headers(data): <TAB> # def search_subchunk(data, subchunk_id): <TAB> pos = 12  # The size of the RIFF chunk descriptor <TAB> subchunks = [] <TAB> while pos + 8 <= len(data) and len(subchunks) < 10: <TAB> <TAB> subchunk_id = data[pos : pos + 4] <TAB> <TAB> subchunk_size = struct.unpack_from(""<I"", data[pos + 4 : pos + 8])[0] <TAB> <TAB> subchunks.append(WavSubChunk(subchunk_id, pos, subchunk_size)) <TAB> <TAB> if subchunk_id == b""data"": <TAB> <TAB> <TAB> # 'data' is the last subchunk <TAB> <TAB> <TAB> break <TAB> <TAB> pos += subchunk_size + 8 <TAB> return subchunks",true,"if subchunk_id == b""data"" :","if subchunk_id == b""data"" :",0.75,0.0
"def _any_targets_have_native_sources(self, targets): <TAB> # TODO(#5949): convert this to checking if the closure of python requirements has any <TAB> # platform-specific packages (maybe find the platforms there too?). <TAB> for tgt in targets: <TAB> <TAB> for type_constraint, target_predicate in self._native_target_matchers.items(): <TAB> <TAB> <TAB> if type_constraint.satisfied_by(tgt) and target_predicate(tgt): <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",true,if type_constraint . satisfied_by ( tgt ) and target_predicate ( tgt ) :,if type_constraint . satisfied_by ( tgt ) and target_predicate ( tgt ) :,1.0,0.0
"def validate_memory(self, value): <TAB> for k, v in value.viewitems(): <TAB> <TAB> if v is None:  # use NoneType to unset a value <TAB> <TAB> <TAB> continue <TAB> <TAB> if not re.match(PROCTYPE_MATCH, k): <TAB> <TAB> <TAB> raise serializers.ValidationError(""Process types can only contain [a-z]"") <TAB> <TAB> if not re.match(MEMLIMIT_MATCH, str(v)): <TAB> <TAB> <TAB> raise serializers.ValidationError( <TAB> <TAB> <TAB> <TAB> ""Limit format: <number><unit>, where unit = B, K, M or G"" <TAB> <TAB> <TAB> ) <TAB> return value",true,"if not re . match ( PROCTYPE_MATCH , k ) :","if not re . match ( PROCTYPE_MATCH , k ) :",0.75,0.0
"def cart_number_checksum_validation(cls, number): <TAB> digits = [] <TAB> even = False <TAB> if not number.isdigit(): <TAB> <TAB> return False <TAB> for digit in reversed(number): <TAB> <TAB> digit = ord(digit) - ord(""0"") <TAB> <TAB> if even: <TAB> <TAB> <TAB> digit *= 2 <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> digit = digit % 10 + digit // 10 <TAB> <TAB> digits.append(digit) <TAB> <TAB> even = not even <TAB> return sum(digits) % 10 == 0 if digits else False",false,if digit >= 10 :,if digit % 10 == 0 :,0.14,0.0
"def transform(a, cmds): <TAB> buf = a.split(""\n"") <TAB> for cmd in cmds: <TAB> <TAB> ctype, line, col, char = cmd <TAB> <TAB> if ctype == ""D"": <TAB> <TAB> <TAB> if char != ""\n"": <TAB> <TAB> <TAB> <TAB> buf[line] = buf[line][:col] + buf[line][col + len(char) :] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> buf[line] = buf[line] + buf[line + 1] <TAB> <TAB> <TAB> <TAB> del buf[line + 1] <TAB> <TAB> elif ctype == ""I"": <TAB> <TAB> <TAB> buf[line] = buf[line][:col] + char + buf[line][col:] <TAB> <TAB> buf = ""\n"".join(buf).split(""\n"") <TAB> return ""\n"".join(buf)",true,"if char != ""\n"" :","if char != ""\n"" :",0.75,0.0
"def get_partners(self) -> Dict[AbstractNode, Set[int]]: <TAB> partners = {}  # type: Dict[AbstractNode, Set[int]] <TAB> for edge in self.edges: <TAB> <TAB> if edge.is_dangling(): <TAB> <TAB> <TAB> raise ValueError(""Cannot contract copy tensor with dangling edges"") <TAB> <TAB> if self._is_my_trace(edge): <TAB> <TAB> <TAB> continue <TAB> <TAB> partner_node, shared_axis = self._get_partner(edge) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> partners[partner_node] = set() <TAB> <TAB> partners[partner_node].add(shared_axis) <TAB> return partners",true,if partner_node not in partners :,if partner_node not in partners :,0.75,0.0
"def _bind_interactive_rez(self): <TAB> if config.set_prompt and self.settings.prompt: <TAB> <TAB> stored_prompt = os.getenv(""REZ_STORED_PROMPT_CMD"") <TAB> <TAB> curr_prompt = stored_prompt or os.getenv(""PROMPT"", """") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.setenv(""REZ_STORED_PROMPT_CMD"", curr_prompt) <TAB> <TAB> new_prompt = ""%%REZ_ENV_PROMPT%%"" <TAB> <TAB> new_prompt = ( <TAB> <TAB> <TAB> (new_prompt + "" %s"") if config.prefix_prompt else (""%s "" + new_prompt) <TAB> <TAB> ) <TAB> <TAB> new_prompt = new_prompt % curr_prompt <TAB> <TAB> self._addline(""set PROMPT=%s"" % new_prompt)",false,if not stored_prompt :,if curr_prompt :,0.05,0.0
"def __listingColumns(self): <TAB> columns = [] <TAB> for name in self.__getColumns(): <TAB> <TAB> definition = column(name) <TAB> <TAB> if not definition: <TAB> <TAB> <TAB> IECore.msg( <TAB> <TAB> <TAB> <TAB> IECore.Msg.Level.Error, <TAB> <TAB> <TAB> <TAB> ""GafferImageUI.CatalogueUI"", <TAB> <TAB> <TAB> <TAB> ""No column registered with name '%s'"" % name, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance(definition, IconColumn): <TAB> <TAB> <TAB> c = GafferUI.PathListingWidget.IconColumn(definition.title(), """", name) <TAB> <TAB> else: <TAB> <TAB> <TAB> c = GafferUI.PathListingWidget.StandardColumn(definition.title(), name) <TAB> <TAB> columns.append(c) <TAB> return columns",true,"if isinstance ( definition , IconColumn ) :","if isinstance ( definition , IconColumn ) :",0.75,0.0
"def _check_invalid_keys(self, section_name, section): <TAB> for key in section: <TAB> <TAB> key_name = str(key) <TAB> <TAB> valid_key_names = [s[0] for s in self.keys] <TAB> <TAB> is_valid_key = key_name in valid_key_names <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> err_msg = ( <TAB> <TAB> <TAB> <TAB> ""'{0}' is not a valid key name for '{1}'. Must "" ""be one of these: {2}"" <TAB> <TAB> <TAB> ).format(key_name, section_name, "", "".join(valid_key_names)) <TAB> <TAB> <TAB> raise InvalidConfig(err_msg)",false,if not is_valid_key :,if is_valid_key :,0.1,0.0
"def _get_startup_packages(lib_path: Path, packages) -> Set[str]: <TAB> names = set() <TAB> for path in lib_path.iterdir(): <TAB> <TAB> name = path.name <TAB> <TAB> if name == ""__pycache__"": <TAB> <TAB> <TAB> continue <TAB> <TAB> if name.endswith("".py""): <TAB> <TAB> <TAB> names.add(name.split(""."")[0]) <TAB> <TAB> elif path.is_dir() and ""."" not in name: <TAB> <TAB> <TAB> names.add(name) <TAB> if packages: <TAB> <TAB> packages = {package.lower().replace(""-"", ""_"") for package in packages} <TAB> <TAB> if len(names & packages) == len(packages): <TAB> <TAB> <TAB> return packages <TAB> return names",false,"elif path . is_dir ( ) and ""."" not in name :","if name == ""__pycache__"" :",0.01,0.0
"def sortkeypicker(keynames): <TAB> negate = set() <TAB> for i, k in enumerate(keynames): <TAB> <TAB> if k[:1] == ""-"": <TAB> <TAB> <TAB> keynames[i] = k[1:] <TAB> <TAB> <TAB> negate.add(k[1:]) <TAB> def getit(adict): <TAB> <TAB> composite = [adict[k] for k in keynames] <TAB> <TAB> for i, (k, v) in enumerate(zip(keynames, composite)): <TAB> <TAB> <TAB> if k in negate: <TAB> <TAB> <TAB> <TAB> composite[i] = -v <TAB> <TAB> return composite <TAB> return getit",true,"if k [ : 1 ] == ""-"" :","if k [ : 1 ] == ""-"" :",0.75,0.0
"def iter_symbols(code): <TAB> """"""Yield names and strings used by `code` and its nested code objects"""""" <TAB> for name in code.co_names: <TAB> <TAB> yield name <TAB> for const in code.co_consts: <TAB> <TAB> if isinstance(const, six.string_types): <TAB> <TAB> <TAB> yield const <TAB> <TAB> elif isinstance(const, CodeType): <TAB> <TAB> <TAB> for name in iter_symbols(const): <TAB> <TAB> <TAB> <TAB> yield name",true,"elif isinstance ( const , CodeType ) :","elif isinstance ( const , CodeType ) :",0.75,0.0
"def set_study_directions( <TAB> self, study_id: int, directions: Sequence[StudyDirection] ) -> None: <TAB> with self._lock: <TAB> <TAB> if study_id in self._studies: <TAB> <TAB> <TAB> current_directions = self._studies[study_id].directions <TAB> <TAB> <TAB> if directions == current_directions: <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> elif ( <TAB> <TAB> <TAB> <TAB> len(current_directions) == 1 <TAB> <TAB> <TAB> <TAB> and current_directions[0] == StudyDirection.NOT_SET <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> self._studies[study_id].directions = list(directions) <TAB> <TAB> <TAB> <TAB> self._backend.set_study_directions(study_id, directions) <TAB> <TAB> <TAB> <TAB> return <TAB> self._backend.set_study_directions(study_id, directions)",false,if study_id in self . _studies :,elif ( ( current_directions [ 0 ] == StudyDirection . NOT_SET ) :,0.01,0.0
"def PreprocessConditionalStatement(self, IfList, ReplacedLine): <TAB> while self: <TAB> <TAB> if self.__Token: <TAB> <TAB> <TAB> x = 1 <TAB> <TAB> elif not IfList: <TAB> <TAB> <TAB> if self <= 2: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionSizeGuid = 3 <TAB> <TAB> <TAB> if not RegionSizeGuid: <TAB> <TAB> <TAB> <TAB> RegionLayoutLine = 5 <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionLayoutLine = self.CurrentLineNumber <TAB> return 1",true,if self . __Token :,if self . __Token :,0.75,0.0
"def _check_blocking(self, current_time): <TAB> if self._switch_flag is False: <TAB> <TAB> active_greenlet = self._active_greenlet <TAB> <TAB> if active_greenlet is not None and active_greenlet != self._hub: <TAB> <TAB> <TAB> self._notify_greenlet_blocked(active_greenlet, current_time) <TAB> self._switch_flag = False",true,if active_greenlet is not None and active_greenlet != self . _hub :,if active_greenlet is not None and active_greenlet != self . _hub :,0.75,0.0
"def detect(get_page): <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS: <TAB> <TAB> page, headers, code = get_page(get=vector) <TAB> <TAB> retval = ( <TAB> <TAB> <TAB> re.search(r""BlockDos\.net"", headers.get(HTTP_HEADER.SERVER, """"), re.I) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> return retval",true,if retval :,if retval :,0.53,0.0
"def _fastqc_data_section(self, section_name): <TAB> out = [] <TAB> in_section = False <TAB> data_file = os.path.join(self._dir, ""fastqc_data.txt"") <TAB> if os.path.exists(data_file): <TAB> <TAB> with open(data_file) as in_handle: <TAB> <TAB> <TAB> for line in in_handle: <TAB> <TAB> <TAB> <TAB> if line.startswith("">>%s"" % section_name): <TAB> <TAB> <TAB> <TAB> <TAB> in_section = True <TAB> <TAB> <TAB> <TAB> elif in_section: <TAB> <TAB> <TAB> <TAB> <TAB> if line.startswith("">>END""): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> <TAB> out.append(line.rstrip(""\r\n"")) <TAB> return out",false,"if line . startswith ( "">>%s"" % section_name ) :","if line . startswith ( "">END"" ) :",0.23,0.0
"def shortcut(self, input, ch_out, stride, is_first, name): <TAB> ch_in = input.shape[1] <TAB> if ch_in != ch_out or stride != 1: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return self.conv_bn_layer(input, ch_out, 1, stride, name=name) <TAB> <TAB> else: <TAB> <TAB> <TAB> return self.conv_bn_layer_new(input, ch_out, 1, stride, name=name) <TAB> elif is_first: <TAB> <TAB> return self.conv_bn_layer(input, ch_out, 1, stride, name=name) <TAB> else: <TAB> <TAB> return input",false,if is_first or stride == 1 :,if is_first :,0.04,0.0
"def get_value_from_string(self, string_value): <TAB> """"""Return internal representation starting from CFN/user-input value."""""" <TAB> param_value = self.get_default_value() <TAB> try: <TAB> <TAB> if string_value is not None: <TAB> <TAB> <TAB> string_value = str(string_value).strip() <TAB> <TAB> <TAB> if string_value != ""NONE"": <TAB> <TAB> <TAB> <TAB> param_value = int(string_value) <TAB> except ValueError: <TAB> <TAB> self.pcluster_config.warn( <TAB> <TAB> <TAB> ""Unable to convert the value '{0}' to an Integer. "" <TAB> <TAB> <TAB> ""Using default value for parameter '{1}'"".format(string_value, self.key) <TAB> <TAB> ) <TAB> return param_value",true,"if string_value != ""NONE"" :","if string_value != ""NONE"" :",0.75,0.0
"def get_running(workers): <TAB> running = [] <TAB> for worker in workers: <TAB> <TAB> current_test_name = worker.current_test_name <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> dt = time.monotonic() - worker.start_time <TAB> <TAB> if dt >= PROGRESS_MIN_TIME: <TAB> <TAB> <TAB> text = ""%s (%s)"" % (current_test_name, format_duration(dt)) <TAB> <TAB> <TAB> running.append(text) <TAB> return running",false,if not current_test_name :,if current_test_name is None :,0.05,0.0
"def generate_data(self, request): <TAB> """"""Generate data for the widget."""""" <TAB> uptime = {} <TAB> cache_stats = get_cache_stats() <TAB> if cache_stats: <TAB> <TAB> for hosts, stats in cache_stats: <TAB> <TAB> <TAB> if stats[""uptime""] > 86400: <TAB> <TAB> <TAB> <TAB> uptime[""value""] = stats[""uptime""] / 60 / 60 / 24 <TAB> <TAB> <TAB> <TAB> uptime[""unit""] = _(""days"") <TAB> <TAB> <TAB> elif stats[""uptime""] > 3600: <TAB> <TAB> <TAB> <TAB> uptime[""value""] = stats[""uptime""] / 60 / 60 <TAB> <TAB> <TAB> <TAB> uptime[""unit""] = _(""hours"") <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> uptime[""value""] = stats[""uptime""] / 60 <TAB> <TAB> <TAB> <TAB> uptime[""unit""] = _(""minutes"") <TAB> return {""cache_stats"": cache_stats, ""uptime"": uptime}",true,"elif stats [ ""uptime"" ] > 3600 :","elif stats [ ""uptime"" ] > 3600 :",0.75,0.0
"def add_actors(self): <TAB> """"""Adds `self.actors` to the scene."""""" <TAB> if not self._actors_added: <TAB> <TAB> self.reader.render_window = self.scene.render_window <TAB> <TAB> self._update_reader() <TAB> <TAB> self._actors_added = True <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._visible_changed(self.visible) <TAB> <TAB> self.scene.render()",false,if not self . visible :,if self . visible :,0.28,0.0
"def _add_uniqu_suffix(self, titles): <TAB> counters = dict() <TAB> titles_with_suffix = [] <TAB> for title in titles: <TAB> <TAB> counters[title] = counters[title] + 1 if title in counters else 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> title = f""{title} ({counters[title]})"" <TAB> <TAB> titles_with_suffix.append(title) <TAB> return titles_with_suffix",false,if counters [ title ] > 1 :,if counters [ title ] > 0 :,0.61,0.0
"def _verify_udf_resources(self, job, config): <TAB> udf_resources = config.get(""userDefinedFunctionResources"", ()) <TAB> self.assertEqual(len(job.udf_resources), len(udf_resources)) <TAB> for found, expected in zip(job.udf_resources, udf_resources): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.assertEqual(found.udf_type, ""resourceUri"") <TAB> <TAB> <TAB> self.assertEqual(found.value, expected[""resourceUri""]) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.assertEqual(found.udf_type, ""inlineCode"") <TAB> <TAB> <TAB> self.assertEqual(found.value, expected[""inlineCode""])",true,"if ""resourceUri"" in expected :","if ""resourceUri"" in expected :",0.75,0.0
"def __init__( <TAB> self, layout, value=None, string=None, *, dtype: np.dtype = np.float64 ) -> None: <TAB> """"""Constructor."""""" <TAB> self.layout = layout <TAB> if value is None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.value = np.zeros((self.layout.gaDims,), dtype=dtype) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.value = layout.parse_multivector(string).value <TAB> else: <TAB> <TAB> self.value = np.array(value) <TAB> <TAB> if self.value.shape != (self.layout.gaDims,): <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""value must be a sequence of length %s"" % self.layout.gaDims <TAB> <TAB> <TAB> )",true,if string is None :,if string is None :,0.75,0.0
"def read_file(filename, print_error=True): <TAB> """"""Returns the contents of a file."""""" <TAB> try: <TAB> <TAB> for encoding in [""utf-8"", ""latin1""]: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> with io.open(filename, encoding=encoding) as fp: <TAB> <TAB> <TAB> <TAB> <TAB> return fp.read() <TAB> <TAB> <TAB> except UnicodeDecodeError: <TAB> <TAB> <TAB> <TAB> pass <TAB> except IOError as exception: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(exception, file=sys.stderr) <TAB> <TAB> return None",true,if print_error :,if print_error :,0.53,0.0
"def get_albums_for_iter(self, iter_): <TAB> obj = self.get_value(iter_) <TAB> if isinstance(obj, AlbumNode): <TAB> <TAB> return {obj.album} <TAB> albums = set() <TAB> for child_iter, value in self.iterrows(iter_): <TAB> <TAB> if isinstance(value, AlbumNode): <TAB> <TAB> <TAB> albums.add(value.album) <TAB> <TAB> else: <TAB> <TAB> <TAB> albums.update(self.get_albums_for_iter(child_iter)) <TAB> return albums",true,"if isinstance ( value , AlbumNode ) :","if isinstance ( value , AlbumNode ) :",0.75,0.0
"def wait_til_ready(cls, connector=None): <TAB> if connector is None: <TAB> <TAB> connector = cls.connector <TAB> while True: <TAB> <TAB> now = time.time() <TAB> <TAB> next_iteration = now // 1.0 + 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> await cls._clock.run_til(next_iteration) <TAB> <TAB> await asyncio.sleep(1.0)",false,if connector . ready :,if next_iteration == 0 :,0.03,0.0
"def remove_property(self, key):  # type: (str) -> None <TAB> with self.secure() as config: <TAB> <TAB> keys = key.split(""."") <TAB> <TAB> current_config = config <TAB> <TAB> for i, key in enumerate(keys): <TAB> <TAB> <TAB> if key not in current_config: <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> del current_config[key] <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> current_config = current_config[key]",false,if i == len ( keys ) - 1 :,if i == 0 :,0.06,0.0
"def get(self, hash160, default=None): <TAB> v = self.p2s_for_hash(hash160) <TAB><IF-STMT> <TAB> <TAB> return v <TAB> if hash160 not in self._secret_exponent_cache: <TAB> <TAB> v = self.path_for_hash160(hash160) <TAB> <TAB> if v: <TAB> <TAB> <TAB> fingerprint, path = v <TAB> <TAB> <TAB> for key in self._secrets.get(fingerprint, []): <TAB> <TAB> <TAB> <TAB> subkey = key.subkey_for_path(path) <TAB> <TAB> <TAB> <TAB> self._add_key_to_cache(subkey) <TAB> return self._secret_exponent_cache.get(hash160, default)",true,if v :,if v :,0.53,0.0
"def fetch_all(self, api_client, fetchstatuslogger, q, targets): <TAB> self.fetchstatuslogger = fetchstatuslogger <TAB> if targets != None: <TAB> <TAB> # Ensure targets is a tuple <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> targets = tuple( <TAB> <TAB> <TAB> <TAB> targets, <TAB> <TAB> <TAB> ) <TAB> <TAB> elif type(targets) != tuple: <TAB> <TAB> <TAB> targets = tuple(targets) <TAB> for target in targets: <TAB> <TAB> self._fetch_targets(api_client, q, target)",false,if type ( targets ) != list and type ( targets ) != tuple :,if type ( targets ) == list :,0.24,0.0
"def dgl_mp_batchify_fn(data): <TAB> if isinstance(data[0], tuple): <TAB> <TAB> data = zip(*data) <TAB> <TAB> return [dgl_mp_batchify_fn(i) for i in data] <TAB> for dt in data: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if isinstance(dt, dgl.DGLGraph): <TAB> <TAB> <TAB> <TAB> return [d for d in data if isinstance(d, dgl.DGLGraph)] <TAB> <TAB> <TAB> elif isinstance(dt, nd.NDArray): <TAB> <TAB> <TAB> <TAB> pad = Pad(axis=(1, 2), num_shards=1, ret_length=False) <TAB> <TAB> <TAB> <TAB> data_list = [dt for dt in data if dt is not None] <TAB> <TAB> <TAB> <TAB> return pad(data_list)",true,if dt is not None :,if dt is not None :,0.75,0.0
"def capture_server(evt, buf, serv): <TAB> try: <TAB> <TAB> serv.listen(5) <TAB> <TAB> conn, addr = serv.accept() <TAB> except socket.timeout: <TAB> <TAB> pass <TAB> else: <TAB> <TAB> n = 200 <TAB> <TAB> while n > 0: <TAB> <TAB> <TAB> r, w, e = select.select([conn], [], []) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> data = conn.recv(10) <TAB> <TAB> <TAB> <TAB> # keep everything except for the newline terminator <TAB> <TAB> <TAB> <TAB> buf.write(data.replace(""\n"", """")) <TAB> <TAB> <TAB> <TAB> if ""\n"" in data: <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> n -= 1 <TAB> <TAB> <TAB> time.sleep(0.01) <TAB> <TAB> conn.close() <TAB> finally: <TAB> <TAB> serv.close() <TAB> <TAB> evt.set()",false,if r :,if w :,0.32,0.0
"def elem(): <TAB> if ints_only: <TAB> <TAB> return random.randint(0, 10000000000) <TAB> else: <TAB> <TAB> t = random.randint(0, 2) <TAB> <TAB> if t == 0: <TAB> <TAB> <TAB> return random.randint(0, 10000000000) <TAB> <TAB> elif t == 1: <TAB> <TAB> <TAB> return float(random.randint(0, 10000000000)) <TAB> <TAB> elif strings is not None: <TAB> <TAB> <TAB> return strings[random.randint(0, len(strings) - 1)] <TAB> <TAB> return random_string(random.randint(100, 1000))",true,elif strings is not None :,elif strings is not None :,0.75,0.0
"def has_changed(self, initial, data): <TAB> if self.disabled: <TAB> <TAB> return False <TAB> if initial is None: <TAB> <TAB> initial = ["""" for x in range(0, len(data))] <TAB> else: <TAB> <TAB> if not isinstance(initial, list): <TAB> <TAB> <TAB> initial = self.widget.decompress(initial) <TAB> for field, initial, data in zip(self.fields, initial, data): <TAB> <TAB> try: <TAB> <TAB> <TAB> initial = field.to_python(initial) <TAB> <TAB> except ValidationError: <TAB> <TAB> <TAB> return True <TAB> <TAB> if field.has_changed(initial, data): <TAB> <TAB> <TAB> return True <TAB> return False",false,"if not isinstance ( initial , list ) :","if field . has_changed ( initial , data ) :",0.07,0.0
"def _load_testfile(filename, package, module_relative): <TAB> if module_relative: <TAB> <TAB> package = _normalize_module(package, 3) <TAB> <TAB> filename = _module_relative_path(package, filename) <TAB> <TAB> if hasattr(package, ""__loader__""): <TAB> <TAB> <TAB> if hasattr(package.__loader__, ""get_data""): <TAB> <TAB> <TAB> <TAB> file_contents = package.__loader__.get_data(filename) <TAB> <TAB> <TAB> <TAB> # get_data() opens files as 'rb', so one must do the equivalent <TAB> <TAB> <TAB> <TAB> # conversion as universal newlines would do. <TAB> <TAB> <TAB> <TAB> return file_contents.replace(os.linesep, ""\n""), filename <TAB> return open(filename).read(), filename",true,"if hasattr ( package , ""__loader__"" ) :","if hasattr ( package , ""__loader__"" ) :",0.75,0.0
"def release(self): <TAB> tid = _thread.get_ident() <TAB> with self.lock: <TAB> <TAB> if self.owner != tid: <TAB> <TAB> <TAB> raise RuntimeError(""cannot release un-acquired lock"") <TAB> <TAB> assert self.count > 0 <TAB> <TAB> self.count -= 1 <TAB> <TAB> if self.count == 0: <TAB> <TAB> <TAB> self.owner = None <TAB> <TAB> <TAB> if self.waiters: <TAB> <TAB> <TAB> <TAB> self.waiters -= 1 <TAB> <TAB> <TAB> <TAB> self.wakeup.release()",true,if self . waiters :,if self . waiters :,0.75,0.0
"def stage( <TAB> self, x, num_modules, num_blocks, channels, multi_scale_output=True, name=None ): <TAB> out = x <TAB> for i in range(num_modules): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> out = self.high_resolution_module( <TAB> <TAB> <TAB> <TAB> out, <TAB> <TAB> <TAB> <TAB> num_blocks, <TAB> <TAB> <TAB> <TAB> channels, <TAB> <TAB> <TAB> <TAB> multi_scale_output=False, <TAB> <TAB> <TAB> <TAB> name=name + ""_"" + str(i + 1), <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> out = self.high_resolution_module( <TAB> <TAB> <TAB> <TAB> out, num_blocks, channels, name=name + ""_"" + str(i + 1) <TAB> <TAB> <TAB> ) <TAB> return out",false,if i == num_modules - 1 and multi_scale_output == False :,if multi_scale_output :,0.01,0.0
"def changeFrontAlteration(intV, alter): <TAB> # fati = front alteration transpose interval <TAB> fati = self.frontAlterationTransposeInterval <TAB> if fati: <TAB> <TAB> newFati = interval.add([fati, intV]) <TAB> <TAB> self.frontAlterationTransposeInterval = newFati <TAB> <TAB> self.frontAlterationAccidental.alter = ( <TAB> <TAB> <TAB> self.frontAlterationAccidental.alter + alter <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.frontAlterationTransposeInterval = None <TAB> <TAB> <TAB> self.frontAlterationAccidental = None <TAB> else: <TAB> <TAB> self.frontAlterationTransposeInterval = intV <TAB> <TAB> self.frontAlterationAccidental = pitch.Accidental(alter)",false,if self . frontAlterationAccidental . alter == 0 :,if self . frontAlterationTransposeInterval == intV :,0.12,0.0
"def set_to_train(self): <TAB> for T in self.trainable_attributes(): <TAB> <TAB> for k, v in T.items(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> c_f.set_requires_grad(v, requires_grad=False) <TAB> <TAB> <TAB> <TAB> v.eval() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> v.train() <TAB> self.maybe_freeze_trunk_batchnorm()",false,if k in self . freeze_these :,if k in self . requires_grad :,0.57,0.0
"def _migrate(self, sig=None, compact=True): <TAB> with self.lock: <TAB> <TAB> sig = sig or self.sig <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> if sig in self.WORDS and len(self.WORDS[sig]) > 0: <TAB> <TAB> <TAB> PostingList.Append( <TAB> <TAB> <TAB> <TAB> self.session, sig, self.WORDS[sig], sig=sig, compact=compact <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> del self.WORDS[sig]",false,if sig in GPL_NEVER_MIGRATE :,if sig is None :,0.31,0.0
"def on_prediction_step(self, args, state, control, eval_dataloader=None, **kwargs): <TAB> if self.prediction_bar is None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.prediction_bar = self.training_tracker.add_child(len(eval_dataloader)) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.prediction_bar = NotebookProgressBar(len(eval_dataloader)) <TAB> <TAB> self.prediction_bar.update(1) <TAB> else: <TAB> <TAB> self.prediction_bar.update(self.prediction_bar.value + 1)",true,if self . training_tracker is not None :,if self . training_tracker is not None :,0.75,0.0
"def show(self, indent=0): <TAB> """"""Pretty print this structure."""""" <TAB> if indent == 0: <TAB> <TAB> print(""struct {}"".format(self.name)) <TAB> for field in self.fields: <TAB> <TAB> if field.offset is None: <TAB> <TAB> <TAB> offset = ""0x??"" <TAB> <TAB> else: <TAB> <TAB> <TAB> offset = ""0x{:02x}"".format(field.offset) <TAB> <TAB> print(""{}+{} {} {}"".format("" "" * indent, offset, field.name, field.type)) <TAB> <TAB> if isinstance(field.type, Structure): <TAB> <TAB> <TAB> field.type.show(indent + 1)",true,"if isinstance ( field . type , Structure ) :","if isinstance ( field . type , Structure ) :",0.75,0.0
"def __exit__(self, exc, value, tb): <TAB> for key in self.overrides.keys(): <TAB> <TAB> old_value = self.old[key] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> delattr(self.instance, key) <TAB> <TAB> else: <TAB> <TAB> <TAB> setattr(self.instance, key, old_value) <TAB> self.instance.save()",false,if old_value is NULL :,if old_value is None :,0.39,0.0
"def complete(self, block): <TAB> with self._condition: <TAB> <TAB> if not self._final: <TAB> <TAB> <TAB> return False <TAB> <TAB> if self._complete(): <TAB> <TAB> <TAB> self._calculate_state_root_if_not_already_done() <TAB> <TAB> <TAB> return True <TAB> <TAB> if block: <TAB> <TAB> <TAB> self._condition.wait_for(self._complete) <TAB> <TAB> <TAB> self._calculate_state_root_if_not_already_done() <TAB> <TAB> <TAB> return True <TAB> <TAB> return False",false,if not self . _final :,if self . _complete ( ) :,0.05,0.0
"def parseArguments(self): <TAB> args = [] <TAB> self.expect(""("") <TAB> if not self.match("")""): <TAB> <TAB> while self.startIndex < self.length: <TAB> <TAB> <TAB> args.append(self.isolateCoverGrammar(self.parseAssignmentExpression)) <TAB> <TAB> <TAB> if self.match("")""): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> self.expectCommaSeparator() <TAB> self.expect("")"") <TAB> return args",true,"if self . match ( "")"" ) :","if self . match ( "")"" ) :",0.75,0.0
"def isValidDateString(config_param_name, value, valid_value): <TAB> try: <TAB> <TAB> if value == ""DD-MM-YYYY"": <TAB> <TAB> <TAB> return value <TAB> <TAB> day, month, year = value.split(""-"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise DateStringValueError(config_param_name, value) <TAB> <TAB> if int(month) < 1 or int(month) > 12: <TAB> <TAB> <TAB> raise DateStringValueError(config_param_name, value) <TAB> <TAB> if int(year) < 1900 or int(year) > 2013: <TAB> <TAB> <TAB> raise DateStringValueError(config_param_name, value) <TAB> <TAB> return value <TAB> except Exception: <TAB> <TAB> raise DateStringValueError(config_param_name, value)",false,if int ( day ) < 1 or int ( day ) > 31 :,if day != valid_value :,0.01,0.0
"def build_tree(path): <TAB> tree = Tree() <TAB> for basename, entry in trees[path].items(): <TAB> <TAB> if isinstance(entry, dict): <TAB> <TAB> <TAB> mode = stat.S_IFDIR <TAB> <TAB> <TAB> sha = build_tree(pathjoin(path, basename)) <TAB> <TAB> else: <TAB> <TAB> <TAB> (mode, sha) = entry <TAB> <TAB> tree.add(basename, mode, sha) <TAB> object_store.add_object(tree) <TAB> return tree.id",true,"if isinstance ( entry , dict ) :","if isinstance ( entry , dict ) :",0.75,0.0
"def get_quarantine_count(self): <TAB> """"""get obj/container/account quarantine counts"""""" <TAB> qcounts = {""objects"": 0, ""containers"": 0, ""accounts"": 0} <TAB> qdir = ""quarantined"" <TAB> for device in os.listdir(self.devices): <TAB> <TAB> for qtype in qcounts: <TAB> <TAB> <TAB> qtgt = os.path.join(self.devices, device, qdir, qtype) <TAB> <TAB> <TAB> if os.path.exists(qtgt): <TAB> <TAB> <TAB> <TAB> linkcount = os.lstat(qtgt).st_nlink <TAB> <TAB> <TAB> <TAB> if linkcount > 2: <TAB> <TAB> <TAB> <TAB> <TAB> qcounts[qtype] += linkcount - 2 <TAB> return qcounts",true,if os . path . exists ( qtgt ) :,if os . path . exists ( qtgt ) :,0.75,0.0
"def _is_static_shape(self, shape): <TAB> if shape is None or not isinstance(shape, list): <TAB> <TAB> return False <TAB> for dim_value in shape: <TAB> <TAB> if not isinstance(dim_value, int): <TAB> <TAB> <TAB> return False <TAB> <TAB> if dim_value < 0: <TAB> <TAB> <TAB> raise Exception(""Negative dimension is illegal: %d"" % dim_value) <TAB> return True",true,"if not isinstance ( dim_value , int ) :","if not isinstance ( dim_value , int ) :",0.75,0.0
"def BraceDetectAll(words): <TAB> # type: (List[compound_word]) -> List[word_t] <TAB> """"""Return a new list of words, possibly with BracedTree instances."""""" <TAB> out = []  # type: List[word_t] <TAB> for w in words: <TAB> <TAB> # The shortest possible brace expansion is {,}.  This heuristic prevents <TAB> <TAB> # a lot of garbage from being created, since otherwise nearly every word <TAB> <TAB> # would be checked.  We could be even more precise but this is cheap. <TAB> <TAB> if len(w.parts) >= 3: <TAB> <TAB> <TAB> brace_tree = _BraceDetect(w) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> out.append(brace_tree) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> out.append(w) <TAB> return out",true,if brace_tree :,if brace_tree :,0.53,0.0
"def __init__(original, self, *args, **kwargs): <TAB> data = args[0] if len(args) > 0 else kwargs.get(""data"") <TAB> if data is not None: <TAB> <TAB> try: <TAB> <TAB> <TAB> if isinstance(data, str): <TAB> <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> <TAB> ""cannot gather example input when dataset is loaded from a file."" <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> input_example_info = _InputExampleInfo( <TAB> <TAB> <TAB> <TAB> input_example=deepcopy(data[:INPUT_EXAMPLE_SAMPLE_ROWS]) <TAB> <TAB> <TAB> ) <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> input_example_info = _InputExampleInfo(error_msg=str(e)) <TAB> <TAB> setattr(self, ""input_example_info"", input_example_info) <TAB> original(self, *args, **kwargs)",true,"if isinstance ( data , str ) :","if isinstance ( data , str ) :",0.75,0.0
"def setRow(self, row, vals): <TAB> if row > self.rowCount() - 1: <TAB> <TAB> self.setRowCount(row + 1) <TAB> for col in range(len(vals)): <TAB> <TAB> val = vals[col] <TAB> <TAB> item = self.itemClass(val, row) <TAB> <TAB> item.setEditable(self.editable) <TAB> <TAB> sortMode = self.sortModes.get(col, None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> item.setSortMode(sortMode) <TAB> <TAB> format = self._formats.get(col, self._formats[None]) <TAB> <TAB> item.setFormat(format) <TAB> <TAB> self.items.append(item) <TAB> <TAB> self.setItem(row, col, item) <TAB> <TAB> item.setValue(val)  # Required--the text-change callback is invoked",false,if sortMode is not None :,if sortMode :,0.05,0.0
"def wakeUp(self): <TAB> """"""Write one byte to the pipe, and flush it."""""" <TAB> # We don't use fdesc.writeToFD since we need to distinguish <TAB> # between EINTR (try again) and EAGAIN (do nothing). <TAB> if self.o is not None: <TAB> <TAB> try: <TAB> <TAB> <TAB> util.untilConcludes(os.write, self.o, b""x"") <TAB> <TAB> except OSError as e: <TAB> <TAB> <TAB> # XXX There is no unit test for raising the exception <TAB> <TAB> <TAB> # for other errnos. See #4285. <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise",false,if e . errno != errno . EAGAIN :,if e . errno != errno . EINTR :,0.88,0.0
"def _setup(self, field_name, owner_model): <TAB> # Resolve possible name-based model references. <TAB> resolved_classes = [] <TAB> for m in self.model_classes: <TAB> <TAB> if isinstance(m, string_type): <TAB> <TAB> <TAB> if m == owner_model.__name__: <TAB> <TAB> <TAB> <TAB> resolved_classes.append(owner_model) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> <TAB> ""PolyModelType: Unable to resolve model '{}'."".format(m) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> resolved_classes.append(m) <TAB> self.model_classes = tuple(resolved_classes) <TAB> super(PolyModelType, self)._setup(field_name, owner_model)",true,"if isinstance ( m , string_type ) :","if isinstance ( m , string_type ) :",0.75,0.0
"def _wrap_forwarded(self, key, value): <TAB> if isinstance(value, SourceCode) and value.late_binding: <TAB> <TAB> # get cached return value if present <TAB> <TAB> value_ = self._late_binding_returnvalues.get(key, KeyError) <TAB> <TAB> if value_ is KeyError: <TAB> <TAB> <TAB> # evaluate the late-bound function <TAB> <TAB> <TAB> value_ = self._eval_late_binding(value) <TAB> <TAB> <TAB> schema = self.late_bind_schemas.get(key) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> value_ = schema.validate(value_) <TAB> <TAB> <TAB> # cache result of late bound func <TAB> <TAB> <TAB> self._late_binding_returnvalues[key] = value_ <TAB> <TAB> return value_ <TAB> else: <TAB> <TAB> return value",false,if schema is not None :,if schema :,0.05,0.0
"def convert(self, ctx, argument): <TAB> arg = argument.replace(""0x"", """").lower() <TAB> if arg[0] == ""#"": <TAB> <TAB> arg = arg[1:] <TAB> try: <TAB> <TAB> value = int(arg, base=16) <TAB> <TAB> if not (0 <= value <= 0xFFFFFF): <TAB> <TAB> <TAB> raise BadColourArgument(arg) <TAB> <TAB> return discord.Colour(value=value) <TAB> except ValueError: <TAB> <TAB> arg = arg.replace("" "", ""_"") <TAB> <TAB> method = getattr(discord.Colour, arg, None) <TAB> <TAB> if arg.startswith(""from_"") or method is None or not inspect.ismethod(method): <TAB> <TAB> <TAB> raise BadColourArgument(arg) <TAB> <TAB> return method()",false,if not ( 0 <= value <= 0xFFFFFF ) :,"if arg . startswith ( ""from_"" ) or method is None or not inspect . ismethod ( method ) :",0.02,0.0
"def get_versions(*, all=False, quiet=None): <TAB> import bonobo <TAB> from bonobo.util.pkgs import bonobo_packages <TAB> yield _format_version(bonobo, quiet=quiet) <TAB> if all: <TAB> <TAB> for name in sorted(bonobo_packages): <TAB> <TAB> <TAB> if name != ""bonobo"": <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> mod = __import__(name.replace(""-"", ""_"")) <TAB> <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield _format_version(mod, name=name, quiet=quiet) <TAB> <TAB> <TAB> <TAB> <TAB> except Exception as exc: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield ""{} ({})"".format(name, exc) <TAB> <TAB> <TAB> <TAB> except ImportError as exc: <TAB> <TAB> <TAB> <TAB> <TAB> yield ""{} is not importable ({})."".format(name, exc)",true,"if name != ""bonobo"" :","if name != ""bonobo"" :",0.75,0.0
"def assertOperationsInjected(self, plan, **kwargs): <TAB> for migration, _backward in plan: <TAB> <TAB> operations = iter(migration.operations) <TAB> <TAB> for operation in operations: <TAB> <TAB> <TAB> if isinstance(operation, migrations.RenameModel): <TAB> <TAB> <TAB> <TAB> next_operation = next(operations) <TAB> <TAB> <TAB> <TAB> self.assertIsInstance( <TAB> <TAB> <TAB> <TAB> <TAB> next_operation, contenttypes_management.RenameContentType <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> self.assertEqual(next_operation.app_label, migration.app_label) <TAB> <TAB> <TAB> <TAB> self.assertEqual(next_operation.old_model, operation.old_name_lower) <TAB> <TAB> <TAB> <TAB> self.assertEqual(next_operation.new_model, operation.new_name_lower)",true,"if isinstance ( operation , migrations . RenameModel ) :","if isinstance ( operation , migrations . RenameModel ) :",0.75,0.0
"def valid_localparts(strip_delimiters=False): <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS.split(""\n""): <TAB> <TAB> # strip line, skip over empty lines <TAB> <TAB> line = line.strip() <TAB> <TAB> if line == """": <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over comments or empty lines <TAB> <TAB> match = COMMENT.match(line) <TAB> <TAB> if match: <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over localparts with delimiters <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if "","" in line or "";"" in line: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield line",true,if strip_delimiters :,if strip_delimiters :,0.53,0.0
"def read_lccn(line, is_marc8=False): <TAB> found = [] <TAB> for k, v in get_raw_subfields(line, [""a""]): <TAB> <TAB> lccn = v.strip() <TAB> <TAB> if re_question.match(lccn): <TAB> <TAB> <TAB> continue <TAB> <TAB> m = re_lccn.search(lccn) <TAB> <TAB> if not m: <TAB> <TAB> <TAB> continue <TAB> <TAB> # remove letters and bad chars <TAB> <TAB> lccn = re_letters_and_bad.sub("""", m.group(1)).strip() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> found.append(lccn) <TAB> return found",false,if lccn :,if lccn not in found :,0.09,0.0
"def test_named_parameters_and_constraints(self): <TAB> likelihood = gpytorch.likelihoods.GaussianLikelihood() <TAB> model = ExactGPModel(None, None, likelihood) <TAB> for name, _param, constraint in model.named_parameters_and_constraints(): <TAB> <TAB> if name == ""likelihood.noise_covar.raw_noise"": <TAB> <TAB> <TAB> self.assertIsInstance(constraint, gpytorch.constraints.GreaterThan) <TAB> <TAB> elif name == ""mean_module.constant"": <TAB> <TAB> <TAB> self.assertIsNone(constraint) <TAB> <TAB> elif name == ""covar_module.raw_outputscale"": <TAB> <TAB> <TAB> self.assertIsInstance(constraint, gpytorch.constraints.Positive) <TAB> <TAB> elif name == ""covar_module.base_kernel.raw_lengthscale"": <TAB> <TAB> <TAB> self.assertIsInstance(constraint, gpytorch.constraints.Positive)",true,"elif name == ""covar_module.base_kernel.raw_lengthscale"" :","elif name == ""covar_module.base_kernel.raw_lengthscale"" :",1.0,0.0
"def _cleanupSocket(self): <TAB> """"""Close the Connection's socket."""""" <TAB> try: <TAB> <TAB> self._sock.shutdown(socket.SHUT_WR) <TAB> except: <TAB> <TAB> return <TAB> try: <TAB> <TAB> while True: <TAB> <TAB> <TAB> r, w, e = select.select([self._sock], [], []) <TAB> <TAB> <TAB> if not r or not self._sock.recv(1024): <TAB> <TAB> <TAB> <TAB> break <TAB> except: <TAB> <TAB> pass <TAB> self._sock.close()",true,if not r or not self . _sock . recv ( 1024 ) :,if not r or not self . _sock . recv ( 1024 ) :,0.75,0.0
"def fadeIn(self, acts=None, t=None, duration=None): <TAB> """"""Gradually switch on the input list of meshes by increasing opacity."""""" <TAB> if self.bookingMode: <TAB> <TAB> acts, t, duration, rng = self._parse(acts, t, duration) <TAB> <TAB> for tt in rng: <TAB> <TAB> <TAB> alpha = linInterpolate(tt, [t, t + duration], [0, 1]) <TAB> <TAB> <TAB> self.events.append((tt, self.fadeIn, acts, alpha)) <TAB> else: <TAB> <TAB> for a in self._performers: <TAB> <TAB> <TAB> if a.alpha() >= self._inputvalues: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> a.alpha(self._inputvalues) <TAB> return self",true,if a . alpha ( ) >= self . _inputvalues :,if a . alpha ( ) >= self . _inputvalues :,0.75,0.0
"def get_config_updates_recursive(self): <TAB> config_updates = self.config_updates.copy() <TAB> for sr_path, subrunner in self.subrunners.items(): <TAB> <TAB> if not is_prefix(self.path, sr_path): <TAB> <TAB> <TAB> continue <TAB> <TAB> update = subrunner.get_config_updates_recursive() <TAB> <TAB> if update: <TAB> <TAB> <TAB> config_updates[rel_path(self.path, sr_path)] = update <TAB> return config_updates",true,"if not is_prefix ( self . path , sr_path ) :","if not is_prefix ( self . path , sr_path ) :",0.75,0.0
"def setArgs(self, **kwargs): <TAB> """"""See GridSearchCostGamma"""""" <TAB> for key, value in list(kwargs.items()): <TAB> <TAB> if key in (""folds"", ""nfolds""): <TAB> <TAB> <TAB> self._n_folds = int(value) <TAB> <TAB> elif key in (""max_epochs""): <TAB> <TAB> <TAB> self._validator_kwargs[""max_epochs""] = value <TAB> <TAB> else: <TAB> <TAB> <TAB> GridSearchDOE.setArgs(self, **{key: value})",false,"elif key in ( ""max_epochs"" ) :","if key in ( ""folds"" , ""nfolds"" ) :",0.09,0.0
"def _parse_composite_axis(composite_axis_name: str): <TAB> axes_names = [axis for axis in composite_axis_name.split("" "") if len(axis) > 0] <TAB> for axis in axes_names: <TAB> <TAB> if axis == ""_"": <TAB> <TAB> <TAB> continue <TAB> <TAB> assert ""a"" <= axis[0] <= ""z"" <TAB> <TAB> for letter in axis: <TAB> <TAB> <TAB> assert str.isdigit(letter) or ""a"" <= letter <= ""z"" <TAB> return axes_names",true,"if axis == ""_"" :","if axis == ""_"" :",0.75,0.0
"def visit_For(self, node, for_branch=""body"", **kwargs): <TAB> if for_branch == ""body"": <TAB> <TAB> self.sym_visitor.visit(node.target, store_as_param=True) <TAB> <TAB> branch = node.body <TAB> elif for_branch == ""else"": <TAB> <TAB> branch = node.else_ <TAB> elif for_branch == ""test"": <TAB> <TAB> self.sym_visitor.visit(node.target, store_as_param=True) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.sym_visitor.visit(node.test) <TAB> <TAB> return <TAB> else: <TAB> <TAB> raise RuntimeError(""Unknown for branch"") <TAB> for item in branch or (): <TAB> <TAB> self.sym_visitor.visit(item)",false,if node . test is not None :,if node . test :,0.23,0.0
def contains_only_whitespace(node): <TAB> if is_tag(node): <TAB> <TAB> if not any([not is_text(s) for s in node.contents]): <TAB> <TAB> <TAB> if not any([unicode(s).strip() for s in node.contents]): <TAB> <TAB> <TAB> <TAB> return True <TAB> return False,false,if not any ( [ not is_text ( s ) for s in node . contents ] ) :,if not any ( [ unicode ( s ) . strip ( ) for s in node . contents ] ) :,0.38,0.0
"def dir_tag_click(event): <TAB> mouse_index = self.path_bar.index(""@%d,%d"" % (event.x, event.y)) <TAB> lineno = int(float(mouse_index)) <TAB> if lineno == 1: <TAB> <TAB> self.request_focus_into("""") <TAB> else: <TAB> <TAB> assert lineno == 2 <TAB> <TAB> dir_range = get_dir_range(event) <TAB> <TAB> if dir_range: <TAB> <TAB> <TAB> _, end_index = dir_range <TAB> <TAB> <TAB> path = self.path_bar.get(""2.0"", end_index) <TAB> <TAB> <TAB> if path.endswith("":""): <TAB> <TAB> <TAB> <TAB> path += ""\\"" <TAB> <TAB> <TAB> self.request_focus_into(path)",true,"if path . endswith ( "":"" ) :","if path . endswith ( "":"" ) :",0.75,0.0
"def validate_employee_id(self): <TAB> if self.employee: <TAB> <TAB> sales_person = frappe.db.get_value(""Sales Person"", {""employee"": self.employee}) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> frappe.throw( <TAB> <TAB> <TAB> <TAB> _(""Another Sales Person {0} exists with the same Employee id"").format( <TAB> <TAB> <TAB> <TAB> <TAB> sales_person <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> )",false,if sales_person and sales_person != self . name :,if sales_person :,0.02,0.0
"def pytest_collection_modifyitems(items): <TAB> for item in items: <TAB> <TAB> if item.nodeid.startswith(""tests/infer""): <TAB> <TAB> <TAB> if ""stage"" not in item.keywords: <TAB> <TAB> <TAB> <TAB> item.add_marker(pytest.mark.stage(""unit"")) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> item.add_marker(pytest.mark.init(rng_seed=123))",true,"if ""init"" not in item . keywords :","if ""init"" not in item . keywords :",0.75,0.0
"def poll(self, timeout): <TAB> if timeout < 0: <TAB> <TAB> timeout = None  # kqueue behaviour <TAB> events = self._kqueue.control(None, KqueueLoop.MAX_EVENTS, timeout) <TAB> results = defaultdict(lambda: POLL_NULL) <TAB> for e in events: <TAB> <TAB> fd = e.ident <TAB> <TAB> if e.filter == select.KQ_FILTER_READ: <TAB> <TAB> <TAB> results[fd] |= POLL_IN <TAB> <TAB> elif e.filter == select.KQ_FILTER_WRITE: <TAB> <TAB> <TAB> results[fd] |= POLL_OUT <TAB> return results.items()",true,elif e . filter == select . KQ_FILTER_WRITE :,elif e . filter == select . KQ_FILTER_WRITE :,0.75,0.0
"def _read_dimensions(self, *dimnames, **kwargs): <TAB> path = kwargs.get(""path"", ""/"") <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return [self.rootgrp.dimensions[dname] for dname in dimnames] <TAB> <TAB> group = self.path2group[path] <TAB> <TAB> return [group.dimensions[dname] for dname in dimnames] <TAB> except KeyError: <TAB> <TAB> raise self.Error( <TAB> <TAB> <TAB> ""In file %s:\nError while reading dimensions: `%s` with kwargs: `%s`"" <TAB> <TAB> <TAB> % (self.path, dimnames, kwargs) <TAB> <TAB> )",false,"if path == ""/"" :",if path in self . rootgrp :,0.05,0.0
"def spam_to_me(address): <TAB> sock = eventlet.connect(address) <TAB> while True: <TAB> <TAB> try: <TAB> <TAB> <TAB> sock.sendall(b""hello world"") <TAB> <TAB> <TAB> # Arbitrary delay to not use all available CPU, keeps the test <TAB> <TAB> <TAB> # running quickly and reliably under a second <TAB> <TAB> <TAB> time.sleep(0.001) <TAB> <TAB> except socket.error as e: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> raise",false,if get_errno ( e ) == errno . EPIPE :,if e . args [ 0 ] == errno . EINTR :,0.11,0.0
"def has_hash_of(self, destpath, code, package_level): <TAB> """"""Determine if a file has the hash of the code."""""" <TAB> if destpath is not None and os.path.isfile(destpath): <TAB> <TAB> with univ_open(destpath, ""r"") as opened: <TAB> <TAB> <TAB> compiled = readfile(opened) <TAB> <TAB> hashash = gethash(compiled) <TAB> <TAB> if hashash is not None and hashash == self.comp.genhash(code, package_level): <TAB> <TAB> <TAB> return True <TAB> return False",true,"if hashash is not None and hashash == self . comp . genhash ( code , package_level ) :","if hashash is not None and hashash == self . comp . genhash ( code , package_level ) :",1.0,0.0
"def insert(self, index, item): <TAB> if len(self.lists) == 1: <TAB> <TAB> self.lists[0].insert(index, item) <TAB> <TAB> self._balance_list(0) <TAB> else: <TAB> <TAB> list_idx, rel_idx = self._translate_index(index) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise IndexError() <TAB> <TAB> self.lists[list_idx].insert(rel_idx, item) <TAB> <TAB> self._balance_list(list_idx) <TAB> return",false,if list_idx is None :,if list_idx == - 1 :,0.06,0.0
"def _parse_class_simplified(symbol): <TAB> results = {} <TAB> name = symbol.name + ""("" <TAB> name += "", "".join([analyzer.expand_attribute(base) for base in symbol.bases]) <TAB> name += "")"" <TAB> for sym in symbol.body: <TAB> <TAB> if isinstance(sym, ast.FunctionDef): <TAB> <TAB> <TAB> result = _parse_function_simplified(sym, symbol.name) <TAB> <TAB> <TAB> results.update(result) <TAB> <TAB> elif isinstance(sym, ast.ClassDef): <TAB> <TAB> <TAB> result = _parse_class_simplified(sym) <TAB> <TAB> <TAB> results.update(result) <TAB> lineno = symbol.lineno <TAB> for decorator in symbol.decorator_list: <TAB> <TAB> lineno += 1 <TAB> results[lineno] = (name, ""c"") <TAB> return results",true,"elif isinstance ( sym , ast . ClassDef ) :","elif isinstance ( sym , ast . ClassDef ) :",0.75,0.0
"def append_vars(pairs, result): <TAB> for name, value in sorted(pairs.items()): <TAB> <TAB> if isinstance(value, list): <TAB> <TAB> <TAB> value = ""[%s]"" % "","".join(value) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result.append(""%s:%s=%s"" % (package, name, value)) <TAB> <TAB> else: <TAB> <TAB> <TAB> result.append(""%s=%s"" % (name, value))",true,if package :,if package :,0.53,0.0
"def nextEditable(self): <TAB> """"""Moves focus of the cursor to the next editable window"""""" <TAB> if self.currentEditable is None: <TAB> <TAB> if len(self._editableChildren): <TAB> <TAB> <TAB> self._currentEditableRef = self._editableChildren[0] <TAB> else: <TAB> <TAB> for ref in weakref.getweakrefs(self.currentEditable): <TAB> <TAB> <TAB> if ref in self._editableChildren: <TAB> <TAB> <TAB> <TAB> cei = self._editableChildren.index(ref) <TAB> <TAB> <TAB> <TAB> nei = cei + 1 <TAB> <TAB> <TAB> <TAB> if nei >= len(self._editableChildren): <TAB> <TAB> <TAB> <TAB> <TAB> nei = 0 <TAB> <TAB> <TAB> <TAB> self._currentEditableRef = self._editableChildren[nei] <TAB> return self.currentEditable",false,if len ( self . _editableChildren ) :,if ref in self . _editableChildren :,0.08,0.0
"def everythingIsUnicode(d): <TAB> """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB> for k, v in d.iteritems(): <TAB> <TAB> if isinstance(v, dict) and k != ""headers"": <TAB> <TAB> <TAB> if not everythingIsUnicode(v): <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance(v, list): <TAB> <TAB> <TAB> for i in v: <TAB> <TAB> <TAB> <TAB> if isinstance(i, dict) and not everythingIsUnicode(i): <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <TAB> elif isinstance(i, _bytes): <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance(v, _bytes): <TAB> <TAB> <TAB> return False <TAB> return True",false,"elif isinstance ( v , _bytes ) :","if isinstance ( v , dict ) and k != ""headers"" :",0.15,0.0
"def is_valid(sample): <TAB> if sample is None: <TAB> <TAB> return False <TAB> if isinstance(sample, tuple): <TAB> <TAB> for s in sample: <TAB> <TAB> <TAB> if s is None: <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> elif isinstance(s, np.ndarray) and s.size == 0: <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> elif isinstance(s, collections.abc.Sequence) and len(s) == 0: <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",false,"elif isinstance ( s , np . ndarray ) and s . size == 0 :","elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 :",0.29,0.0
"def scan_resource_conf(self, conf): <TAB> if ""properties"" in conf: <TAB> <TAB> if ""attributes"" in conf[""properties""]: <TAB> <TAB> <TAB> if ""exp"" in conf[""properties""][""attributes""]: <TAB> <TAB> <TAB> <TAB> if conf[""properties""][""attributes""][""exp""]: <TAB> <TAB> <TAB> <TAB> <TAB> return CheckResult.PASSED <TAB> return CheckResult.FAILED",false,"if conf [ ""properties"" ] [ ""attributes"" ] [ ""exp"" ] :","if ""exp"" in conf [ ""properties"" ] [ ""attributes"" ] :",0.3,0.0
"def encode(self): <TAB> if self.expr in gpregs.expr: <TAB> <TAB> self.value = gpregs.expr.index(self.expr) <TAB> <TAB> self.parent.rot2.value = 0 <TAB> elif isinstance(self.expr, ExprOp) and self.expr.op == allshifts[3]: <TAB> <TAB> reg, value = self.expr.args <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> self.value = gpregs.expr.index(reg) <TAB> <TAB> if not isinstance(value, ExprInt): <TAB> <TAB> <TAB> return False <TAB> <TAB> value = int(value) <TAB> <TAB> if not value in [8, 16, 24]: <TAB> <TAB> <TAB> return False <TAB> <TAB> self.parent.rot2.value = value // 8 <TAB> return True",true,if reg not in gpregs . expr :,if reg not in gpregs . expr :,0.75,0.0
"def validate_transaction_reference(self): <TAB> bank_account = self.paid_to if self.payment_type == ""Receive"" else self.paid_from <TAB> bank_account_type = frappe.db.get_value(""Account"", bank_account, ""account_type"") <TAB> if bank_account_type == ""Bank"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> frappe.throw( <TAB> <TAB> <TAB> <TAB> _(""Reference No and Reference Date is mandatory for Bank transaction"") <TAB> <TAB> <TAB> )",false,if not self . reference_no or not self . reference_date :,if not self . reference_date :,0.26,0.0
"def monad(self): <TAB> if not self.cls_bl_idname: <TAB> <TAB> return None <TAB> for monad in bpy.data.node_groups: <TAB> <TAB> if hasattr(monad, ""cls_bl_idname""): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return monad <TAB> return None",true,if monad . cls_bl_idname == self . cls_bl_idname :,if monad . cls_bl_idname == self . cls_bl_idname :,1.0,0.0
"def _create_mask(self, plen): <TAB> mask = [] <TAB> for i in range(16): <TAB> <TAB> if plen >= 8: <TAB> <TAB> <TAB> mask.append(0xFF) <TAB> <TAB> elif plen > 0: <TAB> <TAB> <TAB> mask.append(0xFF >> (8 - plen) << (8 - plen)) <TAB> <TAB> else: <TAB> <TAB> <TAB> mask.append(0x00) <TAB> <TAB> plen -= 8 <TAB> return mask",true,elif plen > 0 :,elif plen > 0 :,0.75,0.0
"def dataset_to_stream(dataset, input_name): <TAB> """"""Takes a tf.Dataset and creates a numpy stream of ready batches."""""" <TAB> # All input-pipeline processing should be on CPU. <TAB> for example in fastmath.dataset_as_numpy(dataset): <TAB> <TAB> features = example[0] <TAB> <TAB> inp, out = features[input_name], example[1] <TAB> <TAB> mask = features[""mask""] if ""mask"" in features else None <TAB> <TAB> # Some accelerators don't handle uint8 well, cast to int. <TAB> <TAB> if isinstance(inp, np.uint8): <TAB> <TAB> <TAB> inp = inp.astype(np.int32) <TAB> <TAB> if isinstance(out, np.uint8): <TAB> <TAB> <TAB> out = out.astype(np.int32) <TAB> <TAB> yield (inp, out) if mask is None else (inp, out, mask)",false,"if isinstance ( inp , np . uint8 ) :","if isinstance ( out , np . uint8 ) :",0.58,0.0
"def _idle_redraw_cb(self): <TAB> assert self._idle_redraw_src_id is not None <TAB> queue = self._idle_redraw_queue <TAB> if len(queue) > 0: <TAB> <TAB> bbox = queue.pop(0) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> super(CanvasRenderer, self).queue_draw() <TAB> <TAB> else: <TAB> <TAB> <TAB> super(CanvasRenderer, self).queue_draw_area(*bbox) <TAB> if len(queue) == 0: <TAB> <TAB> self._idle_redraw_src_id = None <TAB> <TAB> return False <TAB> return True",true,if bbox is None :,if bbox is None :,0.75,0.0
"def mutated(self, indiv): <TAB> """"""mutate some genes of the given individual"""""" <TAB> res = indiv.copy() <TAB> # to avoid having a child identical to one of the currentpopulation''' <TAB> for i in range(self.numParameters): <TAB> <TAB> if random() < self.mutationProb: <TAB> <TAB> <TAB> if self.xBound is None: <TAB> <TAB> <TAB> <TAB> res[i] = indiv[i] + gauss(0, self.mutationStdDev) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> res[i] = max( <TAB> <TAB> <TAB> <TAB> <TAB> min(indiv[i] + gauss(0, self.mutationStdDev), self.maxs[i]), <TAB> <TAB> <TAB> <TAB> <TAB> self.mins[i], <TAB> <TAB> <TAB> <TAB> ) <TAB> return res",true,if random ( ) < self . mutationProb :,if random ( ) < self . mutationProb :,0.75,0.0
"def _justifyDrawParaLine(tx, offset, extraspace, words, last=0): <TAB> setXPos(tx, offset) <TAB> text = b"" "".join(words) <TAB> if last: <TAB> <TAB> # last one, left align <TAB> <TAB> tx._textOut(text, 1) <TAB> else: <TAB> <TAB> nSpaces = len(words) - 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tx.setWordSpace(extraspace / float(nSpaces)) <TAB> <TAB> <TAB> tx._textOut(text, 1) <TAB> <TAB> <TAB> tx.setWordSpace(0) <TAB> <TAB> else: <TAB> <TAB> <TAB> tx._textOut(text, 1) <TAB> setXPos(tx, -offset) <TAB> return offset",false,if nSpaces :,if nSpaces > 0 :,0.1,0.0
"def _read_0(self, stream): <TAB> r = b"""" <TAB> while True: <TAB> <TAB> c = stream.read(2) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise EOFError() <TAB> <TAB> if c == b""\x00\x00"": <TAB> <TAB> <TAB> break <TAB> <TAB> r += c <TAB> return r.decode(self.encoding)",false,if len ( c ) != 2 :,if not c :,0.02,0.0
"def run(self, app, editor, args): <TAB> line_nums = [] <TAB> for cursor in editor.cursors: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> line_nums.append(cursor.y) <TAB> <TAB> <TAB> data = editor.lines[cursor.y].get_data().upper() <TAB> <TAB> <TAB> editor.lines[cursor.y].set_data(data)",true,if cursor . y not in line_nums :,if cursor . y not in line_nums :,0.75,0.0
"def create_default_energy_point_rules(): <TAB> for rule in get_default_energy_point_rules(): <TAB> <TAB> # check if any rule for ref. doctype exists <TAB> <TAB> rule_exists = frappe.db.exists( <TAB> <TAB> <TAB> ""Energy Point Rule"", {""reference_doctype"": rule.get(""reference_doctype"")} <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> doc = frappe.get_doc(rule) <TAB> <TAB> doc.insert(ignore_permissions=True)",false,if rule_exists :,if not rule_exists :,0.11,0.0
"def __new__(cls, *nodes): <TAB> if not nodes: <TAB> <TAB> raise TypeError(""DisjunctionNode() requires at least one node"") <TAB> elif len(nodes) == 1: <TAB> <TAB> return nodes[0] <TAB> self = super(DisjunctionNode, cls).__new__(cls) <TAB> self.__nodes = [] <TAB> # TODO: Remove duplicates? <TAB> for node in nodes: <TAB> <TAB> if not isinstance(node, Node): <TAB> <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> <TAB> ""DisjunctionNode() expects Node instances as arguments;"" <TAB> <TAB> <TAB> <TAB> "" received a non-Node instance %r"" % node <TAB> <TAB> <TAB> ) <TAB> <TAB> if isinstance(node, DisjunctionNode): <TAB> <TAB> <TAB> self.__nodes.extend(node.__nodes) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.__nodes.append(node) <TAB> return self",true,"if isinstance ( node , DisjunctionNode ) :","if isinstance ( node , DisjunctionNode ) :",0.75,0.0
def dfs(v: str) -> Iterator[Set[str]]: <TAB> index[v] = len(stack) <TAB> stack.append(v) <TAB> boundaries.append(index[v]) <TAB> for w in edges[v]: <TAB> <TAB> if w not in index: <TAB> <TAB> <TAB> yield from dfs(w) <TAB> <TAB> elif w not in identified: <TAB> <TAB> <TAB> while index[w] < boundaries[-1]: <TAB> <TAB> <TAB> <TAB> boundaries.pop() <TAB> if boundaries[-1] == index[v]: <TAB> <TAB> boundaries.pop() <TAB> <TAB> scc = set(stack[index[v] :]) <TAB> <TAB> del stack[index[v] :] <TAB> <TAB> identified.update(scc) <TAB> <TAB> yield scc,true,elif w not in identified :,elif w not in identified :,0.75,0.0
"def unpack_item_obj(map_uuid_global_id, misp_obj): <TAB> obj_meta = get_object_metadata(misp_obj) <TAB> obj_id = None <TAB> io_content = None <TAB> for attribute in misp_obj.attributes: <TAB> <TAB> if attribute.object_relation == ""raw-data"": <TAB> <TAB> <TAB> obj_id = attribute.value  # # TODO: sanitize <TAB> <TAB> <TAB> io_content = attribute.data  # # TODO: check if type == io <TAB> if obj_id and io_content: <TAB> <TAB> res = Item.create_item(obj_id, obj_meta, io_content) <TAB> <TAB> map_uuid_global_id[misp_obj.uuid] = get_global_id(""item"", obj_id)",true,"if attribute . object_relation == ""raw-data"" :","if attribute . object_relation == ""raw-data"" :",0.75,0.0
"def parse(self, response): <TAB> soup = BeautifulSoup(response.content.decode(""utf-8"", ""ignore""), ""lxml"") <TAB> image_divs = soup.find_all(""div"", class_=""imgpt"") <TAB> pattern = re.compile(r""murl\"":\""(.*?)\.jpg"") <TAB> for div in image_divs: <TAB> <TAB> href_str = html_parser.HTMLParser().unescape(div.a[""m""]) <TAB> <TAB> match = pattern.search(href_str) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> name = match.group(1) if six.PY3 else match.group(1).encode(""utf-8"") <TAB> <TAB> <TAB> img_url = ""{}.jpg"".format(name) <TAB> <TAB> <TAB> yield dict(file_url=img_url)",true,if match :,if match :,0.53,0.0
"def filter_errors(self, errors: List[str]) -> List[str]: <TAB> real_errors: List[str] = list() <TAB> current_file = __file__ <TAB> current_path = os.path.split(current_file) <TAB> for line in errors: <TAB> <TAB> line = line.strip() <TAB> <TAB> if not line: <TAB> <TAB> <TAB> continue <TAB> <TAB> fn, lno, lvl, msg = self.parse_trace_line(line) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> _path = os.path.split(fn) <TAB> <TAB> <TAB> if _path[-1] != current_path[-1]: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> real_errors.append(line) <TAB> return real_errors",false,if fn is not None :,if fn :,0.05,0.0
"def decompileFormat1(self, reader, otFont): <TAB> self.classDefs = classDefs = [] <TAB> startGlyphID = reader.readUShort() <TAB> glyphCount = reader.readUShort() <TAB> for i in range(glyphCount): <TAB> <TAB> glyphName = otFont.getglyphName(startGlyphID + i) <TAB> <TAB> classValue = reader.readUShort() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> classDefs.append((glyphName, classValue))",true,if classValue :,if classValue :,0.53,0.0
"def compress(self, data_list): <TAB> if len(data_list) == 2: <TAB> <TAB> value, lookup_expr = data_list <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if lookup_expr not in EMPTY_VALUES: <TAB> <TAB> <TAB> <TAB> return Lookup(value=value, lookup_expr=lookup_expr) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise forms.ValidationError( <TAB> <TAB> <TAB> <TAB> <TAB> self.error_messages[""lookup_required""], code=""lookup_required"" <TAB> <TAB> <TAB> <TAB> ) <TAB> return None",true,if value not in EMPTY_VALUES :,if value not in EMPTY_VALUES :,0.75,0.0
"def open_compat(path, mode=""r""): <TAB> if mode in [""r"", ""rb""] and not os.path.exists(path): <TAB> <TAB> raise FileNotFoundError(u'The file ""%s"" could not be found' % path) <TAB> if sys.version_info >= (3,): <TAB> <TAB> encoding = ""utf-8"" <TAB> <TAB> errors = ""replace"" <TAB> <TAB> if mode in [""rb"", ""wb"", ""ab""]: <TAB> <TAB> <TAB> encoding = None <TAB> <TAB> <TAB> errors = None <TAB> <TAB> return open(path, mode, encoding=encoding, errors=errors) <TAB> else: <TAB> <TAB> return open(path, mode)",true,"if mode in [ ""rb"" , ""wb"" , ""ab"" ] :","if mode in [ ""rb"" , ""wb"" , ""ab"" ] :",0.75,0.0
"def filter_errors(self, errors: List[str]) -> List[str]: <TAB> real_errors: List[str] = list() <TAB> current_file = __file__ <TAB> current_path = os.path.split(current_file) <TAB> for line in errors: <TAB> <TAB> line = line.strip() <TAB> <TAB> if not line: <TAB> <TAB> <TAB> continue <TAB> <TAB> fn, lno, lvl, msg = self.parse_trace_line(line) <TAB> <TAB> if fn is not None: <TAB> <TAB> <TAB> _path = os.path.split(fn) <TAB> <TAB> <TAB> if _path[-1] != current_path[-1]: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> real_errors.append(line) <TAB> return real_errors",true,if _path [ - 1 ] != current_path [ - 1 ] :,if _path [ - 1 ] != current_path [ - 1 ] :,0.75,0.0
"def filter_by_level(record, level_per_module): <TAB> name = record[""name""] <TAB> level = 0 <TAB> if name in level_per_module: <TAB> <TAB> level = level_per_module[name] <TAB> elif name is not None: <TAB> <TAB> lookup = """" <TAB> <TAB> if """" in level_per_module: <TAB> <TAB> <TAB> level = level_per_module[""""] <TAB> <TAB> for n in name.split("".""): <TAB> <TAB> <TAB> lookup += n <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> level = level_per_module[lookup] <TAB> <TAB> <TAB> lookup += ""."" <TAB> if level is False: <TAB> <TAB> return False <TAB> return record[""level""].no >= level",true,if lookup in level_per_module :,if lookup in level_per_module :,0.75,0.0
"def CountButtons(self): <TAB> """"""Returns the number of visible buttons in the docked pane."""""" <TAB> n = 0 <TAB> if self.HasCaption() or self.HasCaptionLeft(): <TAB> <TAB> if isinstance(wx.GetTopLevelParent(self.window), AuiFloatingFrame): <TAB> <TAB> <TAB> return 1 <TAB> <TAB> if self.HasCloseButton(): <TAB> <TAB> <TAB> n += 1 <TAB> <TAB> if self.HasMaximizeButton(): <TAB> <TAB> <TAB> n += 1 <TAB> <TAB> if self.HasMinimizeButton(): <TAB> <TAB> <TAB> n += 1 <TAB> <TAB> if self.HasPinButton(): <TAB> <TAB> <TAB> n += 1 <TAB> return n",false,if self . HasMaximizeButton ( ) :,if self . HasCloseButton ( ) :,0.39,0.0
"def search(a, b, desired): <TAB> if a == b: <TAB> <TAB> return a <TAB> if abs(b - a) < 0.005: <TAB> <TAB> ca = count(a) <TAB> <TAB> cb = count(b) <TAB> <TAB> dista = abs(desired - ca) <TAB> <TAB> distb = abs(desired - cb) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return a <TAB> <TAB> else: <TAB> <TAB> <TAB> return b <TAB> m = (a + b) / 2.0 <TAB> cm = count(m) <TAB> if desired < cm: <TAB> <TAB> return search(m, b, desired) <TAB> else: <TAB> <TAB> return search(a, m, desired)",true,if dista < distb :,if dista < distb :,0.75,0.0
"def force_ipv4(self, *args): <TAB> """"""only ipv4 localhost in /etc/hosts"""""" <TAB> logg.debug(""checking /etc/hosts for '::1 localhost'"") <TAB> lines = [] <TAB> for line in open(self.etc_hosts()): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> newline = re.sub(""\\slocalhost\\s"", "" "", line) <TAB> <TAB> <TAB> if line != newline: <TAB> <TAB> <TAB> <TAB> logg.info(""/etc/hosts: '%s' => '%s'"", line.rstrip(), newline.rstrip()) <TAB> <TAB> <TAB> <TAB> line = newline <TAB> <TAB> lines.append(line) <TAB> f = open(self.etc_hosts(), ""w"") <TAB> for line in lines: <TAB> <TAB> f.write(line) <TAB> f.close()",false,"if ""::1"" in line :",if len ( line ) == 1 :,0.03,0.0
"def aiter_cogs(cls) -> AsyncIterator[Tuple[str, str]]: <TAB> yield ""Core"", ""0"" <TAB> for _dir in data_manager.cog_data_path().iterdir(): <TAB> <TAB> fpath = _dir / ""settings.json"" <TAB> <TAB> if not fpath.exists(): <TAB> <TAB> <TAB> continue <TAB> <TAB> with fpath.open() as f: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> data = json.load(f) <TAB> <TAB> <TAB> except json.JSONDecodeError: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not isinstance(data, dict): <TAB> <TAB> <TAB> continue <TAB> <TAB> cog_name = _dir.stem <TAB> <TAB> for cog_id, inner in data.items(): <TAB> <TAB> <TAB> if not isinstance(inner, dict): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield cog_name, cog_id",false,if not fpath . exists ( ) :,"if not isinstance ( data , dict ) :",0.04,0.0
"def _get_dbutils(): <TAB> try: <TAB> <TAB> import IPython <TAB> <TAB> ip_shell = IPython.get_ipython() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise _NoDbutilsError <TAB> <TAB> return ip_shell.ns_table[""user_global""][""dbutils""] <TAB> except ImportError: <TAB> <TAB> raise _NoDbutilsError <TAB> except KeyError: <TAB> <TAB> raise _NoDbutilsError",false,if ip_shell is None :,"if ""user_global"" not in ip_shell . ns_table :",0.15,0.0
"def _bytecode_filenames(self, py_filenames): <TAB> bytecode_files = [] <TAB> for py_file in py_filenames: <TAB> <TAB> # Since build_py handles package data installation, the <TAB> <TAB> # list of outputs can contain more than just .py files. <TAB> <TAB> # Make sure we only report bytecode for the .py files. <TAB> <TAB> ext = os.path.splitext(os.path.normcase(py_file))[1] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if self.compile: <TAB> <TAB> <TAB> bytecode_files.append(py_file + ""c"") <TAB> <TAB> if self.optimize > 0: <TAB> <TAB> <TAB> bytecode_files.append(py_file + ""o"") <TAB> return bytecode_files",false,if ext != PYTHON_SOURCE_EXTENSION :,if ext in self . extensions :,0.05,0.0
"def compute_distances_mu(line, pts, result, gates, tolerance): <TAB> """"""calculate all distances with mathuutils"""""" <TAB> line_origin = V(line[0]) <TAB> line_end = V(line[-1]) <TAB> local_result = [[], [], [], [], []] <TAB> for point in pts: <TAB> <TAB> data = compute_distance(V(point), line_origin, line_end, tolerance) <TAB> <TAB> for i, res in enumerate(local_result): <TAB> <TAB> <TAB> res.append(data[i]) <TAB> for i, res in enumerate(result): <TAB> <TAB> if gates[i]: <TAB> <TAB> <TAB> res.append(local_result[i])",true,if gates [ i ] :,if gates [ i ] :,0.75,0.0
"def _get_next_segment(self, segment_path, page_size, segment_cursor=None): <TAB> if segment_path: <TAB> <TAB> if self.end_time and self._is_later_than_end_time(segment_path): <TAB> <TAB> <TAB> return None <TAB> <TAB> return Segment(self.client, segment_path, page_size, segment_cursor) <TAB> return None",true,if self . end_time and self . _is_later_than_end_time ( segment_path ) :,if self . end_time and self . _is_later_than_end_time ( segment_path ) :,0.75,0.0
"def _check_number_of_sessions(): <TAB> nb_desktop_sessions = sessions.get_number_of_desktop_sessions(ignore_gdm=True) <TAB> if nb_desktop_sessions > 1: <TAB> <TAB> print( <TAB> <TAB> <TAB> ""WARNING : There are %d other desktop sessions open. The GPU switch will not become effective until you have manually"" <TAB> <TAB> <TAB> "" logged out from ALL desktop sessions.\n"" <TAB> <TAB> <TAB> ""Continue ? (y/N)"" % (nb_desktop_sessions - 1) <TAB> <TAB> ) <TAB> <TAB> confirmation = ask_confirmation() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> sys.exit(0)",true,if not confirmation :,if not confirmation :,0.75,0.0
"def delete_compute_environment(self, compute_environment_name): <TAB> if compute_environment_name is None: <TAB> <TAB> raise InvalidParameterValueException(""Missing computeEnvironment parameter"") <TAB> compute_env = self.get_compute_environment(compute_environment_name) <TAB> if compute_env is not None: <TAB> <TAB> # Pop ComputeEnvironment <TAB> <TAB> self._compute_environments.pop(compute_env.arn) <TAB> <TAB> # Delete ECS cluster <TAB> <TAB> self.ecs_backend.delete_cluster(compute_env.ecs_name) <TAB> <TAB> if compute_env.env_type == ""MANAGED"": <TAB> <TAB> <TAB> # Delete compute environment <TAB> <TAB> <TAB> instance_ids = [instance.id for instance in compute_env.instances] <TAB> <TAB> <TAB> self.ec2_backend.terminate_instances(instance_ids)",true,"if compute_env . env_type == ""MANAGED"" :","if compute_env . env_type == ""MANAGED"" :",0.75,0.0
"def run(self): <TAB> results = {} <TAB> for func_name in [ <TAB> <TAB> # Execute every function starting with check_* <TAB> <TAB> fn <TAB> <TAB> for fn in self.check_functions <TAB> <TAB> # if the user does not specify any name <TAB> <TAB> if not self.args.get(""check"") <TAB> <TAB> # of if specify the current function name <TAB> <TAB> or self.args.get(""check"") == fn <TAB> ]: <TAB> <TAB> function = getattr(self, func_name) <TAB> <TAB> log.warn(function.__doc__) <TAB> <TAB> result = function() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> log.info(""\n"".join(result)) <TAB> <TAB> <TAB> results.update({func_name: result}) <TAB> return results",true,if result :,if result :,0.53,0.0
"def invalidate(self, layers=None): <TAB> if layers is None: <TAB> <TAB> layers = Layer.AllLayers <TAB> if layers: <TAB> <TAB> layers = set(layers) <TAB> <TAB> self.invalidLayers.update(layers) <TAB> <TAB> blockRenderers = [ <TAB> <TAB> <TAB> br <TAB> <TAB> <TAB> for br in self.blockRenderers <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> ] <TAB> <TAB> if len(blockRenderers) < len(self.blockRenderers): <TAB> <TAB> <TAB> self.forgetDisplayLists() <TAB> <TAB> self.blockRenderers = blockRenderers <TAB> <TAB> if self.renderer.showRedraw and Layer.Blocks in layers: <TAB> <TAB> <TAB> self.needsRedisplay = True",false,if br . layer is Layer . Blocks or br . layer not in layers,if br . Layer in layers,0.1,0.0
"def get_library_dirs(platform, arch=None): <TAB> if platform == ""win32"": <TAB> <TAB> jre_home = get_jre_home(platform) <TAB> <TAB> jdk_home = JAVA_HOME <TAB> <TAB> if isinstance(jre_home, bytes): <TAB> <TAB> <TAB> jre_home = jre_home.decode(""utf-8"") <TAB> <TAB> return [join(jdk_home, ""lib""), join(jdk_home, ""bin"", ""server"")] <TAB> elif platform == ""android"": <TAB> <TAB> return [""libs/{}"".format(arch)] <TAB> return []",true,"if isinstance ( jre_home , bytes ) :","if isinstance ( jre_home , bytes ) :",0.75,0.0
"def save_plugin_options(self): <TAB> for name, option_widgets in self._plugin_option_widgets.items(): <TAB> <TAB> if name not in self.config[""plugins""]: <TAB> <TAB> <TAB> self.config[""plugins""][name] = {} <TAB> <TAB> plugin_config = self.config[""plugins""][ <TAB> <TAB> <TAB> name <TAB> <TAB> ]  # use or instead of get incase the value is actually None <TAB> <TAB> for option_name, option_widget in option_widgets.items(): <TAB> <TAB> <TAB> plugin_config[option_name] = option_widget.option.get_widget_value( <TAB> <TAB> <TAB> <TAB> option_widget.widget <TAB> <TAB> <TAB> )",true,"if name not in self . config [ ""plugins"" ] :","if name not in self . config [ ""plugins"" ] :",0.75,0.0
"def _select_block(str_in, start_tag, end_tag): <TAB> """"""Select first block delimited by start_tag and end_tag"""""" <TAB> start_pos = str_in.find(start_tag) <TAB> if start_pos < 0: <TAB> <TAB> raise ValueError(""start_tag not found"") <TAB> depth = 0 <TAB> for pos in range(start_pos, len(str_in)): <TAB> <TAB> if str_in[pos] == start_tag: <TAB> <TAB> <TAB> depth += 1 <TAB> <TAB> elif str_in[pos] == end_tag: <TAB> <TAB> <TAB> depth -= 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> sel = str_in[start_pos + 1 : pos] <TAB> return sel",true,if depth == 0 :,if depth == 0 :,0.75,0.0
"def _coerce_to_bool(self, node, var, true_val=True): <TAB> """"""Coerce the values in a variable to bools."""""" <TAB> bool_var = self.program.NewVariable() <TAB> for b in var.bindings: <TAB> <TAB> v = b.data <TAB> <TAB> if isinstance(v, mixin.PythonConstant) and isinstance(v.pyval, bool): <TAB> <TAB> <TAB> const = v.pyval is true_val <TAB> <TAB> elif not compare.compatible_with(v, True): <TAB> <TAB> <TAB> const = not true_val <TAB> <TAB> elif not compare.compatible_with(v, False): <TAB> <TAB> <TAB> const = true_val <TAB> <TAB> else: <TAB> <TAB> <TAB> const = None <TAB> <TAB> bool_var.AddBinding(self.convert.bool_values[const], {b}, node) <TAB> return bool_var",true,"elif not compare . compatible_with ( v , False ) :","elif not compare . compatible_with ( v , False ) :",0.75,0.0
def multiline_indentation(self): <TAB> if self._multiline_indentation is None: <TAB> <TAB> offset = 0 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> offset = 2 <TAB> <TAB> indentation = make_indentation(3 * self.indent_size + offset) <TAB> <TAB> self._multiline_indentation = indentation <TAB> if self.current_rule: <TAB> <TAB> indent_extra = make_indentation(self.indent_size) <TAB> <TAB> return self._multiline_indentation + indent_extra <TAB> return self._multiline_indentation,false,if self . show_aligned_keywords :,if self . current_rule :,0.39,0.0
"def __call__(self, event, data=None): <TAB> datatype, delta = event <TAB> self.midi_ctrl.delta += delta <TAB> if TIMING_CLOCK in datatype and not self.played: <TAB> <TAB> self.midi_ctrl.pulse += 1 <TAB> <TAB> if self.midi_ctrl.pulse == self.midi_ctrl.ppqn: <TAB> <TAB> <TAB> t_master = 60.0 <TAB> <TAB> <TAB> self.midi_ctrl.bpm = round(60.0 / self.midi_ctrl.delta, 0) <TAB> <TAB> <TAB> self.midi_ctrl.pulse = 0 <TAB> <TAB> <TAB> self.midi_ctrl.delta = 0.0",true,if self . midi_ctrl . pulse == self . midi_ctrl . ppqn :,if self . midi_ctrl . pulse == self . midi_ctrl . ppqn :,1.0,0.0
"def handle_sent(self, elt): <TAB> sent = [] <TAB> for child in elt: <TAB> <TAB> if child.tag in (""wf"", ""punc""): <TAB> <TAB> <TAB> itm = self.handle_word(child) <TAB> <TAB> <TAB> if self._unit == ""word"": <TAB> <TAB> <TAB> <TAB> sent.extend(itm) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> sent.append(itm) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""Unexpected element %s"" % child.tag) <TAB> return SemcorSentence(elt.attrib[""snum""], sent)",false,"if child . tag in ( ""wf"" , ""punc"" ) :","if self . _unit == ""word"" :",0.01,0.0
"def _handle_def_errors(testdef): <TAB> # If the test generation had an error, raise <TAB> if testdef.error: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if isinstance(testdef.exception, Exception): <TAB> <TAB> <TAB> <TAB> raise testdef.exception <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise Exception(testdef.exception) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception(""Test parse failure"")",true,if testdef . exception :,if testdef . exception :,0.75,0.0
"def _authorized_sid(self, jid, sid, ifrom, iq): <TAB> with self._preauthed_sids_lock: <TAB> <TAB> if (jid, sid, ifrom) in self._preauthed_sids: <TAB> <TAB> <TAB> del self._preauthed_sids[(jid, sid, ifrom)] <TAB> <TAB> <TAB> return True <TAB> <TAB> return False",true,"if ( jid , sid , ifrom ) in self . _preauthed_sids :","if ( jid , sid , ifrom ) in self . _preauthed_sids :",0.75,0.0
"def wait(self, timeout=None): <TAB> if self.returncode is None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> msecs = _subprocess.INFINITE <TAB> <TAB> else: <TAB> <TAB> <TAB> msecs = max(0, int(timeout * 1000 + 0.5)) <TAB> <TAB> res = _subprocess.WaitForSingleObject(int(self._handle), msecs) <TAB> <TAB> if res == _subprocess.WAIT_OBJECT_0: <TAB> <TAB> <TAB> code = _subprocess.GetExitCodeProcess(self._handle) <TAB> <TAB> <TAB> if code == TERMINATE: <TAB> <TAB> <TAB> <TAB> code = -signal.SIGTERM <TAB> <TAB> <TAB> self.returncode = code <TAB> return self.returncode",true,if timeout is None :,if timeout is None :,0.75,0.0
"def _gen_legal_y_s_t(self): <TAB> while True: <TAB> <TAB> y = self._gen_random_scalar() <TAB> <TAB> s = self.tec_arithmetic.mul( <TAB> <TAB> <TAB> scalar=y, a=self.tec_arithmetic.get_generator() <TAB> <TAB> )  # S = yG <TAB> <TAB> t = self._hash_tec_element(s) <TAB> <TAB> if self.tec_arithmetic.is_in_group(s) and type(t) != int: <TAB> <TAB> <TAB> # Both S and T are legal <TAB> <TAB> <TAB> LOGGER.info(""randomly generated y, S, T"") <TAB> <TAB> <TAB> return y, s, t",false,if self . tec_arithmetic . is_in_group ( s ) and type ( t ) != int :,if self . ctec_arithmetic . is_in_group ( s ) and type ( t ) != int :,0.67,0.0
"def write_out(): <TAB> while True: <TAB> <TAB> if self.instrument_queue.empty(): <TAB> <TAB> <TAB> time.sleep(0.1) <TAB> <TAB> <TAB> continue <TAB> <TAB> data_str = self.instrument_queue.get() <TAB> <TAB> data_str = data_str.splitlines() <TAB> <TAB> tb.write("""")  # position cursor to end <TAB> <TAB> for line in data_str: <TAB> <TAB> <TAB> tb.write(line) <TAB> <TAB> tb.write(""\n"")",true,if self . instrument_queue . empty ( ) :,if self . instrument_queue . empty ( ) :,0.75,0.0
"def _parse_preamble(self): <TAB> """"""Parse metadata about query (PRIVATE)."""""" <TAB> meta = {} <TAB> while self.line: <TAB> <TAB> regx = re.search(_RE_QUERY, self.line) <TAB> <TAB> if regx: <TAB> <TAB> <TAB> self.query_id = regx.group(1) <TAB> <TAB> if self.line.startswith(""Match_columns""): <TAB> <TAB> <TAB> self.seq_len = int(self.line.strip().split()[1]) <TAB> <TAB> self.line = self.handle.readline().strip() <TAB> return meta",true,"if self . line . startswith ( ""Match_columns"" ) :","if self . line . startswith ( ""Match_columns"" ) :",0.75,0.0
"def init_sequence(self, coll_name, seq_config): <TAB> if not isinstance(seq_config, list): <TAB> <TAB> raise Exception('""sequence"" config must be a list') <TAB> handlers = [] <TAB> for entry in seq_config: <TAB> <TAB> if not isinstance(entry, dict): <TAB> <TAB> <TAB> raise Exception('""sequence"" entry must be a dict') <TAB> <TAB> name = entry.get(""name"", """") <TAB> <TAB> handler = self.load_coll(name, entry) <TAB> <TAB> handlers.append(handler) <TAB> return HandlerSeq(handlers)",true,"if not isinstance ( entry , dict ) :","if not isinstance ( entry , dict ) :",0.75,0.0
"def change_args_to_dict(string): <TAB> if string is None: <TAB> <TAB> return None <TAB> ans = [] <TAB> strings = string.split(""\n"") <TAB> ind = 1 <TAB> start = 0 <TAB> while ind <= len(strings): <TAB> <TAB> if ind < len(strings) and strings[ind].startswith("" ""): <TAB> <TAB> <TAB> ind += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> ans.append(""\n"".join(strings[start:ind])) <TAB> <TAB> <TAB> start = ind <TAB> <TAB> <TAB> ind += 1 <TAB> d = {} <TAB> for line in ans: <TAB> <TAB> if "":"" in line and len(line) > 0: <TAB> <TAB> <TAB> lines = line.split("":"") <TAB> <TAB> <TAB> d[lines[0]] = lines[1].strip() <TAB> return d",false,if start < ind :,if start :,0.07,0.0
"def wait(self): <TAB> while True: <TAB> <TAB> return_code = self._process.poll() <TAB> <TAB> if return_code is not None: <TAB> <TAB> <TAB> line = self._process.stdout.readline().decode(""utf-8"") <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> log.debug(line.strip(""\n"")) <TAB> return True",false,"if line == """" :",if not line :,0.04,0.0
"def __getattr__(self, key): <TAB> for tag in self.tag.children: <TAB> <TAB> if tag.name not in (""input"",): <TAB> <TAB> <TAB> continue <TAB> <TAB> if ""name"" in tag.attrs and tag.attrs[""name""] in (key,): <TAB> <TAB> <TAB> from thug.DOM.W3C.Core.DOMImplementation import DOMImplementation <TAB> <TAB> <TAB> return DOMImplementation.createHTMLElement(self.doc, tag) <TAB> raise AttributeError",true,"if tag . name not in ( ""input"" , ) :","if tag . name not in ( ""input"" , ) :",0.75,0.0
"def compare_hash(hash_of_gold, path_to_file): <TAB> with open(path_to_file, ""rb"") as f: <TAB> <TAB> hash_of_file = hashlib.sha256(f.read()).hexdigest() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print( <TAB> <TAB> <TAB> <TAB> ""########## Hash sum of"", <TAB> <TAB> <TAB> <TAB> path_to_file, <TAB> <TAB> <TAB> <TAB> ""differs from the target, the topology will be deleted !!! ##########"", <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> shutil.rmtree(os.path.dirname(path_to_file))",false,if hash_of_file != hash_of_gold :,if hash_of_gold != hash_of_file :,0.29,0.0
def on_completed2(): <TAB> doner[0] = True <TAB> if not qr: <TAB> <TAB> if len(ql) > 0: <TAB> <TAB> <TAB> observer.on_next(False) <TAB> <TAB> <TAB> observer.on_completed() <TAB> <TAB> elif donel[0]: <TAB> <TAB> <TAB> observer.on_next(True) <TAB> <TAB> <TAB> observer.on_completed(),false,if len ( ql ) > 0 :,elif donel [ 0 ] :,0.02,0.0
"def get_other(self, data, items): <TAB> is_tuple = False <TAB> if type(data) == tuple: <TAB> <TAB> data = list(data) <TAB> <TAB> is_tuple = True <TAB> if type(data) == list: <TAB> <TAB> m_items = items.copy() <TAB> <TAB> for idx, item in enumerate(items): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> m_items[idx] = len(data) - abs(item) <TAB> <TAB> for i in sorted(set(m_items), reverse=True): <TAB> <TAB> <TAB> if i < len(data) and i > -1: <TAB> <TAB> <TAB> <TAB> del data[i] <TAB> <TAB> if is_tuple: <TAB> <TAB> <TAB> return tuple(data) <TAB> <TAB> else: <TAB> <TAB> <TAB> return data <TAB> else: <TAB> <TAB> return None",false,if item < 0 :,if abs ( item ) < 0 :,0.11,0.0
"def _open_url(cls, url): <TAB> if config.browser: <TAB> <TAB> cmd = [config.browser, url] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(""running command: %s"" % "" "".join(cmd)) <TAB> <TAB> p = Popen(cmd) <TAB> <TAB> p.communicate() <TAB> else: <TAB> <TAB> if not config.quiet: <TAB> <TAB> <TAB> print(""opening URL in browser: %s"" % url) <TAB> <TAB> webbrowser.open_new(url)",true,if not config . quiet :,if not config . quiet :,0.75,0.0
"def setLabel(self, s, protect=False): <TAB> """"""Set the label of the minibuffer."""""" <TAB> c, k, w = self.c, self, self.w <TAB> if w: <TAB> <TAB> # Support for the curses gui. <TAB> <TAB> if hasattr(g.app.gui, ""set_minibuffer_label""): <TAB> <TAB> <TAB> g.app.gui.set_minibuffer_label(c, s) <TAB> <TAB> w.setAllText(s) <TAB> <TAB> n = len(s) <TAB> <TAB> w.setSelectionRange(n, n, insert=n) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> k.mb_prefix = s",true,if protect :,if protect :,0.53,0.0
"def __init__(self, path): <TAB> self.symcaches = [] <TAB> for path in path.split("";""): <TAB> <TAB> if os.path.isdir(path): <TAB> <TAB> <TAB> self.symcaches.append(SymbolCache(dirname=path)) <TAB> <TAB> <TAB> continue <TAB> <TAB> if path.startswith(""cobra://"") or path.startswith(""cobrassl://""): <TAB> <TAB> <TAB> import cobra <TAB> <TAB> <TAB> self.symcaches.append(cobra.CobraProxy(path)) <TAB> <TAB> <TAB> continue",false,"if path . startswith ( ""cobra://"" ) or path . startswith ( ""cobrassl://"" ) :",if os . path . isdir ( path ) :,0.15,0.0
"def init_params(net): <TAB> """"""Init layer parameters."""""" <TAB> for module in net.modules(): <TAB> <TAB> if isinstance(module, nn.Conv2d): <TAB> <TAB> <TAB> init.kaiming_normal(module.weight, mode=""fan_out"") <TAB> <TAB> <TAB> if module.bias: <TAB> <TAB> <TAB> <TAB> init.constant(module.bias, 0) <TAB> <TAB> elif isinstance(module, nn.BatchNorm2d): <TAB> <TAB> <TAB> init.constant(module.weight, 1) <TAB> <TAB> <TAB> init.constant(module.bias, 0) <TAB> <TAB> elif isinstance(module, nn.Linear): <TAB> <TAB> <TAB> init.normal(module.weight, std=1e-3) <TAB> <TAB> <TAB> if module.bias: <TAB> <TAB> <TAB> <TAB> init.constant(module.bias, 0)",true,"elif isinstance ( module , nn . BatchNorm2d ) :","elif isinstance ( module , nn . BatchNorm2d ) :",0.75,0.0
"def _diff_dict(self, old, new): <TAB> diff = {} <TAB> removed = [] <TAB> added = [] <TAB> for key, value in old.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> removed.append(key) <TAB> <TAB> elif old[key] != new[key]: <TAB> <TAB> <TAB> # modified is indicated by a remove and add <TAB> <TAB> <TAB> removed.append(key) <TAB> <TAB> <TAB> added.append(key) <TAB> for key, value in new.items(): <TAB> <TAB> if key not in old: <TAB> <TAB> <TAB> added.append(key) <TAB> if removed: <TAB> <TAB> diff[""removed""] = sorted(removed) <TAB> if added: <TAB> <TAB> diff[""added""] = sorted(added) <TAB> return diff",true,if key not in new :,if key not in new :,0.75,0.0
"def __init__(self, *args, **kwargs): <TAB> _kwargs = { <TAB> <TAB> ""max_length"": 20, <TAB> <TAB> ""widget"": forms.TextInput(attrs={""autocomplete"": ""off""}), <TAB> <TAB> ""label"": _(""Card number""), <TAB> } <TAB> if ""types"" in kwargs: <TAB> <TAB> self.accepted_cards = set(kwargs.pop(""types"")) <TAB> <TAB> difference = self.accepted_cards - VALID_CARDS <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ImproperlyConfigured( <TAB> <TAB> <TAB> <TAB> ""The following accepted_cards are "" ""unknown: %s"" % difference <TAB> <TAB> <TAB> ) <TAB> _kwargs.update(kwargs) <TAB> super().__init__(*args, **_kwargs)",true,if difference :,if difference :,0.53,0.0
"def dumps(self): <TAB> sections = [] <TAB> for name, env_info in self._dependencies_.items(): <TAB> <TAB> sections.append(""[ENV_%s]"" % name) <TAB> <TAB> for var, values in sorted(env_info.vars.items()): <TAB> <TAB> <TAB> tmp = ""%s="" % var <TAB> <TAB> <TAB> if isinstance(values, list): <TAB> <TAB> <TAB> <TAB> tmp += ""[%s]"" % "","".join(['""%s""' % val for val in values]) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> tmp += ""%s"" % values <TAB> <TAB> <TAB> sections.append(tmp) <TAB> return ""\n"".join(sections)",true,"if isinstance ( values , list ) :","if isinstance ( values , list ) :",0.75,0.0
"def air_quality(self): <TAB> aqi_data = self._get_aqi_data() <TAB> if aqi_data: <TAB> <TAB> if aqi_data.get(""status"") == ""ok"": <TAB> <TAB> <TAB> aqi_data = self._organize(aqi_data) <TAB> <TAB> <TAB> aqi_data = self._manipulate(aqi_data) <TAB> <TAB> elif aqi_data.get(""status"") == ""error"": <TAB> <TAB> <TAB> self.py3.error(aqi_data.get(""data"")) <TAB> return { <TAB> <TAB> ""cached_until"": self.py3.time_in(self.cache_timeout), <TAB> <TAB> ""full_text"": self.py3.safe_format(self.format, aqi_data), <TAB> }",false,"elif aqi_data . get ( ""status"" ) == ""error"" :","if aqi_data . get ( ""status"" ) == ""ok"" :",0.33,0.0
"def _blend(x, y):  # pylint: disable=invalid-name <TAB> """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB> if isinstance(x, (dict, OrderedDict)): <TAB> <TAB> if not isinstance(y, (dict, OrderedDict)): <TAB> <TAB> <TAB> return y <TAB> <TAB> return _merge(x, y, recursion_func=_blend) <TAB> if isinstance(x, (list, tuple)): <TAB> <TAB> if not isinstance(y, (list, tuple)): <TAB> <TAB> <TAB> return y <TAB> <TAB> result = [_blend(*i) for i in zip(x, y)] <TAB> <TAB> if len(x) > len(y): <TAB> <TAB> <TAB> result += x[len(y) :] <TAB> <TAB> elif len(x) < len(y): <TAB> <TAB> <TAB> result += y[len(x) :] <TAB> <TAB> return result <TAB> return y",false,"if not isinstance ( y , ( list , tuple ) ) :",if len ( x ) > len ( y ) :,0.03,0.0
"def _rate(cls, sample1, sample2): <TAB> ""Simple rate"" <TAB> try: <TAB> <TAB> interval = sample2[0] - sample1[0] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise Infinity() <TAB> <TAB> delta = sample2[1] - sample1[1] <TAB> <TAB> if delta < 0: <TAB> <TAB> <TAB> raise UnknownValue() <TAB> <TAB> return (sample2[0], delta / interval, sample2[2], sample2[3]) <TAB> except Infinity: <TAB> <TAB> raise <TAB> except UnknownValue: <TAB> <TAB> raise <TAB> except Exception as e: <TAB> <TAB> raise NaN(e)",false,if interval == 0 :,if interval < 0 :,0.33,0.0
"def wrapped_request_method(*args, **kwargs): <TAB> """"""Modifies HTTP headers to include a specified user-agent."""""" <TAB> if kwargs.get(""headers"") is not None: <TAB> <TAB> if kwargs[""headers""].get(""user-agent""): <TAB> <TAB> <TAB> if user_agent not in kwargs[""headers""][""user-agent""]: <TAB> <TAB> <TAB> <TAB> # Save the existing user-agent header and tack on our own. <TAB> <TAB> <TAB> <TAB> kwargs[""headers""][""user-agent""] = ( <TAB> <TAB> <TAB> <TAB> <TAB> f""{user_agent} "" f'{kwargs[""headers""][""user-agent""]}' <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> kwargs[""headers""][""user-agent""] = user_agent <TAB> else: <TAB> <TAB> kwargs[""headers""] = {""user-agent"": user_agent} <TAB> return request_method(*args, **kwargs)",false,"if kwargs [ ""headers"" ] . get ( ""user-agent"" ) :","if user_agent not in kwargs [ ""headers"" ] [ ""user-agent"" ] :",0.13,0.0
"def remove_addons(auth, resource_object_list): <TAB> for config in AbstractNode.ADDONS_AVAILABLE: <TAB> <TAB> try: <TAB> <TAB> <TAB> settings_model = config.node_settings <TAB> <TAB> except LookupError: <TAB> <TAB> <TAB> settings_model = None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> addon_list = settings_model.objects.filter( <TAB> <TAB> <TAB> <TAB> owner__in=resource_object_list, is_deleted=False <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> for addon in addon_list: <TAB> <TAB> <TAB> <TAB> addon.after_delete(auth.user)",true,if settings_model :,if settings_model :,0.53,0.0
"def Decorator(*args, **kwargs): <TAB> delay = 0.2 <TAB> num_attempts = 15 <TAB> cur_attempt = 0 <TAB> while True: <TAB> <TAB> try: <TAB> <TAB> <TAB> return f(*args, **kwargs) <TAB> <TAB> except exceptions.WebDriverException as e: <TAB> <TAB> <TAB> logging.warning(""Selenium raised %s"", utils.SmartUnicode(e)) <TAB> <TAB> <TAB> cur_attempt += 1 <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> time.sleep(delay)",false,if cur_attempt == num_attempts :,if cur_attempt >= num_attempts :,0.33,0.0
"def _cleanup_parts_dir(parts_dir, local_plugins_dir, parts): <TAB> if os.path.exists(parts_dir): <TAB> <TAB> logger.info(""Cleaning up parts directory"") <TAB> <TAB> for subdirectory in os.listdir(parts_dir): <TAB> <TAB> <TAB> path = os.path.join(parts_dir, subdirectory) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> shutil.rmtree(path) <TAB> <TAB> <TAB> <TAB> except NotADirectoryError: <TAB> <TAB> <TAB> <TAB> <TAB> os.remove(path) <TAB> for part in parts: <TAB> <TAB> part.mark_cleaned(steps.BUILD) <TAB> <TAB> part.mark_cleaned(steps.PULL)",false,if path != local_plugins_dir :,if path in local_plugins_dir :,0.08,0.0
"def traverse_trees(node_pos, sample, trees: List[HeteroDecisionTreeGuest]): <TAB> if node_pos[""reach_leaf_node""].all(): <TAB> <TAB> return node_pos <TAB> for t_idx, tree in enumerate(trees): <TAB> <TAB> cur_node_idx = node_pos[""node_pos""][t_idx] <TAB> <TAB> # reach leaf <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> rs, reach_leaf = HeteroSecureBoostingTreeGuest.traverse_a_tree( <TAB> <TAB> <TAB> tree, sample, cur_node_idx <TAB> <TAB> ) <TAB> <TAB> if reach_leaf: <TAB> <TAB> <TAB> node_pos[""reach_leaf_node""][t_idx] = True <TAB> <TAB> node_pos[""node_pos""][t_idx] = rs <TAB> return node_pos",false,if cur_node_idx == - 1 :,if cur_node_idx is None :,0.05,0.0
"def get_measurements(self, pipeline, object_name, category): <TAB> if self.get_categories(pipeline, object_name) == [category]: <TAB> <TAB> results = [] <TAB> <TAB> if self.do_corr_and_slope: <TAB> <TAB> <TAB> if object_name == ""Image"": <TAB> <TAB> <TAB> <TAB> results += [""Correlation"", ""Slope""] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> results += [""Correlation""] <TAB> <TAB> if self.do_overlap: <TAB> <TAB> <TAB> results += [""Overlap"", ""K""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> results += [""Manders""] <TAB> <TAB> if self.do_rwc: <TAB> <TAB> <TAB> results += [""RWC""] <TAB> <TAB> if self.do_costes: <TAB> <TAB> <TAB> results += [""Costes""] <TAB> <TAB> return results <TAB> return []",true,if self . do_manders :,if self . do_manders :,0.75,0.0
"def create_connection(self, infos, f2, laddr_infos, protocol): <TAB> for family in infos: <TAB> <TAB> try: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> for laddr in laddr_infos: <TAB> <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> protocol = ""foo"" <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> protocol = ""bar"" <TAB> <TAB> else: <TAB> <TAB> <TAB> break <TAB> else: <TAB> <TAB> raise <TAB> return protocol",false,if f2 :,if family == f2 :,0.1,0.0
"def app_middleware(next, root, info, **kwargs): <TAB> app_auth_header = ""HTTP_AUTHORIZATION"" <TAB> prefix = ""bearer"" <TAB> request = info.context <TAB> if request.path == API_PATH: <TAB> <TAB> if not hasattr(request, ""app""): <TAB> <TAB> <TAB> request.app = None <TAB> <TAB> <TAB> auth = request.META.get(app_auth_header, """").split() <TAB> <TAB> <TAB> if len(auth) == 2: <TAB> <TAB> <TAB> <TAB> auth_prefix, auth_token = auth <TAB> <TAB> <TAB> <TAB> if auth_prefix.lower() == prefix: <TAB> <TAB> <TAB> <TAB> <TAB> request.app = SimpleLazyObject(lambda: get_app(auth_token)) <TAB> return next(root, info, **kwargs)",false,if auth_prefix . lower ( ) == prefix :,"if not hasattr ( request , ""app"" ) :",0.02,0.0
"def when(self, matches, context): <TAB> ret = [] <TAB> for episode in matches.named(""episode"", lambda match: len(match.initiator) == 1): <TAB> <TAB> group = matches.markers.at_match( <TAB> <TAB> <TAB> episode, lambda marker: marker.name == ""group"", index=0 <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if not matches.range( <TAB> <TAB> <TAB> <TAB> *group.span, predicate=lambda match: match.name == ""title"" <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> ret.append(episode) <TAB> return ret",true,if group :,if group :,0.53,0.0
def locate_via_pep514(spec): <TAB> with _PY_LOCK: <TAB> <TAB> if not _PY_AVAILABLE: <TAB> <TAB> <TAB> from . import pep514 <TAB> <TAB> <TAB> _PY_AVAILABLE.extend(pep514.discover_pythons()) <TAB> <TAB> <TAB> _PY_AVAILABLE.append(CURRENT) <TAB> for cur_spec in _PY_AVAILABLE: <TAB> <TAB> if cur_spec.satisfies(spec): <TAB> <TAB> <TAB> return cur_spec.path,true,if cur_spec . satisfies ( spec ) :,if cur_spec . satisfies ( spec ) :,0.75,0.0
"def setCorkImageDefault(self): <TAB> if settings.corkBackground[""image""] != """": <TAB> <TAB> i = self.cmbCorkImage.findData(settings.corkBackground[""image""]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.cmbCorkImage.setCurrentIndex(i)",true,if i != - 1 :,if i != - 1 :,0.75,0.0
"def _split_key(key): <TAB> if isinstance(key, util.string_types): <TAB> <TAB> # coerce fooload('*') into ""default loader strategy"" <TAB> <TAB> if key == _WILDCARD_TOKEN: <TAB> <TAB> <TAB> return (_DEFAULT_TOKEN,) <TAB> <TAB> # coerce fooload("".*"") into ""wildcard on default entity"" <TAB> <TAB> elif key.startswith(""."" + _WILDCARD_TOKEN): <TAB> <TAB> <TAB> key = key[1:] <TAB> <TAB> return key.split(""."") <TAB> else: <TAB> <TAB> return (key,)",true,"elif key . startswith ( ""."" + _WILDCARD_TOKEN ) :","elif key . startswith ( ""."" + _WILDCARD_TOKEN ) :",0.75,0.0
"def detach_volume(self, volume): <TAB> # We need to find the node using this volume <TAB> for node in self.list_nodes(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # This node has only one associated image. It is not the one we <TAB> <TAB> <TAB> # are after. <TAB> <TAB> <TAB> continue <TAB> <TAB> for disk in node.image: <TAB> <TAB> <TAB> if disk.id == volume.id: <TAB> <TAB> <TAB> <TAB> # Node found. We can now detach the volume <TAB> <TAB> <TAB> <TAB> disk_id = disk.extra[""disk_id""] <TAB> <TAB> <TAB> <TAB> return self._do_detach_volume(node.id, disk_id) <TAB> return False",false,if type ( node . image ) is not list :,if node . image is None :,0.09,0.0
"def create(self, private=False): <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> log.info(""Creating private channel %s."", self) <TAB> <TAB> <TAB> self._bot.api_call( <TAB> <TAB> <TAB> <TAB> ""conversations.create"", data={""name"": self.name, ""is_private"": True} <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> log.info(""Creating channel %s."", self) <TAB> <TAB> <TAB> self._bot.api_call(""conversations.create"", data={""name"": self.name}) <TAB> except SlackAPIResponseError as e: <TAB> <TAB> if e.error == ""user_is_bot"": <TAB> <TAB> <TAB> raise RoomError(f""Unable to create channel. {USER_IS_BOT_HELPTEXT}"") <TAB> <TAB> else: <TAB> <TAB> <TAB> raise RoomError(e)",true,if private :,if private :,0.53,0.0
"def test_dataset_has_valid_etag(self, dataset_name): <TAB> py_script_path = list(filter(lambda x: x, dataset_name.split(""/"")))[-1] + "".py"" <TAB> dataset_url = hf_bucket_url(dataset_name, filename=py_script_path, dataset=True) <TAB> etag = None <TAB> try: <TAB> <TAB> response = requests.head( <TAB> <TAB> <TAB> dataset_url, allow_redirects=True, proxies=None, timeout=10 <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> etag = response.headers.get(""Etag"") <TAB> except (EnvironmentError, requests.exceptions.Timeout): <TAB> <TAB> pass <TAB> self.assertIsNotNone(etag)",false,if response . status_code == 200 :,"if ""Etag"" in response . headers :",0.04,0.0
"def set_dir_modes(self, dirname, mode): <TAB> if not self.is_chmod_supported(): <TAB> <TAB> return <TAB> for dirpath, dirnames, fnames in os.walk(dirname): <TAB> <TAB> if os.path.islink(dirpath): <TAB> <TAB> <TAB> continue <TAB> <TAB> log.info(""changing mode of %s to %o"", dirpath, mode) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> os.chmod(dirpath, mode)",false,if not self . dry_run :,if mode != 0 :,0.03,0.0
"def _clean(self): <TAB> logger.info(""Cleaning up..."") <TAB> if self._process is not None: <TAB> <TAB> if self._process.poll() is None: <TAB> <TAB> <TAB> for _ in range(3): <TAB> <TAB> <TAB> <TAB> self._process.terminate() <TAB> <TAB> <TAB> <TAB> time.sleep(0.5) <TAB> <TAB> <TAB> <TAB> if self._process.poll() is not None: <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self._process.kill() <TAB> <TAB> <TAB> <TAB> self._process.wait() <TAB> <TAB> <TAB> <TAB> logger.error(""KILLED"") <TAB> if os.path.exists(self._tmp_dir): <TAB> <TAB> shutil.rmtree(self._tmp_dir) <TAB> self._process = None <TAB> self._ws = None <TAB> logger.info(""Cleanup complete"")",true,if self . _process . poll ( ) is None :,if self . _process . poll ( ) is None :,0.75,0.0
"def iter_chars_to_words(self, chars): <TAB> current_word = [] <TAB> for char in chars: <TAB> <TAB> if not self.keep_blank_chars and char[""text""].isspace(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> yield current_word <TAB> <TAB> <TAB> <TAB> current_word = [] <TAB> <TAB> elif current_word and self.char_begins_new_word(current_word, char): <TAB> <TAB> <TAB> yield current_word <TAB> <TAB> <TAB> current_word = [char] <TAB> <TAB> else: <TAB> <TAB> <TAB> current_word.append(char) <TAB> if current_word: <TAB> <TAB> yield current_word",true,if current_word :,if current_word :,0.53,0.0
"def _lookup(components, specs, provided, name, i, l): <TAB> if i < l: <TAB> <TAB> for spec in specs[i].__sro__: <TAB> <TAB> <TAB> comps = components.get(spec) <TAB> <TAB> <TAB> if comps: <TAB> <TAB> <TAB> <TAB> r = _lookup(comps, specs, provided, name, i + 1, l) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return r <TAB> else: <TAB> <TAB> for iface in provided: <TAB> <TAB> <TAB> comps = components.get(iface) <TAB> <TAB> <TAB> if comps: <TAB> <TAB> <TAB> <TAB> r = comps.get(name) <TAB> <TAB> <TAB> <TAB> if r is not None: <TAB> <TAB> <TAB> <TAB> <TAB> return r <TAB> return None",true,if r is not None :,if r is not None :,0.75,0.0
"def run(cmd, task=None): <TAB> process = subprocess.Popen( <TAB> <TAB> cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, close_fds=True <TAB> ) <TAB> output_lines = [] <TAB> while True: <TAB> <TAB> line = process.stdout.readline() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> line = line.decode(""utf-8"") <TAB> <TAB> output_lines += [line] <TAB> <TAB> logger.info(line.rstrip(""\n"")) <TAB> process.stdout.close() <TAB> exit_code = process.wait() <TAB> if exit_code: <TAB> <TAB> output = """".join(output_lines) <TAB> <TAB> raise subprocess.CalledProcessError(exit_code, cmd, output=output)",true,if not line :,if not line :,0.75,0.0
"def process_response(self, request, response): <TAB> if ( <TAB> <TAB> response.status_code == 404 <TAB> <TAB> and request.path_info.endswith(""/"") <TAB> <TAB> and not is_valid_path(request.path_info) <TAB> <TAB> and is_valid_path(request.path_info[:-1]) <TAB> ): <TAB> <TAB> # Use request.path because we munged app/locale in path_info. <TAB> <TAB> newurl = request.path[:-1] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> with safe_query_string(request): <TAB> <TAB> <TAB> <TAB> newurl += ""?"" + request.META[""QUERY_STRING""] <TAB> <TAB> return HttpResponsePermanentRedirect(newurl) <TAB> return response",false,if request . GET :,if request . META :,0.39,0.0
"def dependencies(self): <TAB> deps = [] <TAB> midx = None <TAB> if self.ref is not None: <TAB> <TAB> query = TypeQuery(self.ref) <TAB> <TAB> super = query.execute(self.schema) <TAB> <TAB> if super is None: <TAB> <TAB> <TAB> log.debug(self.schema) <TAB> <TAB> <TAB> raise TypeNotFound(self.ref) <TAB> <TAB> if not super.builtin(): <TAB> <TAB> <TAB> deps.append(super) <TAB> <TAB> <TAB> midx = 0 <TAB> return (midx, deps)",true,if not super . builtin ( ) :,if not super . builtin ( ) :,0.75,0.0
"def _get_vtkjs(self): <TAB> if self._vtkjs is None and self.object is not None: <TAB> <TAB> if isinstance(self.object, string_types) and self.object.endswith("".vtkjs""): <TAB> <TAB> <TAB> if isfile(self.object): <TAB> <TAB> <TAB> <TAB> with open(self.object, ""rb"") as f: <TAB> <TAB> <TAB> <TAB> <TAB> vtkjs = f.read() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> data_url = urlopen(self.object) <TAB> <TAB> <TAB> <TAB> vtkjs = data_url.read() <TAB> <TAB> elif hasattr(self.object, ""read""): <TAB> <TAB> <TAB> vtkjs = self.object.read() <TAB> <TAB> self._vtkjs = vtkjs <TAB> return self._vtkjs",false,if isfile ( self . object ) :,"if isinstance ( self . object , string_types ) and self . object . endswith ( "".vtkjs"" ) :",0.2,0.0
"def _save(self): <TAB> fd, tempname = tempfile.mkstemp() <TAB> fd = os.fdopen(fd, ""w"") <TAB> json.dump(self._cache, fd, indent=2, separators=("","", "": "")) <TAB> fd.close() <TAB> # Silently ignore errors <TAB> try: <TAB> <TAB> if not os.path.exists(os.path.dirname(self.filename)): <TAB> <TAB> <TAB> os.makedirs(os.path.dirname(self.filename)) <TAB> <TAB> shutil.move(tempname, self.filename) <TAB> except (IOError, OSError): <TAB> <TAB> os.remove(tempname)",true,if not os . path . exists ( os . path . dirname ( self . filename ) ) :,if not os . path . exists ( os . path . dirname ( self . filename ) ) :,1.0,0.0
"def refiner_configs(self): <TAB> rv = {} <TAB> for refiner in refiner_manager: <TAB> <TAB> if self.config.has_section(refiner.name): <TAB> <TAB> <TAB> rv[refiner.name] = {k: v for k, v in self.config.items(refiner.name)} <TAB> return rv",true,if self . config . has_section ( refiner . name ) :,if self . config . has_section ( refiner . name ) :,0.75,0.0
"def com_slice(self, primary, node, assigning): <TAB> # short_slice:  [lower_bound] "":"" [upper_bound] <TAB> lower = upper = None <TAB> if len(node.children) == 2: <TAB> <TAB> if node.children[0].type == token.COLON: <TAB> <TAB> <TAB> upper = self.com_node(node.children[1]) <TAB> <TAB> else: <TAB> <TAB> <TAB> lower = self.com_node(node.children[0]) <TAB> elif len(node.children) == 3: <TAB> <TAB> lower = self.com_node(node.children[0]) <TAB> <TAB> upper = self.com_node(node.children[2]) <TAB> return Slice(primary, assigning, lower, upper, lineno=extractLineNo(node))",true,if node . children [ 0 ] . type == token . COLON :,if node . children [ 0 ] . type == token . COLON :,0.75,0.0
"def close(self, *args, **kwargs): <TAB> super(mytqdm, self).close(*args, **kwargs) <TAB> # If it was not run in a notebook, sp is not assigned, check for it <TAB> if hasattr(self, ""sp""): <TAB> <TAB> # Try to detect if there was an error or KeyboardInterrupt <TAB> <TAB> # in manual mode: if n < total, things probably got wrong <TAB> <TAB> if self.total and self.n < self.total: <TAB> <TAB> <TAB> self.sp(bar_style=""danger"") <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.sp(bar_style=""success"") <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.sp(close=True)",false,if self . leave :,if self . n == self . total :,0.19,0.0
"def test_alloc(self): <TAB> b = bytearray() <TAB> alloc = b.__alloc__() <TAB> self.assertTrue(alloc >= 0) <TAB> seq = [alloc] <TAB> for i in range(100): <TAB> <TAB> b += b""x"" <TAB> <TAB> alloc = b.__alloc__() <TAB> <TAB> self.assertTrue(alloc >= len(b)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> seq.append(alloc)",false,if alloc not in seq :,if i % 2 == 0 :,0.02,0.0
"def flush_file(self, key, f): <TAB> f.flush() <TAB><IF-STMT> <TAB> <TAB> f.compress = zlib.compressobj( <TAB> <TAB> <TAB> 9, zlib.DEFLATED, -zlib.MAX_WBITS, zlib.DEF_MEM_LEVEL, 0 <TAB> <TAB> ) <TAB> if len(self.files) > self.MAX_OPEN_FILES: <TAB> <TAB> if self.compress: <TAB> <TAB> <TAB> open_files = sum(1 for f in self.files.values() if f.fileobj is not None) <TAB> <TAB> <TAB> if open_files > self.MAX_OPEN_FILES: <TAB> <TAB> <TAB> <TAB> f.fileobj.close() <TAB> <TAB> <TAB> <TAB> f.fileobj = None <TAB> <TAB> else: <TAB> <TAB> <TAB> f.close() <TAB> <TAB> <TAB> self.files.pop(key)",true,if self . compress :,if self . compress :,0.75,0.0
"def _run(self): <TAB> # Low-level run method to do the actual scheduling loop. <TAB> self.running = True <TAB> while self.running: <TAB> <TAB> try: <TAB> <TAB> <TAB> self.sched.run() <TAB> <TAB> except Exception as x: <TAB> <TAB> <TAB> logging.error( <TAB> <TAB> <TAB> <TAB> ""Error during scheduler execution: %s"" % str(x), exc_info=True <TAB> <TAB> <TAB> ) <TAB> <TAB> # queue is empty; sleep a short while before checking again <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> time.sleep(5)",false,if self . running :,if self . queue is not None :,0.19,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB> if tt == 10: <TAB> <TAB> <TAB> self.set_app_id(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.set_max_rows(d.getVarInt32()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0: <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 16 :,if tt == 16 :,0.75,0.0
"def check(dbdef): <TAB> ""drop script must clear the database"" <TAB> for version in dbdef: <TAB> <TAB> connector = MemConnector().bound(None) <TAB> <TAB> create(dbdef, version, connector) <TAB> <TAB> drop(dbdef, version, connector) <TAB> <TAB> remaining = connector.execute( <TAB> <TAB> <TAB> ""SELECT * FROM sqlite_master WHERE name NOT LIKE 'sqlite_%'"" <TAB> <TAB> ).fetchall() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield ""{0}:drop.sql"".format(version), remaining",true,if remaining :,if remaining :,0.53,0.0
"def test_open_overwrite_offset_size(self, sftp): <TAB> """"""Test writing data at a specific offset"""""" <TAB> f = None <TAB> try: <TAB> <TAB> self._create_file(""file"", ""xxxxyyyy"") <TAB> <TAB> f = yield from sftp.open(""file"", ""r+"") <TAB> <TAB> yield from f.write(""zz"", 3) <TAB> <TAB> yield from f.close() <TAB> <TAB> with open(""file"") as localf: <TAB> <TAB> <TAB> self.assertEqual(localf.read(), ""xxxzzyyy"") <TAB> finally: <TAB> <TAB><IF-STMT>  # pragma: no branch <TAB> <TAB> <TAB> yield from f.close() <TAB> <TAB> remove(""file"")",true,if f :,if f :,0.53,0.0
"def pump(): <TAB> import sys as _sys <TAB> while self.countdown_active(): <TAB> <TAB> if not (self.connected(""send"") and other.connected(""recv"")): <TAB> <TAB> <TAB> break <TAB> <TAB> try: <TAB> <TAB> <TAB> data = other.recv(timeout=0.05) <TAB> <TAB> except EOFError: <TAB> <TAB> <TAB> break <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> if not data: <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> self.send(data) <TAB> <TAB> except EOFError: <TAB> <TAB> <TAB> break <TAB> <TAB> if not _sys: <TAB> <TAB> <TAB> return <TAB> self.shutdown(""send"") <TAB> other.shutdown(""recv"")",false,if not _sys :,if not data :,0.35,0.0
"def parse_results(cwd): <TAB> optimal_dd = None <TAB> optimal_measure = numpy.inf <TAB> for tup in tools.find_conf_files(cwd): <TAB> <TAB> dd = tup[1] <TAB> <TAB> if ""results.train_y_misclass"" in dd: <TAB> <TAB> <TAB> if dd[""results.train_y_misclass""] < optimal_measure: <TAB> <TAB> <TAB> <TAB> optimal_measure = dd[""results.train_y_misclass""] <TAB> <TAB> <TAB> <TAB> optimal_dd = dd <TAB> print(""Optimal results.train_y_misclass:"", str(optimal_measure)) <TAB> for key, value in optimal_dd.items(): <TAB> <TAB> if ""hyper_parameters"" in key: <TAB> <TAB> <TAB> print(key + "": "" + str(value))",true,"if dd [ ""results.train_y_misclass"" ] < optimal_measure :","if dd [ ""results.train_y_misclass"" ] < optimal_measure :",0.75,0.0
"def valid(self): <TAB> valid = True <TAB> if os.path.exists(self.pathfile): <TAB> <TAB> return valid <TAB> else: <TAB> <TAB> try: <TAB> <TAB> <TAB> with io.open(self.pathfile, ""w"", encoding=""utf-8"") as f: <TAB> <TAB> <TAB> <TAB> f.close()  # do nothing <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> valid = False <TAB> <TAB> if os.path.exists(self.pathfile): <TAB> <TAB> <TAB> os.remove(self.pathfile) <TAB> <TAB> return valid",true,if os . path . exists ( self . pathfile ) :,if os . path . exists ( self . pathfile ) :,0.75,0.0
"def __getitem__(self, key): <TAB> try: <TAB> <TAB> value = self.cache[key] <TAB> except KeyError: <TAB> <TAB> f = BytesIO(self.dict[key.encode(self.keyencoding)]) <TAB> <TAB> value = Unpickler(f).load() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.cache[key] = value <TAB> return value",false,if self . writeback :,if value is not None :,0.03,0.0
"def hasMenu(cls, callingWindow, mainItem, selection, *fullContexts): <TAB> for i, fullContext in enumerate(fullContexts): <TAB> <TAB> srcContext = fullContext[0] <TAB> <TAB> for menuHandler in cls.menus: <TAB> <TAB> <TAB> m = menuHandler() <TAB> <TAB> <TAB> if m._baseDisplay(callingWindow, srcContext, mainItem, selection): <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> return False",true,"if m . _baseDisplay ( callingWindow , srcContext , mainItem , selection ) :","if m . _baseDisplay ( callingWindow , srcContext , mainItem , selection ) :",0.75,0.0
"def lr_read_tables(module=tab_module, optimize=0): <TAB> global _lr_action, _lr_goto, _lr_productions, _lr_method <TAB> try: <TAB> <TAB> exec(""import %s as parsetab"" % module) <TAB> <TAB> global parsetab  # declare the name of the imported module <TAB> <TAB> if (optimize) or (Signature.digest() == parsetab._lr_signature): <TAB> <TAB> <TAB> _lr_action = parsetab._lr_action <TAB> <TAB> <TAB> _lr_goto = parsetab._lr_goto <TAB> <TAB> <TAB> _lr_productions = parsetab._lr_productions <TAB> <TAB> <TAB> _lr_method = parsetab._lr_method <TAB> <TAB> <TAB> return 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> return 0 <TAB> except (ImportError, AttributeError): <TAB> <TAB> return 0",true,if ( optimize ) or ( Signature . digest ( ) == parsetab . _lr_signature ) :,if ( optimize ) or ( Signature . digest ( ) == parsetab . _lr_signature ) :,0.75,0.0
"def _Determine_Do(self): <TAB> if sys.platform.startswith(""win""): <TAB> <TAB> self.applicable = 1 <TAB> <TAB> for opt, optarg in self.chosenOptions: <TAB> <TAB> <TAB> if opt == ""--moz-tools"": <TAB> <TAB> <TAB> <TAB> self.value = os.path.abspath(os.path.normpath(optarg)) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> if os.environ.has_key(self.name): <TAB> <TAB> <TAB> <TAB> self.value = os.environ[self.name] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.value = None <TAB> else: <TAB> <TAB> self.applicable = 0 <TAB> self.determined = 1",false,if os . environ . has_key ( self . name ) :,"if opt == ""--moz-tools"" :",0.01,0.0
"def parse_chunked(self, unreader): <TAB> (size, rest) = self.parse_chunk_size(unreader) <TAB> while size > 0: <TAB> <TAB> while size > len(rest): <TAB> <TAB> <TAB> size -= len(rest) <TAB> <TAB> <TAB> yield rest <TAB> <TAB> <TAB> rest = unreader.read() <TAB> <TAB> <TAB> if not rest: <TAB> <TAB> <TAB> <TAB> raise NoMoreData() <TAB> <TAB> yield rest[:size] <TAB> <TAB> # Remove \r\n after chunk <TAB> <TAB> rest = rest[size:] <TAB> <TAB> while len(rest) < 2: <TAB> <TAB> <TAB> rest += unreader.read() <TAB> <TAB> if rest[:2] != b""\r\n"": <TAB> <TAB> <TAB> raise ChunkMissingTerminator(rest[:2]) <TAB> <TAB> (size, rest) = self.parse_chunk_size(unreader, data=rest[2:])",true,"if rest [ : 2 ] != b""\r\n"" :","if rest [ : 2 ] != b""\r\n"" :",0.75,0.0
"def _scroll_down(self, cli): <TAB> ""Scroll window down."" <TAB> info = self.render_info <TAB> if self.vertical_scroll < info.content_height - info.window_height: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.content.move_cursor_down(cli) <TAB> <TAB> self.vertical_scroll += 1",false,if info . cursor_position . y <= info . configured_scroll_offsets . top :,if self . vertical_scroll > 0 :,0.05,0.0
"def _add_defaults_data_files(self): <TAB> # getting distribution.data_files <TAB> if self.distribution.has_data_files(): <TAB> <TAB> for item in self.distribution.data_files: <TAB> <TAB> <TAB> if isinstance(item, str): <TAB> <TAB> <TAB> <TAB> # plain file <TAB> <TAB> <TAB> <TAB> item = convert_path(item) <TAB> <TAB> <TAB> <TAB> if os.path.isfile(item): <TAB> <TAB> <TAB> <TAB> <TAB> self.filelist.append(item) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> # a (dirname, filenames) tuple <TAB> <TAB> <TAB> <TAB> dirname, filenames = item <TAB> <TAB> <TAB> <TAB> for f in filenames: <TAB> <TAB> <TAB> <TAB> <TAB> f = convert_path(f) <TAB> <TAB> <TAB> <TAB> <TAB> if os.path.isfile(f): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self.filelist.append(f)",false,if os . path . isfile ( f ) :,"if isinstance ( item , str ) :",0.03,0.0
"def list_stuff(self, upto=10, start_after=-1): <TAB> for i in range(upto): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if i == 2 and self.count < 1: <TAB> <TAB> <TAB> self.count += 1 <TAB> <TAB> <TAB> raise TemporaryProblem <TAB> <TAB> if i == 7 and self.count < 4: <TAB> <TAB> <TAB> self.count += 1 <TAB> <TAB> <TAB> raise TemporaryProblem <TAB> <TAB> yield i",false,if i <= start_after :,if i == start_after :,0.33,0.0
"def is_open(self): <TAB> if self.signup_code: <TAB> <TAB> return True <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if self.messages.get(""invalid_signup_code""): <TAB> <TAB> <TAB> <TAB> messages.add_message( <TAB> <TAB> <TAB> <TAB> <TAB> self.request, <TAB> <TAB> <TAB> <TAB> <TAB> self.messages[""invalid_signup_code""][""level""], <TAB> <TAB> <TAB> <TAB> <TAB> self.messages[""invalid_signup_code""][""text""].format( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> **{ <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""code"": self.get_code(), <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> <TAB> ) <TAB> return settings.ACCOUNT_OPEN_SIGNUP",false,if self . signup_code_present :,if settings . ACCOUNT_OPEN_SIGNUP :,0.29,0.0
"def on_delete_from_disk(self, widget, data=None): <TAB> model, iter = self.get_selection().get_selected() <TAB> if iter: <TAB> <TAB> path = model.get_value(iter, COLUMN_PATH) <TAB> <TAB> if self.is_defaultitem(path): <TAB> <TAB> <TAB> ErrorDialog(_(""Can't delete system item from disk."")).launch() <TAB> <TAB> else: <TAB> <TAB> <TAB> os.remove(path) <TAB> self.update_items()",true,if self . is_defaultitem ( path ) :,if self . is_defaultitem ( path ) :,0.75,0.0
"def get_detections_for_batch(self, images): <TAB> images = images[..., ::-1] <TAB> detected_faces = self.face_detector.detect_from_batch(images.copy()) <TAB> results = [] <TAB> for i, d in enumerate(detected_faces): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> results.append(None) <TAB> <TAB> <TAB> continue <TAB> <TAB> d = d[0] <TAB> <TAB> d = np.clip(d, 0, None) <TAB> <TAB> x1, y1, x2, y2 = map(int, d[:-1]) <TAB> <TAB> results.append((x1, y1, x2, y2)) <TAB> return results",false,if len ( d ) == 0 :,if i == 0 :,0.08,0.0
def on_update(self): <TAB> # <TAB> # Calculate maximum # of planes per well <TAB> # <TAB> self.max_per_well = 0 <TAB> for pd in list(self.plate_well_site.values()): <TAB> <TAB> for wd in list(pd.values()): <TAB> <TAB> <TAB> nplanes = sum([len(x) for x in list(wd.values())]) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.max_per_well = nplanes <TAB> for registrant in self.registrants: <TAB> <TAB> registrant(),true,if nplanes > self . max_per_well :,if nplanes > self . max_per_well :,0.75,0.0
"def is_writable(self, path): <TAB> result = False <TAB> while not result: <TAB> <TAB> if os.path.exists(path): <TAB> <TAB> <TAB> result = os.access(path, os.W_OK) <TAB> <TAB> <TAB> break <TAB> <TAB> parent = os.path.dirname(path) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> path = parent <TAB> return result",true,if parent == path :,if parent == path :,0.75,0.0
"def _check_seed(self, seed): <TAB> if seed is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._raise_error( <TAB> <TAB> <TAB> <TAB> ""The random number generator seed value, seed, should be integer type or None."" <TAB> <TAB> <TAB> ) <TAB> <TAB> if seed < 0: <TAB> <TAB> <TAB> self._raise_error( <TAB> <TAB> <TAB> <TAB> ""The random number generator seed value, seed, should be non-negative integer or None."" <TAB> <TAB> <TAB> )",true,if type ( seed ) != int :,if type ( seed ) != int :,0.75,0.0
"def write(self, x): <TAB> # try to use backslash and surrogate escape strategies before failing <TAB> self._errors = ""backslashescape"" if self.encoding != ""mbcs"" else ""surrogateescape"" <TAB> try: <TAB> <TAB> return io.TextIOWrapper.write(self, to_text(x, errors=self._errors)) <TAB> except UnicodeDecodeError: <TAB> <TAB> if self._errors != ""surrogateescape"": <TAB> <TAB> <TAB> self._errors = ""surrogateescape"" <TAB> <TAB> else: <TAB> <TAB> <TAB> self._errors = ""replace"" <TAB> <TAB> return io.TextIOWrapper.write(self, to_text(x, errors=self._errors))",true,"if self . _errors != ""surrogateescape"" :","if self . _errors != ""surrogateescape"" :",0.75,0.0
"def post(self, request, *args, **kwargs): <TAB> validated_session = [] <TAB> for session_id in request.data: <TAB> <TAB> session = get_object_or_none(Session, id=session_id) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> validated_session.append(session_id) <TAB> <TAB> <TAB> self.model.objects.create( <TAB> <TAB> <TAB> <TAB> name=""kill_session"", <TAB> <TAB> <TAB> <TAB> args=session.id, <TAB> <TAB> <TAB> <TAB> terminal=session.terminal, <TAB> <TAB> <TAB> ) <TAB> return Response({""ok"": validated_session})",false,if session and not session . is_finished :,if session :,0.07,0.0
"def _has_list_or_dict_var_value_before(self, arg_index): <TAB> for idx, value in enumerate(self.args): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> if variablematcher.is_list_variable( <TAB> <TAB> <TAB> value <TAB> <TAB> ) and not variablematcher.is_list_variable_subitem(value): <TAB> <TAB> <TAB> return True <TAB> <TAB> if robotapi.is_dict_var(value) and not variablematcher.is_dict_var_access( <TAB> <TAB> <TAB> value <TAB> <TAB> ): <TAB> <TAB> <TAB> return True <TAB> return False",false,if idx > arg_index :,if idx == arg_index :,0.33,0.0
"def test_return_correct_type(self): <TAB> for proto in protocols: <TAB> <TAB> # Protocol 0 supports only ASCII strings. <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._check_return_correct_type(""abc"", 0) <TAB> <TAB> else: <TAB> <TAB> <TAB> for obj in [b""abc\n"", ""abc\n"", -1, -1.1 * 0.1, str]: <TAB> <TAB> <TAB> <TAB> self._check_return_correct_type(obj, proto)",true,if proto == 0 :,if proto == 0 :,0.75,0.0
"def backward_impl(self, inputs, outputs, prop_down, accum): <TAB> # inputs: [inputs_fwd_graph] + [inputs_bwd_graph] or <TAB> # [inputs_fwd_graph] + [outputs_fwd_graph] + [inputs_bwd_graph] <TAB> # Args <TAB> axis = self.forward_func.info.args[""axis""] <TAB> # Compute <TAB> ## w.r.t. dy <TAB> if prop_down[-1]: <TAB> <TAB> g_dy = inputs[-1].grad <TAB> <TAB> g_dy_ = F.stack(*[o.grad for o in outputs], axis=axis) <TAB> <TAB> if accum[-1]: <TAB> <TAB> <TAB> g_dy += g_dy_ <TAB> <TAB> else: <TAB> <TAB> <TAB> g_dy.copy_from(g_dy_)",true,if accum [ - 1 ] :,if accum [ - 1 ] :,0.75,0.0
"def remove(self, url): <TAB> try: <TAB> <TAB> i = self.items.index(url) <TAB> except (ValueError, IndexError): <TAB> <TAB> pass <TAB> else: <TAB> <TAB> was_selected = i in self.selectedindices() <TAB> <TAB> self.list.delete(i) <TAB> <TAB> del self.items[i] <TAB> <TAB> if not self.items: <TAB> <TAB> <TAB> self.mp.hidepanel(self.name) <TAB> <TAB> elif was_selected: <TAB> <TAB> <TAB> if i >= len(self.items): <TAB> <TAB> <TAB> <TAB> i = len(self.items) - 1 <TAB> <TAB> <TAB> self.list.select_set(i)",false,if i >= len ( self . items ) :,elif was_selected :,0.01,0.0
"def prepend(self, value): <TAB> """"""prepend value to nodes"""""" <TAB> root, root_text = self._get_root(value) <TAB> for i, tag in enumerate(self): <TAB> <TAB> if not tag.text: <TAB> <TAB> <TAB> tag.text = """" <TAB> <TAB> if len(root) > 0: <TAB> <TAB> <TAB> root[-1].tail = tag.text <TAB> <TAB> <TAB> tag.text = root_text <TAB> <TAB> else: <TAB> <TAB> <TAB> tag.text = root_text + tag.text <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> root = deepcopy(list(root)) <TAB> <TAB> tag[:0] = root <TAB> <TAB> root = tag[: len(root)] <TAB> return self",false,if i > 0 :,if i == 0 :,0.33,0.0
"def _get_tracks_compositors_list(): <TAB> tracks_list = [] <TAB> tracks = current_sequence().tracks <TAB> compositors = current_sequence().compositors <TAB> for track_index in range(1, len(tracks) - 1): <TAB> <TAB> track_compositors = [] <TAB> <TAB> for j in range(0, len(compositors)): <TAB> <TAB> <TAB> comp = compositors[j] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> track_compositors.append(comp) <TAB> <TAB> tracks_list.append(track_compositors) <TAB> return tracks_list",false,if comp . transition . b_track == track_index :,if comp . track_index == track_index :,0.15,0.0
"def __getattr__(self, name): <TAB> if name in self._sections: <TAB> <TAB> return ""\n"".join(self._sections[name]) <TAB> else: <TAB> <TAB> if self._allowed_fields and name in self._allowed_fields: <TAB> <TAB> <TAB> return """" <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ConanException(""ConfigParser: Unrecognized field '%s'"" % name)",true,if self . _allowed_fields and name in self . _allowed_fields :,if self . _allowed_fields and name in self . _allowed_fields :,0.75,0.0
"def get_first_param_index(self, group_id, param_group, partition_id): <TAB> for index, param in enumerate(param_group): <TAB> <TAB> param_id = self.get_param_id(param) <TAB> <TAB> if partition_id in self.param_to_partition_ids[group_id][param_id]: <TAB> <TAB> <TAB> return index <TAB> return None",true,if partition_id in self . param_to_partition_ids [ group_id ] [ param_id ] :,if partition_id in self . param_to_partition_ids [ group_id ] [ param_id ] :,0.75,0.0
"def handle_uv_sockets(self, context): <TAB> u_socket = self.inputs[""U""] <TAB> v_socket = self.inputs[""V""] <TAB> if self.cast_mode == ""Sphere"": <TAB> <TAB> u_socket.hide_safe = True <TAB> <TAB> v_socket.hide_safe = True <TAB> elif self.cast_mode in [""Cylinder"", ""Prism""]: <TAB> <TAB> v_socket.hide_safe = True <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> u_socket.hide_safe = False <TAB> else: <TAB> <TAB> if u_socket.hide_safe: <TAB> <TAB> <TAB> u_socket.hide_safe = False <TAB> <TAB> if v_socket.hide_safe: <TAB> <TAB> <TAB> v_socket.hide_safe = False",false,if u_socket . hide_safe :,if u_socket . hide_safe and v_socket . hide_safe :,0.47,0.0
"def _scrub_generated_timestamps(self, target_workdir): <TAB> """"""Remove the first line of comment from each file if it contains a timestamp."""""" <TAB> for root, _, filenames in safe_walk(target_workdir): <TAB> <TAB> for filename in filenames: <TAB> <TAB> <TAB> source = os.path.join(root, filename) <TAB> <TAB> <TAB> with open(source, ""r"") as f: <TAB> <TAB> <TAB> <TAB> lines = f.readlines() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> with open(source, ""w"") as f: <TAB> <TAB> <TAB> <TAB> if not self._COMMENT_WITH_TIMESTAMP_RE.match(lines[0]): <TAB> <TAB> <TAB> <TAB> <TAB> f.write(lines[0]) <TAB> <TAB> <TAB> <TAB> for line in lines[1:]: <TAB> <TAB> <TAB> <TAB> <TAB> f.write(line)",false,if len ( lines ) < 1 :,if not lines :,0.02,0.0
"def inner(request, *args, **kwargs): <TAB> page = request.current_page <TAB> if page: <TAB> <TAB> if page.login_required and not request.user.is_authenticated: <TAB> <TAB> <TAB> return redirect_to_login( <TAB> <TAB> <TAB> <TAB> urlquote(request.get_full_path()), settings.LOGIN_URL <TAB> <TAB> <TAB> ) <TAB> <TAB> site = get_current_site() <TAB> <TAB> if not user_can_view_page(request.user, page, site): <TAB> <TAB> <TAB> return _handle_no_page(request) <TAB> return func(request, *args, **kwargs)",false,"if not user_can_view_page ( request . user , page , site ) :",if page . login_required and not request . user . is_authenticated :,0.15,0.0
"def flush(self, *args, **kwargs): <TAB> with self._lock: <TAB> <TAB> self._last_updated = time.time() <TAB> <TAB> try: <TAB> <TAB> <TAB> if kwargs.get(""in_place"", False): <TAB> <TAB> <TAB> <TAB> self._locked_flush_without_tempfile() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> mailbox.mbox.flush(self, *args, **kwargs) <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> if ""_create_temporary"" in traceback.format_exc(): <TAB> <TAB> <TAB> <TAB> self._locked_flush_without_tempfile() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> self._last_updated = time.time()",true,"if kwargs . get ( ""in_place"" , False ) :","if kwargs . get ( ""in_place"" , False ) :",0.75,0.0
"def sanitize_event_keys(kwargs, valid_keys): <TAB> # Sanity check: Don't honor keys that we don't recognize. <TAB> for key in list(kwargs.keys()): <TAB> <TAB> if key not in valid_keys: <TAB> <TAB> <TAB> kwargs.pop(key) <TAB> # Truncate certain values over 1k <TAB> for key in [""play"", ""role"", ""task"", ""playbook""]: <TAB> <TAB> if isinstance(kwargs.get(""event_data"", {}).get(key), str): <TAB> <TAB> <TAB> if len(kwargs[""event_data""][key]) > 1024: <TAB> <TAB> <TAB> <TAB> kwargs[""event_data""][key] = Truncator(kwargs[""event_data""][key]).chars( <TAB> <TAB> <TAB> <TAB> <TAB> 1024 <TAB> <TAB> <TAB> <TAB> )",true,"if isinstance ( kwargs . get ( ""event_data"" , { } ) . get ( key ) , str ) :","if isinstance ( kwargs . get ( ""event_data"" , { } ) . get ( key ) , str ) :",1.0,0.0
"def parse_auth(val): <TAB> if val is not None: <TAB> <TAB> authtype, params = val.split("" "", 1) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if authtype == ""Basic"" and '""' not in params: <TAB> <TAB> <TAB> <TAB> # this is the ""Authentication: Basic XXXXX=="" case <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> params = parse_auth_params(params) <TAB> <TAB> return authtype, params <TAB> return val",false,if authtype in known_auth_schemes :,if authtype :,0.07,0.0
"def _memoized(*args): <TAB> now = time.time() <TAB> try: <TAB> <TAB> value, last_update = self.cache[args] <TAB> <TAB> age = now - last_update <TAB> <TAB> if self._call_count > self.ctl or age > self.ttl: <TAB> <TAB> <TAB> self._call_count = 0 <TAB> <TAB> <TAB> raise AttributeError <TAB> <TAB> if self.ctl: <TAB> <TAB> <TAB> self._call_count += 1 <TAB> <TAB> return value <TAB> except (KeyError, AttributeError): <TAB> <TAB> value = func(*args) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.cache[args] = (value, now) <TAB> <TAB> return value <TAB> except TypeError: <TAB> <TAB> return func(*args)",false,if value :,if value is not None :,0.09,0.0
"def _get_md_bg_color_down(self): <TAB> t = self.theme_cls <TAB> c = self.md_bg_color  # Default to no change on touch <TAB> # Material design specifies using darker hue when on Dark theme <TAB> if t.theme_style == ""Dark"": <TAB> <TAB> if self.md_bg_color == t.primary_color: <TAB> <TAB> <TAB> c = t.primary_dark <TAB> <TAB> elif self.md_bg_color == t.accent_color: <TAB> <TAB> <TAB> c = t.accent_dark <TAB> return c",true,elif self . md_bg_color == t . accent_color :,elif self . md_bg_color == t . accent_color :,0.75,0.0
def _init_table_h(): <TAB> _table_h = [] <TAB> for i in range(256): <TAB> <TAB> part_l = i <TAB> <TAB> part_h = 0 <TAB> <TAB> for j in range(8): <TAB> <TAB> <TAB> rflag = part_l & 1 <TAB> <TAB> <TAB> part_l >>= 1 <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> part_l |= 1 << 31 <TAB> <TAB> <TAB> part_h >>= 1 <TAB> <TAB> <TAB> if rflag: <TAB> <TAB> <TAB> <TAB> part_h ^= 0xD8000000 <TAB> <TAB> _table_h.append(part_h) <TAB> return _table_h,false,if part_h & 1 :,if j == 0 :,0.28,0.0
"def migrate_Stats(self): <TAB> for old_obj in self.session_old.query(self.model_from[""Stats""]): <TAB> <TAB> if not old_obj.summary: <TAB> <TAB> <TAB> self.entries_count[""Stats""] -= 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> new_obj = self.model_to[""Stats""]() <TAB> <TAB> for key in new_obj.__table__.columns._data.keys(): <TAB> <TAB> <TAB> if key not in old_obj.__table__.columns: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> setattr(new_obj, key, getattr(old_obj, key)) <TAB> <TAB> self.session_new.add(new_obj)",true,if key not in old_obj . __table__ . columns :,if key not in old_obj . __table__ . columns :,0.75,0.0
"def get_in_turn_repetition(pred, is_cn=False): <TAB> """"""Get in-turn repetition."""""" <TAB> if len(pred) == 0: <TAB> <TAB> return 1.0 <TAB> if isinstance(pred[0], str): <TAB> <TAB> pred = [tok.lower() for tok in pred] <TAB> <TAB> if is_cn: <TAB> <TAB> <TAB> pred = """".join(pred) <TAB> tri_grams = set() <TAB> for i in range(len(pred) - 2): <TAB> <TAB> tri_gram = tuple(pred[i : i + 3]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return 1.0 <TAB> <TAB> tri_grams.add(tri_gram) <TAB> return 0.0",true,if tri_gram in tri_grams :,if tri_gram in tri_grams :,0.75,0.0
"def translate(): <TAB> assert Lex.next() is AttributeList <TAB> reader.read()  # Discard attribute list from reader. <TAB> attrs = {} <TAB> d = AttributeList.match.groupdict() <TAB> for k, v in d.items(): <TAB> <TAB> if v is not None: <TAB> <TAB> <TAB> if k == ""attrlist"": <TAB> <TAB> <TAB> <TAB> v = subs_attrs(v) <TAB> <TAB> <TAB> <TAB> if v: <TAB> <TAB> <TAB> <TAB> <TAB> parse_attributes(v, attrs) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> AttributeList.attrs[k] = v <TAB> AttributeList.subs(attrs) <TAB> AttributeList.attrs.update(attrs)",true,"if k == ""attrlist"" :","if k == ""attrlist"" :",0.75,0.0
"def _parse(self, engine): <TAB> """"""Parse the layer."""""" <TAB> if isinstance(self.args, dict): <TAB> <TAB> if ""axis"" in self.args: <TAB> <TAB> <TAB> self.axis = engine.evaluate(self.args[""axis""], recursive=True) <TAB> <TAB> <TAB> if not isinstance(self.axis, int): <TAB> <TAB> <TAB> <TAB> raise ParsingError('""axis"" must be an integer.') <TAB> <TAB> if ""momentum"" in self.args: <TAB> <TAB> <TAB> self.momentum = engine.evaluate(self.args[""momentum""], recursive=True) <TAB> <TAB> <TAB> if not isinstance(self.momentum, (int, float)): <TAB> <TAB> <TAB> <TAB> raise ParsingError('""momentum"" must be numeric.')",true,"if not isinstance ( self . axis , int ) :","if not isinstance ( self . axis , int ) :",0.75,0.0
"def __getattr__(self, attrname): <TAB> if attrname in (""visamp"", ""visamperr"", ""visphi"", ""visphierr""): <TAB> <TAB> return ma.masked_array(self.__dict__[""_"" + attrname], mask=self.flag) <TAB> elif attrname in (""cflux"", ""cfluxerr""): <TAB> <TAB> if self.__dict__[""_"" + attrname] != None: <TAB> <TAB> <TAB> return ma.masked_array(self.__dict__[""_"" + attrname], mask=self.flag) <TAB> <TAB> else: <TAB> <TAB> <TAB> return None <TAB> else: <TAB> <TAB> raise AttributeError(attrname)",true,"if self . __dict__ [ ""_"" + attrname ] != None :","if self . __dict__ [ ""_"" + attrname ] != None :",0.75,0.0
"def draw(self, context): <TAB> layout = self.layout <TAB> presets.draw_presets_ops(layout, context=context) <TAB> for category in presets.get_category_names(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if category in preset_category_menus: <TAB> <TAB> <TAB> <TAB> class_name = preset_category_menus[category].__name__ <TAB> <TAB> <TAB> <TAB> layout.menu(class_name)",false,if category in preset_category_menus :,if category is not None :,0.18,0.0
"def __setitem__(self, key, value): <TAB> if isinstance(value, (tuple, list)): <TAB> <TAB> info, reference = value <TAB> <TAB> if info not in self._reverse_infos: <TAB> <TAB> <TAB> self._reverse_infos[info] = len(self._infos) <TAB> <TAB> <TAB> self._infos.append(info) <TAB> <TAB> if reference not in self._reverse_references: <TAB> <TAB> <TAB> self._reverse_references[reference] = len(self._references) <TAB> <TAB> <TAB> self._references.append(reference) <TAB> <TAB> self._trails[key] = ""%d,%d"" % ( <TAB> <TAB> <TAB> self._reverse_infos[info], <TAB> <TAB> <TAB> self._reverse_references[reference], <TAB> <TAB> ) <TAB> else: <TAB> <TAB> raise Exception(""unsupported type '%s'"" % type(value))",true,if reference not in self . _reverse_references :,if reference not in self . _reverse_references :,0.75,0.0
"def format_bpe_text(symbols, delimiter=b""@@""): <TAB> """"""Convert a sequence of bpe words into sentence."""""" <TAB> words = [] <TAB> word = b"""" <TAB> if isinstance(symbols, str): <TAB> <TAB> symbols = symbols.encode() <TAB> delimiter_len = len(delimiter) <TAB> for symbol in symbols: <TAB> <TAB> if len(symbol) >= delimiter_len and symbol[-delimiter_len:] == delimiter: <TAB> <TAB> <TAB> word += symbol[:-delimiter_len] <TAB> <TAB> else:  # end of a word <TAB> <TAB> <TAB> word += symbol <TAB> <TAB> <TAB> words.append(word) <TAB> <TAB> <TAB> word = b"""" <TAB> return b"" "".join(words)",true,if len ( symbol ) >= delimiter_len and symbol [ - delimiter_len : ] == delimiter :,if len ( symbol ) >= delimiter_len and symbol [ - delimiter_len : ] == delimiter :,1.0,0.0
"def output_type(data, request, response): <TAB> accept = request.accept <TAB> if accept in ("""", ""*"", ""/""): <TAB> <TAB> handler = default or handlers and next(iter(handlers.values())) <TAB> else: <TAB> <TAB> handler = default <TAB> <TAB> accepted = [accept_quality(accept_type) for accept_type in accept.split("","")] <TAB> <TAB> accepted.sort(key=itemgetter(0)) <TAB> <TAB> for _quality, accepted_content_type in reversed(accepted): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> handler = handlers[accepted_content_type] <TAB> <TAB> <TAB> <TAB> break <TAB> if not handler: <TAB> <TAB> raise falcon.HTTPNotAcceptable(error) <TAB> response.content_type = handler.content_type <TAB> return handler(data, request=request, response=response)",false,if accepted_content_type in handlers :,if accepted_quality in supported_accepts :,0.29,0.0
"def _render_raw_list(bytes_items): <TAB> flatten_items = [] <TAB> for item in bytes_items: <TAB> <TAB> if item is None: <TAB> <TAB> <TAB> flatten_items.append(b"""") <TAB> <TAB> elif isinstance(item, bytes): <TAB> <TAB> <TAB> flatten_items.append(item) <TAB> <TAB> elif isinstance(item, int): <TAB> <TAB> <TAB> flatten_items.append(str(item).encode()) <TAB> <TAB> elif isinstance(item, list): <TAB> <TAB> <TAB> flatten_items.append(_render_raw_list(item)) <TAB> return b""\n"".join(flatten_items)",false,"elif isinstance ( item , int ) :","elif isinstance ( item , bytes ) :",0.53,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.set_mime_type(d.getVarInt32()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 16: <TAB> <TAB> <TAB> self.set_quality(d.getVarInt32()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0: <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 8 :,if tt == 8 :,0.75,0.0
"def delete(self, waiters): <TAB> # Delete flow. <TAB> msgs = self.ofctl.get_all_flow(waiters) <TAB> for msg in msgs: <TAB> <TAB> for stats in msg.body: <TAB> <TAB> <TAB> vlan_id = VlanRouter._cookie_to_id(REST_VLANID, stats.cookie) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.ofctl.delete_flow(stats) <TAB> assert len(self.packet_buffer) == 0",false,if vlan_id == self . vlan_id :,if vlan_id == REST_VLANID :,0.09,0.0
def missing_push_allowance(push_allowances: List[PushAllowance]) -> bool: <TAB> for push_allowance in push_allowances: <TAB> <TAB> # a null databaseId indicates this is not a GitHub App. <TAB> <TAB> if push_allowance.actor.databaseId is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> if str(push_allowance.actor.databaseId) == str(app_config.GITHUB_APP_ID): <TAB> <TAB> <TAB> return False <TAB> return True,true,if str ( push_allowance . actor . databaseId ) == str ( app_config . GITHUB_APP_ID ) :,if str ( push_allowance . actor . databaseId ) == str ( app_config . GITHUB_APP_ID ) :,1.0,0.0
"def _cluster_page(self, htmlpage): <TAB> template_cluster, preferred = _CLUSTER_NA, None <TAB> if self.clustering: <TAB> <TAB> self.clustering.add_page(htmlpage) <TAB> <TAB> if self.clustering.is_fit: <TAB> <TAB> <TAB> clt = self.clustering.classify(htmlpage) <TAB> <TAB> <TAB> if clt != -1: <TAB> <TAB> <TAB> <TAB> template_cluster = preferred = self.template_names[clt] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> template_cluster = _CLUSTER_OUTLIER <TAB> return template_cluster, preferred",true,if self . clustering . is_fit :,if self . clustering . is_fit :,0.75,0.0
"def readlines(self, size=-1): <TAB> if self._nbr == self._size: <TAB> <TAB> return [] <TAB> # leave all additional logic to our readline method, we just check the size <TAB> out = [] <TAB> nbr = 0 <TAB> while True: <TAB> <TAB> line = self.readline() <TAB> <TAB> if not line: <TAB> <TAB> <TAB> break <TAB> <TAB> out.append(line) <TAB> <TAB> if size > -1: <TAB> <TAB> <TAB> nbr += len(line) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> # END handle size constraint <TAB> # END readline loop <TAB> return out",false,if nbr > size :,if nbr >= size :,0.33,0.0
"def post_mortem(t=None): <TAB> # handling the default <TAB><IF-STMT> <TAB> <TAB> # sys.exc_info() returns (type, value, traceback) if an exception is <TAB> <TAB> # being handled, otherwise it returns None <TAB> <TAB> t = sys.exc_info()[2] <TAB> <TAB> if t is None: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""A valid traceback must be passed if no exception is being handled."" <TAB> <TAB> <TAB> ) <TAB> p = BPdb() <TAB> p.reset() <TAB> p.interaction(None, t)",true,if t is None :,if t is None :,0.75,0.0
"def fixup(m): <TAB> txt = m.group(0) <TAB> if txt[:2] == ""&#"": <TAB> <TAB> # character reference <TAB> <TAB> try: <TAB> <TAB> <TAB> if txt[:3] == ""&#x"": <TAB> <TAB> <TAB> <TAB> return unichr(int(txt[3:-1], 16)) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return unichr(int(txt[2:-1])) <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> pass <TAB> else: <TAB> <TAB> # named entity <TAB> <TAB> try: <TAB> <TAB> <TAB> txt = unichr(htmlentitydefs.name2codepoint[txt[1:-1]]) <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> pass <TAB> return txt  # leave as is",true,"if txt [ : 3 ] == ""&#x"" :","if txt [ : 3 ] == ""&#x"" :",0.75,0.0
"def parse_converter_args(argstr: str) -> t.Tuple[t.Tuple, t.Dict[str, t.Any]]: <TAB> argstr += "","" <TAB> args = [] <TAB> kwargs = {} <TAB> for item in _converter_args_re.finditer(argstr): <TAB> <TAB> value = item.group(""stringval"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> value = item.group(""value"") <TAB> <TAB> value = _pythonize(value) <TAB> <TAB> if not item.group(""name""): <TAB> <TAB> <TAB> args.append(value) <TAB> <TAB> else: <TAB> <TAB> <TAB> name = item.group(""name"") <TAB> <TAB> <TAB> kwargs[name] = value <TAB> return tuple(args), kwargs",true,if value is None :,if value is None :,0.75,0.0
"def IT(cpu): <TAB> cc = cpu.instruction.cc <TAB> true_case = cpu._evaluate_conditional(cc) <TAB> # this is incredibly hacky--how else does capstone expose this? <TAB> # TODO: find a better way than string parsing the mnemonic -GR, 2017-07-13 <TAB> for c in cpu.instruction.mnemonic[1:]: <TAB> <TAB> if c == ""t"": <TAB> <TAB> <TAB> cpu._it_conditional.append(true_case) <TAB> <TAB> elif c == ""e"": <TAB> <TAB> <TAB> cpu._it_conditional.append(not true_case)",false,"if c == ""t"" :","elif c == ""e"" :",0.06,0.0
"def flatten(self): <TAB> # this is similar to fill_messages except it uses a list instead <TAB> # of a queue to place the messages in. <TAB> result = [] <TAB> channel = await self.messageable._get_channel() <TAB> self.channel = channel <TAB> while self._get_retrieve(): <TAB> <TAB> data = await self._retrieve_messages(self.retrieve) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.limit = 0  # terminate the infinite loop <TAB> <TAB> if self.reverse: <TAB> <TAB> <TAB> data = reversed(data) <TAB> <TAB> if self._filter: <TAB> <TAB> <TAB> data = filter(self._filter, data) <TAB> <TAB> for element in data: <TAB> <TAB> <TAB> result.append(self.state.create_message(channel=channel, data=element)) <TAB> return result",false,if len ( data ) < 100 :,if len ( data ) < self . limit :,0.41,0.0
"def _get_beta_accumulators(self): <TAB> with tf.init_scope(): <TAB> <TAB> if tf.executing_eagerly(): <TAB> <TAB> <TAB> graph = None <TAB> <TAB> else: <TAB> <TAB> <TAB> graph = tf.get_default_graph() <TAB> <TAB> return ( <TAB> <TAB> <TAB> self._get_non_slot_variable(""beta1_power"", graph=graph), <TAB> <TAB> <TAB> self._get_non_slot_variable(""beta2_power"", graph=graph), <TAB> <TAB> )",true,if tf . executing_eagerly ( ) :,if tf . executing_eagerly ( ) :,0.75,0.0
"def prefixed(self, prefix: _StrType) -> typing.Iterator[""Env""]: <TAB> """"""Context manager for parsing envvars with a common prefix."""""" <TAB> try: <TAB> <TAB> old_prefix = self._prefix <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._prefix = prefix <TAB> <TAB> else: <TAB> <TAB> <TAB> self._prefix = f""{old_prefix}{prefix}"" <TAB> <TAB> yield self <TAB> finally: <TAB> <TAB> # explicitly reset the stored prefix on completion and exceptions <TAB> <TAB> self._prefix = None <TAB> self._prefix = old_prefix",false,if old_prefix is None :,if prefix is not None :,0.19,0.0
"def decode_content(self): <TAB> """"""Return the best possible representation of the response body."""""" <TAB> ct = self.headers.get(""content-type"") <TAB> if ct: <TAB> <TAB> ct, options = parse_options_header(ct) <TAB> <TAB> charset = options.get(""charset"") <TAB> <TAB> if ct in JSON_CONTENT_TYPES: <TAB> <TAB> <TAB> return self.json(charset) <TAB> <TAB> elif ct.startswith(""text/""): <TAB> <TAB> <TAB> return self.text(charset) <TAB> <TAB> elif ct == FORM_URL_ENCODED: <TAB> <TAB> <TAB> return parse_qsl(self.content.decode(charset), keep_blank_values=True) <TAB> return self.content",false,"elif ct . startswith ( ""text/"" ) :",elif ct == FORM_URL_ENCODED :,0.03,0.0
"def test_incrementaldecoder(self): <TAB> UTF8Writer = codecs.getwriter(""utf-8"") <TAB> for sizehint in [None, -1] + list(range(1, 33)) + [64, 128, 256, 512, 1024]: <TAB> <TAB> istream = BytesIO(self.tstring[0]) <TAB> <TAB> ostream = UTF8Writer(BytesIO()) <TAB> <TAB> decoder = self.incrementaldecoder() <TAB> <TAB> while 1: <TAB> <TAB> <TAB> data = istream.read(sizehint) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> u = decoder.decode(data) <TAB> <TAB> <TAB> <TAB> ostream.write(u) <TAB> <TAB> self.assertEqual(ostream.getvalue(), self.tstring[1])",true,if not data :,if not data :,0.75,0.0
"def delete_all(path): <TAB> ppath = os.getcwd() <TAB> os.chdir(path) <TAB> for fn in glob.glob(""*""): <TAB> <TAB> fn_full = os.path.join(path, fn) <TAB> <TAB> if os.path.isdir(fn): <TAB> <TAB> <TAB> delete_all(fn_full) <TAB> <TAB> elif fn.endswith("".png""): <TAB> <TAB> <TAB> os.remove(fn_full) <TAB> <TAB> elif fn.endswith("".md""): <TAB> <TAB> <TAB> os.remove(fn_full) <TAB> <TAB> elif DELETE_ALL_OLD: <TAB> <TAB> <TAB> os.remove(fn_full) <TAB> os.chdir(ppath) <TAB> os.rmdir(path)",false,if os . path . isdir ( fn ) :,elif delete_ALL_OLD :,0.01,0.0
"def _delete_reason(self): <TAB> for i in range(_lib.X509_REVOKED_get_ext_count(self._revoked)): <TAB> <TAB> ext = _lib.X509_REVOKED_get_ext(self._revoked, i) <TAB> <TAB> obj = _lib.X509_EXTENSION_get_object(ext) <TAB> <TAB> if _lib.OBJ_obj2nid(obj) == _lib.NID_crl_reason: <TAB> <TAB> <TAB> _lib.X509_EXTENSION_free(ext) <TAB> <TAB> <TAB> _lib.X509_REVOKED_delete_ext(self._revoked, i) <TAB> <TAB> <TAB> break",true,if _lib . OBJ_obj2nid ( obj ) == _lib . NID_crl_reason :,if _lib . OBJ_obj2nid ( obj ) == _lib . NID_crl_reason :,1.0,0.0
"def hexcmp(x, y): <TAB> try: <TAB> <TAB> a = int(x, 16) <TAB> <TAB> b = int(y, 16) <TAB> <TAB> if a < b: <TAB> <TAB> <TAB> return -1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return 1 <TAB> <TAB> return 0 <TAB> except: <TAB> <TAB> return cmp(x, y)",true,if a > b :,if a > b :,0.75,0.0
"def get_indentation_count(view, start): <TAB> indent_count = 0 <TAB> i = start - 1 <TAB> while i > 0: <TAB> <TAB> ch = view.substr(i) <TAB> <TAB> scope = view.scope_name(i) <TAB> <TAB> # Skip preprocessors, strings, characaters and comments <TAB> <TAB> if ""string.quoted"" in scope or ""comment"" in scope or ""preprocessor"" in scope: <TAB> <TAB> <TAB> extent = view.extract_scope(i) <TAB> <TAB> <TAB> i = extent.a - 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> else: <TAB> <TAB> <TAB> i -= 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> indent_count -= 1 <TAB> <TAB> elif ch == ""{"": <TAB> <TAB> <TAB> indent_count += 1 <TAB> return indent_count",true,"if ch == ""}"" :","if ch == ""}"" :",0.75,0.0
"def set(self, name, value, ex=None, px=None, nx=False, xx=False): <TAB> if ( <TAB> <TAB> (not nx and not xx) <TAB> <TAB> or (nx and self._db.get(name, None) is None) <TAB> <TAB> or (xx and not self._db.get(name, None) is None) <TAB> ): <TAB> <TAB> if ex > 0: <TAB> <TAB> <TAB> self._db.expire(name, datetime.now() + timedelta(seconds=ex)) <TAB> <TAB> elif px > 0: <TAB> <TAB> <TAB> self._db.expire(name, datetime.now() + timedelta(milliseconds=px)) <TAB> <TAB> self._db[name] = str(value) <TAB> <TAB> return True <TAB> else: <TAB> <TAB> return None",true,elif px > 0 :,elif px > 0 :,0.75,0.0
"def _get_between(content, start, end=None): <TAB> should_yield = False <TAB> for line in content.split(""\n""): <TAB> <TAB> if start in line: <TAB> <TAB> <TAB> should_yield = True <TAB> <TAB> <TAB> continue <TAB> <TAB> if end and end in line: <TAB> <TAB> <TAB> return <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield line.strip().split("" "")[0]",false,if should_yield and line :,if should_yield :,0.07,0.0
"def iter_event_handlers( <TAB> self, <TAB> resource: resources_.Resource, <TAB> event: bodies.RawEvent, ) -> Iterator[handlers.ResourceWatchingHandler]: <TAB> warnings.warn( <TAB> <TAB> ""SimpleRegistry.iter_event_handlers() is deprecated; use "" <TAB> <TAB> ""ResourceWatchingRegistry.iter_handlers()."", <TAB> <TAB> DeprecationWarning, <TAB> ) <TAB> cause = _create_watching_cause(resource, event) <TAB> for handler in self._handlers: <TAB> <TAB> if not isinstance(handler, handlers.ResourceWatchingHandler): <TAB> <TAB> <TAB> pass <TAB> <TAB> elif registries.match(handler=handler, cause=cause, ignore_fields=True): <TAB> <TAB> <TAB> yield handler",false,"if not isinstance ( handler , handlers . ResourceWatchingHandler ) :","elif registries . match ( handler = handler , cause = cause , ignore_fields = True ) :",0.03,0.0
"def __enter__(self): <TAB> if log_timer: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.logger.debug(""%s starting"" % self.name) <TAB> <TAB> else: <TAB> <TAB> <TAB> print((""[%s starting]..."" % self.name)) <TAB> <TAB> self.tstart = time.time()",false,if self . logger :,if self . debug :,0.39,0.0
"def _handle_errors(errors): <TAB> """"""Log out and possibly reraise errors during import."""""" <TAB> if not errors: <TAB> <TAB> return <TAB> log_all = True  # pylint: disable=unused-variable <TAB> err_msg = ""T2T: skipped importing {num_missing} data_generators modules."" <TAB> print(err_msg.format(num_missing=len(errors))) <TAB> for module, err in errors: <TAB> <TAB> err_str = str(err) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(""Did not import module: %s; Cause: %s"" % (module, err_str)) <TAB> <TAB> if not _is_import_err_msg(err_str, module): <TAB> <TAB> <TAB> print(""From module %s"" % module) <TAB> <TAB> <TAB> raise err",true,if log_all :,if log_all :,0.53,0.0
"def _ungroup(sequence, groups=None): <TAB> for v in sequence: <TAB> <TAB> if isinstance(v, (list, tuple)): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> groups.append(list(_ungroup(v, groups=None))) <TAB> <TAB> <TAB> for v in _ungroup(v, groups): <TAB> <TAB> <TAB> <TAB> yield v <TAB> <TAB> else: <TAB> <TAB> <TAB> yield v",true,if groups is not None :,if groups is not None :,0.75,0.0
def run(self): <TAB> while not self.completed: <TAB> <TAB> if self.block: <TAB> <TAB> <TAB> time.sleep(self.period) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._completed.wait(self.period) <TAB> <TAB> self.counter += 1 <TAB> <TAB> try: <TAB> <TAB> <TAB> self.callback(self.counter) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> self.stop() <TAB> <TAB> if self.timeout is not None: <TAB> <TAB> <TAB> dt = time.time() - self._start_time <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.stop() <TAB> <TAB> if self.counter == self.count: <TAB> <TAB> <TAB> self.stop(),false,if dt > self . timeout :,if dt < self . timeout :,0.5,0.0
"def dont_let_stderr_buffer(): <TAB> while True: <TAB> <TAB> line = context.daemon.stderr.readline() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> if DEAD_DEPLOYD_WORKER_MESSAGE.encode(""utf-8"") in line: <TAB> <TAB> <TAB> context.num_workers_crashed += 1 <TAB> <TAB> print(f""deployd stderr: {line}"")",true,if not line :,if not line :,0.75,0.0
"def mergeHiLo(self, x_stats): <TAB> """"""Merge the highs and lows of another accumulator into myself."""""" <TAB> if x_stats.firsttime is not None: <TAB> <TAB> if self.firsttime is None or x_stats.firsttime < self.firsttime: <TAB> <TAB> <TAB> self.firsttime = x_stats.firsttime <TAB> <TAB> <TAB> self.first = x_stats.first <TAB> if x_stats.lasttime is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.lasttime = x_stats.lasttime <TAB> <TAB> <TAB> self.last = x_stats.last",false,if self . lasttime is None or x_stats . lasttime >= self . lasttime :,if self . lasttime is None or x_stats . lasttime < self . lasttime :,0.58,0.0
"def test_rlimit_get(self): <TAB> import resource <TAB> p = psutil.Process(os.getpid()) <TAB> names = [x for x in dir(psutil) if x.startswith(""RLIMIT"")] <TAB> assert names <TAB> for name in names: <TAB> <TAB> value = getattr(psutil, name) <TAB> <TAB> self.assertGreaterEqual(value, 0) <TAB> <TAB> if name in dir(resource): <TAB> <TAB> <TAB> self.assertEqual(value, getattr(resource, name)) <TAB> <TAB> <TAB> self.assertEqual(p.rlimit(value), resource.getrlimit(value)) <TAB> <TAB> else: <TAB> <TAB> <TAB> ret = p.rlimit(value) <TAB> <TAB> <TAB> self.assertEqual(len(ret), 2) <TAB> <TAB> <TAB> self.assertGreaterEqual(ret[0], -1) <TAB> <TAB> <TAB> self.assertGreaterEqual(ret[1], -1)",true,if name in dir ( resource ) :,if name in dir ( resource ) :,0.75,0.0
"def _calculate_writes_for_built_in_indices(self, entity): <TAB> writes = 0 <TAB> for prop_name in entity.keys(): <TAB> <TAB> if not prop_name in entity.unindexed_properties(): <TAB> <TAB> <TAB> prop_vals = entity[prop_name] <TAB> <TAB> <TAB> if isinstance(prop_vals, (list)): <TAB> <TAB> <TAB> <TAB> num_prop_vals = len(prop_vals) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> num_prop_vals = 1 <TAB> <TAB> <TAB> writes += 2 * num_prop_vals <TAB> return writes",true,"if isinstance ( prop_vals , ( list ) ) :","if isinstance ( prop_vals , ( list ) ) :",0.75,0.0
"def check_value_check(self, x_data, t_data, use_cudnn): <TAB> x = chainer.Variable(x_data) <TAB> t = chainer.Variable(t_data) <TAB> with chainer.using_config(""use_cudnn"", use_cudnn): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # Check if it throws nothing <TAB> <TAB> <TAB> functions.softmax_cross_entropy( <TAB> <TAB> <TAB> <TAB> x, t, enable_double_backprop=self.enable_double_backprop <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> with self.assertRaises(ValueError): <TAB> <TAB> <TAB> <TAB> functions.softmax_cross_entropy( <TAB> <TAB> <TAB> <TAB> <TAB> x, t, enable_double_backprop=self.enable_double_backprop <TAB> <TAB> <TAB> <TAB> )",false,if self . valid :,if use_cudnn :,0.04,0.0
"def get_note_title_file(note): <TAB> mo = note_title_re.match(note.get(""content"", """")) <TAB> if mo: <TAB> <TAB> fn = mo.groups()[0] <TAB> <TAB> fn = fn.replace("" "", ""_"") <TAB> <TAB> fn = fn.replace(""/"", ""_"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return """" <TAB> <TAB> if isinstance(fn, str): <TAB> <TAB> <TAB> fn = unicode(fn, ""utf-8"") <TAB> <TAB> else: <TAB> <TAB> <TAB> fn = unicode(fn) <TAB> <TAB> if note_markdown(note): <TAB> <TAB> <TAB> fn += "".mkdn"" <TAB> <TAB> else: <TAB> <TAB> <TAB> fn += "".txt"" <TAB> <TAB> return fn <TAB> else: <TAB> <TAB> return """"",true,if not fn :,if not fn :,0.75,0.0
"def _parseparam(s): <TAB> plist = [] <TAB> while s[:1] == "";"": <TAB> <TAB> s = s[1:] <TAB> <TAB> end = s.find("";"") <TAB> <TAB> while end > 0 and (s.count('""', 0, end) - s.count('\\""', 0, end)) % 2: <TAB> <TAB> <TAB> end = s.find("";"", end + 1) <TAB> <TAB> if end < 0: <TAB> <TAB> <TAB> end = len(s) <TAB> <TAB> f = s[:end] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> i = f.index(""="") <TAB> <TAB> <TAB> f = f[:i].strip().lower() + ""="" + f[i + 1 :].strip() <TAB> <TAB> plist.append(f.strip()) <TAB> <TAB> s = s[end:] <TAB> return plist",true,"if ""="" in f :","if ""="" in f :",0.75,0.0
"def doDir(elem): <TAB> for child in elem.childNodes: <TAB> <TAB> if not isinstance(child, minidom.Element): <TAB> <TAB> <TAB> continue <TAB> <TAB> if child.tagName == ""Directory"": <TAB> <TAB> <TAB> doDir(child) <TAB> <TAB> elif child.tagName == ""Component"": <TAB> <TAB> <TAB> for grandchild in child.childNodes: <TAB> <TAB> <TAB> <TAB> if not isinstance(grandchild, minidom.Element): <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> if grandchild.tagName != ""File"": <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> files.add(grandchild.getAttribute(""Source"").replace(os.sep, ""/""))",true,"if grandchild . tagName != ""File"" :","if grandchild . tagName != ""File"" :",0.75,0.0
"def date_to_format(value, target_format): <TAB> """"""Convert date to specified format"""""" <TAB> if target_format == str: <TAB> <TAB> if isinstance(value, datetime.date): <TAB> <TAB> <TAB> ret = value.strftime(""%d/%m/%y"") <TAB> <TAB> elif isinstance(value, datetime.datetime): <TAB> <TAB> <TAB> ret = value.strftime(""%d/%m/%y"") <TAB> <TAB> elif isinstance(value, datetime.time): <TAB> <TAB> <TAB> ret = value.strftime(""%H:%M:%S"") <TAB> else: <TAB> <TAB> ret = value <TAB> return ret",false,"if isinstance ( value , datetime . date ) :","elif isinstance ( value , datetime . time ) :",0.28,0.0
"def __listingColumns(self): <TAB> columns = [] <TAB> for name in self.__getColumns(): <TAB> <TAB> definition = column(name) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> IECore.msg( <TAB> <TAB> <TAB> <TAB> IECore.Msg.Level.Error, <TAB> <TAB> <TAB> <TAB> ""GafferImageUI.CatalogueUI"", <TAB> <TAB> <TAB> <TAB> ""No column registered with name '%s'"" % name, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance(definition, IconColumn): <TAB> <TAB> <TAB> c = GafferUI.PathListingWidget.IconColumn(definition.title(), """", name) <TAB> <TAB> else: <TAB> <TAB> <TAB> c = GafferUI.PathListingWidget.StandardColumn(definition.title(), name) <TAB> <TAB> columns.append(c) <TAB> return columns",false,if not definition :,if definition is None :,0.05,0.0
"def metrics_to_scalars(self, metrics): <TAB> new_metrics = {} <TAB> for k, v in metrics.items(): <TAB> <TAB> if isinstance(v, torch.Tensor): <TAB> <TAB> <TAB> v = v.item() <TAB> <TAB> if isinstance(v, dict): <TAB> <TAB> <TAB> v = self.metrics_to_scalars(v) <TAB> <TAB> new_metrics[k] = v <TAB> return new_metrics",false,"if isinstance ( v , torch . Tensor ) :","if isinstance ( v , dict ) :",0.23,0.0
"def start(self, connection): <TAB> try: <TAB> <TAB> if self.client_name: <TAB> <TAB> <TAB> creds = gssapi.Credentials(name=gssapi.Name(self.client_name)) <TAB> <TAB> else: <TAB> <TAB> <TAB> creds = None <TAB> <TAB> hostname = self.get_hostname(connection) <TAB> <TAB> name = gssapi.Name( <TAB> <TAB> <TAB> b""@"".join([self.service, hostname]), gssapi.NameType.hostbased_service <TAB> <TAB> ) <TAB> <TAB> context = gssapi.SecurityContext(name=name, creds=creds) <TAB> <TAB> return context.step(None) <TAB> except gssapi.raw.misc.GSSError: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return NotImplemented <TAB> <TAB> else: <TAB> <TAB> <TAB> raise",false,if self . fail_soft :,if self . raise_on_error :,0.39,0.0
"def nanmax(self, axis=None, dtype=None, keepdims=None): <TAB> ret = self._reduction( <TAB> <TAB> ""nanmax"", axis=axis, dtype=dtype, keepdims=keepdims, todense=True <TAB> ) <TAB> if not issparse(ret): <TAB> <TAB> if get_array_module(ret).isscalar(ret): <TAB> <TAB> <TAB> return ret <TAB> <TAB> xps = get_sparse_module(self.spmatrix) <TAB> <TAB> ret = SparseNDArray(xps.csr_matrix(ret)) <TAB> <TAB> return ret <TAB> return ret",true,if get_array_module ( ret ) . isscalar ( ret ) :,if get_array_module ( ret ) . isscalar ( ret ) :,1.0,0.0
"def utterance_to_sample(query_data, tagging_scheme, language): <TAB> tokens, tags = [], [] <TAB> current_length = 0 <TAB> for chunk in query_data: <TAB> <TAB> chunk_tokens = tokenize(chunk[TEXT], language) <TAB> <TAB> tokens += [ <TAB> <TAB> <TAB> Token(t.value, current_length + t.start, current_length + t.end) <TAB> <TAB> <TAB> for t in chunk_tokens <TAB> <TAB> ] <TAB> <TAB> current_length += len(chunk[TEXT]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tags += negative_tagging(len(chunk_tokens)) <TAB> <TAB> else: <TAB> <TAB> <TAB> tags += positive_tagging( <TAB> <TAB> <TAB> <TAB> tagging_scheme, chunk[SLOT_NAME], len(chunk_tokens) <TAB> <TAB> <TAB> ) <TAB> return {TOKENS: tokens, TAGS: tags}",false,if SLOT_NAME not in chunk :,if tagging_scheme == TAG_UNUSED :,0.03,0.0
"def use_index( <TAB> self, term: Union[str, Index], *terms: Union[str, Index] ) -> ""QueryBuilder"": <TAB> for t in (term, *terms): <TAB> <TAB> if isinstance(t, Index): <TAB> <TAB> <TAB> self._use_indexes.append(t) <TAB> <TAB> elif isinstance(t, str): <TAB> <TAB> <TAB> self._use_indexes.append(Index(t))",true,"elif isinstance ( t , str ) :","elif isinstance ( t , str ) :",0.75,0.0
"def reconfigServiceWithBuildbotConfig(self, new_config): <TAB> if new_config.manhole != self.manhole: <TAB> <TAB> if self.manhole: <TAB> <TAB> <TAB> yield self.manhole.disownServiceParent() <TAB> <TAB> <TAB> self.manhole = None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.manhole = new_config.manhole <TAB> <TAB> <TAB> yield self.manhole.setServiceParent(self) <TAB> # chain up <TAB> yield service.ReconfigurableServiceMixin.reconfigServiceWithBuildbotConfig( <TAB> <TAB> self, new_config <TAB> )",true,if new_config . manhole :,if new_config . manhole :,0.75,0.0
"def cleanup_folder(target_folder): <TAB> for file in os.listdir(target_folder): <TAB> <TAB> file_path = os.path.join(target_folder, file) <TAB> <TAB> try: <TAB> <TAB> <TAB> if os.path.isfile(file_path): <TAB> <TAB> <TAB> <TAB> os.remove(file_path) <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> logging.error(e)",true,if os . path . isfile ( file_path ) :,if os . path . isfile ( file_path ) :,0.75,0.0
"def to_key(literal_or_identifier): <TAB> """"""returns string representation of this object"""""" <TAB> if literal_or_identifier[""type""] == ""Identifier"": <TAB> <TAB> return literal_or_identifier[""name""] <TAB> elif literal_or_identifier[""type""] == ""Literal"": <TAB> <TAB> k = literal_or_identifier[""value""] <TAB> <TAB> if isinstance(k, float): <TAB> <TAB> <TAB> return unicode(float_repr(k)) <TAB> <TAB> elif ""regex"" in literal_or_identifier: <TAB> <TAB> <TAB> return compose_regex(k) <TAB> <TAB> elif isinstance(k, bool): <TAB> <TAB> <TAB> return ""true"" if k else ""false"" <TAB> <TAB> elif k is None: <TAB> <TAB> <TAB> return ""null"" <TAB> <TAB> else: <TAB> <TAB> <TAB> return unicode(k)",false,"if isinstance ( k , float ) :",elif k is None :,0.02,0.0
"def decompile(decompiler): <TAB> for pos, next_pos, opname, arg in decompiler.instructions: <TAB> <TAB> if pos in decompiler.targets: <TAB> <TAB> <TAB> decompiler.process_target(pos) <TAB> <TAB> method = getattr(decompiler, opname, None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> throw(DecompileError(""Unsupported operation: %s"" % opname)) <TAB> <TAB> decompiler.pos = pos <TAB> <TAB> decompiler.next_pos = next_pos <TAB> <TAB> x = method(*arg) <TAB> <TAB> if x is not None: <TAB> <TAB> <TAB> decompiler.stack.append(x)",true,if method is None :,if method is None :,0.75,0.0
"def shutdown(self, timeout, callback=None): <TAB> logger.debug(""background worker got shutdown request"") <TAB> with self._lock: <TAB> <TAB> if self.is_alive: <TAB> <TAB> <TAB> self._queue.put_nowait(_TERMINATOR) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self._wait_shutdown(timeout, callback) <TAB> <TAB> self._thread = None <TAB> <TAB> self._thread_for_pid = None <TAB> logger.debug(""background worker shut down"")",false,if timeout > 0.0 :,if callback :,0.04,0.0
"def getDOMImplementation(features=None): <TAB> if features: <TAB> <TAB> if isinstance(features, str): <TAB> <TAB> <TAB> features = domreg._parse_feature_string(features) <TAB> <TAB> for f, v in features: <TAB> <TAB> <TAB> if not Document.implementation.hasFeature(f, v): <TAB> <TAB> <TAB> <TAB> return None <TAB> return Document.implementation",true,"if isinstance ( features , str ) :","if isinstance ( features , str ) :",0.75,0.0
"def validate_subevent(self, subevent): <TAB> if self.context[""event""].has_subevents: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValidationError(""You need to set a subevent."") <TAB> <TAB> if subevent.event != self.context[""event""]: <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> ""The specified subevent does not belong to this event."" <TAB> <TAB> <TAB> ) <TAB> elif subevent: <TAB> <TAB> raise ValidationError(""You cannot set a subevent for this event."") <TAB> return subevent",false,if not subevent :,if subevent :,0.1,0.0
"def einsum(job_id, idx, einsum_expr, data_list): <TAB> _, all_parties = session_init(job_id, idx) <TAB> with SPDZ(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> x = FixedPointTensor.from_source(""x"", data_list[0]) <TAB> <TAB> <TAB> y = FixedPointTensor.from_source(""y"", all_parties[1]) <TAB> <TAB> else: <TAB> <TAB> <TAB> x = FixedPointTensor.from_source(""x"", all_parties[0]) <TAB> <TAB> <TAB> y = FixedPointTensor.from_source(""y"", data_list[1]) <TAB> <TAB> return x.einsum(y, einsum_expr).get()",true,if idx == 0 :,if idx == 0 :,0.75,0.0
"def slowSorted(qq): <TAB> ""Reference sort peformed by insertion using only <"" <TAB> rr = list() <TAB> for q in qq: <TAB> <TAB> i = 0 <TAB> <TAB> for i in range(len(rr)): <TAB> <TAB> <TAB> if q < rr[i]: <TAB> <TAB> <TAB> <TAB> rr.insert(i, q) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> rr.append(q) <TAB> return rr",true,if q < rr [ i ] :,if q < rr [ i ] :,0.75,0.0
"def _format_entry(entry, src): <TAB> if entry: <TAB> <TAB> result = [] <TAB> <TAB> for x in entry.split("",""): <TAB> <TAB> <TAB> x = x.strip() <TAB> <TAB> <TAB> if os.path.exists(os.path.join(src, x)): <TAB> <TAB> <TAB> <TAB> result.append(relpath(os.path.join(src, x), src)) <TAB> <TAB> <TAB> elif os.path.exists(x): <TAB> <TAB> <TAB> <TAB> result.append(relpath(os.path.abspath(x), src)) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise RuntimeError(""No entry script %s found"" % x) <TAB> <TAB> return "","".join(result)",true,elif os . path . exists ( x ) :,elif os . path . exists ( x ) :,0.75,0.0
"def reloadCols(self): <TAB> self.columns = [] <TAB> for i, (name, fmt, *shape) in enumerate(self.npy.dtype.descr): <TAB> <TAB> if shape: <TAB> <TAB> <TAB> t = anytype <TAB> <TAB> elif ""M"" in fmt: <TAB> <TAB> <TAB> self.addColumn(Column(name, type=date, getter=lambda c, r, i=i: str(r[i]))) <TAB> <TAB> <TAB> continue <TAB> <TAB> elif ""i"" in fmt: <TAB> <TAB> <TAB> t = int <TAB> <TAB> elif ""f"" in fmt: <TAB> <TAB> <TAB> t = float <TAB> <TAB> else: <TAB> <TAB> <TAB> t = anytype <TAB> <TAB> self.addColumn(ColumnItem(name, i, type=t))",true,"elif ""f"" in fmt :","elif ""f"" in fmt :",0.75,0.0
"def tool_lineages(self, trans): <TAB> rval = [] <TAB> for id, tool in self.app.toolbox.tools(): <TAB> <TAB> if hasattr(tool, ""lineage""): <TAB> <TAB> <TAB> lineage_dict = tool.lineage.to_dict() <TAB> <TAB> else: <TAB> <TAB> <TAB> lineage_dict = None <TAB> <TAB> entry = dict(id=id, lineage=lineage_dict) <TAB> <TAB> rval.append(entry) <TAB> return rval",true,"if hasattr ( tool , ""lineage"" ) :","if hasattr ( tool , ""lineage"" ) :",0.75,0.0
"def item(self, tensor): <TAB> numel = 0 <TAB> if len(tensor.shape) > 0: <TAB> <TAB> numel = fct.reduce(op.mul, tensor.shape) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> f""expected tensor with one element, "" f""got {tensor.shape}"" <TAB> <TAB> <TAB> ) <TAB> if numel == 1: <TAB> <TAB> return tensor[0] <TAB> return tensor",true,if numel != 1 :,if numel != 1 :,0.75,0.0
"def get_host_metadata(self): <TAB> meta = {} <TAB> if self.agent_url: <TAB> <TAB> try: <TAB> <TAB> <TAB> resp = requests.get( <TAB> <TAB> <TAB> <TAB> self.agent_url + ECS_AGENT_METADATA_PATH, timeout=1 <TAB> <TAB> <TAB> ).json() <TAB> <TAB> <TAB> if ""Version"" in resp: <TAB> <TAB> <TAB> <TAB> match = AGENT_VERSION_EXP.search(resp.get(""Version"")) <TAB> <TAB> <TAB> <TAB> if match is not None and len(match.groups()) == 1: <TAB> <TAB> <TAB> <TAB> <TAB> meta[""ecs_version""] = match.group(1) <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> self.log.debug(""Error getting ECS version: %s"" % str(e)) <TAB> return meta",true,if match is not None and len ( match . groups ( ) ) == 1 :,if match is not None and len ( match . groups ( ) ) == 1 :,0.75,0.0
"def generate(): <TAB> for leaf in u.leaves: <TAB> <TAB> if isinstance(leaf, Integer): <TAB> <TAB> <TAB> val = leaf.get_int_value() <TAB> <TAB> <TAB> if val in (0, 1): <TAB> <TAB> <TAB> <TAB> yield val <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> elif isinstance(leaf, Symbol): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> yield 1 <TAB> <TAB> <TAB> elif leaf == SymbolFalse: <TAB> <TAB> <TAB> <TAB> yield 0 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> else: <TAB> <TAB> <TAB> raise _NoBoolVector",true,if leaf == SymbolTrue :,if leaf == SymbolTrue :,0.75,0.0
"def _test_set_metadata(self, metadata, mask=None): <TAB> header = ofproto.OXM_OF_METADATA <TAB> match = OFPMatch() <TAB> if mask is None: <TAB> <TAB> match.set_metadata(metadata) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> header = ofproto.OXM_OF_METADATA_W <TAB> <TAB> match.set_metadata_masked(metadata, mask) <TAB> <TAB> metadata &= mask <TAB> self._test_serialize_and_parser(match, header, metadata, mask)",false,if ( mask + 1 ) >> 64 != 1 :,if header == ofproto . OXM_OF_METADATA :,0.01,0.0
"def pixbufrenderer(self, column, crp, model, it): <TAB> tok = model.get_value(it, 0) <TAB> if tok.type == ""class"": <TAB> <TAB> icon = ""class"" <TAB> else: <TAB> <TAB> if tok.visibility == ""private"": <TAB> <TAB> <TAB> icon = ""method_priv"" <TAB> <TAB> elif tok.visibility == ""protected"": <TAB> <TAB> <TAB> icon = ""method_prot"" <TAB> <TAB> else: <TAB> <TAB> <TAB> icon = ""method"" <TAB> crp.set_property(""pixbuf"", imagelibrary.pixbufs[icon])",true,"elif tok . visibility == ""protected"" :","elif tok . visibility == ""protected"" :",1.0,0.0
"def path_sum2(root, s): <TAB> if root is None: <TAB> <TAB> return [] <TAB> res = [] <TAB> stack = [(root, [root.val])] <TAB> while stack: <TAB> <TAB> node, ls = stack.pop() <TAB> <TAB> if node.left is None and node.right is None and sum(ls) == s: <TAB> <TAB> <TAB> res.append(ls) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> stack.append((node.left, ls + [node.left.val])) <TAB> <TAB> if node.right is not None: <TAB> <TAB> <TAB> stack.append((node.right, ls + [node.right.val])) <TAB> return res",true,if node . left is not None :,if node . left is not None :,0.75,0.0
"def clear_slot(self, slot_id, trigger_changed): <TAB> if self.slots[slot_id] is not None: <TAB> <TAB> old_resource_id = self.slots[slot_id].resource_id <TAB> <TAB> if self.slots[slot_id].selling: <TAB> <TAB> <TAB> del self.sell_list[old_resource_id] <TAB> <TAB> else: <TAB> <TAB> <TAB> del self.buy_list[old_resource_id] <TAB> self.slots[slot_id] = None <TAB> if trigger_changed: <TAB> <TAB> self._changed()",false,if self . slots [ slot_id ] . selling :,if self . slots [ slot_id ] . ending :,0.64,0.0
"def OnRightUp(self, event): <TAB> self.HandleMouseEvent(event) <TAB> self.Unbind(wx.EVT_RIGHT_UP, handler=self.OnRightUp) <TAB> self.Unbind(wx.EVT_MOUSE_CAPTURE_LOST, handler=self.OnRightUp) <TAB> self._right = False <TAB> if not self._left: <TAB> <TAB> self.Unbind(wx.EVT_MOTION, handler=self.OnMotion) <TAB> <TAB> self.SendChangeEvent() <TAB> <TAB> self.SetToolTip(wx.ToolTip(self._tooltip)) <TAB> <TAB> if self.HasCapture(): <TAB> <TAB> <TAB> self.ReleaseMouse()",true,if self . HasCapture ( ) :,if self . HasCapture ( ) :,0.75,0.0
"def __init__(self, *args, **kwargs): <TAB> for arg in args: <TAB> <TAB> for k, v in arg.items(): <TAB> <TAB> <TAB> if isinstance(v, dict): <TAB> <TAB> <TAB> <TAB> arg[k] = AttrDict(v) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> arg[k] = v <TAB> super(AttrDict, self).__init__(*args, **kwargs)",true,"if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",0.75,0.0
"def _toplevelTryFunc(func, *args, status=status, **kwargs): <TAB> with ThreadProfiler(threading.current_thread()) as prof: <TAB> <TAB> t = threading.current_thread() <TAB> <TAB> t.name = func.__name__ <TAB> <TAB> try: <TAB> <TAB> <TAB> t.status = func(*args, **kwargs) <TAB> <TAB> except EscapeException as e:  # user aborted <TAB> <TAB> <TAB> t.status = ""aborted by user"" <TAB> <TAB> <TAB> if status: <TAB> <TAB> <TAB> <TAB> status(""%s aborted"" % t.name, priority=2) <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> t.exception = e <TAB> <TAB> <TAB> t.status = ""exception"" <TAB> <TAB> <TAB> vd.exceptionCaught(e) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> t.sheet.currentThreads.remove(t)",false,if t . sheet :,if t in prof :,0.06,0.0
"def comboSelectionChanged(self, index): <TAB> text = self.comboBox.cb.itemText(index) <TAB> for i in range(self.labelList.count()): <TAB> <TAB> if text == """": <TAB> <TAB> <TAB> self.labelList.item(i).setCheckState(2) <TAB> <TAB> elif text != self.labelList.item(i).text(): <TAB> <TAB> <TAB> self.labelList.item(i).setCheckState(0) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.labelList.item(i).setCheckState(2)",true,elif text != self . labelList . item ( i ) . text ( ) :,elif text != self . labelList . item ( i ) . text ( ) :,1.0,0.0
"def __attempt_add_to_linked_match( <TAB> self, input_name, hdca, collection_type_description, subcollection_type ): <TAB> structure = get_structure( <TAB> <TAB> hdca, collection_type_description, leaf_subcollection_type=subcollection_type <TAB> ) <TAB> if not self.linked_structure: <TAB> <TAB> self.linked_structure = structure <TAB> <TAB> self.collections[input_name] = hdca <TAB> <TAB> self.subcollection_types[input_name] = subcollection_type <TAB> else: <TAB> <TAB> if not self.linked_structure.can_match(structure): <TAB> <TAB> <TAB> raise exceptions.MessageException(CANNOT_MATCH_ERROR_MESSAGE) <TAB> <TAB> self.collections[input_name] = hdca <TAB> <TAB> self.subcollection_types[input_name] = subcollection_type",true,if not self . linked_structure . can_match ( structure ) :,if not self . linked_structure . can_match ( structure ) :,0.75,0.0
"def _wait_for_bot_presense(self, online): <TAB> for _ in range(10): <TAB> <TAB> time.sleep(2) <TAB> <TAB> if online and self._is_testbot_online(): <TAB> <TAB> <TAB> break <TAB> <TAB> if not online and not self._is_testbot_online(): <TAB> <TAB> <TAB> break <TAB> else: <TAB> <TAB> raise AssertionError( <TAB> <TAB> <TAB> ""test bot is still {}"".format(""offline"" if online else ""online"") <TAB> <TAB> )",true,if online and self . _is_testbot_online ( ) :,if online and self . _is_testbot_online ( ) :,0.75,0.0
"def find(self, path): <TAB> if os.path.isfile(path) or os.path.islink(path): <TAB> <TAB> self.num_files = self.num_files + 1 <TAB> <TAB> if self.match_function(path): <TAB> <TAB> <TAB> self.files.append(path) <TAB> elif os.path.isdir(path): <TAB> <TAB> for content in os.listdir(path): <TAB> <TAB> <TAB> file = os.path.join(path, content) <TAB> <TAB> <TAB> if os.path.isfile(file) or os.path.islink(file): <TAB> <TAB> <TAB> <TAB> self.num_files = self.num_files + 1 <TAB> <TAB> <TAB> <TAB> if self.match_function(file): <TAB> <TAB> <TAB> <TAB> <TAB> self.files.append(file) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.find(file)",false,if self . match_function ( path ) :,if self . match_function ( file ) :,0.55,0.0
"def optimize(self, graph: Graph): <TAB> MAX_TEXTURE_SIZE = config.WEBGL_MAX_TEXTURE_SIZE <TAB> flag_changed = False <TAB> for v in traverse.listup_variables(graph): <TAB> <TAB> if not Placeholder.check_resolved(v.size): <TAB> <TAB> <TAB> continue <TAB> <TAB> height, width = TextureShape.get(v) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not v.has_attribute(SplitTarget): <TAB> <TAB> <TAB> flag_changed = True <TAB> <TAB> <TAB> v.attributes.add(SplitTarget()) <TAB> return graph, flag_changed",false,if height <= MAX_TEXTURE_SIZE and width <= MAX_TEXTURE_SIZE :,if height > MAX_TEXTURE_SIZE or width > MAX_TEXTURE_SIZE :,0.29,0.0
"def brightness_func(args): <TAB> device = _get_device_from_filter(args) <TAB> if args.set is None: <TAB> <TAB> # Get brightness <TAB> <TAB> if args.raw: <TAB> <TAB> <TAB> print(str(device.brightness)) <TAB> <TAB> else: <TAB> <TAB> <TAB> print(""Brightness: {0}%"".format(device.brightness)) <TAB> else: <TAB> <TAB> brightness_value = float(_clamp_u8(args.set)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(""Setting brightness to {0}%"".format(brightness_value)) <TAB> <TAB> device.brightness = brightness_value",false,if not args . raw :,if args . raw :,0.28,0.0
"def _setup(self, field_name, owner_model): <TAB> # Resolve possible name-based model reference. <TAB> if not self.model_class: <TAB> <TAB> if self.model_name == owner_model.__name__: <TAB> <TAB> <TAB> self.model_class = owner_model <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> ""ModelType: Unable to resolve model '{}'."".format(self.model_name) <TAB> <TAB> <TAB> ) <TAB> super(ModelType, self)._setup(field_name, owner_model)",true,if self . model_name == owner_model . __name__ :,if self . model_name == owner_model . __name__ :,0.75,0.0
"def build_json_schema_object(cls, parent_builder=None): <TAB> builder = builders.ObjectBuilder(cls, parent_builder) <TAB> if builder.count_type(builder.type) > 1: <TAB> <TAB> return builder <TAB> for _, name, field in cls.iterate_with_name(): <TAB> <TAB> if isinstance(field, fields.EmbeddedField): <TAB> <TAB> <TAB> builder.add_field(name, field, _parse_embedded(field, builder)) <TAB> <TAB> elif isinstance(field, fields.ListField): <TAB> <TAB> <TAB> builder.add_field(name, field, _parse_list(field, builder)) <TAB> <TAB> else: <TAB> <TAB> <TAB> builder.add_field(name, field, _create_primitive_field_schema(field)) <TAB> return builder",true,"elif isinstance ( field , fields . ListField ) :","elif isinstance ( field , fields . ListField ) :",0.75,0.0
"def filter_module(mod, type_req=None, subclass_req=None): <TAB> for name in dir(mod): <TAB> <TAB> val = getattr(mod, name) <TAB> <TAB> if type_req is not None and not isinstance(val, type_req): <TAB> <TAB> <TAB> continue <TAB> <TAB> if subclass_req is not None and not issubclass(val, subclass_req): <TAB> <TAB> <TAB> continue <TAB> <TAB> yield name, val",false,"if subclass_req is not None and not issubclass ( val , subclass_req ) :","if type_req is not None and not isinstance ( val , type_req ) :",0.45,0.0
"def get_icon(self): <TAB> if self.icon is not None: <TAB> <TAB> # Load it from an absolute filename <TAB> <TAB> if os.path.exists(self.icon): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> return GdkPixbuf.Pixbuf.new_from_file_at_size(self.icon, 24, 24) <TAB> <TAB> <TAB> except GObject.GError as ge: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> # Load it from the current icon theme <TAB> <TAB> (icon_name, extension) = os.path.splitext(os.path.basename(self.icon)) <TAB> <TAB> theme = Gtk.IconTheme() <TAB> <TAB> if theme.has_icon(icon_name): <TAB> <TAB> <TAB> return theme.load_icon(icon_name, 24, 0)",false,if theme . has_icon ( icon_name ) :,if os . path . exists ( self . icon ) :,0.03,0.0
"def sysctlTestAndSet(name, limit): <TAB> ""Helper function to set sysctl limits"" <TAB> # convert non-directory names into directory names <TAB> if ""/"" not in name: <TAB> <TAB> name = ""/proc/sys/"" + name.replace(""."", ""/"") <TAB> # read limit <TAB> with open(name, ""r"") as readFile: <TAB> <TAB> oldLimit = readFile.readline() <TAB> <TAB> if isinstance(limit, int): <TAB> <TAB> <TAB> # compare integer limits before overriding <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> with open(name, ""w"") as writeFile: <TAB> <TAB> <TAB> <TAB> <TAB> writeFile.write(""%d"" % limit) <TAB> <TAB> else: <TAB> <TAB> <TAB> # overwrite non-integer limits <TAB> <TAB> <TAB> with open(name, ""w"") as writeFile: <TAB> <TAB> <TAB> <TAB> writeFile.write(limit)",false,if int ( oldLimit ) < limit :,if limit != oldLimit :,0.02,0.0
"def _wait_for_bot_presense(self, online): <TAB> for _ in range(10): <TAB> <TAB> time.sleep(2) <TAB> <TAB> if online and self._is_testbot_online(): <TAB> <TAB> <TAB> break <TAB> <TAB> if not online and not self._is_testbot_online(): <TAB> <TAB> <TAB> break <TAB> else: <TAB> <TAB> raise AssertionError( <TAB> <TAB> <TAB> ""test bot is still {}"".format(""offline"" if online else ""online"") <TAB> <TAB> )",false,if not online and not self . _is_testbot_online ( ) :,if online and self . _is_testbot_online ( ) :,0.49,0.0
"def handle(self, context, sign, *args): <TAB> if context.rounding in (ROUND_HALF_UP, ROUND_HALF_EVEN, ROUND_HALF_DOWN, ROUND_UP): <TAB> <TAB> return Infsign[sign] <TAB> if sign == 0: <TAB> <TAB> if context.rounding == ROUND_CEILING: <TAB> <TAB> <TAB> return Infsign[sign] <TAB> <TAB> return Decimal((sign, (9,) * context.prec, context.Emax - context.prec + 1)) <TAB> if sign == 1: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return Infsign[sign] <TAB> <TAB> return Decimal((sign, (9,) * context.prec, context.Emax - context.prec + 1))",false,if context . rounding == ROUND_FLOOR :,if context . rounding == ROUND_CEILING :,0.57,0.0
"def _get_item_columns_panel(items, rows): <TAB> hbox = Gtk.HBox(False, 4) <TAB> n_item = 0 <TAB> col_items = 0 <TAB> vbox = Gtk.VBox() <TAB> hbox.pack_start(vbox, False, False, 0) <TAB> while n_item < len(items): <TAB> <TAB> item = items[n_item] <TAB> <TAB> vbox.pack_start(item, False, False, 0) <TAB> <TAB> n_item += 1 <TAB> <TAB> col_items += 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> vbox = Gtk.VBox() <TAB> <TAB> <TAB> hbox.pack_start(vbox, False, False, 0) <TAB> <TAB> <TAB> col_items = 0 <TAB> return hbox",false,if col_items > rows :,if col_items == rows :,0.33,0.0
"def _changed(self): <TAB> if self.gtk_range.get_sensitive(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.timer.cancel() <TAB> <TAB> self.timer = _Timer(0.5, lambda: GLib.idle_add(self._write)) <TAB> <TAB> self.timer.start()",true,if self . timer :,if self . timer :,0.75,0.0
"def unlock_graph(result, callback, interval=1, propagate=False, max_retries=None): <TAB> if result.ready(): <TAB> <TAB> second_level_res = result.get() <TAB> <TAB> if second_level_res.ready(): <TAB> <TAB> <TAB> with allow_join_result(): <TAB> <TAB> <TAB> <TAB> signature(callback).delay( <TAB> <TAB> <TAB> <TAB> <TAB> list(joinall(second_level_res, propagate=propagate)) <TAB> <TAB> <TAB> <TAB> ) <TAB> else: <TAB> <TAB> unlock_graph.retry(countdown=interval, max_retries=max_retries)",true,if second_level_res . ready ( ) :,if second_level_res . ready ( ) :,0.75,0.0
"def update(self, other=None, /, **kwargs): <TAB> if self._pending_removals: <TAB> <TAB> self._commit_removals() <TAB> d = self.data <TAB> if other is not None: <TAB> <TAB> if not hasattr(other, ""items""): <TAB> <TAB> <TAB> other = dict(other) <TAB> <TAB> for key, o in other.items(): <TAB> <TAB> <TAB> d[key] = KeyedRef(o, self._remove, key) <TAB> for key, o in kwargs.items(): <TAB> <TAB> d[key] = KeyedRef(o, self._remove, key)",true,"if not hasattr ( other , ""items"" ) :","if not hasattr ( other , ""items"" ) :",0.75,0.0
"def default(self, o): <TAB> try: <TAB> <TAB> if type(o) == datetime.datetime: <TAB> <TAB> <TAB> return str(o) <TAB> <TAB> else: <TAB> <TAB> <TAB> # remove unwanted attributes from the provider object during conversion to json <TAB> <TAB> <TAB> if hasattr(o, ""profile""): <TAB> <TAB> <TAB> <TAB> del o.profile <TAB> <TAB> <TAB> if hasattr(o, ""credentials""): <TAB> <TAB> <TAB> <TAB> del o.credentials <TAB> <TAB> <TAB> if hasattr(o, ""metadata_path""): <TAB> <TAB> <TAB> <TAB> del o.metadata_path <TAB> <TAB> <TAB> if hasattr(o, ""services_config""): <TAB> <TAB> <TAB> <TAB> del o.services_config <TAB> <TAB> <TAB> return vars(o) <TAB> except Exception as e: <TAB> <TAB> return str(o)",false,"if hasattr ( o , ""services_config"" ) :","if hasattr ( o , ""metadata_path"" ) :",0.55,0.0
"def read(self, count=True, timeout=None, ignore_non_errors=True, ignore_timeouts=True): <TAB> try: <TAB> <TAB> return self._read(count, timeout) <TAB> except usb.USBError as e: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> log.info( <TAB> <TAB> <TAB> <TAB> ""read: e.errno=%s e.strerror=%s e.message=%s repr=%s"" <TAB> <TAB> <TAB> <TAB> % (e.errno, e.strerror, e.message, repr(e)) <TAB> <TAB> <TAB> ) <TAB> <TAB> if ignore_timeouts and is_timeout(e): <TAB> <TAB> <TAB> return [] <TAB> <TAB> if ignore_non_errors and is_noerr(e): <TAB> <TAB> <TAB> return [] <TAB> <TAB> raise",false,if DEBUG_COMM :,if count :,0.32,0.0
def heal(self): <TAB> if not self.doctors: <TAB> <TAB> return <TAB> proc_ids = self._get_process_ids() <TAB> for proc_id in proc_ids: <TAB> <TAB> # get proc every time for latest state <TAB> <TAB> proc = PipelineProcess.objects.get(id=proc_id) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> for dr in self.doctors: <TAB> <TAB> <TAB> if dr.confirm(proc): <TAB> <TAB> <TAB> <TAB> dr.cure(proc) <TAB> <TAB> <TAB> <TAB> break,false,if not proc . is_alive or proc . is_frozen :,if not proc :,0.05,0.0
"def to_value(self, value): <TAB> # Tip: 'value' is the object returned by <TAB> # <TAB>  taiga.projects.history.models.HistoryEntry.values_diff() <TAB> ret = {} <TAB> for key, val in value.items(): <TAB> <TAB> if key in [""attachments"", ""custom_attributes"", ""description_diff""]: <TAB> <TAB> <TAB> ret[key] = val <TAB> <TAB> elif key == ""points"": <TAB> <TAB> <TAB> ret[key] = {k: {""from"": v[0], ""to"": v[1]} for k, v in val.items()} <TAB> <TAB> else: <TAB> <TAB> <TAB> ret[key] = {""from"": val[0], ""to"": val[1]} <TAB> return ret",false,"if key in [ ""attachments"" , ""custom_attributes"" , ""description_diff"" ] :","elif key == ""points"" :",0.01,0.0
"def default_generator( <TAB> self, dataset, epochs=1, mode=""fit"", deterministic=True, pad_batches=True ): <TAB> for epoch in range(epochs): <TAB> <TAB> for (X_b, y_b, w_b, ids_b) in dataset.iterbatches( <TAB> <TAB> <TAB> batch_size=self.batch_size, <TAB> <TAB> <TAB> deterministic=deterministic, <TAB> <TAB> <TAB> pad_batches=pad_batches, <TAB> <TAB> ): <TAB> <TAB> <TAB> if mode == ""predict"": <TAB> <TAB> <TAB> <TAB> dropout = np.array(0.0) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> dropout = np.array(1.0) <TAB> <TAB> <TAB> yield ([X_b, dropout], [y_b], [w_b])",true,"if mode == ""predict"" :","if mode == ""predict"" :",0.75,0.0
"def _cygwin_hack_find_addresses(target): <TAB> addresses = [] <TAB> for h in [ <TAB> <TAB> target, <TAB> <TAB> ""localhost"", <TAB> <TAB> ""127.0.0.1"", <TAB> ]: <TAB> <TAB> try: <TAB> <TAB> <TAB> addr = get_local_ip_for(h) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> addresses.append(addr) <TAB> <TAB> except socket.gaierror: <TAB> <TAB> <TAB> pass <TAB> return defer.succeed(addresses)",false,if addr not in addresses :,if addr :,0.05,0.0
"def _get_notify(self, action_node): <TAB> if action_node.name not in self._skip_notify_tasks: <TAB> <TAB> if action_node.notify: <TAB> <TAB> <TAB> task_notify = NotificationsHelper.to_model(action_node.notify) <TAB> <TAB> <TAB> return task_notify <TAB> <TAB> elif self._chain_notify: <TAB> <TAB> <TAB> return self._chain_notify <TAB> return None",true,elif self . _chain_notify :,elif self . _chain_notify :,0.75,0.0
"def filterTokenLocation(): <TAB> i = None <TAB> entry = None <TAB> token = None <TAB> tokens = [] <TAB> i = 0 <TAB> while 1: <TAB> <TAB> if not (i < len(extra.tokens)): <TAB> <TAB> <TAB> break <TAB> <TAB> entry = extra.tokens[i] <TAB> <TAB> token = jsdict( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> ""type"": entry.type, <TAB> <TAB> <TAB> <TAB> ""value"": entry.value, <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> <TAB> if extra.range: <TAB> <TAB> <TAB> token.range = entry.range <TAB> <TAB> if extra.loc: <TAB> <TAB> <TAB> token.loc = entry.loc <TAB> <TAB> tokens.append(token) <TAB> <TAB> i += 1 <TAB> extra.tokens = tokens",true,if not ( i < len ( extra . tokens ) ) :,if not ( i < len ( extra . tokens ) ) :,0.75,0.0
"def read(self, size=-1): <TAB> buf = bytearray() <TAB> while size != 0 and self.cursor < self.maxpos: <TAB> <TAB> if not self.in_current_block(self.cursor): <TAB> <TAB> <TAB> self.seek_to_block(self.cursor) <TAB> <TAB> part = self.current_stream.read(size) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if len(part) == 0: <TAB> <TAB> <TAB> <TAB> raise EOFError() <TAB> <TAB> <TAB> size -= len(part) <TAB> <TAB> self.cursor += len(part) <TAB> <TAB> buf += part <TAB> return bytes(buf)",false,if size > 0 :,if len ( part ) != 0 :,0.05,0.0
"def get_properties_from_model(model_class): <TAB> """"""Show properties from a model"""""" <TAB> properties = [] <TAB> attr_names = [name for (name, value) in inspect.getmembers(model_class, isprop)] <TAB> for attr_name in attr_names: <TAB> <TAB> if attr_name.endswith(""pk""): <TAB> <TAB> <TAB> attr_names.remove(attr_name) <TAB> <TAB> else: <TAB> <TAB> <TAB> properties.append( <TAB> <TAB> <TAB> <TAB> dict(label=attr_name, name=attr_name.strip(""_"").replace(""_"", "" "")) <TAB> <TAB> <TAB> ) <TAB> return sorted(properties, key=lambda k: k[""label""])",true,"if attr_name . endswith ( ""pk"" ) :","if attr_name . endswith ( ""pk"" ) :",0.75,0.0
"def __getitem__(self, name, set=set, getattr=getattr, id=id): <TAB> visited = set() <TAB> mydict = self.basedict <TAB> while 1: <TAB> <TAB> value = mydict[name] <TAB> <TAB> if value is not None: <TAB> <TAB> <TAB> return value <TAB> <TAB> myid = id(mydict) <TAB> <TAB> assert myid not in visited <TAB> <TAB> visited.add(myid) <TAB> <TAB> mydict = mydict.Parent <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return",true,if mydict is None :,if mydict is None :,0.75,0.0
"def multicolumn(self, list, format, cols=4): <TAB> """"""Format a list of items into a multi-column list."""""" <TAB> result = """" <TAB> rows = (len(list) + cols - 1) // cols <TAB> for col in range(cols): <TAB> <TAB> result = result + '<td width=""%d%%"" valign=top>' % (100 // cols) <TAB> <TAB> for i in range(rows * col, rows * col + rows): <TAB> <TAB> <TAB> if i < len(list): <TAB> <TAB> <TAB> <TAB> result = result + format(list[i]) + ""<br>\n"" <TAB> <TAB> result = result + ""</td>"" <TAB> return '<table width=""100%%"" summary=""list""><tr>%s</tr></table>' % result",true,if i < len ( list ) :,if i < len ( list ) :,0.75,0.0
"def format_exc(exc=None): <TAB> """"""Return exc (or sys.exc_info if None), formatted."""""" <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> exc = _exc_info() <TAB> <TAB> if exc == (None, None, None): <TAB> <TAB> <TAB> return """" <TAB> <TAB> import traceback <TAB> <TAB> return """".join(traceback.format_exception(*exc)) <TAB> finally: <TAB> <TAB> del exc",true,if exc is None :,if exc is None :,0.75,0.0
"def assert_counts(res, lang, files, blank, comment, code): <TAB> for line in res: <TAB> <TAB> fields = line.split() <TAB> <TAB> if len(fields) >= 5: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.assertEqual(files, int(fields[1])) <TAB> <TAB> <TAB> <TAB> self.assertEqual(blank, int(fields[2])) <TAB> <TAB> <TAB> <TAB> self.assertEqual(comment, int(fields[3])) <TAB> <TAB> <TAB> <TAB> self.assertEqual(code, int(fields[4])) <TAB> <TAB> <TAB> <TAB> return <TAB> self.fail(""Found no output line for {}"".format(lang))",true,if fields [ 0 ] == lang :,if fields [ 0 ] == lang :,0.75,0.0
"def __iter__(self): <TAB> for name, value in self.__class__.__dict__.items(): <TAB> <TAB> if isinstance(value, alias_flag_value): <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance(value, flag_value): <TAB> <TAB> <TAB> yield (name, self._has_flag(value.flag))",true,"if isinstance ( value , alias_flag_value ) :","if isinstance ( value , alias_flag_value ) :",0.75,0.0
"def optimize_models(args, use_cuda, models): <TAB> """"""Optimize ensemble for generation"""""" <TAB> for model in models: <TAB> <TAB> model.make_generation_fast_( <TAB> <TAB> <TAB> beamable_mm_beam_size=None if args.no_beamable_mm else args.beam, <TAB> <TAB> <TAB> need_attn=args.print_alignment, <TAB> <TAB> ) <TAB> <TAB> if args.fp16: <TAB> <TAB> <TAB> model.half() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> model.cuda()",true,if use_cuda :,if use_cuda :,0.53,0.0
"def convertstore(self, mydict): <TAB> targetheader = self.mypofile.header() <TAB> targetheader.addnote(""extracted from web2py"", ""developer"") <TAB> for source_str in mydict.keys(): <TAB> <TAB> target_str = mydict[source_str] <TAB> <TAB> if target_str == source_str: <TAB> <TAB> <TAB> # a convention with new (untranslated) web2py files <TAB> <TAB> <TAB> target_str = u"""" <TAB> <TAB> elif target_str.startswith(u""*** ""): <TAB> <TAB> <TAB> # an older convention <TAB> <TAB> <TAB> target_str = u"""" <TAB> <TAB> pounit = self.convertunit(source_str, target_str) <TAB> <TAB> self.mypofile.addunit(pounit) <TAB> return self.mypofile",true,"elif target_str . startswith ( u""*** "" ) :","elif target_str . startswith ( u""*** "" ) :",0.75,0.0
"def __sparse_values_set(instances, static_col_indexes: list): <TAB> tmp_result = {idx: set() for idx in static_col_indexes} <TAB> for _, instance in instances: <TAB> <TAB> data_generator = instance.features.get_all_data() <TAB> <TAB> for idx, value in data_generator: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> tmp_result[idx].add(value) <TAB> result = [tmp_result[x] for x in static_col_indexes] <TAB> return result",false,if idx not in tmp_result :,if value is None :,0.13,0.0
def puts(self): <TAB><IF-STMT> <TAB> <TAB> self.lazy_init_lock_.acquire() <TAB> <TAB> try: <TAB> <TAB> <TAB> if self.puts_ is None: <TAB> <TAB> <TAB> <TAB> self.puts_ = PutRequest() <TAB> <TAB> finally: <TAB> <TAB> <TAB> self.lazy_init_lock_.release() <TAB> return self.puts_,true,if self . puts_ is None :,if self . puts_ is None :,0.75,0.0
"def run(self, args, **kwargs): <TAB> if args.resource_ref or args.policy_type: <TAB> <TAB> filters = {} <TAB> <TAB> if args.resource_ref: <TAB> <TAB> <TAB> filters[""resource_ref""] = args.resource_ref <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> filters[""policy_type""] = args.policy_type <TAB> <TAB> filters.update(**kwargs) <TAB> <TAB> return self.manager.query(**filters) <TAB> else: <TAB> <TAB> return self.manager.get_all(**kwargs)",true,if args . policy_type :,if args . policy_type :,0.75,0.0
"def Get_Gene(self, id): <TAB> """"""Retreive the gene name (GN)."""""" <TAB> entry = self.Get(id) <TAB> if not entry: <TAB> <TAB> return None <TAB> GN = """" <TAB> for line in string.split(entry, ""\n""): <TAB> <TAB> if line[0:5] == ""GN   "": <TAB> <TAB> <TAB> GN = string.strip(line[5:]) <TAB> <TAB> <TAB> if GN[-1] == ""."": <TAB> <TAB> <TAB> <TAB> GN = GN[0:-1] <TAB> <TAB> <TAB> return GN <TAB> <TAB> if line[0:2] == ""//"": <TAB> <TAB> <TAB> break <TAB> return GN",true,"if GN [ - 1 ] == ""."" :","if GN [ - 1 ] == ""."" :",0.75,0.0
"def processMovie(self, atom): <TAB> for field in atom: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.processTrack(field[""track""]) <TAB> <TAB> if ""movie_hdr"" in field: <TAB> <TAB> <TAB> self.processMovieHeader(field[""movie_hdr""])",true,"if ""track"" in field :","if ""track"" in field :",0.75,0.0
"def get_next_video_frame(self, skip_empty_frame=True): <TAB> if not self.video_format: <TAB> <TAB> return <TAB> while True: <TAB> <TAB> # We skip video packets which are not video frames <TAB> <TAB> # This happens in mkv files for the first few frames. <TAB> <TAB> video_packet = self._get_video_packet() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._decode_video_packet(video_packet) <TAB> <TAB> if video_packet.image is not None or not skip_empty_frame: <TAB> <TAB> <TAB> break <TAB> if _debug: <TAB> <TAB> print(""Returning"", video_packet) <TAB> return video_packet.image",false,if video_packet . image == 0 :,if video_packet :,0.04,0.0
"def get_devices(display=None): <TAB> base = ""/dev/input"" <TAB> for filename in os.listdir(base): <TAB> <TAB> if filename.startswith(""event""): <TAB> <TAB> <TAB> path = os.path.join(base, filename) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> _devices[path] = EvdevDevice(display, path) <TAB> <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> <TAB> pass <TAB> return list(_devices.values())",true,if path in _devices :,if path in _devices :,0.75,0.0
"def _ensure_header_written(self, datasize): <TAB> if not self._headerwritten: <TAB> <TAB> if not self._nchannels: <TAB> <TAB> <TAB> raise Error(""# channels not specified"") <TAB> <TAB> if not self._sampwidth: <TAB> <TAB> <TAB> raise Error(""sample width not specified"") <TAB> <TAB> if not self._framerate: <TAB> <TAB> <TAB> raise Error(""sampling rate not specified"") <TAB> <TAB> self._write_header(datasize)",false,if not self . _sampwidth :,if not self . _framerate :,0.52,0.0
"def process(self, fuzzresult): <TAB> base_url = urljoin(fuzzresult.url, "".."") <TAB> for line in fuzzresult.history.content.splitlines(): <TAB> <TAB> record = line.split(""/"") <TAB> <TAB> if len(record) == 6 and record[1]: <TAB> <TAB> <TAB> self.queue_url(urljoin(base_url, record[1])) <TAB> <TAB> <TAB> # Directory <TAB> <TAB> <TAB> if record[0] == ""D"": <TAB> <TAB> <TAB> <TAB> self.queue_url(urljoin(base_url, record[1])) <TAB> <TAB> <TAB> <TAB> self.queue_url(urljoin(base_url, ""%s/CVS/Entries"" % (record[1])))",false,"if record [ 0 ] == ""D"" :",if len ( record ) == 6 and record [ 1 ] :,0.03,0.0
"def tearDown(self): <TAB> """"""Shutdown the UDP server."""""" <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.server.stop(2.0) <TAB> <TAB> if self.sock_hdlr: <TAB> <TAB> <TAB> self.root_logger.removeHandler(self.sock_hdlr) <TAB> <TAB> <TAB> self.sock_hdlr.close() <TAB> finally: <TAB> <TAB> BaseTest.tearDown(self)",true,if self . server :,if self . server :,0.75,0.0
"def get_backend(find_library=None): <TAB> try: <TAB> <TAB> global _lib, _ctx <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> _lib = _load_library(find_library) <TAB> <TAB> <TAB> _setup_prototypes(_lib) <TAB> <TAB> <TAB> _ctx = _Context() <TAB> <TAB> _logger.warning( <TAB> <TAB> <TAB> ""OpenUSB backend deprecated (https://github.com/pyusb/pyusb/issues/284)"" <TAB> <TAB> ) <TAB> <TAB> return _OpenUSB() <TAB> except usb.libloader.LibraryException: <TAB> <TAB> # exception already logged (if any) <TAB> <TAB> _logger.error(""Error loading OpenUSB backend"", exc_info=False) <TAB> <TAB> return None <TAB> except Exception: <TAB> <TAB> _logger.error(""Error loading OpenUSB backend"", exc_info=True) <TAB> <TAB> return None",false,if _lib is None :,if not _lib :,0.04,0.0
"def __init__(self, event, event_info, fields=[]): <TAB> _wmi_object.__init__(self, event, fields=fields) <TAB> _set(self, ""event_type"", None) <TAB> _set(self, ""timestamp"", None) <TAB> _set(self, ""previous"", None) <TAB> if event_info: <TAB> <TAB> event_type = self.event_type_re.match(event_info.Path_.Class).group(1).lower() <TAB> <TAB> _set(self, ""event_type"", event_type) <TAB> <TAB> if hasattr(event_info, ""TIME_CREATED""): <TAB> <TAB> <TAB> _set(self, ""timestamp"", from_1601(event_info.TIME_CREATED)) <TAB> <TAB> if hasattr(event_info, ""PreviousInstance""): <TAB> <TAB> <TAB> _set(self, ""previous"", event_info.PreviousInstance)",false,"if hasattr ( event_info , ""PreviousInstance"" ) :","if hasattr ( event_info , ""TIME_CREATED"" ) :",0.55,0.0
"def _getListNextPackagesReadyToBuild(): <TAB> for pkg in Scheduler.listOfPackagesToBuild: <TAB> <TAB> if pkg in Scheduler.listOfPackagesCurrentlyBuilding: <TAB> <TAB> <TAB> continue <TAB> <TAB> if constants.rpmCheck or Scheduler._checkNextPackageIsReadyToBuild(pkg): <TAB> <TAB> <TAB> Scheduler.listOfPackagesNextToBuild.put((-Scheduler._getPriority(pkg), pkg)) <TAB> <TAB> <TAB> Scheduler.logger.debug(""Adding "" + pkg + "" to the schedule list"")",false,if pkg in Scheduler . listOfPackagesCurrentlyBuilding :,if constants . rpmCheck or Scheduler . _checkNextPackageIsReadyToBuild ( pkg ) :,0.16,0.0
"def process_all(self, lines, times=1): <TAB> gap = False <TAB> for _ in range(times): <TAB> <TAB> for line in lines: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.write("""") <TAB> <TAB> <TAB> self.process(line) <TAB> <TAB> <TAB> if not is_command(line): <TAB> <TAB> <TAB> <TAB> gap = True <TAB> return 0",true,if gap :,if gap :,0.53,0.0
"def diff(old, new, display=True): <TAB> """"""Nice colored diff implementation"""""" <TAB> if not isinstance(old, list): <TAB> <TAB> old = decolorize(str(old)).splitlines() <TAB> if not isinstance(new, list): <TAB> <TAB> new = decolorize(str(new)).splitlines() <TAB> line_types = {"" "": ""%Reset"", ""-"": ""%Red"", ""+"": ""%Green"", ""?"": ""%Pink""} <TAB> if display: <TAB> <TAB> for line in difflib.Differ().compare(old, new): <TAB> <TAB> <TAB> if line.startswith(""?""): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> print(colorize(line_types[line[0]], line)) <TAB> return old != new",true,"if line . startswith ( ""?"" ) :","if line . startswith ( ""?"" ) :",0.75,0.0
"def get_limit(self, request): <TAB> if self.limit_query_param: <TAB> <TAB> try: <TAB> <TAB> <TAB> limit = int(request.query_params[self.limit_query_param]) <TAB> <TAB> <TAB> if limit < 0: <TAB> <TAB> <TAB> <TAB> raise ValueError() <TAB> <TAB> <TAB> # Enforce maximum page size, if defined <TAB> <TAB> <TAB> if settings.MAX_PAGE_SIZE: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return settings.MAX_PAGE_SIZE <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> return min(limit, settings.MAX_PAGE_SIZE) <TAB> <TAB> <TAB> return limit <TAB> <TAB> except (KeyError, ValueError): <TAB> <TAB> <TAB> pass <TAB> return self.default_limit",false,if limit == 0 :,if limit == settings . DEFAULT_PAGE_SIZE :,0.12,0.0
"def slice_fill(self, slice_): <TAB> ""Fills the slice with zeroes for the dimensions that have single elements and squeeze_dims true"" <TAB> if isinstance(self.indexes, int): <TAB> <TAB> new_slice_ = [0] <TAB> <TAB> offset = 0 <TAB> else: <TAB> <TAB> new_slice_ = [slice_[0]] <TAB> <TAB> offset = 1 <TAB> for i in range(1, len(self.nums)): <TAB> <TAB> if self.squeeze_dims[i]: <TAB> <TAB> <TAB> new_slice_.append(0) <TAB> <TAB> elif offset < len(slice_): <TAB> <TAB> <TAB> new_slice_.append(slice_[offset]) <TAB> <TAB> <TAB> offset += 1 <TAB> new_slice_ += slice_[offset:] <TAB> return new_slice_",false,elif offset < len ( slice_ ) :,if self . squeeze_dims [ i ] :,0.01,0.0
"def wrapper(*args, **kw): <TAB> instance = args[0] <TAB> try: <TAB> <TAB> if request.get_json() is None: <TAB> <TAB> <TAB> ret_dict = instance._create_ret_object( <TAB> <TAB> <TAB> <TAB> instance.FAILURE, None, True, instance.MUST_JSON <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> instance.logger.error(instance.MUST_JSON) <TAB> <TAB> <TAB> return jsonify(ret_dict), 400 <TAB> except BadRequest: <TAB> <TAB> ret_dict = instance._create_ret_object( <TAB> <TAB> <TAB> instance.FAILURE, None, True, instance.MUST_JSON <TAB> <TAB> ) <TAB> <TAB> instance.logger.error(instance.MUST_JSON) <TAB> <TAB> return jsonify(ret_dict), 400 <TAB> instance.logger.debug(""JSON is valid"") <TAB> return f(*args, **kw)",true,if request . get_json ( ) is None :,if request . get_json ( ) is None :,0.75,0.0
"def add_css(self, data): <TAB> if data: <TAB> <TAB> for medium, paths in data.items(): <TAB> <TAB> <TAB> for path in paths: <TAB> <TAB> <TAB> <TAB> if not self._css.get(medium) or path not in self._css[medium]: <TAB> <TAB> <TAB> <TAB> <TAB> self._css.setdefault(medium, []).append(path)",true,if not self . _css . get ( medium ) or path not in self . _css [ medium ] :,if not self . _css . get ( medium ) or path not in self . _css [ medium ] :,1.0,0.0
"def mangle_template(template: str, template_vars: Set[str]) -> str: <TAB> if TEMPLATE_PREFIX in template or TEMPLATE_SUFFIX in template: <TAB> <TAB> raise Exception(""Cannot parse a template containing reserved strings"") <TAB> for var in template_vars: <TAB> <TAB> original = f""{{{var}}}"" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> f'Template string is missing a reference to ""{var}"" referred to in kwargs' <TAB> <TAB> <TAB> ) <TAB> <TAB> template = template.replace(original, mangled_name(var)) <TAB> return template",true,if original not in template :,if original not in template :,0.75,0.0
"def filterSimilarKeywords(keyword, kwdsIterator): <TAB> """"""Return a sorted list of keywords similar to the one given."""""" <TAB> seenDict = {} <TAB> kwdSndx = soundex(keyword.encode(""ascii"", ""ignore"")) <TAB> matches = [] <TAB> matchesappend = matches.append <TAB> checkContained = False <TAB> if len(keyword) > 4: <TAB> <TAB> checkContained = True <TAB> for movieID, key in kwdsIterator: <TAB> <TAB> if key in seenDict: <TAB> <TAB> <TAB> continue <TAB> <TAB> seenDict[key] = None <TAB> <TAB> if checkContained and keyword in key: <TAB> <TAB> <TAB> matchesappend(key) <TAB> <TAB> <TAB> continue <TAB> <TAB> if kwdSndx == soundex(key.encode(""ascii"", ""ignore"")): <TAB> <TAB> <TAB> matchesappend(key) <TAB> return _sortKeywords(keyword, matches)",true,"if kwdSndx == soundex ( key . encode ( ""ascii"" , ""ignore"" ) ) :","if kwdSndx == soundex ( key . encode ( ""ascii"" , ""ignore"" ) ) :",0.75,0.0
"def GetInfo(self): <TAB> for k, v in sorted(self.memory_parameters.items()): <TAB> <TAB> if k.startswith(""Pad""): <TAB> <TAB> <TAB> continue <TAB> <TAB> if not v: <TAB> <TAB> <TAB> continue <TAB> <TAB> print(""%s: \t%#08x (%s)"" % (k, v, v)) <TAB> print(""Memory ranges:"") <TAB> print(""Start\t\tEnd\t\tLength"") <TAB> for start, length in self.runs: <TAB> <TAB> print(""0x%X\t\t0x%X\t\t0x%X"" % (start, start + length, length))",true,"if k . startswith ( ""Pad"" ) :","if k . startswith ( ""Pad"" ) :",0.75,0.0
"def Children(self): <TAB> """"""Returns a list of all of this object's owned (strong) children."""""" <TAB> children = [] <TAB> for property, attributes in self._schema.iteritems(): <TAB> <TAB> (is_list, property_type, is_strong) = attributes[0:3] <TAB> <TAB> if is_strong and property in self._properties: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> children.append(self._properties[property]) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> children.extend(self._properties[property]) <TAB> return children",false,if not is_list :,if is_list :,0.1,0.0
"def normalize_res_identifier(self, emu, cw, val): <TAB> mask = (16 ** (emu.get_ptr_size() // 2) - 1) << 16 <TAB> if val & mask:  # not an INTRESOURCE <TAB> <TAB> name = emu.read_mem_string(val, cw) <TAB> <TAB> if name[0] == ""#"": <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> name = int(name[1:]) <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> return 0 <TAB> else: <TAB> <TAB> name = val <TAB> return name",true,"if name [ 0 ] == ""#"" :","if name [ 0 ] == ""#"" :",0.75,0.0
"def _optimize(self, solutions): <TAB> best_a = None <TAB> best_silhouette = None <TAB> best_k = None <TAB> for a, silhouette, k in solutions(): <TAB> <TAB> if best_silhouette is None: <TAB> <TAB> <TAB> pass <TAB> <TAB> elif silhouette <= best_silhouette: <TAB> <TAB> <TAB> break <TAB> <TAB> best_silhouette = silhouette <TAB> <TAB> best_a = a <TAB> <TAB> best_k = k <TAB> return best_a, best_silhouette, best_k",true,elif silhouette <= best_silhouette :,elif silhouette <= best_silhouette :,0.75,0.0
"def find_commit_type(sha): <TAB> try: <TAB> <TAB> o = obj_store[sha] <TAB> except KeyError: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise <TAB> else: <TAB> <TAB> if isinstance(o, Commit): <TAB> <TAB> <TAB> commits.add(sha) <TAB> <TAB> elif isinstance(o, Tag): <TAB> <TAB> <TAB> tags.add(sha) <TAB> <TAB> <TAB> commits.add(o.object[1]) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise KeyError(""Not a commit or a tag: %s"" % sha)",false,if not ignore_unknown :,if o . object [ 0 ] != 1 :,0.03,0.0
"def on_search_entry_keypress(self, widget, event): <TAB> key = Gdk.keyval_name(event.keyval) <TAB> if key == ""Escape"": <TAB> <TAB> self.hide_search_box() <TAB> elif key == ""Return"": <TAB> <TAB> # Combine with Shift? <TAB> <TAB> if event.state & Gdk.ModifierType.SHIFT_MASK: <TAB> <TAB> <TAB> self.search_prev = False <TAB> <TAB> <TAB> self.do_search(None) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.search_prev = True",true,if event . state & Gdk . ModifierType . SHIFT_MASK :,if event . state & Gdk . ModifierType . SHIFT_MASK :,0.75,0.0
"def process_webhook_prop(namespace): <TAB> if not isinstance(namespace.webhook_properties, list): <TAB> <TAB> return <TAB> result = {} <TAB> for each in namespace.webhook_properties: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if ""="" in each: <TAB> <TAB> <TAB> <TAB> key, value = each.split(""="", 1) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> key, value = each, """" <TAB> <TAB> <TAB> result[key] = value <TAB> namespace.webhook_properties = result",true,if each :,if each :,0.53,0.0
"def run(self): <TAB> global WAITING_BEFORE_START <TAB> time.sleep(WAITING_BEFORE_START) <TAB> while self.keep_alive: <TAB> <TAB> path_id, module, resolve = self.queue_receive.get() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> self.lock.acquire() <TAB> <TAB> self.modules[path_id] = module <TAB> <TAB> self.lock.release() <TAB> <TAB> if resolve: <TAB> <TAB> <TAB> resolution = self._resolve_with_other_modules(resolve) <TAB> <TAB> <TAB> self._relations[path_id] = [] <TAB> <TAB> <TAB> for package in resolution: <TAB> <TAB> <TAB> <TAB> self._relations[path_id].append(resolution[package]) <TAB> <TAB> <TAB> self.queue_send.put((path_id, module, False, resolution))",true,if path_id is None :,if path_id is None :,0.75,0.0
"def _get_download_link(self, url, download_type=""torrent""): <TAB> links = { <TAB> <TAB> ""torrent"": """", <TAB> <TAB> ""magnet"": """", <TAB> } <TAB> try: <TAB> <TAB> data = self.session.get(url).text <TAB> <TAB> with bs4_parser(data) as html: <TAB> <TAB> <TAB> downloads = html.find(""div"", {""class"": ""download""}) <TAB> <TAB> <TAB> if downloads: <TAB> <TAB> <TAB> <TAB> for download in downloads.findAll(""a""): <TAB> <TAB> <TAB> <TAB> <TAB> link = download[""href""] <TAB> <TAB> <TAB> <TAB> <TAB> if link.startswith(""magnet""): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> links[""magnet""] = link <TAB> <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> links[""torrent""] = urljoin(self.urls[""base_url""], link) <TAB> except Exception: <TAB> <TAB> pass <TAB> return links[download_type]",true,"if link . startswith ( ""magnet"" ) :","if link . startswith ( ""magnet"" ) :",0.75,0.0
"def _parse_fields(cls, read): <TAB> read = unicode_to_str(read) <TAB> if type(read) is not str: <TAB> <TAB> _wrong_type_for_arg(read, ""str"", ""read"") <TAB> fields = {} <TAB> while read and read[0] != "";"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> DeserializeError(read, ""does not separate fields with commas"") <TAB> <TAB> read = read[1:] <TAB> <TAB> key, _type, value, read = cls._parse_field(read) <TAB> <TAB> fields[key] = (_type, value) <TAB> if read: <TAB> <TAB> # read[0] == ';' <TAB> <TAB> read = read[1:] <TAB> return fields, read",false,"if read and read [ 0 ] != "","" :","if read [ 0 ] == "","" :",0.28,0.0
"def _convertDict(self, d): <TAB> r = {} <TAB> for k, v in d.items(): <TAB> <TAB> if isinstance(v, bytes): <TAB> <TAB> <TAB> v = str(v, ""utf-8"") <TAB> <TAB> elif isinstance(v, list) or isinstance(v, tuple): <TAB> <TAB> <TAB> v = self._convertList(v) <TAB> <TAB> elif isinstance(v, dict): <TAB> <TAB> <TAB> v = self._convertDict(v) <TAB> <TAB> if isinstance(k, bytes): <TAB> <TAB> <TAB> k = str(k, ""utf-8"") <TAB> <TAB> r[k] = v <TAB> return r",false,"if isinstance ( v , bytes ) :","elif isinstance ( v , list ) or isinstance ( v , tuple ) :",0.27,0.0
"def wrapper(filename): <TAB> mtime = getmtime(filename) <TAB> with lock: <TAB> <TAB> if filename in cache: <TAB> <TAB> <TAB> old_mtime, result = cache.pop(filename) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> # Move to the end <TAB> <TAB> <TAB> <TAB> cache[filename] = old_mtime, result <TAB> <TAB> <TAB> <TAB> return result <TAB> result = function(filename) <TAB> with lock: <TAB> <TAB> cache[filename] = mtime, result  # at the end <TAB> <TAB> if len(cache) > max_size: <TAB> <TAB> <TAB> cache.popitem(last=False) <TAB> return result",false,if old_mtime == mtime :,if old_mtime != mtime :,0.33,0.0
def isFinished(self): <TAB> # returns true if episode timesteps has reached episode length and resets the task <TAB> if self.count > self.epiLen: <TAB> <TAB> self.res() <TAB> <TAB> return True <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.pertGlasPos(0) <TAB> <TAB> if self.count == self.epiLen / 2 + 1: <TAB> <TAB> <TAB> self.env.reset() <TAB> <TAB> <TAB> self.pertGlasPos(1) <TAB> <TAB> self.count += 1 <TAB> <TAB> return False,false,if self . count == 1 :,if self . count == 0 :,0.57,0.0
"def _check_vulnerabilities(self, processed_analysis): <TAB> matched_vulnerabilities = list() <TAB> for vulnerability in self._rule_base_vulnerabilities: <TAB> <TAB> if evaluate(processed_analysis, vulnerability.rule): <TAB> <TAB> <TAB> vulnerability_data = vulnerability.get_dict() <TAB> <TAB> <TAB> name = vulnerability_data.pop(""short_name"") <TAB> <TAB> <TAB> matched_vulnerabilities.append((name, vulnerability_data)) <TAB> return matched_vulnerabilities",true,"if evaluate ( processed_analysis , vulnerability . rule ) :","if evaluate ( processed_analysis , vulnerability . rule ) :",0.75,0.0
"def _table_reprfunc(self, row, col, val): <TAB> if self._table.column_names[col].endswith(""Size""): <TAB> <TAB> if isinstance(val, compat.string_types): <TAB> <TAB> <TAB> return ""  %s"" % val <TAB> <TAB> elif val < 1024 ** 2: <TAB> <TAB> <TAB> return ""  %.1f KB"" % (val / 1024.0 ** 1) <TAB> <TAB> elif val < 1024 ** 3: <TAB> <TAB> <TAB> return ""  %.1f MB"" % (val / 1024.0 ** 2) <TAB> <TAB> else: <TAB> <TAB> <TAB> return ""  %.1f GB"" % (val / 1024.0 ** 3) <TAB> if col in (0, """"): <TAB> <TAB> return str(val) <TAB> else: <TAB> <TAB> return ""  %s"" % val",false,"if isinstance ( val , compat . string_types ) :",elif val < 1024 ** 3 :,0.01,0.0
"def serve_until_stopped(self) -> None: <TAB> while True: <TAB> <TAB> rd, wr, ex = select.select([self.socket.fileno()], [], [], self.timeout) <TAB> <TAB> if rd: <TAB> <TAB> <TAB> self.handle_request() <TAB> <TAB> if self.event is not None and self.event.is_set(): <TAB> <TAB> <TAB> break",true,if self . event is not None and self . event . is_set ( ) :,if self . event is not None and self . event . is_set ( ) :,0.75,0.0
"def resize(self, *e): <TAB> bold = (""helvetica"", -self._size.get(), ""bold"") <TAB> helv = (""helvetica"", -self._size.get()) <TAB> xspace = self._size.get() <TAB> yspace = self._size.get() <TAB> for widget in self._widgets: <TAB> <TAB> widget[""node_font""] = bold <TAB> <TAB> widget[""leaf_font""] = helv <TAB> <TAB> widget[""xspace""] = xspace <TAB> <TAB> widget[""yspace""] = yspace <TAB> <TAB> if self._size.get() < 20: <TAB> <TAB> <TAB> widget[""line_width""] = 1 <TAB> <TAB> elif self._size.get() < 30: <TAB> <TAB> <TAB> widget[""line_width""] = 2 <TAB> <TAB> else: <TAB> <TAB> <TAB> widget[""line_width""] = 3 <TAB> self._layout()",true,elif self . _size . get ( ) < 30 :,elif self . _size . get ( ) < 30 :,0.75,0.0
"def __assertTilesChangedInRegion(self, t1, t2, region): <TAB> for tileOriginTuple in t1.keys(): <TAB> <TAB> tileOrigin = imath.V2i(*tileOriginTuple) <TAB> <TAB> tileRegion = imath.Box2i( <TAB> <TAB> <TAB> tileOrigin, tileOrigin + imath.V2i(GafferImage.ImagePlug.tileSize()) <TAB> <TAB> ) <TAB> <TAB> if GafferImage.BufferAlgo.intersects(tileRegion, region): <TAB> <TAB> <TAB> self.assertNotEqual(t1[tileOriginTuple], t2[tileOriginTuple]) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.assertEqual(t1[tileOriginTuple], t2[tileOriginTuple])",true,"if GafferImage . BufferAlgo . intersects ( tileRegion , region ) :","if GafferImage . BufferAlgo . intersects ( tileRegion , region ) :",0.75,0.0
"def grouped_by_prefix(args, prefixes): <TAB> """"""Group behave args by (directory) scope into multiple test-runs."""""" <TAB> group_args = [] <TAB> current_scope = None <TAB> for arg in args.strip().split(): <TAB> <TAB> assert not arg.startswith(""-""), ""REQUIRE: arg, not options"" <TAB> <TAB> scope = select_prefix_for(arg, prefixes) <TAB> <TAB> if scope != current_scope: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> # -- DETECTED GROUP-END: <TAB> <TAB> <TAB> <TAB> yield "" "".join(group_args) <TAB> <TAB> <TAB> <TAB> group_args = [] <TAB> <TAB> <TAB> current_scope = scope <TAB> <TAB> group_args.append(arg) <TAB> if group_args: <TAB> <TAB> yield "" "".join(group_args)",true,if group_args :,if group_args :,0.53,0.0
"def __print__(self, defaults=False): <TAB> if defaults: <TAB> <TAB> print_func = str <TAB> else: <TAB> <TAB> print_func = repr <TAB> pieces = [] <TAB> default_values = self.__defaults__ <TAB> for k in self.__fields__: <TAB> <TAB> value = getattr(self, k) <TAB> <TAB> if not defaults and value == default_values[k]: <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance(value, basestring): <TAB> <TAB> <TAB> print_func = repr  # keep quotes around strings <TAB> <TAB> pieces.append(""%s=%s"" % (k, print_func(value))) <TAB> if pieces or self.__base__: <TAB> <TAB> return ""%s(%s)"" % (self.__class__.__name__, "", "".join(pieces)) <TAB> else: <TAB> <TAB> return """"",true,if not defaults and value == default_values [ k ] :,if not defaults and value == default_values [ k ] :,1.0,0.0
"def setInnerHTML(self, html): <TAB> log.HTMLClassifier.classify( <TAB> <TAB> log.ThugLogging.url if log.ThugOpts.local else log.last_url, html <TAB> ) <TAB> self.tag.clear() <TAB> for node in bs4.BeautifulSoup(html, ""html.parser"").contents: <TAB> <TAB> self.tag.append(node) <TAB> <TAB> name = getattr(node, ""name"", None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> handler = getattr(log.DFT, ""handle_%s"" % (name,), None) <TAB> <TAB> if handler: <TAB> <TAB> <TAB> handler(node)",true,if name is None :,if name is None :,0.75,0.0
"def createFields(self): <TAB> yield Enum(Bits(self, ""class"", 2), self.CLASS_DESC) <TAB> yield Enum(Bit(self, ""form""), self.FORM_DESC) <TAB> if self[""class""].value == 0: <TAB> <TAB> yield Enum(Bits(self, ""type"", 5), self.TYPE_DESC) <TAB> else: <TAB> <TAB> yield Bits(self, ""type"", 5) <TAB> yield ASNInteger(self, ""size"", ""Size in bytes"") <TAB> size = self[""size""].value <TAB> if size: <TAB> <TAB> if self._handler: <TAB> <TAB> <TAB> for field in self._handler(self, size): <TAB> <TAB> <TAB> <TAB> yield field <TAB> <TAB> else: <TAB> <TAB> <TAB> yield RawBytes(self, ""raw"", size)",true,if self . _handler :,if self . _handler :,0.75,0.0
"def _process_service_request(self, pkttype, pktid, packet): <TAB> """"""Process a service request"""""" <TAB> # pylint: disable=unused-argument <TAB> service = packet.get_string() <TAB> packet.check_end() <TAB> if service == self._next_service: <TAB> <TAB> self.logger.debug2(""Accepting request for service %s"", service) <TAB> <TAB> self._next_service = None <TAB> <TAB> self.send_packet(MSG_SERVICE_ACCEPT, String(service)) <TAB> <TAB> if self.is_server() and service == _USERAUTH_SERVICE:  # pragma: no branch <TAB> <TAB> <TAB> self._auth_in_progress = True <TAB> <TAB> <TAB> self._send_deferred_packets() <TAB> else: <TAB> <TAB> raise DisconnectError( <TAB> <TAB> <TAB> DISC_SERVICE_NOT_AVAILABLE, ""Unexpected service request received"" <TAB> <TAB> )",true,if self . is_server ( ) and service == _USERAUTH_SERVICE :,if self . is_server ( ) and service == _USERAUTH_SERVICE :,1.0,0.0
"def _read_fixed_body( <TAB> self, content_length: int, delegate: httputil.HTTPMessageDelegate ) -> None: <TAB> while content_length > 0: <TAB> <TAB> body = await self.stream.read_bytes( <TAB> <TAB> <TAB> min(self.params.chunk_size, content_length), partial=True <TAB> <TAB> ) <TAB> <TAB> content_length -= len(body) <TAB> <TAB> if not self._write_finished or self.is_client: <TAB> <TAB> <TAB> with _ExceptionLoggingContext(app_log): <TAB> <TAB> <TAB> <TAB> ret = delegate.data_received(body) <TAB> <TAB> <TAB> <TAB> if ret is not None: <TAB> <TAB> <TAB> <TAB> <TAB> await ret",true,if not self . _write_finished or self . is_client :,if not self . _write_finished or self . is_client :,1.0,0.0
"def wait_for_child(pid, timeout=1.0): <TAB> deadline = mitogen.core.now() + timeout <TAB> while timeout < mitogen.core.now(): <TAB> <TAB> try: <TAB> <TAB> <TAB> target_pid, status = os.waitpid(pid, os.WNOHANG) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> e = sys.exc_info()[1] <TAB> <TAB> <TAB> if e.args[0] == errno.ECHILD: <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> time.sleep(0.05) <TAB> assert False, ""wait_for_child() timed out""",true,if target_pid == pid :,if target_pid == pid :,0.75,0.0
"def execute(cls, ctx, op: ""DataFrameGroupByAgg""): <TAB> try: <TAB> <TAB> pd.set_option(""mode.use_inf_as_na"", op.use_inf_as_na) <TAB> <TAB> if op.stage == OperandStage.map: <TAB> <TAB> <TAB> cls._execute_map(ctx, op) <TAB> <TAB> elif op.stage == OperandStage.combine: <TAB> <TAB> <TAB> cls._execute_combine(ctx, op) <TAB> <TAB> elif op.stage == OperandStage.agg: <TAB> <TAB> <TAB> cls._execute_agg(ctx, op) <TAB> <TAB> else:  # pragma: no cover <TAB> <TAB> <TAB> raise ValueError(""Aggregation operand not executable"") <TAB> finally: <TAB> <TAB> pd.reset_option(""mode.use_inf_as_na"")",true,elif op . stage == OperandStage . combine :,elif op . stage == OperandStage . combine :,0.75,0.0
def cut(sentence): <TAB> sentence = strdecode(sentence) <TAB> blocks = re_han.split(sentence) <TAB> for blk in blocks: <TAB> <TAB> if re_han.match(blk): <TAB> <TAB> <TAB> for word in __cut(blk): <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> yield word <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> for c in word: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield c <TAB> <TAB> else: <TAB> <TAB> <TAB> tmp = re_skip.split(blk) <TAB> <TAB> <TAB> for x in tmp: <TAB> <TAB> <TAB> <TAB> if x: <TAB> <TAB> <TAB> <TAB> <TAB> yield x,false,if word not in Force_Split_Words :,if word :,0.05,0.0
"def _iter_tags(self, type=None): <TAB> """"""Yield all raw tags (limit to |type| if specified)"""""" <TAB> for n in itertools.count(): <TAB> <TAB> tag = self._get_tag(n) <TAB> <TAB> if type is None or tag[""d_tag""] == type: <TAB> <TAB> <TAB> yield tag <TAB> <TAB> if tag[""d_tag""] == ""DT_NULL"": <TAB> <TAB> <TAB> break",true,"if type is None or tag [ ""d_tag"" ] == type :","if type is None or tag [ ""d_tag"" ] == type :",0.75,0.0
"def reverse_search_history(self, searchfor, startpos=None): <TAB> if startpos is None: <TAB> <TAB> startpos = self.history_cursor <TAB> if _ignore_leading_spaces: <TAB> <TAB> res = [ <TAB> <TAB> <TAB> (idx, line.lstrip()) <TAB> <TAB> <TAB> for idx, line in enumerate(self.history[startpos:0:-1]) <TAB> <TAB> <TAB> if line.lstrip().startswith(searchfor.lstrip()) <TAB> <TAB> ] <TAB> else: <TAB> <TAB> res = [ <TAB> <TAB> <TAB> (idx, line) <TAB> <TAB> <TAB> for idx, line in enumerate(self.history[startpos:0:-1]) <TAB> <TAB> <TAB> if line.startswith(searchfor) <TAB> <TAB> ] <TAB> if res: <TAB> <TAB> self.history_cursor -= res[0][0] <TAB> <TAB> return res[0][1].get_line_text() <TAB> return """"",true,if line . startswith ( searchfor ),if line . startswith ( searchfor ),0.75,0.0
"def value_to_db_datetime(self, value): <TAB> if value is None: <TAB> <TAB> return None <TAB> # Oracle doesn't support tz-aware datetimes <TAB> if timezone.is_aware(value): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> value = value.astimezone(timezone.utc).replace(tzinfo=None) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""Oracle backend does not support timezone-aware datetimes when USE_TZ is False."" <TAB> <TAB> <TAB> ) <TAB> return unicode(value)",true,if settings . USE_TZ :,if settings . USE_TZ :,0.75,0.0
"def _sniff(filename, oxlitype): <TAB> try: <TAB> <TAB> with open(filename, ""rb"") as fileobj: <TAB> <TAB> <TAB> header = fileobj.read(4) <TAB> <TAB> <TAB> if header == b""OXLI"": <TAB> <TAB> <TAB> <TAB> fileobj.read(1)  # skip the version number <TAB> <TAB> <TAB> <TAB> ftype = fileobj.read(1) <TAB> <TAB> <TAB> <TAB> if binascii.hexlify(ftype) == oxlitype: <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> return False <TAB> except OSError: <TAB> <TAB> return False",false,if binascii . hexlify ( ftype ) == oxlitype :,"if header == b""OXLI"" :",0.01,0.0
"def unget(self, char): <TAB> # Only one character is allowed to be ungotten at once - it must <TAB> # be consumed again before any further call to unget <TAB> if char is not EOF: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # unget is called quite rarely, so it's a good idea to do <TAB> <TAB> <TAB> # more work here if it saves a bit of work in the frequently <TAB> <TAB> <TAB> # called char and charsUntil. <TAB> <TAB> <TAB> # So, just prepend the ungotten character onto the current <TAB> <TAB> <TAB> # chunk: <TAB> <TAB> <TAB> self.chunk = char + self.chunk <TAB> <TAB> <TAB> self.chunkSize += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> self.chunkOffset -= 1 <TAB> <TAB> <TAB> assert self.chunk[self.chunkOffset] == char",true,if self . chunkOffset == 0 :,if self . chunkOffset == 0 :,0.75,0.0
"def scan(rule, extensions, paths, ignore_paths=None): <TAB> """"""The libsast scan."""""" <TAB> try: <TAB> <TAB> options = { <TAB> <TAB> <TAB> ""match_rules"": rule, <TAB> <TAB> <TAB> ""match_extensions"": extensions, <TAB> <TAB> <TAB> ""ignore_paths"": ignore_paths, <TAB> <TAB> <TAB> ""show_progress"": False, <TAB> <TAB> } <TAB> <TAB> scanner = Scanner(options, paths) <TAB> <TAB> res = scanner.scan() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return format_findings(res[""pattern_matcher""], paths[0]) <TAB> except Exception: <TAB> <TAB> logger.exception(""libsast scan"") <TAB> return {}",true,if res :,if res :,0.53,0.0
"def _getPatternTemplate(pattern, key=None): <TAB> if key is None: <TAB> <TAB> key = pattern <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> key = pattern.upper() <TAB> template = DD_patternCache.get(key) <TAB> if not template: <TAB> <TAB> if key in (""EPOCH"", ""{^LN-BEG}EPOCH"", ""^EPOCH""): <TAB> <TAB> <TAB> template = DateEpoch(lineBeginOnly=(key != ""EPOCH"")) <TAB> <TAB> elif key in (""TAI64N"", ""{^LN-BEG}TAI64N"", ""^TAI64N""): <TAB> <TAB> <TAB> template = DateTai64n(wordBegin=(""start"" if key != ""TAI64N"" else False)) <TAB> <TAB> else: <TAB> <TAB> <TAB> template = DatePatternRegex(pattern) <TAB> DD_patternCache.set(key, template) <TAB> return template",false,"if ""%"" not in pattern :",if not key :,0.03,0.0
"def _forward_response(self, src, dst): <TAB> """"""Forward an SCP response between two remote SCP servers"""""" <TAB> # pylint: disable=no-self-use <TAB> try: <TAB> <TAB> exc = yield from src.await_response() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> dst.send_error(exc) <TAB> <TAB> <TAB> return exc <TAB> <TAB> else: <TAB> <TAB> <TAB> dst.send_ok() <TAB> <TAB> <TAB> return None <TAB> except OSError as exc: <TAB> <TAB> return exc",true,if exc :,if exc :,0.53,0.0
"def _maybe_signal_recovery_end() -> None: <TAB> if self.in_recovery and not self.active_remaining_total(): <TAB> <TAB> # apply anything stuck in the buffers <TAB> <TAB> self.flush_buffers() <TAB> <TAB> self._set_recovery_ended() <TAB> <TAB> if self._actives_span is not None: <TAB> <TAB> <TAB> self._actives_span.set_tag(""Actives-Ready"", True) <TAB> <TAB> self.signal_recovery_end.set()",true,if self . _actives_span is not None :,if self . _actives_span is not None :,0.75,0.0
"def main(): <TAB> tmpdir = None <TAB> try: <TAB> <TAB> # Create a temporary working directory <TAB> <TAB> tmpdir = tempfile.mkdtemp() <TAB> <TAB> # Unpack the zipfile into the temporary directory <TAB> <TAB> pip_zip = os.path.join(tmpdir, ""pip.zip"") <TAB> <TAB> with open(pip_zip, ""wb"") as fp: <TAB> <TAB> <TAB> fp.write(b85decode(DATA.replace(b""\n"", b""""))) <TAB> <TAB> # Add the zipfile to sys.path so that we can import it <TAB> <TAB> sys.path.insert(0, pip_zip) <TAB> <TAB> # Run the bootstrap <TAB> <TAB> bootstrap(tmpdir=tmpdir) <TAB> finally: <TAB> <TAB> # Clean up our temporary working directory <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> shutil.rmtree(tmpdir, ignore_errors=True)",true,if tmpdir :,if tmpdir :,0.53,0.0
"def __init__(self, api_version_str): <TAB> try: <TAB> <TAB> self.latest = self.preview = False <TAB> <TAB> self.yyyy = self.mm = self.dd = None <TAB> <TAB> if api_version_str == ""latest"": <TAB> <TAB> <TAB> self.latest = True <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.preview = True <TAB> <TAB> <TAB> parts = api_version_str.split(""-"") <TAB> <TAB> <TAB> self.yyyy = int(parts[0]) <TAB> <TAB> <TAB> self.mm = int(parts[1]) <TAB> <TAB> <TAB> self.dd = int(parts[2]) <TAB> except (ValueError, TypeError): <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> ""The API version {} is not in a "" ""supported format"".format(api_version_str) <TAB> <TAB> )",false,"if ""preview"" in api_version_str :","if ""-"" in api_version_str :",0.39,0.0
"def _merge(self, items, map_id, dep_id, use_disk, meminfo, mem_limit): <TAB> combined = self.combined <TAB> merge_combiner = self.aggregator.mergeCombiners <TAB> for k, v in items: <TAB> <TAB> o = combined.get(k) <TAB> <TAB> combined[k] = merge_combiner(o, v) if o is not None else v <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> mem_limit = self._rotate()",false,if use_disk and meminfo . rss > mem_limit :,if mem_limit is None :,0.09,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.set_value(d.getVarInt32()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0: <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 8 :,if tt == 8 :,0.75,0.0
"def nice(deltat): <TAB> # singular,plural <TAB> times = _( <TAB> <TAB> ""second,seconds:minute,minutes:hour,hours:day,days:week,weeks:month,months:year,years"" <TAB> ).split("":"") <TAB> d = abs(int(deltat)) <TAB> for div, time in zip((60, 60, 24, 7, 4, 12, 100), times): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ""%s%i %s"" % (deltat < 0 and ""-"" or """", d, time.split("","")[d != 1]) <TAB> <TAB> d /= div",false,if d < div * 5 :,if div == 1 :,0.09,0.0
"def after_get_object(self, event, view_kwargs): <TAB> if event and event.state == ""draft"": <TAB> <TAB> if not is_logged_in() or not has_access(""is_coorganizer"", event_id=event.id): <TAB> <TAB> <TAB> raise ObjectNotFound({""parameter"": ""{id}""}, ""Event: not found"")",true,"if not is_logged_in ( ) or not has_access ( ""is_coorganizer"" , event_id = event . id ) :","if not is_logged_in ( ) or not has_access ( ""is_coorganizer"" , event_id = event . id ) :",1.0,0.0
def daemonize_if_required(self): <TAB> if self.options.daemon: <TAB> <TAB> if self._setup_mp_logging_listener_ is True: <TAB> <TAB> <TAB> # Stop the logging queue listener for the current process <TAB> <TAB> <TAB> # We'll restart it once forked <TAB> <TAB> <TAB> log.shutdown_multiprocessing_logging_listener(daemonizing=True) <TAB> <TAB> # Late import so logging works correctly <TAB> <TAB> salt.utils.process.daemonize() <TAB> # Setup the multiprocessing log queue listener if enabled <TAB> self._setup_mp_logging_listener(),true,if self . _setup_mp_logging_listener_ is True :,if self . _setup_mp_logging_listener_ is True :,0.75,0.0
"def iter_modules(self, by_clients=False, clients_filter=None): <TAB> """"""iterate over all modules"""""" <TAB> clients = None <TAB> if by_clients: <TAB> <TAB> clients = self.get_clients(clients_filter) <TAB> <TAB> if not clients: <TAB> <TAB> <TAB> return <TAB> self._refresh_modules() <TAB> for module_name in self.modules: <TAB> <TAB> try: <TAB> <TAB> <TAB> module = self.get_module(module_name) <TAB> <TAB> except PupyModuleDisabled: <TAB> <TAB> <TAB> continue <TAB> <TAB> if clients is not None: <TAB> <TAB> <TAB> for client in clients: <TAB> <TAB> <TAB> <TAB> if module.is_compatible_with(client): <TAB> <TAB> <TAB> <TAB> <TAB> yield module <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> yield module",true,if module . is_compatible_with ( client ) :,if module . is_compatible_with ( client ) :,0.75,0.0
"def _incremental_avg_dp(self, avg, new_el, idx): <TAB> for attr in [""coarse_segm"", ""fine_segm"", ""u"", ""v""]: <TAB> <TAB> setattr( <TAB> <TAB> <TAB> avg, attr, (getattr(avg, attr) * idx + getattr(new_el, attr)) / (idx + 1) <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # Deletion of the > 0 index intermediary values to prevent GPU OOM <TAB> <TAB> <TAB> setattr(new_el, attr, None) <TAB> return avg",false,if idx :,if idx == 0 :,0.1,0.0
"def run(self, paths=[]): <TAB> collapsed = False <TAB> for item in SideBarSelection(paths).getSelectedDirectories(): <TAB> <TAB> for view in item.views(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> Window().focus_view(view) <TAB> <TAB> <TAB> <TAB> self.collapse_sidebar_folder() <TAB> <TAB> <TAB> <TAB> collapsed = True <TAB> <TAB> <TAB> view.close()",false,if not collapsed :,if collapsed :,0.1,0.0
"def test_reductions(expr, rdd): <TAB> result = compute(expr, rdd) <TAB> expected = compute(expr, data) <TAB> if not result == expected: <TAB> <TAB> print(result) <TAB> <TAB> print(expected) <TAB> <TAB> if isinstance(result, float): <TAB> <TAB> <TAB> assert abs(result - expected) < 0.001 <TAB> <TAB> else: <TAB> <TAB> <TAB> assert result == expected",true,"if isinstance ( result , float ) :","if isinstance ( result , float ) :",0.75,0.0
"def deltask(task, d): <TAB> if task[:3] != ""do_"": <TAB> <TAB> task = ""do_"" + task <TAB> bbtasks = d.getVar(""__BBTASKS"", False) or [] <TAB> if task in bbtasks: <TAB> <TAB> bbtasks.remove(task) <TAB> <TAB> d.delVarFlag(task, ""task"") <TAB> <TAB> d.setVar(""__BBTASKS"", bbtasks) <TAB> d.delVarFlag(task, ""deps"") <TAB> for bbtask in d.getVar(""__BBTASKS"", False) or []: <TAB> <TAB> deps = d.getVarFlag(bbtask, ""deps"", False) or [] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> deps.remove(task) <TAB> <TAB> <TAB> d.setVarFlag(bbtask, ""deps"", deps)",true,if task in deps :,if task in deps :,0.75,0.0
"def _apply_weightnorm(self, list_layers): <TAB> """"""Try apply weightnorm for all layer in list_layers."""""" <TAB> for i in range(len(list_layers)): <TAB> <TAB> try: <TAB> <TAB> <TAB> layer_name = list_layers[i].name.lower() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> list_layers[i] = WeightNormalization(list_layers[i]) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> pass",false,"if ""conv1d"" in layer_name or ""dense"" in layer_name :",if layer_name in self . weight_layers :,0.02,0.0
"def __init__(self, execution_context, aggregate_operators): <TAB> super(_QueryExecutionAggregateEndpointComponent, self).__init__(execution_context) <TAB> self._local_aggregators = [] <TAB> self._results = None <TAB> self._result_index = 0 <TAB> for operator in aggregate_operators: <TAB> <TAB> if operator == ""Average"": <TAB> <TAB> <TAB> self._local_aggregators.append(_AverageAggregator()) <TAB> <TAB> elif operator == ""Count"": <TAB> <TAB> <TAB> self._local_aggregators.append(_CountAggregator()) <TAB> <TAB> elif operator == ""Max"": <TAB> <TAB> <TAB> self._local_aggregators.append(_MaxAggregator()) <TAB> <TAB> elif operator == ""Min"": <TAB> <TAB> <TAB> self._local_aggregators.append(_MinAggregator()) <TAB> <TAB> elif operator == ""Sum"": <TAB> <TAB> <TAB> self._local_aggregators.append(_SumAggregator())",false,"elif operator == ""Max"" :","elif operator == ""Min"" :",0.64,0.0
"def _conv_layer(self, sess, bottom, name, trainable=True, padding=""SAME"", relu=True): <TAB> with tf.variable_scope(name) as scope: <TAB> <TAB> filt = self._get_conv_filter(sess, name, trainable=trainable) <TAB> <TAB> conv_biases = self._get_bias(sess, name, trainable=trainable) <TAB> <TAB> conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding=padding) <TAB> <TAB> bias = tf.nn.bias_add(conv, conv_biases) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> bias = tf.nn.relu(bias) <TAB> <TAB> return bias",true,if relu :,if relu :,0.53,0.0
"def get_partners(self) -> Dict[AbstractNode, Set[int]]: <TAB> partners = {}  # type: Dict[AbstractNode, Set[int]] <TAB> for edge in self.edges: <TAB> <TAB> if edge.is_dangling(): <TAB> <TAB> <TAB> raise ValueError(""Cannot contract copy tensor with dangling edges"") <TAB> <TAB> if self._is_my_trace(edge): <TAB> <TAB> <TAB> continue <TAB> <TAB> partner_node, shared_axis = self._get_partner(edge) <TAB> <TAB> if partner_node not in partners: <TAB> <TAB> <TAB> partners[partner_node] = set() <TAB> <TAB> partners[partner_node].add(shared_axis) <TAB> return partners",true,if self . _is_my_trace ( edge ) :,if self . _is_my_trace ( edge ) :,0.75,0.0
"def close(self): <TAB> with self._lock: <TAB> <TAB> """"""Close this _MultiFileWatcher object forever."""""" <TAB> <TAB> if len(self._folder_handlers) != 0: <TAB> <TAB> <TAB> self._folder_handlers = {} <TAB> <TAB> <TAB> LOGGER.debug( <TAB> <TAB> <TAB> <TAB> ""Stopping observer thread even though there is a non-zero "" <TAB> <TAB> <TAB> <TAB> ""number of event observers!"" <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> LOGGER.debug(""Stopping observer thread"") <TAB> <TAB> self._observer.stop() <TAB> <TAB> self._observer.join(timeout=5)",true,if len ( self . _folder_handlers ) != 0 :,if len ( self . _folder_handlers ) != 0 :,0.75,0.0
"def comboSelectionChanged(self, index): <TAB> text = self.comboBox.cb.itemText(index) <TAB> for i in range(self.labelList.count()): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.labelList.item(i).setCheckState(2) <TAB> <TAB> elif text != self.labelList.item(i).text(): <TAB> <TAB> <TAB> self.labelList.item(i).setCheckState(0) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.labelList.item(i).setCheckState(2)",true,"if text == """" :","if text == """" :",0.75,0.0
"def _get_messages(self): <TAB> r = [] <TAB> try: <TAB> <TAB> self._connect() <TAB> <TAB> self._login() <TAB> <TAB> for message in self._fetch(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> r.append(message) <TAB> <TAB> self._connection.expunge() <TAB> <TAB> self._connection.close() <TAB> <TAB> self._connection.logout() <TAB> except MailFetcherError as e: <TAB> <TAB> self.log(""error"", str(e)) <TAB> return r",false,if message :,if message . message_type == MailFetcherMessage . MESSAGE :,0.08,0.0
"def get_current_user(self): <TAB> try: <TAB> <TAB> if config.get(""development"") and config.get(""json_authentication_override""): <TAB> <TAB> <TAB> return config.get(""json_authentication_override"") <TAB> <TAB> tkn_header = self.request.headers[""authorization""] <TAB> except KeyError: <TAB> <TAB> raise WebAuthNError(reason=""Missing Authorization Header"") <TAB> else: <TAB> <TAB> tkn_str = tkn_header.split("" "")[-1] <TAB> try: <TAB> <TAB> tkn = self.jwt_validator(tkn_str) <TAB> except AuthenticationError as e: <TAB> <TAB> raise WebAuthNError(reason=e.message) <TAB> else: <TAB> <TAB> return tkn",true,"if config . get ( ""development"" ) and config . get ( ""json_authentication_override"" ) :","if config . get ( ""development"" ) and config . get ( ""json_authentication_override"" ) :",1.0,0.0
def _get_data(self): <TAB> formdata = self._formdata <TAB> if formdata: <TAB> <TAB> data = [] <TAB> <TAB> # TODO: Optimize? <TAB> <TAB> for item in formdata: <TAB> <TAB> <TAB> model = self.loader.get_one(item) if item else None <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> data.append(model) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self._invalid_formdata = True <TAB> <TAB> self._set_data(data) <TAB> return self._data,true,if model :,if model :,0.53,0.0
"def _getSubstrings(self, va, size, ltyp): <TAB> # rip through the desired memory range to populate any substrings <TAB> subs = set() <TAB> end = va + size <TAB> for offs in range(va, end, 1): <TAB> <TAB> loc = self.getLocation(offs, range=True) <TAB> <TAB> if loc and loc[L_LTYPE] == LOC_STRING and loc[L_VA] > va: <TAB> <TAB> <TAB> subs.add((loc[L_VA], loc[L_SIZE])) <TAB> <TAB> <TAB> if loc[L_TINFO]: <TAB> <TAB> <TAB> <TAB> subs = subs.union(set(loc[L_TINFO])) <TAB> return list(subs)",false,if loc [ L_TINFO ] :,if loc and loc [ L_LTYPE ] == LOC_STRING and loc [ L_VA ] > va :,0.13,0.0
"def monad(self): <TAB> if not self.cls_bl_idname: <TAB> <TAB> return None <TAB> for monad in bpy.data.node_groups: <TAB> <TAB> if hasattr(monad, ""cls_bl_idname""): <TAB> <TAB> <TAB> if monad.cls_bl_idname == self.cls_bl_idname: <TAB> <TAB> <TAB> <TAB> return monad <TAB> return None",true,"if hasattr ( monad , ""cls_bl_idname"" ) :","if hasattr ( monad , ""cls_bl_idname"" ) :",0.75,0.0
"def _set_peer_statuses(self): <TAB> """"""Set peer statuses."""""" <TAB> cutoff = time.time() - STALE_SECS <TAB> for peer in self.peers: <TAB> <TAB> if peer.bad: <TAB> <TAB> <TAB> peer.status = PEER_BAD <TAB> <TAB> elif peer.last_good > cutoff: <TAB> <TAB> <TAB> peer.status = PEER_GOOD <TAB> <TAB> elif peer.last_good: <TAB> <TAB> <TAB> peer.status = PEER_STALE <TAB> <TAB> else: <TAB> <TAB> <TAB> peer.status = PEER_NEVER",true,elif peer . last_good > cutoff :,elif peer . last_good > cutoff :,0.75,0.0
"def title_by_index(self, trans, index, context): <TAB> d_type = self.get_datatype(trans, context) <TAB> for i, (composite_name, composite_file) in enumerate(d_type.writable_files.items()): <TAB> <TAB> if i == index: <TAB> <TAB> <TAB> rval = composite_name <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> rval = ""{} ({})"".format(rval, composite_file.description) <TAB> <TAB> <TAB> if composite_file.optional: <TAB> <TAB> <TAB> <TAB> rval = ""%s [optional]"" % rval <TAB> <TAB> <TAB> return rval <TAB> if index < self.get_file_count(trans, context): <TAB> <TAB> return ""Extra primary file"" <TAB> return None",true,if composite_file . description :,if composite_file . description :,0.75,0.0
"def testUiViewServerDump_windowIntM1(self): <TAB> device = None <TAB> try: <TAB> <TAB> device = MockDevice(version=15, startviewserver=True) <TAB> <TAB> vc = ViewClient(device, device.serialno, adb=TRUE, autodump=False) <TAB> <TAB> vc.dump(window=-1) <TAB> <TAB> vc.findViewByIdOrRaise(""id/home"") <TAB> finally: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> device.shutdownMockViewServer()",true,if device :,if device :,0.53,0.0
"def _convertDict(self, d): <TAB> r = {} <TAB> for k, v in d.items(): <TAB> <TAB> if isinstance(v, bytes): <TAB> <TAB> <TAB> v = str(v, ""utf-8"") <TAB> <TAB> elif isinstance(v, list) or isinstance(v, tuple): <TAB> <TAB> <TAB> v = self._convertList(v) <TAB> <TAB> elif isinstance(v, dict): <TAB> <TAB> <TAB> v = self._convertDict(v) <TAB> <TAB> if isinstance(k, bytes): <TAB> <TAB> <TAB> k = str(k, ""utf-8"") <TAB> <TAB> r[k] = v <TAB> return r",false,"elif isinstance ( v , dict ) :","elif isinstance ( v , list ) or isinstance ( v , tuple ) :",0.37,0.0
"def _testSendmsgTimeout(self): <TAB> try: <TAB> <TAB> self.cli_sock.settimeout(0.03) <TAB> <TAB> try: <TAB> <TAB> <TAB> while True: <TAB> <TAB> <TAB> <TAB> self.sendmsgToServer([b""a"" * 512]) <TAB> <TAB> except socket.timeout: <TAB> <TAB> <TAB> pass <TAB> <TAB> except OSError as exc: <TAB> <TAB> <TAB> if exc.errno != errno.ENOMEM: <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> # bpo-33937 the test randomly fails on Travis CI with <TAB> <TAB> <TAB> # ""OSError: [Errno 12] Cannot allocate memory"" <TAB> <TAB> else: <TAB> <TAB> <TAB> self.fail(""socket.timeout not raised"") <TAB> finally: <TAB> <TAB> self.misc_event.set()",false,if exc . errno != errno . ENOMEM :,if exc . errno != errno . ENOENT :,0.88,0.0
"def addError(self, test, err): <TAB> if err[0] is SkipTest: <TAB> <TAB> if self.showAll: <TAB> <TAB> <TAB> self.stream.writeln(str(err[1])) <TAB> <TAB> elif self.dots: <TAB> <TAB> <TAB> self.stream.write(""s"") <TAB> <TAB> <TAB> self.stream.flush() <TAB> <TAB> return <TAB> _org_AddError(self, test, err)",true,elif self . dots :,elif self . dots :,0.75,0.0
"def mouse_down(self, event): <TAB> if event.button == 1: <TAB> <TAB> if self.scrolling: <TAB> <TAB> <TAB> p = event.local <TAB> <TAB> <TAB> if self.scroll_up_rect().collidepoint(p): <TAB> <TAB> <TAB> <TAB> self.scroll_up() <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> elif self.scroll_down_rect().collidepoint(p): <TAB> <TAB> <TAB> <TAB> self.scroll_down() <TAB> <TAB> <TAB> <TAB> return <TAB> if event.button == 4: <TAB> <TAB> self.scroll_up() <TAB> if event.button == 5: <TAB> <TAB> self.scroll_down() <TAB> GridView.mouse_down(self, event)",false,elif self . scroll_down_rect ( ) . collidepoint ( p ) :,if self . scroll_up_rect ( ) . collidepoint ( p ) :,0.37,0.0
"def find_file_copyright_notices(fname): <TAB> ret = set() <TAB> f = open(fname) <TAB> lines = f.readlines() <TAB> for l in lines[:80]:  # hmmm, assume copyright to be in first 80 lines <TAB> <TAB> idx = l.lower().find(""copyright"") <TAB> <TAB> if idx < 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> copyright = l[idx + 9 :].strip() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> copyright = sanitise(copyright) <TAB> <TAB> # hmm, do a quick check to see if there's a year, <TAB> <TAB> # if not, skip it <TAB> <TAB> if not copyright.find(""200"") >= 0 and not copyright.find(""199"") >= 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> ret.add(copyright) <TAB> return ret",true,if not copyright :,if not copyright :,0.75,0.0
"def get_selectable_values(self, request): <TAB> shop = lfs.core.utils.get_default_shop(request) <TAB> countries = [] <TAB> for country in shop.shipping_countries.all(): <TAB> <TAB> if country in self.value.all(): <TAB> <TAB> <TAB> selected = True <TAB> <TAB> else: <TAB> <TAB> <TAB> selected = False <TAB> <TAB> countries.append( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> ""id"": country.id, <TAB> <TAB> <TAB> <TAB> ""name"": country.name, <TAB> <TAB> <TAB> <TAB> ""selected"": selected, <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> return countries",true,if country in self . value . all ( ) :,if country in self . value . all ( ) :,0.75,0.0
"def _addItemToLayout(self, sample, label): <TAB> col = self.layout.columnCount() <TAB> row = self.layout.rowCount() <TAB> if row: <TAB> <TAB> row -= 1 <TAB> nCol = self.columnCount * 2 <TAB> # FIRST ROW FULL <TAB> if col == nCol: <TAB> <TAB> for col in range(0, nCol, 2): <TAB> <TAB> <TAB> # FIND RIGHT COLUMN <TAB> <TAB> <TAB> if not self.layout.itemAt(row, col): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # MAKE NEW ROW <TAB> <TAB> <TAB> col = 0 <TAB> <TAB> <TAB> row += 1 <TAB> self.layout.addItem(sample, row, col) <TAB> self.layout.addItem(label, row, col + 1)",false,if col + 2 == nCol :,if col == nCol :,0.11,0.0
def contains_only_whitespace(node): <TAB> if is_tag(node): <TAB> <TAB> if not any([not is_text(s) for s in node.contents]): <TAB> <TAB> <TAB> if not any([unicode(s).strip() for s in node.contents]): <TAB> <TAB> <TAB> <TAB> return True <TAB> return False,true,if not any ( [ unicode ( s ) . strip ( ) for s in node . contents ] ) :,if not any ( [ unicode ( s ) . strip ( ) for s in node . contents ] ) :,1.0,0.0
"def tokenize_generator(cw): <TAB> ret = [] <TAB> done = {} <TAB> for op in ops: <TAB> <TAB> ch = op.symbol[0] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> sops = start_symbols[ch] <TAB> <TAB> cw.write(""case '%s':"" % ch) <TAB> <TAB> for t in gen_tests(sops, 1): <TAB> <TAB> <TAB> cw.write(t) <TAB> <TAB> done[ch] = True <TAB> return ret",true,if ch in done :,if ch in done :,0.75,0.0
"def _convertNbCharsInNbBits(self, nbChars): <TAB> nbMinBit = None <TAB> nbMaxBit = None <TAB> if nbChars is not None: <TAB> <TAB> if isinstance(nbChars, int): <TAB> <TAB> <TAB> nbMinBit = nbChars * 8 <TAB> <TAB> <TAB> nbMaxBit = nbMinBit <TAB> <TAB> else: <TAB> <TAB> <TAB> if nbChars[0] is not None: <TAB> <TAB> <TAB> <TAB> nbMinBit = nbChars[0] * 8 <TAB> <TAB> <TAB> if nbChars[1] is not None: <TAB> <TAB> <TAB> <TAB> nbMaxBit = nbChars[1] * 8 <TAB> return (nbMinBit, nbMaxBit)",true,"if isinstance ( nbChars , int ) :","if isinstance ( nbChars , int ) :",0.75,0.0
"def init(self, *args, **kwargs): <TAB> if ""_state"" not in kwargs: <TAB> <TAB> state = {} <TAB> <TAB> # Older versions have the _state entries as individual kwargs <TAB> <TAB> for arg in (""children"", ""windowState"", ""detachedPanels""): <TAB> <TAB> <TAB> if arg in kwargs: <TAB> <TAB> <TAB> <TAB> state[arg] = kwargs[arg] <TAB> <TAB> <TAB> <TAB> del kwargs[arg] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> kwargs[""_state""] = state <TAB> originalInit(self, *args, **kwargs)",true,if state :,if state :,0.53,0.0
"def spm_decode(tokens: List[str]) -> List[str]: <TAB> words = [] <TAB> pieces: List[str] = [] <TAB> for t in tokens: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if len(pieces) > 0: <TAB> <TAB> <TAB> <TAB> words.append("""".join(pieces)) <TAB> <TAB> <TAB> pieces = [t[1:]] <TAB> <TAB> else: <TAB> <TAB> <TAB> pieces.append(t) <TAB> if len(pieces) > 0: <TAB> <TAB> words.append("""".join(pieces)) <TAB> return words",false,if t [ 0 ] == DecodeMixin . spm_bos_token :,"if t [ 0 ] == "" "" and t [ 1 ] == "" "" and t [ 0 ] == "" "" :",0.25,0.0
"def _compare_dirs(self, dir1: str, dir2: str) -> List[str]: <TAB> # check that dir1 and dir2 are equivalent, <TAB> # return the diff <TAB> diff = []  # type: List[str] <TAB> for root, dirs, files in os.walk(dir1): <TAB> <TAB> for file_ in files: <TAB> <TAB> <TAB> path = os.path.join(root, file_) <TAB> <TAB> <TAB> target_path = os.path.join(dir2, os.path.split(path)[-1]) <TAB> <TAB> <TAB> if not os.path.exists(target_path): <TAB> <TAB> <TAB> <TAB> diff.append(file_) <TAB> return diff",true,if not os . path . exists ( target_path ) :,if not os . path . exists ( target_path ) :,0.75,0.0
"def credentials(self): <TAB> """"""The session credentials as a dict"""""" <TAB> creds = {} <TAB> if self._creds: <TAB> <TAB> if self._creds.access_key:  # pragma: no branch <TAB> <TAB> <TAB> creds[""aws_access_key_id""] = self._creds.access_key <TAB> <TAB> if self._creds.secret_key:  # pragma: no branch <TAB> <TAB> <TAB> creds[""aws_secret_access_key""] = self._creds.secret_key <TAB> <TAB> if self._creds.token: <TAB> <TAB> <TAB> creds[""aws_session_token""] = self._creds.token <TAB> if self._session.region_name: <TAB> <TAB> creds[""aws_region""] = self._session.region_name <TAB> if self.requester_pays: <TAB> <TAB> creds[""aws_request_payer""] = ""requester"" <TAB> return creds",true,if self . _creds . access_key :,if self . _creds . access_key :,0.75,0.0
"def got_arbiter_module_type_defined(self, mod_type): <TAB> for a in self.arbiters: <TAB> <TAB> # Do like the linkify will do after.... <TAB> <TAB> for m in getattr(a, ""modules"", []): <TAB> <TAB> <TAB> # So look at what the arbiter try to call as module <TAB> <TAB> <TAB> m = m.strip() <TAB> <TAB> <TAB> # Ok, now look in modules... <TAB> <TAB> <TAB> for mod in self.modules: <TAB> <TAB> <TAB> <TAB> # try to see if this module is the good type <TAB> <TAB> <TAB> <TAB> if getattr(mod, ""module_type"", """").strip() == mod_type.strip(): <TAB> <TAB> <TAB> <TAB> <TAB> # if so, the good name? <TAB> <TAB> <TAB> <TAB> <TAB> if getattr(mod, ""module_name"", """").strip() == m: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",false,"if getattr ( mod , ""module_name"" , """" ) . strip ( ) == m :","if getattr ( mod , ""module_type"" , """" ) . strip ( ) == mod_type . strip ( ) :",0.45,0.0
"def find_file_at_path_with_indexes(self, path, url): <TAB> if url.endswith(""/""): <TAB> <TAB> path = os.path.join(path, self.index_file) <TAB> <TAB> return self.get_static_file(path, url) <TAB> elif url.endswith(""/"" + self.index_file): <TAB> <TAB> if os.path.isfile(path): <TAB> <TAB> <TAB> return self.redirect(url, url[: -len(self.index_file)]) <TAB> else: <TAB> <TAB> try: <TAB> <TAB> <TAB> return self.get_static_file(path, url) <TAB> <TAB> except IsDirectoryError: <TAB> <TAB> <TAB> if os.path.isfile(os.path.join(path, self.index_file)): <TAB> <TAB> <TAB> <TAB> return self.redirect(url, url + ""/"") <TAB> raise MissingFileError(path)",true,"if os . path . isfile ( os . path . join ( path , self . index_file ) ) :","if os . path . isfile ( os . path . join ( path , self . index_file ) ) :",1.0,0.0
def _use_full_params(self) -> None: <TAB> for p in self.params: <TAB> <TAB> if not p._is_sharded: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> assert p._fp16_shard.storage().size() != 0 <TAB> <TAB> <TAB> <TAB> p.data = p._fp16_shard <TAB> <TAB> else: <TAB> <TAB> <TAB> assert p._full_param_padded.storage().size() != 0 <TAB> <TAB> <TAB> p.data = p._full_param_padded[: p._orig_size.numel()].view(p._orig_size),false,if self . mixed_precision :,if p . data is None :,0.11,0.0
"def _attrdata(self, cont, name, *val): <TAB> if not name: <TAB> <TAB> return None, False <TAB> if isinstance(name, Mapping): <TAB> <TAB> if val: <TAB> <TAB> <TAB> raise TypeError(""Cannot set a value to %s"" % name) <TAB> <TAB> return name, True <TAB> else: <TAB> <TAB> if val: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return {name: val[0]}, True <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise TypeError(""Too may arguments"") <TAB> <TAB> else: <TAB> <TAB> <TAB> cont = self._extra.get(cont) <TAB> <TAB> <TAB> return cont.get(name) if cont else None, False",true,if len ( val ) == 1 :,if len ( val ) == 1 :,0.75,0.0
"def evaluate(env, net, device=""cpu""): <TAB> obs = env.reset() <TAB> reward = 0.0 <TAB> steps = 0 <TAB> while True: <TAB> <TAB> obs_v = ptan.agent.default_states_preprocessor([obs]).to(device) <TAB> <TAB> action_v = net(obs_v) <TAB> <TAB> action = action_v.data.cpu().numpy()[0] <TAB> <TAB> obs, r, done, _ = env.step(action) <TAB> <TAB> reward += r <TAB> <TAB> steps += 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> return reward, steps",true,if done :,if done :,0.53,0.0
"def convert_html_js_files(app: Sphinx, config: Config) -> None: <TAB> """"""This converts string styled html_js_files to tuple styled one."""""" <TAB> html_js_files = []  # type: List[Tuple[str, Dict]] <TAB> for entry in config.html_js_files: <TAB> <TAB> if isinstance(entry, str): <TAB> <TAB> <TAB> html_js_files.append((entry, {})) <TAB> <TAB> else: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> filename, attrs = entry <TAB> <TAB> <TAB> <TAB> html_js_files.append((filename, attrs)) <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> logger.warning(__(""invalid js_file: %r, ignored""), entry) <TAB> <TAB> <TAB> <TAB> continue <TAB> config.html_js_files = html_js_files  # type: ignore",true,"if isinstance ( entry , str ) :","if isinstance ( entry , str ) :",0.75,0.0
"def _check_duplications(self, regs): <TAB> """"""n^2 loop which verifies that each reg exists only once."""""" <TAB> for reg in regs: <TAB> <TAB> count = 0 <TAB> <TAB> for r in regs: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> count += 1 <TAB> <TAB> if count > 1: <TAB> <TAB> <TAB> genutil.die(""reg %s defined more than once"" % reg)",true,if reg == r :,if reg == r :,0.75,0.0
"def PyJsHoisted_vault_(key, forget, this, arguments, var=var): <TAB> var = Scope( <TAB> <TAB> {u""this"": this, u""forget"": forget, u""key"": key, u""arguments"": arguments}, var <TAB> ) <TAB> var.registers([u""forget"", u""key""]) <TAB> if PyJsStrictEq(var.get(u""key""), var.get(u""passkey"")): <TAB> <TAB> return ( <TAB> <TAB> <TAB> var.put(u""secret"", var.get(u""null"")) <TAB> <TAB> <TAB> if var.get(u""forget"") <TAB> <TAB> <TAB> else ( <TAB> <TAB> <TAB> <TAB> var.get(u""secret"") <TAB> <TAB> <TAB> <TAB> or var.put(u""secret"", var.get(u""secretCreatorFn"")(var.get(u""object""))) <TAB> <TAB> <TAB> ) <TAB> <TAB> )",true,"if var . get ( u""forget"" )","if var . get ( u""forget"" )",0.75,0.0
"def sort_nested_dictionary_lists(d): <TAB> for k, v in d.items(): <TAB> <TAB> if isinstance(v, list): <TAB> <TAB> <TAB> for i in range(0, len(v)): <TAB> <TAB> <TAB> <TAB> if isinstance(v[i], dict): <TAB> <TAB> <TAB> <TAB> <TAB> v[i] = await sort_nested_dictionary_lists(v[i]) <TAB> <TAB> <TAB> <TAB> d[k] = sorted(v) <TAB> <TAB> if isinstance(v, dict): <TAB> <TAB> <TAB> d[k] = await sort_nested_dictionary_lists(v) <TAB> return d",true,"if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",0.75,0.0
"def transceiver(self, data): <TAB> out = [] <TAB> for t in range(8): <TAB> <TAB> if data[t] == 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> value = data[t] <TAB> <TAB> for b in range(8): <TAB> <TAB> <TAB> if value & 0x80: <TAB> <TAB> <TAB> <TAB> if len(TRANSCEIVER[t]) < b + 1: <TAB> <TAB> <TAB> <TAB> <TAB> out.append(""(unknown)"") <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> out.append(TRANSCEIVER[t][b]) <TAB> <TAB> <TAB> value <<= 1 <TAB> self.annotate(""Transceiver compliance"", "", "".join(out))",true,if len ( TRANSCEIVER [ t ] ) < b + 1 :,if len ( TRANSCEIVER [ t ] ) < b + 1 :,0.75,0.0
"def process_string(self, remove_repetitions, sequence): <TAB> string = """" <TAB> for i, char in enumerate(sequence): <TAB> <TAB> if char != self.int_to_char[self.blank_index]: <TAB> <TAB> <TAB> # if this char is a repetition and remove_repetitions=true, <TAB> <TAB> <TAB> # skip. <TAB> <TAB> <TAB> if remove_repetitions and i != 0 and char == sequence[i - 1]: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> elif char == self.labels[self.space_index]: <TAB> <TAB> <TAB> <TAB> string += "" "" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> string = string + char <TAB> return string",true,if remove_repetitions and i != 0 and char == sequence [ i - 1 ] :,if remove_repetitions and i != 0 and char == sequence [ i - 1 ] :,1.0,0.0
"def clean(self): <TAB> username = self.cleaned_data.get(""username"") <TAB> password = self.cleaned_data.get(""password"") <TAB> if username and password: <TAB> <TAB> self.user_cache = authenticate(username=username, password=password) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise forms.ValidationError(self.error_messages[""invalid_login""]) <TAB> <TAB> elif not self.user_cache.is_active: <TAB> <TAB> <TAB> raise forms.ValidationError(self.error_messages[""inactive""]) <TAB> self.check_for_test_cookie() <TAB> return self.cleaned_data",true,if self . user_cache is None :,if self . user_cache is None :,0.75,0.0
"def is_listening_for_message(conversation_id: Text, endpoint: EndpointConfig) -> bool: <TAB> """"""Check if the conversation is in need for a user message."""""" <TAB> tracker = await retrieve_tracker(endpoint, conversation_id, EventVerbosity.APPLIED) <TAB> for i, e in enumerate(reversed(tracker.get(""events"", []))): <TAB> <TAB> if e.get(""event"") == UserUttered.type_name: <TAB> <TAB> <TAB> return False <TAB> <TAB> elif e.get(""event"") == ActionExecuted.type_name: <TAB> <TAB> <TAB> return e.get(""name"") == ACTION_LISTEN_NAME <TAB> return False",true,"elif e . get ( ""event"" ) == ActionExecuted . type_name :","elif e . get ( ""event"" ) == ActionExecuted . type_name :",0.75,0.0
"def getReferences(view, name=""""): <TAB> """"""Find all reference definitions."""""" <TAB> # returns {name -> Region} <TAB> refs = [] <TAB> name = re.escape(name) <TAB> if name == """": <TAB> <TAB> refs.extend(view.find_all(r""(?<=^\[)([^\]]+)(?=\]:)"", 0)) <TAB> else: <TAB> <TAB> refs.extend(view.find_all(r""(?<=^\[)(%s)(?=\]:)"" % name, 0)) <TAB> regions = refs <TAB> ids = {} <TAB> for reg in regions: <TAB> <TAB> name = view.substr(reg).strip() <TAB> <TAB> key = name.lower() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ids[key].regions.append(reg) <TAB> <TAB> else: <TAB> <TAB> <TAB> ids[key] = Obj(regions=[reg], label=name) <TAB> return ids",true,if key in ids :,if key in ids :,0.75,0.0
"def _get_header(self, requester, header_name): <TAB> hits = sum([header_name in headers for _, headers in requester.requests]) <TAB> self.assertEquals(hits, 2 if self.revs_enabled else 1) <TAB> for url, headers in requester.requests: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if self.revs_enabled: <TAB> <TAB> <TAB> <TAB> self.assertTrue(url.endswith(""/latest""), msg=url) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.assertTrue(url.endswith(""/download_urls""), msg=url) <TAB> <TAB> <TAB> return headers.get(header_name)",false,if header_name in headers :,if url :,0.04,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.set_shuffle_name(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0: <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 10 :,if tt == 10 :,0.75,0.0
"def make_release_tree(self, base_dir, files): <TAB> """"""Make the release tree."""""" <TAB> self.mkpath(base_dir) <TAB> create_tree(base_dir, files, dry_run=self.dry_run) <TAB> if not files: <TAB> <TAB> self.log.warning(""no files to distribute -- empty manifest?"") <TAB> else: <TAB> <TAB> self.log.info(""copying files to %s..."", base_dir) <TAB> for filename in files: <TAB> <TAB> if not os.path.isfile(filename): <TAB> <TAB> <TAB> self.log.warning(""'%s' not a regular file -- skipping"", filename) <TAB> <TAB> else: <TAB> <TAB> <TAB> dest = os.path.join(base_dir, filename) <TAB> <TAB> <TAB> self.copy_file(filename, dest) <TAB> self.distribution.metadata.write_pkg_info(base_dir)",true,if not os . path . isfile ( filename ) :,if not os . path . isfile ( filename ) :,0.75,0.0
"def _parse_names_set(feature_names): <TAB> """"""Helping function of `_parse_feature_names` that parses a set of feature names."""""" <TAB> feature_collection = OrderedDict() <TAB> for feature_name in feature_names: <TAB> <TAB> if isinstance(feature_name, str): <TAB> <TAB> <TAB> feature_collection[feature_name] = ... <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""Failed to parse {}, expected string"".format(feature_name)) <TAB> return feature_collection",true,"if isinstance ( feature_name , str ) :","if isinstance ( feature_name , str ) :",0.75,0.0
"def get_connection(self, url, proxies=None): <TAB> with self.pools.lock: <TAB> <TAB> pool = self.pools.get(url) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return pool <TAB> <TAB> pool = NpipeHTTPConnectionPool( <TAB> <TAB> <TAB> self.npipe_path, self.timeout, maxsize=self.max_pool_size <TAB> <TAB> ) <TAB> <TAB> self.pools[url] = pool <TAB> return pool",true,if pool :,if pool :,0.53,0.0
"def _parse_dimensions(dimensions): <TAB> arrays = [] <TAB> names = [] <TAB> for key in dimensions: <TAB> <TAB> values = [v[""name""] for v in key[""values""]] <TAB> <TAB> role = key.get(""role"", None) <TAB> <TAB> if role in (""time"", ""TIME_PERIOD""): <TAB> <TAB> <TAB> values = [_fix_quarter_values(v) for v in values] <TAB> <TAB> <TAB> values = pd.DatetimeIndex(values) <TAB> <TAB> arrays.append(values) <TAB> <TAB> names.append(key[""name""]) <TAB> midx = pd.MultiIndex.from_product(arrays, names=names) <TAB> if len(arrays) == 1 and isinstance(midx, pd.MultiIndex): <TAB> <TAB> # Fix for pandas >= 0.21 <TAB> <TAB> midx = midx.levels[0] <TAB> return midx",true,"if role in ( ""time"" , ""TIME_PERIOD"" ) :","if role in ( ""time"" , ""TIME_PERIOD"" ) :",0.75,0.0
"def _add_trials(self, name, spec): <TAB> """"""Add trial by invoking TrialRunner."""""" <TAB> resource = {} <TAB> resource[""trials""] = [] <TAB> trial_generator = BasicVariantGenerator() <TAB> trial_generator.add_configurations({name: spec}) <TAB> while not trial_generator.is_finished(): <TAB> <TAB> trial = trial_generator.next_trial() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> runner.add_trial(trial) <TAB> <TAB> resource[""trials""].append(self._trial_info(trial)) <TAB> return resource",true,if not trial :,if not trial :,0.75,0.0
"def _retrieve_key(self): <TAB> url = ""http://www.canadapost.ca/cpo/mc/personal/postalcode/fpc.jsf"" <TAB> text = """" <TAB> try: <TAB> <TAB> r = requests.get(url, timeout=self.timeout, proxies=self.proxies) <TAB> <TAB> text = r.text <TAB> except: <TAB> <TAB> self.error = ""ERROR - URL Connection"" <TAB> if text: <TAB> <TAB> expression = r""'(....-....-....-....)';"" <TAB> <TAB> pattern = re.compile(expression) <TAB> <TAB> match = pattern.search(text) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.key = match.group(1) <TAB> <TAB> <TAB> return self.key <TAB> <TAB> else: <TAB> <TAB> <TAB> self.error = ""ERROR - No API Key""",true,if match :,if match :,0.53,0.0
"def test_net(net, env, count=10, device=""cpu""): <TAB> rewards = 0.0 <TAB> steps = 0 <TAB> for _ in range(count): <TAB> <TAB> obs = env.reset() <TAB> <TAB> while True: <TAB> <TAB> <TAB> obs_v = ptan.agent.float32_preprocessor([obs]).to(device) <TAB> <TAB> <TAB> mu_v = net(obs_v)[0] <TAB> <TAB> <TAB> action = mu_v.squeeze(dim=0).data.cpu().numpy() <TAB> <TAB> <TAB> action = np.clip(action, -1, 1) <TAB> <TAB> <TAB> obs, reward, done, _ = env.step(action) <TAB> <TAB> <TAB> rewards += reward <TAB> <TAB> <TAB> steps += 1 <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> return rewards / count, steps / count",true,if done :,if done :,0.53,0.0
"def compile(self, filename, obfuscate=False, raw=False, magic=""\x00"" * 8): <TAB> body = marshal.dumps(compile(self.visit(self._source_ast), filename, ""exec"")) <TAB> if obfuscate: <TAB> <TAB> body_len = len(body) <TAB> <TAB> offset = 0 if raw else 8 <TAB> <TAB> output = bytearray(body_len + 8) <TAB> <TAB> for i, x in enumerate(body): <TAB> <TAB> <TAB> output[i + offset] = ord(x) ^ ((2 ** ((65535 - i) % 65535)) % 251) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for i in xrange(8): <TAB> <TAB> <TAB> <TAB> output[i] = 0 <TAB> <TAB> return output <TAB> elif raw: <TAB> <TAB> return body <TAB> else: <TAB> <TAB> return magic + body",true,if raw :,if raw :,0.53,0.0
"def _map_saslprep(s): <TAB> """"""Map stringprep table B.1 to nothing and C.1.2 to ASCII space"""""" <TAB> r = [] <TAB> for c in s: <TAB> <TAB> if stringprep.in_table_c12(c): <TAB> <TAB> <TAB> r.append("" "") <TAB> <TAB> elif not stringprep.in_table_b1(c): <TAB> <TAB> <TAB> r.append(c) <TAB> return """".join(r)",true,elif not stringprep . in_table_b1 ( c ) :,elif not stringprep . in_table_b1 ( c ) :,0.75,0.0
"def ensemble(self, pairs, other_preds): <TAB> """"""Ensemble the dict with statistical model predictions."""""" <TAB> lemmas = [] <TAB> assert len(pairs) == len(other_preds) <TAB> for p, pred in zip(pairs, other_preds): <TAB> <TAB> w, pos = p <TAB> <TAB> if (w, pos) in self.composite_dict: <TAB> <TAB> <TAB> lemma = self.composite_dict[(w, pos)] <TAB> <TAB> elif w in self.word_dict: <TAB> <TAB> <TAB> lemma = self.word_dict[w] <TAB> <TAB> else: <TAB> <TAB> <TAB> lemma = pred <TAB> <TAB> if lemma is None: <TAB> <TAB> <TAB> lemma = w <TAB> <TAB> lemmas.append(lemma) <TAB> return lemmas",true,elif w in self . word_dict :,elif w in self . word_dict :,0.75,0.0
"def quiet_f(*args): <TAB> vars = {arg_name: Real(arg) for arg_name, arg in zip(arg_names, args)} <TAB> value = dynamic_scoping(quiet_expr.evaluate, vars, evaluation) <TAB> if expect_list: <TAB> <TAB> if value.has_form(""List"", None): <TAB> <TAB> <TAB> value = [extract_pyreal(item) for item in value.leaves] <TAB> <TAB> <TAB> if any(item is None for item in value): <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> return value <TAB> <TAB> else: <TAB> <TAB> <TAB> return None <TAB> else: <TAB> <TAB> value = extract_pyreal(value) <TAB> <TAB> if value is None or isinf(value) or isnan(value): <TAB> <TAB> <TAB> return None <TAB> <TAB> return value",true,"if value . has_form ( ""List"" , None ) :","if value . has_form ( ""List"" , None ) :",0.75,0.0
"def _copy_package_apps( <TAB> local_bin_dir: Path, app_paths: List[Path], suffix: str = """" ) -> None: <TAB> for src_unresolved in app_paths: <TAB> <TAB> src = src_unresolved.resolve() <TAB> <TAB> app = src.name <TAB> <TAB> dest = Path(local_bin_dir / add_suffix(app, suffix)) <TAB> <TAB> if not dest.parent.is_dir(): <TAB> <TAB> <TAB> mkdir(dest.parent) <TAB> <TAB> if dest.exists(): <TAB> <TAB> <TAB> logger.warning(f""{hazard}  Overwriting file {str(dest)} with {str(src)}"") <TAB> <TAB> <TAB> dest.unlink() <TAB> <TAB> if src.exists(): <TAB> <TAB> <TAB> shutil.copy(src, dest)",false,if dest . exists ( ) :,if src . exists ( ) :,0.57,0.0
"def assert_readback(vehicle, values): <TAB> i = 10 <TAB> while i > 0: <TAB> <TAB> time.sleep(0.1) <TAB> <TAB> i -= 0.1 <TAB> <TAB> for k, v in values.items(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> break <TAB> if i <= 0: <TAB> <TAB> raise Exception(""Did not match in channels readback %s"" % values)",false,if vehicle . channels [ k ] != v :,if v . channel_id == vehicle . channel_id :,0.08,0.0
"def _get_linode_client(self): <TAB> api_key = self.credentials.conf(""key"") <TAB> api_version = self.credentials.conf(""version"") <TAB> if api_version == """": <TAB> <TAB> api_version = None <TAB> if not api_version: <TAB> <TAB> api_version = 3 <TAB> <TAB> # Match for v4 api key <TAB> <TAB> regex_v4 = re.compile(""^[0-9a-f]{64}$"") <TAB> <TAB> regex_match = regex_v4.match(api_key) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> api_version = 4 <TAB> else: <TAB> <TAB> api_version = int(api_version) <TAB> return _LinodeLexiconClient(api_key, api_version)",true,if regex_match :,if regex_match :,0.53,0.0
"def mergeHiLo(self, x_stats): <TAB> """"""Merge the highs and lows of another accumulator into myself."""""" <TAB> if x_stats.firsttime is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.firsttime = x_stats.firsttime <TAB> <TAB> <TAB> self.first = x_stats.first <TAB> if x_stats.lasttime is not None: <TAB> <TAB> if self.lasttime is None or x_stats.lasttime >= self.lasttime: <TAB> <TAB> <TAB> self.lasttime = x_stats.lasttime <TAB> <TAB> <TAB> self.last = x_stats.last",false,if self . firsttime is None or x_stats . firsttime < self . firsttime :,if self . firsttime is None or x_stats . firsttime >= self . firsttime :,0.6,0.0
"def _check_good_input(self, X, y=None): <TAB> if isinstance(X, dict): <TAB> <TAB> lengths = [len(X1) for X1 in X.values()] <TAB> <TAB> if len(set(lengths)) > 1: <TAB> <TAB> <TAB> raise ValueError(""Not all values of X are of equal length."") <TAB> <TAB> x_len = lengths[0] <TAB> else: <TAB> <TAB> x_len = len(X) <TAB> if y is not None: <TAB> <TAB> if len(y) != x_len: <TAB> <TAB> <TAB> raise ValueError(""X and y are not of equal length."") <TAB> if self.regression and y is not None and y.ndim == 1: <TAB> <TAB> y = y.reshape(-1, 1) <TAB> return X, y",true,if len ( set ( lengths ) ) > 1 :,if len ( set ( lengths ) ) > 1 :,0.75,0.0
"def set(self, obj, **kwargs): <TAB> """"""Check for missing event functions and substitute these with"""""" <TAB> """"""the ignore method"""""" <TAB> ignore = getattr(self, ""ignore"") <TAB> for k, v in kwargs.iteritems(): <TAB> <TAB> setattr(self, k, getattr(obj, v)) <TAB> <TAB> if k in self.combinations: <TAB> <TAB> <TAB> for k1 in self.combinations[k]: <TAB> <TAB> <TAB> <TAB> if not hasattr(self, k1): <TAB> <TAB> <TAB> <TAB> <TAB> setattr(self, k1, ignore)",false,"if not hasattr ( self , k1 ) :",if k in self . combinations :,0.02,0.0
"def _parse_list(self, tokens): <TAB> # Process left to right, allow descending in sub lists <TAB> assert tokens[0] in (""["", ""("") <TAB> delim = ""]"" if tokens.pop(0) == ""["" else "")"" <TAB> expr = ExpressionList() <TAB> while tokens and tokens[0] != delim: <TAB> <TAB> item = self._parse(tokens) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if tokens.pop(0) != "","": <TAB> <TAB> <TAB> <TAB> raise ExpressionSyntaxError('Expected: "",""') <TAB> <TAB> expr.append(item) <TAB> if not tokens or tokens[0] != delim: <TAB> <TAB> raise ExpressionSyntaxError('Missing: ""%s""' % delim) <TAB> else: <TAB> <TAB> tokens.pop(0) <TAB> return expr",false,if tokens and tokens [ 0 ] != delim :,if item :,0.01,0.0
"def param_value(self): <TAB> # This is part of the ""handle quoted extended parameters"" hack. <TAB> for token in self: <TAB> <TAB> if token.token_type == ""value"": <TAB> <TAB> <TAB> return token.stripped_value <TAB> <TAB> if token.token_type == ""quoted-string"": <TAB> <TAB> <TAB> for token in token: <TAB> <TAB> <TAB> <TAB> if token.token_type == ""bare-quoted-string"": <TAB> <TAB> <TAB> <TAB> <TAB> for token in token: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if token.token_type == ""value"": <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return token.stripped_value <TAB> return """"",false,"if token . token_type == ""quoted-string"" :","if token . token_type == ""value"" :",0.57,0.0
"def paragraph_is_fully_commented(lines, comment, main_language): <TAB> """"""Is the paragraph fully commented?"""""" <TAB> for i, line in enumerate(lines): <TAB> <TAB> if line.startswith(comment): <TAB> <TAB> <TAB> if line[len(comment) :].lstrip().startswith(comment): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if is_magic(line, main_language): <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> continue <TAB> <TAB> return i > 0 and _BLANK_LINE.match(line) <TAB> return True",false,if line . startswith ( comment ) :,if line [ len ( comment ) : ] . lstrip ( ) . startswith ( comment ) :,0.32,0.0
"def lots_connected_to_existing_roads(model): <TAB> set = [] <TAB> for h in model.HarvestCells: <TAB> <TAB> for (i, j) in model.ExistingRoads: <TAB> <TAB> <TAB> if (i in model.COriginNodeForCell[h]) or (j in model.COriginNodeForCell[h]): <TAB> <TAB> <TAB> <TAB> if h not in set: <TAB> <TAB> <TAB> <TAB> <TAB> set.append(h) <TAB> return set",true,if ( i in model . COriginNodeForCell [ h ] ) or ( j in model . COriginNodeForCell [ h ] ) :,if ( i in model . COriginNodeForCell [ h ] ) or ( j in model . COriginNodeForCell [ h ] ) :,1.0,0.0
"def detect(get_page): <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS: <TAB> <TAB> page, headers, code = get_page(get=vector) <TAB> <TAB> retval = ( <TAB> <TAB> <TAB> re.search( <TAB> <TAB> <TAB> <TAB> r""\Abarra_counter_session="", <TAB> <TAB> <TAB> <TAB> headers.get(HTTP_HEADER.SET_COOKIE, """"), <TAB> <TAB> <TAB> <TAB> re.I, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB> retval |= ( <TAB> <TAB> <TAB> re.search( <TAB> <TAB> <TAB> <TAB> r""(\A|\b)barracuda_"", headers.get(HTTP_HEADER.SET_COOKIE, """"), re.I <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> return retval",true,if retval :,if retval :,0.53,0.0
"def test_files(self): <TAB> # get names of files to test <TAB> dist_dir = os.path.join(os.path.dirname(__file__), os.pardir, os.pardir) <TAB> names = [] <TAB> for d in self.test_directories: <TAB> <TAB> test_dir = os.path.join(dist_dir, d) <TAB> <TAB> for n in os.listdir(test_dir): <TAB> <TAB> <TAB> if n.endswith("".py"") and not n.startswith(""bad""): <TAB> <TAB> <TAB> <TAB> names.append(os.path.join(test_dir, n)) <TAB> for filename in names: <TAB> <TAB> if test_support.verbose: <TAB> <TAB> <TAB> print(""Testing %s"" % filename) <TAB> <TAB> source = read_pyfile(filename) <TAB> <TAB> self.check_roundtrip(source)",true,"if n . endswith ( "".py"" ) and not n . startswith ( ""bad"" ) :","if n . endswith ( "".py"" ) and not n . startswith ( ""bad"" ) :",1.0,0.0
"def test_calibrate_target(create_target): <TAB> mod, params = testing.synthetic.get_workload() <TAB> dataset = get_calibration_dataset(mod, ""data"") <TAB> with relay.quantize.qconfig(calibrate_mode=""kl_divergence""): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> with tvm.target.Target(""llvm""): <TAB> <TAB> <TAB> <TAB> relay.quantize.quantize(mod, params, dataset) <TAB> <TAB> else: <TAB> <TAB> <TAB> # current_target = None <TAB> <TAB> <TAB> relay.quantize.quantize(mod, params, dataset)",true,if create_target :,if create_target :,0.53,0.0
"def _cleanSubmodule(self, _=None): <TAB> rc = RC_SUCCESS <TAB> if self.submodules: <TAB> <TAB> command = [ <TAB> <TAB> <TAB> ""submodule"", <TAB> <TAB> <TAB> ""foreach"", <TAB> <TAB> <TAB> ""--recursive"", <TAB> <TAB> <TAB> ""git"", <TAB> <TAB> <TAB> ""clean"", <TAB> <TAB> <TAB> ""-f"", <TAB> <TAB> <TAB> ""-f"", <TAB> <TAB> <TAB> ""-d"", <TAB> <TAB> ] <TAB> <TAB> if self.mode == ""full"" and self.method == ""fresh"": <TAB> <TAB> <TAB> command.append(""-x"") <TAB> <TAB> rc = yield self._dovccmd(command) <TAB> defer.returnValue(rc)",true,"if self . mode == ""full"" and self . method == ""fresh"" :","if self . mode == ""full"" and self . method == ""fresh"" :",1.0,0.0
"def screen_length_to_bytes_count(string, screen_length_limit, encoding): <TAB> bytes_count = 0 <TAB> screen_length = 0 <TAB> for unicode_char in string: <TAB> <TAB> screen_length += screen_len(unicode_char) <TAB> <TAB> char_bytes_count = len(unicode_char.encode(encoding)) <TAB> <TAB> bytes_count += char_bytes_count <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> bytes_count -= char_bytes_count <TAB> <TAB> <TAB> break <TAB> return bytes_count",false,if screen_length > screen_length_limit :,if bytes_count >= screen_length_limit :,0.31,0.0
"def tamper(payload, **kwargs): <TAB> junk_chars = ""!#$%&()*~+-_.,:;?@[/|\]^`"" <TAB> retval = """" <TAB> for i, char in enumerate(payload, start=1): <TAB> <TAB> amount = random.randint(10, 15) <TAB> <TAB> if char == "">"": <TAB> <TAB> <TAB> retval += "">"" <TAB> <TAB> <TAB> for _ in range(amount): <TAB> <TAB> <TAB> <TAB> retval += random.choice(junk_chars) <TAB> <TAB> elif char == ""<"": <TAB> <TAB> <TAB> retval += ""<"" <TAB> <TAB> <TAB> for _ in range(amount): <TAB> <TAB> <TAB> <TAB> retval += random.choice(junk_chars) <TAB> <TAB> elif char == "" "": <TAB> <TAB> <TAB> for _ in range(amount): <TAB> <TAB> <TAB> <TAB> retval += random.choice(junk_chars) <TAB> <TAB> else: <TAB> <TAB> <TAB> retval += char <TAB> return retval",true,"elif char == ""<"" :","elif char == ""<"" :",1.0,0.0
"def test_parse(self): <TAB> correct = 0 <TAB> for example in EXAMPLES: <TAB> <TAB> try: <TAB> <TAB> <TAB> schema.parse(example.schema_string) <TAB> <TAB> <TAB> if example.valid: <TAB> <TAB> <TAB> <TAB> correct += 1 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.fail(""Invalid schema was parsed: "" + example.schema_string) <TAB> <TAB> except: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> correct += 1 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.fail(""Valid schema failed to parse: "" + example.schema_string) <TAB> fail_msg = ""Parse behavior correct on %d out of %d schemas."" % ( <TAB> <TAB> correct, <TAB> <TAB> len(EXAMPLES), <TAB> ) <TAB> self.assertEqual(correct, len(EXAMPLES), fail_msg)",false,if not example . valid :,if example . valid :,0.28,0.0
"def _on_change(self): <TAB> changed = False <TAB> self.save() <TAB> for key, value in self.data.items(): <TAB> <TAB> if isinstance(value, bool): <TAB> <TAB> <TAB> if value: <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if isinstance(value, int): <TAB> <TAB> <TAB> if value != 1: <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> elif value is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> elif len(value) != 0: <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> break <TAB> self._reset_button.disabled = not changed",false,"if isinstance ( value , bool ) :",elif len ( value ) != 0 :,0.03,0.0
"def normalize(d: Dict[Any, Any]) -> Dict[str, Any]: <TAB> first_exception = None <TAB> for normalizer in normalizers: <TAB> <TAB> try: <TAB> <TAB> <TAB> normalized = normalizer(d) <TAB> <TAB> except KeyError as e: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> first_exception = e <TAB> <TAB> else: <TAB> <TAB> <TAB> return normalized <TAB> assert first_exception is not None <TAB> raise first_exception",false,if not first_exception :,if first_exception is None :,0.05,0.0
"def gather_callback_args(self, obj, callbacks): <TAB> session = sa.orm.object_session(obj) <TAB> for callback in callbacks: <TAB> <TAB> backref = callback.backref <TAB> <TAB> root_objs = getdotattr(obj, backref) if backref else obj <TAB> <TAB> if root_objs: <TAB> <TAB> <TAB> if not isinstance(root_objs, Iterable): <TAB> <TAB> <TAB> <TAB> root_objs = [root_objs] <TAB> <TAB> <TAB> with session.no_autoflush: <TAB> <TAB> <TAB> <TAB> for root_obj in root_objs: <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> args = self.get_callback_args(root_obj, callback) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if args: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield args",true,if root_obj :,if root_obj :,0.53,0.0
"def test_opdm_to_oqdm(self): <TAB> for file in filter(lambda x: x.endswith("".hdf5""), os.listdir(DATA_DIRECTORY)): <TAB> <TAB> molecule = MolecularData(filename=os.path.join(DATA_DIRECTORY, file)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> test_oqdm = map_one_pdm_to_one_hole_dm(molecule.fci_one_rdm) <TAB> <TAB> <TAB> true_oqdm = numpy.eye(molecule.n_qubits) - molecule.fci_one_rdm <TAB> <TAB> <TAB> assert numpy.allclose(test_oqdm, true_oqdm)",true,if molecule . fci_one_rdm is not None :,if molecule . fci_one_rdm is not None :,0.75,0.0
"def emitSubDomainData(self, subDomainData, event): <TAB> self.emitRawRirData(subDomainData, event) <TAB> for subDomainElem in subDomainData: <TAB> <TAB> if self.checkForStop(): <TAB> <TAB> <TAB> return None <TAB> <TAB> subDomain = subDomainElem.get(""subdomain"", """").strip() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.emitHostname(subDomain, event)",true,if subDomain :,if subDomain :,0.53,0.0
"def download_cve( <TAB> download_path: str, years: Optional[List[int]] = None, update: bool = False ): <TAB> if update: <TAB> <TAB> process_url(CVE_URL.format(""modified""), download_path) <TAB> else: <TAB> <TAB> all_cve_urls = get_cve_links(CVE_URL, years) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise CveLookupException(""Error: No CVE links found"") <TAB> <TAB> for url in all_cve_urls: <TAB> <TAB> <TAB> process_url(url, download_path)",true,if not all_cve_urls :,if not all_cve_urls :,0.75,0.0
"def is_special(s, i, directive): <TAB> """"""Return True if the body text contains the @ directive."""""" <TAB> # j = skip_line(s,i) ; trace(s[i:j],':',directive) <TAB> assert directive and directive[0] == ""@"" <TAB> # 10/23/02: all directives except @others must start the line. <TAB> skip_flag = directive in (""@others"", ""@all"") <TAB> while i < len(s): <TAB> <TAB> if match_word(s, i, directive): <TAB> <TAB> <TAB> return True, i <TAB> <TAB> else: <TAB> <TAB> <TAB> i = skip_line(s, i) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> i = skip_ws(s, i) <TAB> return False, -1",true,if skip_flag :,if skip_flag :,0.53,0.0
"def run_async(self, nuke_cursors): <TAB> # type: (bool) -> None <TAB> interface_type = self.view.settings().get(""git_savvy.interface"") <TAB> for cls in subclasses: <TAB> <TAB> if cls.interface_type == interface_type: <TAB> <TAB> <TAB> vid = self.view.id() <TAB> <TAB> <TAB> interface = interfaces.get(vid, None) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> interface = interfaces[vid] = cls(view=self.view) <TAB> <TAB> <TAB> interface.render(nuke_cursors=nuke_cursors)  # type: ignore[union-attr] <TAB> <TAB> <TAB> break",true,if not interface :,if not interface :,0.75,0.0
"def scan_resource_conf(self, conf): <TAB> if ""properties"" in conf: <TAB> <TAB> if ""sslEnforcement"" in conf[""properties""]: <TAB> <TAB> <TAB> if str(conf[""properties""][""sslEnforcement""]).lower() == ""enabled"": <TAB> <TAB> <TAB> <TAB> return CheckResult.PASSED <TAB> return CheckResult.FAILED",false,"if ""sslEnforcement"" in conf [ ""properties"" ] :","if str ( conf [ ""properties"" ] [ ""sslEnforcement"" ] ) . lower ( ) == ""enabled"" :",0.14,0.0
"def do_shorts( <TAB> opts: List[Tuple[str, str]], optstring: str, shortopts: str, args: List[str] ) -> Tuple[List[Tuple[str, str]], List[str]]: <TAB> while optstring != """": <TAB> <TAB> opt, optstring = optstring[0], optstring[1:] <TAB> <TAB> if short_has_arg(opt, shortopts): <TAB> <TAB> <TAB> if optstring == """": <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise GetoptError(""option -%s requires argument"" % opt, opt) <TAB> <TAB> <TAB> <TAB> optstring, args = args[0], args[1:] <TAB> <TAB> <TAB> optarg, optstring = optstring, """" <TAB> <TAB> else: <TAB> <TAB> <TAB> optarg = """" <TAB> <TAB> opts.append((""-"" + opt, optarg)) <TAB> return opts, args",true,if not args :,if not args :,0.75,0.0
"def release(self): <TAB> tid = _thread.get_ident() <TAB> with self.lock: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError(""cannot release un-acquired lock"") <TAB> <TAB> assert self.count > 0 <TAB> <TAB> self.count -= 1 <TAB> <TAB> if self.count == 0: <TAB> <TAB> <TAB> self.owner = None <TAB> <TAB> <TAB> if self.waiters: <TAB> <TAB> <TAB> <TAB> self.waiters -= 1 <TAB> <TAB> <TAB> <TAB> self.wakeup.release()",false,if self . owner != tid :,if tid in self . locks :,0.04,0.0
"def _summarize_kraken(fn): <TAB> """"""get the value at species level"""""" <TAB> kraken = {} <TAB> list_sp, list_value = [], [] <TAB> with open(fn) as handle: <TAB> <TAB> for line in handle: <TAB> <TAB> <TAB> cols = line.strip().split(""\t"") <TAB> <TAB> <TAB> sp = cols[5].strip() <TAB> <TAB> <TAB> if len(sp.split("" "")) > 1 and not sp.startswith(""cellular""): <TAB> <TAB> <TAB> <TAB> list_sp.append(sp) <TAB> <TAB> <TAB> <TAB> list_value.append(cols[0]) <TAB> kraken = {""kraken_sp"": list_sp, ""kraken_value"": list_value} <TAB> return kraken",true,"if len ( sp . split ( "" "" ) ) > 1 and not sp . startswith ( ""cellular"" ) :","if len ( sp . split ( "" "" ) ) > 1 and not sp . startswith ( ""cellular"" ) :",1.0,0.0
"def _sync_remote_run(remote_run): <TAB> assert remote_run.remote <TAB> remote_name = remote_run.remote.name <TAB> pull_args = click_util.Args(remote=remote_name, delete=False) <TAB> try: <TAB> <TAB> remote_impl_support.pull_runs([remote_run], pull_args) <TAB> except Exception as e: <TAB> <TAB> if log.getEffectiveLevel() <= logging.DEBUG: <TAB> <TAB> <TAB> log.exception(""pull %s from %s"", remote_run.id, remote_name) <TAB> <TAB> else: <TAB> <TAB> <TAB> log.error(""error pulling %s from %s: %s"", remote_run.id, remote_name, e)",true,if log . getEffectiveLevel ( ) <= logging . DEBUG :,if log . getEffectiveLevel ( ) <= logging . DEBUG :,0.75,0.0
"def group_by_sign(seq, slop=sin(pi / 18), key=lambda x: x): <TAB> sign = None <TAB> subseq = [] <TAB> for i in seq: <TAB> <TAB> ki = key(i) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> subseq.append(i) <TAB> <TAB> <TAB> if ki != 0: <TAB> <TAB> <TAB> <TAB> sign = ki / abs(ki) <TAB> <TAB> else: <TAB> <TAB> <TAB> subseq.append(i) <TAB> <TAB> <TAB> if sign * ki < -slop: <TAB> <TAB> <TAB> <TAB> sign = ki / abs(ki) <TAB> <TAB> <TAB> <TAB> yield subseq <TAB> <TAB> <TAB> <TAB> subseq = [i] <TAB> if subseq: <TAB> <TAB> yield subseq",true,if sign is None :,if sign is None :,0.75,0.0
"def import_til(self): <TAB> log(""Importing type libraries..."") <TAB> cur = self.db_cursor() <TAB> sql = ""select name from diff.program_data where type = 'til'"" <TAB> cur.execute(sql) <TAB> for row in cur.fetchall(): <TAB> <TAB> til = row[""name""] <TAB> <TAB> if type(til) is bytes: <TAB> <TAB> <TAB> til = til.decode(""utf-8"") <TAB> <TAB> try: <TAB> <TAB> <TAB> add_default_til(til) <TAB> <TAB> except: <TAB> <TAB> <TAB> log(""Error loading til %s: %s"" % (row[""name""], str(sys.exc_info()[1]))) <TAB> cur.close() <TAB> auto_wait()",true,if type ( til ) is bytes :,if type ( til ) is bytes :,0.75,0.0
"def getBranches(self): <TAB> returned = [] <TAB> for git_branch_line in self._executeGitCommandAssertSuccess(""branch"").stdout: <TAB> <TAB> if git_branch_line.startswith(""*""): <TAB> <TAB> <TAB> git_branch_line = git_branch_line[1:] <TAB> <TAB> git_branch_line = git_branch_line.strip() <TAB> <TAB> if BRANCH_ALIAS_MARKER in git_branch_line: <TAB> <TAB> <TAB> alias_name, aliased = git_branch_line.split(BRANCH_ALIAS_MARKER) <TAB> <TAB> <TAB> returned.append(branch.LocalBranchAlias(self, alias_name, aliased)) <TAB> <TAB> else: <TAB> <TAB> <TAB> returned.append(branch.LocalBranch(self, git_branch_line)) <TAB> return returned",true,"if git_branch_line . startswith ( ""*"" ) :","if git_branch_line . startswith ( ""*"" ) :",0.75,0.0
"def add_include_dirs(self, args): <TAB> ids = [] <TAB> for a in args: <TAB> <TAB> # FIXME same hack, forcibly unpack from holder. <TAB> <TAB> if hasattr(a, ""includedirs""): <TAB> <TAB> <TAB> a = a.includedirs <TAB> <TAB> if not isinstance(a, IncludeDirs): <TAB> <TAB> <TAB> raise InvalidArguments( <TAB> <TAB> <TAB> <TAB> ""Include directory to be added is not an include directory object."" <TAB> <TAB> <TAB> ) <TAB> <TAB> ids.append(a) <TAB> self.include_dirs += ids",true,"if hasattr ( a , ""includedirs"" ) :","if hasattr ( a , ""includedirs"" ) :",0.75,0.0
"def _serialize_feature(self, feature): <TAB> name = feature.unique_name() <TAB> if name not in self._features_dict: <TAB> <TAB> self._features_dict[feature.unique_name()] = feature.to_dictionary() <TAB> <TAB> for dependency in feature.get_dependencies(deep=True): <TAB> <TAB> <TAB> name = dependency.unique_name() <TAB> <TAB> <TAB> if name not in self._features_dict: <TAB> <TAB> <TAB> <TAB> self._features_dict[name] = dependency.to_dictionary()",true,if name not in self . _features_dict :,if name not in self . _features_dict :,0.75,0.0
"def generate_io(chart_type, race_configs, environment): <TAB> # output JSON structures <TAB> structures = [] <TAB> for race_config in race_configs: <TAB> <TAB> if ""io"" in race_config.charts: <TAB> <TAB> <TAB> title = chart_type.format_title( <TAB> <TAB> <TAB> <TAB> environment, <TAB> <TAB> <TAB> <TAB> race_config.track, <TAB> <TAB> <TAB> <TAB> es_license=race_config.es_license, <TAB> <TAB> <TAB> <TAB> suffix=""%s-io"" % race_config.label, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> structures.append(chart_type.io(title, environment, race_config)) <TAB> return structures",true,"if ""io"" in race_config . charts :","if ""io"" in race_config . charts :",0.75,0.0
"def format_partition(partition, partition_schema): <TAB> tokens = [] <TAB> if isinstance(partition, dict): <TAB> <TAB> for name in partition_schema: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> tok = _format_partition_kv( <TAB> <TAB> <TAB> <TAB> <TAB> name, partition[name], partition_schema[name] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> # dynamic partitioning <TAB> <TAB> <TAB> <TAB> tok = name <TAB> <TAB> <TAB> tokens.append(tok) <TAB> else: <TAB> <TAB> for name, value in zip(partition_schema, partition): <TAB> <TAB> <TAB> tok = _format_partition_kv(name, value, partition_schema[name]) <TAB> <TAB> <TAB> tokens.append(tok) <TAB> return ""PARTITION ({})"".format("", "".join(tokens))",true,if name in partition :,if name in partition :,0.75,0.0
"def to_dict(self, validate=True, ignore=(), context=None): <TAB> context = context or {} <TAB> condition = getattr(self, ""condition"", Undefined) <TAB> copy = self  # don't copy unless we need to <TAB> if condition is not Undefined: <TAB> <TAB> if isinstance(condition, core.SchemaBase): <TAB> <TAB> <TAB> pass <TAB> <TAB> elif ""field"" in condition and ""type"" not in condition: <TAB> <TAB> <TAB> kwds = parse_shorthand(condition[""field""], context.get(""data"", None)) <TAB> <TAB> <TAB> copy = self.copy(deep=[""condition""]) <TAB> <TAB> <TAB> copy.condition.update(kwds) <TAB> return super(ValueChannelMixin, copy).to_dict( <TAB> <TAB> validate=validate, ignore=ignore, context=context <TAB> )",true,"elif ""field"" in condition and ""type"" not in condition :","elif ""field"" in condition and ""type"" not in condition :",1.0,0.0
"def _checkForCommand(self): <TAB> prompt = b""cftp> "" <TAB> if self._expectingCommand and self._lineBuffer == prompt: <TAB> <TAB> buf = b""\n"".join(self._linesReceived) <TAB> <TAB> if buf.startswith(prompt): <TAB> <TAB> <TAB> buf = buf[len(prompt) :] <TAB> <TAB> self.clearBuffer() <TAB> <TAB> d, self._expectingCommand = self._expectingCommand, None <TAB> <TAB> d.callback(buf)",true,if buf . startswith ( prompt ) :,if buf . startswith ( prompt ) :,0.75,0.0
"def schedule_logger(job_id=None, delete=False): <TAB> if not job_id: <TAB> <TAB> return getLogger(""fate_flow_schedule"") <TAB> else: <TAB> <TAB> if delete: <TAB> <TAB> <TAB> with LoggerFactory.lock: <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> for key in LoggerFactory.schedule_logger_dict.keys(): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if job_id in key: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> del LoggerFactory.schedule_logger_dict[key] <TAB> <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> return True <TAB> <TAB> key = job_id + ""schedule"" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return LoggerFactory.schedule_logger_dict[key] <TAB> <TAB> return LoggerFactory.get_schedule_logger(job_id)",true,if key in LoggerFactory . schedule_logger_dict :,if key in LoggerFactory . schedule_logger_dict :,0.75,0.0
"def halfMultipartScore(nzb_name): <TAB> try: <TAB> <TAB> wrong_found = 0 <TAB> <TAB> for nr in [1, 2, 3, 4, 5, ""i"", ""ii"", ""iii"", ""iv"", ""v"", ""a"", ""b"", ""c"", ""d"", ""e""]: <TAB> <TAB> <TAB> for wrong in [""cd"", ""part"", ""dis"", ""disc"", ""dvd""]: <TAB> <TAB> <TAB> <TAB> if ""%s%s"" % (wrong, nr) in nzb_name.lower(): <TAB> <TAB> <TAB> <TAB> <TAB> wrong_found += 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return -30 <TAB> <TAB> return 0 <TAB> except: <TAB> <TAB> log.error(""Failed doing halfMultipartScore: %s"", traceback.format_exc()) <TAB> return 0",false,if wrong_found == 1 :,if wrong_found >= 5 :,0.31,0.0
"def parse_converter_args(argstr: str) -> t.Tuple[t.Tuple, t.Dict[str, t.Any]]: <TAB> argstr += "","" <TAB> args = [] <TAB> kwargs = {} <TAB> for item in _converter_args_re.finditer(argstr): <TAB> <TAB> value = item.group(""stringval"") <TAB> <TAB> if value is None: <TAB> <TAB> <TAB> value = item.group(""value"") <TAB> <TAB> value = _pythonize(value) <TAB> <TAB> if not item.group(""name""): <TAB> <TAB> <TAB> args.append(value) <TAB> <TAB> else: <TAB> <TAB> <TAB> name = item.group(""name"") <TAB> <TAB> <TAB> kwargs[name] = value <TAB> return tuple(args), kwargs",true,"if not item . group ( ""name"" ) :","if not item . group ( ""name"" ) :",0.75,0.0
"def leaves(self, unique=True): <TAB> """"""Get the leaves of the tree starting at this root."""""" <TAB> if not self.children: <TAB> <TAB> return [self] <TAB> else: <TAB> <TAB> res = list() <TAB> <TAB> for child in self.children: <TAB> <TAB> <TAB> for sub_child in child.leaves(unique=unique): <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> res.append(sub_child) <TAB> <TAB> return res",false,if not unique or sub_child not in res :,if sub_child not in res :,0.43,0.0
"def to_tree(self, tagname=None, idx=None, namespace=None): <TAB> axIds = set((ax.axId for ax in self._axes)) <TAB> for chart in self._charts: <TAB> <TAB> for id, axis in chart._axes.items(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> setattr(self, axis.tagname, axis) <TAB> <TAB> <TAB> <TAB> axIds.add(id) <TAB> return super(PlotArea, self).to_tree(tagname)",true,if id not in axIds :,if id not in axIds :,0.75,0.0
"def update_neighbor(neigh_ip_address, changes): <TAB> rets = [] <TAB> for k, v in changes.items(): <TAB> <TAB> if k == neighbors.MULTI_EXIT_DISC: <TAB> <TAB> <TAB> rets.append(_update_med(neigh_ip_address, v)) <TAB> <TAB> if k == neighbors.ENABLED: <TAB> <TAB> <TAB> rets.append(update_neighbor_enabled(neigh_ip_address, v)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> rets.append(_update_connect_mode(neigh_ip_address, v)) <TAB> return all(rets)",true,if k == neighbors . CONNECT_MODE :,if k == neighbors . CONNECT_MODE :,0.75,0.0
"def close_all_connections(): <TAB> global _managers, _lock, _in_use, _timer <TAB> _lock.acquire() <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> _timer.cancel() <TAB> <TAB> <TAB> _timer = None <TAB> <TAB> for domain, managers in _managers.items(): <TAB> <TAB> <TAB> for manager in managers: <TAB> <TAB> <TAB> <TAB> manager.close() <TAB> <TAB> _managers = {} <TAB> finally: <TAB> <TAB> _lock.release()",true,if _timer :,if _timer :,0.53,0.0
"def _instrument_model(self, model): <TAB> for key, value in list( <TAB> <TAB> model.__dict__.items() <TAB> ):  # avoid ""dictionary keys changed during iteration"" <TAB> <TAB> if isinstance(value, tf.keras.layers.Layer): <TAB> <TAB> <TAB> new_layer = self._instrument(value) <TAB> <TAB> <TAB> if new_layer is not value: <TAB> <TAB> <TAB> <TAB> setattr(model, key, new_layer) <TAB> <TAB> elif isinstance(value, list): <TAB> <TAB> <TAB> for i, item in enumerate(value): <TAB> <TAB> <TAB> <TAB> if isinstance(item, tf.keras.layers.Layer): <TAB> <TAB> <TAB> <TAB> <TAB> value[i] = self._instrument(item) <TAB> return model",true,"if isinstance ( item , tf . keras . layers . Layer ) :","if isinstance ( item , tf . keras . layers . Layer ) :",0.75,0.0
"def target_glob(tgt, hosts): <TAB> ret = {} <TAB> for host in hosts: <TAB> <TAB> if fnmatch.fnmatch(tgt, host): <TAB> <TAB> <TAB> ret[host] = copy.deepcopy(__opts__.get(""roster_defaults"", {})) <TAB> <TAB> <TAB> ret[host].update({""host"": host}) <TAB> <TAB> <TAB> if __opts__.get(""ssh_user""): <TAB> <TAB> <TAB> <TAB> ret[host].update({""user"": __opts__[""ssh_user""]}) <TAB> return ret",false,"if __opts__ . get ( ""ssh_user"" ) :","if fnmatch . fnmatch ( tgt , host ) :",0.03,0.0
"def write(self, data): <TAB> if mock_target._mirror_on_stderr: <TAB> <TAB> if self._write_line: <TAB> <TAB> <TAB> sys.stderr.write(fn + "": "") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> sys.stderr.write(data.decode(""utf8"")) <TAB> <TAB> else: <TAB> <TAB> <TAB> sys.stderr.write(data) <TAB> <TAB> if (data[-1]) == ""\n"": <TAB> <TAB> <TAB> self._write_line = True <TAB> <TAB> else: <TAB> <TAB> <TAB> self._write_line = False <TAB> super(Buffer, self).write(data)",false,if bytes :,if six . PY2 :,0.05,0.0
"def task_thread(): <TAB> while not task_queue.empty(): <TAB> <TAB> host, port, username, password = task_queue.get() <TAB> <TAB> logger.info( <TAB> <TAB> <TAB> ""try burst {}:{} use username:{} password:{}"".format( <TAB> <TAB> <TAB> <TAB> host, port, username, password <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> if telnet_login(host, port, username, password): <TAB> <TAB> <TAB> with task_queue.mutex: <TAB> <TAB> <TAB> <TAB> task_queue.queue.clear() <TAB> <TAB> <TAB> result_queue.put((username, password))",true,"if telnet_login ( host , port , username , password ) :","if telnet_login ( host , port , username , password ) :",0.75,0.0
"def _format_results(name, ppl, scores, metrics): <TAB> """"""Format results."""""" <TAB> result_str = """" <TAB> if ppl: <TAB> <TAB> result_str = ""%s ppl %.2f"" % (name, ppl) <TAB> if scores: <TAB> <TAB> for metric in metrics: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> result_str += "", %s %s %.1f"" % (name, metric, scores[metric]) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> result_str = ""%s %s %.1f"" % (name, metric, scores[metric]) <TAB> return result_str",false,if result_str :,if metric in scores :,0.05,0.0
"def info_query(self, query): <TAB> """"""Send a query which only returns 1 row"""""" <TAB> self._cmysql.query(query) <TAB> first_row = () <TAB> if self._cmysql.have_result_set: <TAB> <TAB> first_row = self._cmysql.fetch_row() <TAB> <TAB> if self._cmysql.fetch_row(): <TAB> <TAB> <TAB> self._cmysql.free_result() <TAB> <TAB> <TAB> raise errors.InterfaceError(""Query should not return more than 1 row"") <TAB> self._cmysql.free_result() <TAB> return first_row",true,if self . _cmysql . fetch_row ( ) :,if self . _cmysql . fetch_row ( ) :,0.75,0.0
"def reset_class(self): <TAB> for f in self.fields_order: <TAB> <TAB> if f.strbits and isbin(f.strbits): <TAB> <TAB> <TAB> f.value = int(f.strbits, 2) <TAB> <TAB> elif ""default_val"" in f.kargs: <TAB> <TAB> <TAB> f.value = int(f.kargs[""default_val""], 2) <TAB> <TAB> else: <TAB> <TAB> <TAB> f.value = None <TAB> <TAB> if f.fname: <TAB> <TAB> <TAB> setattr(self, f.fname, f)",false,if f . strbits and isbin ( f . strbits ) :,"elif ""default_val"" in f . kargs :",0.02,0.0
"def _walk_map_list(self, access_func): <TAB> seen = [] <TAB> cur = self <TAB> while cur: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> yield cur <TAB> <TAB> seen.append(cur.obj_offset) <TAB> <TAB> # check for signs of infinite looping <TAB> <TAB> if len(seen) > 1024: <TAB> <TAB> <TAB> break <TAB> <TAB> cur = access_func(cur)",true,if cur . obj_offset in seen :,if cur . obj_offset in seen :,0.75,0.0
def bgdel(): <TAB> q = bgdelq <TAB> while True: <TAB> <TAB> name = q.get() <TAB> <TAB> while os.path.exists(name): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> if os.path.isfile(name): <TAB> <TAB> <TAB> <TAB> <TAB> os.remove(name) <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> shutil.rmtree(name) <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> if os.path.exists(name): <TAB> <TAB> <TAB> <TAB> time.sleep(0.1),true,if os . path . isfile ( name ) :,if os . path . isfile ( name ) :,0.75,0.0
"def _find_all_variables(transfer_variable): <TAB> d = {} <TAB> for _k, _v in transfer_variable.__dict__.items(): <TAB> <TAB> if isinstance(_v, Variable): <TAB> <TAB> <TAB> d[_v._name] = _v <TAB> <TAB> elif isinstance(_v, BaseTransferVariables): <TAB> <TAB> <TAB> d.update(_find_all_variables(_v)) <TAB> return d",false,"elif isinstance ( _v , BaseTransferVariables ) :","if isinstance ( _v , Variable ) :",0.21,0.0
"def set_val(): <TAB> idx = 0 <TAB> for idx in range(0, len(model)): <TAB> <TAB> row = model[idx] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> if idx == len(os_widget.get_model()) - 1: <TAB> <TAB> <TAB> idx = -1 <TAB> os_widget.set_active(idx) <TAB> if idx == -1: <TAB> <TAB> os_widget.set_active(0) <TAB> if idx >= 0: <TAB> <TAB> return row[1] <TAB> if self.show_all_os: <TAB> <TAB> return None",false,if value and row [ 0 ] == value :,if row [ 0 ] == 0 :,0.26,0.0
"def _make_cache_key(group, window, rate, value, methods): <TAB> count, period = _split_rate(rate) <TAB> safe_rate = ""%d/%ds"" % (count, period) <TAB> parts = [group, safe_rate, value, str(window)] <TAB> if methods is not None: <TAB> <TAB> if methods == ALL: <TAB> <TAB> <TAB> methods = """" <TAB> <TAB> elif isinstance(methods, (list, tuple)): <TAB> <TAB> <TAB> methods = """".join(sorted([m.upper() for m in methods])) <TAB> <TAB> parts.append(methods) <TAB> prefix = getattr(settings, ""RATELIMIT_CACHE_PREFIX"", ""rl:"") <TAB> return prefix + hashlib.md5(u"""".join(parts).encode(""utf-8"")).hexdigest()",true,"elif isinstance ( methods , ( list , tuple ) ) :","elif isinstance ( methods , ( list , tuple ) ) :",0.75,0.0
"def findfiles(path): <TAB> files = [] <TAB> for name in os.listdir(path): <TAB> <TAB> # ignore hidden files/dirs and other unwanted files <TAB> <TAB> if name.startswith(""."") or name == ""lastsnap.jpg"": <TAB> <TAB> <TAB> continue <TAB> <TAB> pathname = os.path.join(path, name) <TAB> <TAB> st = os.lstat(pathname) <TAB> <TAB> mode = st.st_mode <TAB> <TAB> if stat.S_ISDIR(mode): <TAB> <TAB> <TAB> files.extend(findfiles(pathname)) <TAB> <TAB> elif stat.S_ISREG(mode): <TAB> <TAB> <TAB> files.append((pathname, name, st)) <TAB> return files",false,"if name . startswith ( ""."" ) or name == ""lastsnap.jpg"" :",if stat . S_ISDIR ( mode ) :,0.01,0.0
"def __getitem__(self, key): <TAB> if isinstance(key, str_types): <TAB> <TAB> keys = self.get_keys() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise KeyError(' ""{0}"" is an invalid key'.format(key)) <TAB> <TAB> else: <TAB> <TAB> <TAB> return self[keys.index(key)] <TAB> else: <TAB> <TAB> return list.__getitem__(self, key)",true,if key not in keys :,if key not in keys :,0.75,0.0
"def test_assert_set_equal(estimate: tp.Iterable[int], message: str) -> None: <TAB> reference = {1, 2, 3} <TAB> try: <TAB> <TAB> testing.assert_set_equal(estimate, reference) <TAB> except AssertionError as error: <TAB> <TAB> if not message: <TAB> <TAB> <TAB> raise AssertionError( <TAB> <TAB> <TAB> <TAB> ""An error has been raised while it should not."" <TAB> <TAB> <TAB> ) from error <TAB> <TAB> np.testing.assert_equal(error.args[0].split(""\n"")[1:], message) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise AssertionError(""An error should have been raised."")",false,if message :,if not np . testing . is_testable :,0.04,0.0
"def get_directory_info(prefix, pth, recursive): <TAB> res = [] <TAB> directory = os.listdir(pth) <TAB> directory.sort() <TAB> for p in directory: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> subp = os.path.join(pth, p) <TAB> <TAB> <TAB> p = os.path.join(prefix, p) <TAB> <TAB> <TAB> if recursive and os.path.isdir(subp): <TAB> <TAB> <TAB> <TAB> res.append([p, get_directory_info(prefix, subp, 1)]) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> res.append([p, None]) <TAB> return res",false,"if p [ 0 ] != ""."" :",if prefix :,0.02,0.0
"def check(self, runner, script, info): <TAB> if isinstance(info, ast.FunctionDef): <TAB> <TAB> for arg in info.args.args: <TAB> <TAB> <TAB> if isinstance(arg, ast.Name): <TAB> <TAB> <TAB> <TAB> if arg.id in script.modelVars: <TAB> <TAB> <TAB> <TAB> <TAB> self.problem( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""Function {0} may shadow model variable {1}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> info.name, arg.id <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> lineno=info.lineno, <TAB> <TAB> <TAB> <TAB> <TAB> )",true,"if isinstance ( arg , ast . Name ) :","if isinstance ( arg , ast . Name ) :",0.75,0.0
"def db_lookup(field, key, publish_year=None): <TAB> sql = ""select sum(ebook_count) as num from subjects where field=$field and key=$key"" <TAB> if publish_year: <TAB> <TAB> if isinstance(publish_year, (tuple, list)): <TAB> <TAB> <TAB> sql += "" and publish_year between $y1 and $y2"" <TAB> <TAB> <TAB> (y1, y2) = publish_year <TAB> <TAB> else: <TAB> <TAB> <TAB> sql += "" and publish_year=$publish_year"" <TAB> return list(ebook_count_db.query(sql, vars=locals()))[0].num",true,"if isinstance ( publish_year , ( tuple , list ) ) :","if isinstance ( publish_year , ( tuple , list ) ) :",0.75,0.0
"def put(self, session): <TAB> with sess_lock: <TAB> <TAB> self.parent.put(session) <TAB> <TAB> # Do not store the session if skip paths <TAB> <TAB> for sp in self.skip_paths: <TAB> <TAB> <TAB> if request.path.startswith(sp): <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> if session.sid in self._cache: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> del self._cache[session.sid] <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> self._cache[session.sid] = session <TAB> self._normalize()",true,if request . path . startswith ( sp ) :,if request . path . startswith ( sp ) :,0.75,0.0
"def summarize(self): <TAB> if self.bad_commit and self.good_commit: <TAB> <TAB> for subresult in self.subresults.values(): <TAB> <TAB> <TAB> sub = subresult.summarize() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return sub <TAB> <TAB> return ""Detected bad commit in {} repository:\n{} {}"".format( <TAB> <TAB> <TAB> self.repo_name, self.bad_commit, get_message(self.suite, self.bad_commit) <TAB> <TAB> ) <TAB> return """"",true,if sub :,if sub :,0.53,0.0
def compute_nullable_nonterminals(self): <TAB> nullable = {} <TAB> num_nullable = 0 <TAB> while 1: <TAB> <TAB> for p in self.grammar.Productions[1:]: <TAB> <TAB> <TAB> if p.len == 0: <TAB> <TAB> <TAB> <TAB> nullable[p.name] = 1 <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> for t in p.prod: <TAB> <TAB> <TAB> <TAB> if not t in nullable: <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> nullable[p.name] = 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> num_nullable = len(nullable) <TAB> return nullable,false,if len ( nullable ) == num_nullable :,if num_nullable == 0 :,0.02,0.0
"def _cast_float64_to_float32(self, feeds): <TAB> for input_name, input_type in self.inputs: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> feed = feeds.get(input_name) <TAB> <TAB> <TAB> if feed is not None and feed.dtype == np.float64: <TAB> <TAB> <TAB> <TAB> feeds[input_name] = feed.astype(np.float32) <TAB> return feeds",false,"if input_type == ""tensor(float)"" :",if input_type == np . float64 :,0.12,0.0
"def proc_minute(d): <TAB> if expanded[0][0] != ""*"": <TAB> <TAB> diff_min = nearest_diff_method(d.minute, expanded[0], 60) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if is_prev: <TAB> <TAB> <TAB> <TAB> d += relativedelta(minutes=diff_min, second=59) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> d += relativedelta(minutes=diff_min, second=0) <TAB> <TAB> <TAB> return True, d <TAB> return False, d",false,if diff_min is not None and diff_min != 0 :,if diff_min is not None :,0.39,0.0
"def detype(self): <TAB> if self._detyped is not None: <TAB> <TAB> return self._detyped <TAB> ctx = {} <TAB> for key, val in self._d.items(): <TAB> <TAB> if not isinstance(key, str): <TAB> <TAB> <TAB> key = str(key) <TAB> <TAB> detyper = self.get_detyper(key) <TAB> <TAB> if detyper is None: <TAB> <TAB> <TAB> # cannot be detyped <TAB> <TAB> <TAB> continue <TAB> <TAB> deval = detyper(val) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # cannot be detyped <TAB> <TAB> <TAB> continue <TAB> <TAB> ctx[key] = deval <TAB> self._detyped = ctx <TAB> return ctx",true,if deval is None :,if deval is None :,0.75,0.0
"def get_or_create_user(request, user_data): <TAB> try: <TAB> <TAB> user = User.objects.get(sso_id=user_data[""id""]) <TAB> <TAB> if user_needs_updating(user, user_data): <TAB> <TAB> <TAB> update_user(user, user_data) <TAB> <TAB> return user <TAB> except User.DoesNotExist: <TAB> <TAB> user = User.objects.create_user( <TAB> <TAB> <TAB> user_data[""username""], <TAB> <TAB> <TAB> user_data[""email""], <TAB> <TAB> <TAB> is_active=user_data.get(""is_active"", True), <TAB> <TAB> <TAB> sso_id=user_data[""id""], <TAB> <TAB> ) <TAB> <TAB> user.update_acl_key() <TAB> <TAB> setup_new_user(request.settings, user) <TAB> <TAB> return user",true,"if user_needs_updating ( user , user_data ) :","if user_needs_updating ( user , user_data ) :",0.75,0.0
"def _populate_tree(self, element, d): <TAB> """"""Populates an etree with attributes & elements, given a dict."""""" <TAB> for k, v in d.iteritems(): <TAB> <TAB> if isinstance(v, dict): <TAB> <TAB> <TAB> self._populate_dict(element, k, v) <TAB> <TAB> elif isinstance(v, list): <TAB> <TAB> <TAB> self._populate_list(element, k, v) <TAB> <TAB> elif isinstance(v, bool): <TAB> <TAB> <TAB> self._populate_bool(element, k, v) <TAB> <TAB> elif isinstance(v, basestring): <TAB> <TAB> <TAB> self._populate_str(element, k, v) <TAB> <TAB> elif type(v) in [int, float, long, complex]: <TAB> <TAB> <TAB> self._populate_number(element, k, v)",false,"elif isinstance ( v , bool ) :","elif isinstance ( v , basestring ) :",0.55,0.0
"def load(cls): <TAB> if not cls._loaded: <TAB> <TAB> cls.log.debug(""Loading action_sets..."") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> cls._find_action_sets(PATHS.ACTION_SETS_DIRECTORY) <TAB> <TAB> else: <TAB> <TAB> <TAB> cls.action_sets = JsonDecoder.load(PATHS.ACTION_SETS_JSON_FILE) <TAB> <TAB> cls.log.debug(""Done!"") <TAB> <TAB> cls._loaded = True",false,if not horizons . globals . fife . use_atlases :,if PY3 :,0.01,0.0
"def Resolve(self, updater=None): <TAB> if len(self.Conflicts): <TAB> <TAB> for setting, edge in self.Conflicts: <TAB> <TAB> <TAB> answer = self.AskUser(self.Setting, setting) <TAB> <TAB> <TAB> if answer == Gtk.ResponseType.YES: <TAB> <TAB> <TAB> <TAB> value = setting.Value.split(""|"") <TAB> <TAB> <TAB> <TAB> value.remove(edge) <TAB> <TAB> <TAB> <TAB> setting.Value = ""|"".join(value) <TAB> <TAB> <TAB> <TAB> if updater: <TAB> <TAB> <TAB> <TAB> <TAB> updater.UpdateSetting(setting) <TAB> <TAB> <TAB> if answer == Gtk.ResponseType.NO: <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",true,if answer == Gtk . ResponseType . YES :,if answer == Gtk . ResponseType . YES :,0.75,0.0
"def read_tsv(input_file, quotechar=None): <TAB> """"""Reads a tab separated value file."""""" <TAB> with open(input_file, ""r"", encoding=""utf-8-sig"") as f: <TAB> <TAB> reader = csv.reader(f, delimiter=""\t"", quotechar=quotechar) <TAB> <TAB> lines = [] <TAB> <TAB> for line in reader: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> line = list(str(cell, ""utf-8"") for cell in line)  # noqa: F821 <TAB> <TAB> <TAB> lines.append(line) <TAB> <TAB> return lines",false,if sys . version_info [ 0 ] == 2 :,if line :,0.01,0.0
"def devd_devfs_hook(middleware, data): <TAB> if data.get(""subsystem"") != ""CDEV"": <TAB> <TAB> return <TAB> if data[""type""] == ""CREATE"": <TAB> <TAB> disks = await middleware.run_in_thread( <TAB> <TAB> <TAB> lambda: sysctl.filter(""kern.disks"")[0].value.split() <TAB> <TAB> ) <TAB> <TAB> # Device notified about is not a disk <TAB> <TAB> if data[""cdev""] not in disks: <TAB> <TAB> <TAB> return <TAB> <TAB> await added_disk(middleware, data[""cdev""]) <TAB> elif data[""type""] == ""DESTROY"": <TAB> <TAB> # Device notified about is not a disk <TAB> <TAB> if not RE_ISDISK.match(data[""cdev""]): <TAB> <TAB> <TAB> return <TAB> <TAB> await remove_disk(middleware, data[""cdev""])",false,"if not RE_ISDISK . match ( data [ ""cdev"" ] ) :","if data [ ""cdev"" ] not in disks :",0.19,0.0
"def on_edit_button_clicked(self, event=None, a=None, col=None): <TAB> tree, tree_id = self.treeView.get_selection().get_selected() <TAB> watchdir_id = str(self.store.get_value(tree_id, 0)) <TAB> if watchdir_id: <TAB> <TAB> if col and col.get_title() == _(""Active""): <TAB> <TAB> <TAB> if self.watchdirs[watchdir_id][""enabled""]: <TAB> <TAB> <TAB> <TAB> client.autoadd.disable_watchdir(watchdir_id) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> client.autoadd.enable_watchdir(watchdir_id) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.opts_dialog.show(self.watchdirs[watchdir_id], watchdir_id)",true,"if col and col . get_title ( ) == _ ( ""Active"" ) :","if col and col . get_title ( ) == _ ( ""Active"" ) :",0.75,0.0
"def _execute(self, options, args): <TAB> if len(args) < 1: <TAB> <TAB> raise CommandError(_(""Not enough arguments"")) <TAB> paths = args <TAB> songs = [self.load_song(p) for p in paths] <TAB> for song in songs: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise CommandError( <TAB> <TAB> <TAB> <TAB> _(""Image editing not supported for %(file_name)s "" ""(%(file_format)s)"") <TAB> <TAB> <TAB> <TAB> % {""file_name"": song(""~filename""), ""file_format"": song(""~format"")} <TAB> <TAB> <TAB> ) <TAB> for song in songs: <TAB> <TAB> try: <TAB> <TAB> <TAB> song.clear_images() <TAB> <TAB> except AudioFileError as e: <TAB> <TAB> <TAB> raise CommandError(e)",false,if not song . can_change_images :,if song . file_name is None :,0.05,0.0
"def filter_pricing_rule_based_on_condition(pricing_rules, doc=None): <TAB> filtered_pricing_rules = [] <TAB> if doc: <TAB> <TAB> for pricing_rule in pricing_rules: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> if frappe.safe_eval(pricing_rule.condition, None, doc.as_dict()): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> filtered_pricing_rules.append(pricing_rule) <TAB> <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> filtered_pricing_rules.append(pricing_rule) <TAB> else: <TAB> <TAB> filtered_pricing_rules = pricing_rules <TAB> return filtered_pricing_rules",true,if pricing_rule . condition :,if pricing_rule . condition :,0.75,0.0
"def ProcessStringLiteral(self): <TAB> if self._lastToken == None or self._lastToken.type == self.OpenBrace: <TAB> <TAB> text = super(JavaScriptBaseLexer, self).text <TAB> <TAB> if text == '""use strict""' or text == ""'use strict'"": <TAB> <TAB> <TAB> if len(self._scopeStrictModes) > 0: <TAB> <TAB> <TAB> <TAB> self._scopeStrictModes.pop() <TAB> <TAB> <TAB> self._useStrictCurrent = True <TAB> <TAB> <TAB> self._scopeStrictModes.append(self._useStrictCurrent)",true,if len ( self . _scopeStrictModes ) > 0 :,if len ( self . _scopeStrictModes ) > 0 :,0.75,0.0
"def _find_remote_inputs(metadata): <TAB> out = [] <TAB> for fr_key in metadata.keys(): <TAB> <TAB> if isinstance(fr_key, (list, tuple)): <TAB> <TAB> <TAB> frs = fr_key <TAB> <TAB> else: <TAB> <TAB> <TAB> frs = [fr_key] <TAB> <TAB> for fr in frs: <TAB> <TAB> <TAB> if objectstore.is_remote(fr): <TAB> <TAB> <TAB> <TAB> out.append(fr) <TAB> return out",true,if objectstore . is_remote ( fr ) :,if objectstore . is_remote ( fr ) :,0.75,0.0
"def sub_paragraph(self, li): <TAB> """"""Search for checkbox in sub-paragraph."""""" <TAB> found = False <TAB> if len(li): <TAB> <TAB> first = list(li)[0] <TAB> <TAB> if first.tag == ""p"" and first.text is not None: <TAB> <TAB> <TAB> m = RE_CHECKBOX.match(first.text) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> first.text = self.markdown.htmlStash.store( <TAB> <TAB> <TAB> <TAB> <TAB> get_checkbox(m.group(""state"")), safe=True <TAB> <TAB> <TAB> <TAB> ) + m.group(""line"") <TAB> <TAB> <TAB> <TAB> found = True <TAB> return found",false,if m is not None :,if m :,0.05,0.0
"def list_files(basedir): <TAB> """"""List files in the directory rooted at |basedir|."""""" <TAB> if not os.path.isdir(basedir): <TAB> <TAB> raise NoSuchDirectory(basedir) <TAB> directories = [""""] <TAB> while directories: <TAB> <TAB> d = directories.pop() <TAB> <TAB> for basename in os.listdir(os.path.join(basedir, d)): <TAB> <TAB> <TAB> filename = os.path.join(d, basename) <TAB> <TAB> <TAB> if os.path.isdir(os.path.join(basedir, filename)): <TAB> <TAB> <TAB> <TAB> directories.append(filename) <TAB> <TAB> <TAB> elif os.path.exists(os.path.join(basedir, filename)): <TAB> <TAB> <TAB> <TAB> yield filename",false,"if os . path . isdir ( os . path . join ( basedir , filename ) ) :","elif os . path . exists ( os . path . join ( basedir , filename ) ) :",0.76,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB> if tt == 10: <TAB> <TAB> <TAB> self.set_version(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 0 :,if tt == 0 :,0.75,0.0
"def _dump(self, fd): <TAB> with self.no_unpicklable_properties(): <TAB> <TAB> if self.__module__ == ""__main__"": <TAB> <TAB> <TAB> d = pickle.dumps(self) <TAB> <TAB> <TAB> module_name = os.path.basename(sys.argv[0]).rsplit(""."", 1)[0] <TAB> <TAB> <TAB> d = d.replace(b""c__main__"", b""c"" + module_name.encode(""ascii"")) <TAB> <TAB> <TAB> fd.write(d) <TAB> <TAB> else: <TAB> <TAB> <TAB> pickle.dump(self, fd)",true,"if self . __module__ == ""__main__"" :","if self . __module__ == ""__main__"" :",0.75,0.0
"def assert_session_stack(classes): <TAB> assert len(_SklearnTrainingSession._session_stack) == len(classes) <TAB> for idx, (sess, (parent_clazz, clazz)) in enumerate( <TAB> <TAB> zip(_SklearnTrainingSession._session_stack, classes) <TAB> ): <TAB> <TAB> assert sess.clazz == clazz <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> assert sess._parent is None <TAB> <TAB> else: <TAB> <TAB> <TAB> assert sess._parent.clazz == parent_clazz",true,if idx == 0 :,if idx == 0 :,0.75,0.0
"def native_color(c): <TAB> try: <TAB> <TAB> color = CACHE[c] <TAB> except KeyError: <TAB> <TAB> if isinstance(c, str): <TAB> <TAB> <TAB> c = NAMED_COLOR[c] <TAB> <TAB> color = Color.FromArgb( <TAB> <TAB> <TAB> int(c.rgba.a * 255), int(c.rgba.r), int(c.rgba.g), int(c.rgba.b) <TAB> <TAB> ) <TAB> <TAB> CACHE[c] = color <TAB> return color",true,"if isinstance ( c , str ) :","if isinstance ( c , str ) :",0.75,0.0
"def callback(name): <TAB> # XXX: move into Action <TAB> for neighbor_name in reactor.configuration.neighbors.keys(): <TAB> <TAB> neighbor = reactor.configuration.neighbors.get(neighbor_name, None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> neighbor.rib.outgoing.announce_watchdog(name) <TAB> <TAB> yield False <TAB> reactor.processes.answer_done(service)",false,if not neighbor :,if neighbor is None :,0.05,0.0
"def token_producer(source): <TAB> token = source.read_uint8() <TAB> while token is not None: <TAB> <TAB> if is_push_data_token(token): <TAB> <TAB> <TAB> yield DataToken(read_data(token, source)) <TAB> <TAB> elif is_small_integer(token): <TAB> <TAB> <TAB> yield SmallIntegerToken(read_small_integer(token)) <TAB> <TAB> else: <TAB> <TAB> <TAB> yield Token(token) <TAB> <TAB> token = source.read_uint8()",false,if is_push_data_token ( token ) :,elif is_small_integer ( token ) :,0.24,0.0
"def setattr(self, req, ino, attr, to_set, fi): <TAB> print(""setattr:"", ino, to_set) <TAB> a = self.attr[ino] <TAB> for key in to_set: <TAB> <TAB> if key == ""st_mode"": <TAB> <TAB> <TAB> # Keep the old file type bit fields <TAB> <TAB> <TAB> a[""st_mode""] = S_IFMT(a[""st_mode""]) | S_IMODE(attr[""st_mode""]) <TAB> <TAB> else: <TAB> <TAB> <TAB> a[key] = attr[key] <TAB> self.attr[ino] = a <TAB> self.reply_attr(req, a, 1.0)",true,"if key == ""st_mode"" :","if key == ""st_mode"" :",0.75,0.0
"def check_enum_exports(module, eq_callback, only=None): <TAB> """"""Make sure module exports all mnemonics from enums"""""" <TAB> for attr in enumerate_module(module, enum.Enum): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(""SKIP"", attr) <TAB> <TAB> <TAB> continue <TAB> <TAB> for flag, value in attr.__members__.items(): <TAB> <TAB> <TAB> print(module, flag, value) <TAB> <TAB> <TAB> eq_callback(getattr(module, flag), value)",false,if only is not None and attr not in only :,if only :,0.02,0.0
"def remove_edit_vars_to(self, n): <TAB> try: <TAB> <TAB> removals = [] <TAB> <TAB> for v, cei in self.edit_var_map.items(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> removals.append(v) <TAB> <TAB> for v in removals: <TAB> <TAB> <TAB> self.remove_edit_var(v) <TAB> <TAB> assert len(self.edit_var_map) == n <TAB> except ConstraintNotFound: <TAB> <TAB> raise InternalError(""Constraint not found during internal removal"")",false,if cei . index >= n :,if cei . value == n :,0.35,0.0
"def fix_repeating_arguments(self): <TAB> """"""Fix elements that should accumulate/increment values."""""" <TAB> either = [list(child.children) for child in transform(self).children] <TAB> for case in either: <TAB> <TAB> for e in [child for child in case if case.count(child) > 1]: <TAB> <TAB> <TAB> if type(e) is Argument or type(e) is Option and e.argcount: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> e.value = [] <TAB> <TAB> <TAB> <TAB> elif type(e.value) is not list: <TAB> <TAB> <TAB> <TAB> <TAB> e.value = e.value.split() <TAB> <TAB> <TAB> if type(e) is Command or type(e) is Option and e.argcount == 0: <TAB> <TAB> <TAB> <TAB> e.value = 0 <TAB> return self",false,if e . value is None :,if type ( e . value ) is None :,0.12,0.0
"def add_I_prefix(current_line: List[str], ner: int, tag: str): <TAB> for i in range(0, len(current_line)): <TAB> <TAB> if i == 0: <TAB> <TAB> <TAB> f.write(line_list[i]) <TAB> <TAB> elif i == ner: <TAB> <TAB> <TAB> f.write("" I-"" + tag) <TAB> <TAB> else: <TAB> <TAB> <TAB> f.write("" "" + current_line[i]) <TAB> f.write(""\n"")",true,elif i == ner :,elif i == ner :,1.0,0.0
def select_word_at_cursor(self): <TAB> word_region = None <TAB> selection = self.view.sel() <TAB> for region in selection: <TAB> <TAB> word_region = self.view.word(region) <TAB> <TAB> if not word_region.empty(): <TAB> <TAB> <TAB> selection.clear() <TAB> <TAB> <TAB> selection.add(word_region) <TAB> <TAB> <TAB> return word_region <TAB> return word_region,true,if not word_region . empty ( ) :,if not word_region . empty ( ) :,0.75,0.0
"def calc(self, arg): <TAB> op = arg[""op""] <TAB> if op == ""C"": <TAB> <TAB> self.clear() <TAB> <TAB> return str(self.current) <TAB> num = decimal.Decimal(arg[""num""]) <TAB> if self.op: <TAB> <TAB> if self.op == ""+"": <TAB> <TAB> <TAB> self.current += num <TAB> <TAB> elif self.op == ""-"": <TAB> <TAB> <TAB> self.current -= num <TAB> <TAB> elif self.op == ""*"": <TAB> <TAB> <TAB> self.current *= num <TAB> <TAB> elif self.op == ""/"": <TAB> <TAB> <TAB> self.current /= num <TAB> <TAB> self.op = op <TAB> else: <TAB> <TAB> self.op = op <TAB> <TAB> self.current = num <TAB> res = str(self.current) <TAB> if op == ""="": <TAB> <TAB> self.clear() <TAB> return res",false,"elif self . op == ""-"" :","elif self . op == ""/"" :",0.82,0.0
"def strip_pod(lines): <TAB> in_pod = False <TAB> stripped_lines = [] <TAB> for line in lines: <TAB> <TAB> if re.match(r""^=(?:end|cut)"", line): <TAB> <TAB> <TAB> in_pod = False <TAB> <TAB> elif re.match(r""^=\w+"", line): <TAB> <TAB> <TAB> in_pod = True <TAB> <TAB> elif not in_pod: <TAB> <TAB> <TAB> stripped_lines.append(line) <TAB> return stripped_lines",false,elif not in_pod :,"elif re . match ( r""^=\w+"" , line ) :",0.09,0.0
"def __init__(self, patch_files, patch_directories): <TAB> files = [] <TAB> files_data = {} <TAB> for filename_data in patch_files: <TAB> <TAB> if isinstance(filename_data, list): <TAB> <TAB> <TAB> filename, data = filename_data <TAB> <TAB> else: <TAB> <TAB> <TAB> filename = filename_data <TAB> <TAB> <TAB> data = None <TAB> <TAB> if not filename.startswith(os.sep): <TAB> <TAB> <TAB> filename = ""{0}{1}"".format(FakeState.deploy_dir, filename) <TAB> <TAB> files.append(filename) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> files_data[filename] = data <TAB> self.files = files <TAB> self.files_data = files_data <TAB> self.directories = patch_directories",true,if data :,if data :,0.53,0.0
"def loadPerfsFromModule(self, module): <TAB> """"""Return a suite of all perfs cases contained in the given module"""""" <TAB> perfs = [] <TAB> for name in dir(module): <TAB> <TAB> obj = getattr(module, name) <TAB> <TAB> if type(obj) == types.ClassType and issubclass(obj, PerfCase): <TAB> <TAB> <TAB> perfs.append(self.loadPerfsFromPerfCase(obj)) <TAB> return self.suiteClass(perfs)",true,"if type ( obj ) == types . ClassType and issubclass ( obj , PerfCase ) :","if type ( obj ) == types . ClassType and issubclass ( obj , PerfCase ) :",1.0,0.0
"def download_subtitle(self, subtitle): <TAB> if isinstance(subtitle, XSubsSubtitle): <TAB> <TAB> # download the subtitle <TAB> <TAB> logger.info(""Downloading subtitle %r"", subtitle) <TAB> <TAB> r = self.session.get( <TAB> <TAB> <TAB> subtitle.download_link, headers={""Referer"": subtitle.page_link}, timeout=10 <TAB> <TAB> ) <TAB> <TAB> r.raise_for_status() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> logger.debug(""Unable to download subtitle. No data returned from provider"") <TAB> <TAB> <TAB> return <TAB> <TAB> subtitle.content = fix_line_ending(r.content)",false,if not r . content :,if r . status_code == 404 :,0.05,0.0
"def get_inlaws(self, person): <TAB> inlaws = [] <TAB> family_handles = person.get_family_handle_list() <TAB> for handle in family_handles: <TAB> <TAB> fam = self.database.get_family_from_handle(handle) <TAB> <TAB> if fam.father_handle and not fam.father_handle == person.handle: <TAB> <TAB> <TAB> inlaws.append(self.database.get_person_from_handle(fam.father_handle)) <TAB> <TAB> elif fam.mother_handle and not fam.mother_handle == person.handle: <TAB> <TAB> <TAB> inlaws.append(self.database.get_person_from_handle(fam.mother_handle)) <TAB> return inlaws",true,elif fam . mother_handle and not fam . mother_handle == person . handle :,elif fam . mother_handle and not fam . mother_handle == person . handle :,1.0,0.0
"def _check_xorg_conf(): <TAB> if is_there_a_default_xorg_conf_file(): <TAB> <TAB> print( <TAB> <TAB> <TAB> ""WARNING : Found a Xorg config file at /etc/X11/xorg.conf. If you did not"" <TAB> <TAB> <TAB> "" create it yourself, it was likely generated by your distribution or by an Nvidia utility.\n"" <TAB> <TAB> <TAB> ""This file may contain hard-coded GPU configuration that could interfere with optimus-manager,"" <TAB> <TAB> <TAB> "" so it is recommended that you delete it before proceeding.\n"" <TAB> <TAB> <TAB> ""Ignore this warning and proceed with GPU switching ? (y/N)"" <TAB> <TAB> ) <TAB> <TAB> confirmation = ask_confirmation() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> sys.exit(0)",true,if not confirmation :,if not confirmation :,0.75,0.0
"def _make_cache_key(group, window, rate, value, methods): <TAB> count, period = _split_rate(rate) <TAB> safe_rate = ""%d/%ds"" % (count, period) <TAB> parts = [group, safe_rate, value, str(window)] <TAB> if methods is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> methods = """" <TAB> <TAB> elif isinstance(methods, (list, tuple)): <TAB> <TAB> <TAB> methods = """".join(sorted([m.upper() for m in methods])) <TAB> <TAB> parts.append(methods) <TAB> prefix = getattr(settings, ""RATELIMIT_CACHE_PREFIX"", ""rl:"") <TAB> return prefix + hashlib.md5(u"""".join(parts).encode(""utf-8"")).hexdigest()",false,if methods == ALL :,if methods is None :,0.06,0.0
"def num_of_mapped_volumes(self, initiator): <TAB> cnt = 0 <TAB> for lm_link in self.req(""lun-maps"")[""lun-maps""]: <TAB> <TAB> idx = lm_link[""href""].split(""/"")[-1] <TAB> <TAB> # NOTE(geguileo): There can be races so mapped elements retrieved <TAB> <TAB> # in the listing may no longer exist. <TAB> <TAB> try: <TAB> <TAB> <TAB> lm = self.req(""lun-maps"", idx=int(idx))[""content""] <TAB> <TAB> except exception.NotFound: <TAB> <TAB> <TAB> continue <TAB> <TAB> if lm[""ig-name""] == initiator: <TAB> <TAB> <TAB> cnt += 1 <TAB> return cnt",true,"if lm [ ""ig-name"" ] == initiator :","if lm [ ""ig-name"" ] == initiator :",0.75,0.0
"def _setAbsoluteY(self, value): <TAB> if value is None: <TAB> <TAB> self._absoluteY = None <TAB> else: <TAB> <TAB> if value == ""above"": <TAB> <TAB> <TAB> value = 10 <TAB> <TAB> elif value == ""below"": <TAB> <TAB> <TAB> value = -70 <TAB> <TAB> try: <TAB> <TAB> <TAB> value = common.numToIntOrFloat(value) <TAB> <TAB> except ValueError as ve: <TAB> <TAB> <TAB> raise TextFormatException( <TAB> <TAB> <TAB> <TAB> f""Not a supported absoluteY position: {value!r}"" <TAB> <TAB> <TAB> ) from ve <TAB> <TAB> self._absoluteY = value",false,"if value == ""above"" :","elif value == ""below"" :",0.06,0.0
"def render_markdown(text): <TAB> users = {u.username.lower(): u for u in get_mention_users(text)} <TAB> parts = MENTION_RE.split(text) <TAB> for pos, part in enumerate(parts): <TAB> <TAB> if not part.startswith(""@""): <TAB> <TAB> <TAB> continue <TAB> <TAB> username = part[1:].lower() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> user = users[username] <TAB> <TAB> <TAB> parts[pos] = '**[{}]({} ""{}"")**'.format( <TAB> <TAB> <TAB> <TAB> part, user.get_absolute_url(), user.get_visible_name() <TAB> <TAB> <TAB> ) <TAB> text = """".join(parts) <TAB> return mark_safe(MARKDOWN(text))",true,if username in users :,if username in users :,0.75,0.0
def start_process(self): <TAB> with self.thread_lock: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.allow_process_request = False <TAB> <TAB> <TAB> t = threading.Thread(target=self.__start) <TAB> <TAB> <TAB> t.daemon = True <TAB> <TAB> <TAB> t.start(),true,if self . allow_process_request :,if self . allow_process_request :,0.75,0.0
"def close(self): <TAB> if self._fh.closed: <TAB> <TAB> return <TAB> self._fh.close() <TAB> if os.path.isfile(self._filename): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> salt.utils.win_dacl.copy_security( <TAB> <TAB> <TAB> <TAB> source=self._filename, target=self._tmp_filename <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> shutil.copymode(self._filename, self._tmp_filename) <TAB> <TAB> <TAB> st = os.stat(self._filename) <TAB> <TAB> <TAB> os.chown(self._tmp_filename, st.st_uid, st.st_gid) <TAB> atomic_rename(self._tmp_filename, self._filename)",false,if salt . utils . win_dacl . HAS_WIN32 :,if self . is_live :,0.07,0.0
"def _splitSchemaNameDotFieldName(sn_fn, fnRequired=True): <TAB> if sn_fn.find(""."") != -1: <TAB> <TAB> schemaName, fieldName = sn_fn.split(""."", 1) <TAB> <TAB> schemaName = schemaName.strip() <TAB> <TAB> fieldName = fieldName.strip() <TAB> <TAB> if schemaName and fieldName: <TAB> <TAB> <TAB> return (schemaName, fieldName) <TAB> elif not fnRequired: <TAB> <TAB> schemaName = sn_fn.strip() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return (schemaName, None) <TAB> controlflow.system_error_exit( <TAB> <TAB> 2, f""{sn_fn} is not a valid custom schema.field name."" <TAB> )",true,if schemaName :,if schemaName :,0.53,0.0
"def modified(self): <TAB> paths = set() <TAB> dictionary_list = [] <TAB> for op_list in self._operations: <TAB> <TAB> if not isinstance(op_list, list): <TAB> <TAB> <TAB> op_list = (op_list,) <TAB> <TAB> for item in chain(*op_list): <TAB> <TAB> <TAB> if item is None: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> dictionary = item.dictionary <TAB> <TAB> <TAB> if dictionary.path in paths: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> paths.add(dictionary.path) <TAB> <TAB> <TAB> dictionary_list.append(dictionary) <TAB> return dictionary_list",true,"if not isinstance ( op_list , list ) :","if not isinstance ( op_list , list ) :",0.75,0.0
"def apply(self, db, person): <TAB> for family_handle in person.get_family_handle_list(): <TAB> <TAB> family = db.get_family_from_handle(family_handle) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for event_ref in family.get_event_ref_list(): <TAB> <TAB> <TAB> <TAB> if event_ref: <TAB> <TAB> <TAB> <TAB> <TAB> event = db.get_event_from_handle(event_ref.ref) <TAB> <TAB> <TAB> <TAB> <TAB> if not event.get_place_handle(): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> <TAB> if not event.get_date_object(): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",true,if family :,if family :,0.53,0.0
"def test_cleanup_params(self, body, rpc_mock): <TAB> res = self._get_resp_post(body) <TAB> self.assertEqual(http_client.ACCEPTED, res.status_code) <TAB> rpc_mock.assert_called_once_with(self.context, mock.ANY) <TAB> cleanup_request = rpc_mock.call_args[0][1] <TAB> for key, value in body.items(): <TAB> <TAB> if key in (""disabled"", ""is_up""): <TAB> <TAB> <TAB> if value is not None: <TAB> <TAB> <TAB> <TAB> value = value == ""true"" <TAB> <TAB> self.assertEqual(value, getattr(cleanup_request, key)) <TAB> self.assertEqual(self._expected_services(*SERVICES), res.json)",true,"if key in ( ""disabled"" , ""is_up"" ) :","if key in ( ""disabled"" , ""is_up"" ) :",0.75,0.0
"def get_billable_and_total_duration(activity, start_time, end_time): <TAB> precision = frappe.get_precision(""Timesheet Detail"", ""hours"") <TAB> activity_duration = time_diff_in_hours(end_time, start_time) <TAB> billing_duration = 0.0 <TAB> if activity.billable: <TAB> <TAB> billing_duration = activity.billing_hours <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> billing_duration = ( <TAB> <TAB> <TAB> <TAB> activity_duration * activity.billing_hours / activity.hours <TAB> <TAB> <TAB> ) <TAB> return flt(activity_duration, precision), flt(billing_duration, precision)",false,if activity_duration != activity . billing_hours :,if activity . hours :,0.13,0.0
"def cpus(self): <TAB> try: <TAB> <TAB> cpus = ( <TAB> <TAB> <TAB> self.inspect[""Spec""][""Resources""][""Reservations""][""NanoCPUs""] / 1000000000.0 <TAB> <TAB> ) <TAB> <TAB> if cpus == int(cpus): <TAB> <TAB> <TAB> cpus = int(cpus) <TAB> <TAB> return cpus <TAB> except TypeError: <TAB> <TAB> return None <TAB> except KeyError: <TAB> <TAB> return 0",true,if cpus == int ( cpus ) :,if cpus == int ( cpus ) :,1.0,0.0
"def _create_object(self, obj_body): <TAB> props = obj_body[SYMBOL_PROPERTIES] <TAB> for prop_name, prop_value in props.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # get the first key as the convert function <TAB> <TAB> <TAB> func_name = list(prop_value.keys())[0] <TAB> <TAB> <TAB> if func_name.startswith(""_""): <TAB> <TAB> <TAB> <TAB> func = getattr(self, func_name) <TAB> <TAB> <TAB> <TAB> props[prop_name] = func(prop_value[func_name]) <TAB> if SYMBOL_TYPE in obj_body and obj_body[SYMBOL_TYPE] in self.fake_func_mapping: <TAB> <TAB> return self.fake_func_mapping[obj_body[SYMBOL_TYPE]](**props) <TAB> else: <TAB> <TAB> return props",false,"if isinstance ( prop_value , dict ) and prop_value :",if prop_name in prop_value :,0.03,0.0
"def _yield_unescaped(self, string): <TAB> while ""\\"" in string: <TAB> <TAB> finder = EscapeFinder(string) <TAB> <TAB> yield finder.before + finder.backslashes <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield self._unescape(finder.text) <TAB> <TAB> else: <TAB> <TAB> <TAB> yield finder.text <TAB> <TAB> string = finder.after <TAB> yield string",false,if finder . escaped and finder . text :,if self . escape_chars :,0.12,0.0
"def _check_matches(rule, matches): <TAB> errors = 0 <TAB> for match in matches: <TAB> <TAB> filematch = _match_to_test_file(match) <TAB> <TAB> if not filematch.exists(): <TAB> <TAB> <TAB> utils.error( <TAB> <TAB> <TAB> <TAB> ""The match '{}' for rule '{}' points to a non existing test module path: {}"", <TAB> <TAB> <TAB> <TAB> match, <TAB> <TAB> <TAB> <TAB> rule, <TAB> <TAB> <TAB> <TAB> filematch, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> errors += 1 <TAB> return errors",true,if not filematch . exists ( ) :,if not filematch . exists ( ) :,0.75,0.0
"def focused_windows(): <TAB> tree = i3.get_tree() <TAB> workspaces = tree.workspaces() <TAB> for workspace in workspaces: <TAB> <TAB> container = workspace <TAB> <TAB> while container: <TAB> <TAB> <TAB> if not hasattr(container, ""focus"") or not container.focus: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> container_id = container.focus[0] <TAB> <TAB> <TAB> container = container.find_by_id(container_id) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> coname = container.name <TAB> <TAB> <TAB> wsname = workspace.name <TAB> <TAB> <TAB> print(""WS"", wsname + "":"", coname)",true,if container :,if container :,0.53,0.0
"def normals(self, value): <TAB> if value is not None: <TAB> <TAB> value = np.asanyarray(value, dtype=np.float32) <TAB> <TAB> value = np.ascontiguousarray(value) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError(""Incorrect normals shape"") <TAB> self._normals = value",false,if value . shape != self . positions . shape :,if len ( value . shape ) != self . shape :,0.45,0.0
"def test_hexdigest(self): <TAB> for cons in self.hash_constructors: <TAB> <TAB> h = cons() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.assertIsInstance(h.digest(16), bytes) <TAB> <TAB> <TAB> self.assertEqual(hexstr(h.digest(16)), h.hexdigest(16)) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.assertIsInstance(h.digest(), bytes) <TAB> <TAB> <TAB> self.assertEqual(hexstr(h.digest()), h.hexdigest())",false,if h . name in self . shakes :,if PY2 :,0.01,0.0
"def _get_cluster_status(self): <TAB> try: <TAB> <TAB> return ( <TAB> <TAB> <TAB> self.dataproc_client.projects() <TAB> <TAB> <TAB> .regions() <TAB> <TAB> <TAB> .clusters() <TAB> <TAB> <TAB> .get( <TAB> <TAB> <TAB> <TAB> projectId=self.gcloud_project_id, <TAB> <TAB> <TAB> <TAB> region=self.dataproc_region, <TAB> <TAB> <TAB> <TAB> clusterName=self.dataproc_cluster_name, <TAB> <TAB> <TAB> <TAB> fields=""status"", <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> .execute() <TAB> <TAB> ) <TAB> except HttpError as e: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return None  # We got a 404 so the cluster doesn't exist <TAB> <TAB> else: <TAB> <TAB> <TAB> raise e",false,if e . resp . status == 404 :,if e . status == 404 :,0.35,0.0
"def _items_from(self, context): <TAB> self._context = context <TAB> if self._is_local_variable(self._keyword_name, context): <TAB> <TAB> for item in self._items_from_controller(context): <TAB> <TAB> <TAB> yield item <TAB> else: <TAB> <TAB> for df in context.datafiles: <TAB> <TAB> <TAB> self._yield_for_other_threads() <TAB> <TAB> <TAB> if self._items_from_datafile_should_be_checked(df): <TAB> <TAB> <TAB> <TAB> for item in self._items_from_datafile(df): <TAB> <TAB> <TAB> <TAB> <TAB> yield item",true,if self . _items_from_datafile_should_be_checked ( df ) :,if self . _items_from_datafile_should_be_checked ( df ) :,0.75,0.0
"def Command(argv, funcs, path_val): <TAB> arg, i = COMMAND_SPEC.Parse(argv) <TAB> status = 0 <TAB> if arg.v: <TAB> <TAB> for kind, arg in _ResolveNames(argv[i:], funcs, path_val): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> status = 1  # nothing printed, but we fail <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> # This is for -v, -V is more detailed. <TAB> <TAB> <TAB> <TAB> print(arg) <TAB> else: <TAB> <TAB> util.warn(""*** command without -v not not implemented ***"") <TAB> <TAB> status = 1 <TAB> return status",false,if kind is None :,"if kind == ""-v"" and arg . v == kind :",0.04,0.0
"def delete_doc(elastic_document_id, node, index=None, category=None): <TAB> index = index or INDEX <TAB> if not category: <TAB> <TAB> if isinstance(node, Preprint): <TAB> <TAB> <TAB> category = ""preprint"" <TAB> <TAB> elif node.is_registration: <TAB> <TAB> <TAB> category = ""registration"" <TAB> <TAB> else: <TAB> <TAB> <TAB> category = node.project_or_component <TAB> client().delete( <TAB> <TAB> index=index, <TAB> <TAB> doc_type=category, <TAB> <TAB> id=elastic_document_id, <TAB> <TAB> refresh=True, <TAB> <TAB> ignore=[404], <TAB> )",true,elif node . is_registration :,elif node . is_registration :,0.75,0.0
"def getDictFromTree(tree): <TAB> ret_dict = {} <TAB> for child in tree.getchildren(): <TAB> <TAB> if child.getchildren(): <TAB> <TAB> <TAB> ## Complex-type child. Recurse <TAB> <TAB> <TAB> content = getDictFromTree(child) <TAB> <TAB> else: <TAB> <TAB> <TAB> content = child.text <TAB> <TAB> if ret_dict.has_key(child.tag): <TAB> <TAB> <TAB> if not type(ret_dict[child.tag]) == list: <TAB> <TAB> <TAB> <TAB> ret_dict[child.tag] = [ret_dict[child.tag]] <TAB> <TAB> <TAB> ret_dict[child.tag].append(content or """") <TAB> <TAB> else: <TAB> <TAB> <TAB> ret_dict[child.tag] = content or """" <TAB> return ret_dict",true,if child . getchildren ( ) :,if child . getchildren ( ) :,0.75,0.0
"def get(self, block=True, timeout=None, ack=False): <TAB> if not block: <TAB> <TAB> return self.get_nowait() <TAB> start_time = time.time() <TAB> while True: <TAB> <TAB> try: <TAB> <TAB> <TAB> return self.get_nowait(ack) <TAB> <TAB> except BaseQueue.Empty: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> lasted = time.time() - start_time <TAB> <TAB> <TAB> <TAB> if timeout > lasted: <TAB> <TAB> <TAB> <TAB> <TAB> time.sleep(min(self.max_timeout, timeout - lasted)) <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> time.sleep(self.max_timeout)",true,if timeout :,if timeout :,0.53,0.0
"def rewrite(self, string): <TAB> string = super(JSReplaceFuzzy, self).rewrite(string) <TAB> cdx = self.url_rewriter.rewrite_opts[""cdx""] <TAB> if cdx.get(""is_fuzzy""): <TAB> <TAB> expected = unquote(cdx[""url""]) <TAB> <TAB> actual = unquote(self.url_rewriter.wburl.url) <TAB> <TAB> exp_m = self.rx_obj.search(expected) <TAB> <TAB> act_m = self.rx_obj.search(actual) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result = string.replace(exp_m.group(1), act_m.group(1)) <TAB> <TAB> <TAB> if result != string: <TAB> <TAB> <TAB> <TAB> string = result <TAB> return string",false,if exp_m and act_m :,if exp_m :,0.07,0.0
"def locate_exe_dir(d, check=True): <TAB> exe_dir = os.path.join(d, ""Scripts"") if ON_WINDOWS else os.path.join(d, ""bin"") <TAB> if not os.path.isdir(exe_dir): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> bin_dir = os.path.join(d, ""bin"") <TAB> <TAB> <TAB> if os.path.isdir(bin_dir): <TAB> <TAB> <TAB> <TAB> return bin_dir <TAB> <TAB> if check: <TAB> <TAB> <TAB> raise InvalidVirtualEnv(""Unable to locate executables directory."") <TAB> return exe_dir",true,if ON_WINDOWS :,if ON_WINDOWS :,0.53,0.0
"def _ensuresyspath(self, ensuremode, path): <TAB> if ensuremode: <TAB> <TAB> s = str(path) <TAB> <TAB> if ensuremode == ""append"": <TAB> <TAB> <TAB> if s not in sys.path: <TAB> <TAB> <TAB> <TAB> sys.path.append(s) <TAB> <TAB> else: <TAB> <TAB> <TAB> if s != sys.path[0]: <TAB> <TAB> <TAB> <TAB> sys.path.insert(0, s)",false,if s != sys . path [ 0 ] :,"if ensuremode == ""append"" :",0.01,0.0
"def create_season_banners(self, show_obj): <TAB> if self.season_banners and show_obj: <TAB> <TAB> result = [] <TAB> <TAB> for season, episodes in show_obj.episodes.iteritems():  # @UnusedVariable <TAB> <TAB> <TAB> if not self._has_season_banner(show_obj, season): <TAB> <TAB> <TAB> <TAB> logger.log( <TAB> <TAB> <TAB> <TAB> <TAB> u""Metadata provider "" <TAB> <TAB> <TAB> <TAB> <TAB> + self.name <TAB> <TAB> <TAB> <TAB> <TAB> + "" creating season banners for "" <TAB> <TAB> <TAB> <TAB> <TAB> + show_obj.name, <TAB> <TAB> <TAB> <TAB> <TAB> logger.DEBUG, <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> result = result + [self.save_season_banners(show_obj, season)] <TAB> <TAB> return all(result) <TAB> return False",true,"if not self . _has_season_banner ( show_obj , season ) :","if not self . _has_season_banner ( show_obj , season ) :",0.75,0.0
"def validate_nb(self, nb): <TAB> super(MetadataValidatorV3, self).validate_nb(nb) <TAB> ids = set([]) <TAB> for cell in nb.cells: <TAB> <TAB> if ""nbgrader"" not in cell.metadata: <TAB> <TAB> <TAB> continue <TAB> <TAB> grade = cell.metadata[""nbgrader""][""grade""] <TAB> <TAB> solution = cell.metadata[""nbgrader""][""solution""] <TAB> <TAB> locked = cell.metadata[""nbgrader""][""locked""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> grade_id = cell.metadata[""nbgrader""][""grade_id""] <TAB> <TAB> if grade_id in ids: <TAB> <TAB> <TAB> raise ValidationError(""Duplicate grade id: {}"".format(grade_id)) <TAB> <TAB> ids.add(grade_id)",false,if not grade and not solution and not locked :,if grade != solution :,0.02,0.0
"def read_version(): <TAB> regexp = re.compile(r""^__version__\W*=\W*'([\d.abrc]+)'"") <TAB> init_py = os.path.join(os.path.dirname(__file__), ""aiopg"", ""__init__.py"") <TAB> with open(init_py) as f: <TAB> <TAB> for line in f: <TAB> <TAB> <TAB> match = regexp.match(line) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return match.group(1) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise RuntimeError(""Cannot find version in aiopg/__init__.py"")",false,if match is not None :,if match :,0.05,0.0
"def _column_keys(self): <TAB> """"""Get a dictionary of all columns and their case mapping."""""" <TAB> if not self.exists: <TAB> <TAB> return {} <TAB> with self.db.lock: <TAB> <TAB> if self._columns is None: <TAB> <TAB> <TAB> # Initialise the table if it doesn't exist <TAB> <TAB> <TAB> table = self.table <TAB> <TAB> <TAB> self._columns = {} <TAB> <TAB> <TAB> for column in table.columns: <TAB> <TAB> <TAB> <TAB> name = normalize_column_name(column.name) <TAB> <TAB> <TAB> <TAB> key = normalize_column_key(name) <TAB> <TAB> <TAB> <TAB> if key in self._columns: <TAB> <TAB> <TAB> <TAB> <TAB> log.warning(""Duplicate column: %s"", name) <TAB> <TAB> <TAB> <TAB> self._columns[key] = name <TAB> <TAB> return self._columns",true,if key in self . _columns :,if key in self . _columns :,0.75,0.0
"def find_controller_by_names(self, names, testname): <TAB> namestring = ""."".join(names) <TAB> if not namestring.startswith(self.name): <TAB> <TAB> return None <TAB> if namestring == self.name: <TAB> <TAB> return self <TAB> for suite in self.suites: <TAB> <TAB> res = suite.find_controller_by_names( <TAB> <TAB> <TAB> namestring[len(self.name) + 1 :].split("".""), testname <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return res",true,if res :,if res :,0.53,0.0
"def _volume_x_metadata_get_item( <TAB> context, volume_id, key, model, notfound_exec, session=None ): <TAB> result = ( <TAB> <TAB> _volume_x_metadata_get_query(context, volume_id, model, session=session) <TAB> <TAB> .filter_by(key=key) <TAB> <TAB> .first() <TAB> ) <TAB> if not result: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise notfound_exec(id=volume_id) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise notfound_exec(metadata_key=key, volume_id=volume_id) <TAB> return result",false,if model is models . VolumeGlanceMetadata :,if not volume_id :,0.02,0.0
"def parse_results(cwd): <TAB> optimal_dd = None <TAB> optimal_measure = numpy.inf <TAB> for tup in tools.find_conf_files(cwd): <TAB> <TAB> dd = tup[1] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if dd[""results.train_y_misclass""] < optimal_measure: <TAB> <TAB> <TAB> <TAB> optimal_measure = dd[""results.train_y_misclass""] <TAB> <TAB> <TAB> <TAB> optimal_dd = dd <TAB> print(""Optimal results.train_y_misclass:"", str(optimal_measure)) <TAB> for key, value in optimal_dd.items(): <TAB> <TAB> if ""hyper_parameters"" in key: <TAB> <TAB> <TAB> print(key + "": "" + str(value))",true,"if ""results.train_y_misclass"" in dd :","if ""results.train_y_misclass"" in dd :",0.75,0.0
"def _stop_by_max_time_mins(self): <TAB> """"""Stop optimization process once maximum minutes have elapsed."""""" <TAB> if self.max_time_mins: <TAB> <TAB> total_mins_elapsed = ( <TAB> <TAB> <TAB> datetime.now() - self._start_datetime <TAB> <TAB> ).total_seconds() / 60.0 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise KeyboardInterrupt( <TAB> <TAB> <TAB> <TAB> ""{:.2f} minutes have elapsed. TPOT will close down."".format( <TAB> <TAB> <TAB> <TAB> <TAB> total_mins_elapsed <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> )",false,if total_mins_elapsed >= self . max_time_mins :,if total_mins_elapsed > self . max_time_mins :,0.5,0.0
"def __new__(meta, cls_name, bases, cls_dict): <TAB> func = cls_dict.get(""func"") <TAB> monad_cls = super(FuncMonadMeta, meta).__new__(meta, cls_name, bases, cls_dict) <TAB> if func: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> functions = func <TAB> <TAB> else: <TAB> <TAB> <TAB> functions = (func,) <TAB> <TAB> for func in functions: <TAB> <TAB> <TAB> registered_functions[func] = monad_cls <TAB> return monad_cls",false,if type ( func ) is tuple :,if registered_functions is None :,0.02,0.0
"def get_tokens_unprocessed(self, text): <TAB> buffered = """" <TAB> insertions = [] <TAB> lng_buffer = [] <TAB> for i, t, v in self.language_lexer.get_tokens_unprocessed(text): <TAB> <TAB> if t is self.needle: <TAB> <TAB> <TAB> if lng_buffer: <TAB> <TAB> <TAB> <TAB> insertions.append((len(buffered), lng_buffer)) <TAB> <TAB> <TAB> <TAB> lng_buffer = [] <TAB> <TAB> <TAB> buffered += v <TAB> <TAB> else: <TAB> <TAB> <TAB> lng_buffer.append((i, t, v)) <TAB> if lng_buffer: <TAB> <TAB> insertions.append((len(buffered), lng_buffer)) <TAB> return do_insertions(insertions, self.root_lexer.get_tokens_unprocessed(buffered))",true,if t is self . needle :,if t is self . needle :,0.75,0.0
"def get_conditions(filters): <TAB> conditions = {""docstatus"": (""="", 1)} <TAB> if filters.get(""from_date"") and filters.get(""to_date""): <TAB> <TAB> conditions[""result_date""] = ( <TAB> <TAB> <TAB> ""between"", <TAB> <TAB> <TAB> (filters.get(""from_date""), filters.get(""to_date"")), <TAB> <TAB> ) <TAB> <TAB> filters.pop(""from_date"") <TAB> <TAB> filters.pop(""to_date"") <TAB> for key, value in filters.items(): <TAB> <TAB> if filters.get(key): <TAB> <TAB> <TAB> conditions[key] = value <TAB> return conditions",true,if filters . get ( key ) :,if filters . get ( key ) :,0.75,0.0
"def _limit_value(key, value, config): <TAB> if config[key].get(""upper_limit""): <TAB> <TAB> limit = config[key][""upper_limit""] <TAB> <TAB> # auto handle datetime <TAB> <TAB> if isinstance(value, datetime) and isinstance(limit, timedelta): <TAB> <TAB> <TAB> if config[key][""inverse""] is True: <TAB> <TAB> <TAB> <TAB> if (datetime.now() - limit) > value: <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime.now() - limit <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> if (datetime.now() + limit) < value: <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime.now() + limit <TAB> <TAB> elif value > limit: <TAB> <TAB> <TAB> value = limit <TAB> return value",false,"if config [ key ] [ ""inverse"" ] is True :","if isinstance ( value , datetime ) and isinstance ( limit , timedelta ) :",0.01,0.0
"def GetCurrentKeySet(self): <TAB> ""Return CurrentKeys with 'darwin' modifications."" <TAB> result = self.GetKeySet(self.CurrentKeys()) <TAB> if sys.platform == ""darwin"": <TAB> <TAB> # macOS (OS X) Tk variants do not support the ""Alt"" <TAB> <TAB> # keyboard modifier.  Replace it with ""Option"". <TAB> <TAB> # TODO (Ned?): the ""Option"" modifier does not work properly <TAB> <TAB> # <TAB> for Cocoa Tk and XQuartz Tk so we should not use it <TAB> <TAB> # <TAB> in the default 'OSX' keyset. <TAB> <TAB> for k, v in result.items(): <TAB> <TAB> <TAB> v2 = [x.replace(""<Alt-"", ""<Option-"") for x in v] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> result[k] = v2 <TAB> return result",false,if v != v2 :,if v2 :,0.07,0.0
"def _load_testfile(filename, package, module_relative): <TAB> if module_relative: <TAB> <TAB> package = _normalize_module(package, 3) <TAB> <TAB> filename = _module_relative_path(package, filename) <TAB> <TAB> if hasattr(package, ""__loader__""): <TAB> <TAB> <TAB> if hasattr(package.__loader__, ""get_data""): <TAB> <TAB> <TAB> <TAB> file_contents = package.__loader__.get_data(filename) <TAB> <TAB> <TAB> <TAB> # get_data() opens files as 'rb', so one must do the equivalent <TAB> <TAB> <TAB> <TAB> # conversion as universal newlines would do. <TAB> <TAB> <TAB> <TAB> return file_contents.replace(os.linesep, ""\n""), filename <TAB> return open(filename).read(), filename",false,"if hasattr ( package . __loader__ , ""get_data"" ) :","if hasattr ( package , ""__loader__"" ) :",0.17,0.0
"def iter_from_X_lengths(X, lengths): <TAB> if lengths is None: <TAB> <TAB> yield 0, len(X) <TAB> else: <TAB> <TAB> n_samples = X.shape[0] <TAB> <TAB> end = np.cumsum(lengths).astype(np.int32) <TAB> <TAB> start = end - lengths <TAB> <TAB> if end[-1] > n_samples: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""more than {:d} samples in lengths array {!s}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> n_samples, lengths <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> for i in range(len(lengths)): <TAB> <TAB> <TAB> yield start[i], end[i]",true,if end [ - 1 ] > n_samples :,if end [ - 1 ] > n_samples :,0.75,0.0
"def change_sel(self): <TAB> """"""Change the view's selections."""""" <TAB> if self.alter_select and len(self.sels) > 0: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.view.show(self.sels[0]) <TAB> <TAB> self.view.sel().clear() <TAB> <TAB> self.view.sel().add_all(self.sels)",false,if self . multi_select is False :,if len ( self . sels ) == 1 :,0.04,0.0
"def cb_syncthing_device_data_changed( <TAB> self, daemon, nid, address, client_version, inbps, outbps, inbytes, outbytes ): <TAB> if nid in self.devices:  # Should be always <TAB> <TAB> device = self.devices[nid] <TAB> <TAB> # Update strings <TAB> <TAB> device[""address""] = address <TAB> <TAB> if client_version not in (""?"", None): <TAB> <TAB> <TAB> device[""version""] = client_version <TAB> <TAB> # Update rates <TAB> <TAB> device[""inbps""] = ""%s/s (%s)"" % (sizeof_fmt(inbps), sizeof_fmt(inbytes)) <TAB> <TAB> device[""outbps""] = ""%s/s (%s)"" % (sizeof_fmt(outbps), sizeof_fmt(outbytes))",true,"if client_version not in ( ""?"" , None ) :","if client_version not in ( ""?"" , None ) :",0.75,0.0
"def then(self, matches, when_response, context): <TAB> if is_iterable(when_response): <TAB> <TAB> ret = [] <TAB> <TAB> when_response = list(when_response) <TAB> <TAB> for match in when_response: <TAB> <TAB> <TAB> if match not in matches: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> match.name = self.match_name <TAB> <TAB> <TAB> <TAB> matches.append(match) <TAB> <TAB> <TAB> <TAB> ret.append(match) <TAB> <TAB> return ret <TAB> if self.match_name: <TAB> <TAB> when_response.name = self.match_name <TAB> if when_response not in matches: <TAB> <TAB> matches.append(when_response) <TAB> <TAB> return when_response",true,if self . match_name :,if self . match_name :,0.75,0.0
"def __update_parents(self, fileobj, path, delta): <TAB> """"""Update all parent atoms with the new size."""""" <TAB> if delta == 0: <TAB> <TAB> return <TAB> for atom in path: <TAB> <TAB> fileobj.seek(atom.offset) <TAB> <TAB> size = cdata.uint_be(fileobj.read(4)) <TAB> <TAB><IF-STMT>  # 64bit <TAB> <TAB> <TAB> # skip name (4B) and read size (8B) <TAB> <TAB> <TAB> size = cdata.ulonglong_be(fileobj.read(12)[4:]) <TAB> <TAB> <TAB> fileobj.seek(atom.offset + 8) <TAB> <TAB> <TAB> fileobj.write(cdata.to_ulonglong_be(size + delta)) <TAB> <TAB> else:  # 32bit <TAB> <TAB> <TAB> fileobj.seek(atom.offset) <TAB> <TAB> <TAB> fileobj.write(cdata.to_uint_be(size + delta))",false,if size == 1 :,if size == 0 :,0.39,0.0
"def _fields_to_index(cls): <TAB> fields = [] <TAB> for field in cls._meta.sorted_fields: <TAB> <TAB> if field.primary_key: <TAB> <TAB> <TAB> continue <TAB> <TAB> requires_index = any( <TAB> <TAB> <TAB> (field.index, field.unique, isinstance(field, ForeignKeyField)) <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> fields.append(field) <TAB> return fields",true,if requires_index :,if requires_index :,0.53,0.0
"def __init__(self, value): <TAB> """"""Initialize the integer to the given value."""""" <TAB> self._mpz_p = new_mpz() <TAB> self._initialized = False <TAB> if isinstance(value, float): <TAB> <TAB> raise ValueError(""A floating point type is not a natural number"") <TAB> self._initialized = True <TAB> if isinstance(value, (int, long)): <TAB> <TAB> _gmp.mpz_init(self._mpz_p) <TAB> <TAB> result = _gmp.gmp_sscanf(tobytes(str(value)), b(""%Zd""), self._mpz_p) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError(""Error converting '%d'"" % value) <TAB> else: <TAB> <TAB> _gmp.mpz_init_set(self._mpz_p, value._mpz_p)",false,if result != 1 :,if result != 0 :,0.39,0.0
"def decode(cls, data): <TAB> while data: <TAB> <TAB> length, format_type, control_flags, sequence, pid = unpack( <TAB> <TAB> <TAB> cls.Header.PACK, data[: cls.Header.LEN] <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise NetLinkError(""Buffer underrun"") <TAB> <TAB> yield cls.format( <TAB> <TAB> <TAB> format_type, control_flags, sequence, pid, data[cls.Header.LEN : length] <TAB> <TAB> ) <TAB> <TAB> data = data[length:]",false,if len ( data ) < length :,if length == 0 :,0.02,0.0
"def __post_init__(self): <TAB> if self._node_id is not None: <TAB> <TAB> if not len(self._node_id) == constants.HASH_LENGTH: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""invalid node_id: {}"".format(hexlify(self._node_id).decode()) <TAB> <TAB> <TAB> ) <TAB> if self.udp_port is not None and not 1 <= self.udp_port <= 65535: <TAB> <TAB> raise ValueError(""invalid udp port"") <TAB> if self.tcp_port is not None and not 1 <= self.tcp_port <= 65535: <TAB> <TAB> raise ValueError(""invalid tcp port"") <TAB> if not is_valid_public_ipv4(self.address, self.allow_localhost): <TAB> <TAB> raise ValueError(f""invalid ip address: '{self.address}'"")",true,if not len ( self . _node_id ) == constants . HASH_LENGTH :,if not len ( self . _node_id ) == constants . HASH_LENGTH :,0.75,0.0
"def orderUp(self, items): <TAB> sel = []  # new selection <TAB> undoinfo = [] <TAB> for bid, lid in items: <TAB> <TAB> if isinstance(lid, int): <TAB> <TAB> <TAB> undoinfo.append(self.orderUpLineUndo(bid, lid)) <TAB> <TAB> <TAB> sel.append((bid, lid - 1)) <TAB> <TAB> elif lid is None: <TAB> <TAB> <TAB> undoinfo.append(self.orderUpBlockUndo(bid)) <TAB> <TAB> <TAB> if bid == 0: <TAB> <TAB> <TAB> <TAB> return items <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> sel.append((bid - 1, None)) <TAB> self.addUndo(undoinfo, ""Move Up"") <TAB> return sel",true,elif lid is None :,elif lid is None :,0.75,0.0
"def filter_data(self, min_len, max_len): <TAB> logging.info(f""filtering data, min len: {min_len}, max len: {max_len}"") <TAB> initial_len = len(self.src) <TAB> filtered_src = [] <TAB> filtered_tgt = [] <TAB> for src, tgt in zip(self.src, self.tgt): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> filtered_src.append(src) <TAB> <TAB> <TAB> filtered_tgt.append(tgt) <TAB> self.src = filtered_src <TAB> self.tgt = filtered_tgt <TAB> filtered_len = len(self.src) <TAB> logging.info(f""pairs before: {initial_len}, after: {filtered_len}"")",false,if min_len <= len ( src ) <= max_len and min_len <= len ( tgt ) <= max_len :,if src not in filtered_src and tgt not in filtered_tgt :,0.13,0.0
"def layer_pretrained(self, net, args, options): <TAB> model = getattr(torchvision.models, args[0])(pretrained=True) <TAB> model.train(True) <TAB> if options.layer: <TAB> <TAB> layers = list(model.children())[: options.layer] <TAB> <TAB> if options.sublayer: <TAB> <TAB> <TAB> layers[-1] = nn.Sequential(*layers[-1][: options.sublayer]) <TAB> else: <TAB> <TAB> layers = [model] <TAB> <TAB> print(""List of pretrained layers:"", layers) <TAB> <TAB> raise ValidationException( <TAB> <TAB> <TAB> ""layer=-1 required for pretrained, sublayer=-1 optional.  Layers outputted above."" <TAB> <TAB> ) <TAB> return nn.Sequential(*layers)",true,if options . sublayer :,if options . sublayer :,0.75,0.0
"def deleteCalendar(users): <TAB> calendarId = normalizeCalendarId(sys.argv[5]) <TAB> for user in users: <TAB> <TAB> user, cal = buildCalendarGAPIObject(user) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> gapi.call(cal.calendarList(), ""delete"", soft_errors=True, calendarId=calendarId)",true,if not cal :,if not cal :,0.75,0.0
"def iter_modules(self, by_clients=False, clients_filter=None): <TAB> """"""iterate over all modules"""""" <TAB> clients = None <TAB> if by_clients: <TAB> <TAB> clients = self.get_clients(clients_filter) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> self._refresh_modules() <TAB> for module_name in self.modules: <TAB> <TAB> try: <TAB> <TAB> <TAB> module = self.get_module(module_name) <TAB> <TAB> except PupyModuleDisabled: <TAB> <TAB> <TAB> continue <TAB> <TAB> if clients is not None: <TAB> <TAB> <TAB> for client in clients: <TAB> <TAB> <TAB> <TAB> if module.is_compatible_with(client): <TAB> <TAB> <TAB> <TAB> <TAB> yield module <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> yield module",false,if not clients :,if clients is None :,0.05,0.0
"def update_me(self): <TAB> try: <TAB> <TAB> while 1: <TAB> <TAB> <TAB> line = self.queue.get_nowait() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.delete(1.0, tk.END) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.insert(tk.END, str(line)) <TAB> <TAB> <TAB> self.see(tk.END) <TAB> <TAB> <TAB> self.update_idletasks() <TAB> except queue.Empty: <TAB> <TAB> pass <TAB> self.after(100, self.update_me)",true,if line is None :,if line is None :,0.75,0.0
"def request_power_state(self, state, force=False): <TAB> if self.current_state != state or force: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.request_in_progress = True <TAB> <TAB> <TAB> logging.info(""Requesting %s"" % state) <TAB> <TAB> <TAB> cb = PowerManager.Callback(self, state) <TAB> <TAB> <TAB> rets = self.parent.Plugins.run( <TAB> <TAB> <TAB> <TAB> ""on_power_state_change_requested"", self, state, cb <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> cb.num_cb = len(rets) <TAB> <TAB> <TAB> cb.check() <TAB> <TAB> else: <TAB> <TAB> <TAB> logging.info(""Another request in progress"")",false,if not self . request_in_progress :,if self . request_in_progress :,0.28,0.0
"def __getitem__(self, idx): <TAB> super(BatchDataset, self).__getitem__(idx) <TAB> maxidx = len(self.dataset) <TAB> samples = [] <TAB> for i in range(0, self.batchsize): <TAB> <TAB> j = idx * self.batchsize + i <TAB> <TAB> if j >= maxidx: <TAB> <TAB> <TAB> break <TAB> <TAB> j = self.perm(j, maxidx) <TAB> <TAB> sample = self.dataset[j] <TAB> <TAB> if self.filter(sample): <TAB> <TAB> <TAB> samples.append(sample) <TAB> samples = self.makebatch(samples) <TAB> return samples",true,if self . filter ( sample ) :,if self . filter ( sample ) :,0.75,0.0
"def __call__(self, request, *args, **kwargs): <TAB> template_vars = {} <TAB> for form_name, form_class in self.forms.iteritems(): <TAB> <TAB> if form_class.must_display(request, *args, **kwargs): <TAB> <TAB> <TAB> template_vars[form_name] = form_class(request) <TAB> <TAB> else: <TAB> <TAB> <TAB> template_vars[form_name] = None <TAB> if request.method == ""POST"": <TAB> <TAB> action = self.find_post_handler_action(request) <TAB> <TAB> form = self.handlers[action](request, data=request.POST, files=request.FILES) <TAB> <TAB> template_vars.update(form.dispatch(action, request, *args, **kwargs)) <TAB> return self.GET(template_vars, request, *args, **kwargs)",true,"if form_class . must_display ( request , * args , ** kwargs ) :","if form_class . must_display ( request , * args , ** kwargs ) :",0.75,0.0
"def on_show_all(self, widget, another): <TAB> if widget.get_active(): <TAB> <TAB> if another.get_active(): <TAB> <TAB> <TAB> self.treeview.update_items(all=True, comment=True) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.treeview.update_items(all=True) <TAB> else: <TAB> <TAB> if another.get_active(): <TAB> <TAB> <TAB> self.treeview.update_items(comment=True) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.treeview.update_items()",true,if another . get_active ( ) :,if another . get_active ( ) :,0.75,0.0
"def close(self): <TAB> if self._closed: <TAB> <TAB> return <TAB> self._closed = True <TAB> for proto in self._pipes.values(): <TAB> <TAB> if proto is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> proto.pipe.close() <TAB> if ( <TAB> <TAB> self._proc is not None <TAB> <TAB> and <TAB> <TAB> # has the child process finished? <TAB> <TAB> self._returncode is None <TAB> <TAB> and <TAB> <TAB> # the child process has finished, but the <TAB> <TAB> # transport hasn't been notified yet? <TAB> <TAB> self._proc.poll() is None <TAB> ): <TAB> <TAB> if self._loop.get_debug(): <TAB> <TAB> <TAB> logger.warning(""Close running child process: kill %r"", self) <TAB> <TAB> try: <TAB> <TAB> <TAB> self._proc.kill() <TAB> <TAB> except ProcessLookupError: <TAB> <TAB> <TAB> pass",true,if self . _loop . get_debug ( ) :,if self . _loop . get_debug ( ) :,0.75,0.0
"def runTest(self): <TAB> self.poco(text=""wait UI"").click() <TAB> bomb_count = 0 <TAB> while True: <TAB> <TAB> blue_fish = self.poco(""fish_emitter"").child(""blue"") <TAB> <TAB> yellow_fish = self.poco(""fish_emitter"").child(""yellow"") <TAB> <TAB> bomb = self.poco(""fish_emitter"").child(""bomb"") <TAB> <TAB> fish = self.poco.wait_for_any([blue_fish, yellow_fish, bomb]) <TAB> <TAB> if fish is bomb: <TAB> <TAB> <TAB> bomb_count += 1 <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> else: <TAB> <TAB> <TAB> fish.click() <TAB> <TAB> time.sleep(2.5)",false,if bomb_count > 3 :,if bomb_count >= 10 :,0.31,0.0
"def load_managers(*, loop, only): <TAB> managers = {} <TAB> for key in DB_CLASSES: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> params = DB_DEFAULTS.get(key) or {} <TAB> <TAB> params.update(DB_OVERRIDES.get(key) or {}) <TAB> <TAB> database = DB_CLASSES[key](**params) <TAB> <TAB> managers[key] = peewee_async.Manager(database, loop=loop) <TAB> return managers",false,if only and key not in only :,if only :,0.04,0.0
"def links_extracted(self, request, links): <TAB> for link in links: <TAB> <TAB> if link.meta[b""state""] == States.NOT_CRAWLED: <TAB> <TAB> <TAB> r = self._create_request(link.url) <TAB> <TAB> <TAB> r.meta[b""depth""] = request.meta[b""depth""] + 1 <TAB> <TAB> <TAB> self.schedule(r, self._get_score(r.meta[b""depth""])) <TAB> <TAB> <TAB> link.meta[b""state""] = States.QUEUED",true,"if link . meta [ b""state"" ] == States . NOT_CRAWLED :","if link . meta [ b""state"" ] == States . NOT_CRAWLED :",0.75,0.0
"def find_worktree_git_dir(dotgit): <TAB> """"""Search for a gitdir for this worktree."""""" <TAB> try: <TAB> <TAB> statbuf = os.stat(dotgit) <TAB> except OSError: <TAB> <TAB> return None <TAB> if not stat.S_ISREG(statbuf.st_mode): <TAB> <TAB> return None <TAB> try: <TAB> <TAB> lines = open(dotgit, ""r"").readlines() <TAB> <TAB> for key, value in [line.strip().split("": "") for line in lines]: <TAB> <TAB> <TAB> if key == ""gitdir"": <TAB> <TAB> <TAB> <TAB> return value <TAB> except ValueError: <TAB> <TAB> pass <TAB> return None",true,"if key == ""gitdir"" :","if key == ""gitdir"" :",0.75,0.0
"def _is_static_shape(self, shape): <TAB> if shape is None or not isinstance(shape, list): <TAB> <TAB> return False <TAB> for dim_value in shape: <TAB> <TAB> if not isinstance(dim_value, int): <TAB> <TAB> <TAB> return False <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise Exception(""Negative dimension is illegal: %d"" % dim_value) <TAB> return True",true,if dim_value < 0 :,if dim_value < 0 :,0.75,0.0
"def init_logger(): <TAB> configured_loggers = [log_config.get(""root"", {})] + [ <TAB> <TAB> logger for logger in log_config.get(""loggers"", {}).values() <TAB> ] <TAB> used_handlers = { <TAB> <TAB> handler for log in configured_loggers for handler in log.get(""handlers"", []) <TAB> } <TAB> for handler_id, handler in list(log_config[""handlers""].items()): <TAB> <TAB> if handler_id not in used_handlers: <TAB> <TAB> <TAB> del log_config[""handlers""][handler_id] <TAB> <TAB> elif ""filename"" in handler.keys(): <TAB> <TAB> <TAB> filename = handler[""filename""] <TAB> <TAB> <TAB> logfile_path = Path(filename).expanduser().resolve() <TAB> <TAB> <TAB> handler[""filename""] = str(logfile_path) <TAB> logging.config.dictConfig(log_config)",true,"elif ""filename"" in handler . keys ( ) :","elif ""filename"" in handler . keys ( ) :",0.75,0.0
"def __call__(self): <TAB> dmin, dmax = self.viewlim_to_dt() <TAB> ymin = self.base.le(dmin.year) <TAB> ymax = self.base.ge(dmax.year) <TAB> ticks = [dmin.replace(year=ymin, **self.replaced)] <TAB> while 1: <TAB> <TAB> dt = ticks[-1] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return date2num(ticks) <TAB> <TAB> year = dt.year + self.base.get_base() <TAB> <TAB> ticks.append(dt.replace(year=year, **self.replaced))",false,if dt . year >= ymax :,if dt . year == ymin and dt . year == ymax :,0.24,0.0
"def taiga(request, trigger_id, key): <TAB> signature = request.META.get(""HTTP_X_TAIGA_WEBHOOK_SIGNATURE"") <TAB> # check that the data are ok with the provided signature <TAB> if verify_signature(request._request.body, key, signature): <TAB> <TAB> data = data_filter(trigger_id, **request.data) <TAB> <TAB> status = save_data(trigger_id, data) <TAB> <TAB> return ( <TAB> <TAB> <TAB> Response({""message"": ""Success""}) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> else Response({""message"": ""Failed!""}) <TAB> <TAB> ) <TAB> Response({""message"": ""Bad request""})",true,if status,if status,0.41,0.0
"def ParseResponses( <TAB> self, <TAB> knowledge_base: rdf_client.KnowledgeBase, <TAB> responses: Iterable[rdfvalue.RDFValue], ) -> Iterator[rdf_client.User]: <TAB> for response in responses: <TAB> <TAB> if not isinstance(response, rdf_client_fs.StatEntry): <TAB> <TAB> <TAB> raise TypeError(f""Unexpected response type: `{type(response)}`"") <TAB> <TAB> # TODO: `st_mode` has to be an `int`, not `StatMode`. <TAB> <TAB> if stat.S_ISDIR(int(response.st_mode)): <TAB> <TAB> <TAB> homedir = response.pathspec.path <TAB> <TAB> <TAB> username = os.path.basename(homedir) <TAB> <TAB> <TAB> if username not in self._ignore_users: <TAB> <TAB> <TAB> <TAB> yield rdf_client.User(username=username, homedir=homedir)",false,"if not isinstance ( response , rdf_client_fs . StatEntry ) :",if stat . S_ISDIR ( int ( response . st_mode ) ) :,0.03,0.0
"def _iter_lines(path=path, response=response, max_next=options.http_max_next): <TAB> path.responses = [] <TAB> n = 0 <TAB> while response: <TAB> <TAB> path.responses.append(response) <TAB> <TAB> yield from response.iter_lines(decode_unicode=True) <TAB> <TAB> src = response.links.get(""next"", {}).get(""url"", None) <TAB> <TAB> if not src: <TAB> <TAB> <TAB> break <TAB> <TAB> n += 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> vd.warning(f""stopping at max {max_next} pages"") <TAB> <TAB> <TAB> break <TAB> <TAB> vd.status(f""fetching next page from {src}"") <TAB> <TAB> response = requests.get(src, stream=True)",true,if n > max_next :,if n > max_next :,0.75,0.0
"def __enter__(self): <TAB> """"""Open a file and read it."""""" <TAB> if self.code is None: <TAB> <TAB> LOGGER.info(""File is reading: %s"", self.path) <TAB> <TAB> if sys.version_info >= (3,): <TAB> <TAB> <TAB> self._file = open(self.path, encoding=""utf-8"") <TAB> <TAB> else: <TAB> <TAB> <TAB> self._file = open(self.path, ""rU"") <TAB> <TAB> self.code = self._file.read() <TAB> return self",true,"if sys . version_info >= ( 3 , ) :","if sys . version_info >= ( 3 , ) :",0.75,0.0
"def facts_for_oauthclients(self, namespace): <TAB> """"""Gathers facts for oauthclients used with logging"""""" <TAB> self.default_keys_for(""oauthclients"") <TAB> a_list = self.oc_command( <TAB> <TAB> ""get"", ""oauthclients"", namespace=namespace, add_options=[""-l"", LOGGING_SELECTOR] <TAB> ) <TAB> if len(a_list[""items""]) == 0: <TAB> <TAB> return <TAB> for item in a_list[""items""]: <TAB> <TAB> name = item[""metadata""][""name""] <TAB> <TAB> comp = self.comp(name) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result = dict(redirectURIs=item[""redirectURIs""]) <TAB> <TAB> <TAB> self.add_facts_for(comp, ""oauthclients"", name, result)",false,if comp is not None :,if comp :,0.05,0.0
"def get(self, k): <TAB> with self._lock: <TAB> <TAB> if k not in self._data1 and k in self._data2: <TAB> <TAB> <TAB> self._data1[k] = self._data2[k] <TAB> <TAB> <TAB> del self._data2[k] <TAB> return self._data1.get(k)",true,if k not in self . _data1 and k in self . _data2 :,if k not in self . _data1 and k in self . _data2 :,1.0,0.0
"def _parseparam(s): <TAB> plist = [] <TAB> while s[:1] == "";"": <TAB> <TAB> s = s[1:] <TAB> <TAB> end = s.find("";"") <TAB> <TAB> while end > 0 and (s.count('""', 0, end) - s.count('\\""', 0, end)) % 2: <TAB> <TAB> <TAB> end = s.find("";"", end + 1) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> end = len(s) <TAB> <TAB> f = s[:end] <TAB> <TAB> if ""="" in f: <TAB> <TAB> <TAB> i = f.index(""="") <TAB> <TAB> <TAB> f = f[:i].strip().lower() + ""="" + f[i + 1 :].strip() <TAB> <TAB> plist.append(f.strip()) <TAB> <TAB> s = s[end:] <TAB> return plist",true,if end < 0 :,if end < 0 :,0.75,0.0
"def __init__(self, **params): <TAB> if ""length"" in params: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError(""Supply either length or start and end to Player not both"") <TAB> <TAB> params[""start""] = 0 <TAB> <TAB> params[""end""] = params.pop(""length"") - 1 <TAB> elif params.get(""start"", 0) > 0 and not ""value"" in params: <TAB> <TAB> params[""value""] = params[""start""] <TAB> super(Player, self).__init__(**params)",false,"if ""start"" in params or ""end"" in params :","if ""start"" in params :",0.19,0.0
"def libcxx_define(settings): <TAB> compiler = _base_compiler(settings) <TAB> libcxx = settings.get_safe(""compiler.libcxx"") <TAB> if not compiler or not libcxx: <TAB> <TAB> return """" <TAB> if str(compiler) in GCC_LIKE: <TAB> <TAB> if str(libcxx) == ""libstdc++"": <TAB> <TAB> <TAB> return ""_GLIBCXX_USE_CXX11_ABI=0"" <TAB> <TAB> elif str(libcxx) == ""libstdc++11"": <TAB> <TAB> <TAB> return ""_GLIBCXX_USE_CXX11_ABI=1"" <TAB> return """"",true,"elif str ( libcxx ) == ""libstdc++11"" :","elif str ( libcxx ) == ""libstdc++11"" :",0.75,0.0
"def _get_sort_map(tags): <TAB> """"""See TAG_TO_SORT"""""" <TAB> tts = {} <TAB> for name, tag in tags.items(): <TAB> <TAB> if tag.has_sort: <TAB> <TAB> <TAB> if tag.user: <TAB> <TAB> <TAB> <TAB> tts[name] = ""%ssort"" % name <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> tts[""~%s"" % name] = ""~%ssort"" % name <TAB> return tts",false,if tag . internal :,if tag . user . is_staff :,0.2,0.0
"def quiet_f(*args): <TAB> vars = {arg_name: Real(arg) for arg_name, arg in zip(arg_names, args)} <TAB> value = dynamic_scoping(quiet_expr.evaluate, vars, evaluation) <TAB> if expect_list: <TAB> <TAB> if value.has_form(""List"", None): <TAB> <TAB> <TAB> value = [extract_pyreal(item) for item in value.leaves] <TAB> <TAB> <TAB> if any(item is None for item in value): <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> return value <TAB> <TAB> else: <TAB> <TAB> <TAB> return None <TAB> else: <TAB> <TAB> value = extract_pyreal(value) <TAB> <TAB> if value is None or isinf(value) or isnan(value): <TAB> <TAB> <TAB> return None <TAB> <TAB> return value",false,if value is None or isinf ( value ) or isnan ( value ) :,"if value . has_form ( ""List"" , None ) :",0.02,0.0
"def on_action_chosen(self, id, action, mark_changed=True): <TAB> before = self.set_action(self.current, id, action) <TAB> if mark_changed: <TAB> <TAB> if before.to_string() != action.to_string(): <TAB> <TAB> <TAB> # TODO: Maybe better comparison <TAB> <TAB> <TAB> self.undo.append(UndoRedo(id, before, action)) <TAB> <TAB> <TAB> self.builder.get_object(""btUndo"").set_sensitive(True) <TAB> <TAB> self.on_profile_modified() <TAB> else: <TAB> <TAB> self.on_profile_modified(update_ui=False) <TAB> return before",true,if before . to_string ( ) != action . to_string ( ) :,if before . to_string ( ) != action . to_string ( ) :,1.0,0.0
"def setUp(self): <TAB> super(OperaterTest, self).setUp() <TAB> if is_cli: <TAB> <TAB> import clr <TAB> <TAB> self.load_iron_python_test() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> clr.AddReference(""System.Drawing.Primitives"") <TAB> <TAB> else: <TAB> <TAB> <TAB> clr.AddReference(""System.Drawing"")",false,if is_netcoreapp :,if is_primitives :,0.32,0.0
"def field_to_field_type(field): <TAB> field_type = field[""type""] <TAB> if isinstance(field_type, dict): <TAB> <TAB> field_type = field_type[""type""] <TAB> if isinstance(field_type, list): <TAB> <TAB> field_type_length = len(field_type) <TAB> <TAB> if field_type_length == 0: <TAB> <TAB> <TAB> raise Exception(""Zero-length type list encountered, invalid CWL?"") <TAB> <TAB> elif len(field_type) == 1: <TAB> <TAB> <TAB> field_type = field_type[0] <TAB> return field_type",true,elif len ( field_type ) == 1 :,elif len ( field_type ) == 1 :,0.75,0.0
"def _flatten(*args): <TAB> ahs = set() <TAB> if len(args) > 0: <TAB> <TAB> for item in args: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> ahs.add(item) <TAB> <TAB> <TAB> elif type(item) in (list, tuple, dict, set): <TAB> <TAB> <TAB> <TAB> for ah in item: <TAB> <TAB> <TAB> <TAB> <TAB> if type(ah) is not ActionHandle:  # pragma:nocover <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ActionManagerError(""Bad argument type %s"" % str(ah)) <TAB> <TAB> <TAB> <TAB> <TAB> ahs.add(ah) <TAB> <TAB> <TAB> else:  # pragma:nocover <TAB> <TAB> <TAB> <TAB> raise ActionManagerError(""Bad argument type %s"" % str(item)) <TAB> return ahs",true,if type ( item ) is ActionHandle :,if type ( item ) is ActionHandle :,0.75,0.0
"def _Determine_Do(self): <TAB> self.applicable = 1 <TAB> configTokens = black.configure.items[""configTokens""].Get() <TAB> buildFlavour = black.configure.items[""buildFlavour""].Get() <TAB> if buildFlavour == ""full"": <TAB> <TAB> self.value = False <TAB> else: <TAB> <TAB> self.value = True <TAB> for opt, optarg in self.chosenOptions: <TAB> <TAB> if opt == ""--with-tests"": <TAB> <TAB> <TAB> if not self.value: <TAB> <TAB> <TAB> <TAB> configTokens.append(""tests"") <TAB> <TAB> <TAB> self.value = True <TAB> <TAB> elif opt == ""--without-tests"": <TAB> <TAB> <TAB> if self.value: <TAB> <TAB> <TAB> <TAB> configTokens.append(""notests"") <TAB> <TAB> <TAB> self.value = False <TAB> self.determined = 1",false,"if opt == ""--with-tests"" :","elif opt == ""--without-tests"" :",0.06,0.0
"def title_by_index(self, trans, index, context): <TAB> d_type = self.get_datatype(trans, context) <TAB> for i, (composite_name, composite_file) in enumerate(d_type.writable_files.items()): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> rval = composite_name <TAB> <TAB> <TAB> if composite_file.description: <TAB> <TAB> <TAB> <TAB> rval = ""{} ({})"".format(rval, composite_file.description) <TAB> <TAB> <TAB> if composite_file.optional: <TAB> <TAB> <TAB> <TAB> rval = ""%s [optional]"" % rval <TAB> <TAB> <TAB> return rval <TAB> if index < self.get_file_count(trans, context): <TAB> <TAB> return ""Extra primary file"" <TAB> return None",true,if i == index :,if i == index :,0.75,0.0
"def func(x, y): <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> z = x + 2 * math.sin(y) <TAB> <TAB> <TAB> return z ** 2 <TAB> <TAB> elif x == y: <TAB> <TAB> <TAB> return 4 <TAB> <TAB> else: <TAB> <TAB> <TAB> return 2 ** 3 <TAB> except ValueError: <TAB> <TAB> foo = 0 <TAB> <TAB> for i in range(4): <TAB> <TAB> <TAB> foo += i <TAB> <TAB> return foo <TAB> except TypeError: <TAB> <TAB> return 42 <TAB> else: <TAB> <TAB> return 33 <TAB> finally: <TAB> <TAB> print(""finished"")",false,if x > y :,if x < y :,0.08,0.0
"def test_suite(): <TAB> suite = unittest.TestSuite() <TAB> for fn in os.listdir(here): <TAB> <TAB> if fn.startswith(""test"") and fn.endswith("".py""): <TAB> <TAB> <TAB> modname = ""distutils.tests."" + fn[:-3] <TAB> <TAB> <TAB> __import__(modname) <TAB> <TAB> <TAB> module = sys.modules[modname] <TAB> <TAB> <TAB> suite.addTest(module.test_suite()) <TAB> return suite",true,"if fn . startswith ( ""test"" ) and fn . endswith ( "".py"" ) :","if fn . startswith ( ""test"" ) and fn . endswith ( "".py"" ) :",1.0,0.0
"def check_stack_names(self, frame, expected): <TAB> names = [] <TAB> while frame: <TAB> <TAB> name = frame.f_code.co_name <TAB> <TAB> # Stop checking frames when we get to our test helper. <TAB> <TAB> if name.startswith(""check_"") or name.startswith(""call_""): <TAB> <TAB> <TAB> break <TAB> <TAB> names.append(name) <TAB> <TAB> frame = frame.f_back <TAB> self.assertEqual(names, expected)",true,"if name . startswith ( ""check_"" ) or name . startswith ( ""call_"" ) :","if name . startswith ( ""check_"" ) or name . startswith ( ""call_"" ) :",1.0,0.0
"def leave(self, reason=None): <TAB> try: <TAB> <TAB> if self.id.startswith(""C""): <TAB> <TAB> <TAB> log.info(""Leaving channel %s (%s)"", self, self.id) <TAB> <TAB> <TAB> self._bot.api_call(""conversations.leave"", data={""channel"": self.id}) <TAB> <TAB> else: <TAB> <TAB> <TAB> log.info(""Leaving group %s (%s)"", self, self.id) <TAB> <TAB> <TAB> self._bot.api_call(""conversations.leave"", data={""channel"": self.id}) <TAB> except SlackAPIResponseError as e: <TAB> <TAB> if e.error == ""user_is_bot"": <TAB> <TAB> <TAB> raise RoomError(f""Unable to leave channel. {USER_IS_BOT_HELPTEXT}"") <TAB> <TAB> else: <TAB> <TAB> <TAB> raise RoomError(e) <TAB> self._id = None",true,"if e . error == ""user_is_bot"" :","if e . error == ""user_is_bot"" :",0.75,0.0
"def ident(self): <TAB> value = self._ident <TAB> if value is False: <TAB> <TAB> value = None <TAB> <TAB> # XXX: how will this interact with orig_prefix ? <TAB> <TAB> # <TAB>  not exposing attrs for now if orig_prefix is set. <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> wrapped = self.wrapped <TAB> <TAB> <TAB> ident = getattr(wrapped, ""ident"", None) <TAB> <TAB> <TAB> if ident is not None: <TAB> <TAB> <TAB> <TAB> value = self._wrap_hash(ident) <TAB> <TAB> self._ident = value <TAB> return value",false,if not self . orig_prefix :,if self . wrapped is not None :,0.05,0.0
"def is_ac_power_connected(): <TAB> for power_source_path in Path(""/sys/class/power_supply/"").iterdir(): <TAB> <TAB> try: <TAB> <TAB> <TAB> with open(power_source_path / ""type"", ""r"") as f: <TAB> <TAB> <TAB> <TAB> if f.read().strip() != ""Mains"": <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> with open(power_source_path / ""online"", ""r"") as f: <TAB> <TAB> <TAB> <TAB> if f.read(1) == ""1"": <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> except IOError: <TAB> <TAB> <TAB> continue <TAB> return False",false,"if f . read ( ) . strip ( ) != ""Mains"" :","if f . read ( 1 ) == ""1"" :",0.16,0.0
"def _get_pending_by_app_token(self, app_token): <TAB> result = [] <TAB> with self._pending_lock: <TAB> <TAB> self._remove_stale_pending() <TAB> <TAB> for data in self._pending_decisions: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> result.append(data) <TAB> return result",true,if data . app_token == app_token :,if data . app_token == app_token :,1.0,0.0
"def do_create(specific_tables=None, base=Base): <TAB> engine = get_engine() <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> logger.info( <TAB> <TAB> <TAB> <TAB> ""Initializing only a subset of tables as requested: {}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> specific_tables <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> base.metadata.create_all(engine, tables=specific_tables) <TAB> <TAB> else: <TAB> <TAB> <TAB> base.metadata.create_all(engine) <TAB> except Exception as err: <TAB> <TAB> raise Exception(""could not create/re-create DB tables - exception: "" + str(err))",true,if specific_tables :,if specific_tables :,0.53,0.0
"def __setitem__(self, ndx, val): <TAB> # <TAB> # Get the expression data object <TAB> # <TAB> exprdata = None <TAB> if ndx in self._data: <TAB> <TAB> exprdata = self._data[ndx] <TAB> else: <TAB> <TAB> _ndx = normalize_index(ndx) <TAB> <TAB> if _ndx in self._data: <TAB> <TAB> <TAB> exprdata = self._data[_ndx] <TAB> if exprdata is None: <TAB> <TAB> raise KeyError( <TAB> <TAB> <TAB> ""Cannot set the value of Expression '%s' with "" <TAB> <TAB> <TAB> ""invalid index '%s'"" % (self.cname(True), str(ndx)) <TAB> <TAB> ) <TAB> # <TAB> # Set the value <TAB> # <TAB> exprdata.set_value(val)",true,if _ndx in self . _data :,if _ndx in self . _data :,0.75,0.0
"def write(self, *bits): <TAB> for bit in bits: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.bytestream.append(0) <TAB> <TAB> byte = self.bytestream[self.bytenum] <TAB> <TAB> if self.bitnum == 8: <TAB> <TAB> <TAB> if self.bytenum == len(self.bytestream) - 1: <TAB> <TAB> <TAB> <TAB> byte = 0 <TAB> <TAB> <TAB> <TAB> self.bytestream += bytes([byte]) <TAB> <TAB> <TAB> self.bytenum += 1 <TAB> <TAB> <TAB> self.bitnum = 0 <TAB> <TAB> mask = 2 ** self.bitnum <TAB> <TAB> if bit: <TAB> <TAB> <TAB> byte |= mask <TAB> <TAB> else: <TAB> <TAB> <TAB> byte &= ~mask <TAB> <TAB> self.bytestream[self.bytenum] = byte <TAB> <TAB> self.bitnum += 1",false,if not self . bytestream :,if not bit :,0.05,0.0
"def terminate_subprocess(proc, timeout=0.1, log=None): <TAB> if proc.poll() is None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> log.info(""Sending SIGTERM to %r"", proc) <TAB> <TAB> proc.terminate() <TAB> <TAB> timeout_time = time.time() + timeout <TAB> <TAB> while proc.poll() is None and time.time() < timeout_time: <TAB> <TAB> <TAB> time.sleep(0.02) <TAB> <TAB> if proc.poll() is None: <TAB> <TAB> <TAB> if log: <TAB> <TAB> <TAB> <TAB> log.info(""Sending SIGKILL to %r"", proc) <TAB> <TAB> <TAB> proc.kill() <TAB> return proc.returncode",true,if log :,if log :,0.53,0.0
"def mkpanel(color, rows, cols, tly, tlx): <TAB> win = curses.newwin(rows, cols, tly, tlx) <TAB> pan = panel.new_panel(win) <TAB> if curses.has_colors(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> fg = curses.COLOR_WHITE <TAB> <TAB> else: <TAB> <TAB> <TAB> fg = curses.COLOR_BLACK <TAB> <TAB> bg = color <TAB> <TAB> curses.init_pair(color, fg, bg) <TAB> <TAB> win.bkgdset(ord("" ""), curses.color_pair(color)) <TAB> else: <TAB> <TAB> win.bkgdset(ord("" ""), curses.A_BOLD) <TAB> return pan",false,if color == curses . COLOR_BLUE :,if color is None :,0.04,0.0
"def all_words(filename): <TAB> start_char = True <TAB> for c in characters(filename): <TAB> <TAB> if start_char == True: <TAB> <TAB> <TAB> word = """" <TAB> <TAB> <TAB> if c.isalnum(): <TAB> <TAB> <TAB> <TAB> # We found the start of a word <TAB> <TAB> <TAB> <TAB> word = c.lower() <TAB> <TAB> <TAB> <TAB> start_char = False <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> if c.isalnum(): <TAB> <TAB> <TAB> <TAB> word += c.lower() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> # We found end of word, emit it <TAB> <TAB> <TAB> <TAB> start_char = True <TAB> <TAB> <TAB> <TAB> yield word",true,if c . isalnum ( ) :,if c . isalnum ( ) :,0.75,0.0
"def get_tf_weights_as_numpy(path=""./ckpt/aeslc/model.ckpt-32000"") -> Dict: <TAB> init_vars = tf.train.list_variables(path) <TAB> tf_weights = {} <TAB> ignore_name = [""Adafactor"", ""global_step""] <TAB> for name, shape in tqdm(init_vars, desc=""converting tf checkpoint to dict""): <TAB> <TAB> skip_key = any([pat in name for pat in ignore_name]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> array = tf.train.load_variable(path, name) <TAB> <TAB> tf_weights[name] = array <TAB> return tf_weights",true,if skip_key :,if skip_key :,0.53,0.0
"def app(scope, receive, send): <TAB> while True: <TAB> <TAB> message = await receive() <TAB> <TAB> if message[""type""] == ""websocket.connect"": <TAB> <TAB> <TAB> await send({""type"": ""websocket.accept""}) <TAB> <TAB> elif message[""type""] == ""websocket.receive"": <TAB> <TAB> <TAB> pass <TAB> <TAB> elif message[""type""] == ""websocket.disconnect"": <TAB> <TAB> <TAB> break",true,"elif message [ ""type"" ] == ""websocket.receive"" :","elif message [ ""type"" ] == ""websocket.receive"" :",1.0,0.0
"def autoload(self): <TAB> if self._app.config.THEME == ""auto"": <TAB> <TAB> if sys.platform == ""darwin"": <TAB> <TAB> <TAB> if get_osx_theme() == 1: <TAB> <TAB> <TAB> <TAB> theme = DARK <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> theme = LIGHT <TAB> <TAB> else: <TAB> <TAB> <TAB> theme = self.guess_system_theme() <TAB> <TAB> <TAB> if theme == Dark: <TAB> <TAB> <TAB> <TAB> theme = MacOSDark <TAB> else:  # user settings have highest priority <TAB> <TAB> theme = self._app.config.THEME <TAB> self.load_theme(theme)",false,if get_osx_theme ( ) == 1 :,"if sys . platform == ""darwin"" :",0.02,0.0
"def example_reading_spec(self): <TAB> data_fields = {""targets"": tf.VarLenFeature(tf.int64)} <TAB><IF-STMT> <TAB> <TAB> data_fields[""inputs""] = tf.VarLenFeature(tf.int64) <TAB> if self.packed_length: <TAB> <TAB> if self.has_inputs: <TAB> <TAB> <TAB> data_fields[""inputs_segmentation""] = tf.VarLenFeature(tf.int64) <TAB> <TAB> <TAB> data_fields[""inputs_position""] = tf.VarLenFeature(tf.int64) <TAB> <TAB> data_fields[""targets_segmentation""] = tf.VarLenFeature(tf.int64) <TAB> <TAB> data_fields[""targets_position""] = tf.VarLenFeature(tf.int64) <TAB> data_items_to_decoders = None <TAB> return (data_fields, data_items_to_decoders)",true,if self . has_inputs :,if self . has_inputs :,0.75,0.0
"def _prepare_travel_graph(self): <TAB> for op in self.op_dict.values(): <TAB> <TAB> op.const = False <TAB> <TAB> if op.node.op in [""Const"", ""Placeholder""]: <TAB> <TAB> <TAB> op.resolved = True <TAB> <TAB> <TAB> if op.node.op == ""Const"": <TAB> <TAB> <TAB> <TAB> op.const = True <TAB> <TAB> else: <TAB> <TAB> <TAB> op.resolved = False",true,"if op . node . op == ""Const"" :","if op . node . op == ""Const"" :",1.0,0.0
"def get_filestream_file_items(self): <TAB> data = {} <TAB> fs_file_updates = self.get_filestream_file_updates() <TAB> for k, v in six.iteritems(fs_file_updates): <TAB> <TAB> l = [] <TAB> <TAB> for d in v: <TAB> <TAB> <TAB> offset = d.get(""offset"") <TAB> <TAB> <TAB> content = d.get(""content"") <TAB> <TAB> <TAB> assert offset is not None <TAB> <TAB> <TAB> assert content is not None <TAB> <TAB> <TAB> assert offset == 0 or offset == len(l), (k, v, l, d) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> l = [] <TAB> <TAB> <TAB> l.extend(map(json.loads, content)) <TAB> <TAB> data[k] = l <TAB> return data",false,if not offset :,if not l :,0.35,0.0
"def _rewrite_exprs(self, table, what): <TAB> from ibis.expr.analysis import substitute_parents <TAB> what = util.promote_list(what) <TAB> all_exprs = [] <TAB> for expr in what: <TAB> <TAB> if isinstance(expr, ir.ExprList): <TAB> <TAB> <TAB> all_exprs.extend(expr.exprs()) <TAB> <TAB> else: <TAB> <TAB> <TAB> bound_expr = ir.bind_expr(table, expr) <TAB> <TAB> <TAB> all_exprs.append(bound_expr) <TAB> return [substitute_parents(x, past_projection=False) for x in all_exprs]",true,"if isinstance ( expr , ir . ExprList ) :","if isinstance ( expr , ir . ExprList ) :",0.75,0.0
"def _group_by_commit_and_time(self, hits): <TAB> result = {} <TAB> for hit in hits: <TAB> <TAB> source_hit = hit[""_source""] <TAB> <TAB> key = ""%s_%s"" % (source_hit[""commit_info""][""id""], source_hit[""datetime""]) <TAB> <TAB> benchmark = self._benchmark_from_es_record(source_hit) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result[key][""benchmarks""].append(benchmark) <TAB> <TAB> else: <TAB> <TAB> <TAB> run_info = self._run_info_from_es_record(source_hit) <TAB> <TAB> <TAB> run_info[""benchmarks""] = [benchmark] <TAB> <TAB> <TAB> result[key] = run_info <TAB> return result",false,if key in result :,if benchmark :,0.04,0.0
"def _build_index(self): <TAB> self._index = {} <TAB> for start_char, sorted_offsets in self._offsets.items(): <TAB> <TAB> self._index[start_char] = {} <TAB> <TAB> for i, offset in enumerate(sorted_offsets.get_offsets()): <TAB> <TAB> <TAB> identifier = sorted_offsets.get_identifier_by_offset(offset) <TAB> <TAB> <TAB> if identifier[0 : self.index_depth] not in self._index[start_char]: <TAB> <TAB> <TAB> <TAB> self._index[start_char][identifier[0 : self.index_depth]] = i",true,if identifier [ 0 : self . index_depth ] not in self . _index [ start_char ] :,if identifier [ 0 : self . index_depth ] not in self . _index [ start_char ] :,1.0,0.0
"def scan_resource_conf(self, conf): <TAB> if ""properties"" in conf: <TAB> <TAB> if ""attributes"" in conf[""properties""]: <TAB> <TAB> <TAB> if ""exp"" in conf[""properties""][""attributes""]: <TAB> <TAB> <TAB> <TAB> if conf[""properties""][""attributes""][""exp""]: <TAB> <TAB> <TAB> <TAB> <TAB> return CheckResult.PASSED <TAB> return CheckResult.FAILED",false,"if ""attributes"" in conf [ ""properties"" ] :","if ""exp"" in conf [ ""properties"" ] [ ""attributes"" ] :",0.26,0.0
"def _PatchArtifact(self, artifact: rdf_artifacts.Artifact) -> rdf_artifacts.Artifact: <TAB> """"""Patches artifact to not contain byte-string source attributes."""""" <TAB> patched = False <TAB> for source in artifact.sources: <TAB> <TAB> attributes = source.attributes.ToDict() <TAB> <TAB> unicode_attributes = compatibility.UnicodeJson(attributes) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> source.attributes = unicode_attributes <TAB> <TAB> <TAB> patched = True <TAB> if patched: <TAB> <TAB> self.DeleteArtifact(str(artifact.name)) <TAB> <TAB> self.WriteArtifact(artifact) <TAB> return artifact",false,if attributes != unicode_attributes :,if unicode_attributes :,0.07,0.0
"def edit_file(self, filename): <TAB> import subprocess <TAB> editor = self.get_editor() <TAB> if self.env: <TAB> <TAB> environ = os.environ.copy() <TAB> <TAB> environ.update(self.env) <TAB> else: <TAB> <TAB> environ = None <TAB> try: <TAB> <TAB> c = subprocess.Popen('%s ""%s""' % (editor, filename), env=environ, shell=True) <TAB> <TAB> exit_code = c.wait() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ClickException(""%s: Editing failed!"" % editor) <TAB> except OSError as e: <TAB> <TAB> raise ClickException(""%s: Editing failed: %s"" % (editor, e))",true,if exit_code != 0 :,if exit_code != 0 :,0.75,0.0
"def findControlPointsInMesh(glyph, va, subsegments): <TAB> controlPointIndices = np.zeros((len(va), 1)) <TAB> index = 0 <TAB> for i, c in enumerate(subsegments): <TAB> <TAB> segmentCount = len(glyph.contours[i].segments) - 1 <TAB> <TAB> for j, s in enumerate(c): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if glyph.contours[i].segments[j].type == ""line"": <TAB> <TAB> <TAB> <TAB> <TAB> controlPointIndices[index] = 1 <TAB> <TAB> <TAB> index += s[1] <TAB> return controlPointIndices",false,if j < segmentCount :,if s [ 0 ] < segmentCount :,0.11,0.0
"def to_representation(self, value): <TAB> old_social_string_fields = [""twitter"", ""github"", ""linkedIn""] <TAB> request = self.context.get(""request"") <TAB> show_old_format = ( <TAB> <TAB> request <TAB> <TAB> and is_deprecated(request.version, self.min_version) <TAB> <TAB> and request.method == ""GET"" <TAB> ) <TAB> if show_old_format: <TAB> <TAB> social = value.copy() <TAB> <TAB> for key in old_social_string_fields: <TAB> <TAB> <TAB> if social.get(key): <TAB> <TAB> <TAB> <TAB> social[key] = value[key][0] <TAB> <TAB> <TAB> elif social.get(key) == []: <TAB> <TAB> <TAB> <TAB> social[key] = """" <TAB> <TAB> value = social <TAB> return super(SocialField, self).to_representation(value)",false,if social . get ( key ) :,elif social . get ( key ) == [ ] :,0.28,0.0
"def iter_raw_frames(path, packet_sizes, ctx): <TAB> with open(path, ""rb"") as f: <TAB> <TAB> for i, size in enumerate(packet_sizes): <TAB> <TAB> <TAB> packet = Packet(size) <TAB> <TAB> <TAB> read_size = f.readinto(packet) <TAB> <TAB> <TAB> assert size <TAB> <TAB> <TAB> assert read_size == size <TAB> <TAB> <TAB> if not read_size: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> for frame in ctx.decode(packet): <TAB> <TAB> <TAB> <TAB> yield frame <TAB> <TAB> while True: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> frames = ctx.decode(None) <TAB> <TAB> <TAB> except EOFError: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> for frame in frames: <TAB> <TAB> <TAB> <TAB> yield frame <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break",true,if not frames :,if not frames :,0.75,0.0
"def get_shadows_zip(filename): <TAB> import zipfile <TAB> shadow_pkgs = set() <TAB> with zipfile.ZipFile(filename) as lib_zip: <TAB> <TAB> already_test = [] <TAB> <TAB> for fname in lib_zip.namelist(): <TAB> <TAB> <TAB> pname, fname = os.path.split(fname) <TAB> <TAB> <TAB> if fname or (pname and fname): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if pname not in already_test and ""/"" not in pname: <TAB> <TAB> <TAB> <TAB> already_test.append(pname) <TAB> <TAB> <TAB> <TAB> if is_shadowing(pname): <TAB> <TAB> <TAB> <TAB> <TAB> shadow_pkgs.add(pname) <TAB> return shadow_pkgs",true,if is_shadowing ( pname ) :,if is_shadowing ( pname ) :,0.75,0.0
"def metrics_to_scalars(self, metrics): <TAB> new_metrics = {} <TAB> for k, v in metrics.items(): <TAB> <TAB> if isinstance(v, torch.Tensor): <TAB> <TAB> <TAB> v = v.item() <TAB> <TAB> if isinstance(v, dict): <TAB> <TAB> <TAB> v = self.metrics_to_scalars(v) <TAB> <TAB> new_metrics[k] = v <TAB> return new_metrics",true,"if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",0.75,0.0
"def insert_resets(f): <TAB> newsync = dict() <TAB> for k, v in f.sync.items(): <TAB> <TAB> if f.clock_domains[k].rst is not None: <TAB> <TAB> <TAB> newsync[k] = insert_reset(ResetSignal(k), v) <TAB> <TAB> else: <TAB> <TAB> <TAB> newsync[k] = v <TAB> f.sync = newsync",true,if f . clock_domains [ k ] . rst is not None :,if f . clock_domains [ k ] . rst is not None :,0.75,0.0
"def get_attached_nodes(self, external_account): <TAB> for node in self.get_nodes_with_oauth_grants(external_account): <TAB> <TAB> if node is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> node_settings = node.get_addon(self.oauth_provider.short_name) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if node_settings.external_account == external_account: <TAB> <TAB> <TAB> yield node",true,if node_settings is None :,if node_settings is None :,0.75,0.0
"def visitIf(self, node, scope): <TAB> for test, body in node.tests: <TAB> <TAB> if isinstance(test, ast.Const): <TAB> <TAB> <TAB> if type(test.value) in self._const_types: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> self.visit(test, scope) <TAB> <TAB> self.visit(body, scope) <TAB> if node.else_: <TAB> <TAB> self.visit(node.else_, scope)",false,if not test . value :,if type ( test ) is Literal :,0.02,0.0
"def flatten(self): <TAB> # this is similar to fill_messages except it uses a list instead <TAB> # of a queue to place the messages in. <TAB> result = [] <TAB> channel = await self.messageable._get_channel() <TAB> self.channel = channel <TAB> while self._get_retrieve(): <TAB> <TAB> data = await self._retrieve_messages(self.retrieve) <TAB> <TAB> if len(data) < 100: <TAB> <TAB> <TAB> self.limit = 0  # terminate the infinite loop <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> data = reversed(data) <TAB> <TAB> if self._filter: <TAB> <TAB> <TAB> data = filter(self._filter, data) <TAB> <TAB> for element in data: <TAB> <TAB> <TAB> result.append(self.state.create_message(channel=channel, data=element)) <TAB> return result",true,if self . reverse :,if self . reverse :,0.75,0.0
"def compute(self, x, y=None, targets=None): <TAB> if targets is None: <TAB> <TAB> targets = self.out_params <TAB> in_params = list(self.in_x) <TAB> if len(in_params) == 1: <TAB> <TAB> args = [x] <TAB> else: <TAB> <TAB> args = list(zip(*x)) <TAB> if y is None: <TAB> <TAB> pipe = self.pipe <TAB> else: <TAB> <TAB> pipe = self.train_pipe <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> args.append(y) <TAB> <TAB> else: <TAB> <TAB> <TAB> args += list(zip(*y)) <TAB> <TAB> in_params += self.in_y <TAB> return self._compute(*args, pipe=pipe, param_names=in_params, targets=targets)",false,if len ( self . in_y ) == 1 :,if len ( y ) == 1 :,0.2,0.0
"def _import_top_module(self, name): <TAB> # scan sys.path looking for a location in the filesystem that contains <TAB> # the module, or an Importer object that can import the module. <TAB> for item in sys.path: <TAB> <TAB> if isinstance(item, _StringType): <TAB> <TAB> <TAB> module = self.fs_imp.import_from_dir(item, name) <TAB> <TAB> else: <TAB> <TAB> <TAB> module = item.import_top(name) <TAB> <TAB> if module: <TAB> <TAB> <TAB> return module <TAB> return None",true,"if isinstance ( item , _StringType ) :","if isinstance ( item , _StringType ) :",0.75,0.0
"def __getitem__(self, key, _get_mode=False): <TAB> if not _get_mode: <TAB> <TAB> if isinstance(key, (int, long)): <TAB> <TAB> <TAB> return self._list[key] <TAB> <TAB> elif isinstance(key, slice): <TAB> <TAB> <TAB> return self.__class__(self._list[key]) <TAB> ikey = key.lower() <TAB> for k, v in self._list: <TAB> <TAB> if k.lower() == ikey: <TAB> <TAB> <TAB> return v <TAB> # micro optimization: if we are in get mode we will catch that <TAB> # exception one stack level down so we can raise a standard <TAB> # key error instead of our special one. <TAB> if _get_mode: <TAB> <TAB> raise KeyError() <TAB> raise BadRequestKeyError(key)",true,if k . lower ( ) == ikey :,if k . lower ( ) == ikey :,0.75,0.0
"def execute(self, arbiter, props): <TAB> watcher = self._get_watcher(arbiter, props.pop(""name"")) <TAB> action = 0 <TAB> for key, val in props.get(""options"", {}).items(): <TAB> <TAB> if key == ""hooks"": <TAB> <TAB> <TAB> new_action = 0 <TAB> <TAB> <TAB> for name, _val in val.items(): <TAB> <TAB> <TAB> <TAB> action = watcher.set_opt(""hooks.%s"" % name, _val) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> new_action = 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> new_action = watcher.set_opt(key, val) <TAB> <TAB> if new_action == 1: <TAB> <TAB> <TAB> action = 1 <TAB> # trigger needed action <TAB> return watcher.do_action(action)",false,if action == 1 :,if new_action == 1 :,0.39,0.0
"def OnBodyClick(self, event=None): <TAB> try: <TAB> <TAB> c = self.c <TAB> <TAB> p = c.currentPosition() <TAB> <TAB> if not g.doHook(""bodyclick1"", c=c, p=p, v=p, event=event): <TAB> <TAB> <TAB> self.OnActivateBody(event=event) <TAB> <TAB> g.doHook(""bodyclick2"", c=c, p=p, v=p, event=event) <TAB> except: <TAB> <TAB> g.es_event_exception(""bodyclick"")",true,"if not g . doHook ( ""bodyclick1"" , c = c , p = p , v = p , event = event ) :","if not g . doHook ( ""bodyclick1"" , c = c , p = p , v = p , event = event ) :",1.0,0.0
"def _class_weights(spec: config.MetricsSpec) -> Optional[Dict[int, float]]: <TAB> """"""Returns class weights associated with AggregationOptions at offset."""""" <TAB> if spec.aggregate.HasField(""top_k_list""): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""class_weights are not supported when top_k_list used: "" <TAB> <TAB> <TAB> <TAB> ""spec={}"".format(spec) <TAB> <TAB> <TAB> ) <TAB> <TAB> return None <TAB> return dict(spec.aggregate.class_weights) or None",false,if spec . aggregate . class_weights :,"if ""class_weights"" not in spec . aggregate . top_k_list :",0.38,0.0
"def _is_perf_file(file_path): <TAB> f = get_file(file_path) <TAB> for line in f: <TAB> <TAB> if line[0] == ""#"": <TAB> <TAB> <TAB> continue <TAB> <TAB> r = event_regexp.search(line) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> f.close() <TAB> <TAB> <TAB> return True <TAB> <TAB> f.close() <TAB> <TAB> return False",true,if r :,if r :,0.53,0.0
"def _get_before_insertion_node(self): <TAB> if self._nodes_stack.is_empty(): <TAB> <TAB> return None <TAB> line = self._nodes_stack.parsed_until_line + 1 <TAB> node = self._new_module.get_last_leaf() <TAB> while True: <TAB> <TAB> parent = node.parent <TAB> <TAB> if parent.type in (""suite"", ""file_input""): <TAB> <TAB> <TAB> assert node.end_pos[0] <= line <TAB> <TAB> <TAB> assert node.end_pos[1] == 0 or ""\n"" in self._prefix <TAB> <TAB> <TAB> return node <TAB> <TAB> node = parent",true,"if parent . type in ( ""suite"" , ""file_input"" ) :","if parent . type in ( ""suite"" , ""file_input"" ) :",0.75,0.0
"def PyJsHoisted_parseClassRanges_(this, arguments, var=var): <TAB> var = Scope({u""this"": this, u""arguments"": arguments}, var) <TAB> var.registers([u""res""]) <TAB> pass <TAB> if var.get(u""current"")(Js(u""]"")): <TAB> <TAB> return Js([]) <TAB> else: <TAB> <TAB> var.put(u""res"", var.get(u""parseNonemptyClassRanges"")()) <TAB> <TAB> if var.get(u""res"").neg(): <TAB> <TAB> <TAB> var.get(u""bail"")(Js(u""nonEmptyClassRanges"")) <TAB> <TAB> return var.get(u""res"")",true,"if var . get ( u""res"" ) . neg ( ) :","if var . get ( u""res"" ) . neg ( ) :",0.75,0.0
"def _recurse_children(self, offset): <TAB> """"""Recurses thorugh the available children"""""" <TAB> while offset < self.obj_offset + self.Length: <TAB> <TAB> item = obj.Object(""VerStruct"", offset=offset, vm=self.obj_vm, parent=self) <TAB> <TAB> if item.Length < 1 or item.get_key() == None: <TAB> <TAB> <TAB> raise StopIteration( <TAB> <TAB> <TAB> <TAB> ""Could not recover a key for a child at offset {0}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> item.obj_offset <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> yield item.get_key(), item.get_children() <TAB> <TAB> offset = self.offset_pad(offset + item.Length) <TAB> raise StopIteration(""No children"")",true,if item . Length < 1 or item . get_key ( ) == None :,if item . Length < 1 or item . get_key ( ) == None :,1.0,0.0
"def _adapt_types(self, descr): <TAB> names = [] <TAB> adapted_types = [] <TAB> for col in descr: <TAB> <TAB> names.append(col[0]) <TAB> <TAB> impala_typename = col[1] <TAB> <TAB> typename = udf._impala_to_ibis_type[impala_typename.lower()] <TAB> <TAB> if typename == ""decimal"": <TAB> <TAB> <TAB> precision, scale = col[4:6] <TAB> <TAB> <TAB> adapted_types.append(dt.Decimal(precision, scale)) <TAB> <TAB> else: <TAB> <TAB> <TAB> adapted_types.append(typename) <TAB> return names, adapted_types",true,"if typename == ""decimal"" :","if typename == ""decimal"" :",0.75,0.0
"def sniff(self, filename): <TAB> try: <TAB> <TAB> if filename and tarfile.is_tarfile(filename): <TAB> <TAB> <TAB> with tarfile.open(filename, ""r"") as temptar: <TAB> <TAB> <TAB> <TAB> for f in temptar: <TAB> <TAB> <TAB> <TAB> <TAB> if not f.isfile(): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> <TAB> if f.name.endswith("".fast5""): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> except Exception as e: <TAB> <TAB> log.warning(""%s, sniff Exception: %s"", self, e) <TAB> return False",true,if filename and tarfile . is_tarfile ( filename ) :,if filename and tarfile . is_tarfile ( filename ) :,0.75,0.0
"def getValue(self): <TAB> if getattr(self.object, ""type"", """") != ""CURVE"": <TAB> <TAB> return BezierSpline() <TAB> evaluatedObject = getEvaluatedID(self.object) <TAB> bSplines = evaluatedObject.data.splines <TAB> if len(bSplines) > 0: <TAB> <TAB> spline = createSplineFromBlenderSpline(bSplines[0]) <TAB> <TAB> # Is None when the spline type is not supported. <TAB> <TAB> if spline is not None: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> spline.transform(evaluatedObject.matrix_world) <TAB> <TAB> <TAB> return spline <TAB> return BezierSpline()",false,if self . useWorldSpace :,if evaluatedObject . matrix_world is not None :,0.11,0.0
"def escape(text, newline=False): <TAB> """"""Escape special html characters."""""" <TAB> if isinstance(text, str): <TAB> <TAB> if ""&"" in text: <TAB> <TAB> <TAB> text = text.replace(""&"", ""&amp;"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> text = text.replace("">"", ""&gt;"") <TAB> <TAB> if ""<"" in text: <TAB> <TAB> <TAB> text = text.replace(""<"", ""&lt;"") <TAB> <TAB> if '""' in text: <TAB> <TAB> <TAB> text = text.replace('""', ""&quot;"") <TAB> <TAB> if ""'"" in text: <TAB> <TAB> <TAB> text = text.replace(""'"", ""&quot;"") <TAB> <TAB> if newline: <TAB> <TAB> <TAB> if ""\n"" in text: <TAB> <TAB> <TAB> <TAB> text = text.replace(""\n"", ""<br>"") <TAB> return text",true,"if "">"" in text :","if "">"" in text :",0.75,0.0
"def _get_ilo_version(self): <TAB> try: <TAB> <TAB> self._get_ilo2('<?xml version=""1.0""?><RIBCL VERSION=""2.0""></RIBCL>') <TAB> except ResponseError as e: <TAB> <TAB> if hasattr(e, ""code""): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return 3 <TAB> <TAB> <TAB> if e.code == 501: <TAB> <TAB> <TAB> <TAB> return 1 <TAB> <TAB> raise <TAB> return 2",false,if e . code == 405 :,if e . code == 502 :,0.57,0.0
"def convert_path(ctx, tpath): <TAB> for points, code in tpath.iter_segments(): <TAB> <TAB> if code == Path.MOVETO: <TAB> <TAB> <TAB> ctx.move_to(*points) <TAB> <TAB> elif code == Path.LINETO: <TAB> <TAB> <TAB> ctx.line_to(*points) <TAB> <TAB> elif code == Path.CURVE3: <TAB> <TAB> <TAB> ctx.curve_to( <TAB> <TAB> <TAB> <TAB> points[0], points[1], points[0], points[1], points[2], points[3] <TAB> <TAB> <TAB> ) <TAB> <TAB> elif code == Path.CURVE4: <TAB> <TAB> <TAB> ctx.curve_to(*points) <TAB> <TAB> elif code == Path.CLOSEPOLY: <TAB> <TAB> <TAB> ctx.close_path()",false,elif code == Path . CLOSEPOLY :,elif code == Path . LINETO :,0.57,0.0
"def called_by_shrinker(): <TAB> frame = sys._getframe(0) <TAB> while frame: <TAB> <TAB> fname = frame.f_globals.get(""__file__"", """") <TAB> <TAB> if os.path.basename(fname) == ""shrinker.py"": <TAB> <TAB> <TAB> return True <TAB> <TAB> frame = frame.f_back <TAB> return False",true,"if os . path . basename ( fname ) == ""shrinker.py"" :","if os . path . basename ( fname ) == ""shrinker.py"" :",0.75,0.0
"def _ensuresyspath(self, ensuremode, path): <TAB> if ensuremode: <TAB> <TAB> s = str(path) <TAB> <TAB> if ensuremode == ""append"": <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> sys.path.append(s) <TAB> <TAB> else: <TAB> <TAB> <TAB> if s != sys.path[0]: <TAB> <TAB> <TAB> <TAB> sys.path.insert(0, s)",true,if s not in sys . path :,if s not in sys . path :,0.75,0.0
"def get_instances(self, region: str, vpc: str): <TAB> try: <TAB> <TAB> await self._cache_instances(region) <TAB> <TAB> return [ <TAB> <TAB> <TAB> instance <TAB> <TAB> <TAB> for instance in self._instances_cache[region] <TAB> <TAB> <TAB> if instance[""VpcId""] == vpc <TAB> <TAB> ] <TAB> except Exception as e: <TAB> <TAB> print_exception(f""Failed to get RDS instances: {e}"") <TAB> <TAB> return []",true,"if instance [ ""VpcId"" ] == vpc","if instance [ ""VpcId"" ] == vpc",0.75,0.0
def get_and_set_all_disambiguation(self): <TAB> all_disambiguations = [] <TAB> for page in self.pages: <TAB> <TAB> if page.relations.disambiguation_links_norm is not None: <TAB> <TAB> <TAB> all_disambiguations.extend(page.relations.disambiguation_links_norm) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> all_disambiguations.extend(page.relations.disambiguation_links) <TAB> return set(all_disambiguations),true,if page . relations . disambiguation_links is not None :,if page . relations . disambiguation_links is not None :,0.75,0.0
"def __str__(self, prefix="""", printElemNumber=0): <TAB> res = """" <TAB> cnt = 0 <TAB> for e in self.options_: <TAB> <TAB> elm = """" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> elm = ""(%d)"" % cnt <TAB> <TAB> res += prefix + (""options%s <\n"" % elm) <TAB> <TAB> res += e.__str__(prefix + ""  "", printElemNumber) <TAB> <TAB> res += prefix + "">\n"" <TAB> <TAB> cnt += 1 <TAB> return res",true,if printElemNumber :,if printElemNumber :,0.53,0.0
"def pre_save_task(self, task, credentials, verrors): <TAB> if task[""attributes""][""encryption""] not in (None, """", ""AES256""): <TAB> <TAB> verrors.add(""encryption"", 'Encryption should be null or ""AES256""') <TAB> if not credentials[""attributes""].get(""skip_region"", False): <TAB> <TAB> if not credentials[""attributes""].get(""region"", """").strip(): <TAB> <TAB> <TAB> response = await self.middleware.run_in_thread( <TAB> <TAB> <TAB> <TAB> self._get_client(credentials).get_bucket_location, <TAB> <TAB> <TAB> <TAB> Bucket=task[""attributes""][""bucket""], <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> task[""attributes""][""region""] = response[""LocationConstraint""] or ""us-east-1""",true,"if not credentials [ ""attributes"" ] . get ( ""region"" , """" ) . strip ( ) :","if not credentials [ ""attributes"" ] . get ( ""region"" , """" ) . strip ( ) :",0.75,0.0
"def get_best_config_reward(self): <TAB> """"""Returns the best configuration found so far, as well as the reward associated with this best config."""""" <TAB> with self.LOCK: <TAB> <TAB> if self._results: <TAB> <TAB> <TAB> config_pkl = max(self._results, key=self._results.get) <TAB> <TAB> <TAB> return pickle.loads(config_pkl), self._results[config_pkl] <TAB> <TAB> else: <TAB> <TAB> <TAB> return dict(), self._reward_while_pending()",true,if self . _results :,if self . _results :,0.75,0.0
"def parse_setup_cfg(self): <TAB> # type: () -> Dict[STRING_TYPE, Any] <TAB> if self.setup_cfg is not None and self.setup_cfg.exists(): <TAB> <TAB> contents = self.setup_cfg.read_text() <TAB> <TAB> base_dir = self.setup_cfg.absolute().parent.as_posix() <TAB> <TAB> try: <TAB> <TAB> <TAB> parsed = setuptools_parse_setup_cfg(self.setup_cfg.as_posix()) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> contents = self.setup_cfg.read_bytes() <TAB> <TAB> <TAB> parsed = parse_setup_cfg(contents, base_dir) <TAB> <TAB> if not parsed: <TAB> <TAB> <TAB> return {} <TAB> <TAB> return parsed <TAB> return {}",false,if six . PY2 :,if contents is None :,0.03,0.0
"def readall(read_fn, sz): <TAB> buff = b"""" <TAB> have = 0 <TAB> while have < sz: <TAB> <TAB> chunk = yield from read_fn(sz - have) <TAB> <TAB> have += len(chunk) <TAB> <TAB> buff += chunk <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise TTransportException( <TAB> <TAB> <TAB> <TAB> TTransportException.END_OF_FILE, ""End of file reading from transport"" <TAB> <TAB> <TAB> ) <TAB> return buff",false,if len ( chunk ) == 0 :,if not chunk :,0.02,0.0
"def _get_use_previous( <TAB> f, ):  # TODO Sort and group features for DateOffset with two different temporal values <TAB> if isinstance(f, AggregationFeature) and f.use_previous is not None: <TAB> <TAB> if len(f.use_previous.times.keys()) > 1: <TAB> <TAB> <TAB> return ("""", -1) <TAB> <TAB> else: <TAB> <TAB> <TAB> unit = list(f.use_previous.times.keys())[0] <TAB> <TAB> <TAB> value = f.use_previous.times[unit] <TAB> <TAB> <TAB> return (unit, value) <TAB> else: <TAB> <TAB> return ("""", -1)",true,if len ( f . use_previous . times . keys ( ) ) > 1 :,if len ( f . use_previous . times . keys ( ) ) > 1 :,0.75,0.0
"def istrue(self): <TAB> try: <TAB> <TAB> return self._istrue() <TAB> except Exception: <TAB> <TAB> self.exc = sys.exc_info() <TAB> <TAB> if isinstance(self.exc[1], SyntaxError): <TAB> <TAB> <TAB> msg = [ <TAB> <TAB> <TAB> <TAB> "" "" * (self.exc[1].offset + 4) + ""^"", <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> msg.append(""SyntaxError: invalid syntax"") <TAB> <TAB> else: <TAB> <TAB> <TAB> msg = traceback.format_exception_only(*self.exc[:2]) <TAB> <TAB> pytest.fail( <TAB> <TAB> <TAB> ""Error evaluating %r expression\n"" <TAB> <TAB> <TAB> "" <TAB>%s\n"" <TAB> <TAB> <TAB> ""%s"" % (self.name, self.expr, ""\n"".join(msg)), <TAB> <TAB> <TAB> pytrace=False, <TAB> <TAB> )",true,"if isinstance ( self . exc [ 1 ] , SyntaxError ) :","if isinstance ( self . exc [ 1 ] , SyntaxError ) :",0.75,0.0
"def wait_for_crm_operation(operation, crm): <TAB> """"""Poll for cloud resource manager operation until finished."""""" <TAB> logger.info( <TAB> <TAB> ""wait_for_crm_operation: "" <TAB> <TAB> ""Waiting for operation {} to finish..."".format(operation) <TAB> ) <TAB> for _ in range(MAX_POLLS): <TAB> <TAB> result = crm.operations().get(name=operation[""name""]).execute() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise Exception(result[""error""]) <TAB> <TAB> if ""done"" in result and result[""done""]: <TAB> <TAB> <TAB> logger.info(""wait_for_crm_operation: Operation done."") <TAB> <TAB> <TAB> break <TAB> <TAB> time.sleep(POLL_INTERVAL) <TAB> return result",true,"if ""error"" in result :","if ""error"" in result :",0.75,0.0
"def cb_blob_detail_from_elem_and_buf(self, elem, buf): <TAB> if elem.get(""lang"") != buf.lang:  # multi-lang doc <TAB> <TAB> return ""%s Code in %s"" % (elem.get(""lang""), buf.path) <TAB> else: <TAB> <TAB> dir, base = os.path.split(buf.path) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ""%s (%s)"" % (base, dir) <TAB> <TAB> else: <TAB> <TAB> <TAB> return base",true,if dir :,if dir :,0.53,0.0
"def removedir(self, path): <TAB> # type: (Text) -> None <TAB> _path = self.validatepath(path) <TAB> if _path == ""/"": <TAB> <TAB> raise errors.RemoveRootError() <TAB> with ftp_errors(self, path): <TAB> <TAB> try: <TAB> <TAB> <TAB> self.ftp.rmd(_encode(_path, self.ftp.encoding)) <TAB> <TAB> except error_perm as error: <TAB> <TAB> <TAB> code, _ = _parse_ftp_error(error) <TAB> <TAB> <TAB> if code == ""550"": <TAB> <TAB> <TAB> <TAB> if self.isfile(path): <TAB> <TAB> <TAB> <TAB> <TAB> raise errors.DirectoryExpected(path) <TAB> <TAB> <TAB> <TAB> if not self.isempty(path): <TAB> <TAB> <TAB> <TAB> <TAB> raise errors.DirectoryNotEmpty(path) <TAB> <TAB> <TAB> raise  # pragma: no cover",true,"if code == ""550"" :","if code == ""550"" :",0.75,0.0
"def p_clause(self, node, position): <TAB> if isinstance(node, Graph): <TAB> <TAB> self.subjectDone(node) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.write("" "") <TAB> <TAB> self.write(""{"") <TAB> <TAB> self.depth += 1 <TAB> <TAB> serializer = N3Serializer(node, parent=self) <TAB> <TAB> serializer.serialize(self.stream) <TAB> <TAB> self.depth -= 1 <TAB> <TAB> self.write(self.indent() + ""}"") <TAB> <TAB> return True <TAB> else: <TAB> <TAB> return False",false,if position is OBJECT :,if self . depth > 0 :,0.03,0.0
"def get_default_shell_info(shell_name=None, settings=None): <TAB> if not shell_name: <TAB> <TAB> settings = settings or load_settings(lazy=True) <TAB> <TAB> shell_name = settings.get(""shell"") <TAB> <TAB> if shell_name: <TAB> <TAB> <TAB> return shell_name, None <TAB> <TAB> shell_path = os.environ.get(""SHELL"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> shell_name = basepath(shell_path) <TAB> <TAB> else: <TAB> <TAB> <TAB> shell_name = DEFAULT_SHELL <TAB> <TAB> return shell_name, shell_path <TAB> return shell_name, None",true,if shell_path :,if shell_path :,0.53,0.0
"def GetCategory(self, pidls): <TAB> ret = [] <TAB> for pidl in pidls: <TAB> <TAB> # Why don't we just get the size of the PIDL? <TAB> <TAB> val = self.sf.GetDetailsEx(pidl, PKEY_Sample_AreaSize) <TAB> <TAB> val = int(val)  # it probably came in a VT_BSTR variant <TAB> <TAB> if val < 255 // 3: <TAB> <TAB> <TAB> cid = IDS_SMALL <TAB> <TAB> elif val < 2 * 255 // 3: <TAB> <TAB> <TAB> cid = IDS_MEDIUM <TAB> <TAB> else: <TAB> <TAB> <TAB> cid = IDS_LARGE <TAB> <TAB> ret.append(cid) <TAB> return ret",true,elif val < 2 * 255 // 3 :,elif val < 2 * 255 // 3 :,0.75,0.0
"def Tokenize(s): <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE.findall(s): <TAB> <TAB> # The type checker can't know the true type of item! <TAB> <TAB> item = cast(TupleStr4, item) <TAB> <TAB> if item[0]: <TAB> <TAB> <TAB> typ = ""number"" <TAB> <TAB> <TAB> val = item[0] <TAB> <TAB> elif item[1]: <TAB> <TAB> <TAB> typ = ""name"" <TAB> <TAB> <TAB> val = item[1] <TAB> <TAB> elif item[2]: <TAB> <TAB> <TAB> typ = item[2] <TAB> <TAB> <TAB> val = item[2] <TAB> <TAB> elif item[3]: <TAB> <TAB> <TAB> typ = item[3] <TAB> <TAB> <TAB> val = item[3] <TAB> <TAB> yield Token(typ, val)",true,elif item [ 3 ] :,elif item [ 3 ] :,0.75,0.0
"def add_package_declarations(generated_root_path): <TAB> file_names = os.listdir(generated_root_path) <TAB> for file_name in file_names: <TAB> <TAB> if not file_name.endswith("".java""): <TAB> <TAB> <TAB> continue <TAB> <TAB> full_name = os.path.join(generated_root_path, file_name) <TAB> <TAB> add_package(full_name)",true,"if not file_name . endswith ( "".java"" ) :","if not file_name . endswith ( "".java"" ) :",0.75,0.0
"def _call_with_retry(out, retry, retry_wait, method, *args, **kwargs): <TAB> for counter in range(retry + 1): <TAB> <TAB> try: <TAB> <TAB> <TAB> return method(*args, **kwargs) <TAB> <TAB> except ( <TAB> <TAB> <TAB> NotFoundException, <TAB> <TAB> <TAB> ForbiddenException, <TAB> <TAB> <TAB> AuthenticationException, <TAB> <TAB> <TAB> RequestErrorException, <TAB> <TAB> ): <TAB> <TAB> <TAB> raise <TAB> <TAB> except ConanException as exc: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> if out: <TAB> <TAB> <TAB> <TAB> <TAB> out.error(exc) <TAB> <TAB> <TAB> <TAB> <TAB> out.info(""Waiting %d seconds to retry..."" % retry_wait) <TAB> <TAB> <TAB> <TAB> time.sleep(retry_wait)",true,if counter == retry :,if counter == retry :,0.75,0.0
"def to_wburl_str( <TAB> url, type=BaseWbUrl.LATEST_REPLAY, mod="""", timestamp="""", end_timestamp="""" ): <TAB> if WbUrl.is_query_type(type): <TAB> <TAB> tsmod = """" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tsmod += mod + ""/"" <TAB> <TAB> tsmod += timestamp <TAB> <TAB> tsmod += ""*"" <TAB> <TAB> tsmod += end_timestamp <TAB> <TAB> tsmod += ""/"" + url <TAB> <TAB> if type == BaseWbUrl.URL_QUERY: <TAB> <TAB> <TAB> tsmod += ""*"" <TAB> <TAB> return tsmod <TAB> else: <TAB> <TAB> tsmod = timestamp + mod <TAB> <TAB> if len(tsmod) > 0: <TAB> <TAB> <TAB> return tsmod + ""/"" + url <TAB> <TAB> else: <TAB> <TAB> <TAB> return url",false,if mod :,if type == BaseWbUrl . URL_MOD :,0.05,0.0
"def _configured_ploidy(items): <TAB> ploidies = collections.defaultdict(set) <TAB> for data in items: <TAB> <TAB> ploidy = dd.get_ploidy(data) <TAB> <TAB> if isinstance(ploidy, dict): <TAB> <TAB> <TAB> for k, v in ploidy.items(): <TAB> <TAB> <TAB> <TAB> ploidies[k].add(v) <TAB> <TAB> else: <TAB> <TAB> <TAB> ploidies[""default""].add(ploidy) <TAB> out = {} <TAB> for k, vs in ploidies.items(): <TAB> <TAB> assert len(vs) == 1, ""Multiple ploidies set for group calling: %s %s"" % ( <TAB> <TAB> <TAB> k, <TAB> <TAB> <TAB> list(vs), <TAB> <TAB> ) <TAB> <TAB> out[k] = vs.pop() <TAB> return out",true,"if isinstance ( ploidy , dict ) :","if isinstance ( ploidy , dict ) :",0.75,0.0
"def removeUser(self, username): <TAB> hideFromOSD = not constants.SHOW_DIFFERENT_ROOM_OSD <TAB> if username in self._users: <TAB> <TAB> user = self._users[username] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if self.isRoomSame(user.room): <TAB> <TAB> <TAB> <TAB> hideFromOSD = not constants.SHOW_SAME_ROOM_OSD <TAB> if username in self._users: <TAB> <TAB> self._users.pop(username) <TAB> <TAB> message = getMessage(""left-notification"").format(username) <TAB> <TAB> self.ui.showMessage(message, hideFromOSD) <TAB> <TAB> self._client.lastLeftTime = time.time() <TAB> <TAB> self._client.lastLeftUser = username <TAB> self.userListChange()",true,if user . room :,if user . room :,0.75,0.0
"def _thd_cleanup_instance(self): <TAB> container_name = self.getContainerName() <TAB> instances = self.client.containers(all=1, filters=dict(name=container_name)) <TAB> for instance in instances: <TAB> <TAB> # hyper filtering will match 'hyper12"" if you search for 'hyper1' ! <TAB> <TAB> if """".join(instance[""Names""]).strip(""/"") != container_name: <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> self.client.remove_container(instance[""Id""], v=True, force=True) <TAB> <TAB> except NotFound: <TAB> <TAB> <TAB> pass  # that's a race condition <TAB> <TAB> except docker.errors.APIError as e: <TAB> <TAB> <TAB> if ""Conflict operation on container"" not in str(e): <TAB> <TAB> <TAB> <TAB> raise",false,"if """" . join ( instance [ ""Names"" ] ) . strip ( ""/"" ) != container_name :","if ""Conflict operation on container"" not in str ( e ) :",0.01,0.0
"def handle_ctcp(self, conn, evt): <TAB> args = evt.arguments() <TAB> source = evt.source().split(""!"")[0] <TAB> if args: <TAB> <TAB> if args[0] == ""VERSION"": <TAB> <TAB> <TAB> conn.ctcp_reply(source, ""VERSION "" + BOT_VERSION) <TAB> <TAB> elif args[0] == ""PING"": <TAB> <TAB> <TAB> conn.ctcp_reply(source, ""PING"") <TAB> <TAB> elif args[0] == ""CLIENTINFO"": <TAB> <TAB> <TAB> conn.ctcp_reply(source, ""CLIENTINFO PING VERSION CLIENTINFO"")",true,"elif args [ 0 ] == ""PING"" :","elif args [ 0 ] == ""PING"" :",1.0,0.0
"def new_func(self, *args, **kwargs): <TAB> obj = self.obj_ref() <TAB> attr = self.attr <TAB> if obj is not None: <TAB> <TAB> args = tuple(TrackedValue.make(obj, attr, arg) for arg in args) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> kwargs = { <TAB> <TAB> <TAB> <TAB> key: TrackedValue.make(obj, attr, value) <TAB> <TAB> <TAB> <TAB> for key, value in iteritems(kwargs) <TAB> <TAB> <TAB> } <TAB> result = func(self, *args, **kwargs) <TAB> self._changed_() <TAB> return result",false,if kwargs :,if kwargs is not None :,0.09,0.0
"def add_doc(target, variables, body_lines): <TAB> if isinstance(target, ast.Name): <TAB> <TAB> # if it is a variable name add it to the doc <TAB> <TAB> name = target.id <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> doc = find_doc_for(target, body_lines) <TAB> <TAB> <TAB> if doc is not None: <TAB> <TAB> <TAB> <TAB> variables[name] = doc <TAB> elif isinstance(target, ast.Tuple): <TAB> <TAB> # if it is a tuple then iterate the elements <TAB> <TAB> # this can happen like this: <TAB> <TAB> # a, b = 1, 2 <TAB> <TAB> for e in target.elts: <TAB> <TAB> <TAB> add_doc(e, variables, body_lines)",true,if name not in variables :,if name not in variables :,0.75,0.0
"def _terminal_messenger(tp=""write"", msg="""", out=sys.stdout): <TAB> try: <TAB> <TAB> if tp == ""write"": <TAB> <TAB> <TAB> out.write(msg) <TAB> <TAB> elif tp == ""flush"": <TAB> <TAB> <TAB> out.flush() <TAB> <TAB> elif tp == ""write_flush"": <TAB> <TAB> <TAB> out.write(msg) <TAB> <TAB> <TAB> out.flush() <TAB> <TAB> elif tp == ""print"": <TAB> <TAB> <TAB> print(msg, file=out) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""Unsupported type: "" + tp) <TAB> except IOError as e: <TAB> <TAB> logger.critical(""{}: {}"".format(type(e).__name__, ucd(e))) <TAB> <TAB> pass",false,"elif tp == ""write_flush"" :","elif tp == ""flush"" :",0.64,0.0
"def get_files(d): <TAB> res = [] <TAB> for p in glob.glob(os.path.join(d, ""*"")): <TAB> <TAB> if not p: <TAB> <TAB> <TAB> continue <TAB> <TAB> (pth, fname) = os.path.split(p) <TAB> <TAB> if skip_file(fname): <TAB> <TAB> <TAB> continue <TAB> <TAB> if os.path.islink(p): <TAB> <TAB> <TAB> continue <TAB> <TAB> if os.path.isdir(p): <TAB> <TAB> <TAB> res += get_dir(p) <TAB> <TAB> else: <TAB> <TAB> <TAB> res.append(p) <TAB> return res",true,if skip_file ( fname ) :,if skip_file ( fname ) :,0.75,0.0
"def _list_outputs(self): <TAB> outputs = super(VolSymm, self)._list_outputs() <TAB> # Have to manually check for the grid files. <TAB> if os.path.exists(outputs[""trans_file""]): <TAB> <TAB> if ""grid"" in open(outputs[""trans_file""], ""r"").read(): <TAB> <TAB> <TAB> outputs[""output_grid""] = re.sub( <TAB> <TAB> <TAB> <TAB> "".(nlxfm|xfm)$"", ""_grid_0.mnc"", outputs[""trans_file""] <TAB> <TAB> <TAB> ) <TAB> return outputs",true,"if ""grid"" in open ( outputs [ ""trans_file"" ] , ""r"" ) . read ( ) :","if ""grid"" in open ( outputs [ ""trans_file"" ] , ""r"" ) . read ( ) :",0.75,0.0
"def _set_texture(self, texture): <TAB> if texture.id is not self._texture.id: <TAB> <TAB> self._group = SpriteGroup( <TAB> <TAB> <TAB> texture, self._group.blend_src, self._group.blend_dest, self._group.parent <TAB> <TAB> ) <TAB> <TAB> if self._batch is None: <TAB> <TAB> <TAB> self._vertex_list.tex_coords[:] = texture.tex_coords <TAB> <TAB> else: <TAB> <TAB> <TAB> self._vertex_list.delete() <TAB> <TAB> <TAB> self._texture = texture <TAB> <TAB> <TAB> self._create_vertex_list() <TAB> else: <TAB> <TAB> self._vertex_list.tex_coords[:] = texture.tex_coords <TAB> self._texture = texture",true,if self . _batch is None :,if self . _batch is None :,0.75,0.0
"def got_result(result): <TAB> deployment = self.persistence_service.get() <TAB> for node in deployment.nodes: <TAB> <TAB> if same_node(node, origin): <TAB> <TAB> <TAB> dataset_ids = [ <TAB> <TAB> <TAB> <TAB> (m.dataset.deleted, m.dataset.dataset_id) <TAB> <TAB> <TAB> <TAB> for m in node.manifestations.values() <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> self.assertIn((True, expected_dataset_id), dataset_ids) <TAB> <TAB> <TAB> break <TAB> else: <TAB> <TAB> self.fail(""Node not found. {}"".format(node.uuid))",true,"if same_node ( node , origin ) :","if same_node ( node , origin ) :",0.75,0.0
"def check_result(result, func, arguments): <TAB> if check_warning(result) and (result.value != ReturnCode.WARN_NODATA): <TAB> <TAB> log.warning(UcanWarning(result, func, arguments)) <TAB> elif check_error(result): <TAB> <TAB> if check_error_cmd(result): <TAB> <TAB> <TAB> raise UcanCmdError(result, func, arguments) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise UcanError(result, func, arguments) <TAB> return result",true,if check_error_cmd ( result ) :,if check_error_cmd ( result ) :,0.75,0.0
"def _compress_and_sort_bdg_files(out_dir, data): <TAB> for fn in glob.glob(os.path.join(out_dir, ""*bdg"")): <TAB> <TAB> out_file = fn + "".gz"" <TAB> <TAB> if utils.file_exists(out_file): <TAB> <TAB> <TAB> continue <TAB> <TAB> bedtools = config_utils.get_program(""bedtools"", data) <TAB> <TAB> with file_transaction(out_file) as tx_out_file: <TAB> <TAB> <TAB> cmd = f""sort -k1,1 -k2,2n {fn} | bgzip -c > {tx_out_file}"" <TAB> <TAB> <TAB> message = f""Compressing and sorting {fn}."" <TAB> <TAB> <TAB> do.run(cmd, message)",true,if utils . file_exists ( out_file ) :,if utils . file_exists ( out_file ) :,0.75,0.0
"def kill_members(members, sig, hosts=nodes): <TAB> for member in sorted(members): <TAB> <TAB> try: <TAB> <TAB> <TAB> if ha_tools_debug: <TAB> <TAB> <TAB> <TAB> print(""killing %s"" % member) <TAB> <TAB> <TAB> proc = hosts[member][""proc""] <TAB> <TAB> <TAB> # Not sure if cygwin makes sense here... <TAB> <TAB> <TAB> if sys.platform in (""win32"", ""cygwin""): <TAB> <TAB> <TAB> <TAB> os.kill(proc.pid, signal.CTRL_C_EVENT) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> os.kill(proc.pid, sig) <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> if ha_tools_debug: <TAB> <TAB> <TAB> <TAB> print(""%s already dead?"" % member)",true,"if sys . platform in ( ""win32"" , ""cygwin"" ) :","if sys . platform in ( ""win32"" , ""cygwin"" ) :",0.75,0.0
"def get_top_level_stats(self): <TAB> for func, (cc, nc, tt, ct, callers) in self.stats.items(): <TAB> <TAB> self.total_calls += nc <TAB> <TAB> self.prim_calls += cc <TAB> <TAB> self.total_tt += tt <TAB> <TAB> if (""jprofile"", 0, ""profiler"") in callers: <TAB> <TAB> <TAB> self.top_level[func] = None <TAB> <TAB> if len(func_std_string(func)) > self.max_name_len: <TAB> <TAB> <TAB> self.max_name_len = len(func_std_string(func))",true,"if ( ""jprofile"" , 0 , ""profiler"" ) in callers :","if ( ""jprofile"" , 0 , ""profiler"" ) in callers :",0.75,0.0
"def __str__(self): <TAB> """"""Only keeps the True values."""""" <TAB> result = [""SlicingSpec(""] <TAB> if self.entire_dataset: <TAB> <TAB> result.append("" Entire dataset,"") <TAB> if self.by_class: <TAB> <TAB> if isinstance(self.by_class, Iterable): <TAB> <TAB> <TAB> result.append("" Into classes %s,"" % self.by_class) <TAB> <TAB> elif isinstance(self.by_class, int): <TAB> <TAB> <TAB> result.append("" Up to class %d,"" % self.by_class) <TAB> <TAB> else: <TAB> <TAB> <TAB> result.append("" By classes,"") <TAB> if self.by_percentiles: <TAB> <TAB> result.append("" By percentiles,"") <TAB> if self.by_classification_correctness: <TAB> <TAB> result.append("" By classification correctness,"") <TAB> result.append("")"") <TAB> return ""\n"".join(result)",true,"elif isinstance ( self . by_class , int ) :","elif isinstance ( self . by_class , int ) :",0.75,0.0
"def save_params(self): <TAB> if self._save_controller: <TAB> <TAB> if not os.path.exists(self._save_controller): <TAB> <TAB> <TAB> os.makedirs(self._save_controller) <TAB> <TAB> output_dir = self._save_controller <TAB> else: <TAB> <TAB> if not os.path.exists(""./.rlnas_controller""): <TAB> <TAB> <TAB> os.makedirs(""./.rlnas_controller"") <TAB> <TAB> output_dir = ""./.rlnas_controller"" <TAB> with open(os.path.join(output_dir, ""rlnas.params""), ""wb"") as f: <TAB> <TAB> pickle.dump(self._params_dict, f) <TAB> _logger.debug(""Save params done"")",false,"if not os . path . exists ( ""./.rlnas_controller"" ) :",if not os . path . exists ( self . _save_controller ) :,0.4,0.0
"def unexport(self, pin): <TAB> with self._lock: <TAB> <TAB> self._pin_refs[pin] -= 1 <TAB> <TAB> if self._pin_refs[pin] == 0: <TAB> <TAB> <TAB> with io.open(self.path(""unexport""), ""wb"") as f: <TAB> <TAB> <TAB> <TAB> f.write(str(pin).encode(""ascii""))",true,if self . _pin_refs [ pin ] == 0 :,if self . _pin_refs [ pin ] == 0 :,0.75,0.0
"def emit(self, type, info=None): <TAB> # Overload emit() to send events to the proxy object at the other end <TAB> ev = super().emit(type, info) <TAB> if self._has_proxy is True and self._session.status > 0: <TAB> <TAB> # implicit: and self._disposed is False: <TAB> <TAB> if type in self.__proxy_properties__: <TAB> <TAB> <TAB> self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev]) <TAB> <TAB> elif type in self.__event_types_at_proxy: <TAB> <TAB> <TAB> self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev])",true,elif type in self . __event_types_at_proxy :,elif type in self . __event_types_at_proxy :,0.75,0.0
"def __call__(self, params): <TAB> all_errs = {} <TAB> for handler in self.handlers: <TAB> <TAB> out_headers, res, errs = handler(params) <TAB> <TAB> all_errs.update(errs) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return out_headers, res, all_errs <TAB> return None, None, all_errs",false,if res is not None :,if out_headers :,0.03,0.0
"def await_test_end(self): <TAB> iterations = 0 <TAB> while True: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.log.debug(""Await: iteration limit reached"") <TAB> <TAB> <TAB> return <TAB> <TAB> status = self.master.get_status() <TAB> <TAB> if status.get(""status"") == ""ENDED"": <TAB> <TAB> <TAB> return <TAB> <TAB> iterations += 1 <TAB> <TAB> time.sleep(1.0)",true,if iterations > 100 :,if iterations > 100 :,0.75,0.0
"def _load(self, path: str): <TAB> ds = DataSet() <TAB> with open(path, ""r"", encoding=""utf-8"") as f: <TAB> <TAB> for line in f: <TAB> <TAB> <TAB> line = line.strip() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> parts = line.split(""\t"") <TAB> <TAB> <TAB> <TAB> raw_words1 = parts[1] <TAB> <TAB> <TAB> <TAB> raw_words2 = parts[2] <TAB> <TAB> <TAB> <TAB> target = parts[0] <TAB> <TAB> <TAB> <TAB> if raw_words1 and raw_words2 and target: <TAB> <TAB> <TAB> <TAB> <TAB> ds.append( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> Instance( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raw_words1=raw_words1, raw_words2=raw_words2, target=target <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> return ds",true,if line :,if line :,0.53,0.0
"def avatar_delete(event_id, speaker_id): <TAB> if request.method == ""DELETE"": <TAB> <TAB> speaker = ( <TAB> <TAB> <TAB> DataGetter.get_speakers(event_id) <TAB> <TAB> <TAB> .filter_by(user_id=login.current_user.id, id=speaker_id) <TAB> <TAB> <TAB> .first() <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> speaker.photo = """" <TAB> <TAB> <TAB> speaker.small = """" <TAB> <TAB> <TAB> speaker.thumbnail = """" <TAB> <TAB> <TAB> speaker.icon = """" <TAB> <TAB> <TAB> save_to_db(speaker) <TAB> <TAB> <TAB> return jsonify({""status"": ""ok""}) <TAB> <TAB> else: <TAB> <TAB> <TAB> abort(403)",true,if speaker :,if speaker :,0.53,0.0
"def getline(filename, lineno, *args, **kwargs): <TAB> line = py2exe_getline(filename, lineno, *args, **kwargs) <TAB> if not line: <TAB> <TAB> try: <TAB> <TAB> <TAB> with open(filename, ""rb"") as f: <TAB> <TAB> <TAB> <TAB> for i, line in enumerate(f): <TAB> <TAB> <TAB> <TAB> <TAB> line = line.decode(""utf-8"") <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> line = """" <TAB> <TAB> except (IOError, OSError): <TAB> <TAB> <TAB> line = """" <TAB> return line",false,if lineno == i + 1 :,if i :,0.02,0.0
"def write(self, data): <TAB> if not isinstance(data, (bytes, bytearray, memoryview)): <TAB> <TAB> raise TypeError(""data argument must be byte-ish (%r)"", type(data)) <TAB> if not data: <TAB> <TAB> return <TAB> if self._conn_lost: <TAB> <TAB> if self._conn_lost >= constants.LOG_THRESHOLD_FOR_CONNLOST_WRITES: <TAB> <TAB> <TAB> logger.warning(""socket.send() raised exception."") <TAB> <TAB> self._conn_lost += 1 <TAB> <TAB> return <TAB> if not self._buffer: <TAB> <TAB> self._loop.add_writer(self._sock_fd, self._write_ready) <TAB> # Add it to the buffer. <TAB> self._buffer.extend(data) <TAB> self._maybe_pause_protocol()",true,if self . _conn_lost >= constants . LOG_THRESHOLD_FOR_CONNLOST_WRITES :,if self . _conn_lost >= constants . LOG_THRESHOLD_FOR_CONNLOST_WRITES :,0.75,0.0
"def _get_x_for_y(self, xValue, x, y): <TAB> # print(""searching ""+x+"" with the value ""+str(xValue)+"" and want to give back ""+y) <TAB> if not self.xmlMap: <TAB> <TAB> return 0 <TAB> x_value = str(xValue) <TAB> for anime in self.xmlMap.findall(""anime""): <TAB> <TAB> try: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return int(anime.get(y, 0)) <TAB> <TAB> except ValueError as e: <TAB> <TAB> <TAB> continue <TAB> return 0",false,"if anime . get ( x , False ) == x_value :",if x_value in anime :,0.01,0.0
"def _RewriteModinfo( <TAB> self, <TAB> modinfo, <TAB> obj_kernel_version, <TAB> this_kernel_version, <TAB> info_strings=None, <TAB> to_remove=None, ): <TAB> new_modinfo = """" <TAB> for line in modinfo.split(""\x00""): <TAB> <TAB> if not line: <TAB> <TAB> <TAB> continue <TAB> <TAB> if to_remove and line.split(""="")[0] == to_remove: <TAB> <TAB> <TAB> continue <TAB> <TAB> if info_strings is not None: <TAB> <TAB> <TAB> info_strings.add(line.split(""="")[0]) <TAB> <TAB> if line.startswith(""vermagic""): <TAB> <TAB> <TAB> line = line.replace(obj_kernel_version, this_kernel_version) <TAB> <TAB> new_modinfo += line + ""\x00"" <TAB> return new_modinfo",false,"if line . startswith ( ""vermagic"" ) :","if to_remove and line . split ( ""="" ) [ 0 ] == to_remove :",0.15,0.0
"def _score(self, X, y): <TAB> for col in self.cols: <TAB> <TAB> # Score the column <TAB> <TAB> X[col] = X[col].map(self.mapping[col]) <TAB> <TAB> # Randomization is meaningful only for training data -> we do it only if y is present <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> random_state_generator = check_random_state(self.random_state) <TAB> <TAB> <TAB> X[col] = X[col] * random_state_generator.normal( <TAB> <TAB> <TAB> <TAB> 1.0, self.sigma, X[col].shape[0] <TAB> <TAB> <TAB> ) <TAB> return X",false,if self . randomized and y is not None :,if y is not None :,0.3,0.0
"def onMouseWheel(self, event): <TAB> if self.selectedHuman.isVisible(): <TAB> <TAB> zoomOut = event.wheelDelta > 0 <TAB> <TAB> if self.getSetting(""invertMouseWheel""): <TAB> <TAB> <TAB> zoomOut = not zoomOut <TAB> <TAB> if event.x is not None: <TAB> <TAB> <TAB> self.modelCamera.mousePickHumanCenter(event.x, event.y) <TAB> <TAB> if zoomOut: <TAB> <TAB> <TAB> self.zoomOut() <TAB> <TAB> else: <TAB> <TAB> <TAB> self.zoomIn()",true,"if self . getSetting ( ""invertMouseWheel"" ) :","if self . getSetting ( ""invertMouseWheel"" ) :",0.75,0.0
"def prehook(self, emu, op, eip): <TAB> if op in self.badops: <TAB> <TAB> emu.stopEmu() <TAB> <TAB> raise v_exc.BadOpBytes(op.va) <TAB> if op.mnem in STOS: <TAB> <TAB> if self.arch == ""i386"": <TAB> <TAB> <TAB> reg = emu.getRegister(envi.archs.i386.REG_EDI) <TAB> <TAB> elif self.arch == ""amd64"": <TAB> <TAB> <TAB> reg = emu.getRegister(envi.archs.amd64.REG_RDI) <TAB> <TAB> if self.vw.isValidPointer(reg) and self.vw.getLocation(reg) is None: <TAB> <TAB> <TAB> self.vw.makePointer(reg, follow=True)",false,"elif self . arch == ""amd64"" :",if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None :,0.15,0.0
"def callback(actions, form, tablename=None): <TAB> if actions: <TAB> <TAB> if tablename and isinstance(actions, dict): <TAB> <TAB> <TAB> actions = actions.get(tablename, []) <TAB> <TAB> if not isinstance(actions, (list, tuple)): <TAB> <TAB> <TAB> actions = [actions] <TAB> <TAB> [action(form) for action in actions]",false,"if not isinstance ( actions , ( list , tuple ) ) :","if tablename and isinstance ( actions , dict ) :",0.21,0.0
"def FetchFn(bigger_than_3_only=None, less_than_7_only=None, even_only=None): <TAB> result = [] <TAB> for i in range(10): <TAB> <TAB> # This line introduces a bug. <TAB> <TAB> if bigger_than_3_only and less_than_7_only and i == 4: <TAB> <TAB> <TAB> continue <TAB> <TAB> if bigger_than_3_only and i <= 3: <TAB> <TAB> <TAB> continue <TAB> <TAB> if less_than_7_only and i >= 7: <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> result.append(i) <TAB> return result",true,if even_only and i % 2 != 0 :,if even_only and i % 2 != 0 :,0.75,0.0
"def set_trial_values(self, trial_id: int, values: Sequence[float]) -> None: <TAB> with self._lock: <TAB> <TAB> cached_trial = self._get_cached_trial(trial_id) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._check_trial_is_updatable(cached_trial) <TAB> <TAB> <TAB> updates = self._get_updates(trial_id) <TAB> <TAB> <TAB> cached_trial.values = values <TAB> <TAB> <TAB> updates.values = values <TAB> <TAB> <TAB> return <TAB> self._backend._update_trial(trial_id, values=values)",false,if cached_trial is not None :,if cached_trial :,0.05,0.0
"def _get_label_format(self, workunit): <TAB> for label, label_format in self.LABEL_FORMATTING.items(): <TAB> <TAB> if workunit.has_label(label): <TAB> <TAB> <TAB> return label_format <TAB> # Recursively look for a setting to suppress child label formatting. <TAB> if workunit.parent: <TAB> <TAB> label_format = self._get_label_format(workunit.parent) <TAB> <TAB> if label_format == LabelFormat.CHILD_DOT: <TAB> <TAB> <TAB> return LabelFormat.DOT <TAB> <TAB> if label_format == LabelFormat.CHILD_SUPPRESS: <TAB> <TAB> <TAB> return LabelFormat.SUPPRESS <TAB> return LabelFormat.FULL",false,if label_format == LabelFormat . CHILD_SUPPRESS :,if workunit . has_label ( label ) :,0.02,0.0
"def open_session(self, app, request): <TAB> sid = request.cookies.get(app.session_cookie_name) <TAB> if sid: <TAB> <TAB> stored_session = self.cls.objects(sid=sid).first() <TAB> <TAB> if stored_session: <TAB> <TAB> <TAB> expiration = stored_session.expiration <TAB> <TAB> <TAB> if not expiration.tzinfo: <TAB> <TAB> <TAB> <TAB> expiration = expiration.replace(tzinfo=utc) <TAB> <TAB> <TAB> if expiration > datetime.datetime.utcnow().replace(tzinfo=utc): <TAB> <TAB> <TAB> <TAB> return MongoEngineSession( <TAB> <TAB> <TAB> <TAB> <TAB> initial=stored_session.data, sid=stored_session.sid <TAB> <TAB> <TAB> <TAB> ) <TAB> return MongoEngineSession(sid=str(uuid.uuid4()))",true,if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) :,if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) :,1.0,0.0
"def _manage_torrent_cache(self): <TAB> """"""Carry tracker/peer/file lists over to new torrent list"""""" <TAB> for torrent in self._torrent_cache: <TAB> <TAB> new_torrent = rtorrentlib.common.find_torrent(torrent.info_hash, self.torrents) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> new_torrent.files = torrent.files <TAB> <TAB> <TAB> new_torrent.peers = torrent.peers <TAB> <TAB> <TAB> new_torrent.trackers = torrent.trackers <TAB> self._torrent_cache = self.torrents",false,if new_torrent is not None :,if new_torrent :,0.05,0.0
"def _clean_regions(items, region): <TAB> """"""Intersect region with target file if it exists"""""" <TAB> variant_regions = bedutils.population_variant_regions(items, merged=True) <TAB> with utils.tmpfile() as tx_out_file: <TAB> <TAB> target = subset_variant_regions(variant_regions, region, tx_out_file, items) <TAB> <TAB> if target: <TAB> <TAB> <TAB> if isinstance(target, six.string_types) and os.path.isfile(target): <TAB> <TAB> <TAB> <TAB> target = _load_regions(target) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> target = [target] <TAB> <TAB> <TAB> return target",true,"if isinstance ( target , six . string_types ) and os . path . isfile ( target ) :","if isinstance ( target , six . string_types ) and os . path . isfile ( target ) :",1.0,0.0
def _get_stdout(self): <TAB> while True: <TAB> <TAB> BUFFER_SIZE = 1000 <TAB> <TAB> stdout_buffer = self.kernel.process.GetSTDOUT(BUFFER_SIZE) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> yield stdout_buffer,false,if len ( stdout_buffer ) == 0 :,if not stdout_buffer :,0.02,0.0
"def do_query(data, q): <TAB> ret = [] <TAB> if not q: <TAB> <TAB> return ret <TAB> qkey = q[0] <TAB> for key, value in iterate(data): <TAB> <TAB> if len(q) == 1: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> ret.append(value) <TAB> <TAB> <TAB> elif is_iterable(value): <TAB> <TAB> <TAB> <TAB> ret.extend(do_query(value, q)) <TAB> <TAB> else: <TAB> <TAB> <TAB> if not is_iterable(value): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if key == qkey: <TAB> <TAB> <TAB> <TAB> ret.extend(do_query(value, q[1:])) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> ret.extend(do_query(value, q)) <TAB> return ret",true,if key == qkey :,if key == qkey :,0.75,0.0
"def test_expect_setecho_off(self): <TAB> """"""This tests that echo may be toggled off."""""" <TAB> p = pexpect.spawn(""cat"", echo=True, timeout=5) <TAB> try: <TAB> <TAB> self._expect_echo_toggle(p) <TAB> except IOError: <TAB> <TAB> if sys.platform.lower().startswith(""sunos""): <TAB> <TAB> <TAB> if hasattr(unittest, ""SkipTest""): <TAB> <TAB> <TAB> <TAB> raise unittest.SkipTest(""Not supported on this platform."") <TAB> <TAB> <TAB> return ""skip"" <TAB> <TAB> raise",true,"if sys . platform . lower ( ) . startswith ( ""sunos"" ) :","if sys . platform . lower ( ) . startswith ( ""sunos"" ) :",0.75,0.0
"def _resolve_relative_config(dir, config): <TAB> # Some code shared between Notebook and NotebookInfo <TAB> # Resolve icon, can be relative <TAB> icon = config.get(""icon"") <TAB> if icon: <TAB> <TAB> if zim.fs.isabs(icon) or not dir: <TAB> <TAB> <TAB> icon = File(icon) <TAB> <TAB> else: <TAB> <TAB> <TAB> icon = dir.resolve_file(icon) <TAB> # Resolve document_root, can also be relative <TAB> document_root = config.get(""document_root"") <TAB> if document_root: <TAB> <TAB> if zim.fs.isabs(document_root) or not dir: <TAB> <TAB> <TAB> document_root = Dir(document_root) <TAB> <TAB> else: <TAB> <TAB> <TAB> document_root = dir.resolve_dir(document_root) <TAB> return icon, document_root",false,if zim . fs . isabs ( icon ) or not dir :,if zim . fs . isabs ( document_root ) or not dir :,0.63,0.0
"def _providers(self, descriptor): <TAB> res = [] <TAB> for _md in self.metadata.values(): <TAB> <TAB> for ent_id, ent_desc in _md.items(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if ent_id in res: <TAB> <TAB> <TAB> <TAB> <TAB> # print(""duplicated entity_id: %s"" % res) <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> res.append(ent_id) <TAB> return res",false,if descriptor in ent_desc :,if ent_desc == descriptor :,0.04,0.0
"def poll_ms(self, timeout=-1): <TAB> s = bytearray(self.evbuf) <TAB> if timeout >= 0: <TAB> <TAB> deadline = utime.ticks_add(utime.ticks_ms(), timeout) <TAB> while True: <TAB> <TAB> n = epoll_wait(self.epfd, s, 1, timeout) <TAB> <TAB> if not os.check_error(n): <TAB> <TAB> <TAB> break <TAB> <TAB> if timeout >= 0: <TAB> <TAB> <TAB> timeout = utime.ticks_diff(deadline, utime.ticks_ms()) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> n = 0 <TAB> <TAB> <TAB> <TAB> break <TAB> res = [] <TAB> if n > 0: <TAB> <TAB> vals = struct.unpack(epoll_event, s) <TAB> <TAB> res.append((vals[1], vals[0])) <TAB> return res",false,if timeout < 0 :,if timeout == 0 :,0.33,0.0
"def banned(): <TAB> if request.endpoint == ""views.themes"": <TAB> <TAB> return <TAB> if authed(): <TAB> <TAB> user = get_current_user_attrs() <TAB> <TAB> team = get_current_team_attrs() <TAB> <TAB> if user and user.banned: <TAB> <TAB> <TAB> return ( <TAB> <TAB> <TAB> <TAB> render_template( <TAB> <TAB> <TAB> <TAB> <TAB> ""errors/403.html"", error=""You have been banned from this CTF"" <TAB> <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> <TAB> 403, <TAB> <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ( <TAB> <TAB> <TAB> <TAB> render_template( <TAB> <TAB> <TAB> <TAB> <TAB> ""errors/403.html"", <TAB> <TAB> <TAB> <TAB> <TAB> error=""Your team has been banned from this CTF"", <TAB> <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> <TAB> 403, <TAB> <TAB> <TAB> )",true,if team and team . banned :,if team and team . banned :,0.75,0.0
"def _update_read(self): <TAB> """"""Update state when there is read event"""""" <TAB> try: <TAB> <TAB> msg = bytes(self._sock.recv(4096)) <TAB> <TAB> if msg: <TAB> <TAB> <TAB> self.on_message(msg) <TAB> <TAB> <TAB> return True <TAB> <TAB> # normal close, remote is closed <TAB> <TAB> self.close() <TAB> except socket.error as err: <TAB> <TAB> if err.args[0] in (errno.EAGAIN, errno.EWOULDBLOCK): <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> self.on_error(err) <TAB> return False",true,"if err . args [ 0 ] in ( errno . EAGAIN , errno . EWOULDBLOCK ) :","if err . args [ 0 ] in ( errno . EAGAIN , errno . EWOULDBLOCK ) :",1.0,0.0
"def update_topic_attr_as_not(modeladmin, request, queryset, attr): <TAB> for topic in queryset: <TAB> <TAB> if attr == ""sticky"": <TAB> <TAB> <TAB> topic.sticky = not topic.sticky <TAB> <TAB> elif attr == ""closed"": <TAB> <TAB> <TAB> topic.closed = not topic.closed <TAB> <TAB> elif attr == ""hidden"": <TAB> <TAB> <TAB> topic.hidden = not topic.hidden <TAB> <TAB> topic.save()",false,"elif attr == ""hidden"" :","elif attr == ""closed"" :",0.64,0.0
"def Startprobe(self, q): <TAB> while not self.finished: <TAB> <TAB> try: <TAB> <TAB> <TAB> sniff(iface=self.interface, count=10, prn=lambda x: q.put(x)) <TAB> <TAB> except: <TAB> <TAB> <TAB> pass <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break",true,if self . finished :,if self . finished :,0.75,0.0
"def _maybe_female(self, path_elements, female, strict): <TAB> if female: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> elements = path_elements + [""female""] <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> return self._get_file(elements, "".png"", strict=strict) <TAB> <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> <TAB> if strict: <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> elif strict: <TAB> <TAB> <TAB> raise ValueError(""Pokemon %s has no gender differences"" % self.species_id) <TAB> return self._get_file(path_elements, "".png"", strict=strict)",false,if self . has_gender_differences :,if self . species_id in path_elements :,0.2,0.0
"def change_args_to_dict(string): <TAB> if string is None: <TAB> <TAB> return None <TAB> ans = [] <TAB> strings = string.split(""\n"") <TAB> ind = 1 <TAB> start = 0 <TAB> while ind <= len(strings): <TAB> <TAB> if ind < len(strings) and strings[ind].startswith("" ""): <TAB> <TAB> <TAB> ind += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> if start < ind: <TAB> <TAB> <TAB> <TAB> ans.append(""\n"".join(strings[start:ind])) <TAB> <TAB> <TAB> start = ind <TAB> <TAB> <TAB> ind += 1 <TAB> d = {} <TAB> for line in ans: <TAB> <TAB> if "":"" in line and len(line) > 0: <TAB> <TAB> <TAB> lines = line.split("":"") <TAB> <TAB> <TAB> d[lines[0]] = lines[1].strip() <TAB> return d",true,"if ind < len ( strings ) and strings [ ind ] . startswith ( "" "" ) :","if ind < len ( strings ) and strings [ ind ] . startswith ( "" "" ) :",1.0,0.0
"def _send_with_auth(self, req_kwargs, desired_auth, rsession): <TAB> if desired_auth.oauth: <TAB> <TAB> if self._oauth_creds.access_token_expired: <TAB> <TAB> <TAB> self._oauth_creds.refresh(httplib2.Http()) <TAB> <TAB> req_kwargs[""headers""] = req_kwargs.get(""headers"", {}) <TAB> <TAB> req_kwargs[""headers""][""Authorization""] = ( <TAB> <TAB> <TAB> ""Bearer "" + self._oauth_creds.access_token <TAB> <TAB> ) <TAB> return rsession.request(**req_kwargs)",true,if self . _oauth_creds . access_token_expired :,if self . _oauth_creds . access_token_expired :,0.75,0.0
"def parse_search_response(json_data): <TAB> """"""Construct response for any input"""""" <TAB> if json_data is None: <TAB> <TAB> return {""error"": ""Error parsing empty search engine response""} <TAB> try: <TAB> <TAB> return json.loads(json_data) <TAB> except json.JSONDecodeError: <TAB> <TAB> logger.exception(""Error parsing search engine response"") <TAB> <TAB> m = re_pre.search(json_data) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return {""error"": ""Error parsing search engine response""} <TAB> <TAB> error = web.htmlunquote(m.group(1)) <TAB> <TAB> solr_error = ""org.apache.lucene.queryParser.ParseException: "" <TAB> <TAB> if error.startswith(solr_error): <TAB> <TAB> <TAB> error = error[len(solr_error) :] <TAB> <TAB> return {""error"": error}",false,if m is None :,if not m :,0.04,0.0
"def wrapper(*args, **kws): <TAB> missing = [] <TAB> saved = getattr(warnings, ""__warningregistry__"", missing).copy() <TAB> try: <TAB> <TAB> return func(*args, **kws) <TAB> finally: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> del warnings.__warningregistry__ <TAB> <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> warnings.__warningregistry__ = saved",true,if saved is missing :,if saved is missing :,0.75,0.0
"def parse_expression(self): <TAB> """"""Return string containing command to run."""""" <TAB> expression_el = self.root.find(""expression"") <TAB> if expression_el is not None: <TAB> <TAB> expression_type = expression_el.get(""type"") <TAB> <TAB> if expression_type != ""ecma5.1"": <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> ""Unknown expression type [%s] encountered"" % expression_type <TAB> <TAB> <TAB> ) <TAB> <TAB> return expression_el.text <TAB> return None",true,"if expression_type != ""ecma5.1"" :","if expression_type != ""ecma5.1"" :",0.75,0.0
"def test_geocode(): <TAB> # look for tweets from New York ; the search radius is larger than NYC <TAB> # so hopefully we'll find one from New York in the first 500? <TAB> count = 0 <TAB> found = False <TAB> for tweet in T.search(None, geocode=""40.7484,-73.9857,1mi""): <TAB> <TAB> if (tweet[""place""] or {}).get(""name"") == ""Manhattan"": <TAB> <TAB> <TAB> found = True <TAB> <TAB> <TAB> break <TAB> <TAB> if count > 500: <TAB> <TAB> <TAB> break <TAB> <TAB> count += 1 <TAB> assert found",true,"if ( tweet [ ""place"" ] or { } ) . get ( ""name"" ) == ""Manhattan"" :","if ( tweet [ ""place"" ] or { } ) . get ( ""name"" ) == ""Manhattan"" :",0.75,0.0
"def __init__(self, name: Optional[str] = None, order: int = 0): <TAB> if name is None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> name = ""std_dev"" <TAB> <TAB> elif order == 1: <TAB> <TAB> <TAB> name = ""sample_std_dev"" <TAB> <TAB> else: <TAB> <TAB> <TAB> name = f""std_dev{order})"" <TAB> super().__init__(name=name, order=order) <TAB> self.order = order",true,if order == 0 :,if order == 0 :,0.75,0.0
"def __cmp__(self, other): <TAB> if isinstance(other, date) or isinstance(other, datetime): <TAB> <TAB> a = self._d.getTime() <TAB> <TAB> b = other._d.getTime() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return -1 <TAB> <TAB> elif a == b: <TAB> <TAB> <TAB> return 0 <TAB> else: <TAB> <TAB> raise TypeError(""expected date or datetime object"") <TAB> return 1",false,if a < b :,if a > b :,0.08,0.0
"def run(self): <TAB> tid = self.ident <TAB> try: <TAB> <TAB> with self._lock: <TAB> <TAB> <TAB> _GUIS[tid] = self <TAB> <TAB> <TAB> self._state(True) <TAB> <TAB> self.new_mail_notifications(summarize=True) <TAB> <TAB> loop_count = 0 <TAB> <TAB> while self._sock: <TAB> <TAB> <TAB> loop_count += 1 <TAB> <TAB> <TAB> self._select_sleep(1)  # FIXME: Lengthen this when possible <TAB> <TAB> <TAB> self.change_state() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> # FIXME: This involves a fair number of set operations, <TAB> <TAB> <TAB> <TAB> # <TAB> <TAB>should only do this after new mail has arrived. <TAB> <TAB> <TAB> <TAB> self.new_mail_notifications() <TAB> finally: <TAB> <TAB> del _GUIS[tid]",false,if loop_count % 5 == 0 :,if loop_count == 0 :,0.17,0.0
"def __cache_dimension_masks(self, *args): <TAB> # cache masks for each feature map we'll need <TAB> if len(self.masks) == 0: <TAB> <TAB> for m1 in args: <TAB> <TAB> <TAB> batch_size, emb_dim, h, w = m1.size() <TAB> <TAB> <TAB> # make mask <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> mask = self.feat_size_w_mask(h, m1) <TAB> <TAB> <TAB> <TAB> self.masks[h] = mask",false,if h not in self . masks :,if batch_size == 0 and emb_dim == 0 :,0.02,0.0
"def __call__(self, *flattened_representation): <TAB> unflattened_representation = [] <TAB> for index, subtree in self.children: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> unflattened_representation.append(flattened_representation[index]) <TAB> <TAB> else: <TAB> <TAB> <TAB> sub_representation = flattened_representation[index] <TAB> <TAB> <TAB> unflattened_representation.append(subtree(*sub_representation)) <TAB> return self._cls(*unflattened_representation, **self._kwargs)",false,if subtree is None :,if index in flattened_representation :,0.28,0.0
"def click_outside(event): <TAB> if event not in d: <TAB> <TAB> x, y, z = self.blockFaceUnderCursor[0] <TAB> <TAB> if y == 0: <TAB> <TAB> <TAB> y = 64 <TAB> <TAB> y += 3 <TAB> <TAB> gotoPanel.X, gotoPanel.Y, gotoPanel.Z = x, y, z <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> d.dismiss(""Goto"")",false,if event . num_clicks == 2 :,if x == 0 and y == 64 :,0.02,0.0
"def get_mapped_input_keysequences(self, mode=""global"", prefix=u""""): <TAB> # get all bindings in this mode <TAB> globalmaps, modemaps = self.get_keybindings(mode) <TAB> candidates = list(globalmaps.keys()) + list(modemaps.keys()) <TAB> if prefix is not None: <TAB> <TAB> prefixes = prefix + "" "" <TAB> <TAB> cand = [c for c in candidates if c.startswith(prefixes)] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> candidates = cand + [prefix] <TAB> <TAB> else: <TAB> <TAB> <TAB> candidates = cand <TAB> return candidates",false,if prefix in candidates :,if prefix :,0.07,0.0
"def _set_length(self, length): <TAB> with self._cond: <TAB> <TAB> self._length = length <TAB> <TAB> if self._index == self._length: <TAB> <TAB> <TAB> self._ready = True <TAB> <TAB> <TAB> self._cond.notify() <TAB> <TAB> <TAB> del self._cache[self._job]",true,if self . _index == self . _length :,if self . _index == self . _length :,1.0,0.0
"def _pct_encoded_replace_unreserved(mo): <TAB> try: <TAB> <TAB> i = int(mo.group(1), 16) <TAB> <TAB> if _unreserved[i]: <TAB> <TAB> <TAB> return chr(i) <TAB> <TAB> else: <TAB> <TAB> <TAB> return mo.group().upper() <TAB> except ValueError: <TAB> <TAB> return mo.group()",true,if _unreserved [ i ] :,if _unreserved [ i ] :,0.75,0.0
"def is_open(self): <TAB> if self.signup_code: <TAB> <TAB> return True <TAB> else: <TAB> <TAB> if self.signup_code_present: <TAB> <TAB> <TAB> if self.messages.get(""invalid_signup_code""): <TAB> <TAB> <TAB> <TAB> messages.add_message( <TAB> <TAB> <TAB> <TAB> <TAB> self.request, <TAB> <TAB> <TAB> <TAB> <TAB> self.messages[""invalid_signup_code""][""level""], <TAB> <TAB> <TAB> <TAB> <TAB> self.messages[""invalid_signup_code""][""text""].format( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> **{ <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""code"": self.get_code(), <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> <TAB> ) <TAB> return settings.ACCOUNT_OPEN_SIGNUP",true,"if self . messages . get ( ""invalid_signup_code"" ) :","if self . messages . get ( ""invalid_signup_code"" ) :",0.75,0.0
"def _get_field_value(self, test, key, match): <TAB> if test.ver == ofproto_v1_0.OFP_VERSION: <TAB> <TAB> members = inspect.getmembers(match) <TAB> <TAB> for member in members: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> field_value = member[1] <TAB> <TAB> <TAB> elif member[0] == ""wildcards"": <TAB> <TAB> <TAB> <TAB> wildcards = member[1] <TAB> <TAB> if key == ""nw_src"": <TAB> <TAB> <TAB> field_value = test.nw_src_to_str(wildcards, field_value) <TAB> <TAB> elif key == ""nw_dst"": <TAB> <TAB> <TAB> field_value = test.nw_dst_to_str(wildcards, field_value) <TAB> else: <TAB> <TAB> field_value = match[key] <TAB> return field_value",false,if member [ 0 ] == key :,if len ( member ) == 2 :,0.02,0.0
"def move_sender_strings_to_sender_model(apps, schema_editor): <TAB> sender_model = apps.get_model(""documents"", ""Sender"") <TAB> document_model = apps.get_model(""documents"", ""Document"") <TAB> # Create the sender and log the relationship with the document <TAB> for document in document_model.objects.all(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> DOCUMENT_SENDER_MAP[document.pk], <TAB> <TAB> <TAB> <TAB> created, <TAB> <TAB> <TAB> ) = sender_model.objects.get_or_create( <TAB> <TAB> <TAB> <TAB> name=document.sender, defaults={""slug"": slugify(document.sender)} <TAB> <TAB> <TAB> )",false,if document . sender :,if document . sender in DOCUMENT_SENDER_MAP :,0.37,0.0
"def compute_output_shape(self, input_shape): <TAB> if None not in input_shape[1:]: <TAB> <TAB> if keras.backend.image_data_format() == ""channels_first"": <TAB> <TAB> <TAB> total = np.prod(input_shape[2:4]) * self.num_anchors <TAB> <TAB> else: <TAB> <TAB> <TAB> total = np.prod(input_shape[1:3]) * self.num_anchors <TAB> <TAB> return (input_shape[0], total, 4) <TAB> else: <TAB> <TAB> return (input_shape[0], None, 4)",true,"if keras . backend . image_data_format ( ) == ""channels_first"" :","if keras . backend . image_data_format ( ) == ""channels_first"" :",0.75,0.0
"def decompress(self, value): <TAB> if value: <TAB> <TAB> if type(value) == PhoneNumber: <TAB> <TAB> <TAB> if value.country_code and value.national_number: <TAB> <TAB> <TAB> <TAB> return [ <TAB> <TAB> <TAB> <TAB> <TAB> ""+%d"" % value.country_code, <TAB> <TAB> <TAB> <TAB> <TAB> national_significant_number(value), <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> else: <TAB> <TAB> <TAB> return value.split(""."") <TAB> return [None, """"]",true,if value . country_code and value . national_number :,if value . country_code and value . national_number :,0.75,0.0
"def ignore(self, other): <TAB> if isinstance(other, Suppress): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> super(ParseElementEnhance, self).ignore(other) <TAB> <TAB> <TAB> if self.expr is not None: <TAB> <TAB> <TAB> <TAB> self.expr.ignore(self.ignoreExprs[-1]) <TAB> else: <TAB> <TAB> super(ParseElementEnhance, self).ignore(other) <TAB> <TAB> if self.expr is not None: <TAB> <TAB> <TAB> self.expr.ignore(self.ignoreExprs[-1]) <TAB> return self",false,if other not in self . ignoreExprs :,if self . ignoreExprs :,0.19,0.0
"def mkdir(self, mode=0o777, parents=False, exist_ok=False): <TAB> if self._closed: <TAB> <TAB> self._raise_closed() <TAB> if not parents: <TAB> <TAB> try: <TAB> <TAB> <TAB> self._accessor.mkdir(self, mode) <TAB> <TAB> except FileExistsError: <TAB> <TAB> <TAB> if not exist_ok or not self.is_dir(): <TAB> <TAB> <TAB> <TAB> raise <TAB> else: <TAB> <TAB> try: <TAB> <TAB> <TAB> self._accessor.mkdir(self, mode) <TAB> <TAB> except FileExistsError: <TAB> <TAB> <TAB> if not exist_ok or not self.is_dir(): <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> except OSError as e: <TAB> <TAB> <TAB> if e.errno != ENOENT: <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> self.parent.mkdir(parents=True) <TAB> <TAB> <TAB> self._accessor.mkdir(self, mode)",true,if not exist_ok or not self . is_dir ( ) :,if not exist_ok or not self . is_dir ( ) :,0.75,0.0
"def _mark_lcs(mask, dirs, m, n): <TAB> while m != 0 and n != 0: <TAB> <TAB> if dirs[m, n] == ""|"": <TAB> <TAB> <TAB> m -= 1 <TAB> <TAB> <TAB> n -= 1 <TAB> <TAB> <TAB> mask[m] = 1 <TAB> <TAB> elif dirs[m, n] == ""^"": <TAB> <TAB> <TAB> m -= 1 <TAB> <TAB> elif dirs[m, n] == ""<"": <TAB> <TAB> <TAB> n -= 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> raise UnboundLocalError(""Illegal move"") <TAB> return mask",true,"elif dirs [ m , n ] == ""<"" :","elif dirs [ m , n ] == ""<"" :",0.75,0.0
"def clean(self, *args, **kwargs): <TAB> data = super().clean(*args, **kwargs) <TAB> if isinstance(data, File): <TAB> <TAB> filename = data.name <TAB> <TAB> ext = os.path.splitext(filename)[1] <TAB> <TAB> ext = ext.lower() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise forms.ValidationError(_(""Filetype not allowed!"")) <TAB> return data",false,if ext not in self . ext_whitelist :,if ext not in FILESYSTEM_EXTENSIONS :,0.32,0.0
"def get_doc_object(obj, what=None): <TAB> if what is None: <TAB> <TAB> if inspect.isclass(obj): <TAB> <TAB> <TAB> what = ""class"" <TAB> <TAB> elif inspect.ismodule(obj): <TAB> <TAB> <TAB> what = ""module"" <TAB> <TAB> elif callable(obj): <TAB> <TAB> <TAB> what = ""function"" <TAB> <TAB> else: <TAB> <TAB> <TAB> what = ""object"" <TAB> if what == ""class"": <TAB> <TAB> return SphinxClassDoc(obj, """", func_doc=SphinxFunctionDoc) <TAB> elif what in (""function"", ""method""): <TAB> <TAB> return SphinxFunctionDoc(obj, """") <TAB> else: <TAB> <TAB> return SphinxDocString(pydoc.getdoc(obj))",false,elif inspect . ismodule ( obj ) :,elif callable ( obj ) :,0.31,0.0
"def apply_pssm(val): <TAB> if val is not None: <TAB> <TAB> val_c = PSSM_VALUES.get(val, None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> assert isinstance( <TAB> <TAB> <TAB> <TAB> val, tuple(PSSM_VALUES.values()) <TAB> <TAB> <TAB> ), ""'store_as' should be one of: %r or an instance of %r not %r"" % ( <TAB> <TAB> <TAB> <TAB> tuple(PSSM_VALUES.keys()), <TAB> <TAB> <TAB> <TAB> tuple(PSSM_VALUES.values()), <TAB> <TAB> <TAB> <TAB> val, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return val <TAB> <TAB> return val_c()",true,if val_c is None :,if val_c is None :,0.75,0.0
"def read_postmaster_opts(self): <TAB> """"""returns the list of option names/values from postgres.opts, Empty dict if read failed or no file"""""" <TAB> result = {} <TAB> try: <TAB> <TAB> with open(os.path.join(self._postgresql.data_dir, ""postmaster.opts"")) as f: <TAB> <TAB> <TAB> data = f.read() <TAB> <TAB> <TAB> for opt in data.split('"" ""'): <TAB> <TAB> <TAB> <TAB> if ""="" in opt and opt.startswith(""--""): <TAB> <TAB> <TAB> <TAB> <TAB> name, val = opt.split(""="", 1) <TAB> <TAB> <TAB> <TAB> <TAB> result[name.strip(""-"")] = val.rstrip('""\n') <TAB> except IOError: <TAB> <TAB> logger.exception(""Error when reading postmaster.opts"") <TAB> return result",true,"if ""="" in opt and opt . startswith ( ""--"" ) :","if ""="" in opt and opt . startswith ( ""--"" ) :",1.0,0.0
"def detect(get_page): <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS: <TAB> <TAB> page, headers, code = get_page(get=vector) <TAB> <TAB> retval = ( <TAB> <TAB> <TAB> re.search(r""F5-TrafficShield"", headers.get(HTTP_HEADER.SERVER, """"), re.I) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB> retval |= ( <TAB> <TAB> <TAB> re.search(r""\AASINFO="", headers.get(HTTP_HEADER.SET_COOKIE, """"), re.I) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> return retval",true,if retval :,if retval :,0.53,0.0
"def on_task_start(self, task, config): <TAB> for item in config: <TAB> <TAB> for plugin_name, plugin_config in item.items(): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> thelist = plugin.get(plugin_name, self).get_list(plugin_config) <TAB> <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> <TAB> raise PluginError( <TAB> <TAB> <TAB> <TAB> <TAB> ""Plugin %s does not support list interface"" % plugin_name <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if thelist.immutable: <TAB> <TAB> <TAB> <TAB> raise plugin.PluginError(thelist.immutable)",true,if thelist . immutable :,if thelist . immutable :,0.75,0.0
"def nq(t): <TAB> p = t[0] if (t and t[0] in ""-+"") else """" <TAB> t = t[len(p) :] <TAB> if t.startswith(""tag:"") or t.startswith(""in:""): <TAB> <TAB> try: <TAB> <TAB> <TAB> raw_tag = session.config.get_tag(t.split("":"")[1]) <TAB> <TAB> <TAB> if raw_tag and raw_tag.hasattr(slug): <TAB> <TAB> <TAB> <TAB> t = ""in:%s"" % raw_tag.slug <TAB> <TAB> except (IndexError, KeyError, TypeError): <TAB> <TAB> <TAB> pass <TAB> return p + t",true,if raw_tag and raw_tag . hasattr ( slug ) :,if raw_tag and raw_tag . hasattr ( slug ) :,0.75,0.0
"def _recur_strip(s): <TAB> if is_str(s): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return "" "".join(s.strip().split()) <TAB> <TAB> else: <TAB> <TAB> <TAB> return "" "".join(s.strip().split()).replace(bos_token + "" "", """") <TAB> else: <TAB> <TAB> s_ = [_recur_strip(si) for si in s] <TAB> <TAB> return _maybe_list_to_array(s_, s)",true,"if bos_token == """" :","if bos_token == """" :",0.75,0.0
"def __delitem__(self, key): <TAB> ""Deleting tag[key] deletes all 'key' attributes for the tag."" <TAB> for item in self.attrs: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.attrs.remove(item) <TAB> <TAB> <TAB> # We don't break because bad HTML can define the same <TAB> <TAB> <TAB> # attribute multiple times. <TAB> <TAB> self._getAttrMap() <TAB> <TAB> if self.attrMap.has_key(key): <TAB> <TAB> <TAB> del self.attrMap[key]",false,if item [ 0 ] == key :,if item . key == key :,0.09,0.0
"def comment_import_help(init_file, out_file): <TAB> f_out = open(out_file, ""w"") <TAB> output = """" <TAB> updated = False <TAB> with open(init_file, ""r"") as f_in: <TAB> <TAB> for line in f_in: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> updated = True <TAB> <TAB> <TAB> <TAB> line = ""# "" + line <TAB> <TAB> <TAB> output += line <TAB> f_out.write(output) <TAB> f_out.close() <TAB> return updated",false,"if ""import"" in line and ""_help"" in line and not updated :",if line :,0.01,0.0
"def prepare_text(lines): <TAB> out = [] <TAB> for s in lines.split(""|""): <TAB> <TAB> s = s.strip() <TAB> <TAB> if s.startswith(""/""): <TAB> <TAB> <TAB> # line beginning with '/' is in italics <TAB> <TAB> <TAB> s = r""{\i1}%s{\i0}"" % s[1:].strip() <TAB> <TAB> out.append(s) <TAB> return ""\\N"".join(out)",true,"if s . startswith ( ""/"" ) :","if s . startswith ( ""/"" ) :",0.75,0.0
"def sqlctx(sc): <TAB> pytest.importorskip(""pyspark"") <TAB> from odo.backends.sparksql import HiveContext <TAB> try: <TAB> <TAB> yield HiveContext(sc) <TAB> finally: <TAB> <TAB> dbpath = ""metastore_db"" <TAB> <TAB> logpath = ""derby.log"" <TAB> <TAB> if os.path.exists(dbpath): <TAB> <TAB> <TAB> assert os.path.isdir(dbpath) <TAB> <TAB> <TAB> shutil.rmtree(dbpath) <TAB> <TAB> if os.path.exists(logpath): <TAB> <TAB> <TAB> assert os.path.isfile(logpath) <TAB> <TAB> <TAB> os.remove(logpath)",false,if os . path . exists ( dbpath ) :,if os . path . exists ( logpath ) :,0.6,0.0
"def _user2dict(self, uid): <TAB> usdict = None <TAB> if uid in self.users: <TAB> <TAB> usdict = self.users[uid] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> infos = self.users_info[uid] <TAB> <TAB> <TAB> for attr in infos: <TAB> <TAB> <TAB> <TAB> usdict[attr[""attr_type""]] = attr[""attr_data""] <TAB> <TAB> usdict[""uid""] = uid <TAB> return usdict",false,if uid in self . users_info :,if usdict is None :,0.11,0.0
"def _validate_options(self): <TAB> for option in self.options: <TAB> <TAB> # if value type is bool or int, then we know the options is set <TAB> <TAB> if not type(self.options[option]) in [bool, int]: <TAB> <TAB> <TAB> if self.options.required[option] is True and not self.options[option]: <TAB> <TAB> <TAB> <TAB> if option == Constants.PASSWORD_CLEAR: <TAB> <TAB> <TAB> <TAB> <TAB> option = ""password"".upper() <TAB> <TAB> <TAB> <TAB> raise FrameworkException( <TAB> <TAB> <TAB> <TAB> <TAB> ""Value required for the '%s' option."" % (option.upper()) <TAB> <TAB> <TAB> <TAB> ) <TAB> return",false,"if not type ( self . options [ option ] ) in [ bool , int ] :",if self . options . required [ option ] is True and not self . options [ option ] :,0.22,0.0
"def _copy_package_apps( <TAB> local_bin_dir: Path, app_paths: List[Path], suffix: str = """" ) -> None: <TAB> for src_unresolved in app_paths: <TAB> <TAB> src = src_unresolved.resolve() <TAB> <TAB> app = src.name <TAB> <TAB> dest = Path(local_bin_dir / add_suffix(app, suffix)) <TAB> <TAB> if not dest.parent.is_dir(): <TAB> <TAB> <TAB> mkdir(dest.parent) <TAB> <TAB> if dest.exists(): <TAB> <TAB> <TAB> logger.warning(f""{hazard}  Overwriting file {str(dest)} with {str(src)}"") <TAB> <TAB> <TAB> dest.unlink() <TAB> <TAB> if src.exists(): <TAB> <TAB> <TAB> shutil.copy(src, dest)",false,if not dest . parent . is_dir ( ) :,if src . exists ( ) :,0.06,0.0
"def truncate_seq_pair(tokens_a, tokens_b, max_length): <TAB> """"""Truncates a sequence pair in place to the maximum length."""""" <TAB> # This is a simple heuristic which will always truncate the longer sequence <TAB> # one token at a time. This makes more sense than truncating an equal percent <TAB> # of tokens from each, since if one sequence is very short then each token <TAB> # that's truncated likely contains more information than a longer sequence. <TAB> while True: <TAB> <TAB> total_length = len(tokens_a) + len(tokens_b) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> if len(tokens_a) > len(tokens_b): <TAB> <TAB> <TAB> tokens_a.pop() <TAB> <TAB> else: <TAB> <TAB> <TAB> tokens_b.pop()",true,if total_length <= max_length :,if total_length <= max_length :,0.75,0.0
"def add_channels(cls, voucher, add_channels): <TAB> for add_channel in add_channels: <TAB> <TAB> channel = add_channel[""channel""] <TAB> <TAB> defaults = {""currency"": channel.currency_code} <TAB> <TAB> if ""discount_value"" in add_channel.keys(): <TAB> <TAB> <TAB> defaults[""discount_value""] = add_channel.get(""discount_value"") <TAB> <TAB> if ""min_amount_spent"" in add_channel.keys(): <TAB> <TAB> <TAB> defaults[""min_spent_amount""] = add_channel.get(""min_amount_spent"", None) <TAB> <TAB> models.VoucherChannelListing.objects.update_or_create( <TAB> <TAB> <TAB> voucher=voucher, <TAB> <TAB> <TAB> channel=channel, <TAB> <TAB> <TAB> defaults=defaults, <TAB> <TAB> )",true,"if ""min_amount_spent"" in add_channel . keys ( ) :","if ""min_amount_spent"" in add_channel . keys ( ) :",0.75,0.0
"def services(self, id=None, name=None): <TAB> for service_dict in self.service_ls(id=id, name=name): <TAB> <TAB> service_id = service_dict[""ID""] <TAB> <TAB> service_name = service_dict[""NAME""] <TAB> <TAB> if not service_name.startswith(self._name_prefix): <TAB> <TAB> <TAB> continue <TAB> <TAB> task_list = self.service_ps(service_id) <TAB> <TAB> yield DockerService.from_cli(self, service_dict, task_list)",true,if not service_name . startswith ( self . _name_prefix ) :,if not service_name . startswith ( self . _name_prefix ) :,0.75,0.0
"def lll(dirname): <TAB> for name in os.listdir(dirname): <TAB> <TAB> if name not in (os.curdir, os.pardir): <TAB> <TAB> <TAB> full = os.path.join(dirname, name) <TAB> <TAB> <TAB> if os.path.islink(full): <TAB> <TAB> <TAB> <TAB> print(name, ""->"", os.readlink(full))",false,"if name not in ( os . curdir , os . pardir ) :",if os . path . islink ( full ) :,0.08,0.0
"def convertstore(self, mydict): <TAB> targetheader = self.mypofile.header() <TAB> targetheader.addnote(""extracted from web2py"", ""developer"") <TAB> for source_str in mydict.keys(): <TAB> <TAB> target_str = mydict[source_str] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # a convention with new (untranslated) web2py files <TAB> <TAB> <TAB> target_str = u"""" <TAB> <TAB> elif target_str.startswith(u""*** ""): <TAB> <TAB> <TAB> # an older convention <TAB> <TAB> <TAB> target_str = u"""" <TAB> <TAB> pounit = self.convertunit(source_str, target_str) <TAB> <TAB> self.mypofile.addunit(pounit) <TAB> return self.mypofile",false,if target_str == source_str :,"if target_str == u""*** "" :",0.13,0.0
"def __init__(self, **kwargs): <TAB> for k, v in kwargs.items(): <TAB> <TAB> setattr(self, k, v) <TAB> self.attempted_charsets = set() <TAB> request = cherrypy.serving.request <TAB> if request.handler is not None: <TAB> <TAB> # Replace request.handler with self <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> cherrypy.log(""Replacing request.handler"", ""TOOLS.ENCODE"") <TAB> <TAB> self.oldhandler = request.handler <TAB> <TAB> request.handler = self",false,if self . debug :,if request . handler . errno != cherrypy . ECODE :,0.11,0.0
"def _fastqc_data_section(self, section_name): <TAB> out = [] <TAB> in_section = False <TAB> data_file = os.path.join(self._dir, ""fastqc_data.txt"") <TAB> if os.path.exists(data_file): <TAB> <TAB> with open(data_file) as in_handle: <TAB> <TAB> <TAB> for line in in_handle: <TAB> <TAB> <TAB> <TAB> if line.startswith("">>%s"" % section_name): <TAB> <TAB> <TAB> <TAB> <TAB> in_section = True <TAB> <TAB> <TAB> <TAB> elif in_section: <TAB> <TAB> <TAB> <TAB> <TAB> if line.startswith("">>END""): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> <TAB> out.append(line.rstrip(""\r\n"")) <TAB> return out",false,elif in_section :,"if line . startswith ( "">END"" ) :",0.03,0.0
"def bit_length(n): <TAB> try: <TAB> <TAB> return n.bit_length() <TAB> except AttributeError: <TAB> <TAB> norm = deflate_long(n, False) <TAB> <TAB> hbyte = byte_ord(norm[0]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return 1 <TAB> <TAB> bitlen = len(norm) * 8 <TAB> <TAB> while not (hbyte & 0x80): <TAB> <TAB> <TAB> hbyte <<= 1 <TAB> <TAB> <TAB> bitlen -= 1 <TAB> <TAB> return bitlen",false,if hbyte == 0 :,if hbyte == 0x7F :,0.14,0.0
"def step(self, action): <TAB> """"""Repeat action, sum reward, and max over last observations."""""" <TAB> total_reward = 0.0 <TAB> done = None <TAB> for i in range(self._skip): <TAB> <TAB> obs, reward, done, info = self.env.step(action) <TAB> <TAB> if i == self._skip - 2: <TAB> <TAB> <TAB> self._obs_buffer[0] = obs <TAB> <TAB> if i == self._skip - 1: <TAB> <TAB> <TAB> self._obs_buffer[1] = obs <TAB> <TAB> total_reward += reward <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> # Note that the observation on the done=True frame <TAB> # doesn't matter <TAB> max_frame = self._obs_buffer.max(axis=0) <TAB> return max_frame, total_reward, done, info",true,if done :,if done :,0.53,0.0
"def _sample_translation(reference, max_len): <TAB> translation = reference[:] <TAB> while np.random.uniform() < 0.8 and 1 < len(translation) < max_len: <TAB> <TAB> trans_len = len(translation) <TAB> <TAB> ind = np.random.randint(trans_len) <TAB> <TAB> action = np.random.choice(actions) <TAB> <TAB> if action == ""deletion"": <TAB> <TAB> <TAB> del translation[ind] <TAB> <TAB> elif action == ""replacement"": <TAB> <TAB> <TAB> ind_rep = np.random.randint(trans_len) <TAB> <TAB> <TAB> translation[ind] = translation[ind_rep] <TAB> <TAB> else: <TAB> <TAB> <TAB> ind_insert = np.random.randint(trans_len) <TAB> <TAB> <TAB> translation.insert(ind, translation[ind_insert]) <TAB> return translation",false,"if action == ""deletion"" :","elif action == ""replacement"" :",0.06,0.0
"def group_by_sign(seq, slop=sin(pi / 18), key=lambda x: x): <TAB> sign = None <TAB> subseq = [] <TAB> for i in seq: <TAB> <TAB> ki = key(i) <TAB> <TAB> if sign is None: <TAB> <TAB> <TAB> subseq.append(i) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> sign = ki / abs(ki) <TAB> <TAB> else: <TAB> <TAB> <TAB> subseq.append(i) <TAB> <TAB> <TAB> if sign * ki < -slop: <TAB> <TAB> <TAB> <TAB> sign = ki / abs(ki) <TAB> <TAB> <TAB> <TAB> yield subseq <TAB> <TAB> <TAB> <TAB> subseq = [i] <TAB> if subseq: <TAB> <TAB> yield subseq",false,if ki != 0 :,if sign * ki > slop :,0.03,0.0
"def get_dirlist(_rootdir): <TAB> dirlist = [] <TAB> with os.scandir(_rootdir) as rit: <TAB> <TAB> for entry in rit: <TAB> <TAB> <TAB> if not entry.name.startswith(""."") and entry.is_dir(): <TAB> <TAB> <TAB> <TAB> dirlist.append(entry.path) <TAB> <TAB> <TAB> <TAB> dirlist += get_dirlist(entry.path) <TAB> return dirlist",true,"if not entry . name . startswith ( ""."" ) and entry . is_dir ( ) :","if not entry . name . startswith ( ""."" ) and entry . is_dir ( ) :",1.0,0.0
"def __init__( <TAB> self, <TAB> fixed: MQTTFixedHeader = None, <TAB> variable_header: PublishVariableHeader = None, <TAB> payload=None, ): <TAB> if fixed is None: <TAB> <TAB> header = MQTTFixedHeader(PUBLISH, 0x00) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise HBMQTTException( <TAB> <TAB> <TAB> <TAB> ""Invalid fixed packet type %s for PublishPacket init"" <TAB> <TAB> <TAB> <TAB> % fixed.packet_type <TAB> <TAB> <TAB> ) <TAB> <TAB> header = fixed <TAB> super().__init__(header) <TAB> self.variable_header = variable_header <TAB> self.payload = payload",true,if fixed . packet_type is not PUBLISH :,if fixed . packet_type is not PUBLISH :,0.75,0.0
"def get_files(d): <TAB> res = [] <TAB> for p in glob.glob(os.path.join(d, ""*"")): <TAB> <TAB> if not p: <TAB> <TAB> <TAB> continue <TAB> <TAB> (pth, fname) = os.path.split(p) <TAB> <TAB> if fname == ""output"": <TAB> <TAB> <TAB> continue <TAB> <TAB> if fname == ""PureMVC_Python_1_0"": <TAB> <TAB> <TAB> continue <TAB> <TAB> if fname[-4:] == "".pyc"":  # ehmm.. no. <TAB> <TAB> <TAB> continue <TAB> <TAB> if os.path.isdir(p): <TAB> <TAB> <TAB> get_dir(p) <TAB> <TAB> else: <TAB> <TAB> <TAB> res.append(p) <TAB> return res",false,"if fname == ""output"" :","if fname [ - 4 : ] == "".pyc"" :",0.05,0.0
"def reward(self): <TAB> """"""Returns a tuple of sum of raw and processed rewards."""""" <TAB> raw_rewards, processed_rewards = 0, 0 <TAB> for ts in self.time_steps: <TAB> <TAB> # NOTE: raw_reward and processed_reward are None for the first time-step. <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raw_rewards += ts.raw_reward <TAB> <TAB> if ts.processed_reward is not None: <TAB> <TAB> <TAB> processed_rewards += ts.processed_reward <TAB> return raw_rewards, processed_rewards",true,if ts . raw_reward is not None :,if ts . raw_reward is not None :,0.75,0.0
"def _process_file(self, content): <TAB> args = [] <TAB> for line in content.splitlines(): <TAB> <TAB> line = line.strip() <TAB> <TAB> if line.startswith(""-""): <TAB> <TAB> <TAB> args.extend(self._split_option(line)) <TAB> <TAB> elif line and not line.startswith(""#""): <TAB> <TAB> <TAB> args.append(line) <TAB> return args",false,"if line . startswith ( ""-"" ) :","elif line and not line . startswith ( ""#"" ) :",0.35,0.0
"def __on_change_button_clicked(self, widget=None): <TAB> """"""compute all primary objects and toggle the 'Change' attribute"""""" <TAB> self.change_status = not self.change_status <TAB> for prim_obj, tmp in self.xobjects: <TAB> <TAB> obj_change = self.top.get_object(""%s_change"" % prim_obj) <TAB> <TAB> if not obj_change.get_sensitive(): <TAB> <TAB> <TAB> continue <TAB> <TAB> self.change_entries[prim_obj].set_val(self.change_status) <TAB> <TAB> obj_change.set_active(self.change_status)",true,if not obj_change . get_sensitive ( ) :,if not obj_change . get_sensitive ( ) :,0.75,0.0
"def aiter_cogs(cls) -> AsyncIterator[Tuple[str, str]]: <TAB> yield ""Core"", ""0"" <TAB> for _dir in data_manager.cog_data_path().iterdir(): <TAB> <TAB> fpath = _dir / ""settings.json"" <TAB> <TAB> if not fpath.exists(): <TAB> <TAB> <TAB> continue <TAB> <TAB> with fpath.open() as f: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> data = json.load(f) <TAB> <TAB> <TAB> except json.JSONDecodeError: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not isinstance(data, dict): <TAB> <TAB> <TAB> continue <TAB> <TAB> cog_name = _dir.stem <TAB> <TAB> for cog_id, inner in data.items(): <TAB> <TAB> <TAB> if not isinstance(inner, dict): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield cog_name, cog_id",true,"if not isinstance ( data , dict ) :","if not isinstance ( data , dict ) :",0.75,0.0
"def _verifySubs(self): <TAB> for inst in self.subs: <TAB> <TAB> if not isinstance(inst, (_Block, _Instantiator, Cosimulation)): <TAB> <TAB> <TAB> raise BlockError(_error.ArgType % (self.name,)) <TAB> <TAB> if isinstance(inst, (_Block, _Instantiator)): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise BlockError(_error.InstanceError % (self.name, inst.callername))",false,if not inst . modctxt :,if inst . callername != self . name :,0.04,0.0
"def _is_xml(accepts): <TAB> if accepts.startswith(b""application/""): <TAB> <TAB> has_xml = accepts.find(b""xml"") <TAB> <TAB> if has_xml > 0: <TAB> <TAB> <TAB> semicolon = accepts.find(b"";"") <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",false,if semicolon < 0 or has_xml < semicolon :,if semicolon > 0 and semicolon < has_xml :,0.42,0.0
"def _accept_with(cls, orm, target): <TAB> if target is orm.mapper: <TAB> <TAB> return mapperlib.Mapper <TAB> elif isinstance(target, type): <TAB> <TAB> if issubclass(target, mapperlib.Mapper): <TAB> <TAB> <TAB> return target <TAB> <TAB> else: <TAB> <TAB> <TAB> mapper = _mapper_or_none(target) <TAB> <TAB> <TAB> if mapper is not None: <TAB> <TAB> <TAB> <TAB> return mapper <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return _MapperEventsHold(target) <TAB> else: <TAB> <TAB> return target",true,"if issubclass ( target , mapperlib . Mapper ) :","if issubclass ( target , mapperlib . Mapper ) :",0.75,0.0
"def _get_font_afm(self, prop): <TAB> key = hash(prop) <TAB> font = self.afmfontd.get(key) <TAB><IF-STMT> <TAB> <TAB> fname = findfont(prop, fontext=""afm"") <TAB> <TAB> font = self.afmfontd.get(fname) <TAB> <TAB> if font is None: <TAB> <TAB> <TAB> font = AFM(file(findfont(prop, fontext=""afm""))) <TAB> <TAB> <TAB> self.afmfontd[fname] = font <TAB> <TAB> self.afmfontd[key] = font <TAB> return font",true,if font is None :,if font is None :,0.75,0.0
"def __call__(self, groupby): <TAB> normalize_reduction_funcs(self, ndim=groupby.ndim) <TAB> df = groupby <TAB> while df.op.output_types[0] not in (OutputType.dataframe, OutputType.series): <TAB> <TAB> df = df.inputs[0] <TAB> if self.raw_func == ""size"": <TAB> <TAB> self.output_types = [OutputType.series] <TAB> else: <TAB> <TAB> self.output_types = ( <TAB> <TAB> <TAB> [OutputType.dataframe] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> else [OutputType.series] <TAB> <TAB> ) <TAB> if self.output_types[0] == OutputType.dataframe: <TAB> <TAB> return self._call_dataframe(groupby, df) <TAB> else: <TAB> <TAB> return self._call_series(groupby, df)",false,if groupby . op . output_types [ 0 ] == OutputType . dataframe_groupby,"if self . raw_func == ""size""",0.05,0.0
"def save(self): <TAB> if self.preferences.get(ENCRYPT_ON_DISK, False): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return self.storage.write( <TAB> <TAB> <TAB> <TAB> self.to_dict(encrypt_password=self.encryption_password) <TAB> <TAB> <TAB> ) <TAB> <TAB> elif not self.is_locked: <TAB> <TAB> <TAB> log.warning( <TAB> <TAB> <TAB> <TAB> ""Disk encryption requested but no password available for encryption. "" <TAB> <TAB> <TAB> <TAB> ""Resetting encryption preferences and saving wallet in an unencrypted state."" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self.preferences[ENCRYPT_ON_DISK] = False <TAB> return self.storage.write(self.to_dict())",false,if self . encryption_password is not None :,if self . encryption_password :,0.23,0.0
"def isValidDateString(config_param_name, value, valid_value): <TAB> try: <TAB> <TAB> if value == ""DD-MM-YYYY"": <TAB> <TAB> <TAB> return value <TAB> <TAB> day, month, year = value.split(""-"") <TAB> <TAB> if int(day) < 1 or int(day) > 31: <TAB> <TAB> <TAB> raise DateStringValueError(config_param_name, value) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise DateStringValueError(config_param_name, value) <TAB> <TAB> if int(year) < 1900 or int(year) > 2013: <TAB> <TAB> <TAB> raise DateStringValueError(config_param_name, value) <TAB> <TAB> return value <TAB> except Exception: <TAB> <TAB> raise DateStringValueError(config_param_name, value)",false,if int ( month ) < 1 or int ( month ) > 12 :,if month != 1 :,0.01,0.0
"def _capture(self, call_name, data=None, **kwargs): <TAB> if data is None: <TAB> <TAB> data = self.get_default_context() <TAB> else: <TAB> <TAB> default_context = self.get_default_context() <TAB> <TAB> if isinstance(data, dict): <TAB> <TAB> <TAB> default_context.update(data) <TAB> <TAB> else: <TAB> <TAB> <TAB> default_context[""extra""][""extra_data""] = data <TAB> <TAB> data = default_context <TAB> client = self.get_sentry_client() <TAB> return getattr(client, call_name)(data=data, **kwargs)",true,"if isinstance ( data , dict ) :","if isinstance ( data , dict ) :",0.75,0.0
"def check(input, expected_output=None, expected_ffi_error=False): <TAB> import _cffi_backend <TAB> ffi = _cffi_backend.FFI() <TAB> if not expected_ffi_error: <TAB> <TAB> ct = ffi.typeof(input) <TAB> <TAB> assert isinstance(ct, ffi.CType) <TAB> <TAB> assert ct.cname == (expected_output or input) <TAB> else: <TAB> <TAB> e = py.test.raises(ffi.error, ffi.typeof, input) <TAB> <TAB> if isinstance(expected_ffi_error, str): <TAB> <TAB> <TAB> assert str(e.value) == expected_ffi_error",true,"if isinstance ( expected_ffi_error , str ) :","if isinstance ( expected_ffi_error , str ) :",0.75,0.0
"def run(self): <TAB> """"""Process queries from task queue, stop if processor is None."""""" <TAB> while True: <TAB> <TAB> try: <TAB> <TAB> <TAB> processor, iprot, oprot, otrans, callback = self.queue.get() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> processor.process(iprot, oprot) <TAB> <TAB> <TAB> callback(True, otrans.getvalue()) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> logging.exception(""Exception while processing request"") <TAB> <TAB> <TAB> callback(False, """")",true,if processor is None :,if processor is None :,0.75,0.0
"def search(self, query): <TAB> query = query.strip().lower() <TAB> results = [] <TAB> for provider in SidebarItemProvider.all(self.context): <TAB> <TAB> for item in provider.provide(): <TAB> <TAB> <TAB> if ""url"" in item: <TAB> <TAB> <TAB> <TAB> search_source = ""$"".join( <TAB> <TAB> <TAB> <TAB> <TAB> [item.get(""id"", """"), item.get(""name"", """")] <TAB> <TAB> <TAB> <TAB> ).lower() <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> results.append( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""title"": item[""name""], <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""icon"": item[""icon""], <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""url"": item[""url""], <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> return results",false,if query in search_source :,if search_source in query :,0.29,0.0
"def handle(self) -> None: <TAB> """"""Handles a request ignoring dropped connections."""""" <TAB> try: <TAB> <TAB> BaseHTTPRequestHandler.handle(self) <TAB> except (ConnectionError, socket.timeout) as e: <TAB> <TAB> self.connection_dropped(e) <TAB> except Exception as e: <TAB> <TAB> if self.server.ssl_context is not None and is_ssl_error(e): <TAB> <TAB> <TAB> self.log_error(""SSL error occurred: %s"", e) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise <TAB> if self.server.shutdown_signal: <TAB> <TAB> self.initiate_shutdown()",true,if self . server . ssl_context is not None and is_ssl_error ( e ) :,if self . server . ssl_context is not None and is_ssl_error ( e ) :,0.75,0.0
"def cdn_url_handler(error, endpoint, kwargs): <TAB> if endpoint == ""cdn"": <TAB> <TAB> path = kwargs.pop(""path"") <TAB> <TAB> # cdn = app.config.get('cdn', 'http://cdn.staticfile.org/') <TAB> <TAB> # cdn = app.config.get('cdn', '//cdnjs.cloudflare.com/ajax/libs/') <TAB> <TAB> cdn = app.config.get(""cdn"", ""//cdnjscn.b0.upaiyun.com/libs/"") <TAB> <TAB> return urljoin(cdn, path) <TAB> else: <TAB> <TAB> exc_type, exc_value, tb = sys.exc_info() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> reraise(exc_type, exc_value, tb) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise error",false,if exc_value is error :,if exc_type :,0.04,0.0
"def pairs(self): <TAB> for path in os.listdir(""src""): <TAB> <TAB> if path == "".svn"": <TAB> <TAB> <TAB> continue <TAB> <TAB> dep = join(""src"", path) <TAB> <TAB> if isdir(dep): <TAB> <TAB> <TAB> continue <TAB> <TAB> yield dep, join(build_dir, path)",true,if isdir ( dep ) :,if isdir ( dep ) :,0.75,0.0
"def get_condition(self): <TAB> """"""Return the condition element's name."""""" <TAB> for child in self.xml: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> cond = child.tag.split(""}"", 1)[-1] <TAB> <TAB> <TAB> if cond in self.conditions: <TAB> <TAB> <TAB> <TAB> return cond <TAB> return ""not-authorized""",false,"if ""{%s}"" % self . namespace in child . tag :","if ""{%s}"" % self . condition_ns in child . tag :",0.6,0.0
"def end(self, tag): <TAB> # call the appropriate end tag handler <TAB> try: <TAB> <TAB> f = self.dispatch[tag] <TAB> except KeyError: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return  # unknown tag ? <TAB> <TAB> try: <TAB> <TAB> <TAB> f = self.dispatch[tag.split("":"")[-1]] <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> return  # unknown tag ? <TAB> return f(self, """".join(self._data))",true,"if "":"" not in tag :","if "":"" not in tag :",0.75,0.0
"def checkIfSessionCodeExists(self, sessionCode): <TAB> if self.emrtFile: <TAB> <TAB> sessionsForExperiment = ( <TAB> <TAB> <TAB> self.emrtFile.root.data_collection.session_meta_data.where( <TAB> <TAB> <TAB> <TAB> ""experiment_id == %d"" % (self.active_experiment_id,) <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> sessionCodeMatch = [ <TAB> <TAB> <TAB> sess for sess in sessionsForExperiment if sess[""code""] == sessionCode <TAB> <TAB> ] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> return False",false,if len ( sessionCodeMatch ) > 0 :,if sessionCodeMatch :,0.02,0.0
"def save_bytearray(self, obj): <TAB> if self.proto < 5: <TAB> <TAB><IF-STMT>  # bytearray is empty <TAB> <TAB> <TAB> self.save_reduce(bytearray, (), obj=obj) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.save_reduce(bytearray, (bytes(obj),), obj=obj) <TAB> <TAB> return <TAB> n = len(obj) <TAB> if n >= self.framer._FRAME_SIZE_TARGET: <TAB> <TAB> self._write_large_bytes(BYTEARRAY8 + pack(""<Q"", n), obj) <TAB> else: <TAB> <TAB> self.write(BYTEARRAY8 + pack(""<Q"", n) + obj)",true,if not obj :,if not obj :,0.75,0.0
"def _restore_freeze(self, new): <TAB> size_change = [] <TAB> for k, v in six.iteritems(self._freeze_backup): <TAB> <TAB> newv = new.get(k, []) <TAB> <TAB> if len(v) != len(newv): <TAB> <TAB> <TAB> size_change.append((self._key_name(k), len(v), len(newv))) <TAB> if size_change: <TAB> <TAB> logger.info( <TAB> <TAB> <TAB> ""These collections were modified but restored in {}: {}"".format( <TAB> <TAB> <TAB> <TAB> self._name, <TAB> <TAB> <TAB> <TAB> "", "".join(map(lambda t: ""({}: {}->{})"".format(*t), size_change)), <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> restore_collection(self._freeze_backup)",true,if len ( v ) != len ( newv ) :,if len ( v ) != len ( newv ) :,1.0,0.0
"def check_options(self, expr, evaluation, options): <TAB> for key in options: <TAB> <TAB> if key != ""System`SameTest"": <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> evaluation.message(""ContainsOnly"", ""optx"", Symbol(key)) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return evaluation.message(""ContainsOnly"", ""optx"", Symbol(key), expr) <TAB> return None",false,if expr is None :,if key in self . allowed_options :,0.15,0.0
"def bundle_directory(self, dirpath): <TAB> """"""Bundle all modules/packages in the given directory."""""" <TAB> dirpath = os.path.abspath(dirpath) <TAB> for nm in os.listdir(dirpath): <TAB> <TAB> nm = _u(nm) <TAB> <TAB> if nm.startswith("".""): <TAB> <TAB> <TAB> continue <TAB> <TAB> itempath = os.path.join(dirpath, nm) <TAB> <TAB> if os.path.isdir(itempath): <TAB> <TAB> <TAB> if os.path.exists(os.path.join(itempath, ""__init__.py"")): <TAB> <TAB> <TAB> <TAB> self.bundle_package(itempath) <TAB> <TAB> elif nm.endswith("".py""): <TAB> <TAB> <TAB> self.bundle_module(itempath)",false,"if os . path . exists ( os . path . join ( itempath , ""__init__.py"" ) ) :",if os . path . isdir ( itempath ) :,0.18,0.0
"def _read_block(self, size): <TAB> if self._file_end is not None: <TAB> <TAB> max_size = self._file_end - self._file.tell() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> size = max_size <TAB> <TAB> size = max(min(size, max_size), 0) <TAB> return self._file.read(size)",false,if size == - 1 :,if size < 0 :,0.05,0.0
"def question_mark(self): <TAB> """"""Shows help for this command and it's sub-commands."""""" <TAB> ret = [] <TAB> if self.param_help_msg or len(self.subcommands) == 0: <TAB> <TAB> ret.append(self._quick_help()) <TAB> if len(self.subcommands) > 0: <TAB> <TAB> for k, _ in sorted(self.subcommands.items()): <TAB> <TAB> <TAB> command_path, param_help, cmd_help = self._instantiate_subcommand( <TAB> <TAB> <TAB> <TAB> k <TAB> <TAB> <TAB> )._quick_help(nested=True) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> ret.append((command_path, param_help, cmd_help)) <TAB> return (CommandsResponse(STATUS_OK, self.help_formatter(ret)), self.__class__)",false,if command_path or param_help or cmd_help :,if cmd_help :,0.04,0.0
"def list_domains(self, r53, **kwargs): <TAB> marker = None <TAB> domains = [] <TAB> while True: <TAB> <TAB> if marker: <TAB> <TAB> <TAB> response = self.wrap_aws_rate_limited_call(r53.list_domains(Marker=marker)) <TAB> <TAB> else: <TAB> <TAB> <TAB> response = self.wrap_aws_rate_limited_call(r53.list_domains) <TAB> <TAB> for domain in response.get(""Domains""): <TAB> <TAB> <TAB> domains.append(domain) <TAB> <TAB> if response.get(""NextPageMarker""): <TAB> <TAB> <TAB> marker = response.get(""NextPageMarker"") <TAB> <TAB> else: <TAB> <TAB> <TAB> break <TAB> return domains",true,"if response . get ( ""NextPageMarker"" ) :","if response . get ( ""NextPageMarker"" ) :",0.75,0.0
"def writer(stream, items): <TAB> sep = """" <TAB> for item in items: <TAB> <TAB> stream.write(sep) <TAB> <TAB> sep = "" "" <TAB> <TAB> if not isinstance(item, str): <TAB> <TAB> <TAB> item = str(item) <TAB> <TAB> if not PY3K: <TAB> <TAB> <TAB> if not isinstance(item, unicode): <TAB> <TAB> <TAB> <TAB> item = str(item) <TAB> <TAB> stream.write(item) <TAB> stream.write(""\n"")",true,"if not isinstance ( item , unicode ) :","if not isinstance ( item , unicode ) :",0.75,0.0
"def f(view, s): <TAB> if mode == modes.INTERNAL_NORMAL: <TAB> <TAB> view.run_command(""toggle_comment"") <TAB> <TAB> if utils.row_at(self.view, s.a) != utils.row_at(self.view, self.view.size()): <TAB> <TAB> <TAB> pt = utils.next_non_white_space_char(view, s.a, white_space="" \t"") <TAB> <TAB> else: <TAB> <TAB> <TAB> pt = utils.next_non_white_space_char( <TAB> <TAB> <TAB> <TAB> view, self.view.line(s.a).a, white_space="" \t"" <TAB> <TAB> <TAB> ) <TAB> <TAB> return R(pt, pt) <TAB> return s",true,"if utils . row_at ( self . view , s . a ) != utils . row_at ( self . view , self . view . size ( ) ) :","if utils . row_at ( self . view , s . a ) != utils . row_at ( self . view , self . view . size ( ) ) :",1.0,0.0
"def _parse_timestamp(value): <TAB> if value: <TAB> <TAB> match = _TIMESTAMP_PATTERN.match(value) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if match.group(2): <TAB> <TAB> <TAB> <TAB> format = ""%Y-%m-%d %H:%M:%S.%f"" <TAB> <TAB> <TAB> <TAB> # use the pattern to truncate the value <TAB> <TAB> <TAB> <TAB> value = match.group() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> format = ""%Y-%m-%d %H:%M:%S"" <TAB> <TAB> <TAB> value = datetime.datetime.strptime(value, format) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception('Cannot convert ""{}"" into a datetime'.format(value)) <TAB> else: <TAB> <TAB> value = None <TAB> return value",true,if match :,if match :,0.53,0.0
"def _compute_log_r(model_trace, guide_trace): <TAB> log_r = MultiFrameTensor() <TAB> stacks = get_plate_stacks(model_trace) <TAB> for name, model_site in model_trace.nodes.items(): <TAB> <TAB> if model_site[""type""] == ""sample"": <TAB> <TAB> <TAB> log_r_term = model_site[""log_prob""] <TAB> <TAB> <TAB> if not model_site[""is_observed""]: <TAB> <TAB> <TAB> <TAB> log_r_term = log_r_term - guide_trace.nodes[name][""log_prob""] <TAB> <TAB> <TAB> log_r.add((stacks[name], log_r_term.detach())) <TAB> return log_r",false,"if not model_site [ ""is_observed"" ] :","if model_site [ ""type"" ] == ""sample"" :",0.04,0.0
"def get_translationproject(self): <TAB> """"""returns the translation project belonging to this directory."""""" <TAB> if self.is_language() or self.is_project(): <TAB> <TAB> return None <TAB> else: <TAB> <TAB> if self.is_translationproject(): <TAB> <TAB> <TAB> return self.translationproject <TAB> <TAB> else: <TAB> <TAB> <TAB> aux_dir = self <TAB> <TAB> <TAB> while not aux_dir.is_translationproject() and aux_dir.parent is not None: <TAB> <TAB> <TAB> <TAB> aux_dir = aux_dir.parent <TAB> <TAB> <TAB> return aux_dir.translationproject",true,if self . is_translationproject ( ) :,if self . is_translationproject ( ) :,0.75,0.0
"def get_hosted_content(): <TAB> try: <TAB> <TAB> scheme, rest = target.split(""://"", 1) <TAB> <TAB> prefix, host_and_port = rest.split("".interactivetool."") <TAB> <TAB> faked_host = rest <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> faked_host = rest.split(""/"", 1)[0] <TAB> <TAB> url = ""%s://%s"" % (scheme, host_and_port) <TAB> <TAB> response = requests.get(url, timeout=1, headers={""Host"": faked_host}) <TAB> <TAB> return response.text <TAB> except Exception as e: <TAB> <TAB> print(e) <TAB> <TAB> return None",true,"if ""/"" in rest :","if ""/"" in rest :",0.75,0.0
"def install(self): <TAB> log.info(self.openssl_cli) <TAB> if not self.has_openssl or self.args.force: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._download_src() <TAB> <TAB> else: <TAB> <TAB> <TAB> log.debug(""Already has src {}"".format(self.src_file)) <TAB> <TAB> self._unpack_src() <TAB> <TAB> self._build_src() <TAB> <TAB> self._make_install() <TAB> else: <TAB> <TAB> log.info(""Already has installation {}"".format(self.install_dir)) <TAB> # validate installation <TAB> version = self.openssl_version <TAB> if self.version not in version: <TAB> <TAB> raise ValueError(version)",false,if not self . has_src :,if self . src_file is None :,0.05,0.0
"def format(self, formatstr): <TAB> pieces = [] <TAB> for i, piece in enumerate(re_formatchars.split(force_text(formatstr))): <TAB> <TAB> if i % 2: <TAB> <TAB> <TAB> pieces.append(force_text(getattr(self, piece)())) <TAB> <TAB> elif piece: <TAB> <TAB> <TAB> pieces.append(re_escaped.sub(r""\1"", piece)) <TAB> return """".join(pieces)",true,elif piece :,elif piece :,0.51,0.0
"def get_current_events_users(calendar): <TAB> now = timezone.make_aware(datetime.now(), timezone.get_current_timezone()) <TAB> result = [] <TAB> day = Day(calendar.events.all(), now) <TAB> for o in day.get_occurrences(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> usernames = o.event.title.split("","") <TAB> <TAB> <TAB> for username in usernames: <TAB> <TAB> <TAB> <TAB> result.append(User.objects.get(username=username.strip())) <TAB> return result",false,if o . start <= now <= o . end :,if o . event . title :,0.1,0.0
"def from_cfn_params(self, cfn_params): <TAB> """"""Initialize param value by parsing CFN input only if the scheduler is awsbatch."""""" <TAB> cfn_converter = self.definition.get(""cfn_param_mapping"", None) <TAB> if cfn_converter and cfn_params: <TAB> <TAB> if get_cfn_param(cfn_params, ""Scheduler"") == ""awsbatch"": <TAB> <TAB> <TAB> # we have the same CFN input parameters for both spot_price and spot_bid_percentage <TAB> <TAB> <TAB> # so the CFN input could be a float <TAB> <TAB> <TAB> self.value = int(float(get_cfn_param(cfn_params, cfn_converter))) <TAB> return self",true,"if get_cfn_param ( cfn_params , ""Scheduler"" ) == ""awsbatch"" :","if get_cfn_param ( cfn_params , ""Scheduler"" ) == ""awsbatch"" :",0.75,0.0
"def onCompletion(self, text): <TAB> res = [] <TAB> for l in text.split(""\n""): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> l = l.split("":"") <TAB> <TAB> if len(l) != 2: <TAB> <TAB> <TAB> continue <TAB> <TAB> res.append([l[0].strip(), l[1].strip()]) <TAB> self.panel.setChapters(res)",false,if not l :,if len ( l ) != 3 :,0.04,0.0
"def update_ranges(l, i): <TAB> for _range in l: <TAB> <TAB> # most common case: extend a range <TAB> <TAB> if i == _range[0] - 1: <TAB> <TAB> <TAB> _range[0] = i <TAB> <TAB> <TAB> merge_ranges(l) <TAB> <TAB> <TAB> return <TAB> <TAB> elif i == _range[1] + 1: <TAB> <TAB> <TAB> _range[1] = i <TAB> <TAB> <TAB> merge_ranges(l) <TAB> <TAB> <TAB> return <TAB> # somewhere outside of range proximity <TAB> l.append([i, i]) <TAB> l.sort(key=lambda x: x[0])",true,elif i == _range [ 1 ] + 1 :,elif i == _range [ 1 ] + 1 :,1.0,0.0
"def process_dollar(token, state, command_line): <TAB> if not state.is_range_start_line_parsed: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError(""bad range: {0}"".format(state.scanner.state.source)) <TAB> <TAB> command_line.line_range.start.append(token) <TAB> else: <TAB> <TAB> if command_line.line_range.end: <TAB> <TAB> <TAB> raise ValueError(""bad range: {0}"".format(state.scanner.state.source)) <TAB> <TAB> command_line.line_range.end.append(token) <TAB> return parse_line_ref, command_line",true,if command_line . line_range . start :,if command_line . line_range . start :,0.75,0.0
"def _parse_description(self, text: str): <TAB> result = dict(links=[], versions=[]) <TAB> for line in text.splitlines(): <TAB> <TAB> clean = REX_TAG.sub("""", line.strip()) <TAB> <TAB> if clean.startswith(""Severity:""): <TAB> <TAB> <TAB> result[""severity""] = clean.split()[1] <TAB> <TAB> <TAB> continue <TAB> <TAB> if clean.startswith(""Affects:""): <TAB> <TAB> <TAB> result[""name""] = clean.split()[1] <TAB> <TAB> <TAB> continue <TAB> <TAB> if "" or higher"" in clean: <TAB> <TAB> <TAB> result[""versions""] = self._get_versions(clean) <TAB> <TAB> result[""links""].extend(REX_LINK.findall(line)) <TAB> return result",true,"if clean . startswith ( ""Severity:"" ) :","if clean . startswith ( ""Severity:"" ) :",0.75,0.0
"def apply(self, chart, grammar): <TAB> for prod in grammar.productions(empty=True): <TAB> <TAB> for index in compat.xrange(chart.num_leaves() + 1): <TAB> <TAB> <TAB> new_edge = TreeEdge.from_production(prod, index) <TAB> <TAB> <TAB> if chart.insert(new_edge, ()): <TAB> <TAB> <TAB> <TAB> yield new_edge",true,"if chart . insert ( new_edge , ( ) ) :","if chart . insert ( new_edge , ( ) ) :",0.75,0.0
"def calc(self, arg): <TAB> op = arg[""op""] <TAB> if op == ""C"": <TAB> <TAB> self.clear() <TAB> <TAB> return str(self.current) <TAB> num = decimal.Decimal(arg[""num""]) <TAB> if self.op: <TAB> <TAB> if self.op == ""+"": <TAB> <TAB> <TAB> self.current += num <TAB> <TAB> elif self.op == ""-"": <TAB> <TAB> <TAB> self.current -= num <TAB> <TAB> elif self.op == ""*"": <TAB> <TAB> <TAB> self.current *= num <TAB> <TAB> elif self.op == ""/"": <TAB> <TAB> <TAB> self.current /= num <TAB> <TAB> self.op = op <TAB> else: <TAB> <TAB> self.op = op <TAB> <TAB> self.current = num <TAB> res = str(self.current) <TAB> if op == ""="": <TAB> <TAB> self.clear() <TAB> return res",false,"if self . op == ""+"" :","elif self . op == ""/"" :",0.21,0.0
"def cascade(self, event=None): <TAB> """"""Cascade all Leo windows."""""" <TAB> x, y, delta = 50, 50, 50 <TAB> for frame in g.app.windowList: <TAB> <TAB> w = frame and frame.top <TAB> <TAB> if w: <TAB> <TAB> <TAB> r = w.geometry()  # a Qt.Rect <TAB> <TAB> <TAB> # 2011/10/26: Fix bug 823601: cascade-windows fails. <TAB> <TAB> <TAB> w.setGeometry(QtCore.QRect(x, y, r.width(), r.height())) <TAB> <TAB> <TAB> # Compute the new offsets. <TAB> <TAB> <TAB> x += 30 <TAB> <TAB> <TAB> y += 30 <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> x = 10 + delta <TAB> <TAB> <TAB> <TAB> y = 40 + delta <TAB> <TAB> <TAB> <TAB> delta += 10",false,if x > 200 :,if x < 0 :,0.31,0.0
"def redirect(self): <TAB> c = self.c <TAB> if c.config.getBool(""eval-redirect""): <TAB> <TAB> self.old_stderr = g.stdErrIsRedirected() <TAB> <TAB> self.old_stdout = g.stdOutIsRedirected() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> g.redirectStderr() <TAB> <TAB> if not self.old_stdout: <TAB> <TAB> <TAB> g.redirectStdout()",true,if not self . old_stderr :,if not self . old_stderr :,0.75,0.0
"def on_event(self, c, button, data): <TAB> if self.rvGestureGrab.get_reveal_child(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.use() <TAB> <TAB> elif button == ""Y"" and data[0] == 0: <TAB> <TAB> <TAB> self.start_over()",false,"if button == ""A"" and data [ 0 ] == 0 :","if button == ""X"" and data [ 0 ] == 0 :",0.87,0.0
"def __init__(self, in_feats, out_feats, norm=""both"", bias=True, activation=None): <TAB> super(DenseGraphConv, self).__init__() <TAB> self._in_feats = in_feats <TAB> self._out_feats = out_feats <TAB> self._norm = norm <TAB> with self.name_scope(): <TAB> <TAB> self.weight = self.params.get( <TAB> <TAB> <TAB> ""weight"", <TAB> <TAB> <TAB> shape=(in_feats, out_feats), <TAB> <TAB> <TAB> init=mx.init.Xavier(magnitude=math.sqrt(2.0)), <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.bias = self.params.get(""bias"", shape=(out_feats,), init=mx.init.Zero()) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.bias = None <TAB> <TAB> self._activation = activation",true,if bias :,if bias :,0.53,0.0
"def _import_top_module(self, name): <TAB> # scan sys.path looking for a location in the filesystem that contains <TAB> # the module, or an Importer object that can import the module. <TAB> for item in sys.path: <TAB> <TAB> if isinstance(item, _StringType): <TAB> <TAB> <TAB> module = self.fs_imp.import_from_dir(item, name) <TAB> <TAB> else: <TAB> <TAB> <TAB> module = item.import_top(name) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return module <TAB> return None",true,if module :,if module :,0.53,0.0
"def resolver(schemas, f): <TAB> if not callable(f): <TAB> <TAB> return <TAB> if not hasattr(f, ""accepts""): <TAB> <TAB> return <TAB> new_params = [] <TAB> for p in f.accepts: <TAB> <TAB> if isinstance(p, (Patch, Ref, Attribute)): <TAB> <TAB> <TAB> new_params.append(p.resolve(schemas)) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ResolverError(""Invalid parameter definition {0}"".format(p)) <TAB> # FIXME: for some reason assigning params (f.accepts = new_params) does not work <TAB> f.accepts.clear() <TAB> f.accepts.extend(new_params)",true,"if isinstance ( p , ( Patch , Ref , Attribute ) ) :","if isinstance ( p , ( Patch , Ref , Attribute ) ) :",0.75,0.0
"def get_files(d): <TAB> res = [] <TAB> for p in glob.glob(os.path.join(d, ""*"")): <TAB> <TAB> if not p: <TAB> <TAB> <TAB> continue <TAB> <TAB> (pth, fname) = os.path.split(p) <TAB> <TAB> if fname == ""output"": <TAB> <TAB> <TAB> continue <TAB> <TAB> if fname == ""PureMVC_Python_1_0"": <TAB> <TAB> <TAB> continue <TAB> <TAB> if fname[-4:] == "".pyc"":  # ehmm.. no. <TAB> <TAB> <TAB> continue <TAB> <TAB> if os.path.isdir(p): <TAB> <TAB> <TAB> get_dir(p) <TAB> <TAB> else: <TAB> <TAB> <TAB> res.append(p) <TAB> return res",false,"if fname == ""PureMVC_Python_1_0"" :","if fname [ - 4 : ] == "".pyc"" :",0.05,0.0
"def _addRightnames(groups, kerning, leftname, rightnames, includeAll=True): <TAB> if leftname in kerning: <TAB> <TAB> for rightname in kerning[leftname]: <TAB> <TAB> <TAB> if rightname[0] == ""@"": <TAB> <TAB> <TAB> <TAB> for rightname2 in groups[rightname]: <TAB> <TAB> <TAB> <TAB> <TAB> rightnames.add(rightname2) <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> # TODO: in this case, pick the one rightname that has the highest <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> # ranking in glyphorder <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> rightnames.add(rightname)",false,if not includeAll :,if includeAll :,0.1,0.0
"def migrate_Stats(self): <TAB> for old_obj in self.session_old.query(self.model_from[""Stats""]): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.entries_count[""Stats""] -= 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> new_obj = self.model_to[""Stats""]() <TAB> <TAB> for key in new_obj.__table__.columns._data.keys(): <TAB> <TAB> <TAB> if key not in old_obj.__table__.columns: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> setattr(new_obj, key, getattr(old_obj, key)) <TAB> <TAB> self.session_new.add(new_obj)",false,if not old_obj . summary :,"if ""Stats"" in old_obj . entries :",0.05,0.0
"def _readenv(var, msg): <TAB> match = _ENV_VAR_PAT.match(var) <TAB> if match and match.groups(): <TAB> <TAB> envvar = match.groups()[0] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> value = os.environ[envvar] <TAB> <TAB> <TAB> if six.PY2: <TAB> <TAB> <TAB> <TAB> value = value.decode(""utf8"") <TAB> <TAB> <TAB> return value <TAB> <TAB> else: <TAB> <TAB> <TAB> raise InvalidConfigException( <TAB> <TAB> <TAB> <TAB> ""{} - environment variable '{}' not set"".format(msg, var) <TAB> <TAB> <TAB> ) <TAB> else: <TAB> <TAB> raise InvalidConfigException( <TAB> <TAB> <TAB> ""{} - environment variable name '{}' does not match pattern '{}'"".format( <TAB> <TAB> <TAB> <TAB> msg, var, _ENV_VAR_PAT_STR <TAB> <TAB> <TAB> ) <TAB> <TAB> )",true,if envvar in os . environ :,if envvar in os . environ :,0.75,0.0
"def __next__(self): <TAB> self._parse_reset() <TAB> while True: <TAB> <TAB> try: <TAB> <TAB> <TAB> line = next(self.input_iter) <TAB> <TAB> except StopIteration: <TAB> <TAB> <TAB> # End of input OR exception <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise Error(""newline inside string"") <TAB> <TAB> <TAB> raise <TAB> <TAB> self.line_num += 1 <TAB> <TAB> if ""\0"" in line: <TAB> <TAB> <TAB> raise Error(""line contains NULL byte"") <TAB> <TAB> pos = 0 <TAB> <TAB> while pos < len(line): <TAB> <TAB> <TAB> pos = self._parse_process_char(line, pos) <TAB> <TAB> self._parse_eol() <TAB> <TAB> if self.state == self.START_RECORD: <TAB> <TAB> <TAB> break <TAB> fields = self.fields <TAB> self.fields = [] <TAB> return fields",false,if len ( self . field ) > 0 :,if self . line_num >= self . max_line_num :,0.07,0.0
"def createFields(self): <TAB> while self.current_size < self.size: <TAB> <TAB> pos = self.stream.searchBytes( <TAB> <TAB> <TAB> ""\0\0\1"", self.current_size, self.current_size + 1024 * 1024 * 8 <TAB> <TAB> )  # seek forward by at most 1MB <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> padsize = pos - self.current_size <TAB> <TAB> <TAB> if padsize: <TAB> <TAB> <TAB> <TAB> yield PaddingBytes(self, ""pad[]"", padsize // 8) <TAB> <TAB> chunk = Chunk(self, ""chunk[]"") <TAB> <TAB> try: <TAB> <TAB> <TAB> # force chunk to be processed, so that CustomFragments are complete <TAB> <TAB> <TAB> chunk[""content/data""] <TAB> <TAB> except: <TAB> <TAB> <TAB> pass <TAB> <TAB> yield chunk",false,if pos is not None :,if pos :,0.05,0.0
"def spew(): <TAB> seenUID = False <TAB> start() <TAB> for part in query: <TAB> <TAB> if part.type == ""uid"": <TAB> <TAB> <TAB> seenUID = True <TAB> <TAB> if part.type == ""body"": <TAB> <TAB> <TAB> yield self.spew_body(part, id, msg, write, flush) <TAB> <TAB> else: <TAB> <TAB> <TAB> f = getattr(self, ""spew_"" + part.type) <TAB> <TAB> <TAB> yield f(id, msg, write, flush) <TAB> <TAB> if part is not query[-1]: <TAB> <TAB> <TAB> space() <TAB> if uid and not seenUID: <TAB> <TAB> space() <TAB> <TAB> yield self.spew_uid(id, msg, write, flush) <TAB> finish() <TAB> flush()",false,"if part . type == ""body"" :",if part is not query [ - 1 ] :,0.03,0.0
"def _limit_value(key, value, config): <TAB> if config[key].get(""upper_limit""): <TAB> <TAB> limit = config[key][""upper_limit""] <TAB> <TAB> # auto handle datetime <TAB> <TAB> if isinstance(value, datetime) and isinstance(limit, timedelta): <TAB> <TAB> <TAB> if config[key][""inverse""] is True: <TAB> <TAB> <TAB> <TAB> if (datetime.now() - limit) > value: <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime.now() - limit <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> if (datetime.now() + limit) < value: <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime.now() + limit <TAB> <TAB> elif value > limit: <TAB> <TAB> <TAB> value = limit <TAB> return value",false,if ( datetime . now ( ) + limit ) < value :,"if isinstance ( value , datetime ) and isinstance ( limit , timedelta ) :",0.01,0.0
"def _fix_var_naming(operators, names, mod=""input""): <TAB> new_names = [] <TAB> map = {} <TAB> for op in operators: <TAB> <TAB> if mod == ""input"": <TAB> <TAB> <TAB> iter = op.inputs <TAB> <TAB> else: <TAB> <TAB> <TAB> iter = op.outputs <TAB> <TAB> for i in iter: <TAB> <TAB> <TAB> for name in names: <TAB> <TAB> <TAB> <TAB> if i.raw_name == name and name not in map: <TAB> <TAB> <TAB> <TAB> <TAB> map[i.raw_name] = i.full_name <TAB> <TAB> if len(map) == len(names): <TAB> <TAB> <TAB> break <TAB> for name in names: <TAB> <TAB> new_names.append(map[name]) <TAB> return new_names",false,if len ( map ) == len ( names ) :,"if mod == ""input"" :",0.01,0.0
"def traverse(tree): <TAB> """"""Generator dropping comment nodes"""""" <TAB> for entry in tree: <TAB> <TAB> # key, values = entry <TAB> <TAB> spaceless = [e for e in entry if not nginxparser.spacey(e)] <TAB> <TAB> if spaceless: <TAB> <TAB> <TAB> key = spaceless[0] <TAB> <TAB> <TAB> values = spaceless[1] if len(spaceless) > 1 else None <TAB> <TAB> else: <TAB> <TAB> <TAB> key = values = """" <TAB> <TAB> if isinstance(key, list): <TAB> <TAB> <TAB> new = copy.deepcopy(entry) <TAB> <TAB> <TAB> new[1] = filter_comments(values) <TAB> <TAB> <TAB> yield new <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> yield spaceless",false,"if key != ""#"" and spaceless :",if len ( spaceless ) > 1 :,0.02,0.0
"def mergeCombiners(self, x, y): <TAB> for item in y: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.heap.push(x, item) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.heap.push_pop(x, item) <TAB> return x",false,if len ( x ) < self . heap_limit :,if self . heap :,0.08,0.0
"def test_scatter(self, harness: primitive_harness.Harness): <TAB> f_name = harness.params[""f_lax""].__name__ <TAB> dtype = harness.params[""dtype""] <TAB> if jtu.device_under_test() == ""tpu"": <TAB> <TAB> if dtype is np.complex64 and f_name in [""scatter_min"", ""scatter_max""]: <TAB> <TAB> <TAB> raise unittest.SkipTest(f""TODO: complex {f_name} on TPU fails in JAX"") <TAB> self.ConvertAndCompare(harness.dyn_fun, *harness.dyn_args_maker(self.rng()))",true,"if dtype is np . complex64 and f_name in [ ""scatter_min"" , ""scatter_max"" ] :","if dtype is np . complex64 and f_name in [ ""scatter_min"" , ""scatter_max"" ] :",0.75,0.0
"def TryMerge(self, decoder): <TAB> while decoder.avail() > 0: <TAB> <TAB> tag = decoder.getVarInt32() <TAB> <TAB> if tag == TAG_BEGIN_ITEM_GROUP: <TAB> <TAB> <TAB> (type_id, message) = Item.Decode(decoder) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.items[type_id].MergeFrom(Item(message)) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.items[type_id] = Item(message) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tag == 0: <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> decoder.skipData(tag)",true,if type_id in self . items :,if type_id in self . items :,0.75,0.0
"def process_continuations(lines): <TAB> global continuation_pattern <TAB> olines = [] <TAB> while len(lines) != 0: <TAB> <TAB> line = no_comments(lines[0]) <TAB> <TAB> line = line.strip() <TAB> <TAB> lines.pop(0) <TAB> <TAB> if line == """": <TAB> <TAB> <TAB> continue <TAB> <TAB> if continuation_pattern.search(line): <TAB> <TAB> <TAB> # combine this line with the next line if the next line exists <TAB> <TAB> <TAB> line = continuation_pattern.sub("""", line) <TAB> <TAB> <TAB> if len(lines) >= 1: <TAB> <TAB> <TAB> <TAB> combined_lines = [line + lines[0]] <TAB> <TAB> <TAB> <TAB> lines.pop(0) <TAB> <TAB> <TAB> <TAB> lines = combined_lines + lines <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> olines.append(line) <TAB> del lines <TAB> return olines",true,if continuation_pattern . search ( line ) :,if continuation_pattern . search ( line ) :,0.75,0.0
"def _getListNextPackagesReadyToBuild(): <TAB> for pkg in Scheduler.listOfPackagesToBuild: <TAB> <TAB> if pkg in Scheduler.listOfPackagesCurrentlyBuilding: <TAB> <TAB> <TAB> continue <TAB> <TAB> if constants.rpmCheck or Scheduler._checkNextPackageIsReadyToBuild(pkg): <TAB> <TAB> <TAB> Scheduler.listOfPackagesNextToBuild.put((-Scheduler._getPriority(pkg), pkg)) <TAB> <TAB> <TAB> Scheduler.logger.debug(""Adding "" + pkg + "" to the schedule list"")",true,if constants . rpmCheck or Scheduler . _checkNextPackageIsReadyToBuild ( pkg ) :,if constants . rpmCheck or Scheduler . _checkNextPackageIsReadyToBuild ( pkg ) :,0.75,0.0
"def process_signature(app, what, name, obj, options, signature, return_annotation): <TAB> if signature: <TAB> <TAB> # replace Mock function names <TAB> <TAB> signature = re.sub(""<Mock name='([^']+)'.*>"", ""\g<1>"", signature) <TAB> <TAB> signature = re.sub(""tensorflow"", ""tf"", signature) <TAB> <TAB> # add scope name to layer signatures: <TAB> <TAB> if hasattr(obj, ""use_scope""): <TAB> <TAB> <TAB> if obj.use_scope: <TAB> <TAB> <TAB> <TAB> signature = signature[0] + ""variable_scope_name, "" + signature[1:] <TAB> <TAB> <TAB> elif obj.use_scope is None: <TAB> <TAB> <TAB> <TAB> signature = signature[0] + ""[variable_scope_name,] "" + signature[1:] <TAB> # signature: arg list <TAB> return signature, return_annotation",true,elif obj . use_scope is None :,elif obj . use_scope is None :,0.75,0.0
"def find_distribution_modules(name=__name__, file=__file__): <TAB> current_dist_depth = len(name.split(""."")) - 1 <TAB> current_dist = os.path.join( <TAB> <TAB> os.path.dirname(file), *([os.pardir] * current_dist_depth) <TAB> ) <TAB> abs = os.path.abspath(current_dist) <TAB> dist_name = os.path.basename(abs) <TAB> for dirpath, dirnames, filenames in os.walk(abs): <TAB> <TAB> package = (dist_name + dirpath[len(abs) :]).replace(""/"", ""."") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield package <TAB> <TAB> <TAB> for filename in filenames: <TAB> <TAB> <TAB> <TAB> if filename.endswith("".py"") and filename != ""__init__.py"": <TAB> <TAB> <TAB> <TAB> <TAB> yield ""."".join([package, filename])[:-3]",false,"if ""__init__.py"" in filenames :",if len ( filenames ) == current_dist_depth :,0.03,0.0
"def transform_value(i, v, *args): <TAB> if i not in converter_functions: <TAB> <TAB> # no converter defined on this field, return value as-is <TAB> <TAB> return v <TAB> else: <TAB> <TAB> try: <TAB> <TAB> <TAB> return converter_functions[i](v, *args) <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> if failonerror == ""inline"": <TAB> <TAB> <TAB> <TAB> return e <TAB> <TAB> <TAB> elif failonerror: <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return errorvalue",true,elif failonerror :,elif failonerror :,0.51,0.0
"def _get_file(self): <TAB> if self._file is None: <TAB> <TAB> self._file = SpooledTemporaryFile( <TAB> <TAB> <TAB> max_size=self._storage.max_memory_size, <TAB> <TAB> <TAB> suffix="".S3Boto3StorageFile"", <TAB> <TAB> <TAB> dir=setting(""FILE_UPLOAD_TEMP_DIR""), <TAB> <TAB> ) <TAB> <TAB> if ""r"" in self._mode: <TAB> <TAB> <TAB> self._is_dirty = False <TAB> <TAB> <TAB> self.obj.download_fileobj(self._file) <TAB> <TAB> <TAB> self._file.seek(0) <TAB> <TAB> if self._storage.gzip and self.obj.content_encoding == ""gzip"": <TAB> <TAB> <TAB> self._file = GzipFile(mode=self._mode, fileobj=self._file, mtime=0.0) <TAB> return self._file",true,"if ""r"" in self . _mode :","if ""r"" in self . _mode :",0.75,0.0
"def connect(self, host, port, timeout): <TAB> fp = Telnet() <TAB> for i in range(50): <TAB> <TAB> try: <TAB> <TAB> <TAB> fp.sock = socket.create_connection( <TAB> <TAB> <TAB> <TAB> (host, int(port)), timeout=int(timeout), source_address=("""", 1023 - i) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> break <TAB> <TAB> except socket.error as e: <TAB> <TAB> <TAB> if (e.errno, e.strerror) != (98, ""Address already in use""): <TAB> <TAB> <TAB> <TAB> raise e <TAB> self.need_handshake = True <TAB> return TCP_Connection(fp)",false,"if ( e . errno , e . strerror ) != ( 98 , ""Address already in use"" ) :","if ( e . errno , e . strerror ) != ( 99 , ""Address already in use"" ) :",0.68,0.0
"def filtercomments(source): <TAB> """"""NOT USED: strips trailing comments and put them at the top."""""" <TAB> trailing_comments = [] <TAB> comment = True <TAB> while comment: <TAB> <TAB> if re.search(r""^\s*\/\*"", source): <TAB> <TAB> <TAB> comment = source[0, source.index(""*/"") + 2] <TAB> <TAB> elif re.search(r""^\s*\/\/"", source): <TAB> <TAB> <TAB> comment = re.search(r""^\s*\/\/"", source).group(0) <TAB> <TAB> else: <TAB> <TAB> <TAB> comment = None <TAB> <TAB> if comment: <TAB> <TAB> <TAB> source = re.sub(r""^\s+"", """", source[len(comment) :]) <TAB> <TAB> <TAB> trailing_comments.append(comment) <TAB> return ""\n"".join(trailing_comments) + source",true,"elif re . search ( r""^\s*\/\/"" , source ) :","elif re . search ( r""^\s*\/\/"" , source ) :",0.75,0.0
"def yview(self, mode=None, value=None, units=None): <TAB> if type(value) == str: <TAB> <TAB> value = float(value) <TAB> if mode is None: <TAB> <TAB> return self.vsb.get() <TAB> elif mode == ""moveto"": <TAB> <TAB> frameHeight = self.innerframe.winfo_reqheight() <TAB> <TAB> self._startY = value * float(frameHeight) <TAB> else:  # mode == 'scroll' <TAB> <TAB> clipperHeight = self._clipper.winfo_height() <TAB> <TAB> if units == ""units"": <TAB> <TAB> <TAB> jump = int(clipperHeight * self._jfraction) <TAB> <TAB> else: <TAB> <TAB> <TAB> jump = clipperHeight <TAB> <TAB> self._startY = self._startY + value * jump <TAB> self.reposition()",true,"if units == ""units"" :","if units == ""units"" :",0.75,0.0
"def visit(stmt): <TAB> """"""Collect information about VTCM buffers and their alignments."""""" <TAB> if isinstance(stmt, tvm.tir.AttrStmt): <TAB> <TAB> if stmt.attr_key == ""storage_scope"" and stmt.value == ""local.vtcm"": <TAB> <TAB> <TAB> vtcm_buffers.append(stmt.node) <TAB> <TAB> elif stmt.attr_key == ""storage_alignment"": <TAB> <TAB> <TAB> if not stmt.node in alignments: <TAB> <TAB> <TAB> <TAB> alignments[stmt.node] = [] <TAB> <TAB> <TAB> alignments[stmt.node].append(stmt.value)",false,"elif stmt . attr_key == ""storage_alignment"" :","if stmt . attr_key == ""storage_scope"" and stmt . value == ""local.vtcm"" :",0.48,0.0
"def cost(P): <TAB> # wda loss <TAB> loss_b = 0 <TAB> loss_w = 0 <TAB> for i, xi in enumerate(xc): <TAB> <TAB> xi = np.dot(xi, P) <TAB> <TAB> for j, xj in enumerate(xc[i:]): <TAB> <TAB> <TAB> xj = np.dot(xj, P) <TAB> <TAB> <TAB> M = dist(xi, xj) <TAB> <TAB> <TAB> G = sinkhorn(wc[i], wc[j + i], M, reg, k) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> loss_w += np.sum(G * M) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> loss_b += np.sum(G * M) <TAB> # loss inversed because minimization <TAB> return loss_w / loss_b",false,if j == 0 :,if k == 0 :,0.39,0.0
"def __init__(self, comm, in_channels, out_channels, ksize, pad=1): <TAB> super(Block, self).__init__() <TAB> with self.init_scope(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.conv = ParallelConvolution2D( <TAB> <TAB> <TAB> <TAB> comm, in_channels, out_channels, ksize, pad=pad, nobias=True <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.conv = chainer.links.Convolution2D( <TAB> <TAB> <TAB> <TAB> in_channels, out_channels, ksize, pad=pad, nobias=True <TAB> <TAB> <TAB> ) <TAB> <TAB> self.bn = L.BatchNormalization(out_channels)",false,if comm . size <= in_channels :,if comm . num_layers == 1 :,0.15,0.0
"def halfMultipartScore(nzb_name): <TAB> try: <TAB> <TAB> wrong_found = 0 <TAB> <TAB> for nr in [1, 2, 3, 4, 5, ""i"", ""ii"", ""iii"", ""iv"", ""v"", ""a"", ""b"", ""c"", ""d"", ""e""]: <TAB> <TAB> <TAB> for wrong in [""cd"", ""part"", ""dis"", ""disc"", ""dvd""]: <TAB> <TAB> <TAB> <TAB> if ""%s%s"" % (wrong, nr) in nzb_name.lower(): <TAB> <TAB> <TAB> <TAB> <TAB> wrong_found += 1 <TAB> <TAB> if wrong_found == 1: <TAB> <TAB> <TAB> return -30 <TAB> <TAB> return 0 <TAB> except: <TAB> <TAB> log.error(""Failed doing halfMultipartScore: %s"", traceback.format_exc()) <TAB> return 0",true,"if ""%s%s"" % ( wrong , nr ) in nzb_name . lower ( ) :","if ""%s%s"" % ( wrong , nr ) in nzb_name . lower ( ) :",0.75,0.0
"def should_include(service): <TAB> for f in filt: <TAB> <TAB> if f == ""status"": <TAB> <TAB> <TAB> state = filt[f] <TAB> <TAB> <TAB> containers = project.containers([service.name], stopped=True) <TAB> <TAB> <TAB> if not has_container_with_state(containers, state): <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif f == ""source"": <TAB> <TAB> <TAB> source = filt[f] <TAB> <TAB> <TAB> if source == ""image"" or source == ""build"": <TAB> <TAB> <TAB> <TAB> if source not in service.options: <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise UserError(""Invalid value for source filter: %s"" % source) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise UserError(""Invalid filter: %s"" % f) <TAB> return True",true,"if f == ""status"" :","if f == ""status"" :",0.75,0.0
"def get_blob_type_declaration_sql(self, column): <TAB> length = column.get(""length"") <TAB> if length: <TAB> <TAB> if length <= self.LENGTH_LIMIT_TINYBLOB: <TAB> <TAB> <TAB> return ""TINYBLOB"" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ""BLOB"" <TAB> <TAB> if length <= self.LENGTH_LIMIT_MEDIUMBLOB: <TAB> <TAB> <TAB> return ""MEDIUMBLOB"" <TAB> return ""LONGBLOB""",true,if length <= self . LENGTH_LIMIT_BLOB :,if length <= self . LENGTH_LIMIT_BLOB :,0.75,0.0
"def click_outside(event): <TAB> if event not in d: <TAB> <TAB> x, y, z = self.blockFaceUnderCursor[0] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> y = 64 <TAB> <TAB> y += 3 <TAB> <TAB> gotoPanel.X, gotoPanel.Y, gotoPanel.Z = x, y, z <TAB> <TAB> if event.num_clicks == 2: <TAB> <TAB> <TAB> d.dismiss(""Goto"")",false,if y == 0 :,if y == - 1 :,0.13,0.0
"def check_related_active_jobs(self, obj): <TAB> active_jobs = obj.get_active_jobs() <TAB> if len(active_jobs) > 0: <TAB> <TAB> raise ActiveJobConflict(active_jobs) <TAB> time_cutoff = now() - dateutil.relativedelta.relativedelta(minutes=1) <TAB> recent_jobs = obj._get_related_jobs().filter(finished__gte=time_cutoff) <TAB> for unified_job in recent_jobs.get_real_instances(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise PermissionDenied( <TAB> <TAB> <TAB> <TAB> _(""Related job {} is still processing events."").format( <TAB> <TAB> <TAB> <TAB> <TAB> unified_job.log_format <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> )",false,if not unified_job . event_processing_finished :,if unified_job . log_format :,0.05,0.0
"def run(self): <TAB> self.alive = True <TAB> if _log.isEnabledFor(_DEBUG): <TAB> <TAB> _log.debug(""started"") <TAB> while self.alive: <TAB> <TAB> task = self.queue.get() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> function, args, kwargs = task <TAB> <TAB> <TAB> assert function <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> function(*args, **kwargs) <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> _log.exception(""calling %s"", function) <TAB> if _log.isEnabledFor(_DEBUG): <TAB> <TAB> _log.debug(""stopped"")",true,if task :,if task :,0.53,0.0
"def update_sysconfig_file(fn, adjustments, allow_empty=False): <TAB> if not adjustments: <TAB> <TAB> return <TAB> (exists, contents) = read_sysconfig_file(fn) <TAB> updated_am = 0 <TAB> for (k, v) in adjustments.items(): <TAB> <TAB> if v is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> v = str(v) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> contents[k] = v <TAB> <TAB> updated_am += 1 <TAB> if updated_am: <TAB> <TAB> lines = [ <TAB> <TAB> <TAB> str(contents), <TAB> <TAB> ] <TAB> <TAB> if not exists: <TAB> <TAB> <TAB> lines.insert(0, util.make_header()) <TAB> <TAB> util.write_file(fn, ""\n"".join(lines) + ""\n"", 0o644)",false,if len ( v ) == 0 and not allow_empty :,"if v == """" and allow_empty :",0.03,0.0
"def wrapper(  # type: ignore <TAB> self: RequestHandler, *args, **kwargs ) -> Optional[Awaitable[None]]: <TAB> if self.request.path.endswith(""/""): <TAB> <TAB> if self.request.method in (""GET"", ""HEAD""): <TAB> <TAB> <TAB> uri = self.request.path.rstrip(""/"") <TAB> <TAB> <TAB><IF-STMT>  # don't try to redirect '/' to '' <TAB> <TAB> <TAB> <TAB> if self.request.query: <TAB> <TAB> <TAB> <TAB> <TAB> uri += ""?"" + self.request.query <TAB> <TAB> <TAB> <TAB> self.redirect(uri, permanent=True) <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> else: <TAB> <TAB> <TAB> raise HTTPError(404) <TAB> return method(self, *args, **kwargs)",true,if uri :,if uri :,0.53,0.0
def output_handles_from_execution_plan(execution_plan): <TAB> output_handles_for_current_run = set() <TAB> for step_level in execution_plan.execution_step_levels(): <TAB> <TAB> for step in step_level: <TAB> <TAB> <TAB> for step_input in step.step_inputs: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> output_handles_for_current_run.update(step_input.source_handles) <TAB> return output_handles_for_current_run,false,if step_input . source_handles :,if step_input . is_current :,0.39,0.0
"def _read_value(self, item): <TAB> item = _normalize_path(item) <TAB> if item in self._store: <TAB> <TAB> if item in self._expire_time and self._expire_time[item] < datetime.now(): <TAB> <TAB> <TAB> del self._store[item] <TAB> <TAB> <TAB> raise KeyError(item) <TAB> <TAB> return PathResult(item, value=self._store[item]) <TAB> elif item in self._children: <TAB> <TAB> return PathResult(item, dir=True) <TAB> else: <TAB> <TAB> raise KeyError(item)",true,if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) :,if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) :,0.75,0.0
"def _line_ranges(statements, lines): <TAB> """"""Produce a list of ranges for `format_lines`."""""" <TAB> statements = sorted(statements) <TAB> lines = sorted(lines) <TAB> pairs = [] <TAB> start = None <TAB> lidx = 0 <TAB> for stmt in statements: <TAB> <TAB> if lidx >= len(lines): <TAB> <TAB> <TAB> break <TAB> <TAB> if stmt == lines[lidx]: <TAB> <TAB> <TAB> lidx += 1 <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> start = stmt <TAB> <TAB> <TAB> end = stmt <TAB> <TAB> elif start: <TAB> <TAB> <TAB> pairs.append((start, end)) <TAB> <TAB> <TAB> start = None <TAB> if start: <TAB> <TAB> pairs.append((start, end)) <TAB> return pairs",false,if not start :,if start is None :,0.05,0.0
"def _update_help_obj_params(help_obj, data_params, params_equal, attr_key_tups): <TAB> loaded_params = [] <TAB> for param_obj in help_obj.parameters: <TAB> <TAB> loaded_param = next( <TAB> <TAB> <TAB> (n for n in data_params if params_equal(param_obj, n)), None <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> BaseHelpLoader._update_obj_from_data_dict( <TAB> <TAB> <TAB> <TAB> param_obj, loaded_param, attr_key_tups <TAB> <TAB> <TAB> ) <TAB> <TAB> loaded_params.append(param_obj) <TAB> help_obj.parameters = loaded_params",false,if loaded_param :,if loaded_param is not None :,0.09,0.0
"def __get_ratio(self): <TAB> """"""Return splitter ratio of the main splitter."""""" <TAB> c = self.c <TAB> free_layout = c.free_layout <TAB> if free_layout: <TAB> <TAB> w = free_layout.get_main_splitter() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> aList = w.sizes() <TAB> <TAB> <TAB> if len(aList) == 2: <TAB> <TAB> <TAB> <TAB> n1, n2 = aList <TAB> <TAB> <TAB> <TAB> # 2017/06/07: guard against division by zero. <TAB> <TAB> <TAB> <TAB> ratio = 0.5 if n1 + n2 == 0 else float(n1) / float(n1 + n2) <TAB> <TAB> <TAB> <TAB> return ratio <TAB> return 0.5",true,if w :,if w :,0.53,0.0
"def _check_required_env_variables(vars): <TAB> for var in vars: <TAB> <TAB> if not os.environ.get(var): <TAB> <TAB> <TAB> self.tc.logger.error( <TAB> <TAB> <TAB> <TAB> ""%s is not set. Did you forget to source your build environment setup script?"" <TAB> <TAB> <TAB> <TAB> % var <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> raise OEQAPreRun",true,if not os . environ . get ( var ) :,if not os . environ . get ( var ) :,0.75,0.0
"def clean_indexes(): <TAB> for coll_name in mongo.collection_types.keys(): <TAB> <TAB> coll = mongo.get_collection(coll_name) <TAB> <TAB> indexes = coll_indexes[coll_name] <TAB> <TAB> try: <TAB> <TAB> <TAB> for index in coll.list_indexes(): <TAB> <TAB> <TAB> <TAB> name = index[""name""] <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> coll.drop_index(name) <TAB> <TAB> except pymongo.errors.OperationFailure: <TAB> <TAB> <TAB> pass",false,"if name == ""_id"" or name == ""_id_"" or name in indexes :",if name not in indexes :,0.17,0.0
"def _compare_dirs(self, dir1, dir2): <TAB> # check that dir1 and dir2 are equivalent, <TAB> # return the diff <TAB> diff = [] <TAB> for root, dirs, files in os.walk(dir1): <TAB> <TAB> for file_ in files: <TAB> <TAB> <TAB> path = os.path.join(root, file_) <TAB> <TAB> <TAB> target_path = os.path.join(dir2, os.path.split(path)[-1]) <TAB> <TAB> <TAB> if not os.path.exists(target_path): <TAB> <TAB> <TAB> <TAB> diff.append(file_) <TAB> return diff",true,if not os . path . exists ( target_path ) :,if not os . path . exists ( target_path ) :,0.75,0.0
"def load_state_dict(self, state_dict, strict=True): <TAB> """"""Customized load."""""" <TAB> self.language_model.load_state_dict( <TAB> <TAB> state_dict[self._language_model_key], strict=strict <TAB> ) <TAB> if mpu.is_pipeline_last_stage(): <TAB> <TAB> if self._multichoice_head_key in state_dict: <TAB> <TAB> <TAB> self.multichoice_head.load_state_dict( <TAB> <TAB> <TAB> <TAB> state_dict[self._multichoice_head_key], strict=strict <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> print_rank_last( <TAB> <TAB> <TAB> <TAB> ""***WARNING*** could not find {} in the checkpoint, "" <TAB> <TAB> <TAB> <TAB> ""initializing to random"".format(self._multichoice_head_key) <TAB> <TAB> <TAB> )",true,if self . _multichoice_head_key in state_dict :,if self . _multichoice_head_key in state_dict :,0.75,0.0
"def _parse_timedelta(self, value): <TAB> try: <TAB> <TAB> sum = datetime.timedelta() <TAB> <TAB> start = 0 <TAB> <TAB> while start < len(value): <TAB> <TAB> <TAB> m = self._TIMEDELTA_PATTERN.match(value, start) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise Exception() <TAB> <TAB> <TAB> num = float(m.group(1)) <TAB> <TAB> <TAB> units = m.group(2) or ""seconds"" <TAB> <TAB> <TAB> units = self._TIMEDELTA_ABBREV_DICT.get(units, units) <TAB> <TAB> <TAB> sum += datetime.timedelta(**{units: num}) <TAB> <TAB> <TAB> start = m.end() <TAB> <TAB> return sum <TAB> except: <TAB> <TAB> raise",true,if not m :,if not m :,0.75,0.0
"def SetChildMenuBar(self, pChild): <TAB> if not pChild: <TAB> <TAB> # No Child, set Our menu bar back. <TAB> <TAB> if self._pMyMenuBar: <TAB> <TAB> <TAB> self.SetMenuBar(self._pMyMenuBar) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.SetMenuBar(self.GetMenuBar()) <TAB> <TAB> # Make sure we know our menu bar is in use <TAB> <TAB> self._pMyMenuBar = None <TAB> else: <TAB> <TAB> if pChild.GetMenuBar() is None: <TAB> <TAB> <TAB> return <TAB> <TAB> # Do we need to save the current bar? <TAB> <TAB> if self._pMyMenuBar is None: <TAB> <TAB> <TAB> self._pMyMenuBar = self.GetMenuBar() <TAB> <TAB> self.SetMenuBar(pChild.GetMenuBar())",false,if self . _pMyMenuBar is None :,if pChild . GetMenuBar ( ) is None :,0.08,0.0
"def init_weights(self): <TAB> """"""Initialize weights of the head."""""" <TAB> # retinanet_bias_init <TAB> bias_cls = bias_init_with_prob(0.01) <TAB> normal_init(self.conv_reg, std=0.01) <TAB> normal_init(self.conv_centerness, std=0.01) <TAB> normal_init(self.conv_cls, std=0.01, bias=bias_cls) <TAB> for branch in [self.cls_convs, self.reg_convs]: <TAB> <TAB> for module in branch.modules(): <TAB> <TAB> <TAB> if isinstance(module, ConvModule) and isinstance(module.conv, nn.Conv2d): <TAB> <TAB> <TAB> <TAB> caffe2_xavier_init(module.conv)",true,"if isinstance ( module , ConvModule ) and isinstance ( module . conv , nn . Conv2d ) :","if isinstance ( module , ConvModule ) and isinstance ( module . conv , nn . Conv2d ) :",1.0,0.0
"def handle_exception(self, e, result): <TAB> for k in sorted(result.thrift_spec): <TAB> <TAB> if result.thrift_spec[k][1] == ""success"": <TAB> <TAB> <TAB> continue <TAB> <TAB> _, exc_name, exc_cls, _ = result.thrift_spec[k] <TAB> <TAB> if isinstance(e, exc_cls): <TAB> <TAB> <TAB> setattr(result, exc_name, e) <TAB> <TAB> <TAB> break <TAB> else: <TAB> <TAB> raise",true,"if isinstance ( e , exc_cls ) :","if isinstance ( e , exc_cls ) :",0.75,0.0
"def scripts(self): <TAB> application_root = current_app.config.get(""APPLICATION_ROOT"") <TAB> subdir = application_root != ""/"" <TAB> scripts = [] <TAB> for script in get_registered_scripts(): <TAB> <TAB> if script.startswith(""http""): <TAB> <TAB> <TAB> scripts.append(f'<script defer src=""{script}""></script>') <TAB> <TAB> elif subdir: <TAB> <TAB> <TAB> scripts.append(f'<script defer src=""{application_root}/{script}""></script>') <TAB> <TAB> else: <TAB> <TAB> <TAB> scripts.append(f'<script defer src=""{script}""></script>') <TAB> return markup(""\n"".join(scripts))",false,"if script . startswith ( ""http"" ) :",elif subdir :,0.01,0.0
"def test_related_objects_local(self): <TAB> result_key = ""get_all_related_objects_with_model_local"" <TAB> for model, expected in TEST_RESULTS[result_key].items(): <TAB> <TAB> objects = [ <TAB> <TAB> <TAB> (field, self._model(model, field)) <TAB> <TAB> <TAB> for field in model._meta.get_fields(include_parents=False) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> ] <TAB> <TAB> self.assertEqual( <TAB> <TAB> <TAB> sorted(self._map_related_query_names(objects), key=self.key_name), <TAB> <TAB> <TAB> sorted(expected, key=self.key_name), <TAB> <TAB> )",false,if field . auto_created and not field . concrete,if field . related_query_names,0.09,0.0
"def setTestOutcome(self, event): <TAB> """"""Update outcome, exc_info and reason based on configured mappings"""""" <TAB> if event.exc_info: <TAB> <TAB> ec, ev, tb = event.exc_info <TAB> <TAB> classname = ec.__name__ <TAB> <TAB> if classname in self.treatAsFail: <TAB> <TAB> <TAB> short, long_ = self.labels(classname) <TAB> <TAB> <TAB> self._setOutcome(event, ""failed"", short, long_) <TAB> <TAB> elif classname in self.treatAsSkip: <TAB> <TAB> <TAB> short, long_ = self.labels(classname, upper=False) <TAB> <TAB> <TAB> self._setOutcome(event, ""skipped"", short, ""%s: '%s'"" % (long_, ev), str(ev))",true,elif classname in self . treatAsSkip :,elif classname in self . treatAsSkip :,0.75,0.0
"def small_count(v): <TAB> if not v: <TAB> <TAB> return 0 <TAB> z = [ <TAB> <TAB> (1000000000, _(""b"")), <TAB> <TAB> (1000000, _(""m"")), <TAB> <TAB> (1000, _(""k"")), <TAB> ] <TAB> v = int(v) <TAB> for x, y in z: <TAB> <TAB> o, p = divmod(v, x) <TAB> <TAB> if o: <TAB> <TAB> <TAB> if len(str(o)) > 2 or not p: <TAB> <TAB> <TAB> <TAB> return ""%d%s"" % (o, y) <TAB> <TAB> <TAB> return ""%.1f%s"" % (v / float(x), y) <TAB> return v",true,if len ( str ( o ) ) > 2 or not p :,if len ( str ( o ) ) > 2 or not p :,0.75,0.0
"def __read(self, n): <TAB> if self._read_watcher is None: <TAB> <TAB> raise UnsupportedOperation(""read"") <TAB> while 1: <TAB> <TAB> try: <TAB> <TAB> <TAB> return _read(self._fileno, n) <TAB> <TAB> except (IOError, OSError) as ex: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> wait_on_watcher(self._read_watcher, None, None, self.hub)",false,if ex . args [ 0 ] not in ignored_errors :,if ex . errno != errno . EINTR :,0.09,0.0
"def locked(self): <TAB> inputfiles = set(self.all_inputfiles()) <TAB> outputfiles = set(self.all_outputfiles()) <TAB> if os.path.exists(self._lockdir): <TAB> <TAB> for lockfile in self._locks(""input""): <TAB> <TAB> <TAB> with open(lockfile) as lock: <TAB> <TAB> <TAB> <TAB> for f in lock: <TAB> <TAB> <TAB> <TAB> <TAB> f = f.strip() <TAB> <TAB> <TAB> <TAB> <TAB> if f in outputfiles: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> for lockfile in self._locks(""output""): <TAB> <TAB> <TAB> with open(lockfile) as lock: <TAB> <TAB> <TAB> <TAB> for f in lock: <TAB> <TAB> <TAB> <TAB> <TAB> f = f.strip() <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",false,if f in outputfiles or f in inputfiles :,if f in inputfiles :,0.19,0.0
"def _flags_to_int(flags): <TAB> # Note, that order does not matter, libev has its own predefined order <TAB> if not flags: <TAB> <TAB> return 0 <TAB> if isinstance(flags, integer_types): <TAB> <TAB> return flags <TAB> result = 0 <TAB> try: <TAB> <TAB> if isinstance(flags, basestring): <TAB> <TAB> <TAB> flags = flags.split("","") <TAB> <TAB> for value in flags: <TAB> <TAB> <TAB> value = value.strip().lower() <TAB> <TAB> <TAB> if value: <TAB> <TAB> <TAB> <TAB> result |= _flags_str2int[value] <TAB> except KeyError as ex: <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> ""Invalid backend or flag: %s\nPossible values: %s"" <TAB> <TAB> <TAB> % (ex, "", "".join(sorted(_flags_str2int.keys()))) <TAB> <TAB> ) <TAB> return result",true,"if isinstance ( flags , basestring ) :","if isinstance ( flags , basestring ) :",0.75,0.0
"def setFg(self, colour, override=False): <TAB> if not self.ttkFlag: <TAB> <TAB> self.containerStack[-1][""fg""] = colour <TAB> <TAB> gui.SET_WIDGET_FG(self._getContainerProperty(""container""), colour, override) <TAB> <TAB> for child in self._getContainerProperty(""container"").winfo_children(): <TAB> <TAB> <TAB> if not self._isWidgetContainer(child): <TAB> <TAB> <TAB> <TAB> gui.SET_WIDGET_FG(child, colour, override) <TAB> else: <TAB> <TAB> gui.trace(""In ttk mode - trying to set FG to %s"", colour) <TAB> <TAB> self.ttkStyle.configure(""TLabel"", foreground=colour) <TAB> <TAB> self.ttkStyle.configure(""TFrame"", foreground=colour)",true,if not self . _isWidgetContainer ( child ) :,if not self . _isWidgetContainer ( child ) :,0.75,0.0
"def find_scintilla_constants(f): <TAB> lexers = [] <TAB> states = [] <TAB> for name in f.order: <TAB> <TAB> v = f.features[name] <TAB> <TAB> if v[""Category""] != ""Deprecated"": <TAB> <TAB> <TAB> if v[""FeatureType""] == ""val"": <TAB> <TAB> <TAB> <TAB> if name.startswith(""SCE_""): <TAB> <TAB> <TAB> <TAB> <TAB> states.append((name, v[""Value""])) <TAB> <TAB> <TAB> <TAB> elif name.startswith(""SCLEX_""): <TAB> <TAB> <TAB> <TAB> <TAB> lexers.append((name, v[""Value""])) <TAB> return (lexers, states)",false,"elif name . startswith ( ""SCLEX_"" ) :","if v [ ""FeatureType"" ] == ""val"" :",0.01,0.0
"def extract_error_message(response: requests.Response): <TAB> if response.content: <TAB> <TAB> try: <TAB> <TAB> <TAB> content = json.loads(response.content) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return content[""message""] <TAB> <TAB> except: <TAB> <TAB> <TAB> logging.debug(f""Failed to parse the response content: {response.content}"") <TAB> return response.reason",true,"if ""message"" in content :","if ""message"" in content :",0.75,0.0
"def canvas_size(self): <TAB> """"""Return the width and height for this sprite canvas"""""" <TAB> width = height = 0 <TAB> for image in self.images: <TAB> <TAB> x = image.x + image.absolute_width <TAB> <TAB> y = image.y + image.absolute_height <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> width = x <TAB> <TAB> if height < y: <TAB> <TAB> <TAB> height = y <TAB> return round_up(width), round_up(height)",true,if width < x :,if width < x :,0.75,0.0
"def _load_widgets(self): <TAB> logger.info(""Loading plugins preferences widgets"") <TAB> # Collect the preferences widget for each active plugin <TAB> for plugin in self.plugin_manager.get_active_plugins(): <TAB> <TAB> plugin_name = plugin.metadata.get(""name"") <TAB> <TAB> try: <TAB> <TAB> <TAB> preferences_widget = plugin.get_preferences_widget() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self._tabs.addTab(preferences_widget, plugin_name) <TAB> <TAB> except Exception as reason: <TAB> <TAB> <TAB> logger.error( <TAB> <TAB> <TAB> <TAB> ""Unable to add the preferences widget (%s): %s"", plugin_name, reason <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue",true,if preferences_widget :,if preferences_widget :,0.53,0.0
"def clean_objects(string, common_attributes): <TAB> """"""Return object and attribute lists"""""" <TAB> string = clean_string(string) <TAB> words = string.split() <TAB> if len(words) > 1: <TAB> <TAB> prefix_words_are_adj = True <TAB> <TAB> for att in words[:-1]: <TAB> <TAB> <TAB> if att not in common_attributes: <TAB> <TAB> <TAB> <TAB> prefix_words_are_adj = False <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return words[-1:], words[:-1] <TAB> <TAB> else: <TAB> <TAB> <TAB> return [string], [] <TAB> else: <TAB> <TAB> return [string], []",true,if prefix_words_are_adj :,if prefix_words_are_adj :,0.53,0.0
"def _reader(): <TAB> if shuffle: <TAB> <TAB> random.shuffle(file_list) <TAB> while True: <TAB> <TAB> for fn in file_list: <TAB> <TAB> <TAB> for line in open(fn, ""r""): <TAB> <TAB> <TAB> <TAB> yield self._process_line(line) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break",false,if not cycle :,if not self . is_running :,0.07,0.0
"def load(weights, model, K, fsz, dil): <TAB> index = 0 <TAB> layers = model.layers <TAB> for layer in layers._layers: <TAB> <TAB> if hasattr(layer, ""W""): <TAB> <TAB> <TAB> if layer.W.shape == weights[index].shape: <TAB> <TAB> <TAB> <TAB> layer.W[:] = weights[index] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> layer.W[:] = dilate(weights[index], K, fsz, dil) <TAB> <TAB> <TAB> index += 1",true,"if hasattr ( layer , ""W"" ) :","if hasattr ( layer , ""W"" ) :",0.75,0.0
"def upgrade(migrate_engine): <TAB> print(__doc__) <TAB> metadata.bind = migrate_engine <TAB> liftoverjobs = dict() <TAB> jobs = context.query(DeferredJob).filter_by(plugin=""LiftOverTransferPlugin"").all() <TAB> for job in jobs: <TAB> <TAB> if job.params[""parentjob""] not in liftoverjobs: <TAB> <TAB> <TAB> liftoverjobs[job.params[""parentjob""]] = [] <TAB> <TAB> liftoverjobs[job.params[""parentjob""]].append(job.id) <TAB> for parent in liftoverjobs: <TAB> <TAB> lifts = liftoverjobs[parent] <TAB> <TAB> deferred = context.query(DeferredJob).filter_by(id=parent).first() <TAB> <TAB> deferred.params[""liftover""] = lifts <TAB> context.flush()",true,"if job . params [ ""parentjob"" ] not in liftoverjobs :","if job . params [ ""parentjob"" ] not in liftoverjobs :",0.75,0.0
"def get_refs(self, recursive=False): <TAB> """""":see: AbstractExpression.get_refs()"""""" <TAB> if recursive: <TAB> <TAB> conds_refs = self.refs + sum((c.get_refs(True) for c in self.conds), []) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> conds_refs.extend(self.consequent.get_refs(True)) <TAB> <TAB> return conds_refs <TAB> else: <TAB> <TAB> return self.refs",true,if self . consequent :,if self . consequent :,0.75,0.0
"def _parse(self, engine): <TAB> """"""Parse the layer."""""" <TAB> if isinstance(self.args, dict): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.axis = engine.evaluate(self.args[""axis""], recursive=True) <TAB> <TAB> <TAB> if not isinstance(self.axis, int): <TAB> <TAB> <TAB> <TAB> raise ParsingError('""axis"" must be an integer.') <TAB> <TAB> if ""momentum"" in self.args: <TAB> <TAB> <TAB> self.momentum = engine.evaluate(self.args[""momentum""], recursive=True) <TAB> <TAB> <TAB> if not isinstance(self.momentum, (int, float)): <TAB> <TAB> <TAB> <TAB> raise ParsingError('""momentum"" must be numeric.')",true,"if ""axis"" in self . args :","if ""axis"" in self . args :",0.75,0.0
"def CountMatches(pat, predicate): <TAB> num_matches = 0 <TAB> for i in xrange(256): <TAB> <TAB> b = chr(i) <TAB> <TAB> m = pat.match(b) <TAB> <TAB> left = bool(m) <TAB> <TAB> right = predicate(i) <TAB> <TAB> if left != right: <TAB> <TAB> <TAB> self.fail(""i = %d, b = %r, match: %s, predicate: %s"" % (i, b, left, right)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> num_matches += 1 <TAB> return num_matches",true,if m :,if m :,0.53,0.0
"def __new__(cls, *args, **kwargs): <TAB> if len(args) == 1: <TAB> <TAB> if len(kwargs): <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""You can either use {} with one positional argument or with keyword arguments, not both."".format( <TAB> <TAB> <TAB> <TAB> <TAB> cls.__name__ <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> if not args[0]: <TAB> <TAB> <TAB> return super().__new__(cls) <TAB> <TAB> if isinstance(args[0], cls): <TAB> <TAB> <TAB> return cls <TAB> return super().__new__(cls, *args, **kwargs)",true,"if isinstance ( args [ 0 ] , cls ) :","if isinstance ( args [ 0 ] , cls ) :",0.75,0.0
"def concatenateCharacterTokens(tokens): <TAB> pendingCharacters = [] <TAB> for token in tokens: <TAB> <TAB> type = token[""type""] <TAB> <TAB> if type in (""Characters"", ""SpaceCharacters""): <TAB> <TAB> <TAB> pendingCharacters.append(token[""data""]) <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> yield {""type"": ""Characters"", ""data"": """".join(pendingCharacters)} <TAB> <TAB> <TAB> <TAB> pendingCharacters = [] <TAB> <TAB> <TAB> yield token <TAB> if pendingCharacters: <TAB> <TAB> yield {""type"": ""Characters"", ""data"": """".join(pendingCharacters)}",true,if pendingCharacters :,if pendingCharacters :,0.53,0.0
"def get_ranges_from_func_set(support_set): <TAB> pos_start = 0 <TAB> pos_end = 0 <TAB> ranges = [] <TAB> for pos, func in enumerate(network.function): <TAB> <TAB> if func.type in support_set: <TAB> <TAB> <TAB> pos_end = pos <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> ranges.append((pos_start, pos_end)) <TAB> <TAB> <TAB> pos_start = pos + 1 <TAB> if pos_end >= pos_start: <TAB> <TAB> ranges.append((pos_start, pos_end)) <TAB> return ranges",false,if pos_end >= pos_start :,if pos_start >= pos_end :,0.29,0.0
"def _visit(self, func): <TAB> fname = func[0] <TAB> if fname in self._flags: <TAB> <TAB> if self._flags[fname] == 1: <TAB> <TAB> <TAB> logger.critical(""Fatal error! network ins not Dag."") <TAB> <TAB> <TAB> import sys <TAB> <TAB> <TAB> sys.exit(-1) <TAB> <TAB> else: <TAB> <TAB> <TAB> return <TAB> else: <TAB> <TAB> if fname not in self._flags: <TAB> <TAB> <TAB> self._flags[fname] = 1 <TAB> <TAB> for output in func[3]: <TAB> <TAB> <TAB> for f in self._orig: <TAB> <TAB> <TAB> <TAB> for input in f[2]: <TAB> <TAB> <TAB> <TAB> <TAB> if output == input: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self._visit(f) <TAB> self._flags[fname] = 2 <TAB> self._sorted.insert(0, func)",false,if self . _flags [ fname ] == 1 :,if fname not in self . _flags :,0.06,0.0
"def graph_merge_softmax_with_crossentropy_softmax(node): <TAB> if node.op == softmax_with_bias: <TAB> <TAB> x, b = node.inputs <TAB> <TAB> for x_client in x.clients: <TAB> <TAB> <TAB> if x_client[0].op == crossentropy_softmax_argmax_1hot_with_bias: <TAB> <TAB> <TAB> <TAB> big_client = x_client[0] <TAB> <TAB> <TAB> <TAB> if big_client in [b_client[0] for b_client in b.clients]: <TAB> <TAB> <TAB> <TAB> <TAB> xx, bb, ll = big_client.inputs <TAB> <TAB> <TAB> <TAB> <TAB> mergeable_client = big_client.op(x, b, ll) <TAB> <TAB> <TAB> <TAB> <TAB> copy_stack_trace(node.outputs[0], mergeable_client[1]) <TAB> <TAB> <TAB> <TAB> <TAB> return [mergeable_client[1]]",false,if x_client [ 0 ] . op == crossentropy_softmax_argmax_1hot_with_bias :,if big_client in [ b_client [ 0 ] for b_client in b . clients ] :,0.05,0.0
"def confidence(self): <TAB> if self.bbox: <TAB> <TAB> # Units are measured in Kilometers <TAB> <TAB> distance = Distance(self.northeast, self.southwest, units=""km"") <TAB> <TAB> for score, maximum in [ <TAB> <TAB> <TAB> (10, 0.25), <TAB> <TAB> <TAB> (9, 0.5), <TAB> <TAB> <TAB> (8, 1), <TAB> <TAB> <TAB> (7, 5), <TAB> <TAB> <TAB> (6, 7.5), <TAB> <TAB> <TAB> (5, 10), <TAB> <TAB> <TAB> (4, 15), <TAB> <TAB> <TAB> (3, 20), <TAB> <TAB> <TAB> (2, 25), <TAB> <TAB> ]: <TAB> <TAB> <TAB> if distance < maximum: <TAB> <TAB> <TAB> <TAB> return score <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return 1 <TAB> # Cannot determine score <TAB> return 0",false,if distance >= 25 :,if distance > maximum :,0.06,0.0
"def OnListEndLabelEdit(self, std, extra): <TAB> item = extra[0] <TAB> text = item[4] <TAB> if text is None: <TAB> <TAB> return <TAB> item_id = self.GetItem(item[0])[6] <TAB> from bdb import Breakpoint <TAB> for bplist in Breakpoint.bplist.itervalues(): <TAB> <TAB> for bp in bplist: <TAB> <TAB> <TAB> if id(bp) == item_id: <TAB> <TAB> <TAB> <TAB> if text.strip().lower() == ""none"": <TAB> <TAB> <TAB> <TAB> <TAB> text = None <TAB> <TAB> <TAB> <TAB> bp.cond = text <TAB> <TAB> <TAB> <TAB> break <TAB> self.RespondDebuggerData()",true,"if text . strip ( ) . lower ( ) == ""none"" :","if text . strip ( ) . lower ( ) == ""none"" :",0.75,0.0
"def _handle_autocomplete_request_for_text(text): <TAB> if not hasattr(text, ""autocompleter""): <TAB> <TAB> if isinstance(text, (CodeViewText, ShellText)) and text.is_python_text(): <TAB> <TAB> <TAB> if isinstance(text, CodeViewText): <TAB> <TAB> <TAB> <TAB> text.autocompleter = Completer(text) <TAB> <TAB> <TAB> elif isinstance(text, ShellText): <TAB> <TAB> <TAB> <TAB> text.autocompleter = ShellCompleter(text) <TAB> <TAB> <TAB> text.bind(""<1>"", text.autocompleter.on_text_click) <TAB> <TAB> else: <TAB> <TAB> <TAB> return <TAB> text.autocompleter.handle_autocomplete_request()",true,"if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) :","if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) :",1.0,0.0
"def visit_Macro(self, node, frame): <TAB> macro_frame, macro_ref = self.macro_body(node, frame) <TAB> self.newline() <TAB> if frame.toplevel: <TAB> <TAB> if not node.name.startswith(""_""): <TAB> <TAB> <TAB> self.write(""context.exported_vars.add(%r)"" % node.name) <TAB> <TAB> ref = frame.symbols.ref(node.name) <TAB> <TAB> self.writeline(""context.vars[%r] = "" % node.name) <TAB> self.write(""%s = "" % frame.symbols.ref(node.name)) <TAB> self.macro_def(macro_ref, macro_frame)",true,"if not node . name . startswith ( ""_"" ) :","if not node . name . startswith ( ""_"" ) :",0.75,0.0
"def execute(cls, ctx, op): <TAB> try: <TAB> <TAB> pd.set_option(""mode.use_inf_as_na"", op.use_inf_as_na) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return cls._execute_map(ctx, op) <TAB> <TAB> else: <TAB> <TAB> <TAB> return cls._execute_combine(ctx, op) <TAB> finally: <TAB> <TAB> pd.reset_option(""mode.use_inf_as_na"")",false,if op . stage == OperandStage . map :,if ctx . map_mode :,0.08,0.0
"def ranges(self, start, end): <TAB> try: <TAB> <TAB> iterators = [i.ranges(start, end) for i in self.range_iterators] <TAB> <TAB> starts, ends, values = zip(*[next(i) for i in iterators]) <TAB> <TAB> starts = list(starts) <TAB> <TAB> ends = list(ends) <TAB> <TAB> values = list(values) <TAB> <TAB> while start < end: <TAB> <TAB> <TAB> min_end = min(ends) <TAB> <TAB> <TAB> yield start, min_end, values <TAB> <TAB> <TAB> start = min_end <TAB> <TAB> <TAB> for i, iterator in enumerate(iterators): <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> starts[i], ends[i], values[i] = next(iterator) <TAB> except StopIteration: <TAB> <TAB> return",false,if ends [ i ] == min_end :,if i in starts :,0.02,0.0
"def get_explanation(self, spec): <TAB> """"""Expand an explanation."""""" <TAB> if spec: <TAB> <TAB> try: <TAB> <TAB> <TAB> a = self.dns_txt(spec) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return str(self.expand(to_ascii(a[0]), stripdot=False)) <TAB> <TAB> except PermError: <TAB> <TAB> <TAB> # RFC4408 6.2/4 syntax errors cause exp= to be ignored <TAB> <TAB> <TAB> if self.strict > 1: <TAB> <TAB> <TAB> <TAB> raise  # but report in harsh mode for record checking tools <TAB> <TAB> <TAB> pass <TAB> elif self.strict > 1: <TAB> <TAB> raise PermError(""Empty domain-spec on exp="") <TAB> # RFC4408 6.2/4 empty domain spec is ignored <TAB> # (unless you give precedence to the grammar). <TAB> return None",true,if len ( a ) == 1 :,if len ( a ) == 1 :,0.75,0.0
"def iter_fields(node, *, include_meta=True, exclude_unset=False): <TAB> exclude_meta = not include_meta <TAB> for field_name, field in node._fields.items(): <TAB> <TAB> if exclude_meta and field.meta: <TAB> <TAB> <TAB> continue <TAB> <TAB> field_val = getattr(node, field_name, _marker) <TAB> <TAB> if field_val is _marker: <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if callable(field.default): <TAB> <TAB> <TAB> <TAB> default = field.default() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> default = field.default <TAB> <TAB> <TAB> if field_val == default: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield field_name, field_val",true,if exclude_unset :,if exclude_unset :,0.53,0.0
"def __setattr__(self, name, value): <TAB> try: <TAB> <TAB> field = self._meta.get_field(name) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> value = value[: field.max_length] <TAB> except models.fields.FieldDoesNotExist: <TAB> <TAB> pass  # This happens with foreign keys. <TAB> super.__setattr__(self, name, value)",false,"if type ( field ) in [ models . CharField , models . TextField ] and type ( value ) == str :",if field . max_length :,0.03,0.0
"def create_child(self, value=None, _id=None): <TAB> with atomic(savepoint=False): <TAB> <TAB> child_key = self.get_next_child_key() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> value = child_key <TAB> <TAB> child = self.__class__.objects.create(id=_id, key=child_key, value=value) <TAB> <TAB> return child",true,if value is None :,if value is None :,0.75,0.0
"def list_tags_for_stream(self, stream_name, exclusive_start_tag_key=None, limit=None): <TAB> stream = self.describe_stream(stream_name) <TAB> tags = [] <TAB> result = {""HasMoreTags"": False, ""Tags"": tags} <TAB> for key, val in sorted(stream.tags.items(), key=lambda x: x[0]): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result[""HasMoreTags""] = True <TAB> <TAB> <TAB> break <TAB> <TAB> if exclusive_start_tag_key and key < exclusive_start_tag_key: <TAB> <TAB> <TAB> continue <TAB> <TAB> tags.append({""Key"": key, ""Value"": val}) <TAB> return result",false,if limit and len ( tags ) >= limit :,if limit and limit [ key ] > limit :,0.16,0.0
"def emit(self, record): <TAB> try: <TAB> <TAB> app = get_app() <TAB> <TAB> if app.is_running and getattr(app, ""debug"", False): <TAB> <TAB> <TAB> msg = self.format(record) <TAB> <TAB> <TAB> debug_buffer = app.layout.get_buffer_by_name(""debug_buffer"") <TAB> <TAB> <TAB> current_document = debug_buffer.document.text <TAB> <TAB> <TAB> if current_document: <TAB> <TAB> <TAB> <TAB> msg = ""\n"".join([current_document, msg]) <TAB> <TAB> <TAB> debug_buffer.set_document(Document(text=msg), bypass_readonly=True) <TAB> <TAB> else: <TAB> <TAB> <TAB> super().emit(record) <TAB> except: <TAB> <TAB> self.handleError(record)",true,"if app . is_running and getattr ( app , ""debug"" , False ) :","if app . is_running and getattr ( app , ""debug"" , False ) :",0.75,0.0
"def worker(): <TAB> global error <TAB> while True: <TAB> <TAB> (num, q) = pq.get() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> pq.task_done() <TAB> <TAB> <TAB> break <TAB> <TAB> try: <TAB> <TAB> <TAB> process_one(q) <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> error = e <TAB> <TAB> finally: <TAB> <TAB> <TAB> pq.task_done()",false,if q is None or error is not None :,if num is None :,0.22,0.0
"def transceiver(self, data): <TAB> out = [] <TAB> for t in range(8): <TAB> <TAB> if data[t] == 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> value = data[t] <TAB> <TAB> for b in range(8): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if len(TRANSCEIVER[t]) < b + 1: <TAB> <TAB> <TAB> <TAB> <TAB> out.append(""(unknown)"") <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> out.append(TRANSCEIVER[t][b]) <TAB> <TAB> <TAB> value <<= 1 <TAB> self.annotate(""Transceiver compliance"", "", "".join(out))",true,if value & 0x80 :,if value & 0x80 :,0.75,0.0
"def skip_to_close_match(self): <TAB> nestedCount = 1 <TAB> while 1: <TAB> <TAB> tok = self.tokenizer.get_next_token() <TAB> <TAB> ttype = tok[""style""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> elif self.classifier.is_index_op(tok): <TAB> <TAB> <TAB> tval = tok[""text""] <TAB> <TAB> <TAB> if self.opHash.has_key(tval): <TAB> <TAB> <TAB> <TAB> if self.opHash[tval][1] == 1: <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount += 1 <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount -= 1 <TAB> <TAB> <TAB> <TAB> <TAB> if nestedCount <= 0: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break",false,if ttype == SCE_PL_UNUSED :,"if ttype == ""end"" or ttype == ""end"" or ttype == ""end"" or ttype == ""end"" or ttype == ""end"" or ttype == ""end"" or ttype == ""end"" or ttype == ""end"" or ttype == ""end"" or ttype == ""end"" or ttype == ""end"" or ttype == ""end"" or ttype == ""end"" or ttype == ""end"" or ttype == ""end"" or ttype == ""end"" or ttype",0.07,0.0
"def GenerateVector(self, hits, vector, level): <TAB> """"""Generate possible hit vectors which match the rules."""""" <TAB> for item in hits.get(level, []): <TAB> <TAB> if vector: <TAB> <TAB> <TAB> if item < vector[-1]: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if item > self.max_separation + vector[-1]: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> new_vector = vector + [item] <TAB> <TAB> if level + 1 == len(hits): <TAB> <TAB> <TAB> yield new_vector <TAB> <TAB> elif level + 1 < len(hits): <TAB> <TAB> <TAB> for result in self.GenerateVector(hits, new_vector, level + 1): <TAB> <TAB> <TAB> <TAB> yield result",false,if item < vector [ - 1 ] :,if item > self . max_separation + vector [ - 1 ] :,0.37,0.0
"def __setattr__(self, name, value): <TAB> if name == ""path"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if value[0] != ""/"": <TAB> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> <TAB> 'The page path should always start with a slash (""/"").' <TAB> <TAB> <TAB> <TAB> ) <TAB> elif name == ""load_time"": <TAB> <TAB> if value and not isinstance(value, int): <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""Page load time must be specified in integer milliseconds."" <TAB> <TAB> <TAB> ) <TAB> object.__setattr__(self, name, value)",false,"if value and value != """" :",if value :,0.04,0.0
"def awaitTermination(self, timeout=None): <TAB> if self.scheduler is None: <TAB> <TAB> raise RuntimeError(""StreamimgContext not started"") <TAB> try: <TAB> <TAB> deadline = time.time() + timeout if timeout is not None else None <TAB> <TAB> while True: <TAB> <TAB> <TAB> is_terminated = self._runOnce() <TAB> <TAB> <TAB> if is_terminated or (deadline is not None and time.time() > deadline): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if self.batchCallback: <TAB> <TAB> <TAB> <TAB> self.batchCallback() <TAB> except KeyboardInterrupt: <TAB> <TAB> pass <TAB> finally: <TAB> <TAB> self.sc.stop() <TAB> <TAB> logger.info(""StreamingContext stopped successfully"")",true,if is_terminated or ( deadline is not None and time . time ( ) > deadline ) :,if is_terminated or ( deadline is not None and time . time ( ) > deadline ) :,1.0,0.0
"def stopbutton(self): <TAB> if GPIOcontrol: <TAB> <TAB> while mediastopbutton: <TAB> <TAB> <TAB> time.sleep(0.25) <TAB> <TAB> <TAB> if not GPIO.input(stoppushbutton): <TAB> <TAB> <TAB> <TAB> print(""Stopped"") <TAB> <TAB> <TAB> <TAB> stop()",true,if not GPIO . input ( stoppushbutton ) :,if not GPIO . input ( stoppushbutton ) :,0.75,0.0
"def test_create_connection_timeout(self): <TAB> # Issue #9792: create_connection() should not recast timeout errors <TAB> # as generic socket errors. <TAB> with self.mocked_socket_module(): <TAB> <TAB> try: <TAB> <TAB> <TAB> socket.create_connection((HOST, 1234)) <TAB> <TAB> except socket.timeout: <TAB> <TAB> <TAB> pass <TAB> <TAB> except OSError as exc: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> else: <TAB> <TAB> <TAB> self.fail(""socket.timeout not raised"")",false,if support . IPV6_ENABLED or exc . errno != errno . EAFNOSUPPORT :,if exc . errno != errno . ECONNREFUSED :,0.58,0.0
"def handle_exception_and_die(e): <TAB> if hasattr(e, ""kind""): <TAB> <TAB> if e.kind == ""die"": <TAB> <TAB> <TAB> sys.stderr.write(""ABORT: "" + e.msg + ""\n"") <TAB> <TAB> <TAB> sys.exit(e.value) <TAB> <TAB> elif e.kind == ""exit"": <TAB> <TAB> <TAB> sys.stderr.write(""EXITING\n"") <TAB> <TAB> <TAB> sys.exit(e.value) <TAB> else: <TAB> <TAB> print(str(e)) <TAB> <TAB> sys.exit(1)",false,"if e . kind == ""die"" :","elif e . kind == ""exit"" :",0.21,0.0
"def gets(self, key): <TAB> with self.client_pool.get_and_release(destroy_on_fail=True) as client: <TAB> <TAB> try: <TAB> <TAB> <TAB> return client.gets(key) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return (None, None) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise",false,if self . ignore_exc :,if self . fail_silently :,0.39,0.0
"def _execute(self, options, args): <TAB> if len(args) < 3: <TAB> <TAB> raise CommandError(_(""Not enough arguments"")) <TAB> tag = fsn2text(args[0]) <TAB> value = fsn2text(args[1]) <TAB> paths = args[2:] <TAB> songs = [] <TAB> for path in paths: <TAB> <TAB> song = self.load_song(path) <TAB> <TAB> if not song.can_change(tag): <TAB> <TAB> <TAB> raise CommandError(_(""Can not set %r"") % tag) <TAB> <TAB> self.log(""Add %r to %r"" % (value, tag)) <TAB> <TAB> song.add(tag, value) <TAB> <TAB> songs.append(song) <TAB> self.save_songs(songs)",true,if not song . can_change ( tag ) :,if not song . can_change ( tag ) :,0.75,0.0
"def get_place_name(self, place_handle): <TAB> """"""Obtain a place name"""""" <TAB> text = """" <TAB> if place_handle: <TAB> <TAB> place = self.dbstate.db.get_place_from_handle(place_handle) <TAB> <TAB> if place: <TAB> <TAB> <TAB> place_title = place_displayer.display(self.dbstate.db, place) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if len(place_title) > 25: <TAB> <TAB> <TAB> <TAB> <TAB> text = place_title[:24] + ""..."" <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> text = place_title <TAB> return text",false,"if place_title != """" :",if len ( place_title ) > 24 :,0.03,0.0
"def _Determine_Do(self): <TAB> self.applicable = 1 <TAB> self.value = os.environ.get(self.name, None) <TAB> if self.value is None and black.configure.items.has_key(""buildType""): <TAB> <TAB> buildType = black.configure.items[""buildType""].Get() <TAB> <TAB> if buildType == ""debug"": <TAB> <TAB> <TAB> self.value = ""warn"" <TAB> <TAB> else: <TAB> <TAB> <TAB> self.value = None <TAB> self.determined = 1",true,"if buildType == ""debug"" :","if buildType == ""debug"" :",0.75,0.0
"def bundle_directory(self, dirpath): <TAB> """"""Bundle all modules/packages in the given directory."""""" <TAB> dirpath = os.path.abspath(dirpath) <TAB> for nm in os.listdir(dirpath): <TAB> <TAB> nm = _u(nm) <TAB> <TAB> if nm.startswith("".""): <TAB> <TAB> <TAB> continue <TAB> <TAB> itempath = os.path.join(dirpath, nm) <TAB> <TAB> if os.path.isdir(itempath): <TAB> <TAB> <TAB> if os.path.exists(os.path.join(itempath, ""__init__.py"")): <TAB> <TAB> <TAB> <TAB> self.bundle_package(itempath) <TAB> <TAB> elif nm.endswith("".py""): <TAB> <TAB> <TAB> self.bundle_module(itempath)",false,"if nm . startswith ( ""."" ) :",if os . path . isdir ( itempath ) :,0.03,0.0
"def header_fields(self, fields): <TAB> headers = dict(self.conn.response.getheaders()) <TAB> ret = {} <TAB> for field in fields: <TAB> <TAB> if not headers.has_key(field[1]): <TAB> <TAB> <TAB> raise ValueError(""%s was not found in response header"" % (field[1])) <TAB> <TAB> try: <TAB> <TAB> <TAB> ret[field[0]] = int(headers[field[1]]) <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> ret[field[0]] = headers[field[1]] <TAB> return ret",true,if not headers . has_key ( field [ 1 ] ) :,if not headers . has_key ( field [ 1 ] ) :,0.75,0.0
"def caesar_cipher(s, k): <TAB> result = """" <TAB> for char in s: <TAB> <TAB> n = ord(char) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> n = ((n - 65 + k) % 26) + 65 <TAB> <TAB> if 96 < n < 123: <TAB> <TAB> <TAB> n = ((n - 97 + k) % 26) + 97 <TAB> <TAB> result = result + chr(n) <TAB> return result",false,if 64 < n < 91 :,if 65 < n < 65 :,0.34,0.0
"def qtTypeIdent(conn, *args): <TAB> # We're not using the conn object at the moment, but - we will <TAB> # modify the <TAB> # logic to use the server version specific keywords later. <TAB> res = None <TAB> value = None <TAB> for val in args: <TAB> <TAB> # DataType doesn't have len function then convert it to string <TAB> <TAB> if not hasattr(val, ""__len__""): <TAB> <TAB> <TAB> val = str(val) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> value = val <TAB> <TAB> if Driver.needsQuoting(val, True): <TAB> <TAB> <TAB> value = value.replace('""', '""""') <TAB> <TAB> <TAB> value = '""' + value + '""' <TAB> <TAB> res = ((res and res + ""."") or """") + value <TAB> return res",false,if len ( val ) == 0 :,if value is None :,0.02,0.0
"def _parse_timezone( <TAB> value: Optional[str], error: Type[Exception] ) -> Union[None, int, timezone]: <TAB> if value == ""Z"": <TAB> <TAB> return timezone.utc <TAB> elif value is not None: <TAB> <TAB> offset_mins = int(value[-2:]) if len(value) > 3 else 0 <TAB> <TAB> offset = 60 * int(value[1:3]) + offset_mins <TAB> <TAB> if value[0] == ""-"": <TAB> <TAB> <TAB> offset = -offset <TAB> <TAB> try: <TAB> <TAB> <TAB> return timezone(timedelta(minutes=offset)) <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> raise error() <TAB> else: <TAB> <TAB> return None",true,"if value [ 0 ] == ""-"" :","if value [ 0 ] == ""-"" :",0.75,0.0
"def indent(elem, level=0): <TAB> i = ""\n"" + level * ""  "" <TAB> if len(elem): <TAB> <TAB> if not elem.text or not elem.text.strip(): <TAB> <TAB> <TAB> elem.text = i + ""  "" <TAB> <TAB> if not elem.tail or not elem.tail.strip(): <TAB> <TAB> <TAB> elem.tail = i <TAB> <TAB> for elem in elem: <TAB> <TAB> <TAB> indent(elem, level + 1) <TAB> <TAB> if not elem.tail or not elem.tail.strip(): <TAB> <TAB> <TAB> elem.tail = i <TAB> else: <TAB> <TAB> if level and (not elem.tail or not elem.tail.strip()): <TAB> <TAB> <TAB> elem.tail = i",false,if not elem . tail or not elem . tail . strip ( ) :,if level and ( not elem . tail or not elem . tail . strip ( ) ) :,0.52,0.0
"def _make_slices( <TAB> shape: tp.Tuple[int, ...], <TAB> axes: tp.Tuple[int, ...], <TAB> size: int, <TAB> rng: np.random.RandomState, ) -> tp.List[slice]: <TAB> slices = [] <TAB> for a, s in enumerate(shape): <TAB> <TAB> if a in axes: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise ValueError(""Cannot crossover on axis with size 1"") <TAB> <TAB> <TAB> start = rng.randint(s - size) <TAB> <TAB> <TAB> slices.append(slice(start, start + size)) <TAB> <TAB> else: <TAB> <TAB> <TAB> slices.append(slice(None)) <TAB> return slices",false,if s <= 1 :,if s < 1 :,0.33,0.0
"def _loadTestsFromTestCase(self, event, testCaseClass): <TAB> evt = events.LoadFromTestCaseEvent(event.loader, testCaseClass) <TAB> result = self.session.hooks.loadTestsFromTestCase(evt) <TAB> if evt.handled: <TAB> <TAB> loaded_suite = result or event.loader.suiteClass() <TAB> else: <TAB> <TAB> names = self._getTestCaseNames(event, testCaseClass) <TAB> <TAB> if not names and hasattr(testCaseClass, ""runTest""): <TAB> <TAB> <TAB> names = [""runTest""] <TAB> <TAB> # FIXME return failure test case if name not in testcase class <TAB> <TAB> loaded_suite = event.loader.suiteClass(map(testCaseClass, names)) <TAB> if evt.extraTests: <TAB> <TAB> loaded_suite.addTests(evt.extraTests) <TAB> return loaded_suite",true,"if not names and hasattr ( testCaseClass , ""runTest"" ) :","if not names and hasattr ( testCaseClass , ""runTest"" ) :",0.75,0.0
"def check_settings(self): <TAB> if self.settings_dict[""TIME_ZONE""] is not None: <TAB> <TAB> if not settings.USE_TZ: <TAB> <TAB> <TAB> raise ImproperlyConfigured( <TAB> <TAB> <TAB> <TAB> ""Connection '%s' cannot set TIME_ZONE because USE_TZ is "" <TAB> <TAB> <TAB> <TAB> ""False."" % self.alias <TAB> <TAB> <TAB> ) <TAB> <TAB> elif self.features.supports_timezones: <TAB> <TAB> <TAB> raise ImproperlyConfigured( <TAB> <TAB> <TAB> <TAB> ""Connection '%s' cannot set TIME_ZONE because its engine "" <TAB> <TAB> <TAB> <TAB> ""handles time zones conversions natively."" % self.alias <TAB> <TAB> <TAB> )",true,elif self . features . supports_timezones :,elif self . features . supports_timezones :,0.75,0.0
"def collect_conflicting_diffs(path, decisions): <TAB> local_conflict_diffs = [] <TAB> remote_conflict_diffs = [] <TAB> for d in decisions: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ld = adjust_patch_level(path, d.common_path, d.local_diff) <TAB> <TAB> <TAB> rd = adjust_patch_level(path, d.common_path, d.remote_diff) <TAB> <TAB> <TAB> local_conflict_diffs.extend(ld) <TAB> <TAB> <TAB> remote_conflict_diffs.extend(rd) <TAB> return local_conflict_diffs, remote_conflict_diffs",false,if d . conflict :,if d . local_diff :,0.39,0.0
"def short_repr(obj): <TAB> if isinstance( <TAB> <TAB> obj, <TAB> <TAB> (type, types.ModuleType, types.BuiltinMethodType, types.BuiltinFunctionType), <TAB> ): <TAB> <TAB> return obj.__name__ <TAB> if isinstance(obj, types.MethodType): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return obj.im_func.__name__ + "" (bound)"" <TAB> <TAB> else: <TAB> <TAB> <TAB> return obj.im_func.__name__ <TAB> if isinstance(obj, (tuple, list, dict, set)): <TAB> <TAB> return ""%d items"" % len(obj) <TAB> if isinstance(obj, weakref.ref): <TAB> <TAB> return ""all_weakrefs_are_one"" <TAB> return repr(obj)[:40]",false,if obj . im_self is not None :,if type ( obj ) is types . FunctionType :,0.02,0.0
"def _massage_uri(uri): <TAB> if uri: <TAB> <TAB> if uri.startswith(""hdfs:///""): <TAB> <TAB> <TAB> uri = uri.replace(""hdfs://"", get_defaultfs()) <TAB> <TAB> elif uri.startswith(""/""): <TAB> <TAB> <TAB> uri = get_defaultfs() + uri <TAB> return uri",false,"if uri . startswith ( ""hdfs:///"" ) :","elif uri . startswith ( ""/"" ) :",0.2,0.0
"def chsub(self, msg, chatid): <TAB> (cmd, evt, params) = self.tokenize(msg, 3) <TAB> if cmd == ""/sub"": <TAB> <TAB> sql = ""replace into telegram_subscriptions(uid, event_type, parameters) values (?, ?, ?)"" <TAB> else: <TAB> <TAB> if evt == ""everything"": <TAB> <TAB> <TAB> sql = ""delete from telegram_subscriptions where uid = ? and (event_type = ? or parameters = ? or 1 = 1)""  # does not look very elegant, but makes unsub'ing everythign possible <TAB> <TAB> else: <TAB> <TAB> <TAB> sql = ""delete from telegram_subscriptions where uid = ? and event_type = ? and parameters = ?"" <TAB> with self.bot.database as conn: <TAB> <TAB> conn.execute(sql, [chatid, evt, params]) <TAB> <TAB> conn.commit() <TAB> return",true,"if evt == ""everything"" :","if evt == ""everything"" :",0.75,0.0
"def undefined_symbols(self): <TAB> result = [] <TAB> for p in self.Productions: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> for s in p.prod: <TAB> <TAB> <TAB> if not s in self.Prodnames and not s in self.Terminals and s != ""error"": <TAB> <TAB> <TAB> <TAB> result.append((s, p)) <TAB> return result",false,if not p :,if p . name in self . Productionnames :,0.04,0.0
"def renumber(self, x1, y1, x2, y2, dx, dy): <TAB> out = [] <TAB> for part in re.split(""(\w+)"", self.formula): <TAB> <TAB> m = re.match(""^([A-Z]+)([1-9][0-9]*)$"", part) <TAB> <TAB> if m is not None: <TAB> <TAB> <TAB> sx, sy = m.groups() <TAB> <TAB> <TAB> x = colname2num(sx) <TAB> <TAB> <TAB> y = int(sy) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> part = cellname(x + dx, y + dy) <TAB> <TAB> out.append(part) <TAB> return FormulaCell("""".join(out), self.fmt, self.alignment)",false,if x1 <= x <= x2 and y1 <= y <= y2 :,if x != x2 and y != y :,0.06,0.0
"def modify_column(self, column: List[Optional[""Cell""]]): <TAB> for i in range(len(column)): <TAB> <TAB> gate = column[i] <TAB> <TAB> if gate is self: <TAB> <TAB> <TAB> continue <TAB> <TAB> elif isinstance(gate, ParityControlCell): <TAB> <TAB> <TAB> # The first parity control to modify the column must merge all <TAB> <TAB> <TAB> # of the other parity controls into itself. <TAB> <TAB> <TAB> column[i] = None <TAB> <TAB> <TAB> self._basis_change += gate._basis_change <TAB> <TAB> <TAB> self.qubits += gate.qubits <TAB> <TAB> elif gate is not None: <TAB> <TAB> <TAB> column[i] = gate.controlled_by(self.qubits[0])",true,"elif isinstance ( gate , ParityControlCell ) :","elif isinstance ( gate , ParityControlCell ) :",0.75,0.0
"def update_neighbor(neigh_ip_address, changes): <TAB> rets = [] <TAB> for k, v in changes.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> rets.append(_update_med(neigh_ip_address, v)) <TAB> <TAB> if k == neighbors.ENABLED: <TAB> <TAB> <TAB> rets.append(update_neighbor_enabled(neigh_ip_address, v)) <TAB> <TAB> if k == neighbors.CONNECT_MODE: <TAB> <TAB> <TAB> rets.append(_update_connect_mode(neigh_ip_address, v)) <TAB> return all(rets)",false,if k == neighbors . MULTI_EXIT_DISC :,if k == neighbors . MONGO :,0.57,0.0
"def writexml( <TAB> self, <TAB> stream, <TAB> indent="""", <TAB> addindent="""", <TAB> newl="""", <TAB> strip=0, <TAB> nsprefixes={}, <TAB> namespace="""", ): <TAB> w = _streamWriteWrapper(stream) <TAB> if self.raw: <TAB> <TAB> val = self.nodeValue <TAB> <TAB> if not isinstance(val, str): <TAB> <TAB> <TAB> val = str(self.nodeValue) <TAB> else: <TAB> <TAB> v = self.nodeValue <TAB> <TAB> if not isinstance(v, str): <TAB> <TAB> <TAB> v = str(v) <TAB> <TAB> if strip: <TAB> <TAB> <TAB> v = "" "".join(v.split()) <TAB> <TAB> val = escape(v) <TAB> w(val)",true,"if not isinstance ( v , str ) :","if not isinstance ( v , str ) :",0.75,0.0
"def _condition(ct): <TAB> for qobj in args: <TAB> <TAB> if qobj.connector == ""AND"" and not qobj.negated: <TAB> <TAB> <TAB> # normal kwargs are an AND anyway, so just use those for now <TAB> <TAB> <TAB> for child in qobj.children: <TAB> <TAB> <TAB> <TAB> kwargs.update(dict([child])) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise NotImplementedError(""Unsupported Q object"") <TAB> for attr, val in kwargs.items(): <TAB> <TAB> if getattr(ct, attr) != val: <TAB> <TAB> <TAB> return False <TAB> return True",false,"if qobj . connector == ""AND"" and not qobj . negated :","if getattr ( ct , attr ) != val :",0.01,0.0
"def results_iter(self): <TAB> if self.connection.ops.oracle: <TAB> <TAB> from django.db.models.fields import DateTimeField <TAB> <TAB> fields = [DateTimeField()] <TAB> else: <TAB> <TAB> needs_string_cast = self.connection.features.needs_datetime_string_cast <TAB> offset = len(self.query.extra_select) <TAB> for rows in self.execute_sql(MULTI): <TAB> <TAB> for row in rows: <TAB> <TAB> <TAB> date = row[offset] <TAB> <TAB> <TAB> if self.connection.ops.oracle: <TAB> <TAB> <TAB> <TAB> date = self.resolve_columns(row, fields)[offset] <TAB> <TAB> <TAB> elif needs_string_cast: <TAB> <TAB> <TAB> <TAB> date = typecast_timestamp(str(date)) <TAB> <TAB> <TAB> yield date",false,if self . connection . ops . oracle :,elif needs_string_cast :,0.01,0.0
"def get_job_type(self): <TAB> if int(self.job_runtime_conf.get(""dsl_version"", 1)) == 2: <TAB> <TAB> job_type = ( <TAB> <TAB> <TAB> self.job_runtime_conf[""job_parameters""].get(""common"", {}).get(""job_type"") <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> job_type = self.job_runtime_conf[""job_parameters""].get(""job_type"", ""train"") <TAB> else: <TAB> <TAB> job_type = self.job_runtime_conf[""job_parameters""].get(""job_type"", ""train"") <TAB> return job_type",false,if not job_type :,if job_type is None :,0.05,0.0
"def validate_assessment_criteria(self): <TAB> if self.assessment_criteria: <TAB> <TAB> total_weightage = 0 <TAB> <TAB> for criteria in self.assessment_criteria: <TAB> <TAB> <TAB> total_weightage += criteria.weightage or 0 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> frappe.throw(_(""Total Weightage of all Assessment Criteria must be 100%""))",false,if total_weightage != 100 :,if total_weightage > 100 :,0.33,0.0
"def get_list_of_strings_to_mongo_objects(self, notifications_list=None): <TAB> result = [] <TAB> if len(notifications_list) > 0: <TAB> <TAB> for x in notifications_list: <TAB> <TAB> <TAB> split_provider_id = x.split("":"")  # email:id <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> _id = split_provider_id[1] <TAB> <TAB> <TAB> <TAB> cursor = self.get_by_id(_id) <TAB> <TAB> <TAB> <TAB> if cursor:  # Append if exists <TAB> <TAB> <TAB> <TAB> <TAB> result.append(cursor) <TAB> return result",false,if len ( split_provider_id ) == 2 :,if len ( split_provider_id ) > 1 :,0.52,0.0
"def dump_predictions_to_database(relation, predictions): <TAB> judge = ""iepy-run on {}"".format(datetime.now().strftime(""%Y-%m-%d %H:%M"")) <TAB> for evidence, relation_is_present in predictions.items(): <TAB> <TAB> label = ( <TAB> <TAB> <TAB> EvidenceLabel.YESRELATION <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> else EvidenceLabel.NORELATION <TAB> <TAB> ) <TAB> <TAB> evidence.set_label(relation, label, judge, labeled_by_machine=True)",true,if relation_is_present,if relation_is_present,0.41,0.0
"def __init__(self, **kwargs): <TAB> # We hard-code the `to` argument for ForeignKey.__init__ <TAB> dfl = get_model_label(self.default_model_class) <TAB> if ""to"" in kwargs.keys():  # pragma: no cover <TAB> <TAB> old_to = get_model_label(kwargs.pop(""to"")) <TAB> <TAB> if old_to.lower() != dfl.lower(): <TAB> <TAB> <TAB> msg = ""%s can only be a ForeignKey to %s; %s passed"" % ( <TAB> <TAB> <TAB> <TAB> self.__class__.__name__, <TAB> <TAB> <TAB> <TAB> dfl, <TAB> <TAB> <TAB> <TAB> old_to, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> warnings.warn(msg, SyntaxWarning) <TAB> kwargs[""to""] = dfl <TAB> super().__init__(**kwargs)",true,if old_to . lower ( ) != dfl . lower ( ) :,if old_to . lower ( ) != dfl . lower ( ) :,1.0,0.0
"def reverse(self): <TAB> """"""Reverse *IN PLACE*."""""" <TAB> li = self.leftindex <TAB> lb = self.leftblock <TAB> ri = self.rightindex <TAB> rb = self.rightblock <TAB> for i in range(self.len >> 1): <TAB> <TAB> lb.data[li], rb.data[ri] = rb.data[ri], lb.data[li] <TAB> <TAB> li += 1 <TAB> <TAB> if li >= BLOCKLEN: <TAB> <TAB> <TAB> lb = lb.rightlink <TAB> <TAB> <TAB> li = 0 <TAB> <TAB> ri -= 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> rb = rb.leftlink <TAB> <TAB> <TAB> ri = BLOCKLEN - 1",false,if ri < 0 :,if ri == 0 :,0.33,0.0
"def get_api(user, url): <TAB> global API_CACHE <TAB> if API_CACHE is None or API_CACHE.get(url) is None: <TAB> <TAB> API_CACHE_LOCK.acquire() <TAB> <TAB> try: <TAB> <TAB> <TAB> if API_CACHE is None: <TAB> <TAB> <TAB> <TAB> API_CACHE = {} <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> API_CACHE[url] = ImpalaDaemonApi(url) <TAB> <TAB> finally: <TAB> <TAB> <TAB> API_CACHE_LOCK.release() <TAB> api = API_CACHE[url] <TAB> api.set_user(user) <TAB> return api",false,if API_CACHE . get ( url ) is None :,if url not in API_CACHE :,0.02,0.0
"def invert_index(cls, index, length): <TAB> if np.isscalar(index): <TAB> <TAB> return length - index <TAB> elif isinstance(index, slice): <TAB> <TAB> start, stop = index.start, index.stop <TAB> <TAB> new_start, new_stop = None, None <TAB> <TAB> if start is not None: <TAB> <TAB> <TAB> new_stop = length - start <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> new_start = length - stop <TAB> <TAB> return slice(new_start - 1, new_stop - 1) <TAB> elif isinstance(index, Iterable): <TAB> <TAB> new_index = [] <TAB> <TAB> for ind in index: <TAB> <TAB> <TAB> new_index.append(length - ind) <TAB> return new_index",true,if stop is not None :,if stop is not None :,0.75,0.0
"def infer_returned_object(pyfunction, args): <TAB> """"""Infer the `PyObject` this `PyFunction` returns after calling"""""" <TAB> object_info = pyfunction.pycore.object_info <TAB> result = object_info.get_exact_returned(pyfunction, args) <TAB> if result is not None: <TAB> <TAB> return result <TAB> result = _infer_returned(pyfunction, args) <TAB> if result is not None: <TAB> <TAB> if args and pyfunction.get_module().get_resource() is not None: <TAB> <TAB> <TAB> params = args.get_arguments(pyfunction.get_param_names(special_args=False)) <TAB> <TAB> <TAB> object_info.function_called(pyfunction, params, result) <TAB> <TAB> return result <TAB> return object_info.get_returned(pyfunction, args)",true,if args and pyfunction . get_module ( ) . get_resource ( ) is not None :,if args and pyfunction . get_module ( ) . get_resource ( ) is not None :,0.75,0.0
"def _check_imports(lib): <TAB> # Make sure no conflicting libraries have been imported. <TAB> libs = [""PyQt4"", ""PyQt5"", ""PySide""] <TAB> libs.remove(lib) <TAB> for lib2 in libs: <TAB> <TAB> lib2 += "".QtCore"" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError( <TAB> <TAB> <TAB> <TAB> ""Refusing to import %s because %s is already "" ""imported."" % (lib, lib2) <TAB> <TAB> <TAB> )",false,if lib2 in sys . modules :,if lib2 in libs :,0.18,0.0
"def _poll(fds, timeout): <TAB> if timeout is not None: <TAB> <TAB> timeout = int(timeout * 1000)  # timeout is in milliseconds <TAB> fd_map = {} <TAB> pollster = select.poll() <TAB> for fd in fds: <TAB> <TAB> pollster.register(fd, select.POLLIN) <TAB> <TAB> if hasattr(fd, ""fileno""): <TAB> <TAB> <TAB> fd_map[fd.fileno()] = fd <TAB> <TAB> else: <TAB> <TAB> <TAB> fd_map[fd] = fd <TAB> ls = [] <TAB> for fd, event in pollster.poll(timeout): <TAB> <TAB> if event & select.POLLNVAL: <TAB> <TAB> <TAB> raise ValueError(""invalid file descriptor %i"" % fd) <TAB> <TAB> ls.append(fd_map[fd]) <TAB> return ls",true,"if hasattr ( fd , ""fileno"" ) :","if hasattr ( fd , ""fileno"" ) :",0.75,0.0
"def default(cls, connection=None): <TAB> """"""show the default connection, or make CONNECTION the default"""""" <TAB> if connection is not None: <TAB> <TAB> target = cls._get_config_filename(connection) <TAB> <TAB> if os.path.exists(target): <TAB> <TAB> <TAB> if os.path.exists(cls._default_symlink): <TAB> <TAB> <TAB> <TAB> os.remove(cls._default_symlink) <TAB> <TAB> <TAB> os.symlink(target, cls._default_symlink) <TAB> <TAB> else: <TAB> <TAB> <TAB> cls._no_config_file_error(target) <TAB> if os.path.exists(cls._default_symlink): <TAB> <TAB> print(""Default connection is "" + cls._default_connection()) <TAB> else: <TAB> <TAB> print(""There is no default connection set"")",true,if os . path . exists ( target ) :,if os . path . exists ( target ) :,0.75,0.0
"def process(self, fuzzresult): <TAB> base_url = urljoin(fuzzresult.url, "".."") <TAB> for line in fuzzresult.history.content.splitlines(): <TAB> <TAB> record = line.split(""/"") <TAB> <TAB> if len(record) == 6 and record[1]: <TAB> <TAB> <TAB> self.queue_url(urljoin(base_url, record[1])) <TAB> <TAB> <TAB> # Directory <TAB> <TAB> <TAB> if record[0] == ""D"": <TAB> <TAB> <TAB> <TAB> self.queue_url(urljoin(base_url, record[1])) <TAB> <TAB> <TAB> <TAB> self.queue_url(urljoin(base_url, ""%s/CVS/Entries"" % (record[1])))",true,if len ( record ) == 6 and record [ 1 ] :,if len ( record ) == 6 and record [ 1 ] :,1.0,0.0
"def _GetCSVRow(self, value): <TAB> row = [] <TAB> for type_info in value.__class__.type_infos: <TAB> <TAB> if isinstance(type_info, rdf_structs.ProtoEmbedded): <TAB> <TAB> <TAB> row.extend(self._GetCSVRow(value.Get(type_info.name))) <TAB> <TAB> elif isinstance(type_info, rdf_structs.ProtoBinary): <TAB> <TAB> <TAB> row.append(text.Asciify(value.Get(type_info.name))) <TAB> <TAB> else: <TAB> <TAB> <TAB> row.append(str(value.Get(type_info.name))) <TAB> return row",false,"if isinstance ( type_info , rdf_structs . ProtoEmbedded ) :","elif isinstance ( type_info , rdf_structs . ProtoBinary ) :",0.28,0.0
"def get_history(self, state, dict_, passive=PASSIVE_OFF): <TAB> if self.key in dict_: <TAB> <TAB> return History.from_scalar_attribute(self, state, dict_[self.key]) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> passive ^= INIT_OK <TAB> <TAB> current = self.get(state, dict_, passive=passive) <TAB> <TAB> if current is PASSIVE_NO_RESULT: <TAB> <TAB> <TAB> return HISTORY_BLANK <TAB> <TAB> else: <TAB> <TAB> <TAB> return History.from_scalar_attribute(self, state, current)",true,if passive & INIT_OK :,if passive & INIT_OK :,0.75,0.0
"def _iterate_self_and_parents(self, upto=None): <TAB> current = self <TAB> result = () <TAB> while current: <TAB> <TAB> result += (current,) <TAB> <TAB> if current._parent is upto: <TAB> <TAB> <TAB> break <TAB> <TAB> elif current._parent is None: <TAB> <TAB> <TAB> raise sa_exc.InvalidRequestError( <TAB> <TAB> <TAB> <TAB> ""Transaction %s is not on the active transaction list"" % (upto) <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> current = current._parent <TAB> return result",false,if current . _parent is upto :,elif current . _parent is None :,0.21,0.0
"def get_by_uri(self, uri: str) -> bytes: <TAB> userId, bucket, key = self._parse_uri(uri) <TAB> try: <TAB> <TAB> with db.session_scope() as dbsession: <TAB> <TAB> <TAB> result = db_archivedocument.get(userId, bucket, key, session=dbsession) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return utils.ensure_bytes(self._decode(result)) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ObjectKeyNotFoundError(userId, bucket, key, caused_by=None) <TAB> except Exception as err: <TAB> <TAB> logger.debug(""cannot get data: exception - "" + str(err)) <TAB> <TAB> raise err",true,if result :,if result :,0.53,0.0
"def app(scope, receive, send): <TAB> while True: <TAB> <TAB> message = await receive() <TAB> <TAB> if message[""type""] == ""websocket.connect"": <TAB> <TAB> <TAB> await send({""type"": ""websocket.accept""}) <TAB> <TAB> elif message[""type""] == ""websocket.receive"": <TAB> <TAB> <TAB> pass <TAB> <TAB> elif message[""type""] == ""websocket.disconnect"": <TAB> <TAB> <TAB> break",false,"elif message [ ""type"" ] == ""websocket.disconnect"" :","elif message [ ""type"" ] == ""websocket.receive"" :",0.85,0.0
"def recv_some(p, t=0.1, e=1, tr=5, stderr=0): <TAB> if tr < 1: <TAB> <TAB> tr = 1 <TAB> x = time.time() + t <TAB> y = [] <TAB> r = """" <TAB> if stderr: <TAB> <TAB> pr = p.recv_err <TAB> else: <TAB> <TAB> pr = p.recv <TAB> while time.time() < x or r: <TAB> <TAB> r = pr() <TAB> <TAB> if r is None: <TAB> <TAB> <TAB> break <TAB> <TAB> elif r: <TAB> <TAB> <TAB> y.append(r) <TAB> <TAB> else: <TAB> <TAB> <TAB> time.sleep(max((x - time.time()) / tr, 0)) <TAB> return """".join(y)",true,elif r :,elif r :,0.51,0.0
"def mouse_down(self, event): <TAB> if event.button == 1: <TAB> <TAB> if self.scrolling: <TAB> <TAB> <TAB> p = event.local <TAB> <TAB> <TAB> if self.scroll_up_rect().collidepoint(p): <TAB> <TAB> <TAB> <TAB> self.scroll_up() <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> elif self.scroll_down_rect().collidepoint(p): <TAB> <TAB> <TAB> <TAB> self.scroll_down() <TAB> <TAB> <TAB> <TAB> return <TAB> if event.button == 4: <TAB> <TAB> self.scroll_up() <TAB> if event.button == 5: <TAB> <TAB> self.scroll_down() <TAB> GridView.mouse_down(self, event)",false,if self . scrolling :,if self . scroll_up_rect ( ) . collidepoint ( p ) :,0.1,0.0
"def copy_from(self, other): <TAB> if self is other: <TAB> <TAB> return  # Myself! <TAB> self.strictness = other.strictness  # sets behaviors in bulk <TAB> for name in self.all_behaviors: <TAB> <TAB> self.set_behavior(name, other.get_behavior(name)) <TAB> for name in self._plain_attrs: <TAB> <TAB> val = getattr(other, name) <TAB> <TAB> if isinstance(val, set): <TAB> <TAB> <TAB> val = val.copy() <TAB> <TAB> elif decimal and isinstance(val, decimal.Decimal): <TAB> <TAB> <TAB> val = val.copy() <TAB> <TAB> setattr(self, name, val)",true,"elif decimal and isinstance ( val , decimal . Decimal ) :","elif decimal and isinstance ( val , decimal . Decimal ) :",1.0,0.0
"def __array_wrap__(self, out_arr, context=None): <TAB> if self.dim is None: <TAB> <TAB> return out_arr <TAB> else: <TAB> <TAB> this = self[:] <TAB> <TAB> if isinstance(this, Quantity): <TAB> <TAB> <TAB> return Quantity.__array_wrap__(self[:], out_arr, context=context) <TAB> <TAB> else: <TAB> <TAB> <TAB> return out_arr",true,"if isinstance ( this , Quantity ) :","if isinstance ( this , Quantity ) :",0.75,0.0
"def _ArgumentListHasDictionaryEntry(self, token): <TAB> """"""Check if the function argument list has a dictionary as an arg."""""" <TAB> if _IsArgumentToFunction(token): <TAB> <TAB> while token: <TAB> <TAB> <TAB> if token.value == ""{"": <TAB> <TAB> <TAB> <TAB> length = token.matching_bracket.total_length - token.total_length <TAB> <TAB> <TAB> <TAB> return length + self.stack[-2].indent > self.column_limit <TAB> <TAB> <TAB> if token.ClosesScope(): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if token.OpensScope(): <TAB> <TAB> <TAB> <TAB> token = token.matching_bracket <TAB> <TAB> <TAB> token = token.next_token <TAB> return False",true,"if token . value == ""{"" :","if token . value == ""{"" :",0.75,0.0
"def save_all_changed_extensions(self): <TAB> """"""Save configuration changes to the user config file."""""" <TAB> has_changes = False <TAB> for ext_name in self.extensions: <TAB> <TAB> options = self.extensions[ext_name] <TAB> <TAB> for opt in options: <TAB> <TAB> <TAB> if self.set_extension_value(ext_name, opt): <TAB> <TAB> <TAB> <TAB> has_changes = True <TAB> if has_changes: <TAB> <TAB> self.ext_userCfg.Save()",true,"if self . set_extension_value ( ext_name , opt ) :","if self . set_extension_value ( ext_name , opt ) :",0.75,0.0
"def to_dict(self): <TAB> out = {} <TAB> for key in ACTIVITY_KEYS: <TAB> <TAB> attr = getattr(self, key) <TAB> <TAB> if isinstance(attr, (datetime.timedelta, datetime.datetime)): <TAB> <TAB> <TAB> out[key] = str(attr) <TAB> <TAB> else: <TAB> <TAB> <TAB> out[key] = attr <TAB> if self.streak: <TAB> <TAB> out[""streak""] = self.streak <TAB> return out",true,"if isinstance ( attr , ( datetime . timedelta , datetime . datetime ) ) :","if isinstance ( attr , ( datetime . timedelta , datetime . datetime ) ) :",0.75,0.0
"def clean_publication_date(cls, cleaned_input): <TAB> for add_channel in cleaned_input.get(""add_channels"", []): <TAB> <TAB> is_published = add_channel.get(""is_published"") <TAB> <TAB> publication_date = add_channel.get(""publication_date"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> add_channel[""publication_date""] = datetime.date.today()",false,if is_published and not publication_date :,if publication_date is None or is_published :,0.13,0.0
"def _random_blur(self, batch, sigma_max): <TAB> for i in range(len(batch)): <TAB> <TAB> if bool(random.getrandbits(1)): <TAB> <TAB> <TAB> # Random sigma <TAB> <TAB> <TAB> sigma = random.uniform(0.0, sigma_max) <TAB> <TAB> <TAB> batch[i] = scipy.ndimage.filters.gaussian_filter(batch[i], sigma) <TAB> return batch",true,if bool ( random . getrandbits ( 1 ) ) :,if bool ( random . getrandbits ( 1 ) ) :,0.75,0.0
"def conninfo_parse(dsn): <TAB> ret = {} <TAB> length = len(dsn) <TAB> i = 0 <TAB> while i < length: <TAB> <TAB> if dsn[i].isspace(): <TAB> <TAB> <TAB> i += 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> param_match = PARAMETER_RE.match(dsn[i:]) <TAB> <TAB> if not param_match: <TAB> <TAB> <TAB> return <TAB> <TAB> param = param_match.group(1) <TAB> <TAB> i += param_match.end() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> value, end = read_param_value(dsn[i:]) <TAB> <TAB> if value is None: <TAB> <TAB> <TAB> return <TAB> <TAB> i += end <TAB> <TAB> ret[param] = value <TAB> return ret",false,if i >= length :,if param is None :,0.03,0.0
"def set_environment_vars(env, source_env): <TAB> """"""Copy allowed environment variables from |source_env|."""""" <TAB> if not source_env: <TAB> <TAB> return <TAB> for name, value in six.iteritems(source_env): <TAB> <TAB> if is_forwarded_environment_variable(name): <TAB> <TAB> <TAB> # Avoid creating circular dependencies from importing environment by <TAB> <TAB> <TAB> # using os.getenv. <TAB> <TAB> <TAB> if os.getenv(""TRUSTED_HOST"") and should_rebase_environment_value(name): <TAB> <TAB> <TAB> <TAB> value = file_host.rebase_to_worker_root(value) <TAB> <TAB> <TAB> env[name] = value",false,"if os . getenv ( ""TRUSTED_HOST"" ) and should_rebase_environment_value ( name ) :",if is_forwarded_environment_variable ( name ) :,0.1,0.0
"def toterminal(self, tw): <TAB> # the entries might have different styles <TAB> last_style = None <TAB> for i, entry in enumerate(self.reprentries): <TAB> <TAB> if entry.style == ""long"": <TAB> <TAB> <TAB> tw.line("""") <TAB> <TAB> entry.toterminal(tw) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> next_entry = self.reprentries[i + 1] <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> entry.style == ""long"" <TAB> <TAB> <TAB> <TAB> or entry.style == ""short"" <TAB> <TAB> <TAB> <TAB> and next_entry.style == ""long"" <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> tw.sep(self.entrysep) <TAB> if self.extraline: <TAB> <TAB> tw.line(self.extraline)",true,if i < len ( self . reprentries ) - 1 :,if i < len ( self . reprentries ) - 1 :,0.75,0.0
"def __init__(self, loc, tabs=None): <TAB> if os.path.isdir(loc): <TAB> <TAB> for item in os.listdir(loc): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> path = os.path.join(loc, item) <TAB> <TAB> <TAB> self.append(CronTab(user=False, tabfile=path)) <TAB> elif os.path.isfile(loc): <TAB> <TAB> self.append(CronTab(user=False, tabfile=loc))",false,"if item [ 0 ] == ""."" :",if tabs and item in tabs :,0.02,0.0
"def import_data(self, fname): <TAB> """"""Import data in current namespace"""""" <TAB> if self.count(): <TAB> <TAB> nsb = self.currentWidget() <TAB> <TAB> nsb.refresh_table() <TAB> <TAB> nsb.import_data(fname) <TAB> <TAB> if self.dockwidget and not self.ismaximized: <TAB> <TAB> <TAB> self.dockwidget.setVisible(True) <TAB> <TAB> <TAB> self.dockwidget.raise_()",true,if self . dockwidget and not self . ismaximized :,if self . dockwidget and not self . ismaximized :,0.75,0.0
"def get_menu_items(node): <TAB> aList = [] <TAB> for child in node.children: <TAB> <TAB> for tag in (""@menu"", ""@item""): <TAB> <TAB> <TAB> if child.h.startswith(tag): <TAB> <TAB> <TAB> <TAB> name = child.h[len(tag) + 1 :].strip() <TAB> <TAB> <TAB> <TAB> if tag == ""@menu"": <TAB> <TAB> <TAB> <TAB> <TAB> aList.append((""%s %s"" % (tag, name), get_menu_items(child), None)) <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> b = g.splitLines("""".join(child.b)) <TAB> <TAB> <TAB> <TAB> <TAB> aList.append((tag, name, b[0] if b else """")) <TAB> <TAB> <TAB> <TAB> break <TAB> return aList",true,if child . h . startswith ( tag ) :,if child . h . startswith ( tag ) :,0.75,0.0
"def __init__(self, *args, **kw): <TAB> if len(args) > 1: <TAB> <TAB> raise TypeError(""MultiDict can only be called with one positional "" ""argument"") <TAB> if args: <TAB> <TAB> if hasattr(args[0], ""iteritems""): <TAB> <TAB> <TAB> items = list(args[0].iteritems()) <TAB> <TAB> elif hasattr(args[0], ""items""): <TAB> <TAB> <TAB> items = list(args[0].items()) <TAB> <TAB> else: <TAB> <TAB> <TAB> items = list(args[0]) <TAB> <TAB> self._items = items <TAB> else: <TAB> <TAB> self._items = [] <TAB> if kw: <TAB> <TAB> self._items.extend(kw.items())",true,"elif hasattr ( args [ 0 ] , ""items"" ) :","elif hasattr ( args [ 0 ] , ""items"" ) :",0.75,0.0
"def open(self) -> ""KeyValueDb"": <TAB> """"""Create a new data base or open existing one"""""" <TAB> if os.path.exists(self._name): <TAB> <TAB> if not os.path.isfile(self._name): <TAB> <TAB> <TAB> raise IOError(""%s exists and is not a file"" % self._name) <TAB> <TAB> if os.path.getsize(self._name) == 0: <TAB> <TAB> <TAB> # ignore empty files <TAB> <TAB> <TAB> return self <TAB> <TAB> with open(self._name, ""rb"") as _in:  # binary mode <TAB> <TAB> <TAB> self.set_records(pickle.load(_in)) <TAB> else: <TAB> <TAB> # make sure path exists <TAB> <TAB> mkpath(os.path.dirname(self._name)) <TAB> <TAB> self.commit() <TAB> return self",true,if os . path . getsize ( self . _name ) == 0 :,if os . path . getsize ( self . _name ) == 0 :,0.75,0.0
"def sortModules(self): <TAB> super(NeuronDecomposableNetwork, self).sortModules() <TAB> self._constructParameterInfo() <TAB> # contains a list of lists of indices <TAB> self.decompositionIndices = {} <TAB> for neuron in self._neuronIterator(): <TAB> <TAB> self.decompositionIndices[neuron] = [] <TAB> for w in range(self.paramdim): <TAB> <TAB> inneuron, outneuron = self.paramInfo[w] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.decompositionIndices[inneuron].append(w) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.decompositionIndices[outneuron].append(w)",false,if self . espStyleDecomposition and outneuron [ 0 ] in self . outmodules :,if inneuron in self . decompositionIndices :,0.12,0.0
"def visit_Options(self, node: qlast.Options) -> None: <TAB> for i, opt in enumerate(node.options.values()): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.write("" "") <TAB> <TAB> self.write(opt.name) <TAB> <TAB> if not isinstance(opt, qlast.Flag): <TAB> <TAB> <TAB> self.write(f"" {opt.val}"")",true,if i > 0 :,if i > 0 :,0.75,0.0
"def is_child_of(self, item_hash, possible_child_hash): <TAB> if self.get_last(item_hash) != self.get_last(possible_child_hash): <TAB> <TAB> return None <TAB> while True: <TAB> <TAB> if possible_child_hash == item_hash: <TAB> <TAB> <TAB> return True <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> possible_child_hash = self.items[possible_child_hash].previous_hash",false,if possible_child_hash not in self . items :,if possible_child_hash in self . items :,0.43,0.0
"def __call__(self, text, **kargs): <TAB> words = jieba.tokenize(text, mode=""search"") <TAB> token = Token() <TAB> for (w, start_pos, stop_pos) in words: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> token.original = token.text = w <TAB> <TAB> token.pos = start_pos <TAB> <TAB> token.startchar = start_pos <TAB> <TAB> token.endchar = stop_pos <TAB> <TAB> yield token",false,if not accepted_chars . match ( w ) and len ( w ) <= 1 :,"if w == """" :",0.01,0.0
"def test_analysis_jobs_cypher_syntax(neo4j_session): <TAB> parameters = { <TAB> <TAB> ""AWS_ID"": None, <TAB> <TAB> ""UPDATE_TAG"": None, <TAB> <TAB> ""OKTA_ORG_ID"": None, <TAB> } <TAB> for job_name in contents(""cartography.data.jobs.analysis""): <TAB> <TAB> if not job_name.endswith("".json""): <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> cartography.util.run_analysis_job(job_name, neo4j_session, parameters) <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> pytest.fail( <TAB> <TAB> <TAB> <TAB> f""run_analysis_job failed for analysis job '{job_name}' with exception: {e}"" <TAB> <TAB> <TAB> )",true,"if not job_name . endswith ( "".json"" ) :","if not job_name . endswith ( "".json"" ) :",0.75,0.0
"def _interleave_dataset_results_and_tensors(dataset_results, flat_run_tensors): <TAB> flattened_results = [] <TAB> for idx in range(len(dataset_results) + len(flat_run_tensors)): <TAB> <TAB> if dataset_results.get(idx): <TAB> <TAB> <TAB> flattened_results.append(dataset_results[idx]) <TAB> <TAB> else: <TAB> <TAB> <TAB> flattened_results.append(flat_run_tensors.pop(0)) <TAB> return flattened_results",true,if dataset_results . get ( idx ) :,if dataset_results . get ( idx ) :,0.75,0.0
"def test_k_is_stochastic_parameter(self): <TAB> # k as stochastic parameter <TAB> aug = iaa.MedianBlur(k=iap.Choice([3, 5])) <TAB> seen = [False, False] <TAB> for i in sm.xrange(100): <TAB> <TAB> observed = aug.augment_image(self.base_img) <TAB> <TAB> if np.array_equal(observed, self.blur3x3): <TAB> <TAB> <TAB> seen[0] += True <TAB> <TAB> elif np.array_equal(observed, self.blur5x5): <TAB> <TAB> <TAB> seen[1] += True <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception(""Unexpected result in MedianBlur@2"") <TAB> <TAB> if all(seen): <TAB> <TAB> <TAB> break <TAB> assert np.all(seen)",true,"if np . array_equal ( observed , self . blur3x3 ) :","if np . array_equal ( observed , self . blur3x3 ) :",0.75,0.0
"def pickPath(self, color): <TAB> self.path[color] = () <TAB> currentPos = self.starts[color] <TAB> while True: <TAB> <TAB> minDist = None <TAB> <TAB> minGuide = None <TAB> <TAB> for guide in self.guides[color]: <TAB> <TAB> <TAB> guideDist = dist(currentPos, guide) <TAB> <TAB> <TAB> if minDist == None or guideDist < minDist: <TAB> <TAB> <TAB> <TAB> minDist = guideDist <TAB> <TAB> <TAB> <TAB> minGuide = guide <TAB> <TAB> if dist(currentPos, self.ends[color]) == 1: <TAB> <TAB> <TAB> return <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> self.path[color] = self.path[color] + (minGuide,) <TAB> <TAB> currentPos = minGuide <TAB> <TAB> self.guides[color].remove(minGuide)",true,if minGuide == None :,if minGuide == None :,0.75,0.0
"def UpdateRepository(self): <TAB> if hasattr(self, ""commit_update""): <TAB> <TAB> if self.commit_update[""Updates""] != []: <TAB> <TAB> <TAB> if not path.isdir("".git/""): <TAB> <TAB> <TAB> <TAB> self.gitZipRepo() <TAB> <TAB> <TAB> call([""git"", ""reset"", ""--hard"", ""origin/{}"".format(self.getBranch)]) <TAB> <TAB> <TAB> self.ProcessCall_([""git"", ""pull"", ""origin"", self.getBranch]) <TAB> <TAB> <TAB> self.ProcessCall_([""pip"", ""install"", ""-r"", ""requirements.txt""])",true,"if self . commit_update [ ""Updates"" ] != [ ] :","if self . commit_update [ ""Updates"" ] != [ ] :",0.75,0.0
"def callback(result=Cr.NS_OK, message=None, success=None): <TAB> if success is None: <TAB> <TAB> if Cr.NS_SUCCEEDED(result): <TAB> <TAB> <TAB> success = Ci.koIAsyncCallback.RESULT_SUCCESSFUL <TAB> <TAB> else: <TAB> <TAB> <TAB> success = Ci.koIAsyncCallback.RESULT_ERROR <TAB> data = Namespace(result=result, message=message, _com_interfaces_=[Ci.koIErrorInfo]) <TAB> self._invoke_activate_callbacks(success, data)",true,if Cr . NS_SUCCEEDED ( result ) :,if Cr . NS_SUCCEEDED ( result ) :,0.75,0.0
"def get_location(device): <TAB> location = [] <TAB> node = device <TAB> while node: <TAB> <TAB> position = node.get_position() or """" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> position = "" [%s]"" % position <TAB> <TAB> location.append(node.name + position) <TAB> <TAB> node = node.parent <TAB> return "" / "".join(reversed(location))",true,if position :,if position :,0.53,0.0
"def load_checkpoint(path, model, optimizer, reset_optimizer): <TAB> global global_step <TAB> global global_epoch <TAB> print(""Load checkpoint from: {}"".format(path)) <TAB> checkpoint = _load(path) <TAB> model.load_state_dict(checkpoint[""state_dict""]) <TAB> if not reset_optimizer: <TAB> <TAB> optimizer_state = checkpoint[""optimizer""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(""Load optimizer state from {}"".format(path)) <TAB> <TAB> <TAB> optimizer.load_state_dict(checkpoint[""optimizer""]) <TAB> global_step = checkpoint[""global_step""] <TAB> global_epoch = checkpoint[""global_epoch""] <TAB> return model",false,if optimizer_state is not None :,if optimizer_state :,0.05,0.0
"def run_command(self, command: str, data: Dict[str, object]) -> Dict[str, object]: <TAB> """"""Run a specific command from the registry."""""" <TAB> key = ""cmd_"" + command <TAB> method = getattr(self.__class__, key, None) <TAB> if method is None: <TAB> <TAB> return {""error"": ""Unrecognized command '%s'"" % command} <TAB> else: <TAB> <TAB> if command not in {""check"", ""recheck"", ""run""}: <TAB> <TAB> <TAB> # Only the above commands use some error formatting. <TAB> <TAB> <TAB> del data[""is_tty""] <TAB> <TAB> <TAB> del data[""terminal_width""] <TAB> <TAB> return method(self, **data)",true,"if command not in { ""check"" , ""recheck"" , ""run"" } :","if command not in { ""check"" , ""recheck"" , ""run"" } :",0.75,0.0
"def call_init(self, node, instance): <TAB> # Call __init__ on each binding. <TAB> for b in instance.bindings: <TAB> <TAB> if b.data in self._initialized_instances: <TAB> <TAB> <TAB> continue <TAB> <TAB> self._initialized_instances.add(b.data) <TAB> <TAB> node = self._call_init_on_binding(node, b) <TAB> return node",true,if b . data in self . _initialized_instances :,if b . data in self . _initialized_instances :,0.75,0.0
"def get_request_headers() -> Dict: <TAB> url = urlparse(uri) <TAB> candidates = [ <TAB> <TAB> ""%s://%s"" % (url.scheme, url.netloc), <TAB> <TAB> ""%s://%s/"" % (url.scheme, url.netloc), <TAB> <TAB> uri, <TAB> <TAB> ""*"", <TAB> ] <TAB> for u in candidates: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> headers = dict(DEFAULT_REQUEST_HEADERS) <TAB> <TAB> <TAB> headers.update(self.config.linkcheck_request_headers[u]) <TAB> <TAB> <TAB> return headers <TAB> return {}",true,if u in self . config . linkcheck_request_headers :,if u in self . config . linkcheck_request_headers :,0.75,0.0
"def get_next_video_frame(self, skip_empty_frame=True): <TAB> if not self.video_format: <TAB> <TAB> return <TAB> while True: <TAB> <TAB> # We skip video packets which are not video frames <TAB> <TAB> # This happens in mkv files for the first few frames. <TAB> <TAB> video_packet = self._get_video_packet() <TAB> <TAB> if video_packet.image == 0: <TAB> <TAB> <TAB> self._decode_video_packet(video_packet) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> if _debug: <TAB> <TAB> print(""Returning"", video_packet) <TAB> return video_packet.image",false,if video_packet . image is not None or not skip_empty_frame :,if skip_empty_frame :,0.02,0.0
"def convert_path(ctx, tpath): <TAB> for points, code in tpath.iter_segments(): <TAB> <TAB> if code == Path.MOVETO: <TAB> <TAB> <TAB> ctx.move_to(*points) <TAB> <TAB> elif code == Path.LINETO: <TAB> <TAB> <TAB> ctx.line_to(*points) <TAB> <TAB> elif code == Path.CURVE3: <TAB> <TAB> <TAB> ctx.curve_to( <TAB> <TAB> <TAB> <TAB> points[0], points[1], points[0], points[1], points[2], points[3] <TAB> <TAB> <TAB> ) <TAB> <TAB> elif code == Path.CURVE4: <TAB> <TAB> <TAB> ctx.curve_to(*points) <TAB> <TAB> elif code == Path.CLOSEPOLY: <TAB> <TAB> <TAB> ctx.close_path()",false,elif code == Path . CURVE3 :,elif code == Path . LINETO :,0.57,0.0
"def __init__( <TAB> self, layout, value=None, string=None, *, dtype: np.dtype = np.float64 ) -> None: <TAB> """"""Constructor."""""" <TAB> self.layout = layout <TAB> if value is None: <TAB> <TAB> if string is None: <TAB> <TAB> <TAB> self.value = np.zeros((self.layout.gaDims,), dtype=dtype) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.value = layout.parse_multivector(string).value <TAB> else: <TAB> <TAB> self.value = np.array(value) <TAB> <TAB> if self.value.shape != (self.layout.gaDims,): <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""value must be a sequence of length %s"" % self.layout.gaDims <TAB> <TAB> <TAB> )",true,"if self . value . shape != ( self . layout . gaDims , ) :","if self . value . shape != ( self . layout . gaDims , ) :",1.0,0.0
"def to_dict(self): <TAB> contexts_ = {} <TAB> for k, data in self.contexts.items(): <TAB> <TAB> data_ = data.copy() <TAB> <TAB> if ""context"" in data_: <TAB> <TAB> <TAB> del data_[""context""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> del data_[""loaded""] <TAB> <TAB> contexts_[k] = data_ <TAB> return dict(contexts=contexts_)",true,"if ""loaded"" in data_ :","if ""loaded"" in data_ :",0.75,0.0
"def include_module(module): <TAB> if not include_these: <TAB> <TAB> return True <TAB> result = False <TAB> for check in include_these: <TAB> <TAB> if ""/*"" in check: <TAB> <TAB> <TAB> if check[:-1] in module: <TAB> <TAB> <TAB> <TAB> result = True <TAB> <TAB> else: <TAB> <TAB> <TAB> if (os.getcwd() + ""/"" + check + "".py"") == module: <TAB> <TAB> <TAB> <TAB> result = True <TAB> if result: <TAB> <TAB> print_status(""Including module: "" + module) <TAB> return result",false,if check [ : - 1 ] in module :,"if ( os . getcwd ( ) + ""/"" + check + "".py"" ) == module :",0.02,0.0
"def extract_from(msg_body, content_type=""text/plain""): <TAB> try: <TAB> <TAB> if content_type == ""text/plain"": <TAB> <TAB> <TAB> return extract_from_plain(msg_body) <TAB> <TAB> elif content_type == ""text/html"": <TAB> <TAB> <TAB> return extract_from_html(msg_body) <TAB> except Exception: <TAB> <TAB> log.exception(""ERROR extracting message"") <TAB> return msg_body",true,"elif content_type == ""text/html"" :","elif content_type == ""text/html"" :",1.0,0.0
"def test_list(self): <TAB> self._create_locations() <TAB> response = self.client.get(self.geojson_boxedlocation_list_url) <TAB> self.assertEqual(response.status_code, 200) <TAB> self.assertEqual(len(response.data[""features""]), 2) <TAB> for feature in response.data[""features""]: <TAB> <TAB> self.assertIn(""bbox"", feature) <TAB> <TAB> fid = feature[""id""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.assertEqual(feature[""bbox""], self.bl1.bbox_geometry.extent) <TAB> <TAB> elif fid == 2: <TAB> <TAB> <TAB> self.assertEqual(feature[""bbox""], self.bl2.bbox_geometry.extent) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.fail(""Unexpected id: {0}"".format(fid)) <TAB> BoxedLocation.objects.all().delete()",true,if fid == 1 :,if fid == 1 :,0.75,0.0
"def overrideCommand(self, commandName, func): <TAB> # Override entries in c.k.masterBindingsDict <TAB> k = self <TAB> d = k.masterBindingsDict <TAB> for key in d: <TAB> <TAB> d2 = d.get(key) <TAB> <TAB> for key2 in d2: <TAB> <TAB> <TAB> bi = d2.get(key2) <TAB> <TAB> <TAB> if bi.commandName == commandName: <TAB> <TAB> <TAB> <TAB> bi.func = func <TAB> <TAB> <TAB> <TAB> d2[key2] = bi",true,if bi . commandName == commandName :,if bi . commandName == commandName :,1.0,0.0
"def _lookup(components, specs, provided, name, i, l): <TAB> if i < l: <TAB> <TAB> for spec in specs[i].__sro__: <TAB> <TAB> <TAB> comps = components.get(spec) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> r = _lookup(comps, specs, provided, name, i + 1, l) <TAB> <TAB> <TAB> <TAB> if r is not None: <TAB> <TAB> <TAB> <TAB> <TAB> return r <TAB> else: <TAB> <TAB> for iface in provided: <TAB> <TAB> <TAB> comps = components.get(iface) <TAB> <TAB> <TAB> if comps: <TAB> <TAB> <TAB> <TAB> r = comps.get(name) <TAB> <TAB> <TAB> <TAB> if r is not None: <TAB> <TAB> <TAB> <TAB> <TAB> return r <TAB> return None",true,if comps :,if comps :,0.53,0.0
"def to_representation(self, value): <TAB> old_social_string_fields = [""twitter"", ""github"", ""linkedIn""] <TAB> request = self.context.get(""request"") <TAB> show_old_format = ( <TAB> <TAB> request <TAB> <TAB> and is_deprecated(request.version, self.min_version) <TAB> <TAB> and request.method == ""GET"" <TAB> ) <TAB> if show_old_format: <TAB> <TAB> social = value.copy() <TAB> <TAB> for key in old_social_string_fields: <TAB> <TAB> <TAB> if social.get(key): <TAB> <TAB> <TAB> <TAB> social[key] = value[key][0] <TAB> <TAB> <TAB> elif social.get(key) == []: <TAB> <TAB> <TAB> <TAB> social[key] = """" <TAB> <TAB> value = social <TAB> return super(SocialField, self).to_representation(value)",true,elif social . get ( key ) == [ ] :,elif social . get ( key ) == [ ] :,0.75,0.0
"def process_ref_attribute(self, node, array_type=None): <TAB> ref = qname_attr(node, ""ref"") <TAB> if ref: <TAB> <TAB> ref = self._create_qname(ref) <TAB> <TAB> # Some wsdl's reference to xs:schema, we ignore that for now. It <TAB> <TAB> # might be better in the future to process the actual schema file <TAB> <TAB> # so that it is handled correctly <TAB> <TAB> if ref.namespace == ""http://www.w3.org/2001/XMLSchema"": <TAB> <TAB> <TAB> return <TAB> <TAB> return xsd_elements.RefAttribute( <TAB> <TAB> <TAB> node.tag, ref, self.schema, array_type=array_type <TAB> <TAB> )",true,"if ref . namespace == ""http://www.w3.org/2001/XMLSchema"" :","if ref . namespace == ""http://www.w3.org/2001/XMLSchema"" :",0.75,0.0
"def unescape(text): <TAB> """"""Removes '\\' escaping from 'text'."""""" <TAB> rv = """" <TAB> i = 0 <TAB> while i < len(text): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> rv += text[i + 1] <TAB> <TAB> <TAB> i += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> rv += text[i] <TAB> <TAB> i += 1 <TAB> return rv",false,"if i + 1 < len ( text ) and text [ i ] == ""\\"" :","if text [ i ] == ""\\"" :",0.17,0.0
"def wait_child_process(signum, frame): <TAB> try: <TAB> <TAB> while True: <TAB> <TAB> <TAB> child_pid, status = os.waitpid(-1, os.WNOHANG) <TAB> <TAB> <TAB> if child_pid == 0: <TAB> <TAB> <TAB> <TAB> stat_logger.info(""no child process was immediately available"") <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> exitcode = status >> 8 <TAB> <TAB> <TAB> stat_logger.info( <TAB> <TAB> <TAB> <TAB> ""child process %s exit with exitcode %s"", child_pid, exitcode <TAB> <TAB> <TAB> ) <TAB> except OSError as e: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> stat_logger.warning( <TAB> <TAB> <TAB> <TAB> ""current process has no existing unwaited-for child processes."" <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise",false,if e . errno == errno . ECHILD :,if e . errno == errno . EINTR :,0.88,0.0
"def translate_from_sortname(name, sortname): <TAB> """"""'Translate' the artist name by reversing the sortname."""""" <TAB> for c in name: <TAB> <TAB> ctg = unicodedata.category(c) <TAB> <TAB> if ctg[0] == ""L"" and unicodedata.name(c).find(""LATIN"") == -1: <TAB> <TAB> <TAB> for separator in ("" & "", ""; "", "" and "", "" vs. "", "" with "", "" y ""): <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> parts = sortname.split(separator) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> parts = [sortname] <TAB> <TAB> <TAB> <TAB> separator = """" <TAB> <TAB> <TAB> return separator.join(map(_reverse_sortname, parts)) <TAB> return name",false,if separator in sortname :,if separator :,0.07,0.0
"def python_value(self, value): <TAB> if value: <TAB> <TAB> if isinstance(value, basestring): <TAB> <TAB> <TAB> pp = lambda x: x.time() <TAB> <TAB> <TAB> return format_date_time(value, self.formats, pp) <TAB> <TAB> elif isinstance(value, datetime.datetime): <TAB> <TAB> <TAB> return value.time() <TAB> if value is not None and isinstance(value, datetime.timedelta): <TAB> <TAB> return (datetime.datetime.min + value).time() <TAB> return value",true,"if isinstance ( value , basestring ) :","if isinstance ( value , basestring ) :",0.75,0.0
"def __init__(self, fileobj, info): <TAB> pages = [] <TAB> complete = False <TAB> while not complete: <TAB> <TAB> page = OggPage(fileobj) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> pages.append(page) <TAB> <TAB> <TAB> complete = page.complete or (len(page.packets) > 1) <TAB> data = OggPage.to_packets(pages)[0][7:] <TAB> super(OggTheoraCommentDict, self).__init__(data, framing=False) <TAB> self._padding = len(data) - self._size",false,if page . serial == info . serial :,if page . info == info :,0.39,0.0
"def configure(self): <TAB> # hack to configure 'from_' and 'to' and avoid exception <TAB> if ""from_"" in self.wmeta.properties: <TAB> <TAB> from_ = float(self.wmeta.properties[""from_""]) <TAB> <TAB> to = float(self.wmeta.properties.get(""to"", 0)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> to = from_ + 1 <TAB> <TAB> <TAB> self.wmeta.properties[""to""] = str(to) <TAB> super(TKSpinbox, self).configure()",false,if from_ > to :,if to < from_ :,0.04,0.0
"def get_error_diagnostics(self): <TAB> diagnostics = [] <TAB> if self.stdout is not None: <TAB> <TAB> with open(self.stdout.name) as fds: <TAB> <TAB> <TAB> contents = fds.read().strip() <TAB> <TAB> <TAB> if contents.strip(): <TAB> <TAB> <TAB> <TAB> diagnostics.append(""ab STDOUT:\n"" + contents) <TAB> if self.stderr is not None: <TAB> <TAB> with open(self.stderr.name) as fds: <TAB> <TAB> <TAB> contents = fds.read().strip() <TAB> <TAB> <TAB> if contents.strip(): <TAB> <TAB> <TAB> <TAB> diagnostics.append(""ab STDERR:\n"" + contents) <TAB> return diagnostics",true,if contents . strip ( ) :,if contents . strip ( ) :,0.75,0.0
"def set_environment_vars(env, source_env): <TAB> """"""Copy allowed environment variables from |source_env|."""""" <TAB> if not source_env: <TAB> <TAB> return <TAB> for name, value in six.iteritems(source_env): <TAB> <TAB> if is_forwarded_environment_variable(name): <TAB> <TAB> <TAB> # Avoid creating circular dependencies from importing environment by <TAB> <TAB> <TAB> # using os.getenv. <TAB> <TAB> <TAB> if os.getenv(""TRUSTED_HOST"") and should_rebase_environment_value(name): <TAB> <TAB> <TAB> <TAB> value = file_host.rebase_to_worker_root(value) <TAB> <TAB> <TAB> env[name] = value",true,if is_forwarded_environment_variable ( name ) :,if is_forwarded_environment_variable ( name ) :,0.75,0.0
"def update_content(self, more_content: StringList) -> None: <TAB> if isinstance(self.object, TypeVar): <TAB> <TAB> attrs = [repr(self.object.__name__)] <TAB> <TAB> for constraint in self.object.__constraints__: <TAB> <TAB> <TAB> attrs.append(stringify_typehint(constraint)) <TAB> <TAB> if self.object.__covariant__: <TAB> <TAB> <TAB> attrs.append(""covariant=True"") <TAB> <TAB> if self.object.__contravariant__: <TAB> <TAB> <TAB> attrs.append(""contravariant=True"") <TAB> <TAB> more_content.append(_(""alias of TypeVar(%s)"") % "", "".join(attrs), """") <TAB> <TAB> more_content.append("""", """") <TAB> super().update_content(more_content)",true,if self . object . __contravariant__ :,if self . object . __contravariant__ :,0.75,0.0
"def after(self, event, state): <TAB> group = event.group <TAB> for plugin in self.get_plugins(): <TAB> <TAB> if not safe_execute(plugin.should_notify, group=group, event=event): <TAB> <TAB> <TAB> continue <TAB> <TAB> metrics.incr(""notifications.sent"", instance=plugin.slug) <TAB> <TAB> yield self.future(plugin.rule_notify)",true,"if not safe_execute ( plugin . should_notify , group = group , event = event ) :","if not safe_execute ( plugin . should_notify , group = group , event = event ) :",1.0,0.0
"def distinct(expr, *on): <TAB> fields = frozenset(expr.fields) <TAB> _on = [] <TAB> append = _on.append <TAB> for n in on: <TAB> <TAB> if isinstance(n, Field): <TAB> <TAB> <TAB> if n._child.isidentical(expr): <TAB> <TAB> <TAB> <TAB> n = n._name <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise ValueError(""{0} is not a field of {1}"".format(n, expr)) <TAB> <TAB> if not isinstance(n, _strtypes): <TAB> <TAB> <TAB> raise TypeError(""on must be a name or field, not: {0}"".format(n)) <TAB> <TAB> elif n not in fields: <TAB> <TAB> <TAB> raise ValueError(""{0} is not a field of {1}"".format(n, expr)) <TAB> <TAB> append(n) <TAB> return Distinct(expr, tuple(_on))",true,if n . _child . isidentical ( expr ) :,if n . _child . isidentical ( expr ) :,0.75,0.0
"def build_filter(arg): <TAB> filt = {} <TAB> if arg is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise UserError(""Arguments to --filter should be in form KEY=VAL"") <TAB> <TAB> key, val = arg.split(""="", 1) <TAB> <TAB> filt[key] = val <TAB> return filt",true,"if ""="" not in arg :","if ""="" not in arg :",0.75,0.0
"def pickline(file, key, casefold=1): <TAB> try: <TAB> <TAB> f = open(file, ""r"") <TAB> except IOError: <TAB> <TAB> return None <TAB> pat = re.escape(key) + "":"" <TAB> prog = re.compile(pat, casefold and re.IGNORECASE) <TAB> while 1: <TAB> <TAB> line = f.readline() <TAB> <TAB> if not line: <TAB> <TAB> <TAB> break <TAB> <TAB> if prog.match(line): <TAB> <TAB> <TAB> text = line[len(key) + 1 :] <TAB> <TAB> <TAB> while 1: <TAB> <TAB> <TAB> <TAB> line = f.readline() <TAB> <TAB> <TAB> <TAB> if not line or not line[0].isspace(): <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> text = text + line <TAB> <TAB> <TAB> return text.strip() <TAB> return None",true,if prog . match ( line ) :,if prog . match ( line ) :,0.75,0.0
"def delete_doc(elastic_document_id, node, index=None, category=None): <TAB> index = index or INDEX <TAB> if not category: <TAB> <TAB> if isinstance(node, Preprint): <TAB> <TAB> <TAB> category = ""preprint"" <TAB> <TAB> elif node.is_registration: <TAB> <TAB> <TAB> category = ""registration"" <TAB> <TAB> else: <TAB> <TAB> <TAB> category = node.project_or_component <TAB> client().delete( <TAB> <TAB> index=index, <TAB> <TAB> doc_type=category, <TAB> <TAB> id=elastic_document_id, <TAB> <TAB> refresh=True, <TAB> <TAB> ignore=[404], <TAB> )",false,"if isinstance ( node , Preprint ) :",elif node . is_registration :,0.02,0.0
"def update(self, preds, labels): <TAB> if not _is_numpy_(labels): <TAB> <TAB> raise ValueError(""The 'labels' must be a numpy ndarray."") <TAB> if not _is_numpy_(preds): <TAB> <TAB> raise ValueError(""The 'predictions' must be a numpy ndarray."") <TAB> for i, lbl in enumerate(labels): <TAB> <TAB> value = preds[i, 1] <TAB> <TAB> bin_idx = int(value * self._num_thresholds) <TAB> <TAB> assert bin_idx <= self._num_thresholds <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._stat_pos[bin_idx] += 1.0 <TAB> <TAB> else: <TAB> <TAB> <TAB> self._stat_neg[bin_idx] += 1.0",false,if lbl :,if lbl == lbl :,0.12,0.0
"def checkStatusClient(self): <TAB> if str(self.comboxBoxIPAddress.currentText()) != """": <TAB> <TAB> if self.ClientsLogged[str(self.comboxBoxIPAddress.currentText())][""Status""]: <TAB> <TAB> <TAB> self.btnEnable.setEnabled(False) <TAB> <TAB> <TAB> self.btncancel.setEnabled(True) <TAB> <TAB> <TAB> return None <TAB> <TAB> self.btnEnable.setEnabled(True) <TAB> <TAB> self.btncancel.setEnabled(False)",true,"if self . ClientsLogged [ str ( self . comboxBoxIPAddress . currentText ( ) ) ] [ ""Status"" ] :","if self . ClientsLogged [ str ( self . comboxBoxIPAddress . currentText ( ) ) ] [ ""Status"" ] :",1.0,0.0
"def colorizeDiffs(sheet, col, row, cellval): <TAB> if not row or not col: <TAB> <TAB> return None <TAB> vcolidx = sheet.visibleCols.index(col) <TAB> rowidx = sheet.rows.index(row) <TAB> if vcolidx < len(othersheet.visibleCols) and rowidx < len(othersheet.rows): <TAB> <TAB> otherval = othersheet.visibleCols[vcolidx].getDisplayValue( <TAB> <TAB> <TAB> othersheet.rows[rowidx] <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ""color_diff"" <TAB> else: <TAB> <TAB> return ""color_diff_add""",false,if cellval . display != otherval :,if otherval == cellval :,0.03,0.0
"def identwaf(self, findall=False): <TAB> detected = list() <TAB> try: <TAB> <TAB> self.attackres = self.performCheck(self.centralAttack) <TAB> except RequestBlocked: <TAB> <TAB> return detected <TAB> for wafvendor in self.checklist: <TAB> <TAB> self.log.info(""Checking for %s"" % wafvendor) <TAB> <TAB> if self.wafdetections[wafvendor](self): <TAB> <TAB> <TAB> detected.append(wafvendor) <TAB> <TAB> <TAB> if not findall: <TAB> <TAB> <TAB> <TAB> break <TAB> self.knowledge[""wafname""] = detected <TAB> return detected",true,if self . wafdetections [ wafvendor ] ( self ) :,if self . wafdetections [ wafvendor ] ( self ) :,1.0,0.0
"def get_repository_metadata_by_repository_id_changeset_revision( <TAB> app, id, changeset_revision, metadata_only=False ): <TAB> """"""Get a specified metadata record for a specified repository in the tool shed."""""" <TAB> if metadata_only: <TAB> <TAB> repository_metadata = get_repository_metadata_by_changeset_revision( <TAB> <TAB> <TAB> app, id, changeset_revision <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return repository_metadata.metadata <TAB> <TAB> return None <TAB> return get_repository_metadata_by_changeset_revision(app, id, changeset_revision)",false,if repository_metadata and repository_metadata . metadata :,if repository_metadata :,0.04,0.0
"def getmultiline(self): <TAB> line = self.getline() <TAB> if line[3:4] == ""-"": <TAB> <TAB> code = line[:3] <TAB> <TAB> while 1: <TAB> <TAB> <TAB> nextline = self.getline() <TAB> <TAB> <TAB> line = line + (""\n"" + nextline) <TAB> <TAB> <TAB> if nextline[:3] == code and nextline[3:4] != ""-"": <TAB> <TAB> <TAB> <TAB> break <TAB> return line",true,"if nextline [ : 3 ] == code and nextline [ 3 : 4 ] != ""-"" :","if nextline [ : 3 ] == code and nextline [ 3 : 4 ] != ""-"" :",0.75,0.0
"def _validate_reports(value, *args, **kwargs): <TAB> from osf.models import OSFUser <TAB> for key, val in value.items(): <TAB> <TAB> if not OSFUser.load(key): <TAB> <TAB> <TAB> raise ValidationValueError(""Keys must be user IDs"") <TAB> <TAB> if not isinstance(val, dict): <TAB> <TAB> <TAB> raise ValidationTypeError(""Values must be dictionaries"") <TAB> <TAB> if ( <TAB> <TAB> <TAB> ""category"" not in val <TAB> <TAB> <TAB> or ""text"" not in val <TAB> <TAB> <TAB> or ""date"" not in val <TAB> <TAB> <TAB> or ""retracted"" not in val <TAB> <TAB> ): <TAB> <TAB> <TAB> raise ValidationValueError( <TAB> <TAB> <TAB> <TAB> (""Values must include `date`, `category`, "", ""`text`, `retracted` keys"") <TAB> <TAB> <TAB> )",true,"if not isinstance ( val , dict ) :","if not isinstance ( val , dict ) :",0.75,0.0
"def deselectItem(self, item): <TAB> if self.isSelected(item): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> listItem = self._getListItem(item) <TAB> <TAB> <TAB> selections = self.getSelectedItems() <TAB> <TAB> <TAB> selections.remove(self.loadHandler.getSelection(listItem)) <TAB> <TAB> <TAB> self.setSelections(selections) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.deselectAll()",false,if self . multiSelect :,if item in self . selectedItems :,0.22,0.0
"def __init__(self, **kwargs): <TAB> if self.name is None: <TAB> <TAB> raise RuntimeError(""RenderPrimitive cannot be used directly"") <TAB> self.option_values = {} <TAB> for key, val in kwargs.items(): <TAB> <TAB> if not key in self.options: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""primitive `{0}' has no option `{1}'"".format(self.name, key) <TAB> <TAB> <TAB> ) <TAB> <TAB> self.option_values[key] = val <TAB> # set up defaults <TAB> for name, (description, default) in self.options.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.option_values[name] = default",false,if not name in self . option_values :,if description :,0.06,0.0
"def setup_smart_indent(self, view, lang): <TAB> # Configure a ""per-view"" instance <TAB> if type(view) == gedit.View: <TAB> <TAB> if getattr(view, ""smart_indent_instance"", False) == False: <TAB> <TAB> <TAB> setattr(view, ""smart_indent_instance"", SmartIndent()) <TAB> <TAB> <TAB> handler_id = view.connect( <TAB> <TAB> <TAB> <TAB> ""key-press-event"", view.smart_indent_instance.key_press_handler <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self.handler_ids.append((handler_id, view)) <TAB> <TAB> view.smart_indent_instance.set_language(lang, view)",true,"if getattr ( view , ""smart_indent_instance"" , False ) == False :","if getattr ( view , ""smart_indent_instance"" , False ) == False :",1.0,0.0
"def get_strings_of_set(word, char_set, threshold=20): <TAB> count = 0 <TAB> letters = """" <TAB> strings = [] <TAB> for char in word: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> letters += char <TAB> <TAB> <TAB> count += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> if count > threshold: <TAB> <TAB> <TAB> <TAB> strings.append(letters) <TAB> <TAB> <TAB> letters = """" <TAB> <TAB> <TAB> count = 0 <TAB> if count > threshold: <TAB> <TAB> strings.append(letters) <TAB> return strings",true,if char in char_set :,if char in char_set :,0.75,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB> if tt == 10: <TAB> <TAB> <TAB> self.set_logout_url(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 0 :,if tt == 0 :,0.75,0.0
def __create_table(self): <TAB> for i in range(256): <TAB> <TAB> crcreg = i <TAB> <TAB> for j in range(8): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> crcreg = self.__CRCPOLYNOMIAL ^ (crcreg >> 1) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> crcreg >>= 1 <TAB> <TAB> self.__crctable[i] = crcreg,false,if ( crcreg & 1 ) != 0 :,if j == 0 :,0.08,0.0
"def destroy(self): <TAB> """"""Flush all entries and empty cache"""""" <TAB> # Note: this method is currently also used for dropping the cache <TAB> for i in range(len(self.cached_rows)): <TAB> <TAB> id_ = self.cached_rows[i] <TAB> <TAB> self.cached_rows[i] = None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> inode = self.attrs[id_] <TAB> <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> <TAB> # We may have deleted that inode <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> del self.attrs[id_] <TAB> <TAB> <TAB> <TAB> self.setattr(inode) <TAB> assert len(self.attrs) == 0",false,if id_ is not None :,if id_ in self . attrs :,0.2,0.0
"def set_config(self): <TAB> """"""Set configuration options for QTextEdit."""""" <TAB> c = self.c <TAB> w = self.widget <TAB> w.setWordWrapMode(QtGui.QTextOption.NoWrap) <TAB> if 0:  # This only works when there is no style sheet. <TAB> <TAB> n = c.config.getInt(""qt-rich-text-zoom-in"") <TAB> <TAB> if n not in (None, 0): <TAB> <TAB> <TAB> w.zoomIn(n) <TAB> <TAB> <TAB> w.updateMicroFocus() <TAB> # tab stop in pixels - no config for this (yet) <TAB> w.setTabStopWidth(24)",true,"if n not in ( None , 0 ) :","if n not in ( None , 0 ) :",0.75,0.0
"def mouseDragEvent(self, ev): <TAB> if self.movable and ev.button() == QtCore.Qt.LeftButton: <TAB> <TAB> if ev.isStart(): <TAB> <TAB> <TAB> self.moving = True <TAB> <TAB> <TAB> self.cursorOffset = self.pos() - self.mapToParent(ev.buttonDownPos()) <TAB> <TAB> <TAB> self.startPosition = self.pos() <TAB> <TAB> ev.accept() <TAB> <TAB> if not self.moving: <TAB> <TAB> <TAB> return <TAB> <TAB> self.setPos(self.cursorOffset + self.mapToParent(ev.pos())) <TAB> <TAB> self.sigDragged.emit(self) <TAB> <TAB> if ev.isFinish(): <TAB> <TAB> <TAB> self.moving = False <TAB> <TAB> <TAB> self.sigPositionChangeFinished.emit(self)",true,if ev . isFinish ( ) :,if ev . isFinish ( ) :,0.75,0.0
"def reparentChildren(self, newParent): <TAB> if newParent.childNodes: <TAB> <TAB> newParent.childNodes[-1]._element.tail += self._element.text <TAB> else: <TAB> <TAB> if not newParent._element.text: <TAB> <TAB> <TAB> newParent._element.text = """" <TAB> <TAB> if self._element.text is not None: <TAB> <TAB> <TAB> newParent._element.text += self._element.text <TAB> self._element.text = """" <TAB> base.Node.reparentChildren(self, newParent)",true,if self . _element . text is not None :,if self . _element . text is not None :,0.75,0.0
"def _no_sp_or_bp(self, bl): <TAB> for s in bl.vex.statements: <TAB> <TAB> for e in chain([s], s.expressions): <TAB> <TAB> <TAB> if e.tag == ""Iex_Get"": <TAB> <TAB> <TAB> <TAB> reg = self.get_reg_name(self.project.arch, e.offset) <TAB> <TAB> <TAB> <TAB> if reg == ""ebp"" or reg == ""esp"": <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> elif e.tag == ""Ist_Put"": <TAB> <TAB> <TAB> <TAB> reg = self.get_reg_name(self.project.arch, e.offset) <TAB> <TAB> <TAB> <TAB> if reg == ""ebp"" or reg == ""esp"": <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",false,"if e . tag == ""Iex_Get"" :","if reg == ""ebp"" or reg == ""esp"" :",0.02,0.0
"def _get_import_chain(self, *, until=None): <TAB> stack = inspect.stack()[2:] <TAB> try: <TAB> <TAB> for frameinfo in stack: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> data = dedent("""".join(frameinfo.code_context)) <TAB> <TAB> <TAB> <TAB> if data.strip() == until: <TAB> <TAB> <TAB> <TAB> <TAB> raise StopIteration <TAB> <TAB> <TAB> <TAB> yield frameinfo.filename, frameinfo.lineno, data.strip() <TAB> <TAB> <TAB> <TAB> del data <TAB> <TAB> <TAB> finally: <TAB> <TAB> <TAB> <TAB> del frameinfo <TAB> finally: <TAB> <TAB> del stack",false,if not frameinfo . code_context :,if frameinfo . filename == self . filename :,0.04,0.0
"def stream_docker_log(log_stream): <TAB> async for line in log_stream: <TAB> <TAB> if ""stream"" in line and line[""stream""].strip(): <TAB> <TAB> <TAB> logger.debug(line[""stream""].strip()) <TAB> <TAB> elif ""status"" in line: <TAB> <TAB> <TAB> logger.debug(line[""status""].strip()) <TAB> <TAB> elif ""error"" in line: <TAB> <TAB> <TAB> logger.error(line[""error""].strip()) <TAB> <TAB> <TAB> raise DockerBuildError",true,"elif ""error"" in line :","elif ""error"" in line :",0.75,0.0
"def get_cycle_path(self, curr_node, goal_node_index): <TAB> for dep in curr_node[""deps""]: <TAB> <TAB> if dep == goal_node_index: <TAB> <TAB> <TAB> return [curr_node[""address""]] <TAB> for dep in curr_node[""deps""]: <TAB> <TAB> path = self.get_cycle_path( <TAB> <TAB> <TAB> self.get_by_address(dep), goal_node_index <TAB> <TAB> )  # self.nodelist[dep], goal_node_index) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> path.insert(0, curr_node[""address""]) <TAB> <TAB> <TAB> return path <TAB> return []",false,if len ( path ) > 0 :,if path :,0.02,0.0
"def prompt(default=None): <TAB> editor = ""nano"" <TAB> with tempfile.NamedTemporaryFile(mode=""r+"") as tmpfile: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tmpfile.write(default) <TAB> <TAB> <TAB> tmpfile.flush() <TAB> <TAB> child_pid = os.fork() <TAB> <TAB> is_child = child_pid == 0 <TAB> <TAB> if is_child: <TAB> <TAB> <TAB> os.execvp(editor, [editor, tmpfile.name]) <TAB> <TAB> else: <TAB> <TAB> <TAB> os.waitpid(child_pid, 0) <TAB> <TAB> <TAB> tmpfile.seek(0) <TAB> <TAB> <TAB> return tmpfile.read().strip()",false,if default :,if default is not None :,0.09,0.0
"def _get_annotated_template(self, template): <TAB> changed = False <TAB> if template.get(""version"", ""0.12.0"") >= ""0.13.0"": <TAB> <TAB> using_js = self.spider._filter_js_urls(template[""url""]) <TAB> <TAB> body = ""rendered_body"" if using_js else ""original_body"" <TAB> <TAB> if template.get(""body"") != body: <TAB> <TAB> <TAB> template[""body""] = body <TAB> <TAB> <TAB> changed = True <TAB> if changed or not template.get(""annotated""): <TAB> <TAB> _build_sample(template) <TAB> return template",false,"if template . get ( ""body"" ) != body :","if changed or not template . get ( ""annotated"" ) :",0.15,0.0
"def collect(self, paths): <TAB> for path in paths or (): <TAB> <TAB> relpath = os.path.relpath(path, self._artifact_root) <TAB> <TAB> dst = os.path.join(self._directory, relpath) <TAB> <TAB> safe_mkdir(os.path.dirname(dst)) <TAB> <TAB> if os.path.isdir(path): <TAB> <TAB> <TAB> shutil.copytree(path, dst) <TAB> <TAB> else: <TAB> <TAB> <TAB> shutil.copy(path, dst) <TAB> <TAB> self._relpaths.add(relpath)",true,if os . path . isdir ( path ) :,if os . path . isdir ( path ) :,1.0,0.0
"def dependencies(context=None): <TAB> """"""Return all dependencies detected by knowit."""""" <TAB> deps = OrderedDict([]) <TAB> try: <TAB> <TAB> initialize(context) <TAB> <TAB> for name, provider_cls in _provider_map.items(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> deps[name] = available_providers[name].version <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> deps[name] = {} <TAB> except Exception: <TAB> <TAB> pass <TAB> return deps",false,if name in available_providers :,if provider_cls is not None :,0.16,0.0
"def _getaddrinfo(self, host_bytes, port, family, socktype, proto, flags): <TAB> while True: <TAB> <TAB> ares = self.cares <TAB> <TAB> try: <TAB> <TAB> <TAB> return self.__getaddrinfo(host_bytes, port, family, socktype, proto, flags) <TAB> <TAB> except gaierror: <TAB> <TAB> <TAB> if ares is self.cares: <TAB> <TAB> <TAB> <TAB> raise",true,if ares is self . cares :,if ares is self . cares :,0.75,0.0
"def write_entries(cmd, basename, filename): <TAB> ep = cmd.distribution.entry_points <TAB> if isinstance(ep, basestring) or ep is None: <TAB> <TAB> data = ep <TAB> elif ep is not None: <TAB> <TAB> data = [] <TAB> <TAB> for section, contents in ep.items(): <TAB> <TAB> <TAB> if not isinstance(contents, basestring): <TAB> <TAB> <TAB> <TAB> contents = EntryPoint.parse_group(section, contents) <TAB> <TAB> <TAB> <TAB> contents = ""\n"".join(map(str, contents.values())) <TAB> <TAB> <TAB> data.append(""[%s]\n%s\n\n"" % (section, contents)) <TAB> <TAB> data = """".join(data) <TAB> cmd.write_or_delete_file(""entry points"", filename, data, True)",true,"if not isinstance ( contents , basestring ) :","if not isinstance ( contents , basestring ) :",0.75,0.0
"def _highlight_do(self): <TAB> new_hl_text = self.highlight_text.text() <TAB> if new_hl_text != self.hl_text: <TAB> <TAB> self.hl_text = new_hl_text <TAB> <TAB> if self.hl is not None: <TAB> <TAB> <TAB> self.hl.setDocument(None) <TAB> <TAB> <TAB> self.hl = None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.hl = Highlighter(self.hl_text, parent=self.doc) <TAB> <TAB> self.clear_highlight_button.setEnabled(bool(self.hl))",false,if self . hl_text :,if self . hl_text is not None :,0.35,0.0
"def traverse(node, functions=[]): <TAB> if hasattr(node, ""grad_fn""): <TAB> <TAB> node = node.grad_fn <TAB> if hasattr(node, ""variable""): <TAB> <TAB> node = graph.nodes_by_id.get(id(node.variable)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> node.functions = list(functions) <TAB> <TAB> <TAB> del functions[:] <TAB> if hasattr(node, ""next_functions""): <TAB> <TAB> functions.append(type(node).__name__) <TAB> <TAB> for f in node.next_functions: <TAB> <TAB> <TAB> if f[0]: <TAB> <TAB> <TAB> <TAB> functions.append(type(f[0]).__name__) <TAB> <TAB> <TAB> <TAB> traverse(f[0], functions) <TAB> if hasattr(node, ""saved_tensors""): <TAB> <TAB> for t in node.saved_tensors: <TAB> <TAB> <TAB> traverse(t)",false,if node :,if functions :,0.32,0.0
"def compress(self, data_list): <TAB> if data_list: <TAB> <TAB> page_id = data_list[1] <TAB> <TAB> if page_id in EMPTY_VALUES: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> raise forms.ValidationError(self.error_messages[""invalid_page""]) <TAB> <TAB> return Page.objects.get(pk=page_id) <TAB> return None",false,if not self . required :,if page_id in self . error_messages :,0.05,0.0
"def test_field_attr_existence(self): <TAB> for name, item in ast.__dict__.items(): <TAB> <TAB> if self._is_ast_node(name, item): <TAB> <TAB> <TAB> if name == ""Index"": <TAB> <TAB> <TAB> <TAB> # Index(value) just returns value now. <TAB> <TAB> <TAB> <TAB> # The argument is required. <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> x = item() <TAB> <TAB> <TAB> if isinstance(x, ast.AST): <TAB> <TAB> <TAB> <TAB> self.assertEqual(type(x._fields), tuple)",true,"if isinstance ( x , ast . AST ) :","if isinstance ( x , ast . AST ) :",0.75,0.0
"def handle_starttag(self, tag, attrs): <TAB> if tag == ""base"": <TAB> <TAB> self.base_url = dict(attrs).get(""href"") <TAB> if self.scan_tag(tag): <TAB> <TAB> for attr, value in attrs: <TAB> <TAB> <TAB> if self.scan_attr(attr): <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> value = strip_html5_whitespace(value) <TAB> <TAB> <TAB> <TAB> url = self.process_attr(value) <TAB> <TAB> <TAB> <TAB> link = Link(url=url) <TAB> <TAB> <TAB> <TAB> self.links.append(link) <TAB> <TAB> <TAB> <TAB> self.current_link = link",false,if self . strip :,if value :,0.04,0.0
"def _initialize_asset_map(cls): <TAB> # Generating a list of acceptable asset files reduces the possibility of <TAB> # path attacks. <TAB> cls._asset_name_to_path = {} <TAB> assets = os.listdir(ASSETS_PATH) <TAB> for asset in assets: <TAB> <TAB> path = os.path.join(ASSETS_PATH, asset) <TAB> <TAB> if os.path.isfile(path): <TAB> <TAB> <TAB> cls._asset_name_to_path[os.path.basename(path)] = path",true,if os . path . isfile ( path ) :,if os . path . isfile ( path ) :,1.0,0.0
"def dataReceived(self, data): <TAB> self.buf += data <TAB> if self._paused: <TAB> <TAB> log.startLogging(sys.stderr) <TAB> <TAB> log.msg(""dataReceived while transport paused!"") <TAB> <TAB> self.transport.loseConnection() <TAB> else: <TAB> <TAB> self.transport.write(data) <TAB> <TAB> if self.buf.endswith(b""\n0\n""): <TAB> <TAB> <TAB> self.transport.loseConnection() <TAB> <TAB> else: <TAB> <TAB> <TAB> self.pause()",true,"if self . buf . endswith ( b""\n0\n"" ) :","if self . buf . endswith ( b""\n0\n"" ) :",0.75,0.0
"def test_case_sensitive(self): <TAB> with support.EnvironmentVarGuard() as env: <TAB> <TAB> env.unset(""PYTHONCASEOK"") <TAB> <TAB> if b""PYTHONCASEOK"" in _bootstrap_external._os.environ: <TAB> <TAB> <TAB> self.skipTest(""os.environ changes not reflected in "" ""_os.environ"") <TAB> <TAB> loader = self.find_module() <TAB> <TAB> self.assertIsNone(loader)",true,"if b""PYTHONCASEOK"" in _bootstrap_external . _os . environ :","if b""PYTHONCASEOK"" in _bootstrap_external . _os . environ :",0.75,0.0
"def manifest(self): <TAB> """"""The current manifest dictionary."""""" <TAB> if self.reload: <TAB> <TAB> if not self.exists(self.manifest_path): <TAB> <TAB> <TAB> return {} <TAB> <TAB> mtime = self.getmtime(self.manifest_path) <TAB> <TAB> if self._mtime is None or mtime > self._mtime: <TAB> <TAB> <TAB> self._manifest = self.get_manifest() <TAB> <TAB> <TAB> self._mtime = mtime <TAB> return self._manifest",true,if self . _mtime is None or mtime > self . _mtime :,if self . _mtime is None or mtime > self . _mtime :,0.75,0.0
"def test_named_parameters_and_constraints(self): <TAB> likelihood = gpytorch.likelihoods.GaussianLikelihood() <TAB> model = ExactGPModel(None, None, likelihood) <TAB> for name, _param, constraint in model.named_parameters_and_constraints(): <TAB> <TAB> if name == ""likelihood.noise_covar.raw_noise"": <TAB> <TAB> <TAB> self.assertIsInstance(constraint, gpytorch.constraints.GreaterThan) <TAB> <TAB> elif name == ""mean_module.constant"": <TAB> <TAB> <TAB> self.assertIsNone(constraint) <TAB> <TAB> elif name == ""covar_module.raw_outputscale"": <TAB> <TAB> <TAB> self.assertIsInstance(constraint, gpytorch.constraints.Positive) <TAB> <TAB> elif name == ""covar_module.base_kernel.raw_lengthscale"": <TAB> <TAB> <TAB> self.assertIsInstance(constraint, gpytorch.constraints.Positive)",false,"if name == ""likelihood.noise_covar.raw_noise"" :","elif name == ""covar_module.base_kernel.raw_lengthscale"" :",0.06,0.0
"def process_plugin_result(name, result): <TAB> if result: <TAB> <TAB> try: <TAB> <TAB> <TAB> jsonify(test=result) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> logger.exception( <TAB> <TAB> <TAB> <TAB> ""Error while jsonifying settings from plugin {}, please contact the plugin author about this"".format( <TAB> <TAB> <TAB> <TAB> <TAB> name <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> raise <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> del result[""__enabled""] <TAB> <TAB> <TAB> data[name] = result",true,"if ""__enabled"" in result :","if ""__enabled"" in result :",0.75,0.0
"def benchmarking(net, ctx, num_iteration, datashape=300, batch_size=64): <TAB> input_shape = (batch_size, 3) + (datashape, datashape) <TAB> data = mx.random.uniform(-1.0, 1.0, shape=input_shape, ctx=ctx, dtype=""float32"") <TAB> dryrun = 5 <TAB> for i in range(dryrun + num_iteration): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tic = time.time() <TAB> <TAB> ids, scores, bboxes = net(data) <TAB> <TAB> ids.asnumpy() <TAB> <TAB> scores.asnumpy() <TAB> <TAB> bboxes.asnumpy() <TAB> toc = time.time() - tic <TAB> return toc",false,if i == dryrun :,if i % 10000 == 0 :,0.06,0.0
"def merge_weekdays(base_wd, icu_wd): <TAB> result = [] <TAB> for left, right in zip(base_wd, icu_wd): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result.append(left) <TAB> <TAB> <TAB> continue <TAB> <TAB> left = set(left.split(""|"")) <TAB> <TAB> right = set(right.split(""|"")) <TAB> <TAB> result.append(""|"".join(left | right)) <TAB> return result",true,if left == right :,if left == right :,0.75,0.0
"def create_key(self, request): <TAB> if self._ignored_parameters: <TAB> <TAB> url, body = self._remove_ignored_parameters(request) <TAB> else: <TAB> <TAB> url, body = request.url, request.body <TAB> key = hashlib.sha256() <TAB> key.update(_to_bytes(request.method.upper())) <TAB> key.update(_to_bytes(url)) <TAB> if request.body: <TAB> <TAB> key.update(_to_bytes(body)) <TAB> else: <TAB> <TAB> if self._include_get_headers and request.headers != _DEFAULT_HEADERS: <TAB> <TAB> <TAB> for name, value in sorted(request.headers.items()): <TAB> <TAB> <TAB> <TAB> key.update(_to_bytes(name)) <TAB> <TAB> <TAB> <TAB> key.update(_to_bytes(value)) <TAB> return key.hexdigest()",true,if self . _include_get_headers and request . headers != _DEFAULT_HEADERS :,if self . _include_get_headers and request . headers != _DEFAULT_HEADERS :,0.75,0.0
"def test_invalid_mountinfo(self): <TAB> line = ( <TAB> <TAB> ""20 1 252:1 / / rw,relatime - ext4 /dev/mapper/vg0-root"" <TAB> <TAB> ""rw,errors=remount-ro,data=ordered"" <TAB> ) <TAB> elements = line.split() <TAB> for i in range(len(elements) + 1): <TAB> <TAB> lines = ["" "".join(elements[0:i])] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> expected = None <TAB> <TAB> else: <TAB> <TAB> <TAB> expected = (""/dev/mapper/vg0-root"", ""ext4"", ""/"") <TAB> <TAB> self.assertEqual(expected, util.parse_mount_info(""/"", lines))",false,if i < 10 :,if i == 0 :,0.31,0.0
"def nested_filter(self, items, mask): <TAB> keep_current = self.current_mask(mask) <TAB> keep_nested_lookup = self.nested_masks(mask) <TAB> for k, v in items: <TAB> <TAB> keep_nested = keep_nested_lookup.get(k) <TAB> <TAB> if k in keep_current: <TAB> <TAB> <TAB> if keep_nested is not None: <TAB> <TAB> <TAB> <TAB> if isinstance(v, dict): <TAB> <TAB> <TAB> <TAB> <TAB> yield k, dict(self.nested_filter(v.items(), keep_nested)) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> yield k, v",true,"if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",0.75,0.0
"def traverse_trees(node_pos, sample, trees: List[HeteroDecisionTreeGuest]): <TAB> if node_pos[""reach_leaf_node""].all(): <TAB> <TAB> return node_pos <TAB> for t_idx, tree in enumerate(trees): <TAB> <TAB> cur_node_idx = node_pos[""node_pos""][t_idx] <TAB> <TAB> # reach leaf <TAB> <TAB> if cur_node_idx == -1: <TAB> <TAB> <TAB> continue <TAB> <TAB> rs, reach_leaf = HeteroSecureBoostingTreeGuest.traverse_a_tree( <TAB> <TAB> <TAB> tree, sample, cur_node_idx <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> node_pos[""reach_leaf_node""][t_idx] = True <TAB> <TAB> node_pos[""node_pos""][t_idx] = rs <TAB> return node_pos",true,if reach_leaf :,if reach_leaf :,0.53,0.0
"def _pop_waiting_trial_id(self) -> Optional[int]: <TAB> # TODO(c-bata): Reduce database query counts for extracting waiting trials. <TAB> for trial in self._storage.get_all_trials(self._study_id, deepcopy=False): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not self._storage.set_trial_state(trial._trial_id, TrialState.RUNNING): <TAB> <TAB> <TAB> continue <TAB> <TAB> _logger.debug(""Trial {} popped from the trial queue."".format(trial.number)) <TAB> <TAB> return trial._trial_id <TAB> return None",false,if trial . state != TrialState . WAITING :,if trial . number is None :,0.13,0.0
"def get_step_best(self, step_models): <TAB> best_score = None <TAB> best_model = """" <TAB> for model in step_models: <TAB> <TAB> model_info = self.models_trained[model] <TAB> <TAB> score = model_info.get_score() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if best_score is None or score < best_score: <TAB> <TAB> <TAB> best_score = score <TAB> <TAB> <TAB> best_model = model <TAB> LOGGER.info(f""step {self.n_step}, best model {best_model}"") <TAB> return best_model",true,if score is None :,if score is None :,0.75,0.0
"def iter_filters(filters, block_end=False): <TAB> queue = deque(filters) <TAB> while queue: <TAB> <TAB> f = queue.popleft() <TAB> <TAB> if f is not None and f.type in (""or"", ""and"", ""not""): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> queue.appendleft(None) <TAB> <TAB> <TAB> for gf in f.filters: <TAB> <TAB> <TAB> <TAB> queue.appendleft(gf) <TAB> <TAB> yield f",true,if block_end :,if block_end :,0.53,0.0
"def _buffer_decode(self, input, errors, final): <TAB> if self.decoder is None: <TAB> <TAB> (output, consumed, byteorder) = codecs.utf_16_ex_decode(input, errors, 0, final) <TAB> <TAB> if byteorder == -1: <TAB> <TAB> <TAB> self.decoder = codecs.utf_16_le_decode <TAB> <TAB> elif byteorder == 1: <TAB> <TAB> <TAB> self.decoder = codecs.utf_16_be_decode <TAB> <TAB> elif consumed >= 2: <TAB> <TAB> <TAB> raise UnicodeError(""UTF-16 stream does not start with BOM"") <TAB> <TAB> return (output, consumed) <TAB> return self.decoder(input, self.errors, final)",false,elif byteorder == 1 :,elif consumed >= 2 :,0.03,0.0
"def _load_db(self): <TAB> try: <TAB> <TAB> with open(self.db) as db: <TAB> <TAB> <TAB> content = db.read(8) <TAB> <TAB> <TAB> db.seek(0) <TAB> <TAB> <TAB> if content == (""Salted__""): <TAB> <TAB> <TAB> <TAB> data = StringIO() <TAB> <TAB> <TAB> <TAB> if self.encryptor: <TAB> <TAB> <TAB> <TAB> <TAB> self.encryptor.decrypt(db, data) <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> raise EncryptionError( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""Encrpyted credential storage: {}"".format(self.db) <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return json.loads(data.getvalue()) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return json.load(db) <TAB> except: <TAB> <TAB> return {""creds"": []}",true,"if content == ( ""Salted__"" ) :","if content == ( ""Salted__"" ) :",0.75,0.0
"def _getbytes(self, start, l=1): <TAB> out = [] <TAB> for ad in range(l): <TAB> <TAB> offset = ad + start + self.base_address <TAB> <TAB> if not is_mapped(offset): <TAB> <TAB> <TAB> raise IOError(""not enough bytes"") <TAB> <TAB> out.append(int_to_byte(Byte(offset))) <TAB> return b"""".join(out)",true,if not is_mapped ( offset ) :,if not is_mapped ( offset ) :,0.75,0.0
"def cache_sqs_queues_across_accounts() -> bool: <TAB> function: str = f""{__name__}.{sys._getframe().f_code.co_name}"" <TAB> # First, get list of accounts <TAB> accounts_d: list = async_to_sync(get_account_id_to_name_mapping)() <TAB> # Second, call tasks to enumerate all the roles across all accounts <TAB> for account_id in accounts_d.keys(): <TAB> <TAB> if config.get(""environment"") == ""prod"": <TAB> <TAB> <TAB> cache_sqs_queues_for_account.delay(account_id) <TAB> <TAB> else: <TAB> <TAB> <TAB> if account_id in config.get(""celery.test_account_ids"", []): <TAB> <TAB> <TAB> <TAB> cache_sqs_queues_for_account.delay(account_id) <TAB> stats.count(f""{function}.success"") <TAB> return True",true,"if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :","if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :",0.75,0.0
"def insertLine(self, refnum, linenum, line): <TAB> i = -1 <TAB> for i, row in enumerate(self.rows): <TAB> <TAB> if row[0] == linenum: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> row[refnum + 1] = line <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> # else keep looking <TAB> <TAB> elif row[0] > linenum: <TAB> <TAB> <TAB> break <TAB> self.rows.insert(i, self.newRow(linenum, refnum, line))",false,if row [ refnum + 1 ] is None :,if i == refnum :,0.01,0.0
"def __setattr__(self, name, val): <TAB> if self.__dict__.get(name, ""hamster_graphics_no_value_really"") == val: <TAB> <TAB> return <TAB> Sprite.__setattr__(self, name, val) <TAB> if name == ""image_data"": <TAB> <TAB> self._surface = None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.__dict__[""width""] = self.image_data.get_width() <TAB> <TAB> <TAB> self.__dict__[""height""] = self.image_data.get_height()",true,if self . image_data :,if self . image_data :,0.75,0.0
"def process_signature(app, what, name, obj, options, signature, return_annotation): <TAB> if signature: <TAB> <TAB> # replace Mock function names <TAB> <TAB> signature = re.sub(""<Mock name='([^']+)'.*>"", ""\g<1>"", signature) <TAB> <TAB> signature = re.sub(""tensorflow"", ""tf"", signature) <TAB> <TAB> # add scope name to layer signatures: <TAB> <TAB> if hasattr(obj, ""use_scope""): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> signature = signature[0] + ""variable_scope_name, "" + signature[1:] <TAB> <TAB> <TAB> elif obj.use_scope is None: <TAB> <TAB> <TAB> <TAB> signature = signature[0] + ""[variable_scope_name,] "" + signature[1:] <TAB> # signature: arg list <TAB> return signature, return_annotation",false,if obj . use_scope :,if obj . use_scope is None :,0.37,0.0
"def L_op(self, inputs, outputs, gout): <TAB> (x,) = inputs <TAB> (gz,) = gout <TAB> if x.type in complex_types: <TAB> <TAB> raise NotImplementedError() <TAB> if outputs[0].type in discrete_types: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return [x.zeros_like(dtype=theano.config.floatX)] <TAB> <TAB> else: <TAB> <TAB> <TAB> return [x.zeros_like()] <TAB> return (gz * (1 - sqr(tanh(x))),)",true,if x . type in discrete_types :,if x . type in discrete_types :,0.75,0.0
"def confirm_on_console(topic, msg): <TAB> done = False <TAB> print(topic) <TAB> while not done: <TAB> <TAB> output = raw_input(msg + "":[y/n]"") <TAB> <TAB> if output.lower() == ""y"": <TAB> <TAB> <TAB> return True <TAB> <TAB> if output.lower() == ""n"": <TAB> <TAB> <TAB> return False",true,"if output . lower ( ) == ""y"" :","if output . lower ( ) == ""y"" :",0.75,0.0
"def replace_documentation_for_matching_shape(self, event_name, section, **kwargs): <TAB> if self._shape_name == section.context.get(""shape""): <TAB> <TAB> self._replace_documentation(event_name, section) <TAB> for section_name in section.available_sections: <TAB> <TAB> sub_section = section.get_section(section_name) <TAB> <TAB> if self._shape_name == sub_section.context.get(""shape""): <TAB> <TAB> <TAB> self._replace_documentation(event_name, sub_section) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.replace_documentation_for_matching_shape(event_name, sub_section)",true,"if self . _shape_name == sub_section . context . get ( ""shape"" ) :","if self . _shape_name == sub_section . context . get ( ""shape"" ) :",0.75,0.0
"def confirm_on_console(topic, msg): <TAB> done = False <TAB> print(topic) <TAB> while not done: <TAB> <TAB> output = raw_input(msg + "":[y/n]"") <TAB> <TAB> if output.lower() == ""y"": <TAB> <TAB> <TAB> return True <TAB> <TAB> if output.lower() == ""n"": <TAB> <TAB> <TAB> return False",false,"if output . lower ( ) == ""n"" :","if output . lower ( ) == ""y"" :",0.63,0.0
"def __getitem__(self, index): <TAB> if self._check(): <TAB> <TAB> if isinstance(index, int): <TAB> <TAB> <TAB> if index < 0 or index >= len(self.features): <TAB> <TAB> <TAB> <TAB> raise IndexError(index) <TAB> <TAB> <TAB> if self.features[index] is None: <TAB> <TAB> <TAB> <TAB> feature = self.device.feature_request(FEATURE.FEATURE_SET, 0x10, index) <TAB> <TAB> <TAB> <TAB> if feature: <TAB> <TAB> <TAB> <TAB> <TAB> (feature,) = _unpack(""!H"", feature[:2]) <TAB> <TAB> <TAB> <TAB> <TAB> self.features[index] = FEATURE[feature] <TAB> <TAB> <TAB> return self.features[index] <TAB> <TAB> elif isinstance(index, slice): <TAB> <TAB> <TAB> indices = index.indices(len(self.features)) <TAB> <TAB> <TAB> return [self.__getitem__(i) for i in range(*indices)]",false,if index < 0 or index >= len ( self . features ) :,"if isinstance ( index , int ) :",0.02,0.0
"def _parse_locator(self, locator): <TAB> prefix = None <TAB> criteria = locator <TAB> if not locator.startswith(""//""): <TAB> <TAB> locator_parts = locator.partition(""="") <TAB> <TAB> if len(locator_parts[1]) > 0: <TAB> <TAB> <TAB> prefix = locator_parts[0] <TAB> <TAB> <TAB> criteria = locator_parts[2].strip() <TAB> return (prefix, criteria)",true,if len ( locator_parts [ 1 ] ) > 0 :,if len ( locator_parts [ 1 ] ) > 0 :,0.75,0.0
"def trakt_episode_data_generate(self, data): <TAB> # Find how many unique season we have <TAB> uniqueSeasons = [] <TAB> for season, episode in data: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> uniqueSeasons.append(season) <TAB> # build the query <TAB> seasonsList = [] <TAB> for searchedSeason in uniqueSeasons: <TAB> <TAB> episodesList = [] <TAB> <TAB> for season, episode in data: <TAB> <TAB> <TAB> if season == searchedSeason: <TAB> <TAB> <TAB> <TAB> episodesList.append({""number"": episode}) <TAB> <TAB> seasonsList.append({""number"": searchedSeason, ""episodes"": episodesList}) <TAB> post_data = {""seasons"": seasonsList} <TAB> return post_data",true,if season not in uniqueSeasons :,if season not in uniqueSeasons :,0.75,0.0
"def __init__(self, data, n_bins): <TAB> bin_width = span / n_bins <TAB> bins = [0] * n_bins <TAB> for x in data: <TAB> <TAB> b = int(mpfloor((x - minimum) / bin_width)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> b = 0 <TAB> <TAB> elif b >= n_bins: <TAB> <TAB> <TAB> b = n_bins - 1 <TAB> <TAB> bins[b] += 1 <TAB> self.bins = bins <TAB> self.bin_width = bin_width",true,if b < 0 :,if b < 0 :,0.75,0.0
"def infer_context(typ, context=""http://schema.org""): <TAB> parsed_context = urlparse(typ) <TAB> if parsed_context.netloc: <TAB> <TAB> base = """".join([parsed_context.scheme, ""://"", parsed_context.netloc]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> context = urljoin(base, parsed_context.path) <TAB> <TAB> <TAB> typ = parsed_context.fragment.strip(""/"") <TAB> <TAB> elif parsed_context.path: <TAB> <TAB> <TAB> context = base <TAB> <TAB> <TAB> typ = parsed_context.path.strip(""/"") <TAB> return context, typ",false,if parsed_context . path and parsed_context . fragment :,if parsed_context . fragment :,0.3,0.0
"def parse(self, items): <TAB> for index, item in enumerate(items): <TAB> <TAB> keys = self.build_key(item) <TAB> <TAB> if keys is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> # Update `items` <TAB> <TAB> self.items[tuple(keys)] = (index, item) <TAB> <TAB> # Update `table` <TAB> <TAB> if not self.path_set(self.table, keys, (index, item)): <TAB> <TAB> <TAB> log.info(""Unable to update table (keys: %r)"", keys)",true,"if not self . path_set ( self . table , keys , ( index , item ) ) :","if not self . path_set ( self . table , keys , ( index , item ) ) :",1.0,0.0
"def dict_to_XML(tag, dictionary, **kwargs): <TAB> """"""Return XML element converting dicts recursively."""""" <TAB> elem = Element(tag, **kwargs) <TAB> for key, val in dictionary.items(): <TAB> <TAB> if tag == ""layers"": <TAB> <TAB> <TAB> child = dict_to_XML(""layer"", val, name=key) <TAB> <TAB> elif isinstance(val, MutableMapping): <TAB> <TAB> <TAB> child = dict_to_XML(key, val) <TAB> <TAB> else: <TAB> <TAB> <TAB> if tag == ""config"": <TAB> <TAB> <TAB> <TAB> child = Element(""variable"", name=key) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> child = Element(key) <TAB> <TAB> <TAB> child.text = str(val) <TAB> <TAB> elem.append(child) <TAB> return elem",false,"if tag == ""config"" :","if tag == ""layers"" :",0.39,0.0
"def _get_config_value(self, section, key): <TAB> if section: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.log.error(""Error: Config section '%s' not found"", section) <TAB> <TAB> <TAB> return None <TAB> <TAB> return self.config[section].get(key, self.config[key]) <TAB> else: <TAB> <TAB> return self.config[key]",true,if section not in self . config :,if section not in self . config :,0.75,0.0
"def h_line_down(self, input): <TAB> end_this_line = self.value.find(""\n"", self.cursor_position) <TAB> if end_this_line == -1: <TAB> <TAB> if self.scroll_exit: <TAB> <TAB> <TAB> self.h_exit_down(None) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.cursor_position = len(self.value) <TAB> else: <TAB> <TAB> self.cursor_position = end_this_line + 1 <TAB> <TAB> for x in range(self.cursorx): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> elif self.value[self.cursor_position] == ""\n"": <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.cursor_position += 1",false,if self . cursor_position > len ( self . value ) - 1 :,if self . value [ x ] == input :,0.12,0.0
"def printsumfp(fp, filename, out=sys.stdout): <TAB> m = md5() <TAB> try: <TAB> <TAB> while 1: <TAB> <TAB> <TAB> data = fp.read(bufsize) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if isinstance(data, str): <TAB> <TAB> <TAB> <TAB> data = data.encode(fp.encoding) <TAB> <TAB> <TAB> m.update(data) <TAB> except IOError as msg: <TAB> <TAB> sys.stderr.write(""%s: I/O error: %s\n"" % (filename, msg)) <TAB> <TAB> return 1 <TAB> out.write(""%s %s\n"" % (m.hexdigest(), filename)) <TAB> return 0",true,if not data :,if not data :,0.75,0.0
"def main(input): <TAB> logging.info(""Running Azure Cloud Custodian Policy %s"", input) <TAB> context = { <TAB> <TAB> ""config_file"": join(function_directory, ""config.json""), <TAB> <TAB> ""auth_file"": join(function_directory, ""auth.json""), <TAB> } <TAB> event = None <TAB> subscription_id = None <TAB> if isinstance(input, QueueMessage): <TAB> <TAB> if input.dequeue_count > max_dequeue_count: <TAB> <TAB> <TAB> return <TAB> <TAB> event = input.get_json() <TAB> <TAB> subscription_id = ResourceIdParser.get_subscription_id(event[""subject""]) <TAB> handler.run(event, context, subscription_id)",true,if input . dequeue_count > max_dequeue_count :,if input . dequeue_count > max_dequeue_count :,0.75,0.0
"def maybeExtractTarball(self): <TAB> if self.tarball: <TAB> <TAB> tar = self.computeTarballOptions() + [""-xvf"", self.tarball] <TAB> <TAB> res = yield self._Cmd(tar, abandonOnFailure=False) <TAB> <TAB><IF-STMT>  # error with tarball.. erase repo dir and tarball <TAB> <TAB> <TAB> yield self._Cmd([""rm"", ""-f"", self.tarball], abandonOnFailure=False) <TAB> <TAB> <TAB> yield self.runRmdir(self.repoDir(), abandonOnFailure=False)",true,if res :,if res :,0.53,0.0
"def execute(self, arbiter, props): <TAB> watcher = self._get_watcher(arbiter, props.pop(""name"")) <TAB> action = 0 <TAB> for key, val in props.get(""options"", {}).items(): <TAB> <TAB> if key == ""hooks"": <TAB> <TAB> <TAB> new_action = 0 <TAB> <TAB> <TAB> for name, _val in val.items(): <TAB> <TAB> <TAB> <TAB> action = watcher.set_opt(""hooks.%s"" % name, _val) <TAB> <TAB> <TAB> <TAB> if action == 1: <TAB> <TAB> <TAB> <TAB> <TAB> new_action = 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> new_action = watcher.set_opt(key, val) <TAB> <TAB> if new_action == 1: <TAB> <TAB> <TAB> action = 1 <TAB> # trigger needed action <TAB> return watcher.do_action(action)",true,"if key == ""hooks"" :","if key == ""hooks"" :",0.75,0.0
"def _import_playlists(self, fns, library): <TAB> added = 0 <TAB> for filename in fns: <TAB> <TAB> name = _name_for(filename) <TAB> <TAB> with open(filename, ""rb"") as f: <TAB> <TAB> <TAB> if filename.endswith("".m3u"") or filename.endswith("".m3u8""): <TAB> <TAB> <TAB> <TAB> playlist = parse_m3u(f, name, library=library) <TAB> <TAB> <TAB> elif filename.endswith("".pls""): <TAB> <TAB> <TAB> <TAB> playlist = parse_pls(f, name, library=library) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> print_w(""Unsupported playlist type for '%s'"" % filename) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> self.changed(playlist) <TAB> <TAB> library.add(playlist) <TAB> <TAB> added += 1 <TAB> return added",true,"if filename . endswith ( "".m3u"" ) or filename . endswith ( "".m3u8"" ) :","if filename . endswith ( "".m3u"" ) or filename . endswith ( "".m3u8"" ) :",1.0,0.0
"def unwrap_term_buckets(self, timestamp, term_buckets): <TAB> for term_data in term_buckets: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.unwrap_interval_buckets( <TAB> <TAB> <TAB> <TAB> timestamp, term_data[""key""], term_data[""interval_aggs""][""buckets""] <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.check_matches(timestamp, term_data[""key""], term_data)",true,"if ""interval_aggs"" in term_data :","if ""interval_aggs"" in term_data :",0.75,0.0
"def _get_exception(flags, timeout_ms, payload_size): <TAB> if flags & FLAG_ERROR: <TAB> <TAB> if flags & FLAG_TIMEOUT: <TAB> <TAB> <TAB> return SpicommTimeoutError(timeout_ms / 1000.0) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return SpicommOverflowError(payload_size) <TAB> <TAB> return SpicommError() <TAB> return None",true,if flags & FLAG_OVERFLOW :,if flags & FLAG_OVERFLOW :,0.75,0.0
"def _get_pattern(self, pattern_id): <TAB> """"""Get pattern item by id."""""" <TAB> for key in (Tag.PATTERNS1, Tag.PATTERNS2, Tag.PATTERNS3): <TAB> <TAB> if key in self.tagged_blocks: <TAB> <TAB> <TAB> data = self.tagged_blocks.get_data(key) <TAB> <TAB> <TAB> for pattern in data: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return pattern <TAB> return None",false,if pattern . pattern_id == pattern_id :,if pattern . id == pattern_id :,0.39,0.0
"def print_quiet(self, context, *args, **kwargs): <TAB> for index, (key, value) in enumerate( <TAB> <TAB> itertools.chain(enumerate(args), kwargs.items()) <TAB> ): <TAB> <TAB> if self.filter(index, key, value): <TAB> <TAB> <TAB> print( <TAB> <TAB> <TAB> <TAB> self.format_quiet(index, key, value, fields=context.get_input_fields()) <TAB> <TAB> <TAB> )",true,"if self . filter ( index , key , value ) :","if self . filter ( index , key , value ) :",0.75,0.0
"def complete(self, block): <TAB> with self._condition: <TAB> <TAB> if not self._final: <TAB> <TAB> <TAB> return False <TAB> <TAB> if self._complete(): <TAB> <TAB> <TAB> self._calculate_state_root_if_not_already_done() <TAB> <TAB> <TAB> return True <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._condition.wait_for(self._complete) <TAB> <TAB> <TAB> self._calculate_state_root_if_not_already_done() <TAB> <TAB> <TAB> return True <TAB> <TAB> return False",true,if block :,if block :,0.53,0.0
"def compression_rotator(source, dest): <TAB> with open(source, ""rb"") as sf: <TAB> <TAB> with gzip.open(dest, ""wb"") as wf: <TAB> <TAB> <TAB> while True: <TAB> <TAB> <TAB> <TAB> data = sf.read(CHUNK_SIZE) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> wf.write(data) <TAB> os.remove(source)",true,if not data :,if not data :,0.75,0.0
"def mockup(self, records): <TAB> provider = TransipProvider("""", """", """") <TAB> _dns_entries = [] <TAB> for record in records: <TAB> <TAB> if record._type in provider.SUPPORTS: <TAB> <TAB> <TAB> entries_for = getattr(provider, ""_entries_for_{}"".format(record._type)) <TAB> <TAB> <TAB> # Root records have '@' as name <TAB> <TAB> <TAB> name = record.name <TAB> <TAB> <TAB> if name == """": <TAB> <TAB> <TAB> <TAB> name = provider.ROOT_RECORD <TAB> <TAB> <TAB> _dns_entries.extend(entries_for(name, record)) <TAB> <TAB> <TAB> # NS is not supported as a DNS Entry, <TAB> <TAB> <TAB> # so it should cover the if statement <TAB> <TAB> <TAB> _dns_entries.append(DnsEntry(""@"", ""3600"", ""NS"", ""ns01.transip.nl."")) <TAB> self.mockupEntries = _dns_entries",true,if record . _type in provider . SUPPORTS :,if record . _type in provider . SUPPORTS :,0.75,0.0
"def parse_known_args(self, args=None, namespace=None): <TAB> entrypoint = self.prog.split("" "")[0] <TAB> try: <TAB> <TAB> defs = get_defaults_for_argparse(entrypoint) <TAB> <TAB> ignore = defs.pop(""Ignore"", None) <TAB> <TAB> self.set_defaults(**defs) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> set_notebook_diff_ignores(ignore) <TAB> except ValueError: <TAB> <TAB> pass <TAB> return super(ConfigBackedParser, self).parse_known_args( <TAB> <TAB> args=args, namespace=namespace <TAB> )",false,if ignore :,if ignore is not None :,0.09,0.0
"def _maybeRebuildAtlas(self, threshold=4, minlen=1000): <TAB> n = len(self.fragmentAtlas) <TAB> if (n > minlen) and (n > threshold * len(self.data)): <TAB> <TAB> self.fragmentAtlas.rebuild( <TAB> <TAB> <TAB> list(zip(*self._style([""symbol"", ""size"", ""pen"", ""brush""]))) <TAB> <TAB> ) <TAB> <TAB> self.data[""sourceRect""] = 0 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._sourceQRect.clear() <TAB> <TAB> self.updateSpots()",false,if _USE_QRECT :,if n == minlen :,0.05,0.0
"def dispatch_return(self, frame, arg): <TAB> if self.stop_here(frame) or frame == self.returnframe: <TAB> <TAB> # Ignore return events in generator except when stepping. <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return self.trace_dispatch <TAB> <TAB> try: <TAB> <TAB> <TAB> self.frame_returning = frame <TAB> <TAB> <TAB> self.user_return(frame, arg) <TAB> <TAB> finally: <TAB> <TAB> <TAB> self.frame_returning = None <TAB> <TAB> if self.quitting: <TAB> <TAB> <TAB> raise BdbQuit <TAB> <TAB> # The user issued a 'next' or 'until' command. <TAB> <TAB> if self.stopframe is frame and self.stoplineno != -1: <TAB> <TAB> <TAB> self._set_stopinfo(None, None) <TAB> return self.trace_dispatch",false,if self . stopframe and frame . f_code . co_flags & CO_GENERATOR :,if self . trace_dispatch is not None :,0.15,0.0
"def tearDown(self): <TAB> if not self.is_playback(): <TAB> <TAB> try: <TAB> <TAB> <TAB> if self.hosted_service_name is not None: <TAB> <TAB> <TAB> <TAB> self.sms.delete_hosted_service(self.hosted_service_name) <TAB> <TAB> except: <TAB> <TAB> <TAB> pass <TAB> <TAB> try: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.sms.delete_storage_account(self.storage_account_name) <TAB> <TAB> except: <TAB> <TAB> <TAB> pass <TAB> <TAB> try: <TAB> <TAB> <TAB> self.sms.delete_affinity_group(self.affinity_group_name) <TAB> <TAB> except: <TAB> <TAB> <TAB> pass <TAB> return super(LegacyMgmtAffinityGroupTest, self).tearDown()",true,if self . storage_account_name is not None :,if self . storage_account_name is not None :,0.75,0.0
"def make_log_msg(self, msg, *other_messages): <TAB> MAX_MESSAGE_LENGTH = 1000 <TAB> if not other_messages: <TAB> <TAB> # assume that msg is a single string <TAB> <TAB> return msg[-MAX_MESSAGE_LENGTH:] <TAB> else: <TAB> <TAB> if len(msg): <TAB> <TAB> <TAB> msg += ""\n...\n"" <TAB> <TAB> <TAB> NEXT_MESSAGE_OFFSET = MAX_MESSAGE_LENGTH - len(msg) <TAB> <TAB> else: <TAB> <TAB> <TAB> NEXT_MESSAGE_OFFSET = MAX_MESSAGE_LENGTH <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> msg += other_messages[0][-NEXT_MESSAGE_OFFSET:] <TAB> <TAB> <TAB> return self.make_log_msg(msg, *other_messages[1:]) <TAB> <TAB> else: <TAB> <TAB> <TAB> return self.make_log_msg(msg)",false,if NEXT_MESSAGE_OFFSET > 0 :,if len ( other_messages ) > 1 :,0.03,0.0
"def wrapper(  # type: ignore <TAB> self: RequestHandler, *args, **kwargs ) -> Optional[Awaitable[None]]: <TAB> if self.request.path.endswith(""/""): <TAB> <TAB> if self.request.method in (""GET"", ""HEAD""): <TAB> <TAB> <TAB> uri = self.request.path.rstrip(""/"") <TAB> <TAB> <TAB> if uri:  # don't try to redirect '/' to '' <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> uri += ""?"" + self.request.query <TAB> <TAB> <TAB> <TAB> self.redirect(uri, permanent=True) <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> else: <TAB> <TAB> <TAB> raise HTTPError(404) <TAB> return method(self, *args, **kwargs)",true,if self . request . query :,if self . request . query :,0.75,0.0
"def process_lib(vars_, coreval): <TAB> for d in vars_: <TAB> <TAB> var = d.upper() <TAB> <TAB> if var == ""QTCORE"": <TAB> <TAB> <TAB> continue <TAB> <TAB> value = env[""LIBPATH_"" + var] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> core = env[coreval] <TAB> <TAB> <TAB> accu = [] <TAB> <TAB> <TAB> for lib in value: <TAB> <TAB> <TAB> <TAB> if lib in core: <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> accu.append(lib) <TAB> <TAB> <TAB> env[""LIBPATH_"" + var] = accu",true,if value :,if value :,0.53,0.0
"def _attach_children(self, other, exclude_worldbody, dry_run=False): <TAB> for other_child in other.all_children(): <TAB> <TAB> if not other_child.spec.repeated: <TAB> <TAB> <TAB> self_child = self.get_children(other_child.spec.name) <TAB> <TAB> <TAB> self_child._attach( <TAB> <TAB> <TAB> <TAB> other_child, exclude_worldbody, dry_run <TAB> <TAB> <TAB> )  # pylint: disable=protected-access",true,if not other_child . spec . repeated :,if not other_child . spec . repeated :,0.75,0.0
"def getDictFromTree(tree): <TAB> ret_dict = {} <TAB> for child in tree.getchildren(): <TAB> <TAB> if child.getchildren(): <TAB> <TAB> <TAB> ## Complex-type child. Recurse <TAB> <TAB> <TAB> content = getDictFromTree(child) <TAB> <TAB> else: <TAB> <TAB> <TAB> content = child.text <TAB> <TAB> if ret_dict.has_key(child.tag): <TAB> <TAB> <TAB> if not type(ret_dict[child.tag]) == list: <TAB> <TAB> <TAB> <TAB> ret_dict[child.tag] = [ret_dict[child.tag]] <TAB> <TAB> <TAB> ret_dict[child.tag].append(content or """") <TAB> <TAB> else: <TAB> <TAB> <TAB> ret_dict[child.tag] = content or """" <TAB> return ret_dict",false,if ret_dict . has_key ( child . tag ) :,if child . getchildren ( ) :,0.04,0.0
"def nsUriMatch(self, value, wanted, strict=0, tt=type(())): <TAB> """"""Return a true value if two namespace uri values match."""""" <TAB> if value == wanted or (type(wanted) is tt) and value in wanted: <TAB> <TAB> return 1 <TAB> if not strict and value is not None: <TAB> <TAB> wanted = type(wanted) is tt and wanted or (wanted,) <TAB> <TAB> value = value[-1:] != ""/"" and value or value[:-1] <TAB> <TAB> for item in wanted: <TAB> <TAB> <TAB> if item == value or item[:-1] == value: <TAB> <TAB> <TAB> <TAB> return 1 <TAB> return 0",true,if item == value or item [ : - 1 ] == value :,if item == value or item [ : - 1 ] == value :,1.0,0.0
"def update_repository(self, ignore_issues=False, force=False): <TAB> """"""Update."""""" <TAB> if not await self.common_update(ignore_issues, force): <TAB> <TAB> return <TAB> # Get appdaemon objects. <TAB> if self.repository_manifest: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.content.path.remote = """" <TAB> if self.content.path.remote == ""apps"": <TAB> <TAB> self.data.domain = get_first_directory_in_directory( <TAB> <TAB> <TAB> self.tree, self.content.path.remote <TAB> <TAB> ) <TAB> <TAB> self.content.path.remote = f""apps/{self.data.name}"" <TAB> # Set local path <TAB> self.content.path.local = self.localpath",false,if self . data . content_in_root :,if self . content . path . remote is None :,0.2,0.0
"def addOutput(self, data, isAsync=None, **kwargs): <TAB> isAsync = _get_async_param(isAsync, **kwargs) <TAB> if isAsync: <TAB> <TAB> self.terminal.eraseLine() <TAB> <TAB> self.terminal.cursorBackward(len(self.lineBuffer) + len(self.ps[self.pn])) <TAB> self.terminal.write(data) <TAB> if isAsync: <TAB> <TAB> if self._needsNewline(): <TAB> <TAB> <TAB> self.terminal.nextLine() <TAB> <TAB> self.terminal.write(self.ps[self.pn]) <TAB> <TAB> if self.lineBuffer: <TAB> <TAB> <TAB> oldBuffer = self.lineBuffer <TAB> <TAB> <TAB> self.lineBuffer = [] <TAB> <TAB> <TAB> self.lineBufferIndex = 0 <TAB> <TAB> <TAB> self._deliverBuffer(oldBuffer)",true,if self . _needsNewline ( ) :,if self . _needsNewline ( ) :,0.75,0.0
"def is_installed(self, dlc_title="""") -> bool: <TAB> installed = False <TAB> if dlc_title: <TAB> <TAB> dlc_version = self.get_dlc_info(""version"", dlc_title) <TAB> <TAB> installed = True if dlc_version else False <TAB> <TAB> # Start: Code for compatibility with minigalaxy 1.0 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> status = self.legacy_get_dlc_status(dlc_title) <TAB> <TAB> <TAB> installed = True if status in [""installed"", ""updatable""] else False <TAB> <TAB> # End: Code for compatibility with minigalaxy 1.0 <TAB> else: <TAB> <TAB> if self.install_dir and os.path.exists(self.install_dir): <TAB> <TAB> <TAB> installed = True <TAB> return installed",false,if not installed :,if self . legacy_get_dlc_status :,0.04,0.0
"def close(self): <TAB> self.selector.close() <TAB> if self.sock: <TAB> <TAB> sockname = None <TAB> <TAB> try: <TAB> <TAB> <TAB> sockname = self.sock.getsockname() <TAB> <TAB> except (socket.error, OSError): <TAB> <TAB> <TAB> pass <TAB> <TAB> self.sock.close() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # it was a Unix domain socket, remove it from the filesystem <TAB> <TAB> <TAB> if os.path.exists(sockname): <TAB> <TAB> <TAB> <TAB> os.remove(sockname) <TAB> self.sock = None",false,if type ( sockname ) is str :,if sockname :,0.02,0.0
"def post_file(self, file_path, graph_type=""edges"", file_type=""csv""): <TAB> dataset_id = self.dataset_id <TAB> tok = self.token <TAB> base_path = self.server_base_path <TAB> with open(file_path, ""rb"") as file: <TAB> <TAB> out = requests.post( <TAB> <TAB> <TAB> f""{base_path}/api/v2/upload/datasets/{dataset_id}/{graph_type}/{file_type}"", <TAB> <TAB> <TAB> verify=self.certificate_validation, <TAB> <TAB> <TAB> headers={""Authorization"": f""Bearer {tok}""}, <TAB> <TAB> <TAB> data=file.read(), <TAB> <TAB> ).json() <TAB> <TAB> if not out[""success""]: <TAB> <TAB> <TAB> raise Exception(out) <TAB> <TAB> return out",true,"if not out [ ""success"" ] :","if not out [ ""success"" ] :",0.75,0.0
"def _get_vqa_v2_image_raw_dataset(directory, image_root_url, image_urls): <TAB> """"""Extract the VQA V2 image data set to directory unless it's there."""""" <TAB> for url in image_urls: <TAB> <TAB> filename = os.path.basename(url) <TAB> <TAB> download_url = os.path.join(image_root_url, url) <TAB> <TAB> path = generator_utils.maybe_download(directory, filename, download_url) <TAB> <TAB> unzip_dir = os.path.join(directory, filename.strip("".zip"")) <TAB> <TAB> if not tf.gfile.Exists(unzip_dir): <TAB> <TAB> <TAB> zipfile.ZipFile(path, ""r"").extractall(directory)",true,if not tf . gfile . Exists ( unzip_dir ) :,if not tf . gfile . Exists ( unzip_dir ) :,0.75,0.0
"def __call__(self, environ, start_response): <TAB> for key in ""REQUEST_URL"", ""REQUEST_URI"", ""UNENCODED_URL"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> request_uri = unquote(environ[key]) <TAB> <TAB> script_name = unquote(environ.get(""SCRIPT_NAME"", """")) <TAB> <TAB> if request_uri.startswith(script_name): <TAB> <TAB> <TAB> environ[""PATH_INFO""] = request_uri[len(script_name) :].split(""?"", 1)[0] <TAB> <TAB> <TAB> break <TAB> return self.app(environ, start_response)",true,if key not in environ :,if key not in environ :,0.75,0.0
"def _instrument_model(self, model): <TAB> for key, value in list( <TAB> <TAB> model.__dict__.items() <TAB> ):  # avoid ""dictionary keys changed during iteration"" <TAB> <TAB> if isinstance(value, tf.keras.layers.Layer): <TAB> <TAB> <TAB> new_layer = self._instrument(value) <TAB> <TAB> <TAB> if new_layer is not value: <TAB> <TAB> <TAB> <TAB> setattr(model, key, new_layer) <TAB> <TAB> elif isinstance(value, list): <TAB> <TAB> <TAB> for i, item in enumerate(value): <TAB> <TAB> <TAB> <TAB> if isinstance(item, tf.keras.layers.Layer): <TAB> <TAB> <TAB> <TAB> <TAB> value[i] = self._instrument(item) <TAB> return model",false,"elif isinstance ( value , list ) :","if isinstance ( item , tf . keras . layers . Layer ) :",0.03,0.0
"def __init__(self, parent, dir, mask, with_dirs=True): <TAB> filelist = [] <TAB> dirlist = [""..""] <TAB> self.dir = dir <TAB> self.file = """" <TAB> mask = mask.upper() <TAB> pattern = self.MakeRegex(mask) <TAB> for i in os.listdir(dir): <TAB> <TAB> if i == ""."" or i == "".."": <TAB> <TAB> <TAB> continue <TAB> <TAB> path = os.path.join(dir, i) <TAB> <TAB> if os.path.isdir(path): <TAB> <TAB> <TAB> dirlist.append(i) <TAB> <TAB> <TAB> continue <TAB> <TAB> path = path.upper() <TAB> <TAB> value = i.upper() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> filelist.append(i) <TAB> self.files = filelist <TAB> if with_dirs: <TAB> <TAB> self.dirs = dirlist",false,if pattern . match ( value ) is not None :,"if pattern . match ( path , value ) is not None :",0.45,0.0
"def get_text(self, nodelist): <TAB> """"""Return a string representation of the motif's properties listed on nodelist ."""""" <TAB> retlist = [] <TAB> for node in nodelist: <TAB> <TAB> if node.nodeType == Node.TEXT_NODE: <TAB> <TAB> <TAB> retlist.append(node.wholeText) <TAB> <TAB> elif node.hasChildNodes: <TAB> <TAB> <TAB> retlist.append(self.get_text(node.childNodes)) <TAB> return re.sub(r""\s+"", "" "", """".join(retlist))",true,elif node . hasChildNodes :,elif node . hasChildNodes :,0.75,0.0
"def _persist_metadata(self, dirname, filename): <TAB> metadata_path = ""{0}/{1}.json"".format(dirname, filename) <TAB> if self.media_metadata or self.comments or self.include_location: <TAB> <TAB> if self.posts: <TAB> <TAB> <TAB> if self.latest: <TAB> <TAB> <TAB> <TAB> self.merge_json({""GraphImages"": self.posts}, metadata_path) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.save_json({""GraphImages"": self.posts}, metadata_path) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if self.latest: <TAB> <TAB> <TAB> <TAB> self.merge_json({""GraphStories"": self.stories}, metadata_path) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.save_json({""GraphStories"": self.stories}, metadata_path)",true,if self . stories :,if self . stories :,0.75,0.0
"def _get_python_wrapper_content(self, job_class, args): <TAB> job = job_class([""-r"", ""hadoop""] + list(args)) <TAB> job.sandbox() <TAB> with job.make_runner() as runner: <TAB> <TAB> runner._create_setup_wrapper_scripts() <TAB> <TAB> if runner._spark_python_wrapper_path: <TAB> <TAB> <TAB> with open(runner._spark_python_wrapper_path) as f: <TAB> <TAB> <TAB> <TAB> return f.read() <TAB> <TAB> else: <TAB> <TAB> <TAB> return None",true,if runner . _spark_python_wrapper_path :,if runner . _spark_python_wrapper_path :,0.75,0.0
"def computeLeadingWhitespaceWidth(s, tab_width): <TAB> w = 0 <TAB> for ch in s: <TAB> <TAB> if ch == "" "": <TAB> <TAB> <TAB> w += 1 <TAB> <TAB> elif ch == ""\t"": <TAB> <TAB> <TAB> w += abs(tab_width) - (w % abs(tab_width)) <TAB> <TAB> else: <TAB> <TAB> <TAB> break <TAB> return w",false,"if ch == "" "" :","elif ch == ""\t"" :",0.05,0.0
def run(self): <TAB> # if the i3status process dies we want to restart it. <TAB> # We give up restarting if we have died too often <TAB> for _ in range(10): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> self.spawn_i3status() <TAB> <TAB> # check if we never worked properly and if so quit now <TAB> <TAB> if not self.ready: <TAB> <TAB> <TAB> break <TAB> <TAB> # limit restart rate <TAB> <TAB> self.lock.wait(5),false,if not self . py3_wrapper . running :,if self . ready :,0.04,0.0
"def translate_len( <TAB> builder: IRBuilder, expr: CallExpr, callee: RefExpr ) -> Optional[Value]: <TAB> # Special case builtins.len <TAB> if len(expr.args) == 1 and expr.arg_kinds == [ARG_POS]: <TAB> <TAB> expr_rtype = builder.node_type(expr.args[0]) <TAB> <TAB> if isinstance(expr_rtype, RTuple): <TAB> <TAB> <TAB> # len() of fixed-length tuple can be trivially determined statically, <TAB> <TAB> <TAB> # though we still need to evaluate it. <TAB> <TAB> <TAB> builder.accept(expr.args[0]) <TAB> <TAB> <TAB> return Integer(len(expr_rtype.types)) <TAB> <TAB> else: <TAB> <TAB> <TAB> obj = builder.accept(expr.args[0]) <TAB> <TAB> <TAB> return builder.builtin_len(obj, -1) <TAB> return None",true,"if isinstance ( expr_rtype , RTuple ) :","if isinstance ( expr_rtype , RTuple ) :",0.75,0.0
"def parse_auth(val): <TAB> if val is not None: <TAB> <TAB> authtype, params = val.split("" "", 1) <TAB> <TAB> if authtype in known_auth_schemes: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> # this is the ""Authentication: Basic XXXXX=="" case <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> params = parse_auth_params(params) <TAB> <TAB> return authtype, params <TAB> return val",false,"if authtype == ""Basic"" and '""' not in params :",if params is None :,0.01,0.0
"def toxml(self): <TAB> text = self.value <TAB> self.parent.setBidi(getBidiType(text)) <TAB> if not text.startswith(HTML_PLACEHOLDER_PREFIX): <TAB> <TAB> if self.parent.nodeName == ""p"": <TAB> <TAB> <TAB> text = text.replace(""\n"", ""\n   "") <TAB> <TAB> elif self.parent.nodeName == ""li"" and self.parent.childNodes[0] == self: <TAB> <TAB> <TAB> text = ""\n <TAB> "" + text.replace(""\n"", ""\n <TAB> "") <TAB> text = self.doc.normalizeEntities(text) <TAB> return text",true,"elif self . parent . nodeName == ""li"" and self . parent . childNodes [ 0 ] == self :","elif self . parent . nodeName == ""li"" and self . parent . childNodes [ 0 ] == self :",1.0,0.0
"def get_all_related_many_to_many_objects(self): <TAB> try:  # Try the cache first. <TAB> <TAB> return self._all_related_many_to_many_objects <TAB> except AttributeError: <TAB> <TAB> rel_objs = [] <TAB> <TAB> for klass in get_models(): <TAB> <TAB> <TAB> for f in klass._meta.many_to_many: <TAB> <TAB> <TAB> <TAB> if f.rel and self == f.rel.to._meta: <TAB> <TAB> <TAB> <TAB> <TAB> rel_objs.append(RelatedObject(f.rel.to, klass, f)) <TAB> <TAB> self._all_related_many_to_many_objects = rel_objs <TAB> <TAB> return rel_objs",true,if f . rel and self == f . rel . to . _meta :,if f . rel and self == f . rel . to . _meta :,0.75,0.0
"def state_highstate(self, state, dirpath): <TAB> opts = copy.copy(self.config) <TAB> opts[""file_roots""] = dict(base=[dirpath]) <TAB> HIGHSTATE = HighState(opts) <TAB> HIGHSTATE.push_active() <TAB> try: <TAB> <TAB> high, errors = HIGHSTATE.render_highstate(state) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> import pprint <TAB> <TAB> <TAB> pprint.pprint(""\n"".join(errors)) <TAB> <TAB> <TAB> pprint.pprint(high) <TAB> <TAB> out = HIGHSTATE.state.call_high(high) <TAB> <TAB> # pprint.pprint(out) <TAB> finally: <TAB> <TAB> HIGHSTATE.pop_active()",true,if errors :,if errors :,0.53,0.0
"def _update_target_host(self, target, target_host): <TAB> """"""Update target host."""""" <TAB> target_host = None if target_host == """" else target_host <TAB> if not target_host: <TAB> <TAB> for device_type, tgt in target.items(): <TAB> <TAB> <TAB> if device_type.value == tvm.nd.cpu(0).device_type: <TAB> <TAB> <TAB> <TAB> target_host = tgt <TAB> <TAB> <TAB> <TAB> break <TAB> if not target_host: <TAB> <TAB> target_host = ""llvm"" if tvm.runtime.enabled(""llvm"") else ""stackvm"" <TAB> if isinstance(target_host, str): <TAB> <TAB> target_host = tvm.target.Target(target_host) <TAB> return target_host",true,if device_type . value == tvm . nd . cpu ( 0 ) . device_type :,if device_type . value == tvm . nd . cpu ( 0 ) . device_type :,1.0,0.0
"def __console_writer(self): <TAB> while True: <TAB> <TAB> self.__writer_event.wait() <TAB> <TAB> self.__writer_event.clear() <TAB> <TAB> if self.__console_view: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.log.debug(""Writing console view to STDOUT"") <TAB> <TAB> <TAB> <TAB> sys.stdout.write(self.console_markup.clear) <TAB> <TAB> <TAB> <TAB> sys.stdout.write(self.__console_view) <TAB> <TAB> <TAB> <TAB> sys.stdout.write(self.console_markup.TOTAL_RESET)",false,if not self . short_only :,if self . console_markup :,0.05,0.0
"def goToPrevMarkedHeadline(self, event=None): <TAB> """"""Select the next marked node."""""" <TAB> c = self <TAB> p = c.p <TAB> if not p: <TAB> <TAB> return <TAB> p.moveToThreadBack() <TAB> wrapped = False <TAB> while 1: <TAB> <TAB> if p and p.isMarked(): <TAB> <TAB> <TAB> break <TAB> <TAB> elif p: <TAB> <TAB> <TAB> p.moveToThreadBack() <TAB> <TAB> elif wrapped: <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> wrapped = True <TAB> <TAB> <TAB> p = c.rootPosition() <TAB> if not p: <TAB> <TAB> g.blue(""done"") <TAB> c.treeSelectHelper(p)  # Sets focus.",true,elif wrapped :,elif wrapped :,0.51,0.0
"def delete_map(self, query=None): <TAB> query_map = self.interpolated_map(query=query) <TAB> for alias, drivers in six.iteritems(query_map.copy()): <TAB> <TAB> for driver, vms in six.iteritems(drivers.copy()): <TAB> <TAB> <TAB> for vm_name, vm_details in six.iteritems(vms.copy()): <TAB> <TAB> <TAB> <TAB> if vm_details == ""Absent"": <TAB> <TAB> <TAB> <TAB> <TAB> query_map[alias][driver].pop(vm_name) <TAB> <TAB> <TAB> if not query_map[alias][driver]: <TAB> <TAB> <TAB> <TAB> query_map[alias].pop(driver) <TAB> <TAB> if not query_map[alias]: <TAB> <TAB> <TAB> query_map.pop(alias) <TAB> return query_map",false,if not query_map [ alias ] :,"if vm_details == ""Absent"" :",0.02,0.0
"def get_shadows_zip(filename): <TAB> import zipfile <TAB> shadow_pkgs = set() <TAB> with zipfile.ZipFile(filename) as lib_zip: <TAB> <TAB> already_test = [] <TAB> <TAB> for fname in lib_zip.namelist(): <TAB> <TAB> <TAB> pname, fname = os.path.split(fname) <TAB> <TAB> <TAB> if fname or (pname and fname): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if pname not in already_test and ""/"" not in pname: <TAB> <TAB> <TAB> <TAB> already_test.append(pname) <TAB> <TAB> <TAB> <TAB> if is_shadowing(pname): <TAB> <TAB> <TAB> <TAB> <TAB> shadow_pkgs.add(pname) <TAB> return shadow_pkgs",false,if fname or ( pname and fname ) :,if is_shadowing ( pname ) :,0.04,0.0
"def make_chains(chains_info): <TAB> chains = [[] for _ in chains_info[0][1]] <TAB> for i, num_ids in enumerate(chains_info[:-1]): <TAB> <TAB> num, ids = num_ids <TAB> <TAB> for j, ident in enumerate(ids): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> next_chain_info = chains_info[i + 1] <TAB> <TAB> <TAB> <TAB> previous = next_chain_info[1][j] <TAB> <TAB> <TAB> <TAB> block = SimpleBlock(num, ident, previous) <TAB> <TAB> <TAB> <TAB> chains[j].append(block) <TAB> chains = {i: make_generator(chain) for i, chain in enumerate(chains)} <TAB> return chains",false,"if ident != """" :",if i < j :,0.03,0.0
"def filter_input(mindate, maxdate, files): <TAB> mindate = parse(mindate) if mindate is not None else datetime.datetime.min <TAB> maxdate = parse(maxdate) if maxdate is not None else datetime.datetime.max <TAB> for line in fileinput.input(files): <TAB> <TAB> tweet = json.loads(line) <TAB> <TAB> created_at = parse(tweet[""created_at""]) <TAB> <TAB> created_at = created_at.replace(tzinfo=None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(json.dumps(tweet))",false,if mindate < created_at and maxdate > created_at :,if created_at < mindate or created_at > maxdate :,0.02,0.0
"def get(self): <TAB> """"""If a value/an exception is stored, return/raise it. Otherwise until switch() or throw() is called."""""" <TAB> if self._exception is not _NONE: <TAB> <TAB> if self._exception is None: <TAB> <TAB> <TAB> return self.value <TAB> <TAB> getcurrent().throw(*self._exception)  # pylint:disable=undefined-variable <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ConcurrentObjectUseError( <TAB> <TAB> <TAB> <TAB> ""This Waiter is already used by %r"" % (self.greenlet,) <TAB> <TAB> <TAB> ) <TAB> <TAB> self.greenlet = getcurrent()  # pylint:disable=undefined-variable <TAB> <TAB> try: <TAB> <TAB> <TAB> return self.hub.switch() <TAB> <TAB> finally: <TAB> <TAB> <TAB> self.greenlet = None",true,if self . greenlet is not None :,if self . greenlet is not None :,0.75,0.0
"def default_loader(href, parse, encoding=None): <TAB> with open(href) as file: <TAB> <TAB> if parse == ""xml"": <TAB> <TAB> <TAB> data = ElementTree.parse(file).getroot() <TAB> <TAB> else: <TAB> <TAB> <TAB> data = file.read() <TAB> <TAB> <TAB> if encoding: <TAB> <TAB> <TAB> <TAB> data = data.decode(encoding) <TAB> return data",true,"if parse == ""xml"" :","if parse == ""xml"" :",0.75,0.0
def is_all_qud(world): <TAB> m = True <TAB> for obj in world: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if obj.nice: <TAB> <TAB> <TAB> <TAB> m = m and True <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> m = m and False <TAB> <TAB> else: <TAB> <TAB> <TAB> m = m and True <TAB> return m,false,if obj . blond :,if obj . qud :,0.39,0.0
"def run(self, edit): <TAB> if not self.has_selection(): <TAB> <TAB> region = sublime.Region(0, self.view.size()) <TAB> <TAB> originalBuffer = self.view.substr(region) <TAB> <TAB> prefixed = self.prefix(originalBuffer) <TAB> <TAB> if prefixed: <TAB> <TAB> <TAB> self.view.replace(edit, region, prefixed) <TAB> <TAB> return <TAB> for region in self.view.sel(): <TAB> <TAB> if region.empty(): <TAB> <TAB> <TAB> continue <TAB> <TAB> originalBuffer = self.view.substr(region) <TAB> <TAB> prefixed = self.prefix(originalBuffer) <TAB> <TAB> if prefixed: <TAB> <TAB> <TAB> self.view.replace(edit, region, prefixed)",true,if region . empty ( ) :,if region . empty ( ) :,0.75,0.0
"def add_fields(self, params): <TAB> for (key, val) in params.iteritems(): <TAB> <TAB> if isinstance(val, dict): <TAB> <TAB> <TAB> new_params = {} <TAB> <TAB> <TAB> for k in val: <TAB> <TAB> <TAB> <TAB> new_params[""%s__%s"" % (key, k)] = val[k] <TAB> <TAB> <TAB> self.add_fields(new_params) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.add_field(key, val)",true,"if isinstance ( val , dict ) :","if isinstance ( val , dict ) :",0.75,0.0
"def find_magic(self, f, pos, magic): <TAB> f.seek(pos) <TAB> block = f.read(32 * 1024) <TAB> if len(block) < len(magic): <TAB> <TAB> return -1 <TAB> p = block.find(magic) <TAB> while p < 0: <TAB> <TAB> pos += len(block) - len(magic) + 1 <TAB> <TAB> block = block[1 - len(magic) :] + f.read(32 << 10) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return -1 <TAB> <TAB> p = block.find(magic) <TAB> return pos + p",false,if len ( block ) == len ( magic ) - 1 :,if len ( block ) < 0 :,0.28,0.0
"def check_strings(self): <TAB> """"""Check that all strings have been consumed."""""" <TAB> for i, aList in enumerate(self.string_tokens): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> g.trace(""warning: line %s. unused strings"" % i) <TAB> <TAB> <TAB> for z in aList: <TAB> <TAB> <TAB> <TAB> print(self.dump_token(z))",false,if aList :,if i not in aList :,0.09,0.0
"def get_tokens_unprocessed(self, text): <TAB> from pygments.lexers._cocoa_builtins import ( <TAB> <TAB> COCOA_INTERFACES, <TAB> <TAB> COCOA_PROTOCOLS, <TAB> <TAB> COCOA_PRIMITIVES, <TAB> ) <TAB> for index, token, value in RegexLexer.get_tokens_unprocessed(self, text): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> value in COCOA_INTERFACES <TAB> <TAB> <TAB> <TAB> or value in COCOA_PROTOCOLS <TAB> <TAB> <TAB> <TAB> or value in COCOA_PRIMITIVES <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> token = Name.Builtin.Pseudo <TAB> <TAB> yield index, token, value",false,if token is Name or token is Name . Class :,if token is Name :,0.27,0.0
"def key_from_key_value_dict(key_info): <TAB> res = [] <TAB> if not ""key_value"" in key_info: <TAB> <TAB> return res <TAB> for value in key_info[""key_value""]: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> e = base64_to_long(value[""rsa_key_value""][""exponent""]) <TAB> <TAB> <TAB> m = base64_to_long(value[""rsa_key_value""][""modulus""]) <TAB> <TAB> <TAB> key = RSA.construct((m, e)) <TAB> <TAB> <TAB> res.append(key) <TAB> return res",true,"if ""rsa_key_value"" in value :","if ""rsa_key_value"" in value :",0.75,0.0
"def run(self, edit): <TAB> if not self.has_selection(): <TAB> <TAB> region = sublime.Region(0, self.view.size()) <TAB> <TAB> originalBuffer = self.view.substr(region) <TAB> <TAB> prefixed = self.prefix(originalBuffer) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.view.replace(edit, region, prefixed) <TAB> <TAB> return <TAB> for region in self.view.sel(): <TAB> <TAB> if region.empty(): <TAB> <TAB> <TAB> continue <TAB> <TAB> originalBuffer = self.view.substr(region) <TAB> <TAB> prefixed = self.prefix(originalBuffer) <TAB> <TAB> if prefixed: <TAB> <TAB> <TAB> self.view.replace(edit, region, prefixed)",true,if prefixed :,if prefixed :,0.53,0.0
def finalize(self): <TAB> if self.ct < 1: <TAB> <TAB> return <TAB> elif self.ct == 1: <TAB> <TAB> return 0 <TAB> total = ct = 0 <TAB> dtp = None <TAB> while self.heap: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if dtp is None: <TAB> <TAB> <TAB> <TAB> dtp = heapq.heappop(self.heap) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> dt = heapq.heappop(self.heap) <TAB> <TAB> diff = dt - dtp <TAB> <TAB> ct += 1 <TAB> <TAB> total += total_seconds(diff) <TAB> <TAB> dtp = dt <TAB> return float(total) / ct,false,if total == 0 :,if total is None :,0.06,0.0
"def _test_configuration(self): <TAB> config_path = self._write_config() <TAB> try: <TAB> <TAB> self._log.debug(""testing configuration"") <TAB> <TAB> verboseflag = ""-Q"" <TAB> <TAB> if self._log.isEnabledFor(logging.DEBUG): <TAB> <TAB> <TAB> verboseflag = ""-v"" <TAB> <TAB> p = subprocess.Popen([self.PATH_SLAPTEST, verboseflag, ""-f"", config_path]) <TAB> <TAB> if p.wait() != 0: <TAB> <TAB> <TAB> raise RuntimeError(""configuration test failed"") <TAB> <TAB> self._log.debug(""configuration seems ok"") <TAB> finally: <TAB> <TAB> os.remove(config_path)",false,if self . _log . isEnabledFor ( logging . DEBUG ) :,if p . wait ( ) != 0 :,0.01,0.0
"def exe(self, ret): <TAB> if not ret: <TAB> <TAB> self.assertEqual(ret, """") <TAB> else: <TAB> <TAB> assert os.path.isabs(ret), ret <TAB> <TAB> # Note: os.stat() may return False even if the file is there <TAB> <TAB> # hence we skip the test, see: <TAB> <TAB> # http://stackoverflow.com/questions/3112546/os-path-exists-lies <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> assert os.path.isfile(ret), ret <TAB> <TAB> <TAB> if hasattr(os, ""access"") and hasattr(os, ""X_OK""): <TAB> <TAB> <TAB> <TAB> # XXX may fail on OSX <TAB> <TAB> <TAB> <TAB> self.assertTrue(os.access(ret, os.X_OK))",false,if POSIX :,if not ret :,0.06,0.0
"def _do_cleanup(sg_name, device_id): <TAB> masking_view_list = self.rest.get_masking_views_from_storage_group(array, sg_name) <TAB> for masking_view in masking_view_list: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.rest.delete_masking_view(array, masking_view) <TAB> <TAB> <TAB> self.rest.remove_vol_from_sg(array, sg_name, device_id, extra_specs) <TAB> <TAB> <TAB> self.rest.delete_volume(array, device_id) <TAB> <TAB> <TAB> self.rest.delete_storage_group(array, sg_name)",false,"if ""STG-"" in masking_view :",if masking_view . volume_id == device_id :,0.03,0.0
"def hide_tooltip_if_necessary(self, key): <TAB> """"""Hide calltip when necessary"""""" <TAB> try: <TAB> <TAB> calltip_char = self.get_character(self.calltip_position) <TAB> <TAB> before = self.is_cursor_before(self.calltip_position, char_offset=1) <TAB> <TAB> other = key in (Qt.Key_ParenRight, Qt.Key_Period, Qt.Key_Tab) <TAB> <TAB> if calltip_char not in (""?"", ""("") or before or other: <TAB> <TAB> <TAB> QToolTip.hideText() <TAB> except (IndexError, TypeError): <TAB> <TAB> QToolTip.hideText()",true,"if calltip_char not in ( ""?"" , ""("" ) or before or other :","if calltip_char not in ( ""?"" , ""("" ) or before or other :",0.75,0.0
"def list_tags_for_stream(self, stream_name, exclusive_start_tag_key=None, limit=None): <TAB> stream = self.describe_stream(stream_name) <TAB> tags = [] <TAB> result = {""HasMoreTags"": False, ""Tags"": tags} <TAB> for key, val in sorted(stream.tags.items(), key=lambda x: x[0]): <TAB> <TAB> if limit and len(tags) >= limit: <TAB> <TAB> <TAB> result[""HasMoreTags""] = True <TAB> <TAB> <TAB> break <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> tags.append({""Key"": key, ""Value"": val}) <TAB> return result",false,if exclusive_start_tag_key and key < exclusive_start_tag_key :,if exclusive_start_tag_key and key == exclusive_start_tag_key :,0.4,0.0
"def parametrize_function_name(request, function_name): <TAB> suffixes = [] <TAB> if ""parametrize"" in request.keywords: <TAB> <TAB> argnames = request.keywords[""parametrize""].args[::2] <TAB> <TAB> argnames = [x.strip() for names in argnames for x in names.split("","")] <TAB> <TAB> for name in argnames: <TAB> <TAB> <TAB> value = request.getfuncargvalue(name) <TAB> <TAB> <TAB> if inspect.isclass(value): <TAB> <TAB> <TAB> <TAB> value = value.__name__ <TAB> <TAB> <TAB> suffixes.append(""{}={}"".format(name, value)) <TAB> return ""+"".join([function_name] + suffixes)",true,if inspect . isclass ( value ) :,if inspect . isclass ( value ) :,0.75,0.0
"def add_entities(self, positions): <TAB> e1 = EntityFactory() <TAB> for p in positions: <TAB> <TAB> if isinstance(p, tuple): <TAB> <TAB> <TAB> start, length = p <TAB> <TAB> else: <TAB> <TAB> <TAB> start, length = p, 1 <TAB> <TAB> EntityOccurrenceFactory( <TAB> <TAB> <TAB> document=self.doc, <TAB> <TAB> <TAB> entity=e1, <TAB> <TAB> <TAB> offset=start, <TAB> <TAB> <TAB> offset_end=start + length, <TAB> <TAB> <TAB> alias=""AB"", <TAB> <TAB> )",true,"if isinstance ( p , tuple ) :","if isinstance ( p , tuple ) :",0.75,0.0
"def transform_value(value): <TAB> if isinstance(value, collections.MutableMapping): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return DBRef(value[""_ns""], transform_value(value[""_id""])) <TAB> <TAB> else: <TAB> <TAB> <TAB> return transform_dict(SON(value)) <TAB> elif isinstance(value, list): <TAB> <TAB> return [transform_value(v) for v in value] <TAB> return value",false,"if ""_id"" in value and ""_ns"" in value :","if ""_ns"" in value :",0.16,0.0
"def remove(self, items): <TAB> """"""Remove messages from lease management."""""" <TAB> with self._add_remove_lock: <TAB> <TAB> # Remove the ack ID from lease management, and decrement the <TAB> <TAB> # byte counter. <TAB> <TAB> for item in items: <TAB> <TAB> <TAB> if self._leased_messages.pop(item.ack_id, None) is not None: <TAB> <TAB> <TAB> <TAB> self._bytes -= item.byte_size <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> _LOGGER.debug(""Item %s was not managed."", item.ack_id) <TAB> <TAB> if self._bytes < 0: <TAB> <TAB> <TAB> _LOGGER.debug(""Bytes was unexpectedly negative: %d"", self._bytes) <TAB> <TAB> <TAB> self._bytes = 0",false,if self . _bytes < 0 :,"if self . _leased_messages . pop ( item . ack_id , None ) is not None :",0.12,0.0
"def parse_hgsub(lines): <TAB> """"""Fills OrderedDict with hgsub file content passed as list of lines"""""" <TAB> rv = OrderedDict() <TAB> for l in lines: <TAB> <TAB> ls = l.strip() <TAB> <TAB> if not ls or ls[0] == ""#"": <TAB> <TAB> <TAB> continue <TAB> <TAB> name, value = l.split(""="", 1) <TAB> <TAB> rv[name.strip()] = value.strip() <TAB> return rv",true,"if not ls or ls [ 0 ] == ""#"" :","if not ls or ls [ 0 ] == ""#"" :",1.0,0.0
"def del_(self, key): <TAB> initial_hash = hash_ = self.hash(key) <TAB> while True: <TAB> <TAB> if self._keys[hash_] is self._empty: <TAB> <TAB> <TAB> # That key was never assigned <TAB> <TAB> <TAB> return None <TAB> <TAB> elif self._keys[hash_] == key: <TAB> <TAB> <TAB> # key found, assign with deleted sentinel <TAB> <TAB> <TAB> self._keys[hash_] = self._deleted <TAB> <TAB> <TAB> self._values[hash_] = self._deleted <TAB> <TAB> <TAB> self._len -= 1 <TAB> <TAB> <TAB> return <TAB> <TAB> hash_ = self._rehash(hash_) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # table is full and wrapped around <TAB> <TAB> <TAB> return None",false,if initial_hash == hash_ :,if hash_ == initial_hash :,0.29,0.0
"def atom(token, no_symbol=False): <TAB> try: <TAB> <TAB> return int(token) <TAB> except ValueError: <TAB> <TAB> try: <TAB> <TAB> <TAB> return float(token) <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> if token.startswith(""'"") or token.startswith('""'): <TAB> <TAB> <TAB> <TAB> return token[1:-1] <TAB> <TAB> <TAB> elif no_symbol: <TAB> <TAB> <TAB> <TAB> return token <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return Symbol(token)",false,"if token . startswith ( ""'"" ) or token . startswith ( '""' ) :",elif no_symbol :,0.0,0.0
"def __Suffix_Noun_Step1b(self, token): <TAB> for suffix in self.__suffix_noun_step1b: <TAB> <TAB> if token.endswith(suffix) and len(token) > 5: <TAB> <TAB> <TAB> token = token[:-1] <TAB> <TAB> <TAB> self.suffixe_noun_step1b_success = True <TAB> <TAB> <TAB> break <TAB> return token",true,if token . endswith ( suffix ) and len ( token ) > 5 :,if token . endswith ( suffix ) and len ( token ) > 5 :,1.0,0.0
"def _guardAgainstUnicode(self, data): <TAB> # Only accept byte strings or ascii unicode values, otherwise <TAB> # there is no way to correctly decode the data into bytes. <TAB> if _pythonMajorVersion < 3: <TAB> <TAB> if isinstance(data, unicode): <TAB> <TAB> <TAB> data = data.encode(""utf8"") <TAB> else: <TAB> <TAB> if isinstance(data, str): <TAB> <TAB> <TAB> # Only accept ascii unicode values. <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> return data.encode(""ascii"") <TAB> <TAB> <TAB> except UnicodeEncodeError: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> raise ValueError(""pyDes can only work with encoded strings, not Unicode."") <TAB> return data",true,"if isinstance ( data , unicode ) :","if isinstance ( data , unicode ) :",0.75,0.0
"def populate_resource_parameters(self, tool_source): <TAB> root = getattr(tool_source, ""root"", None) <TAB> if ( <TAB> <TAB> root is not None <TAB> <TAB> and hasattr(self.app, ""job_config"") <TAB> <TAB> and hasattr(self.app.job_config, ""get_tool_resource_xml"") <TAB> ): <TAB> <TAB> resource_xml = self.app.job_config.get_tool_resource_xml( <TAB> <TAB> <TAB> root.get(""id""), self.tool_type <TAB> <TAB> ) <TAB> <TAB> if resource_xml is not None: <TAB> <TAB> <TAB> inputs = root.find(""inputs"") <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> inputs = parse_xml_string(""<inputs/>"") <TAB> <TAB> <TAB> <TAB> root.append(inputs) <TAB> <TAB> <TAB> inputs.append(resource_xml)",false,if inputs is None :,if not inputs :,0.04,0.0
"def test_arguments_regex(self): <TAB> argument_matches = ( <TAB> <TAB> (""pip=1.1"", (""pip"", ""1.1"")), <TAB> <TAB> (""pip==1.1"", None), <TAB> <TAB> (""pip=1.2=1"", (""pip"", ""1.2=1"")), <TAB> ) <TAB> for argument, match in argument_matches: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.assertIsNone(salt.utils.args.KWARG_REGEX.match(argument)) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.assertEqual( <TAB> <TAB> <TAB> <TAB> salt.utils.args.KWARG_REGEX.match(argument).groups(), match <TAB> <TAB> <TAB> )",true,if match is None :,if match is None :,0.75,0.0
"def _get_sidebar_selected(self): <TAB> sidebar_selected = None <TAB> if self.businessline_id: <TAB> <TAB> sidebar_selected = ""bl_%s"" % self.businessline_id <TAB> <TAB> if self.service_id: <TAB> <TAB> <TAB> sidebar_selected += ""_s_%s"" % self.service_id <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> sidebar_selected += ""_env_%s"" % self.environment_id <TAB> return sidebar_selected",true,if self . environment_id :,if self . environment_id :,0.75,0.0
"def get_ip_info(ipaddress): <TAB> """"""Returns device information by IP address"""""" <TAB> result = {} <TAB> try: <TAB> <TAB> ip = IPAddress.objects.select_related().get(address=ipaddress) <TAB> except IPAddress.DoesNotExist: <TAB> <TAB> pass <TAB> else: <TAB> <TAB> if ip.venture is not None: <TAB> <TAB> <TAB> result[""venture_id""] = ip.venture.id <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result[""device_id""] = ip.device.id <TAB> <TAB> <TAB> if ip.device.venture is not None: <TAB> <TAB> <TAB> <TAB> result[""venture_id""] = ip.device.venture.id <TAB> return result",true,if ip . device is not None :,if ip . device is not None :,0.75,0.0
"def apply(self, db, person): <TAB> for family_handle in person.get_family_handle_list(): <TAB> <TAB> family = db.get_family_from_handle(family_handle) <TAB> <TAB> if family: <TAB> <TAB> <TAB> for event_ref in family.get_event_ref_list(): <TAB> <TAB> <TAB> <TAB> if event_ref: <TAB> <TAB> <TAB> <TAB> <TAB> event = db.get_event_from_handle(event_ref.ref) <TAB> <TAB> <TAB> <TAB> <TAB> if not event.get_place_handle(): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> <TAB> if not event.get_date_object(): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",false,if not event . get_date_object ( ) :,if not event . get_place_handle ( ) :,0.5,0.0
"def killIfDead(): <TAB> if not self._isalive: <TAB> <TAB> self.log.debug( <TAB> <TAB> <TAB> ""WampLongPoll: killing inactive WAMP session with transport '{0}'"".format( <TAB> <TAB> <TAB> <TAB> self._transport_id <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> self.onClose(False, 5000, ""session inactive"") <TAB> <TAB> self._receive._kill() <TAB> <TAB> if self._transport_id in self._parent._transports: <TAB> <TAB> <TAB> del self._parent._transports[self._transport_id] <TAB> else: <TAB> <TAB> self.log.debug( <TAB> <TAB> <TAB> ""WampLongPoll: transport '{0}' is still alive"".format(self._transport_id) <TAB> <TAB> ) <TAB> <TAB> self._isalive = False <TAB> <TAB> self.reactor.callLater(killAfter, killIfDead)",true,if self . _transport_id in self . _parent . _transports :,if self . _transport_id in self . _parent . _transports :,0.75,0.0
"def offsets(self): <TAB> offsets = {} <TAB> offset_so_far = 0 <TAB> for name, ty in self.fields.items(): <TAB> <TAB> if isinstance(ty, SimTypeBottom): <TAB> <TAB> <TAB> l.warning( <TAB> <TAB> <TAB> <TAB> ""Found a bottom field in struct %s. Ignore and increment the offset using the default "" <TAB> <TAB> <TAB> <TAB> ""element size."", <TAB> <TAB> <TAB> <TAB> self.name, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if not self._pack: <TAB> <TAB> <TAB> align = ty.alignment <TAB> <TAB> <TAB> if offset_so_far % align != 0: <TAB> <TAB> <TAB> <TAB> offset_so_far += align - offset_so_far % align <TAB> <TAB> offsets[name] = offset_so_far <TAB> <TAB> offset_so_far += ty.size // self._arch.byte_width <TAB> return offsets",true,"if isinstance ( ty , SimTypeBottom ) :","if isinstance ( ty , SimTypeBottom ) :",0.75,0.0
"def get_override_css(self): <TAB> """"""handls allow_css_overrides setting."""""" <TAB> if self.settings.get(""allow_css_overrides""): <TAB> <TAB> filename = self.view.file_name() <TAB> <TAB> filetypes = self.settings.get(""markdown_filetypes"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for filetype in filetypes: <TAB> <TAB> <TAB> <TAB> if filename.endswith(filetype): <TAB> <TAB> <TAB> <TAB> <TAB> css_filename = filename.rpartition(filetype)[0] + "".css"" <TAB> <TAB> <TAB> <TAB> <TAB> if os.path.isfile(css_filename): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return u""<style>%s</style>"" % load_utf8(css_filename) <TAB> return """"",false,if filename and filetypes :,if filetypes :,0.07,0.0
"def setFullCSSSource(self, fullsrc, inline=False): <TAB> self.fullsrc = fullsrc <TAB> if type(self.fullsrc) == six.binary_type: <TAB> <TAB> self.fullsrc = six.text_type(self.fullsrc, ""utf-8"") <TAB> if inline: <TAB> <TAB> self.inline = inline <TAB> if self.fullsrc: <TAB> <TAB> self.srcFullIdx = self.fullsrc.find(self.src) <TAB> <TAB> if self.srcFullIdx < 0: <TAB> <TAB> <TAB> del self.srcFullIdx <TAB> <TAB> self.ctxsrcFullIdx = self.fullsrc.find(self.ctxsrc) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> del self.ctxsrcFullIdx",true,if self . ctxsrcFullIdx < 0 :,if self . ctxsrcFullIdx < 0 :,0.75,0.0
"def title(self): <TAB> ret = theme[""title""] <TAB> if isinstance(self.name, six.string_types): <TAB> <TAB> width = self.statwidth() <TAB> <TAB> return ( <TAB> <TAB> <TAB> ret + self.name[0:width].center(width).replace("" "", ""-"") + theme[""default""] <TAB> <TAB> ) <TAB> for i, name in enumerate(self.name): <TAB> <TAB> width = self.colwidth() <TAB> <TAB> ret = ret + name[0:width].center(width).replace("" "", ""-"") <TAB> <TAB> if i + 1 != len(self.vars): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> ret = ret + theme[""frame""] + char[""dash""] + theme[""title""] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> ret = ret + char[""space""] <TAB> return ret",false,if op . color :,if i + 1 == len ( self . vars ) - 1 :,0.02,0.0
"def _get_requested_databases(self): <TAB> """"""Returns a list of databases requested, not including ignored dbs"""""" <TAB> requested_databases = [] <TAB> if (self._requested_namespaces is not None) and (self._requested_namespaces != []): <TAB> <TAB> for requested_namespace in self._requested_namespaces: <TAB> <TAB> <TAB> if requested_namespace[0] is ""*"": <TAB> <TAB> <TAB> <TAB> return [] <TAB> <TAB> <TAB> elif requested_namespace[0] not in IGNORE_DBS: <TAB> <TAB> <TAB> <TAB> requested_databases.append(requested_namespace[0]) <TAB> return requested_databases",false,"if requested_namespace [ 0 ] is ""*"" :",elif requested_namespace [ 0 ] not in IGNORE_DBS :,0.16,0.0
"def add_channels(cls, voucher, add_channels): <TAB> for add_channel in add_channels: <TAB> <TAB> channel = add_channel[""channel""] <TAB> <TAB> defaults = {""currency"": channel.currency_code} <TAB> <TAB> if ""discount_value"" in add_channel.keys(): <TAB> <TAB> <TAB> defaults[""discount_value""] = add_channel.get(""discount_value"") <TAB> <TAB> if ""min_amount_spent"" in add_channel.keys(): <TAB> <TAB> <TAB> defaults[""min_spent_amount""] = add_channel.get(""min_amount_spent"", None) <TAB> <TAB> models.VoucherChannelListing.objects.update_or_create( <TAB> <TAB> <TAB> voucher=voucher, <TAB> <TAB> <TAB> channel=channel, <TAB> <TAB> <TAB> defaults=defaults, <TAB> <TAB> )",false,"if ""discount_value"" in add_channel . keys ( ) :","if ""min_amount_spent"" in add_channel . keys ( ) :",0.63,0.0
"def read_xml(path): <TAB> with tf.gfile.GFile(path) as f: <TAB> <TAB> root = etree.fromstring(f.read()) <TAB> annotations = {} <TAB> for node in root.getchildren(): <TAB> <TAB> key, val = node2dict(node) <TAB> <TAB> # If `key` is object, it's actually a list. <TAB> <TAB> if key == ""object"": <TAB> <TAB> <TAB> annotations.setdefault(key, []).append(val) <TAB> <TAB> else: <TAB> <TAB> <TAB> annotations[key] = val <TAB> return annotations",true,"if key == ""object"" :","if key == ""object"" :",0.75,0.0
"def get_ip_info(ipaddress): <TAB> """"""Returns device information by IP address"""""" <TAB> result = {} <TAB> try: <TAB> <TAB> ip = IPAddress.objects.select_related().get(address=ipaddress) <TAB> except IPAddress.DoesNotExist: <TAB> <TAB> pass <TAB> else: <TAB> <TAB> if ip.venture is not None: <TAB> <TAB> <TAB> result[""venture_id""] = ip.venture.id <TAB> <TAB> if ip.device is not None: <TAB> <TAB> <TAB> result[""device_id""] = ip.device.id <TAB> <TAB> <TAB> if ip.device.venture is not None: <TAB> <TAB> <TAB> <TAB> result[""venture_id""] = ip.device.venture.id <TAB> return result",false,if ip . venture is not None :,if ip . device is not None :,0.5,0.0
"def test_large_headers(self): <TAB> with ExpectLog(gen_log, ""Unsatisfiable read"", required=False): <TAB> <TAB> try: <TAB> <TAB> <TAB> self.fetch(""/"", headers={""X-Filler"": ""a"" * 1000}, raise_error=True) <TAB> <TAB> <TAB> self.fail(""did not raise expected exception"") <TAB> <TAB> except HTTPError as e: <TAB> <TAB> <TAB> # 431 is ""Request Header Fields Too Large"", defined in RFC <TAB> <TAB> <TAB> # 6585. However, many implementations just close the <TAB> <TAB> <TAB> # connection in this case, resulting in a missing response. <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.assertIn(e.response.code, (431, 599))",false,if e . response is not None :,if e . response :,0.23,0.0
"def validate_reserved_serial_no_consumption(self): <TAB> for item in self.items: <TAB> <TAB> if item.s_warehouse and not item.t_warehouse and item.serial_no: <TAB> <TAB> <TAB> for sr in get_serial_nos(item.serial_no): <TAB> <TAB> <TAB> <TAB> sales_order = frappe.db.get_value(""Serial No"", sr, ""sales_order"") <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> msg = _( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""(Serial No: {0}) cannot be consumed as it's reserverd to fullfill Sales Order {1}."" <TAB> <TAB> <TAB> <TAB> <TAB> ).format(sr, sales_order) <TAB> <TAB> <TAB> <TAB> <TAB> frappe.throw(_(""Item {0} {1}"").format(item.item_code, msg))",true,if sales_order :,if sales_order :,0.53,0.0
"def force_decode(string, encoding): <TAB> if isinstance(string, str): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> string = string.decode(encoding) <TAB> <TAB> else: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> # try decoding with utf-8, should only work for real UTF-8 <TAB> <TAB> <TAB> <TAB> string = string.decode(""utf-8"") <TAB> <TAB> <TAB> except UnicodeError: <TAB> <TAB> <TAB> <TAB> # last resort -- can't fail <TAB> <TAB> <TAB> <TAB> string = string.decode(""latin1"") <TAB> return string",true,if encoding :,if encoding :,0.53,0.0
"def _add_cs(master_cs, sub_cs, prefix, delimiter=""."", parent_hp=None): <TAB> new_parameters = [] <TAB> for hp in sub_cs.get_hyperparameters(): <TAB> <TAB> new_parameter = copy.deepcopy(hp) <TAB> <TAB> # Allow for an empty top-level parameter <TAB> <TAB> if new_parameter.name == """": <TAB> <TAB> <TAB> new_parameter.name = prefix <TAB> <TAB> elif not prefix == """": <TAB> <TAB> <TAB> new_parameter.name = ""{}{}{}"".format(prefix, SPLITTER, new_parameter.name) <TAB> <TAB> new_parameters.append(new_parameter) <TAB> for hp in new_parameters: <TAB> <TAB> _add_hp(master_cs, hp)",true,"elif not prefix == """" :","elif not prefix == """" :",0.75,0.0
"def __call__(self, *args, **kwargs): <TAB> if self.log_file is not None: <TAB> <TAB> kwargs[""file""] = self.log_file <TAB> <TAB> print(*args, **kwargs) <TAB> <TAB> if hasattr(self.log_file, ""flush""): <TAB> <TAB> <TAB> # get immediate feedback <TAB> <TAB> <TAB> self.log_file.flush() <TAB> elif self.log_func is not None: <TAB> <TAB> self.log_func(*args, **kwargs)",true,"if hasattr ( self . log_file , ""flush"" ) :","if hasattr ( self . log_file , ""flush"" ) :",0.75,0.0
"def df_index_expr(self, length_expr=None, as_range=False): <TAB> """"""Generate expression to get or create index of DF"""""" <TAB> if isinstance(self.index, types.NoneType): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> length_expr = df_length_expr(self) <TAB> <TAB> if as_range: <TAB> <TAB> <TAB> return f""range({length_expr})"" <TAB> <TAB> else: <TAB> <TAB> <TAB> return f""numpy.arange({length_expr})"" <TAB> return ""self._index""",true,if length_expr is None :,if length_expr is None :,0.75,0.0
"def _setWeight(self, value): <TAB> if value is None: <TAB> <TAB> self._fontWeight = None <TAB> else: <TAB> <TAB> if value.lower() not in (""normal"", ""bold""): <TAB> <TAB> <TAB> raise TextFormatException(f""Not a supported fontWeight: {value}"") <TAB> <TAB> self._fontWeight = value.lower()",true,"if value . lower ( ) not in ( ""normal"" , ""bold"" ) :","if value . lower ( ) not in ( ""normal"" , ""bold"" ) :",0.75,0.0
"def _test_configuration(self): <TAB> config_path = self._write_config() <TAB> try: <TAB> <TAB> self._log.debug(""testing configuration"") <TAB> <TAB> verboseflag = ""-Q"" <TAB> <TAB> if self._log.isEnabledFor(logging.DEBUG): <TAB> <TAB> <TAB> verboseflag = ""-v"" <TAB> <TAB> p = subprocess.Popen([self.PATH_SLAPTEST, verboseflag, ""-f"", config_path]) <TAB> <TAB> if p.wait() != 0: <TAB> <TAB> <TAB> raise RuntimeError(""configuration test failed"") <TAB> <TAB> self._log.debug(""configuration seems ok"") <TAB> finally: <TAB> <TAB> os.remove(config_path)",true,if p . wait ( ) != 0 :,if p . wait ( ) != 0 :,0.75,0.0
"def filter_queryset(self, request, queryset, view): <TAB> kwargs = {} <TAB> for field in view.filterset_fields: <TAB> <TAB> value = request.GET.get(field) <TAB> <TAB> if not value: <TAB> <TAB> <TAB> continue <TAB> <TAB> if field == ""node_id"": <TAB> <TAB> <TAB> value = get_object_or_none(Node, pk=value) <TAB> <TAB> <TAB> kwargs[""node""] = value <TAB> <TAB> <TAB> continue <TAB> <TAB> elif field == ""asset_id"": <TAB> <TAB> <TAB> field = ""asset"" <TAB> <TAB> kwargs[field] = value <TAB> if kwargs: <TAB> <TAB> queryset = queryset.filter(**kwargs) <TAB> logger.debug(""Filter {}"".format(kwargs)) <TAB> return queryset",true,"elif field == ""asset_id"" :","elif field == ""asset_id"" :",1.0,0.0
"def _find_closing_brace(string, start_pos): <TAB> """"""Finds the corresponding closing brace after start_pos."""""" <TAB> bracks_open = 1 <TAB> for idx, char in enumerate(string[start_pos:]): <TAB> <TAB> if char == ""("": <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> bracks_open += 1 <TAB> <TAB> elif char == "")"": <TAB> <TAB> <TAB> if string[idx + start_pos - 1] != ""\\"": <TAB> <TAB> <TAB> <TAB> bracks_open -= 1 <TAB> <TAB> <TAB> if not bracks_open: <TAB> <TAB> <TAB> <TAB> return start_pos + idx + 1",true,"if string [ idx + start_pos - 1 ] != ""\\"" :","if string [ idx + start_pos - 1 ] != ""\\"" :",0.75,0.0
"def _set_hostport(self, host, port): <TAB> if port is None: <TAB> <TAB> i = host.rfind("":"") <TAB> <TAB> j = host.rfind(""]"")  # ipv6 addresses have [...] <TAB> <TAB> if i > j: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> port = int(host[i + 1 :]) <TAB> <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> <TAB> raise InvalidURL(""nonnumeric port: '%s'"" % host[i + 1 :]) <TAB> <TAB> <TAB> host = host[:i] <TAB> <TAB> else: <TAB> <TAB> <TAB> port = self.default_port <TAB> <TAB> if host and host[0] == ""["" and host[-1] == ""]"": <TAB> <TAB> <TAB> host = host[1:-1] <TAB> self.host = host <TAB> self.port = port",true,"if host and host [ 0 ] == ""["" and host [ - 1 ] == ""]"" :","if host and host [ 0 ] == ""["" and host [ - 1 ] == ""]"" :",1.0,0.0
"def __getstate__(self): <TAB> state = {} <TAB> for cls in type(self).mro(): <TAB> <TAB> cls_slots = getattr(cls, ""__slots__"", ()) <TAB> <TAB> for slot in cls_slots: <TAB> <TAB> <TAB> if slot != ""__weakref__"": <TAB> <TAB> <TAB> <TAB> if hasattr(self, slot): <TAB> <TAB> <TAB> <TAB> <TAB> state[slot] = getattr(self, slot) <TAB> state[""_cookiejar_cookies""] = list(self.cookiejar) <TAB> del state[""cookiejar""] <TAB> return state",true,"if hasattr ( self , slot ) :","if hasattr ( self , slot ) :",0.75,0.0
"def _evp_pkey_from_der_traditional_key(self, bio_data, password): <TAB> key = self._lib.d2i_PrivateKey_bio(bio_data.bio, self._ffi.NULL) <TAB> if key != self._ffi.NULL: <TAB> <TAB> key = self._ffi.gc(key, self._lib.EVP_PKEY_free) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise TypeError(""Password was given but private key is not encrypted."") <TAB> <TAB> return key <TAB> else: <TAB> <TAB> self._consume_errors() <TAB> <TAB> return None",false,if password is not None :,if password != key . data :,0.05,0.0
"def is_special(s, i, directive): <TAB> """"""Return True if the body text contains the @ directive."""""" <TAB> # j = skip_line(s,i) ; trace(s[i:j],':',directive) <TAB> assert directive and directive[0] == ""@"" <TAB> # 10/23/02: all directives except @others must start the line. <TAB> skip_flag = directive in (""@others"", ""@all"") <TAB> while i < len(s): <TAB> <TAB> if match_word(s, i, directive): <TAB> <TAB> <TAB> return True, i <TAB> <TAB> else: <TAB> <TAB> <TAB> i = skip_line(s, i) <TAB> <TAB> <TAB> if skip_flag: <TAB> <TAB> <TAB> <TAB> i = skip_ws(s, i) <TAB> return False, -1",true,"if match_word ( s , i , directive ) :","if match_word ( s , i , directive ) :",0.75,0.0
"def _decorator(coro_func): <TAB> fut = asyncio.ensure_future(coro_func()) <TAB> self._tests.append((coro_func.__name__, fut)) <TAB> if timeout_sec is not None: <TAB> <TAB> timeout_at = self._loop.time() + timeout_sec <TAB> <TAB> handle = self.MASTER_LOOP.call_at( <TAB> <TAB> <TAB> timeout_at, self._set_exception_if_not_done, fut, asyncio.TimeoutError() <TAB> <TAB> ) <TAB> <TAB> fut.add_done_callback(lambda *args: handle.cancel()) <TAB> <TAB> if timeout_at > self._global_timeout_at: <TAB> <TAB> <TAB> self._global_timeout_at = timeout_at <TAB> return coro_func",true,if timeout_at > self . _global_timeout_at :,if timeout_at > self . _global_timeout_at :,0.75,0.0
"def _load(self, db, owner): <TAB> self.__init(owner) <TAB> db_result = db( <TAB> <TAB> ""SELECT ship_id, state_id FROM ai_combat_ship WHERE owner_id = ?"", <TAB> <TAB> self.owner.worldid, <TAB> ) <TAB> for ( <TAB> <TAB> ship_id, <TAB> <TAB> state_id, <TAB> ) in db_result: <TAB> <TAB> ship = WorldObject.get_object_by_id(ship_id) <TAB> <TAB> state = self.shipStates[state_id] <TAB> <TAB> # add move callbacks corresponding to given state <TAB> <TAB> if state == self.shipStates.moving: <TAB> <TAB> <TAB> ship.add_move_callback(Callback(BehaviorMoveCallback._arrived, ship)) <TAB> <TAB> self.add_new_unit(ship, state)",true,if state == self . shipStates . moving :,if state == self . shipStates . moving :,0.75,0.0
"def addError(self, test, err): <TAB> if err[0] is SkipTest: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.stream.writeln(str(err[1])) <TAB> <TAB> elif self.dots: <TAB> <TAB> <TAB> self.stream.write(""s"") <TAB> <TAB> <TAB> self.stream.flush() <TAB> <TAB> return <TAB> _org_AddError(self, test, err)",false,if self . showAll :,if self . verbose :,0.39,0.0
"def _construct(self, node): <TAB> self.flatten_mapping(node) <TAB> ret = self.construct_pairs(node) <TAB> keys = [d[0] for d in ret] <TAB> keys_sorted = sorted(keys, key=_natsort_key) <TAB> for key in keys: <TAB> <TAB> expected = keys_sorted.pop(0) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ConstructorError( <TAB> <TAB> <TAB> <TAB> None, <TAB> <TAB> <TAB> <TAB> None, <TAB> <TAB> <TAB> <TAB> ""keys out of order: "" <TAB> <TAB> <TAB> <TAB> ""expected {} got {} at {}"".format(expected, key, node.start_mark), <TAB> <TAB> <TAB> ) <TAB> return dict(ret)",false,if key != expected :,if expected != key :,0.29,0.0
"def sample_pos_items_for_u(u, num): <TAB> # sample num pos items for u-th user <TAB> pos_items = self.train_items[u] <TAB> n_pos_items = len(pos_items) <TAB> pos_batch = [] <TAB> while True: <TAB> <TAB> if len(pos_batch) == num: <TAB> <TAB> <TAB> break <TAB> <TAB> pos_id = np.random.randint(low=0, high=n_pos_items, size=1)[0] <TAB> <TAB> pos_i_id = pos_items[pos_id] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> pos_batch.append(pos_i_id) <TAB> return pos_batch",false,if pos_i_id not in pos_batch :,if pos_i_id not in self . pos_batch :,0.4,0.0
"def _get_id(self, type, id): <TAB> fields = id.split("":"") <TAB> if len(fields) >= 3: <TAB> <TAB> if type != fields[-2]: <TAB> <TAB> <TAB> logger.warning( <TAB> <TAB> <TAB> <TAB> ""Expected id of type %s but found type %s %s"", type, fields[-2], id <TAB> <TAB> <TAB> ) <TAB> <TAB> return fields[-1] <TAB> fields = id.split(""/"") <TAB> if len(fields) >= 3: <TAB> <TAB> itype = fields[-2] <TAB> <TAB> if type != itype: <TAB> <TAB> <TAB> logger.warning( <TAB> <TAB> <TAB> <TAB> ""Expected id of type %s but found type %s %s"", type, itype, id <TAB> <TAB> <TAB> ) <TAB> <TAB> return fields[-1].split(""?"")[0] <TAB> return id",true,if type != fields [ - 2 ] :,if type != fields [ - 2 ] :,0.75,0.0
"def uninstall_environments(self, environments): <TAB> environments = [ <TAB> <TAB> env <TAB> <TAB> if not env.startswith(self.conda_context.envs_path) <TAB> <TAB> else os.path.basename(env) <TAB> <TAB> for env in environments <TAB> ] <TAB> return_codes = [self.conda_context.exec_remove([env]) for env in environments] <TAB> final_return_code = 0 <TAB> for env, return_code in zip(environments, return_codes): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> log.debug(""Conda environment '%s' successfully removed."" % env) <TAB> <TAB> else: <TAB> <TAB> <TAB> log.debug(""Conda environment '%s' could not be removed."" % env) <TAB> <TAB> <TAB> final_return_code = return_code <TAB> return final_return_code",true,if return_code == 0 :,if return_code == 0 :,0.75,0.0
"def _add_hit_offset(self, context_list, string_name, original_offset, value): <TAB> for context in context_list: <TAB> <TAB> hits_by_context_dict = self.hits_by_context.setdefault(context, {}) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> hits_by_context_dict[string_name] = ( <TAB> <TAB> <TAB> <TAB> original_offset, <TAB> <TAB> <TAB> <TAB> value.encode(""base64""), <TAB> <TAB> <TAB> )",true,if string_name not in hits_by_context_dict :,if string_name not in hits_by_context_dict :,0.75,0.0
"def detab(self, text, length=None): <TAB> """"""Remove a tab from the front of each line of the given text."""""" <TAB> if length is None: <TAB> <TAB> length = self.tab_length <TAB> newtext = [] <TAB> lines = text.split(""\n"") <TAB> for line in lines: <TAB> <TAB> if line.startswith("" "" * length): <TAB> <TAB> <TAB> newtext.append(line[length:]) <TAB> <TAB> elif not line.strip(): <TAB> <TAB> <TAB> newtext.append("""") <TAB> <TAB> else: <TAB> <TAB> <TAB> break <TAB> return ""\n"".join(newtext), ""\n"".join(lines[len(newtext) :])",true,elif not line . strip ( ) :,elif not line . strip ( ) :,0.75,0.0
"def dump(self): <TAB> print(self.package_name) <TAB> for package, value in self.entries: <TAB> <TAB> print(str(package.version)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print("" <TAB>[FILTERED]"") <TAB> <TAB> elif isinstance(value, list): <TAB> <TAB> <TAB> variants = value <TAB> <TAB> <TAB> for variant in variants: <TAB> <TAB> <TAB> <TAB> print("" <TAB>%s"" % str(variant)) <TAB> <TAB> else: <TAB> <TAB> <TAB> print("" <TAB>%s"" % str(package))",true,if value is None :,if value is None :,0.75,0.0
"def __lexical_scope(*args, **kwargs): <TAB> try: <TAB> <TAB> scope = Scope(quasi) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> binding_name_set_stack[-1].add_child(scope) <TAB> <TAB> binding_name_set_stack.append(scope) <TAB> <TAB> return func(*args, **kwargs) <TAB> finally: <TAB> <TAB> if binding_name_set_stack[-1] is scope: <TAB> <TAB> <TAB> binding_name_set_stack.pop()",false,if quasi :,if scope not in binding_name_set_stack :,0.05,0.0
"def getnotes(self, origin=None): <TAB> if origin is None: <TAB> <TAB> result = self.translator_comments <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if result: <TAB> <TAB> <TAB> <TAB> result += ""\n"" + self.developer_comments <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> result = self.developer_comments <TAB> <TAB> return result <TAB> elif origin == ""translator"": <TAB> <TAB> return self.translator_comments <TAB> elif origin in (""programmer"", ""developer"", ""source code""): <TAB> <TAB> return self.developer_comments <TAB> else: <TAB> <TAB> raise ValueError(""Comment type not valid"")",false,if self . developer_comments :,if origin :,0.04,0.0
"def fix_datetime_fields(data: TableData, table: TableName) -> None: <TAB> for item in data[table]: <TAB> <TAB> for field_name in DATE_FIELDS[table]: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> item[field_name] = datetime.datetime.fromtimestamp( <TAB> <TAB> <TAB> <TAB> <TAB> item[field_name], tz=datetime.timezone.utc <TAB> <TAB> <TAB> <TAB> )",false,if item [ field_name ] is not None :,if field_name in item :,0.12,0.0
"def _check_for_cart_error(cart): <TAB> if cart._safe_get_element(""Cart.Request.Errors"") is not None: <TAB> <TAB> error = cart._safe_get_element(""Cart.Request.Errors.Error.Code"").text <TAB> <TAB> if error == ""AWS.ECommerceService.CartInfoMismatch"": <TAB> <TAB> <TAB> raise CartInfoMismatchException( <TAB> <TAB> <TAB> <TAB> ""CartGet failed: AWS.ECommerceService.CartInfoMismatch "" <TAB> <TAB> <TAB> <TAB> ""make sure AssociateTag, CartId and HMAC are correct "" <TAB> <TAB> <TAB> <TAB> ""(dont use URLEncodedHMAC!!!)"" <TAB> <TAB> <TAB> ) <TAB> <TAB> raise CartException(""CartGet failed: "" + error)",true,"if error == ""AWS.ECommerceService.CartInfoMismatch"" :","if error == ""AWS.ECommerceService.CartInfoMismatch"" :",0.75,0.0
"def check_bounds(geometry): <TAB> if isinstance(geometry[0], (list, tuple)): <TAB> <TAB> return list(map(check_bounds, geometry)) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""Longitude is out of bounds, check your JSON format or data"" <TAB> <TAB> <TAB> ) <TAB> <TAB> if geometry[1] > 90 or geometry[1] < -90: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""Latitude is out of bounds, check your JSON format or data"" <TAB> <TAB> <TAB> )",false,if geometry [ 0 ] > 180 or geometry [ 0 ] < - 180 :,if geometry [ 0 ] > 180 or geometry [ 0 ] < - 90 :,0.94,0.0
"def _mapper_output_protocol(self, step_num, step_map): <TAB> map_key = self._step_key(step_num, ""mapper"") <TAB> if map_key in step_map: <TAB> <TAB> if step_map[map_key] >= (len(step_map) - 1): <TAB> <TAB> <TAB> return self.output_protocol() <TAB> <TAB> else: <TAB> <TAB> <TAB> return self.internal_protocol() <TAB> else: <TAB> <TAB> # mapper is not a script substep, so protocols don't apply at all <TAB> <TAB> return RawValueProtocol()",true,if step_map [ map_key ] >= ( len ( step_map ) - 1 ) :,if step_map [ map_key ] >= ( len ( step_map ) - 1 ) :,1.0,0.0
"def asset(*paths): <TAB> for path in paths: <TAB> <TAB> fspath = www_root + ""/assets/"" + path <TAB> <TAB> etag = """" <TAB> <TAB> try: <TAB> <TAB> <TAB> if env.cache_static: <TAB> <TAB> <TAB> <TAB> etag = asset_etag(fspath) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> os.stat(fspath) <TAB> <TAB> except FileNotFoundError as e: <TAB> <TAB> <TAB> if path == paths[-1]: <TAB> <TAB> <TAB> <TAB> if not os.path.exists(fspath + "".spt""): <TAB> <TAB> <TAB> <TAB> <TAB> tell_sentry(e, {}) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> tell_sentry(e, {}) <TAB> <TAB> return asset_url + path + (etag and ""?etag="" + etag)",true,if path == paths [ - 1 ] :,if path == paths [ - 1 ] :,0.75,0.0
"def ping(self, payload: Union[str, bytes] = """") -> None: <TAB> if self.trace_enabled and self.ping_pong_trace_enabled: <TAB> <TAB> if isinstance(payload, bytes): <TAB> <TAB> <TAB> payload = payload.decode(""utf-8"") <TAB> <TAB> self.logger.debug( <TAB> <TAB> <TAB> ""Sending a ping data frame "" <TAB> <TAB> <TAB> f""(session id: {self.session_id}, payload: {payload})"" <TAB> <TAB> ) <TAB> data = _build_data_frame_for_sending(payload, FrameHeader.OPCODE_PING) <TAB> with self.sock_send_lock: <TAB> <TAB> self.sock.send(data)",true,"if isinstance ( payload , bytes ) :","if isinstance ( payload , bytes ) :",0.75,0.0
"def is_ac_power_connected(): <TAB> for power_source_path in Path(""/sys/class/power_supply/"").iterdir(): <TAB> <TAB> try: <TAB> <TAB> <TAB> with open(power_source_path / ""type"", ""r"") as f: <TAB> <TAB> <TAB> <TAB> if f.read().strip() != ""Mains"": <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> with open(power_source_path / ""online"", ""r"") as f: <TAB> <TAB> <TAB> <TAB> if f.read(1) == ""1"": <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> except IOError: <TAB> <TAB> <TAB> continue <TAB> return False",true,"if f . read ( 1 ) == ""1"" :","if f . read ( 1 ) == ""1"" :",0.75,0.0
"def handle_noargs(self, **options): <TAB> self.style = color_style() <TAB> print(""Running Django's own validation:"") <TAB> self.validate(display_num_errors=True) <TAB> for model in loading.get_models(): <TAB> <TAB> if hasattr(model, ""_create_content_base""): <TAB> <TAB> <TAB> self.validate_base_model(model) <TAB> <TAB> if hasattr(model, ""_feincms_content_models""): <TAB> <TAB> <TAB> self.validate_content_type(model)",true,"if hasattr ( model , ""_create_content_base"" ) :","if hasattr ( model , ""_create_content_base"" ) :",0.75,0.0
"def _init_weights(self, module): <TAB> if isinstance(module, nn.Linear): <TAB> <TAB> module.weight.data.normal_(mean=0.0, std=self.config.init_std) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> module.bias.data.zero_() <TAB> elif isinstance(module, nn.Embedding): <TAB> <TAB> module.weight.data.normal_(mean=0.0, std=self.config.init_std) <TAB> <TAB> if module.padding_idx is not None: <TAB> <TAB> <TAB> module.weight.data[module.padding_idx].zero_()",true,if module . bias is not None :,if module . bias is not None :,0.75,0.0
"def walk(msg, callback, data): <TAB> partnum = 0 <TAB> for part in msg.walk(): <TAB> <TAB> # multipart/* are just containers <TAB> <TAB> if part.get_content_maintype() == ""multipart"": <TAB> <TAB> <TAB> continue <TAB> <TAB> ctype = part.get_content_type() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ctype = OCTET_TYPE <TAB> <TAB> filename = part.get_filename() <TAB> <TAB> if not filename: <TAB> <TAB> <TAB> filename = PART_FN_TPL % (partnum) <TAB> <TAB> headers = dict(part) <TAB> <TAB> LOG.debug(headers) <TAB> <TAB> headers[""Content-Type""] = ctype <TAB> <TAB> payload = util.fully_decoded_payload(part) <TAB> <TAB> callback(data, filename, payload, headers) <TAB> <TAB> partnum = partnum + 1",false,if ctype is None :,if not ctype :,0.04,0.0
"def _mark_lcs(mask, dirs, m, n): <TAB> while m != 0 and n != 0: <TAB> <TAB> if dirs[m, n] == ""|"": <TAB> <TAB> <TAB> m -= 1 <TAB> <TAB> <TAB> n -= 1 <TAB> <TAB> <TAB> mask[m] = 1 <TAB> <TAB> elif dirs[m, n] == ""^"": <TAB> <TAB> <TAB> m -= 1 <TAB> <TAB> elif dirs[m, n] == ""<"": <TAB> <TAB> <TAB> n -= 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> raise UnboundLocalError(""Illegal move"") <TAB> return mask",false,"elif dirs [ m , n ] == ""^"" :","elif dirs [ m , n ] == ""<"" :",0.64,0.0
"def valid_localparts(strip_delimiters=False): <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS.split(""\n""): <TAB> <TAB> # strip line, skip over empty lines <TAB> <TAB> line = line.strip() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over comments or empty lines <TAB> <TAB> match = COMMENT.match(line) <TAB> <TAB> if match: <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over localparts with delimiters <TAB> <TAB> if strip_delimiters: <TAB> <TAB> <TAB> if "","" in line or "";"" in line: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield line",false,"if line == """" :",if not line :,0.04,0.0
"def fetch(self, *tileables, **kw): <TAB> ret_list = False <TAB> if len(tileables) == 1 and isinstance(tileables[0], (tuple, list)): <TAB> <TAB> ret_list = True <TAB> <TAB> tileables = tileables[0] <TAB> elif len(tileables) > 1: <TAB> <TAB> ret_list = True <TAB> result = self._sess.fetch(*tileables, **kw) <TAB> ret = [] <TAB> for r, t in zip(result, tileables): <TAB> <TAB> if hasattr(t, ""isscalar"") and t.isscalar() and getattr(r, ""size"", None) == 1: <TAB> <TAB> <TAB> ret.append(r.item()) <TAB> <TAB> else: <TAB> <TAB> <TAB> ret.append(r) <TAB> if ret_list: <TAB> <TAB> return ret <TAB> return ret[0]",true,"if hasattr ( t , ""isscalar"" ) and t . isscalar ( ) and getattr ( r , ""size"" , None ) == 1 :","if hasattr ( t , ""isscalar"" ) and t . isscalar ( ) and getattr ( r , ""size"" , None ) == 1 :",1.0,0.0
"def _convert(container): <TAB> if _value_marker in container: <TAB> <TAB> force_list = False <TAB> <TAB> values = container.pop(_value_marker) <TAB> <TAB> if container.pop(_list_marker, False): <TAB> <TAB> <TAB> force_list = True <TAB> <TAB> <TAB> values.extend(_convert(x[1]) for x in sorted(container.items())) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> values = values[0] <TAB> <TAB> if not container: <TAB> <TAB> <TAB> return values <TAB> <TAB> return _convert(container) <TAB> elif container.pop(_list_marker, False): <TAB> <TAB> return [_convert(x[1]) for x in sorted(container.items())] <TAB> return dict_cls((k, _convert(v)) for k, v in iteritems(container))",false,if not force_list and len ( values ) == 1 :,if force_list :,0.01,0.0
"def _transform_init_kwargs(cls, kwargs): <TAB> transformed = [] <TAB> for field in list(kwargs.keys()): <TAB> <TAB> prop = getattr(cls, field, None) <TAB> <TAB> if isinstance(prop, MoneyProperty): <TAB> <TAB> <TAB> value = kwargs.pop(field) <TAB> <TAB> <TAB> _transform_single_init_kwarg(prop, field, value, kwargs) <TAB> <TAB> <TAB> transformed.append((field, value)) <TAB> return transformed",true,"if isinstance ( prop , MoneyProperty ) :","if isinstance ( prop , MoneyProperty ) :",0.75,0.0
"def haslayer(self, cls): <TAB> """"""true if self has a layer that is an instance of cls. Superseded by ""cls in self"" syntax."""""" <TAB> if self.__class__ == cls or self.__class__.__name__ == cls: <TAB> <TAB> return 1 <TAB> for f in self.packetfields: <TAB> <TAB> fvalue_gen = self.getfieldval(f.name) <TAB> <TAB> if fvalue_gen is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> if not f.islist: <TAB> <TAB> <TAB> fvalue_gen = SetGen(fvalue_gen, _iterpacket=0) <TAB> <TAB> for fvalue in fvalue_gen: <TAB> <TAB> <TAB> if isinstance(fvalue, Packet): <TAB> <TAB> <TAB> <TAB> ret = fvalue.haslayer(cls) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return ret <TAB> return self.payload.haslayer(cls)",true,if ret :,if ret :,0.53,0.0
def insert_broken_add_sometimes(node): <TAB> if node.op == theano.tensor.add: <TAB> <TAB> last_time_replaced[0] = not last_time_replaced[0] <TAB> <TAB> if last_time_replaced[0]: <TAB> <TAB> <TAB> return [off_by_half(*node.inputs)] <TAB> return False,true,if last_time_replaced [ 0 ] :,if last_time_replaced [ 0 ] :,0.75,0.0
"def testReadChunk10(self): <TAB> # ""Test BZ2File.read() in chunks of 10 bytes"" <TAB> self.createTempFile() <TAB> with BZ2File(self.filename) as bz2f: <TAB> <TAB> text = """" <TAB> <TAB> while 1: <TAB> <TAB> <TAB> str = bz2f.read(10) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> text += str <TAB> <TAB> self.assertEqual(text, self.TEXT)",true,if not str :,if not str :,0.75,0.0
"def generate_sv_faces(dcel_mesh, point_index, only_select=False, del_flag=None): <TAB> # This part of function creates faces in SV format <TAB> # It ignores  boundless super face <TAB> sv_faces = [] <TAB> for i, face in enumerate(dcel_mesh.faces): <TAB> <TAB> if face.inners and face.outer: <TAB> <TAB> <TAB> ""Face ({}) has inner components! Sverchok cant show polygons with holes."".format( <TAB> <TAB> <TAB> <TAB> i <TAB> <TAB> <TAB> ) <TAB> <TAB> if not face.outer or del_flag in face.flags: <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> sv_faces.append([point_index[hedge.origin] for hedge in face.outer.loop_hedges]) <TAB> return sv_faces",false,if only_select and not face . select :,if only_select and del_flag in face . flags :,0.21,0.0
"def __check_dict_contains(dct, dict_name, keys, comment="""", result=True): <TAB> for key in keys: <TAB> <TAB> if key not in six.iterkeys(dct): <TAB> <TAB> <TAB> result = False <TAB> <TAB> <TAB> comment = __append_comment( <TAB> <TAB> <TAB> <TAB> ""Missing {0} in {1}"".format(key, dict_name), comment <TAB> <TAB> <TAB> ) <TAB> return result, comment",true,if key not in six . iterkeys ( dct ) :,if key not in six . iterkeys ( dct ) :,0.75,0.0
"def _dump_arg_defaults(kwargs): <TAB> """"""Inject default arguments for dump functions."""""" <TAB> if current_app: <TAB> <TAB> kwargs.setdefault(""cls"", current_app.json_encoder) <TAB> <TAB> if not current_app.config[""JSON_AS_ASCII""]: <TAB> <TAB> <TAB> kwargs.setdefault(""ensure_ascii"", False) <TAB> <TAB> kwargs.setdefault(""sort_keys"", current_app.config[""JSON_SORT_KEYS""]) <TAB> else: <TAB> <TAB> kwargs.setdefault(""sort_keys"", True) <TAB> <TAB> kwargs.setdefault(""cls"", JSONEncoder)",true,"if not current_app . config [ ""JSON_AS_ASCII"" ] :","if not current_app . config [ ""JSON_AS_ASCII"" ] :",0.75,0.0
"def _on_change(self): <TAB> changed = False <TAB> self.save() <TAB> for key, value in self.data.items(): <TAB> <TAB> if isinstance(value, bool): <TAB> <TAB> <TAB> if value: <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if isinstance(value, int): <TAB> <TAB> <TAB> if value != 1: <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> elif value is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> elif len(value) != 0: <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> break <TAB> self._reset_button.disabled = not changed",true,elif len ( value ) != 0 :,elif len ( value ) != 0 :,0.75,0.0
"def parse_win_proxy(val): <TAB> proxies = [] <TAB> for p in val.split("";""): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tab = p.split(""="", 1) <TAB> <TAB> <TAB> if tab[0] == ""socks"": <TAB> <TAB> <TAB> <TAB> tab[0] = ""SOCKS4"" <TAB> <TAB> <TAB> proxies.append( <TAB> <TAB> <TAB> <TAB> (tab[0].upper(), tab[1], None, None) <TAB> <TAB> <TAB> )  # type, addr:port, username, password <TAB> <TAB> else: <TAB> <TAB> <TAB> proxies.append((""HTTP"", p, None, None)) <TAB> return proxies",true,"if ""="" in p :","if ""="" in p :",0.75,0.0
"def predict(collect_dir, keys): <TAB> run_all = len(keys) == 0 <TAB> validate_keys(keys) <TAB> for exp_cfg in cfg: <TAB> <TAB> if run_all or exp_cfg[""key""] in keys: <TAB> <TAB> <TAB> key = exp_cfg[""key""] <TAB> <TAB> <TAB> _predict(key, exp_cfg[""sample_img""], collect_dir)",true,"if run_all or exp_cfg [ ""key"" ] in keys :","if run_all or exp_cfg [ ""key"" ] in keys :",0.75,0.0
"def convert_port_bindings(port_bindings): <TAB> result = {} <TAB> for k, v in six.iteritems(port_bindings): <TAB> <TAB> key = str(k) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> key += ""/tcp"" <TAB> <TAB> if isinstance(v, list): <TAB> <TAB> <TAB> result[key] = [_convert_port_binding(binding) for binding in v] <TAB> <TAB> else: <TAB> <TAB> <TAB> result[key] = [_convert_port_binding(v)] <TAB> return result",false,"if ""/"" not in key :","if ""tcp"" not in key :",0.52,0.0
"def assert_conll_writer_output( <TAB> dataset: InternalBioNerDataset, <TAB> expected_output: List[str], <TAB> sentence_splitter: SentenceSplitter = None, ): <TAB> outfile_path = tempfile.mkstemp()[1] <TAB> try: <TAB> <TAB> sentence_splitter = ( <TAB> <TAB> <TAB> sentence_splitter <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> else NoSentenceSplitter(tokenizer=SpaceTokenizer()) <TAB> <TAB> ) <TAB> <TAB> writer = CoNLLWriter(sentence_splitter=sentence_splitter) <TAB> <TAB> writer.write_to_conll(dataset, Path(outfile_path)) <TAB> <TAB> contents = [l.strip() for l in open(outfile_path).readlines() if l.strip()] <TAB> finally: <TAB> <TAB> os.remove(outfile_path) <TAB> assert contents == expected_output",true,if sentence_splitter,if sentence_splitter,0.41,0.0
"def post(self, request, *args, **kwargs): <TAB> self.comment_obj = get_object_or_404(Comment, id=request.POST.get(""commentid"")) <TAB> if request.user == self.comment_obj.commented_by: <TAB> <TAB> form = LeadCommentForm(request.POST, instance=self.comment_obj) <TAB> <TAB> if form.is_valid(): <TAB> <TAB> <TAB> return self.form_valid(form) <TAB> <TAB> return self.form_invalid(form) <TAB> data = {""error"": ""You don't have permission to edit this comment.""} <TAB> return JsonResponse(data)",true,if form . is_valid ( ) :,if form . is_valid ( ) :,0.75,0.0
"def trivia_list(self, ctx: commands.Context): <TAB> """"""List available trivia categories."""""" <TAB> lists = set(p.stem for p in self._all_lists()) <TAB> if await ctx.embed_requested(): <TAB> <TAB> await ctx.send( <TAB> <TAB> <TAB> embed=discord.Embed( <TAB> <TAB> <TAB> <TAB> title=_(""Available trivia lists""), <TAB> <TAB> <TAB> <TAB> colour=await ctx.embed_colour(), <TAB> <TAB> <TAB> <TAB> description="", "".join(sorted(lists)), <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> else: <TAB> <TAB> msg = box(bold(_(""Available trivia lists"")) + ""\n\n"" + "", "".join(sorted(lists))) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> await ctx.author.send(msg) <TAB> <TAB> else: <TAB> <TAB> <TAB> await ctx.send(msg)",false,if len ( msg ) > 1000 :,if ctx . author :,0.02,0.0
"def validate(self): <TAB> result = validators.SUCCESS <TAB> msgs = [] <TAB> for validator in self._validators: <TAB> <TAB> res, err = validator.validate() <TAB> <TAB> if res == validators.ERROR: <TAB> <TAB> <TAB> result = res <TAB> <TAB> elif res == validators.WARNING and result != validators.ERROR: <TAB> <TAB> <TAB> result = res <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> msgs.append(err) <TAB> return result, ""\n"".join(msgs)",false,if len ( err ) > 0 :,if err :,0.02,0.0
"def get_code(self, fullname=None): <TAB> fullname = self._fix_name(fullname) <TAB> if self.code is None: <TAB> <TAB> mod_type = self.etc[2] <TAB> <TAB> if mod_type == imp.PY_SOURCE: <TAB> <TAB> <TAB> source = self.get_source(fullname) <TAB> <TAB> <TAB> self.code = compile(source, self.filename, ""exec"") <TAB> <TAB> elif mod_type == imp.PY_COMPILED: <TAB> <TAB> <TAB> self._reopen() <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> self.code = read_code(self.file) <TAB> <TAB> <TAB> finally: <TAB> <TAB> <TAB> <TAB> self.file.close() <TAB> <TAB> elif mod_type == imp.PKG_DIRECTORY: <TAB> <TAB> <TAB> self.code = self._get_delegate().get_code() <TAB> return self.code",false,elif mod_type == imp . PY_COMPILED :,elif mod_type == imp . PKG_DIRECTORY :,0.57,0.0
"def flush_file(self, key, f): <TAB> f.flush() <TAB> if self.compress: <TAB> <TAB> f.compress = zlib.compressobj( <TAB> <TAB> <TAB> 9, zlib.DEFLATED, -zlib.MAX_WBITS, zlib.DEF_MEM_LEVEL, 0 <TAB> <TAB> ) <TAB> if len(self.files) > self.MAX_OPEN_FILES: <TAB> <TAB> if self.compress: <TAB> <TAB> <TAB> open_files = sum(1 for f in self.files.values() if f.fileobj is not None) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> f.fileobj.close() <TAB> <TAB> <TAB> <TAB> f.fileobj = None <TAB> <TAB> else: <TAB> <TAB> <TAB> f.close() <TAB> <TAB> <TAB> self.files.pop(key)",false,if open_files > self . MAX_OPEN_FILES :,if open_files > 0 :,0.09,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.add_version(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0: <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 10 :,if tt == 10 :,0.75,0.0
"def init_author_file(self): <TAB> self.author_map = {} <TAB> if self.ui.config(""git"", ""authors""): <TAB> <TAB> f = open(self.repo.wjoin(self.ui.config(""git"", ""authors""))) <TAB> <TAB> try: <TAB> <TAB> <TAB> for line in f: <TAB> <TAB> <TAB> <TAB> line = line.strip() <TAB> <TAB> <TAB> <TAB> if not line or line.startswith(""#""): <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> from_, to = RE_AUTHOR_FILE.split(line, 2) <TAB> <TAB> <TAB> <TAB> self.author_map[from_] = to <TAB> <TAB> finally: <TAB> <TAB> <TAB> f.close()",true,"if not line or line . startswith ( ""#"" ) :","if not line or line . startswith ( ""#"" ) :",1.0,0.0
"def decode_imsi(self, imsi): <TAB> new_imsi = """" <TAB> for a in imsi: <TAB> <TAB> c = hex(a) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> new_imsi += str(c[3]) + str(c[2]) <TAB> <TAB> else: <TAB> <TAB> <TAB> new_imsi += str(c[2]) + ""0"" <TAB> mcc = new_imsi[1:4] <TAB> mnc = new_imsi[4:6] <TAB> return new_imsi, mcc, mnc",false,if len ( c ) == 4 :,if c [ 0 ] == 0x20 :,0.02,0.0
"def _get_infoset(self, prefname): <TAB> """"""Return methods with the name starting with prefname."""""" <TAB> infoset = [] <TAB> excludes = (""%sinfoset"" % prefname,) <TAB> preflen = len(prefname) <TAB> for name in dir(self.__class__): <TAB> <TAB> if name.startswith(prefname) and name not in excludes: <TAB> <TAB> <TAB> member = getattr(self.__class__, name) <TAB> <TAB> <TAB> if isinstance(member, MethodType): <TAB> <TAB> <TAB> <TAB> infoset.append(name[preflen:].replace(""_"", "" "")) <TAB> return infoset",false,"if isinstance ( member , MethodType ) :",if name . startswith ( prefname ) and name not in excludes :,0.02,0.0
"def skip_to_close_match(self): <TAB> nestedCount = 1 <TAB> while 1: <TAB> <TAB> tok = self.tokenizer.get_next_token() <TAB> <TAB> ttype = tok[""style""] <TAB> <TAB> if ttype == SCE_PL_UNUSED: <TAB> <TAB> <TAB> return <TAB> <TAB> elif self.classifier.is_index_op(tok): <TAB> <TAB> <TAB> tval = tok[""text""] <TAB> <TAB> <TAB> if self.opHash.has_key(tval): <TAB> <TAB> <TAB> <TAB> if self.opHash[tval][1] == 1: <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount += 1 <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount -= 1 <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break",false,if nestedCount <= 0 :,if nestedCount == 0 :,0.33,0.0
"def findMarkForUnitTestNodes(self): <TAB> """"""return the position of *all* non-ignored @mark-for-unit-test nodes."""""" <TAB> c = self.c <TAB> p, result, seen = c.rootPosition(), [], [] <TAB> while p: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> p.moveToNodeAfterTree() <TAB> <TAB> else: <TAB> <TAB> <TAB> seen.append(p.v) <TAB> <TAB> <TAB> if g.match_word(p.h, 0, ""@ignore""): <TAB> <TAB> <TAB> <TAB> p.moveToNodeAfterTree() <TAB> <TAB> <TAB> elif p.h.startswith(""@mark-for-unit-tests""): <TAB> <TAB> <TAB> <TAB> result.append(p.copy()) <TAB> <TAB> <TAB> <TAB> p.moveToNodeAfterTree() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> p.moveToThreadNext() <TAB> return result",true,if p . v in seen :,if p . v in seen :,0.75,0.0
"def assert_parts_cleaned(self, earlier_parts, current_parts, expected_parts, hint): <TAB> cleaned_parts = [] <TAB> for earlier in earlier_parts: <TAB> <TAB> earlier_part = earlier[""part""] <TAB> <TAB> earlier_step = earlier[""step""] <TAB> <TAB> found = False <TAB> <TAB> for current in current_parts: <TAB> <TAB> <TAB> if earlier_part == current[""part""] and earlier_step == current[""step""]: <TAB> <TAB> <TAB> <TAB> found = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> cleaned_parts.append(dict(part=earlier_part, step=earlier_step)) <TAB> self.assertThat(cleaned_parts, HasLength(len(expected_parts)), hint) <TAB> for expected in expected_parts: <TAB> <TAB> self.assertThat(cleaned_parts, Contains(expected), hint)",false,if not found :,if found :,0.1,0.0
"def unmark_first_parents(event=None): <TAB> """"""Mark the node and all its parents."""""" <TAB> c = event.get(""c"") <TAB> if not c: <TAB> <TAB> return <TAB> changed = [] <TAB> for parent in c.p.self_and_parents(): <TAB> <TAB> if parent.isMarked(): <TAB> <TAB> <TAB> parent.v.clearMarked() <TAB> <TAB> <TAB> parent.setAllAncestorAtFileNodesDirty() <TAB> <TAB> <TAB> changed.append(parent.copy()) <TAB> if changed: <TAB> <TAB> # g.es(""unmarked: "" + ', '.join([z.h for z in changed])) <TAB> <TAB> c.setChanged() <TAB> <TAB> c.redraw() <TAB> return changed",true,if parent . isMarked ( ) :,if parent . isMarked ( ) :,0.75,0.0
"def stop(self): <TAB> self._log(""Monitor stop"") <TAB> self._stop_requested = True <TAB> try: <TAB> <TAB> if os.path.exists(self.fifo_path): <TAB> <TAB> <TAB> fd = os.open(self.fifo_path, os.O_WRONLY) <TAB> <TAB> <TAB> os.write(fd, b""X"") <TAB> <TAB> <TAB> os.close(fd) <TAB> except Exception as e: <TAB> <TAB> self._log(""err while closing: {0}"".format(str(e))) <TAB> if self._thread: <TAB> <TAB> self._thread.join() <TAB> <TAB> self._thread = None",true,if os . path . exists ( self . fifo_path ) :,if os . path . exists ( self . fifo_path ) :,0.75,0.0
"def DeleteEmptyCols(self): <TAB> cols2delete = [] <TAB> for c in range(0, self.GetCols()): <TAB> <TAB> f = True <TAB> <TAB> for r in range(0, self.GetRows()): <TAB> <TAB> <TAB> if self.FindItemAtPosition((r, c)) is not None: <TAB> <TAB> <TAB> <TAB> f = False <TAB> <TAB> if f: <TAB> <TAB> <TAB> cols2delete.append(c) <TAB> for i in range(0, len(cols2delete)): <TAB> <TAB> self.ShiftColsLeft(cols2delete[i] + 1) <TAB> <TAB> cols2delete = [x - 1 for x in cols2delete]",true,"if self . FindItemAtPosition ( ( r , c ) ) is not None :","if self . FindItemAtPosition ( ( r , c ) ) is not None :",0.75,0.0
"def _load_objects(self, obj_id_zset, limit, chunk_size=1000): <TAB> ct = i = 0 <TAB> while True: <TAB> <TAB> id_chunk = obj_id_zset[i : i + chunk_size] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> i += chunk_size <TAB> <TAB> for raw_data in self._data[id_chunk]: <TAB> <TAB> <TAB> if not raw_data: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if self._use_json: <TAB> <TAB> <TAB> <TAB> yield json.loads(decode(raw_data)) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> yield raw_data <TAB> <TAB> <TAB> ct += 1 <TAB> <TAB> <TAB> if limit and ct == limit: <TAB> <TAB> <TAB> <TAB> return",true,if not id_chunk :,if not id_chunk :,0.75,0.0
"def _convert_example(example, use_bfloat16): <TAB> """"""Cast int64 into int32 and float32 to bfloat16 if use_bfloat16."""""" <TAB> for key in list(example.keys()): <TAB> <TAB> val = example[key] <TAB> <TAB> if tf.keras.backend.is_sparse(val): <TAB> <TAB> <TAB> val = tf.sparse.to_dense(val) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> val = tf.cast(val, tf.int32) <TAB> <TAB> if use_bfloat16 and val.dtype == tf.float32: <TAB> <TAB> <TAB> val = tf.cast(val, tf.bfloat16) <TAB> <TAB> example[key] = val",false,if val . dtype == tf . int64 :,if use_bfloat16 and val . dtype == tf . int32 :,0.47,0.0
"def print_callees(self, *amount): <TAB> width, list = self.get_print_list(amount) <TAB> if list: <TAB> <TAB> self.calc_callees() <TAB> <TAB> self.print_call_heading(width, ""called..."") <TAB> <TAB> for func in list: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.print_call_line(width, func, self.all_callees[func]) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.print_call_line(width, func, {}) <TAB> <TAB> print >>self.stream <TAB> <TAB> print >>self.stream <TAB> return self",true,if func in self . all_callees :,if func in self . all_callees :,0.75,0.0
"def on_task_input(self, task, config): <TAB> if config is False: <TAB> <TAB> return <TAB> for entry in task.entries: <TAB> <TAB> if ""&amp;"" in entry[""url""]: <TAB> <TAB> <TAB> log_once( <TAB> <TAB> <TAB> <TAB> ""Corrected `%s` url (replaced &amp; with &)"" % entry[""title""], <TAB> <TAB> <TAB> <TAB> logger=log, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> entry[""url""] = entry[""url""].replace(""&amp;"", ""&"")",true,"if ""&amp;"" in entry [ ""url"" ] :","if ""&amp;"" in entry [ ""url"" ] :",0.75,0.0
"def function(self, inputs, outputs, ignore_empty=False): <TAB> f = function(inputs, outputs, mode=self.mode) <TAB> if self.mode is not None or theano.config.mode != ""FAST_COMPILE"": <TAB> <TAB> topo = f.maker.fgraph.toposort() <TAB> <TAB> topo_ = [node for node in topo if not isinstance(node.op, self.ignore_topo)] <TAB> <TAB> if ignore_empty: <TAB> <TAB> <TAB> assert len(topo_) <= 1, topo_ <TAB> <TAB> else: <TAB> <TAB> <TAB> assert len(topo_) == 1, topo_ <TAB> <TAB> if len(topo_) > 0: <TAB> <TAB> <TAB> assert type(topo_[0].op) is self.op <TAB> return f",true,if len ( topo_ ) > 0 :,if len ( topo_ ) > 0 :,0.75,0.0
"def _get_env_command(self) -> Sequence[str]: <TAB> """"""Get command sequence for `env` with configured flags."""""" <TAB> env_list = [""env""] <TAB> # Pass through configurable environment variables. <TAB> for key in [""http_proxy"", ""https_proxy""]: <TAB> <TAB> value = self.build_provider_flags.get(key) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Ensure item is treated as string and append it. <TAB> <TAB> value = str(value) <TAB> <TAB> env_list.append(f""{key}={value}"") <TAB> return env_list",false,if not value :,if value is None :,0.05,0.0
"def _compare_single_run(self, compares_done): <TAB> try: <TAB> <TAB> compare_id, redo = self.in_queue.get( <TAB> <TAB> <TAB> timeout=float(self.config[""ExpertSettings""][""block_delay""]) <TAB> <TAB> ) <TAB> except Empty: <TAB> <TAB> pass <TAB> else: <TAB> <TAB> if self._decide_whether_to_process(compare_id, redo, compares_done): <TAB> <TAB> <TAB> if redo: <TAB> <TAB> <TAB> <TAB> self.db_interface.delete_old_compare_result(compare_id) <TAB> <TAB> <TAB> compares_done.add(compare_id) <TAB> <TAB> <TAB> self._process_compare(compare_id) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.callback()",true,if self . callback :,if self . callback :,0.75,0.0
"def clean(self): <TAB> # TODO: check for clashes if the random code is already taken <TAB> if not self.code: <TAB> <TAB> self.code = u""static-%s"" % uuid.uuid4() <TAB> if not self.site: <TAB> <TAB> placeholders = StaticPlaceholder.objects.filter( <TAB> <TAB> <TAB> code=self.code, site__isnull=True <TAB> <TAB> ) <TAB> <TAB> if self.pk: <TAB> <TAB> <TAB> placeholders = placeholders.exclude(pk=self.pk) <TAB> <TAB> if placeholders.exists(): <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> _(""A static placeholder with the same site and code already exists"") <TAB> <TAB> <TAB> )",true,if placeholders . exists ( ) :,if placeholders . exists ( ) :,0.75,0.0
"def load_parser(self): <TAB> result = OrderedDict() <TAB> for name, flags in self.filenames: <TAB> <TAB> filename = self.get_filename(name) <TAB> <TAB> for match in sorted(glob(filename), key=self.file_key): <TAB> <TAB> <TAB> # Needed to allow overlapping globs, more specific first <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> result[match] = TextParser(match, os.path.relpath(match, self.base), flags) <TAB> return result",false,if match in result :,if match in self . globs :,0.24,0.0
"def __init__(self, selectable, name=None): <TAB> baseselectable = selectable <TAB> while isinstance(baseselectable, Alias): <TAB> <TAB> baseselectable = baseselectable.element <TAB> self.original = baseselectable <TAB> self.supports_execution = baseselectable.supports_execution <TAB> if self.supports_execution: <TAB> <TAB> self._execution_options = baseselectable._execution_options <TAB> self.element = selectable <TAB> if name is None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> name = getattr(self.original, ""name"", None) <TAB> <TAB> name = _anonymous_label(""%%(%d %s)s"" % (id(self), name or ""anon"")) <TAB> self.name = name",false,if self . original . named_with_column :,if self . original :,0.29,0.0
"def load_tour(self, tour_id): <TAB> for tour_dir in self.tour_directories: <TAB> <TAB> tour_path = os.path.join(tour_dir, tour_id + "".yaml"") <TAB> <TAB> if not os.path.exists(tour_path): <TAB> <TAB> <TAB> tour_path = os.path.join(tour_dir, tour_id + "".yml"") <TAB> <TAB> if os.path.exists(tour_path): <TAB> <TAB> <TAB> return self._load_tour_from_path(tour_path)",true,if os . path . exists ( tour_path ) :,if os . path . exists ( tour_path ) :,0.75,0.0
"def _get_md_bg_color_down(self): <TAB> t = self.theme_cls <TAB> c = self.md_bg_color  # Default to no change on touch <TAB> # Material design specifies using darker hue when on Dark theme <TAB> if t.theme_style == ""Dark"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> c = t.primary_dark <TAB> <TAB> elif self.md_bg_color == t.accent_color: <TAB> <TAB> <TAB> c = t.accent_dark <TAB> return c",true,if self . md_bg_color == t . primary_color :,if self . md_bg_color == t . primary_color :,0.75,0.0
"def get_data(self, state=None, request=None): <TAB> if self.load_in_memory: <TAB> <TAB> data, shapes = self._in_memory_get_data(state, request) <TAB> else: <TAB> <TAB> data, shapes = self._out_of_memory_get_data(state, request) <TAB> for i in range(len(data)): <TAB> <TAB> if shapes[i] is not None: <TAB> <TAB> <TAB> if isinstance(request, numbers.Integral): <TAB> <TAB> <TAB> <TAB> data[i] = data[i].reshape(shapes[i]) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> for j in range(len(data[i])): <TAB> <TAB> <TAB> <TAB> <TAB> data[i][j] = data[i][j].reshape(shapes[i][j]) <TAB> return tuple(data)",true,"if isinstance ( request , numbers . Integral ) :","if isinstance ( request , numbers . Integral ) :",0.75,0.0
"def onClicked(event): <TAB> if not self.path: <TAB> <TAB> if not os.path.exists(mh.getPath(""render"")): <TAB> <TAB> <TAB> os.makedirs(mh.getPath(""render"")) <TAB> <TAB> self.path = mh.getPath(""render"") <TAB> filename, ftype = mh.getSaveFileName( <TAB> <TAB> os.path.splitext(self.path)[0], <TAB> <TAB> ""PNG Image (*.png);;JPEG Image (*.jpg);;Thumbnail (*.thumb);;All files (*.*)"", <TAB> ) <TAB> if filename: <TAB> <TAB> if ""Thumbnail"" in ftype: <TAB> <TAB> <TAB> self.image.save(filename, iformat=""PNG"") <TAB> <TAB> else: <TAB> <TAB> <TAB> self.image.save(filename) <TAB> <TAB> self.path = os.path.dirname(filename)",true,"if not os . path . exists ( mh . getPath ( ""render"" ) ) :","if not os . path . exists ( mh . getPath ( ""render"" ) ) :",0.75,0.0
"def _build_dom(cls, content, mode): <TAB> assert mode in (""html"", ""xml"") <TAB> if mode == ""html"": <TAB> <TAB> if not hasattr(THREAD_STORAGE, ""html_parser""): <TAB> <TAB> <TAB> THREAD_STORAGE.html_parser = HTMLParser() <TAB> <TAB> dom = defusedxml.lxml.parse( <TAB> <TAB> <TAB> StringIO(content), parser=THREAD_STORAGE.html_parser <TAB> <TAB> ) <TAB> <TAB> return dom.getroot() <TAB> else: <TAB> <TAB> if not hasattr(THREAD_STORAGE, ""xml_parser""): <TAB> <TAB> <TAB> THREAD_STORAGE.xml_parser = XMLParser() <TAB> <TAB> dom = defusedxml.lxml.parse(BytesIO(content), parser=THREAD_STORAGE.xml_parser) <TAB> <TAB> return dom.getroot()",true,"if not hasattr ( THREAD_STORAGE , ""html_parser"" ) :","if not hasattr ( THREAD_STORAGE , ""html_parser"" ) :",0.75,0.0
"def convert_path(ctx, tpath): <TAB> for points, code in tpath.iter_segments(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ctx.move_to(*points) <TAB> <TAB> elif code == Path.LINETO: <TAB> <TAB> <TAB> ctx.line_to(*points) <TAB> <TAB> elif code == Path.CURVE3: <TAB> <TAB> <TAB> ctx.curve_to( <TAB> <TAB> <TAB> <TAB> points[0], points[1], points[0], points[1], points[2], points[3] <TAB> <TAB> <TAB> ) <TAB> <TAB> elif code == Path.CURVE4: <TAB> <TAB> <TAB> ctx.curve_to(*points) <TAB> <TAB> elif code == Path.CLOSEPOLY: <TAB> <TAB> <TAB> ctx.close_path()",true,if code == Path . MOVETO :,if code == Path . MOVETO :,0.75,0.0
"def _targets(self, sigmaparser): <TAB> # build list of matching target mappings <TAB> targets = set() <TAB> for condfield in self.conditions: <TAB> <TAB> if condfield in sigmaparser.values: <TAB> <TAB> <TAB> rulefieldvalues = sigmaparser.values[condfield] <TAB> <TAB> <TAB> for condvalue in self.conditions[condfield]: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> targets.update(self.conditions[condfield][condvalue]) <TAB> return targets",true,if condvalue in rulefieldvalues :,if condvalue in rulefieldvalues :,0.75,0.0
"def create_image_upload(): <TAB> if request.method == ""POST"": <TAB> <TAB> image = request.form[""image""] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> image_file = uploaded_file(file_content=image) <TAB> <TAB> <TAB> image_url = upload_local( <TAB> <TAB> <TAB> <TAB> image_file, UPLOAD_PATHS[""temp""][""image""].format(uuid=uuid4()) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return jsonify({""status"": ""ok"", ""image_url"": image_url}) <TAB> <TAB> else: <TAB> <TAB> <TAB> return jsonify({""status"": ""no_image""})",true,if image :,if image :,0.53,0.0
"def lookup_actions(self, resp): <TAB> actions = {} <TAB> for action, conditions in self.actions.items(): <TAB> <TAB> for condition, opts in conditions: <TAB> <TAB> <TAB> for key, val in condition: <TAB> <TAB> <TAB> <TAB> if key[-1] == ""!"": <TAB> <TAB> <TAB> <TAB> <TAB> if resp.match(key[:-1], val): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> if not resp.match(key, val): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> actions[action] = opts <TAB> return actions",true,"if resp . match ( key [ : - 1 ] , val ) :","if resp . match ( key [ : - 1 ] , val ) :",0.75,0.0
"def accept_quality(accept, default=1): <TAB> """"""Separates out the quality score from the accepted content_type"""""" <TAB> quality = default <TAB> if accept and "";"" in accept: <TAB> <TAB> accept, rest = accept.split("";"", 1) <TAB> <TAB> accept_quality = RE_ACCEPT_QUALITY.search(rest) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> quality = float(accept_quality.groupdict().get(""quality"", quality).strip()) <TAB> return (quality, accept.strip())",true,if accept_quality :,if accept_quality :,0.53,0.0
"def save(self, session=None, to=None, pickler=None): <TAB> if to and pickler: <TAB> <TAB> self._save_to = (pickler, to) <TAB> if self._save_to and len(self) > 0: <TAB> <TAB> with self._lock: <TAB> <TAB> <TAB> pickler, fn = self._save_to <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> session.ui.mark(_(""Saving %s state to %s"") % (self, fn)) <TAB> <TAB> <TAB> pickler(self, fn)",true,if session :,if session :,0.53,0.0
"def get_safe_settings(): <TAB> ""Returns a dictionary of the settings module, with sensitive settings blurred out."" <TAB> settings_dict = {} <TAB> for k in dir(settings): <TAB> <TAB> if k.isupper(): <TAB> <TAB> <TAB> if HIDDEN_SETTINGS.search(k): <TAB> <TAB> <TAB> <TAB> settings_dict[k] = ""********************"" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> settings_dict[k] = getattr(settings, k) <TAB> return settings_dict",false,if HIDDEN_SETTINGS . search ( k ) :,if k . isupper ( ) :,0.04,0.0
def _init_table_h(): <TAB> _table_h = [] <TAB> for i in range(256): <TAB> <TAB> part_l = i <TAB> <TAB> part_h = 0 <TAB> <TAB> for j in range(8): <TAB> <TAB> <TAB> rflag = part_l & 1 <TAB> <TAB> <TAB> part_l >>= 1 <TAB> <TAB> <TAB> if part_h & 1: <TAB> <TAB> <TAB> <TAB> part_l |= 1 << 31 <TAB> <TAB> <TAB> part_h >>= 1 <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> part_h ^= 0xD8000000 <TAB> <TAB> _table_h.append(part_h) <TAB> return _table_h,true,if rflag :,if rflag :,0.53,0.0
"def dns_query(server, timeout, protocol, qname, qtype, qclass): <TAB> request = dns.message.make_query(qname, qtype, qclass) <TAB> if protocol == ""tcp"": <TAB> <TAB> response = dns.query.tcp( <TAB> <TAB> <TAB> request, server, timeout=timeout, one_rr_per_rrset=True <TAB> <TAB> ) <TAB> else: <TAB> <TAB> response = dns.query.udp( <TAB> <TAB> <TAB> request, server, timeout=timeout, one_rr_per_rrset=True <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> response = dns.query.tcp( <TAB> <TAB> <TAB> <TAB> request, server, timeout=timeout, one_rr_per_rrset=True <TAB> <TAB> <TAB> ) <TAB> return response",false,if response . flags & dns . flags . TC :,if response is None :,0.02,0.0
"def sum_and_divide(self, losses): <TAB> if self.total_divisor != 0: <TAB> <TAB> output = torch.sum(losses) / self.total_divisor <TAB> <TAB> if torch.is_tensor(self.total_divisor): <TAB> <TAB> <TAB> # remove from autograd graph if necessary <TAB> <TAB> <TAB> self.total_divisor = self.total_divisor.item() <TAB> <TAB> return output <TAB> return torch.sum(losses * 0)",true,if torch . is_tensor ( self . total_divisor ) :,if torch . is_tensor ( self . total_divisor ) :,0.75,0.0
"def __iter__(self): <TAB> for chunk in self.source: <TAB> <TAB> if chunk is not None: <TAB> <TAB> <TAB> self.wait_counter = 0 <TAB> <TAB> <TAB> yield chunk <TAB> <TAB> elif self.wait_counter < self.wait_cntr_max: <TAB> <TAB> <TAB> self.wait_counter += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> logger.warning( <TAB> <TAB> <TAB> <TAB> ""Data poller has been receiving no data for {} seconds.\n"" <TAB> <TAB> <TAB> <TAB> ""Closing data poller"".format(self.wait_cntr_max * self.poll_period) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> break <TAB> <TAB> time.sleep(self.poll_period)",true,elif self . wait_counter < self . wait_cntr_max :,elif self . wait_counter < self . wait_cntr_max :,1.0,0.0
"def test_find_directive_from_block(self): <TAB> blocks = self.config.parser_root.find_blocks(""virtualhost"") <TAB> found = False <TAB> for vh in blocks: <TAB> <TAB> if vh.filepath.endswith(""sites-enabled/certbot.conf""): <TAB> <TAB> <TAB> servername = vh.find_directives(""servername"") <TAB> <TAB> <TAB> self.assertEqual(servername[0].parameters[0], ""certbot.demo"") <TAB> <TAB> <TAB> found = True <TAB> self.assertTrue(found)",true,"if vh . filepath . endswith ( ""sites-enabled/certbot.conf"" ) :","if vh . filepath . endswith ( ""sites-enabled/certbot.conf"" ) :",0.75,0.0
"def assign_products(request, discount_id): <TAB> """"""Assign products to given property group with given property_group_id."""""" <TAB> discount = lfs_get_object_or_404(Discount, pk=discount_id) <TAB> for temp_id in request.POST.keys(): <TAB> <TAB> if temp_id.startswith(""product""): <TAB> <TAB> <TAB> temp_id = temp_id.split(""-"")[1] <TAB> <TAB> <TAB> product = Product.objects.get(pk=temp_id) <TAB> <TAB> <TAB> discount.products.add(product) <TAB> html = [[""#products-inline"", products_inline(request, discount_id, as_string=True)]] <TAB> result = json.dumps( <TAB> <TAB> {""html"": html, ""message"": _(u""Products have been assigned."")}, cls=LazyEncoder <TAB> ) <TAB> return HttpResponse(result, content_type=""application/json"")",true,"if temp_id . startswith ( ""product"" ) :","if temp_id . startswith ( ""product"" ) :",0.75,0.0
"def ChangeStyle(self, combos): <TAB> style = 0 <TAB> for combo in combos: <TAB> <TAB> if combo.GetValue() == 1: <TAB> <TAB> <TAB> if combo.GetLabel() == ""TR_VIRTUAL"": <TAB> <TAB> <TAB> <TAB> style = style | HTL.TR_VIRTUAL <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> style = style | eval(""wx."" + combo.GetLabel()) <TAB> <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> <TAB> style = style | eval(""HTL."" + combo.GetLabel()) <TAB> if self.GetAGWWindowStyleFlag() != style: <TAB> <TAB> self.SetAGWWindowStyleFlag(style)",true,"if combo . GetLabel ( ) == ""TR_VIRTUAL"" :","if combo . GetLabel ( ) == ""TR_VIRTUAL"" :",0.75,0.0
"def _set_autocomplete(self, notebook): <TAB> if notebook: <TAB> <TAB> try: <TAB> <TAB> <TAB> if isinstance(notebook, str): <TAB> <TAB> <TAB> <TAB> notebook = NotebookInfo(notebook) <TAB> <TAB> <TAB> obj, x = build_notebook(notebook) <TAB> <TAB> <TAB> self.form.widgets[""namespace""].notebook = obj <TAB> <TAB> <TAB> self.form.widgets[""page""].notebook = obj <TAB> <TAB> <TAB> logger.debug(""Notebook for autocomplete: %s (%s)"", obj, notebook) <TAB> <TAB> except: <TAB> <TAB> <TAB> logger.exception(""Could not set notebook: %s"", notebook) <TAB> else: <TAB> <TAB> self.form.widgets[""namespace""].notebook = None <TAB> <TAB> self.form.widgets[""page""].notebook = None <TAB> <TAB> logger.debug(""Notebook for autocomplete unset"")",true,"if isinstance ( notebook , str ) :","if isinstance ( notebook , str ) :",0.75,0.0
"def emitSubDomainData(self, subDomainData, event): <TAB> self.emitRawRirData(subDomainData, event) <TAB> for subDomainElem in subDomainData: <TAB> <TAB> if self.checkForStop(): <TAB> <TAB> <TAB> return None <TAB> <TAB> subDomain = subDomainElem.get(""subdomain"", """").strip() <TAB> <TAB> if subDomain: <TAB> <TAB> <TAB> self.emitHostname(subDomain, event)",true,if self . checkForStop ( ) :,if self . checkForStop ( ) :,0.75,0.0
"def get_all_subnets(self, subnet_ids=None, filters=None): <TAB> # Extract a list of all subnets <TAB> matches = itertools.chain(*[x.values() for x in self.subnets.values()]) <TAB> if subnet_ids: <TAB> <TAB> matches = [sn for sn in matches if sn.id in subnet_ids] <TAB> <TAB> if len(subnet_ids) > len(matches): <TAB> <TAB> <TAB> unknown_ids = set(subnet_ids) - set(matches) <TAB> <TAB> <TAB> raise InvalidSubnetIdError(unknown_ids) <TAB> if filters: <TAB> <TAB> matches = generic_filter(filters, matches) <TAB> return matches",true,if len ( subnet_ids ) > len ( matches ) :,if len ( subnet_ids ) > len ( matches ) :,1.0,0.0
"def _compat_map(self, avs): <TAB> apps = {} <TAB> for av in avs: <TAB> <TAB> av.version = self <TAB> <TAB> app_id = av.application <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> apps[amo.APP_IDS[app_id]] = av <TAB> return apps",true,if app_id in amo . APP_IDS :,if app_id in amo . APP_IDS :,0.75,0.0
"def generator(self, data): <TAB> if self._config.SILENT: <TAB> <TAB> silent_vars = self._get_silent_vars() <TAB> for task in data: <TAB> <TAB> for var, val in task.environment_variables(): <TAB> <TAB> <TAB> if self._config.SILENT: <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> 0, <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> int(task.UniqueProcessId), <TAB> <TAB> <TAB> <TAB> <TAB> str(task.ImageFileName), <TAB> <TAB> <TAB> <TAB> <TAB> Address(task.Peb.ProcessParameters.Environment), <TAB> <TAB> <TAB> <TAB> <TAB> str(var), <TAB> <TAB> <TAB> <TAB> <TAB> str(val), <TAB> <TAB> <TAB> <TAB> ], <TAB> <TAB> <TAB> )",true,if var in silent_vars :,if var in silent_vars :,0.75,0.0
"def warn_if_repeatable_read(self): <TAB> if ""mysql"" in self.current_engine().lower(): <TAB> <TAB> cursor = self.connection_for_read().cursor() <TAB> <TAB> if cursor.execute(""SELECT @@tx_isolation""): <TAB> <TAB> <TAB> isolation = cursor.fetchone()[0] <TAB> <TAB> <TAB> if isolation == ""REPEATABLE-READ"": <TAB> <TAB> <TAB> <TAB> warnings.warn( <TAB> <TAB> <TAB> <TAB> <TAB> TxIsolationWarning( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""Polling results with transaction isolation level "" <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""repeatable-read within the same transaction "" <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""may give outdated results. Be sure to commit the "" <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""transaction for each poll iteration."" <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> )",false,"if isolation == ""REPEATABLE-READ"" :","if cursor . execute ( ""SELECT @@tx_isolation"" ) :",0.03,0.0
"def filter_by_level(record, level_per_module): <TAB> name = record[""name""] <TAB> level = 0 <TAB> if name in level_per_module: <TAB> <TAB> level = level_per_module[name] <TAB> elif name is not None: <TAB> <TAB> lookup = """" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> level = level_per_module[""""] <TAB> <TAB> for n in name.split("".""): <TAB> <TAB> <TAB> lookup += n <TAB> <TAB> <TAB> if lookup in level_per_module: <TAB> <TAB> <TAB> <TAB> level = level_per_module[lookup] <TAB> <TAB> <TAB> lookup += ""."" <TAB> if level is False: <TAB> <TAB> return False <TAB> return record[""level""].no >= level",true,"if """" in level_per_module :","if """" in level_per_module :",0.75,0.0
"def _readStream(self, handle: str, path: str) -> None: <TAB> eof = False <TAB> file = Path(path) <TAB> with file.open(""w"") as f: <TAB> <TAB> while not eof: <TAB> <TAB> <TAB> response = await self._client.send(""IO.read"", {""handle"": handle}) <TAB> <TAB> <TAB> eof = response.get(""eof"", False) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> f.write(response.get(""data"", """")) <TAB> await self._client.send(""IO.close"", {""handle"": handle})",false,if path :,if not eof :,0.06,0.0
"def sendall(self, data, flags=0): <TAB> if self._sslobj: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""non-zero flags not allowed in calls to sendall() on %s"" <TAB> <TAB> <TAB> <TAB> % self.__class__ <TAB> <TAB> <TAB> ) <TAB> <TAB> amount = len(data) <TAB> <TAB> count = 0 <TAB> <TAB> while count < amount: <TAB> <TAB> <TAB> v = self.send(data[count:]) <TAB> <TAB> <TAB> count += v <TAB> <TAB> return amount <TAB> else: <TAB> <TAB> return socket.sendall(self, data, flags)",true,if flags != 0 :,if flags != 0 :,0.75,0.0
"def run(self): <TAB> utils.assert_main_thread() <TAB> # As a convenience, we'll set up the connection <TAB> # if there isn't one. So F5 (etc) can be hit <TAB> # to get started. <TAB> if not channel: <TAB> <TAB> if not chrome_launched(): <TAB> <TAB> <TAB> SwiDebugStartChromeCommand.run(self) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.window.run_command(""swi_debug_start"") <TAB> elif paused: <TAB> <TAB> logger.info(""Resuming..."") <TAB> <TAB> channel.send(webkit.Debugger.resume()) <TAB> else: <TAB> <TAB> logger.info(""Pausing..."") <TAB> <TAB> channel.send(webkit.Debugger.setSkipAllPauses(False)) <TAB> <TAB> channel.send(webkit.Debugger.pause())",true,if not chrome_launched ( ) :,if not chrome_launched ( ) :,0.75,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB> if tt == 10: <TAB> <TAB> <TAB> length = d.getVarInt32() <TAB> <TAB> <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB> <TAB> <TAB> d.skip(length) <TAB> <TAB> <TAB> self.add_presence_response().TryMerge(tmp) <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 0 :,if tt == 0 :,0.75,0.0
"def _replace_home(x): <TAB> if xp.ON_WINDOWS: <TAB> <TAB> home = ( <TAB> <TAB> <TAB> builtins.__xonsh__.env[""HOMEDRIVE""] + builtins.__xonsh__.env[""HOMEPATH""][0] <TAB> <TAB> ) <TAB> <TAB> if x.startswith(home): <TAB> <TAB> <TAB> x = x.replace(home, ""~"", 1) <TAB> <TAB> if builtins.__xonsh__.env.get(""FORCE_POSIX_PATHS""): <TAB> <TAB> <TAB> x = x.replace(os.sep, os.altsep) <TAB> <TAB> return x <TAB> else: <TAB> <TAB> home = builtins.__xonsh__.env[""HOME""] <TAB> <TAB> if x.startswith(home): <TAB> <TAB> <TAB> x = x.replace(home, ""~"", 1) <TAB> <TAB> return x",false,"if builtins . __xonsh__ . env . get ( ""FORCE_POSIX_PATHS"" ) :",if x . startswith ( home ) :,0.02,0.0
"def semanticTags(self, semanticTags): <TAB> if semanticTags is None: <TAB> <TAB> self.__semanticTags = OrderedDict() <TAB> # check <TAB> for key, value in list(semanticTags.items()): <TAB> <TAB> if not isinstance(key, int): <TAB> <TAB> <TAB> raise TypeError(""At least one key is not a valid int position"") <TAB> <TAB> if not isinstance(value, list): <TAB> <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> <TAB> ""At least one value of the provided dict is not a list of string"" <TAB> <TAB> <TAB> ) <TAB> <TAB> for x in value: <TAB> <TAB> <TAB> if not isinstance(x, str): <TAB> <TAB> <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> <TAB> <TAB> ""At least one value of the provided dict is not a list of string"" <TAB> <TAB> <TAB> <TAB> ) <TAB> self.__semanticTags = semanticTags",true,"if not isinstance ( key , int ) :","if not isinstance ( key , int ) :",0.75,0.0
"def _recv(): <TAB> try: <TAB> <TAB> return sock.recv(bufsize) <TAB> except SSLWantReadError: <TAB> <TAB> pass <TAB> except socket.error as exc: <TAB> <TAB> error_code = extract_error_code(exc) <TAB> <TAB> if error_code is None: <TAB> <TAB> <TAB> raise <TAB> <TAB> if error_code != errno.EAGAIN or error_code != errno.EWOULDBLOCK: <TAB> <TAB> <TAB> raise <TAB> r, w, e = select.select((sock,), (), (), sock.gettimeout()) <TAB> if r: <TAB> <TAB> return sock.recv(bufsize)",true,if error_code != errno . EAGAIN or error_code != errno . EWOULDBLOCK :,if error_code != errno . EAGAIN or error_code != errno . EWOULDBLOCK :,1.0,0.0
"def _authenticate(self): <TAB> oauth_token = self.options.get(""oauth_token"") <TAB> if oauth_token and not self.api.oauth_token: <TAB> <TAB> self.logger.info(""Attempting to authenticate using OAuth token"") <TAB> <TAB> self.api.oauth_token = oauth_token <TAB> <TAB> user = self.api.user(schema=_user_schema) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.logger.info(""Successfully logged in as {0}"", user) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.logger.error( <TAB> <TAB> <TAB> <TAB> ""Failed to authenticate, the access token "" ""is not valid"" <TAB> <TAB> <TAB> ) <TAB> else: <TAB> <TAB> return JustinTVPluginBase._authenticate(self)",true,if user :,if user :,0.53,0.0
"def reverse(self, *args): <TAB> assert self._path is not None, ""Cannot reverse url regex "" + self.regex.pattern <TAB> assert len(args) == self._group_count, ""required number of arguments "" ""not found"" <TAB> if not len(args): <TAB> <TAB> return self._path <TAB> converted_args = [] <TAB> for a in args: <TAB> <TAB> if not isinstance(a, (unicode_type, bytes)): <TAB> <TAB> <TAB> a = str(a) <TAB> <TAB> converted_args.append(escape.url_escape(utf8(a), plus=False)) <TAB> return self._path % tuple(converted_args)",true,"if not isinstance ( a , ( unicode_type , bytes ) ) :","if not isinstance ( a , ( unicode_type , bytes ) ) :",0.75,0.0
"def determine_block_hints(self, text): <TAB> hints = """" <TAB> if text: <TAB> <TAB> if text[0] in "" \n\x85\u2028\u2029"": <TAB> <TAB> <TAB> hints += str(self.best_indent) <TAB> <TAB> if text[-1] not in ""\n\x85\u2028\u2029"": <TAB> <TAB> <TAB> hints += ""-"" <TAB> <TAB> elif len(text) == 1 or text[-2] in ""\n\x85\u2028\u2029"": <TAB> <TAB> <TAB> hints += ""+"" <TAB> return hints",false,"if text [ 0 ] in "" \n\x85\u2028\u2029"" :","if text [ - 1 ] not in ""\n\x85\u2028\u2029"" :",0.07,0.0
"def find_package_modules(package, mask): <TAB> import fnmatch <TAB> if hasattr(package, ""__loader__"") and hasattr(package.__loader__, ""_files""): <TAB> <TAB> path = package.__name__.replace(""."", os.path.sep) <TAB> <TAB> mask = os.path.join(path, mask) <TAB> <TAB> for fnm in package.__loader__._files.iterkeys(): <TAB> <TAB> <TAB> if fnmatch.fnmatchcase(fnm, mask): <TAB> <TAB> <TAB> <TAB> yield os.path.splitext(fnm)[0].replace(os.path.sep, ""."") <TAB> else: <TAB> <TAB> path = package.__path__[0] <TAB> <TAB> for fnm in os.listdir(path): <TAB> <TAB> <TAB> if fnmatch.fnmatchcase(fnm, mask): <TAB> <TAB> <TAB> <TAB> yield ""%s.%s"" % (package.__name__, os.path.splitext(fnm)[0])",true,"if fnmatch . fnmatchcase ( fnm , mask ) :","if fnmatch . fnmatchcase ( fnm , mask ) :",0.75,0.0
"def _condition(ct): <TAB> for qobj in args: <TAB> <TAB> if qobj.connector == ""AND"" and not qobj.negated: <TAB> <TAB> <TAB> # normal kwargs are an AND anyway, so just use those for now <TAB> <TAB> <TAB> for child in qobj.children: <TAB> <TAB> <TAB> <TAB> kwargs.update(dict([child])) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise NotImplementedError(""Unsupported Q object"") <TAB> for attr, val in kwargs.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return False <TAB> return True",false,"if getattr ( ct , attr ) != val :",if attr != ct :,0.02,0.0
"def process(self, resources): <TAB> session = local_session(self.manager.session_factory) <TAB> client = session.client(""logs"") <TAB> state = self.data.get(""state"", True) <TAB> key = self.resolve_key(self.data.get(""kms-key"")) <TAB> for r in resources: <TAB> <TAB> try: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> client.associate_kms_key(logGroupName=r[""logGroupName""], kmsKeyId=key) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> client.disassociate_kms_key(logGroupName=r[""logGroupName""]) <TAB> <TAB> except client.exceptions.ResourceNotFoundException: <TAB> <TAB> <TAB> continue",true,if state :,if state :,0.53,0.0
"def get_xmm(env, ii): <TAB> if is_gather(ii): <TAB> <TAB> if ii.space == ""evex"": <TAB> <TAB> <TAB> return gen_reg_simd_unified(env, ""xmm_evex"", True) <TAB> <TAB> return gen_reg_simd_unified(env, ""xmm"", False) <TAB> if ii.space == ""evex"": <TAB> <TAB> return gen_reg(env, ""xmm_evex"") <TAB> return gen_reg(env, ""xmm"")",true,"if ii . space == ""evex"" :","if ii . space == ""evex"" :",0.75,0.0
"def parent(self): <TAB> """"""Return the parent device."""""" <TAB> if self._has_parent is None: <TAB> <TAB> _parent = self._ctx.backend.get_parent(self._ctx.dev) <TAB> <TAB> self._has_parent = _parent is not None <TAB> <TAB> if self._has_parent: <TAB> <TAB> <TAB> self._parent = Device(_parent, self._ctx.backend) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._parent = None <TAB> return self._parent",true,if self . _has_parent :,if self . _has_parent :,0.75,0.0
"def cascade(self, event=None): <TAB> """"""Cascade all Leo windows."""""" <TAB> x, y, delta = 50, 50, 50 <TAB> for frame in g.app.windowList: <TAB> <TAB> w = frame and frame.top <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> r = w.geometry()  # a Qt.Rect <TAB> <TAB> <TAB> # 2011/10/26: Fix bug 823601: cascade-windows fails. <TAB> <TAB> <TAB> w.setGeometry(QtCore.QRect(x, y, r.width(), r.height())) <TAB> <TAB> <TAB> # Compute the new offsets. <TAB> <TAB> <TAB> x += 30 <TAB> <TAB> <TAB> y += 30 <TAB> <TAB> <TAB> if x > 200: <TAB> <TAB> <TAB> <TAB> x = 10 + delta <TAB> <TAB> <TAB> <TAB> y = 40 + delta <TAB> <TAB> <TAB> <TAB> delta += 10",true,if w :,if w :,0.53,0.0
"def _GetGoodDispatchAndUserName(IDispatch, userName, clsctx): <TAB> # Get a dispatch object, and a 'user name' (ie, the name as <TAB> # displayed to the user in repr() etc. <TAB> if userName is None: <TAB> <TAB> if isinstance(IDispatch, str): <TAB> <TAB> <TAB> userName = IDispatch <TAB> <TAB> elif isinstance(IDispatch, unicode): <TAB> <TAB> <TAB> # We always want the displayed name to be a real string <TAB> <TAB> <TAB> userName = IDispatch.encode(""ascii"", ""replace"") <TAB> elif type(userName) == unicode: <TAB> <TAB> # As above - always a string... <TAB> <TAB> userName = userName.encode(""ascii"", ""replace"") <TAB> else: <TAB> <TAB> userName = str(userName) <TAB> return (_GetGoodDispatch(IDispatch, clsctx), userName)",false,"elif isinstance ( IDispatch , unicode ) :",elif type ( userName ) == unicode :,0.12,0.0
"def _infer_return_type(*args): <TAB> """"""Look at the type of all args and divine their implied return type."""""" <TAB> return_type = None <TAB> for arg in args: <TAB> <TAB> if arg is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance(arg, bytes): <TAB> <TAB> <TAB> if return_type is str: <TAB> <TAB> <TAB> <TAB> raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."") <TAB> <TAB> <TAB> return_type = bytes <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."") <TAB> <TAB> <TAB> return_type = str <TAB> if return_type is None: <TAB> <TAB> return str  # tempfile APIs return a str by default. <TAB> return return_type",false,if return_type is bytes :,if return_type is str :,0.39,0.0
"def test_ESPnetDataset_h5file_1(h5file_1): <TAB> dataset = IterableESPnetDataset( <TAB> <TAB> path_name_type_list=[(h5file_1, ""data4"", ""hdf5"")], <TAB> <TAB> preprocess=preprocess, <TAB> ) <TAB> for key, data in dataset: <TAB> <TAB> if key == ""a"": <TAB> <TAB> <TAB> assert data[""data4""].shape == ( <TAB> <TAB> <TAB> <TAB> 100, <TAB> <TAB> <TAB> <TAB> 80, <TAB> <TAB> <TAB> ) <TAB> <TAB> if key == ""b"": <TAB> <TAB> <TAB> assert data[""data4""].shape == ( <TAB> <TAB> <TAB> <TAB> 150, <TAB> <TAB> <TAB> <TAB> 80, <TAB> <TAB> <TAB> )",true,"if key == ""b"" :","if key == ""b"" :",0.75,0.0
"def iter_fields(node, *, include_meta=True, exclude_unset=False): <TAB> exclude_meta = not include_meta <TAB> for field_name, field in node._fields.items(): <TAB> <TAB> if exclude_meta and field.meta: <TAB> <TAB> <TAB> continue <TAB> <TAB> field_val = getattr(node, field_name, _marker) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if exclude_unset: <TAB> <TAB> <TAB> if callable(field.default): <TAB> <TAB> <TAB> <TAB> default = field.default() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> default = field.default <TAB> <TAB> <TAB> if field_val == default: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield field_name, field_val",false,if field_val is _marker :,if field_val is None :,0.39,0.0
"def then(self, matches, when_response, context): <TAB> if is_iterable(when_response): <TAB> <TAB> ret = [] <TAB> <TAB> when_response = list(when_response) <TAB> <TAB> for match in when_response: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if self.match_name: <TAB> <TAB> <TAB> <TAB> <TAB> match.name = self.match_name <TAB> <TAB> <TAB> <TAB> matches.append(match) <TAB> <TAB> <TAB> <TAB> ret.append(match) <TAB> <TAB> return ret <TAB> if self.match_name: <TAB> <TAB> when_response.name = self.match_name <TAB> if when_response not in matches: <TAB> <TAB> matches.append(when_response) <TAB> <TAB> return when_response",true,if match not in matches :,if match not in matches :,0.75,0.0
"def _set_chat_ids(self, chat_id: SLT[int]) -> None: <TAB> with self.__lock: <TAB> <TAB> if chat_id and self._usernames: <TAB> <TAB> <TAB> raise RuntimeError( <TAB> <TAB> <TAB> <TAB> f""Can't set {self.chat_id_name} in conjunction with (already set) "" <TAB> <TAB> <TAB> <TAB> f""{self.username_name}s."" <TAB> <TAB> <TAB> ) <TAB> <TAB> self._chat_ids = self._parse_chat_id(chat_id)",true,if chat_id and self . _usernames :,if chat_id and self . _usernames :,0.75,0.0
"def discover(self, *objlist): <TAB> ret = [] <TAB> for l in self.splitlines(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if l[0] == ""Filename"": <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> int(l[2]) <TAB> <TAB> <TAB> int(l[3]) <TAB> <TAB> except: <TAB> <TAB> <TAB> continue <TAB> <TAB> # <TAB> <TAB>   ret.append(improve(l[0])) <TAB> <TAB> ret.append(l[0]) <TAB> ret.sort() <TAB> for item in objlist: <TAB> <TAB> ret.append(item) <TAB> return ret",false,if len ( l ) < 5 :,if len ( l ) < 4 :,0.61,0.0
"def get_changed_module(self): <TAB> source = self.resource.read() <TAB> change_collector = codeanalyze.ChangeCollector(source) <TAB> if self.replacement is not None: <TAB> <TAB> change_collector.add_change(self.skip_start, self.skip_end, self.replacement) <TAB> for occurrence in self.occurrence_finder.find_occurrences(self.resource): <TAB> <TAB> start, end = occurrence.get_primary_range() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.handle.occurred_inside_skip(change_collector, occurrence) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.handle.occurred_outside_skip(change_collector, occurrence) <TAB> result = change_collector.get_changed() <TAB> if result is not None and result != source: <TAB> <TAB> return result",false,if self . skip_start <= start < self . skip_end :,if start < self . skip_start and end < self . skip_end :,0.33,0.0
"def hpat_pandas_series_var_impl( <TAB> self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None ): <TAB> if skipna is None: <TAB> <TAB> skipna = True <TAB> if skipna: <TAB> <TAB> valuable_length = len(self._data) - numpy.sum(numpy.isnan(self._data)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return numpy.nan <TAB> <TAB> return ( <TAB> <TAB> <TAB> numpy_like.nanvar(self._data) * valuable_length / (valuable_length - ddof) <TAB> <TAB> ) <TAB> if len(self._data) <= ddof: <TAB> <TAB> return numpy.nan <TAB> return self._data.var() * len(self._data) / (len(self._data) - ddof)",true,if valuable_length <= ddof :,if valuable_length <= ddof :,0.75,0.0
"def to_dict(self, validate=True, ignore=(), context=None): <TAB> context = context or {} <TAB> condition = getattr(self, ""condition"", Undefined) <TAB> copy = self  # don't copy unless we need to <TAB> if condition is not Undefined: <TAB> <TAB> if isinstance(condition, core.SchemaBase): <TAB> <TAB> <TAB> pass <TAB> <TAB> elif ""field"" in condition and ""type"" not in condition: <TAB> <TAB> <TAB> kwds = parse_shorthand(condition[""field""], context.get(""data"", None)) <TAB> <TAB> <TAB> copy = self.copy(deep=[""condition""]) <TAB> <TAB> <TAB> copy.condition.update(kwds) <TAB> return super(ValueChannelMixin, copy).to_dict( <TAB> <TAB> validate=validate, ignore=ignore, context=context <TAB> )",false,"if isinstance ( condition , core . SchemaBase ) :","elif ""field"" in condition and ""type"" not in condition :",0.01,0.0
"def get_field_result(self, result, field_name): <TAB> if isinstance(result.field, models.ImageField): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> img = getattr(result.obj, field_name) <TAB> <TAB> <TAB> result.text = mark_safe( <TAB> <TAB> <TAB> <TAB> '<a href=""%s"" target=""_blank"" title=""%s"" data-gallery=""gallery""><img src=""%s"" class=""field_img""/></a>' <TAB> <TAB> <TAB> <TAB> % (img.url, result.label, img.url) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self.include_image = True <TAB> return result",false,if result . value :,if field_name :,0.04,0.0
"def run(self): <TAB> try: <TAB> <TAB> while True: <TAB> <TAB> <TAB> dp = self.queue_get_stoppable(self.inq) <TAB> <TAB> <TAB> if self.stopped(): <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> # cannot ignore None here. will lead to unsynced send/recv <TAB> <TAB> <TAB> obj = self.func(dp) <TAB> <TAB> <TAB> self.queue_put_stoppable(self.outq, obj) <TAB> except Exception: <TAB> <TAB> if self.stopped(): <TAB> <TAB> <TAB> pass  # skip duplicated error messages <TAB> <TAB> else: <TAB> <TAB> <TAB> raise <TAB> finally: <TAB> <TAB> self.stop()",true,if self . stopped ( ) :,if self . stopped ( ) :,0.75,0.0
"def _evaluate_local_single(self, iterator): <TAB> for batch in iterator: <TAB> <TAB> in_arrays = convert._call_converter(self.converter, batch, self.device) <TAB> <TAB> with function.no_backprop_mode(): <TAB> <TAB> <TAB> if isinstance(in_arrays, tuple): <TAB> <TAB> <TAB> <TAB> results = self.calc_local(*in_arrays) <TAB> <TAB> <TAB> elif isinstance(in_arrays, dict): <TAB> <TAB> <TAB> <TAB> results = self.calc_local(**in_arrays) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> results = self.calc_local(in_arrays) <TAB> <TAB> if self._progress_hook: <TAB> <TAB> <TAB> self._progress_hook(batch) <TAB> <TAB> yield results",false,if self . _progress_hook :,"if isinstance ( in_arrays , tuple ) :",0.03,0.0
"def merge(self, other): <TAB> d = self._name2ft <TAB> for name, (f, t) in other._name2ft.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # Don't print here by default, since doing <TAB> <TAB> <TAB> # <TAB> so breaks some of the buildbots <TAB> <TAB> <TAB> # print ""*** DocTestRunner.merge: '"" + name + ""' in both"" \ <TAB> <TAB> <TAB> # <TAB>"" testers; summing outcomes."" <TAB> <TAB> <TAB> f2, t2 = d[name] <TAB> <TAB> <TAB> f = f + f2 <TAB> <TAB> <TAB> t = t + t2 <TAB> <TAB> d[name] = f, t",true,if name in d :,if name in d :,0.75,0.0
"def _addSettingsToPanels(self, category, left, right): <TAB> count = len(profile.getSubCategoriesFor(category)) + len( <TAB> <TAB> profile.getSettingsForCategory(category) <TAB> ) <TAB> p = left <TAB> n = 0 <TAB> for title in profile.getSubCategoriesFor(category): <TAB> <TAB> n += 1 + len(profile.getSettingsForCategory(category, title)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> p = right <TAB> <TAB> configBase.TitleRow(p, _(title)) <TAB> <TAB> for s in profile.getSettingsForCategory(category, title): <TAB> <TAB> <TAB> configBase.SettingRow(p, s.getName())",false,if n > count / 2 :,if n > count :,0.23,0.0
"def __init__(self, parent, dir, mask, with_dirs=True): <TAB> filelist = [] <TAB> dirlist = [""..""] <TAB> self.dir = dir <TAB> self.file = """" <TAB> mask = mask.upper() <TAB> pattern = self.MakeRegex(mask) <TAB> for i in os.listdir(dir): <TAB> <TAB> if i == ""."" or i == "".."": <TAB> <TAB> <TAB> continue <TAB> <TAB> path = os.path.join(dir, i) <TAB> <TAB> if os.path.isdir(path): <TAB> <TAB> <TAB> dirlist.append(i) <TAB> <TAB> <TAB> continue <TAB> <TAB> path = path.upper() <TAB> <TAB> value = i.upper() <TAB> <TAB> if pattern.match(value) is not None: <TAB> <TAB> <TAB> filelist.append(i) <TAB> self.files = filelist <TAB> if with_dirs: <TAB> <TAB> self.dirs = dirlist",false,"if i == ""."" or i == "".."" :",if os . path . isdir ( path ) :,0.26,0.0
def check_network_private(test_network): <TAB> test_net = ipaddress.IPNetwork(test_network) <TAB> test_start = test_net.network <TAB> test_end = test_net.broadcast <TAB> for network in settings.vpn.safe_priv_subnets: <TAB> <TAB> network = ipaddress.IPNetwork(network) <TAB> <TAB> net_start = network.network <TAB> <TAB> net_end = network.broadcast <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return True <TAB> return False,false,if test_start >= net_start and test_end <= net_end :,if net_start <= test_end and net_start <= test_end :,0.27,0.0
"def _end_description(self): <TAB> if self._summaryKey == ""content"": <TAB> <TAB> self._end_content() <TAB> else: <TAB> <TAB> value = self.popContent(""description"") <TAB> <TAB> context = self._getContext() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> context[""textinput""][""description""] = value <TAB> <TAB> elif self.inimage: <TAB> <TAB> <TAB> context[""image""][""description""] = value <TAB> self._summaryKey = None",false,if self . intextinput :,if self . textinput :,0.39,0.0
def compute_nullable_nonterminals(self): <TAB> nullable = {} <TAB> num_nullable = 0 <TAB> while 1: <TAB> <TAB> for p in self.grammar.Productions[1:]: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> nullable[p.name] = 1 <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> for t in p.prod: <TAB> <TAB> <TAB> <TAB> if not t in nullable: <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> nullable[p.name] = 1 <TAB> <TAB> if len(nullable) == num_nullable: <TAB> <TAB> <TAB> break <TAB> <TAB> num_nullable = len(nullable) <TAB> return nullable,false,if p . len == 0 :,if p . name not in nullable :,0.08,0.0
"def process_bind_param(self, value, dialect): <TAB> if value is not None: <TAB> <TAB> if MAX_METADATA_VALUE_SIZE is not None: <TAB> <TAB> <TAB> for k, v in list(value.items()): <TAB> <TAB> <TAB> <TAB> sz = total_size(v) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> del value[k] <TAB> <TAB> <TAB> <TAB> <TAB> log.warning( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""Refusing to bind metadata key {} due to size ({})"".format( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> k, sz <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> value = json_encoder.encode(value).encode() <TAB> return value",true,if sz > MAX_METADATA_VALUE_SIZE :,if sz > MAX_METADATA_VALUE_SIZE :,0.75,0.0
"def process_input_line(self, line, store_history=True): <TAB> """"""process the input, capturing stdout"""""" <TAB> stdout = sys.stdout <TAB> splitter = self.IP.input_splitter <TAB> try: <TAB> <TAB> sys.stdout = self.cout <TAB> <TAB> splitter.push(line) <TAB> <TAB> more = splitter.push_accepts_more() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> source_raw = splitter.source_raw_reset()[1] <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> # recent ipython #4504 <TAB> <TAB> <TAB> <TAB> source_raw = splitter.raw_reset() <TAB> <TAB> <TAB> self.IP.run_cell(source_raw, store_history=store_history) <TAB> finally: <TAB> <TAB> sys.stdout = stdout",false,if not more :,if more :,0.1,0.0
"def _dump_section(self, name, values, f): <TAB> doc = ""__doc__"" <TAB><IF-STMT> <TAB> <TAB> print(""# %s"" % values[doc], file=f) <TAB> print(""%s("" % name, file=f) <TAB> for k, v in values.items(): <TAB> <TAB> if k.endswith(""__doc__""): <TAB> <TAB> <TAB> continue <TAB> <TAB> doc = k + ""__doc__"" <TAB> <TAB> if doc in values: <TAB> <TAB> <TAB> print("" <TAB># %s"" % values[doc], file=f) <TAB> <TAB> print("" <TAB>%s = %s,"" % (k, pprint.pformat(v, indent=8)), file=f) <TAB> print("")\n"", file=f)",true,if doc in values :,if doc in values :,0.75,0.0
"def open_session(self, app, request): <TAB> sid = request.cookies.get(app.session_cookie_name) <TAB> if sid: <TAB> <TAB> stored_session = self.cls.objects(sid=sid).first() <TAB> <TAB> if stored_session: <TAB> <TAB> <TAB> expiration = stored_session.expiration <TAB> <TAB> <TAB> if not expiration.tzinfo: <TAB> <TAB> <TAB> <TAB> expiration = expiration.replace(tzinfo=utc) <TAB> <TAB> <TAB> if expiration > datetime.datetime.utcnow().replace(tzinfo=utc): <TAB> <TAB> <TAB> <TAB> return MongoEngineSession( <TAB> <TAB> <TAB> <TAB> <TAB> initial=stored_session.data, sid=stored_session.sid <TAB> <TAB> <TAB> <TAB> ) <TAB> return MongoEngineSession(sid=str(uuid.uuid4()))",false,if not expiration . tzinfo :,if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) :,0.02,0.0
"def table_entry(mode1, bind_type1, mode2, bind_type2): <TAB> with sock(mode1) as sock1: <TAB> <TAB> bind(sock1, bind_type1) <TAB> <TAB> try: <TAB> <TAB> <TAB> with sock(mode2) as sock2: <TAB> <TAB> <TAB> <TAB> bind(sock2, bind_type2) <TAB> <TAB> except OSError as exc: <TAB> <TAB> <TAB> if exc.winerror == errno.WSAEADDRINUSE: <TAB> <TAB> <TAB> <TAB> return ""INUSE"" <TAB> <TAB> <TAB> elif exc.winerror == errno.WSAEACCES: <TAB> <TAB> <TAB> <TAB> return ""ACCESS"" <TAB> <TAB> <TAB> raise <TAB> <TAB> else: <TAB> <TAB> <TAB> return ""Success""",false,if exc . winerror == errno . WSAEADDRINUSE :,elif exc . winerror == errno . WSAEACCES :,0.35,0.0
"def __init__(self, ruleset): <TAB> # Organize rules by path <TAB> self.ruleset = ruleset <TAB> self.rules = {} <TAB> for filename in self.ruleset.rules: <TAB> <TAB> for rule in self.ruleset.rules[filename]: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> manage_dictionary(self.rules, rule.path, []) <TAB> <TAB> <TAB> self.rules[rule.path].append(rule)",false,if not rule . enabled :,if rule . path not in self . rules :,0.21,0.0
"def talk(self, words): <TAB> if self.writeSentence(words) == 0: <TAB> <TAB> return <TAB> r = [] <TAB> while 1: <TAB> <TAB> i = self.readSentence() <TAB> <TAB> if len(i) == 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> reply = i[0] <TAB> <TAB> attrs = {} <TAB> <TAB> for w in i[1:]: <TAB> <TAB> <TAB> j = w.find(""="", 1) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> attrs[w] = """" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> attrs[w[:j]] = w[j + 1 :] <TAB> <TAB> r.append((reply, attrs)) <TAB> <TAB> if reply == ""!done"": <TAB> <TAB> <TAB> return r",true,if j == - 1 :,if j == - 1 :,0.75,0.0
"def _check_decorator_overload(name: str, old: str, new: str) -> int: <TAB> """"""Conditions for a decorator to overload an existing one."""""" <TAB> properties = _property_decorators(name) <TAB> if old == new: <TAB> <TAB> return _MERGE <TAB> elif old in properties and new in properties: <TAB> <TAB> p_old, p_new = properties[old].precedence, properties[new].precedence <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return _DISCARD <TAB> <TAB> elif p_old == p_new: <TAB> <TAB> <TAB> return _MERGE <TAB> <TAB> else: <TAB> <TAB> <TAB> return _REPLACE <TAB> raise OverloadedDecoratorError(name, """")",false,if p_old > p_new :,if p_old == p_new :,0.33,0.0
"def validate_pk(self): <TAB> try: <TAB> <TAB> self._key = serialization.load_pem_private_key( <TAB> <TAB> <TAB> self.key, password=None, backend=default_backend() <TAB> <TAB> ) <TAB> <TAB> if self._key.key_size > 2048: <TAB> <TAB> <TAB> AWSValidationException( <TAB> <TAB> <TAB> <TAB> ""The private key length is not supported. Only 1024-bit and 2048-bit are allowed."" <TAB> <TAB> <TAB> ) <TAB> except Exception as err: <TAB> <TAB> if isinstance(err, AWSValidationException): <TAB> <TAB> <TAB> raise <TAB> <TAB> raise AWSValidationException( <TAB> <TAB> <TAB> ""The private key is not PEM-encoded or is not valid."" <TAB> <TAB> )",false,"if isinstance ( err , AWSValidationException ) :",if self . _key . key_size > 2048 :,0.02,0.0
"def _add_custom_statement(self, custom_statements): <TAB> if custom_statements is None: <TAB> <TAB> return <TAB> self.resource_policy[""Version""] = ""2012-10-17"" <TAB> if self.resource_policy.get(""Statement"") is None: <TAB> <TAB> self.resource_policy[""Statement""] = custom_statements <TAB> else: <TAB> <TAB> if not isinstance(custom_statements, list): <TAB> <TAB> <TAB> custom_statements = [custom_statements] <TAB> <TAB> statement = self.resource_policy[""Statement""] <TAB> <TAB> if not isinstance(statement, list): <TAB> <TAB> <TAB> statement = [statement] <TAB> <TAB> for s in custom_statements: <TAB> <TAB> <TAB> if s not in statement: <TAB> <TAB> <TAB> <TAB> statement.append(s) <TAB> <TAB> self.resource_policy[""Statement""] = statement",false,"if not isinstance ( custom_statements , list ) :","if not isinstance ( statement , list ) :",0.55,0.0
"def load(self, repn): <TAB> for key in repn: <TAB> <TAB> tmp = self._convert(key) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.declare(tmp) <TAB> <TAB> item = dict.__getitem__(self, tmp) <TAB> <TAB> item._active = True <TAB> <TAB> item.load(repn[key])",false,if tmp not in self :,if tmp is not None :,0.3,0.0
"def on_press_release(x): <TAB> """"""Keyboard callback function."""""" <TAB> global is_recording, enable_trigger_record <TAB> press = keyboard.KeyboardEvent(""down"", 28, ""space"") <TAB> release = keyboard.KeyboardEvent(""up"", 28, ""space"") <TAB> if x.event_type == ""down"" and x.name == press.name: <TAB> <TAB> if (not is_recording) and enable_trigger_record: <TAB> <TAB> <TAB> sys.stdout.write(""Start Recording ... "") <TAB> <TAB> <TAB> sys.stdout.flush() <TAB> <TAB> <TAB> is_recording = True <TAB> if x.event_type == ""up"" and x.name == release.name: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> is_recording = False",false,if is_recording == True :,if ( not is_recording ) and enable_trigger_record :,0.03,0.0
"def apply_mask(self, mask, data_t, data_f): <TAB> ind_t, ind_f = 0, 0 <TAB> out = [] <TAB> for m in cycle(mask): <TAB> <TAB> if m: <TAB> <TAB> <TAB> if ind_t == len(data_t): <TAB> <TAB> <TAB> <TAB> return out <TAB> <TAB> <TAB> out.append(data_t[ind_t]) <TAB> <TAB> <TAB> ind_t += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> if ind_f == len(data_f): <TAB> <TAB> <TAB> <TAB> return out <TAB> <TAB> <TAB> out.append(data_f[ind_f]) <TAB> <TAB> <TAB> ind_f += 1 <TAB> return out",true,if ind_f == len ( data_f ) :,if ind_f == len ( data_f ) :,0.75,0.0
"def oo_contains_rule(source, apiGroups, resources, verbs): <TAB> """"""Return true if the specified rule is contained within the provided source"""""" <TAB> rules = source[""rules""] <TAB> if rules: <TAB> <TAB> for rule in rules: <TAB> <TAB> <TAB> if set(rule[""apiGroups""]) == set(apiGroups): <TAB> <TAB> <TAB> <TAB> if set(rule[""resources""]) == set(resources): <TAB> <TAB> <TAB> <TAB> <TAB> if set(rule[""verbs""]) == set(verbs): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",false,"if set ( rule [ ""verbs"" ] ) == set ( verbs ) :","if set ( rule [ ""apiGroups"" ] ) == set ( apiGroups ) :",0.79,0.0
"def _maybe_commit_artifact(self, artifact_id): <TAB> artifact_status = self._artifacts[artifact_id] <TAB> if artifact_status[""pending_count""] == 0 and artifact_status[""commit_requested""]: <TAB> <TAB> for callback in artifact_status[""pre_commit_callbacks""]: <TAB> <TAB> <TAB> callback() <TAB> <TAB> if artifact_status[""finalize""]: <TAB> <TAB> <TAB> self._api.commit_artifact(artifact_id) <TAB> <TAB> for callback in artifact_status[""post_commit_callbacks""]: <TAB> <TAB> <TAB> callback()",true,"if artifact_status [ ""finalize"" ] :","if artifact_status [ ""finalize"" ] :",0.75,0.0
"def shuffler(iterator, pool_size=10 ** 5, refill_threshold=0.9): <TAB> yields_between_refills = round(pool_size * (1 - refill_threshold)) <TAB> # initialize pool; this step may or may not exhaust the iterator. <TAB> pool = take_n(pool_size, iterator) <TAB> while True: <TAB> <TAB> random.shuffle(pool) <TAB> <TAB> for i in range(yields_between_refills): <TAB> <TAB> <TAB> yield pool.pop() <TAB> <TAB> next_batch = take_n(yields_between_refills, iterator) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> pool.extend(next_batch) <TAB> # finish consuming whatever's left - no need for further randomization. <TAB> yield from pool",false,if not next_batch :,if next_batch is None :,0.05,0.0
"def __getitem__(self, key, _get_mode=False): <TAB> if not _get_mode: <TAB> <TAB> if isinstance(key, (int, long)): <TAB> <TAB> <TAB> return self._list[key] <TAB> <TAB> elif isinstance(key, slice): <TAB> <TAB> <TAB> return self.__class__(self._list[key]) <TAB> ikey = key.lower() <TAB> for k, v in self._list: <TAB> <TAB> if k.lower() == ikey: <TAB> <TAB> <TAB> return v <TAB> # micro optimization: if we are in get mode we will catch that <TAB> # exception one stack level down so we can raise a standard <TAB> # key error instead of our special one. <TAB> if _get_mode: <TAB> <TAB> raise KeyError() <TAB> raise BadRequestKeyError(key)",false,"elif isinstance ( key , slice ) :",if k . lower ( ) == ikey :,0.02,0.0
"def find(self, path): <TAB> if os.path.isfile(path) or os.path.islink(path): <TAB> <TAB> self.num_files = self.num_files + 1 <TAB> <TAB> if self.match_function(path): <TAB> <TAB> <TAB> self.files.append(path) <TAB> elif os.path.isdir(path): <TAB> <TAB> for content in os.listdir(path): <TAB> <TAB> <TAB> file = os.path.join(path, content) <TAB> <TAB> <TAB> if os.path.isfile(file) or os.path.islink(file): <TAB> <TAB> <TAB> <TAB> self.num_files = self.num_files + 1 <TAB> <TAB> <TAB> <TAB> if self.match_function(file): <TAB> <TAB> <TAB> <TAB> <TAB> self.files.append(file) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.find(file)",true,if self . match_function ( file ) :,if self . match_function ( file ) :,0.75,0.0
"def validate_nb(self, nb): <TAB> super(MetadataValidatorV3, self).validate_nb(nb) <TAB> ids = set([]) <TAB> for cell in nb.cells: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> grade = cell.metadata[""nbgrader""][""grade""] <TAB> <TAB> solution = cell.metadata[""nbgrader""][""solution""] <TAB> <TAB> locked = cell.metadata[""nbgrader""][""locked""] <TAB> <TAB> if not grade and not solution and not locked: <TAB> <TAB> <TAB> continue <TAB> <TAB> grade_id = cell.metadata[""nbgrader""][""grade_id""] <TAB> <TAB> if grade_id in ids: <TAB> <TAB> <TAB> raise ValidationError(""Duplicate grade id: {}"".format(grade_id)) <TAB> <TAB> ids.add(grade_id)",true,"if ""nbgrader"" not in cell . metadata :","if ""nbgrader"" not in cell . metadata :",0.75,0.0
"def _skip_start(self): <TAB> start, stop = self.start, self.stop <TAB> for chunk in self.app_iter: <TAB> <TAB> self._pos += len(chunk) <TAB> <TAB> if self._pos < start: <TAB> <TAB> <TAB> continue <TAB> <TAB> elif self._pos == start: <TAB> <TAB> <TAB> return b"""" <TAB> <TAB> else: <TAB> <TAB> <TAB> chunk = chunk[start - self._pos :] <TAB> <TAB> <TAB> if stop is not None and self._pos > stop: <TAB> <TAB> <TAB> <TAB> chunk = chunk[: stop - self._pos] <TAB> <TAB> <TAB> <TAB> assert len(chunk) == stop - start <TAB> <TAB> <TAB> return chunk <TAB> else: <TAB> <TAB> raise StopIteration()",false,if stop is not None and self . _pos > stop :,elif self . _pos == start :,0.08,0.0
"def _SetUser(self, users): <TAB> for user in users.items(): <TAB> <TAB> username = user[0] <TAB> <TAB> settings = user[1] <TAB> <TAB> room = settings[""room""][""name""] if ""room"" in settings else None <TAB> <TAB> file_ = settings[""file""] if ""file"" in settings else None <TAB> <TAB> if ""event"" in settings: <TAB> <TAB> <TAB> if ""joined"" in settings[""event""]: <TAB> <TAB> <TAB> <TAB> self._client.userlist.addUser(username, room, file_) <TAB> <TAB> <TAB> elif ""left"" in settings[""event""]: <TAB> <TAB> <TAB> <TAB> self._client.removeUser(username) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._client.userlist.modUser(username, room, file_)",true,"elif ""left"" in settings [ ""event"" ] :","elif ""left"" in settings [ ""event"" ] :",0.75,0.0
"def run_tests(): <TAB> # type: () -> None <TAB> x = 5 <TAB> with switch(x) as case: <TAB> <TAB> if case(0): <TAB> <TAB> <TAB> print(""zero"") <TAB> <TAB> <TAB> print(""zero"") <TAB> <TAB> elif case(1, 2): <TAB> <TAB> <TAB> print(""one or two"") <TAB> <TAB> elif case(3, 4): <TAB> <TAB> <TAB> print(""three or four"") <TAB> <TAB> else: <TAB> <TAB> <TAB> print(""default"") <TAB> <TAB> <TAB> print(""another"")",false,"elif case ( 1 , 2 ) :","elif case ( 3 , 4 ) :",0.34,0.0
"def _populate(): <TAB> for fname in glob.glob(os.path.join(os.path.dirname(__file__), ""data"", ""*.json"")): <TAB> <TAB> with open(fname) as inf: <TAB> <TAB> <TAB> data = json.load(inf) <TAB> <TAB> <TAB> data = data[list(data.keys())[0]] <TAB> <TAB> <TAB> data = data[list(data.keys())[0]] <TAB> <TAB> <TAB> for item in data: <TAB> <TAB> <TAB> <TAB> if item[""key""] in TABLE: <TAB> <TAB> <TAB> <TAB> <TAB> LOGGER.warning(""Repeated emoji {}"".format(item[""key""])) <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> TABLE[item[""key""]] = item[""value""]",true,"if item [ ""key"" ] in TABLE :","if item [ ""key"" ] in TABLE :",0.75,0.0
"def slot_to_material(bobject: bpy.types.Object, slot: bpy.types.MaterialSlot): <TAB> mat = slot.material <TAB> # Pick up backed material if present <TAB> if mat is not None: <TAB> <TAB> baked_mat = mat.name + ""_"" + bobject.name + ""_baked"" <TAB> <TAB> if baked_mat in bpy.data.materials: <TAB> <TAB> <TAB> mat = bpy.data.materials[baked_mat] <TAB> return mat",true,if baked_mat in bpy . data . materials :,if baked_mat in bpy . data . materials :,0.75,0.0
"def __keyPress(self, widget, event): <TAB> if event.key == ""G"" and event.modifiers & event.Modifiers.Control: <TAB> <TAB> if not all(hasattr(p, ""isGanged"") for p in self.getPlugs()): <TAB> <TAB> <TAB> return False <TAB> <TAB> if all(p.isGanged() for p in self.getPlugs()): <TAB> <TAB> <TAB> self.__ungang() <TAB> <TAB> else: <TAB> <TAB> <TAB> self.__gang() <TAB> <TAB> return True <TAB> return False",true,if all ( p . isGanged ( ) for p in self . getPlugs ( ) ) :,if all ( p . isGanged ( ) for p in self . getPlugs ( ) ) :,1.0,0.0
"def check_expected(result, expected, contains=False): <TAB> if sys.version_info[0] >= 3: <TAB> <TAB> if isinstance(result, str): <TAB> <TAB> <TAB> result = result.encode(""ascii"") <TAB> <TAB> if isinstance(expected, str): <TAB> <TAB> <TAB> expected = expected.encode(""ascii"") <TAB> resultlines = result.splitlines() <TAB> expectedlines = expected.splitlines() <TAB> if len(resultlines) != len(expectedlines): <TAB> <TAB> return False <TAB> for rline, eline in zip(resultlines, expectedlines): <TAB> <TAB> if contains: <TAB> <TAB> <TAB> if eline not in rline: <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> else: <TAB> <TAB> <TAB> if not rline.endswith(eline): <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",false,"if isinstance ( expected , str ) :","if isinstance ( result , str ) :",0.5,0.0
"def hosts_to_domains(self, hosts, exclusions=[]): <TAB> domains = [] <TAB> for host in hosts: <TAB> <TAB> elements = host.split(""."") <TAB> <TAB> # recursively walk through the elements <TAB> <TAB> # extracting all possible (sub)domains <TAB> <TAB> while len(elements) >= 2: <TAB> <TAB> <TAB> # account for domains stored as hosts <TAB> <TAB> <TAB> if len(elements) == 2: <TAB> <TAB> <TAB> <TAB> domain = ""."".join(elements) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> # drop the host element <TAB> <TAB> <TAB> <TAB> domain = ""."".join(elements[1:]) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> domains.append(domain) <TAB> <TAB> <TAB> del elements[0] <TAB> return domains",false,if domain not in domains + exclusions :,if domain not in exclusions :,0.37,0.0
"def hsconn_sender(self): <TAB> while not self.stop_event.is_set(): <TAB> <TAB> try: <TAB> <TAB> <TAB> # Block, but timeout, so that we can exit the loop gracefully <TAB> <TAB> <TAB> request = self.send_queue.get(True, 6.0) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> # Socket got closed and set to None in another thread... <TAB> <TAB> <TAB> <TAB> self.socket.sendall(request) <TAB> <TAB> <TAB> if self.send_queue is not None: <TAB> <TAB> <TAB> <TAB> self.send_queue.task_done() <TAB> <TAB> except queue.Empty: <TAB> <TAB> <TAB> pass <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> self.stop_event.set()",false,if self . socket is not None :,if request is not None :,0.32,0.0
"def get_url_args(self, item): <TAB> if self.url_args: <TAB> <TAB> if hasattr(self.url_args, ""__call__""): <TAB> <TAB> <TAB> url_args = self.url_args(item) <TAB> <TAB> else: <TAB> <TAB> <TAB> url_args = dict(self.url_args) <TAB> <TAB> url_args[""id""] = item.id <TAB> <TAB> return url_args <TAB> else: <TAB> <TAB> return dict(operation=self.label, id=item.id)",true,"if hasattr ( self . url_args , ""__call__"" ) :","if hasattr ( self . url_args , ""__call__"" ) :",0.75,0.0
"def list_projects(self): <TAB> projects = [] <TAB> page = 1 <TAB> while True: <TAB> <TAB> repos = self._client.get( <TAB> <TAB> <TAB> ""/user/repos"", {""sort"": ""full_name"", ""page"": page, ""per_page"": 100} <TAB> <TAB> ) <TAB> <TAB> page += 1 <TAB> <TAB> for repo in repos: <TAB> <TAB> <TAB> projects.append( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> ""id"": repo[""full_name""], <TAB> <TAB> <TAB> <TAB> <TAB> ""name"": repo[""full_name""], <TAB> <TAB> <TAB> <TAB> <TAB> ""description"": repo[""description""], <TAB> <TAB> <TAB> <TAB> <TAB> ""is_private"": repo[""private""], <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> return projects",false,if len ( repos ) < 100 :,if not repos :,0.02,0.0
"def scripts(self): <TAB> application_root = current_app.config.get(""APPLICATION_ROOT"") <TAB> subdir = application_root != ""/"" <TAB> scripts = [] <TAB> for script in get_registered_scripts(): <TAB> <TAB> if script.startswith(""http""): <TAB> <TAB> <TAB> scripts.append(f'<script defer src=""{script}""></script>') <TAB> <TAB> elif subdir: <TAB> <TAB> <TAB> scripts.append(f'<script defer src=""{application_root}/{script}""></script>') <TAB> <TAB> else: <TAB> <TAB> <TAB> scripts.append(f'<script defer src=""{script}""></script>') <TAB> return markup(""\n"".join(scripts))",true,elif subdir :,elif subdir :,0.51,0.0
"def print_map(node, l): <TAB> if node.title not in l: <TAB> <TAB> l[node.title] = [] <TAB> for n in node.children: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> w = {n.title: []} <TAB> <TAB> <TAB> l[node.title].append(w) <TAB> <TAB> <TAB> print_map(n, w) <TAB> <TAB> else: <TAB> <TAB> <TAB> l[node.title].append(n.title)",false,if len ( n . children ) > 0 :,if n . title not in l :,0.03,0.0
"def _validate_distinct_on_different_types_and_field_orders( <TAB> self, collection, query, expected_results, get_mock_result ): <TAB> self.count = 0 <TAB> self.get_mock_result = get_mock_result <TAB> query_iterable = collection.query_items(query, enable_cross_partition_query=True) <TAB> results = list(query_iterable) <TAB> for i in range(len(expected_results)): <TAB> <TAB> if isinstance(results[i], dict): <TAB> <TAB> <TAB> self.assertDictEqual(results[i], expected_results[i]) <TAB> <TAB> elif isinstance(results[i], list): <TAB> <TAB> <TAB> self.assertListEqual(results[i], expected_results[i]) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.assertEqual(results[i], expected_results[i]) <TAB> self.count = 0",true,"elif isinstance ( results [ i ] , list ) :","elif isinstance ( results [ i ] , list ) :",0.75,0.0
"def run(self): <TAB> for k, v in iteritems(self.objs): <TAB> <TAB> if k.startswith(""_""): <TAB> <TAB> <TAB> continue <TAB> <TAB> if ( <TAB> <TAB> <TAB> v[""_class""] == ""Question"" <TAB> <TAB> <TAB> or v[""_class""] == ""Message"" <TAB> <TAB> <TAB> or v[""_class""] == ""Announcement"" <TAB> <TAB> ): <TAB> <TAB> <TAB> v[""admin""] = None <TAB> return self.objs",true,"if k . startswith ( ""_"" ) :","if k . startswith ( ""_"" ) :",0.75,0.0
"def qvec(self): <TAB> # <TAB> <TAB>if self.polrep != 'stokes': <TAB> # <TAB> <TAB> <TAB>raise Exception(""qvec is not defined unless self.polrep=='stokes'"") <TAB> qvec = np.array([]) <TAB> if self.polrep == ""stokes"": <TAB> <TAB> qvec = self._imdict[""Q""] <TAB> elif self.polrep == ""circ"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> qvec = np.real(0.5 * (self.lrvec + self.rlvec)) <TAB> return qvec",false,if len ( self . rlvec ) != 0 and len ( self . lrvec ) != 0 :,if len ( self . lrvec + self . rlvec ) > 0 :,0.49,0.0
"def display_value(self, key, w): <TAB> if key == ""vdevices"": <TAB> <TAB> # Very special case <TAB> <TAB> nids = [n[""deviceID""] for n in self.get_value(""devices"")] <TAB> <TAB> for device in self.app.devices.values(): <TAB> <TAB> <TAB> if device[""id""] != self.app.daemon.get_my_id(): <TAB> <TAB> <TAB> <TAB> b = Gtk.CheckButton(device.get_title(), False) <TAB> <TAB> <TAB> <TAB> b.set_tooltip_text(device[""id""]) <TAB> <TAB> <TAB> <TAB> self[""vdevices""].pack_start(b, False, False, 0) <TAB> <TAB> <TAB> <TAB> b.set_active(device[""id""] in nids) <TAB> <TAB> self[""vdevices""].show_all() <TAB> else: <TAB> <TAB> EditorDialog.display_value(self, key, w)",true,"if device [ ""id"" ] != self . app . daemon . get_my_id ( ) :","if device [ ""id"" ] != self . app . daemon . get_my_id ( ) :",0.75,0.0
"def _set_xflux_setting(self, **kwargs): <TAB> for key, value in kwargs.items(): <TAB> <TAB> if key in self._settings_map: <TAB> <TAB> <TAB> if key == ""color"": <TAB> <TAB> <TAB> <TAB> self._set_xflux_screen_color(value) <TAB> <TAB> <TAB> <TAB> self._current_color = str(value) <TAB> <TAB> <TAB> <TAB> # hackish - changing the current color unpauses xflux, <TAB> <TAB> <TAB> <TAB> # must reflect that with state change <TAB> <TAB> <TAB> <TAB> if self.state == self.states[""PAUSED""]: <TAB> <TAB> <TAB> <TAB> <TAB> self.state = self.states[""RUNNING""] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self._xflux.sendline(self._settings_map[key] + str(value)) <TAB> <TAB> <TAB> self._c()",true,"if key == ""color"" :","if key == ""color"" :",0.75,0.0
"def apply_acceleration(self, veh_ids, acc): <TAB> """"""See parent class."""""" <TAB> # to hand the case of a single vehicle <TAB> if type(veh_ids) == str: <TAB> <TAB> veh_ids = [veh_ids] <TAB> <TAB> acc = [acc] <TAB> for i, vid in enumerate(veh_ids): <TAB> <TAB> if acc[i] is not None and vid in self.get_ids(): <TAB> <TAB> <TAB> this_vel = self.get_speed(vid) <TAB> <TAB> <TAB> next_vel = max([this_vel + acc[i] * self.sim_step, 0]) <TAB> <TAB> <TAB> self.kernel_api.vehicle.slowDown(vid, next_vel, 1e-3)",true,if acc [ i ] is not None and vid in self . get_ids ( ) :,if acc [ i ] is not None and vid in self . get_ids ( ) :,0.75,0.0
"def largest_factor_relatively_prime(a, b): <TAB> """"""Return the largest factor of a relatively prime to b."""""" <TAB> while 1: <TAB> <TAB> d = gcd(a, b) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> b = d <TAB> <TAB> while 1: <TAB> <TAB> <TAB> q, r = divmod(a, d) <TAB> <TAB> <TAB> if r > 0: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> a = q <TAB> return a",false,if d <= 1 :,if d > 0 :,0.31,0.0
"def check_status(self): <TAB> try: <TAB> <TAB> du = psutil.disk_usage(""/"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ServiceWarning( <TAB> <TAB> <TAB> <TAB> ""{host} {percent}% disk usage exceeds {disk_usage}%"".format( <TAB> <TAB> <TAB> <TAB> <TAB> host=host, percent=du.percent, disk_usage=DISK_USAGE_MAX <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> except ValueError as e: <TAB> <TAB> self.add_error(ServiceReturnedUnexpectedResult(""ValueError""), e)",false,if DISK_USAGE_MAX and du . percent >= DISK_USAGE_MAX :,if du . disk_usage > DISK_USAGE_MAX :,0.15,0.0
"def build_reply(self, msg, text=None, private=False, threaded=False): <TAB> response = self.build_message(text) <TAB> if msg.is_group: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> response.frm = self.bot_identifier <TAB> <TAB> <TAB> response.to = IRCPerson(str(msg.frm)) <TAB> <TAB> else: <TAB> <TAB> <TAB> response.frm = IRCRoomOccupant(str(self.bot_identifier), msg.frm.room) <TAB> <TAB> <TAB> response.to = msg.frm.room <TAB> else: <TAB> <TAB> response.frm = self.bot_identifier <TAB> <TAB> response.to = msg.frm <TAB> return response",true,if private :,if private :,0.53,0.0
"def _dict_refs(obj, named): <TAB> """"""Return key and value objects of a dict/proxy."""""" <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for k, v in _items(obj): <TAB> <TAB> <TAB> <TAB> s = str(k) <TAB> <TAB> <TAB> <TAB> yield _NamedRef(""[K] "" + s, k) <TAB> <TAB> <TAB> <TAB> yield _NamedRef(""[V] "" + s + "": "" + _repr(v), v) <TAB> <TAB> else: <TAB> <TAB> <TAB> for k, v in _items(obj): <TAB> <TAB> <TAB> <TAB> yield k <TAB> <TAB> <TAB> <TAB> yield v <TAB> except (KeyError, ReferenceError, TypeError) as x: <TAB> <TAB> warnings.warn(""Iterating '%s': %r"" % (_classof(obj), x))",true,if named :,if named :,0.53,0.0
"def fetch_images(): <TAB> images = [] <TAB> marker = None <TAB> while True: <TAB> <TAB> batch = image_service.detail( <TAB> <TAB> <TAB> context, <TAB> <TAB> <TAB> filters=filters, <TAB> <TAB> <TAB> marker=marker, <TAB> <TAB> <TAB> sort_key=""created_at"", <TAB> <TAB> <TAB> sort_dir=""desc"", <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> images += batch <TAB> <TAB> marker = batch[-1][""id""] <TAB> return images",true,if not batch :,if not batch :,0.75,0.0
"def compress(self, data_list): <TAB> warn_untested() <TAB> if data_list: <TAB> <TAB> if data_list[1] in forms.fields.EMPTY_VALUES: <TAB> <TAB> <TAB> error = self.error_messages[""invalid_year""] <TAB> <TAB> <TAB> raise forms.ValidationError(error) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> error = self.error_messages[""invalid_month""] <TAB> <TAB> <TAB> raise forms.ValidationError(error) <TAB> <TAB> year = int(data_list[1]) <TAB> <TAB> month = int(data_list[0]) <TAB> <TAB> # find last day of the month <TAB> <TAB> day = monthrange(year, month)[1] <TAB> <TAB> return date(year, month, day) <TAB> return None",true,if data_list [ 0 ] in forms . fields . EMPTY_VALUES :,if data_list [ 0 ] in forms . fields . EMPTY_VALUES :,0.75,0.0
"def _diff_dict(self, old, new): <TAB> diff = {} <TAB> removed = [] <TAB> added = [] <TAB> for key, value in old.items(): <TAB> <TAB> if key not in new: <TAB> <TAB> <TAB> removed.append(key) <TAB> <TAB> elif old[key] != new[key]: <TAB> <TAB> <TAB> # modified is indicated by a remove and add <TAB> <TAB> <TAB> removed.append(key) <TAB> <TAB> <TAB> added.append(key) <TAB> for key, value in new.items(): <TAB> <TAB> if key not in old: <TAB> <TAB> <TAB> added.append(key) <TAB> if removed: <TAB> <TAB> diff[""removed""] = sorted(removed) <TAB> if added: <TAB> <TAB> diff[""added""] = sorted(added) <TAB> return diff",true,elif old [ key ] != new [ key ] :,elif old [ key ] != new [ key ] :,0.75,0.0
"def add_filters(self, function): <TAB> try: <TAB> <TAB> subscription = self.exists(function) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> response = self._sns.call( <TAB> <TAB> <TAB> <TAB> ""set_subscription_attributes"", <TAB> <TAB> <TAB> <TAB> SubscriptionArn=subscription[""SubscriptionArn""], <TAB> <TAB> <TAB> <TAB> AttributeName=""FilterPolicy"", <TAB> <TAB> <TAB> <TAB> AttributeValue=json.dumps(self.filters), <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> kappa.event_source.sns.LOG.debug(response) <TAB> except Exception: <TAB> <TAB> kappa.event_source.sns.LOG.exception( <TAB> <TAB> <TAB> ""Unable to add filters for SNS topic %s"", self.arn <TAB> <TAB> )",true,if subscription :,if subscription :,0.53,0.0
"def init_weights(self, pretrained=None): <TAB> if isinstance(pretrained, str): <TAB> <TAB> logger = logging.getLogger() <TAB> <TAB> load_checkpoint(self, pretrained, strict=False, logger=logger) <TAB> elif pretrained is None: <TAB> <TAB> for m in self.modules(): <TAB> <TAB> <TAB> if isinstance(m, nn.Conv2d): <TAB> <TAB> <TAB> <TAB> kaiming_init(m) <TAB> <TAB> <TAB> elif isinstance(m, (_BatchNorm, nn.GroupNorm)): <TAB> <TAB> <TAB> <TAB> constant_init(m, 1) <TAB> else: <TAB> <TAB> raise TypeError(""pretrained must be a str or None"")",false,"elif isinstance ( m , ( _BatchNorm , nn . GroupNorm ) ) :","if isinstance ( m , nn . Conv2d ) :",0.19,0.0
"def test_is_native_login(self): <TAB> for campaign in self.campaign_lists: <TAB> <TAB> native = campaigns.is_native_login(campaign) <TAB> <TAB> if campaign == ""prereg"" or campaign == ""erpc"": <TAB> <TAB> <TAB> assert_true(native) <TAB> <TAB> else: <TAB> <TAB> <TAB> assert_false(native) <TAB> native = campaigns.is_proxy_login(self.invalid_campaign) <TAB> assert_true(native is None)",true,"if campaign == ""prereg"" or campaign == ""erpc"" :","if campaign == ""prereg"" or campaign == ""erpc"" :",1.0,0.0
"def _process_filter(self, query, host_state): <TAB> """"""Recursively parse the query structure."""""" <TAB> if not query: <TAB> <TAB> return True <TAB> cmd = query[0] <TAB> method = self.commands[cmd] <TAB> cooked_args = [] <TAB> for arg in query[1:]: <TAB> <TAB> if isinstance(arg, list): <TAB> <TAB> <TAB> arg = self._process_filter(arg, host_state) <TAB> <TAB> elif isinstance(arg, basestring): <TAB> <TAB> <TAB> arg = self._parse_string(arg, host_state) <TAB> <TAB> if arg is not None: <TAB> <TAB> <TAB> cooked_args.append(arg) <TAB> result = method(self, cooked_args) <TAB> return result",true,"elif isinstance ( arg , basestring ) :","elif isinstance ( arg , basestring ) :",0.75,0.0
"def find_go_files_mtime(app_files): <TAB> files, mtime = [], 0 <TAB> for f, mt in app_files.items(): <TAB> <TAB> if not f.endswith("".go""): <TAB> <TAB> <TAB> continue <TAB> <TAB> if APP_CONFIG.nobuild_files.match(f): <TAB> <TAB> <TAB> continue <TAB> <TAB> files.append(f) <TAB> <TAB> mtime = max(mtime, mt) <TAB> return files, mtime",false,"if not f . endswith ( "".go"" ) :",if APP_CONFIG . nobuild_files . match ( f ) :,0.03,0.0
"def ExcludePath(self, path): <TAB> """"""Check to see if this is a service url and matches inbound_services."""""" <TAB> skip = False <TAB> for reserved_path in self.reserved_paths.keys(): <TAB> <TAB> if path.startswith(reserved_path): <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> not self.inbound_services <TAB> <TAB> <TAB> <TAB> or self.reserved_paths[reserved_path] not in self.inbound_services <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> return (True, self.reserved_paths[reserved_path]) <TAB> return (False, None)",true,if path . startswith ( reserved_path ) :,if path . startswith ( reserved_path ) :,0.75,0.0
"def param_cov(self) -> DataFrame: <TAB> """"""Parameter covariance"""""" <TAB> if self._param_cov is not None: <TAB> <TAB> param_cov = self._param_cov <TAB> else: <TAB> <TAB> params = np.asarray(self.params) <TAB> <TAB> if self.cov_type == ""robust"": <TAB> <TAB> <TAB> param_cov = self.model.compute_param_cov(params) <TAB> <TAB> else: <TAB> <TAB> <TAB> param_cov = self.model.compute_param_cov(params, robust=False) <TAB> return DataFrame(param_cov, columns=self._names, index=self._names)",true,"if self . cov_type == ""robust"" :","if self . cov_type == ""robust"" :",0.75,0.0
"def test_calculate_all_attentions(module, atype): <TAB> m = importlib.import_module(module) <TAB> args = make_arg(atype=atype) <TAB><IF-STMT> <TAB> <TAB> batch = prepare_inputs(""pytorch"") <TAB> else: <TAB> <TAB> raise NotImplementedError <TAB> model = m.E2E(6, 5, args) <TAB> with chainer.no_backprop_mode(): <TAB> <TAB> if ""pytorch"" in module: <TAB> <TAB> <TAB> att_ws = model.calculate_all_attentions(*batch)[0] <TAB> <TAB> else: <TAB> <TAB> <TAB> raise NotImplementedError <TAB> <TAB> print(att_ws.shape)",true,"if ""pytorch"" in module :","if ""pytorch"" in module :",0.75,0.0
"def __eq__(self, other): <TAB> try: <TAB> <TAB> if self.type != other.type: <TAB> <TAB> <TAB> return False <TAB> <TAB> if self.type == ""ASK"": <TAB> <TAB> <TAB> return self.askAnswer == other.askAnswer <TAB> <TAB> elif self.type == ""SELECT"": <TAB> <TAB> <TAB> return self.vars == other.vars and self.bindings == other.bindings <TAB> <TAB> else: <TAB> <TAB> <TAB> return self.graph == other.graph <TAB> except: <TAB> <TAB> return False",true,"if self . type == ""ASK"" :","if self . type == ""ASK"" :",0.75,0.0
"def validate_memory(self, value): <TAB> for k, v in value.viewitems(): <TAB> <TAB> if v is None:  # use NoneType to unset a value <TAB> <TAB> <TAB> continue <TAB> <TAB> if not re.match(PROCTYPE_MATCH, k): <TAB> <TAB> <TAB> raise serializers.ValidationError(""Process types can only contain [a-z]"") <TAB> <TAB> if not re.match(MEMLIMIT_MATCH, str(v)): <TAB> <TAB> <TAB> raise serializers.ValidationError( <TAB> <TAB> <TAB> <TAB> ""Limit format: <number><unit>, where unit = B, K, M or G"" <TAB> <TAB> <TAB> ) <TAB> return value",false,"if not re . match ( MEMLIMIT_MATCH , str ( v ) ) :","if not re . match ( PROCTYPE_MATCH , k ) :",0.28,0.0
"def get_connections(data_about): <TAB> data = data_about.find(""h3"", text=""Connections"").findNext() <TAB> connections = {} <TAB> for row in data.find_all(""tr""): <TAB> <TAB> key = row.find_all(""td"")[0].text <TAB> <TAB> value = row.find_all(""td"")[1] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> connections[key] = get_all_links(value) <TAB> <TAB> else: <TAB> <TAB> <TAB> connections[key] = value.text <TAB> return connections",false,"if ""Teams"" in key :",if key in connections :,0.04,0.0
"def _compute_map(self, first_byte, second_byte=None): <TAB> if first_byte != 0x0F: <TAB> <TAB> return ""XED_ILD_MAP0"" <TAB> else: <TAB> <TAB> if second_byte == None: <TAB> <TAB> <TAB> return ""XED_ILD_MAP1"" <TAB> <TAB> if second_byte == 0x38: <TAB> <TAB> <TAB> return ""XED_ILD_MAP2"" <TAB> <TAB> if second_byte == 0x3A: <TAB> <TAB> <TAB> return ""XED_ILD_MAP3"" <TAB> <TAB> if second_byte == 0x0F and self.amd_enabled: <TAB> <TAB> <TAB> return ""XED_ILD_MAPAMD"" <TAB> die(""Unhandled escape {} / map {} bytes"".format(first_byte, second_byte))",true,if second_byte == 0x0F and self . amd_enabled :,if second_byte == 0x0F and self . amd_enabled :,0.75,0.0
"def compress(self, data_list): <TAB> if data_list: <TAB> <TAB> page_id = data_list[1] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if not self.required: <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> raise forms.ValidationError(self.error_messages[""invalid_page""]) <TAB> <TAB> return Page.objects.get(pk=page_id) <TAB> return None",false,if page_id in EMPTY_VALUES :,if page_id not in self . page_ids :,0.18,0.0
"def find_module(self, fullname, path=None): <TAB> path = path or self.path_entry <TAB> # print('looking for ""%s"" in %s ...' % (fullname, path)) <TAB> for _ext in [""js"", ""pyj"", ""py""]: <TAB> <TAB> _filepath = os.path.join(self.path_entry, ""%s.%s"" % (fullname, _ext)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(""module found at %s:%s"" % (_filepath, fullname)) <TAB> <TAB> <TAB> return VFSModuleLoader(_filepath, fullname) <TAB> print(""module %s not found"" % fullname) <TAB> raise ImportError() <TAB> return None",false,if _filepath in VFS :,if _filepath in path :,0.39,0.0
"def __decToBin(self, myDec): <TAB> n = 0 <TAB> binOfDec = """" <TAB> while myDec > 2 ** n: <TAB> <TAB> n = n + 1 <TAB> if (myDec < 2 ** n) & (myDec != 0): <TAB> <TAB> n = n - 1 <TAB> while n >= 0: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> myDec = myDec - 2 ** n <TAB> <TAB> <TAB> binOfDec = binOfDec + ""1"" <TAB> <TAB> else: <TAB> <TAB> <TAB> binOfDec = binOfDec + ""0"" <TAB> <TAB> n = n - 1 <TAB> return binOfDec",false,if myDec >= 2 ** n :,if n < 2 ** n :,0.47,0.0
"def __str__(self): <TAB> try: <TAB> <TAB> if self.value not in NVMLError._errcode_to_string: <TAB> <TAB> <TAB> NVMLError._errcode_to_string[self.value] = str(nvmlErrorString(self.value)) <TAB> <TAB> return NVMLError._errcode_to_string[self.value] <TAB> except NVMLError_Uninitialized: <TAB> <TAB> return ""NVML Error with code %d"" % self.value",true,if self . value not in NVMLError . _errcode_to_string :,if self . value not in NVMLError . _errcode_to_string :,0.75,0.0
"def abspath(pathdir: str) -> str: <TAB> if Path is not None and isinstance(pathdir, Path): <TAB> <TAB> return pathdir.abspath() <TAB> else: <TAB> <TAB> pathdir = path.abspath(pathdir) <TAB> <TAB> if isinstance(pathdir, bytes): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> pathdir = pathdir.decode(fs_encoding) <TAB> <TAB> <TAB> except UnicodeDecodeError as exc: <TAB> <TAB> <TAB> <TAB> raise UnicodeDecodeError( <TAB> <TAB> <TAB> <TAB> <TAB> ""multibyte filename not supported on "" <TAB> <TAB> <TAB> <TAB> <TAB> ""this filesystem encoding "" <TAB> <TAB> <TAB> <TAB> <TAB> ""(%r)"" % fs_encoding <TAB> <TAB> <TAB> <TAB> ) from exc <TAB> <TAB> return pathdir",true,"if isinstance ( pathdir , bytes ) :","if isinstance ( pathdir , bytes ) :",0.75,0.0
"def _get_vtkjs(self): <TAB> if self._vtkjs is None and self.object is not None: <TAB> <TAB> if isinstance(self.object, string_types) and self.object.endswith("".vtkjs""): <TAB> <TAB> <TAB> if isfile(self.object): <TAB> <TAB> <TAB> <TAB> with open(self.object, ""rb"") as f: <TAB> <TAB> <TAB> <TAB> <TAB> vtkjs = f.read() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> data_url = urlopen(self.object) <TAB> <TAB> <TAB> <TAB> vtkjs = data_url.read() <TAB> <TAB> elif hasattr(self.object, ""read""): <TAB> <TAB> <TAB> vtkjs = self.object.read() <TAB> <TAB> self._vtkjs = vtkjs <TAB> return self._vtkjs",true,"if isinstance ( self . object , string_types ) and self . object . endswith ( "".vtkjs"" ) :","if isinstance ( self . object , string_types ) and self . object . endswith ( "".vtkjs"" ) :",1.0,0.0
"def _set_uid(self, val): <TAB> if val is not None: <TAB> <TAB> if pwd is None: <TAB> <TAB> <TAB> self.bus.log(""pwd module not available; ignoring uid."", level=30) <TAB> <TAB> <TAB> val = None <TAB> <TAB> elif isinstance(val, text_or_bytes): <TAB> <TAB> <TAB> val = pwd.getpwnam(val)[2] <TAB> self._uid = val",true,"elif isinstance ( val , text_or_bytes ) :","elif isinstance ( val , text_or_bytes ) :",0.75,0.0
"def get_attached_nodes(self, external_account): <TAB> for node in self.get_nodes_with_oauth_grants(external_account): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> node_settings = node.get_addon(self.oauth_provider.short_name) <TAB> <TAB> if node_settings is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> if node_settings.external_account == external_account: <TAB> <TAB> <TAB> yield node",false,if node is None :,if node . is_linked :,0.06,0.0
"def from_obj(cls, py_obj): <TAB> if not isinstance(py_obj, Image): <TAB> <TAB> raise TypeError(""py_obj must be a wandb.Image"") <TAB> else: <TAB> <TAB> if hasattr(py_obj, ""_boxes"") and py_obj._boxes: <TAB> <TAB> <TAB> box_keys = list(py_obj._boxes.keys()) <TAB> <TAB> else: <TAB> <TAB> <TAB> box_keys = [] <TAB> <TAB> if hasattr(py_obj, ""masks"") and py_obj.masks: <TAB> <TAB> <TAB> mask_keys = list(py_obj.masks.keys()) <TAB> <TAB> else: <TAB> <TAB> <TAB> mask_keys = [] <TAB> <TAB> return cls(box_keys, mask_keys)",true,"if hasattr ( py_obj , ""masks"" ) and py_obj . masks :","if hasattr ( py_obj , ""masks"" ) and py_obj . masks :",1.0,0.0
"def write(self, *bits): <TAB> for bit in bits: <TAB> <TAB> if not self.bytestream: <TAB> <TAB> <TAB> self.bytestream.append(0) <TAB> <TAB> byte = self.bytestream[self.bytenum] <TAB> <TAB> if self.bitnum == 8: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> byte = 0 <TAB> <TAB> <TAB> <TAB> self.bytestream += bytes([byte]) <TAB> <TAB> <TAB> self.bytenum += 1 <TAB> <TAB> <TAB> self.bitnum = 0 <TAB> <TAB> mask = 2 ** self.bitnum <TAB> <TAB> if bit: <TAB> <TAB> <TAB> byte |= mask <TAB> <TAB> else: <TAB> <TAB> <TAB> byte &= ~mask <TAB> <TAB> self.bytestream[self.bytenum] = byte <TAB> <TAB> self.bitnum += 1",false,if self . bytenum == len ( self . bytestream ) - 1 :,if not byte :,0.01,0.0
"def destroy(self, wipe=False): <TAB> if self.state == self.UP: <TAB> <TAB> image = self.image() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return self.confirm_destroy(image, self.full_name, abort=False) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.warn(""tried to destroy {0} which didn't exist"".format(self.full_name)) <TAB> return True",true,if image :,if image :,0.53,0.0
"def get_host_metadata(self): <TAB> meta = {} <TAB> if self.agent_url: <TAB> <TAB> try: <TAB> <TAB> <TAB> resp = requests.get( <TAB> <TAB> <TAB> <TAB> self.agent_url + ECS_AGENT_METADATA_PATH, timeout=1 <TAB> <TAB> <TAB> ).json() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> match = AGENT_VERSION_EXP.search(resp.get(""Version"")) <TAB> <TAB> <TAB> <TAB> if match is not None and len(match.groups()) == 1: <TAB> <TAB> <TAB> <TAB> <TAB> meta[""ecs_version""] = match.group(1) <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> self.log.debug(""Error getting ECS version: %s"" % str(e)) <TAB> return meta",false,"if ""Version"" in resp :",if resp :,0.07,0.0
"def _path_type(st, lst): <TAB> parts = [] <TAB> if st: <TAB> <TAB> if stat.S_ISREG(st.st_mode): <TAB> <TAB> <TAB> parts.append(""file"") <TAB> <TAB> elif stat.S_ISDIR(st.st_mode): <TAB> <TAB> <TAB> parts.append(""dir"") <TAB> <TAB> else: <TAB> <TAB> <TAB> parts.append(""other"") <TAB> if lst: <TAB> <TAB> if stat.S_ISLNK(lst.st_mode): <TAB> <TAB> <TAB> parts.append(""link"") <TAB> return "" "".join(parts)",true,if stat . S_ISREG ( st . st_mode ) :,if stat . S_ISREG ( st . st_mode ) :,0.75,0.0
"def changed(self, action): <TAB> # Something was changed in the 'files' list <TAB> if len(action.key) >= 1 and action.key[0].lower() == ""files"": <TAB> <TAB> # Refresh project files model <TAB> <TAB> if action.type == ""insert"": <TAB> <TAB> <TAB> # Don't clear the existing items if only inserting new things <TAB> <TAB> <TAB> self.update_model(clear=False) <TAB> <TAB> else: <TAB> <TAB> <TAB> # Clear existing items <TAB> <TAB> <TAB> self.update_model(clear=True)",true,"if action . type == ""insert"" :","if action . type == ""insert"" :",0.75,0.0
"def process(self, resources, event=None): <TAB> client = local_session(self.manager.session_factory).client(""es"") <TAB> for r in resources: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result = self.manager.retry( <TAB> <TAB> <TAB> <TAB> client.describe_elasticsearch_domain_config, <TAB> <TAB> <TAB> <TAB> DomainName=r[""DomainName""], <TAB> <TAB> <TAB> <TAB> ignore_err_codes=(""ResourceNotFoundException"",), <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if result: <TAB> <TAB> <TAB> <TAB> r[self.policy_attribute] = json.loads( <TAB> <TAB> <TAB> <TAB> <TAB> result.get(""DomainConfig"").get(""AccessPolicies"").get(""Options"") <TAB> <TAB> <TAB> <TAB> ) <TAB> return super().process(resources)",true,if self . policy_attribute not in r :,if self . policy_attribute not in r :,0.75,0.0
"def line_items(self): <TAB> line_items = [] <TAB> for line in self.lines_str: <TAB> <TAB> line = line.split(""|"") <TAB> <TAB> line = line[1:-1]  # del first and last empty item (consequence of split) <TAB> <TAB> items = [] <TAB> <TAB> for item in line: <TAB> <TAB> <TAB> i = re.search(r""(\S+([ \t]+\S+)*)+"", item) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> items.append(i.group()) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> items.append("" "") <TAB> <TAB> line_items.append(items) <TAB> return line_items",true,if i :,if i :,0.53,0.0
"def on_data(res): <TAB> if terminate.is_set(): <TAB> <TAB> return <TAB> if args.strings and not args.no_content: <TAB> <TAB> if type(res) == tuple: <TAB> <TAB> <TAB> f, v = res <TAB> <TAB> <TAB> if type(f) == unicode: <TAB> <TAB> <TAB> <TAB> f = f.encode(""utf-8"") <TAB> <TAB> <TAB> if type(v) == unicode: <TAB> <TAB> <TAB> <TAB> v = v.encode(""utf-8"") <TAB> <TAB> <TAB> self.success(""{}: {}"".format(f, v)) <TAB> <TAB> elif not args.content_only: <TAB> <TAB> <TAB> self.success(res) <TAB> else: <TAB> <TAB> self.success(res)",true,elif not args . content_only :,elif not args . content_only :,0.75,0.0
"def get_servers(self, detail=True, search_opts=None): <TAB> rel_url = ""/servers/detail"" if detail else ""/servers"" <TAB> if search_opts is not None: <TAB> <TAB> qparams = {} <TAB> <TAB> for opt, val in search_opts.iteritems(): <TAB> <TAB> <TAB> qparams[opt] = val <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> query_string = ""?%s"" % urllib.urlencode(qparams) <TAB> <TAB> <TAB> rel_url += query_string <TAB> return self.api_get(rel_url)[""servers""]",true,if qparams :,if qparams :,0.53,0.0
"def run(self): <TAB> while not self.__exit__: <TAB> <TAB> if len(self.playlist) == 0: <TAB> <TAB> <TAB> sleep(10) <TAB> <TAB> <TAB> continue <TAB> <TAB> o = self.playlist[0] <TAB> <TAB> self.playlist.remove(o) <TAB> <TAB> obj = json.loads(o) <TAB> <TAB> if not ""args"" in obj: <TAB> <TAB> <TAB> obj[""args""] = {""ua"": """", ""header"": """", ""title"": """", ""referer"": """"} <TAB> <TAB> obj[""play""] = False <TAB> <TAB> self.handle = launch_player(obj[""urls""], obj[""ext""], **obj[""args""]) <TAB> <TAB> self.handle.wait()",true,if len ( self . playlist ) == 0 :,if len ( self . playlist ) == 0 :,0.75,0.0
"def get_to_download_runs_ids(session, headers): <TAB> last_date = 0 <TAB> result = [] <TAB> while 1: <TAB> <TAB> r = session.get(RUN_DATA_API.format(last_date=last_date), headers=headers) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> run_logs = r.json()[""data""][""records""] <TAB> <TAB> <TAB> result.extend([i[""logs""][0][""stats""][""id""] for i in run_logs]) <TAB> <TAB> <TAB> last_date = r.json()[""data""][""lastTimestamp""] <TAB> <TAB> <TAB> since_time = datetime.utcfromtimestamp(last_date / 1000) <TAB> <TAB> <TAB> print(f""pares keep ids data since {since_time}"") <TAB> <TAB> <TAB> time.sleep(1)  # spider rule <TAB> <TAB> <TAB> if not last_date: <TAB> <TAB> <TAB> <TAB> break <TAB> return result",false,if r . ok :,if r :,0.07,0.0
"def __saveWork(self, work, results): <TAB> """"""Stores the resulting last log line to the cache with the proxy key"""""" <TAB> del work <TAB> # pylint: disable=broad-except <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> __cached = self.__cache[results[0]] <TAB> <TAB> <TAB> __cached[self.__TIME] = time.time() <TAB> <TAB> <TAB> __cached[self.__LINE] = results[1] <TAB> <TAB> <TAB> __cached[self.__LLU] = results[2] <TAB> except KeyError as e: <TAB> <TAB> # Could happen while switching jobs with work in the queue <TAB> <TAB> pass <TAB> except Exception as e: <TAB> <TAB> list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",true,if results :,if results :,0.53,0.0
"def read_notes(rec): <TAB> found = [] <TAB> for tag in range(500, 595): <TAB> <TAB> if tag in (505, 520): <TAB> <TAB> <TAB> continue <TAB> <TAB> fields = rec.get_fields(str(tag)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> for f in fields: <TAB> <TAB> <TAB> x = f.get_lower_subfields() <TAB> <TAB> <TAB> if x: <TAB> <TAB> <TAB> <TAB> found.append("" "".join(x).strip("" "")) <TAB> if found: <TAB> <TAB> return ""\n\n"".join(found)",true,if not fields :,if not fields :,0.75,0.0
"def serialize_to(self, stream, alternate_script=None): <TAB> stream.write(self.txo_ref.tx_ref.hash) <TAB> stream.write_uint32(self.txo_ref.position) <TAB> if alternate_script is not None: <TAB> <TAB> stream.write_string(alternate_script) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> stream.write_string(self.coinbase) <TAB> <TAB> else: <TAB> <TAB> <TAB> stream.write_string(self.script.source) <TAB> stream.write_uint32(self.sequence)",false,if self . is_coinbase :,if self . coinbase is not None :,0.19,0.0
"def func_named(self, arg): <TAB> result = None <TAB> target = ""do_"" + arg <TAB> if target in dir(self): <TAB> <TAB> result = target <TAB> else: <TAB> <TAB><IF-STMT>  # accept shortened versions of commands <TAB> <TAB> <TAB> funcs = [fname for fname in self.keywords if fname.startswith(arg)] <TAB> <TAB> <TAB> if len(funcs) == 1: <TAB> <TAB> <TAB> <TAB> result = ""do_"" + funcs[0] <TAB> return result",false,if self . abbrev :,if self . keywords :,0.39,0.0
"def static_login(self, token, *, bot): <TAB> # Necessary to get aiohttp to stop complaining about session creation <TAB> self.__session = aiohttp.ClientSession( <TAB> <TAB> connector=self.connector, ws_response_class=DiscordClientWebSocketResponse <TAB> ) <TAB> old_token, old_bot = self.token, self.bot_token <TAB> self._token(token, bot=bot) <TAB> try: <TAB> <TAB> data = await self.request(Route(""GET"", ""/users/@me"")) <TAB> except HTTPException as exc: <TAB> <TAB> self._token(old_token, bot=old_bot) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise LoginFailure(""Improper token has been passed."") from exc <TAB> <TAB> raise <TAB> return data",false,if exc . response . status == 401 :,"if ""Invalid token"" in exc . args :",0.03,0.0
"def render_buttons(self): <TAB> for x, button in enumerate(self.button_list): <TAB> <TAB> gcolor = Gdk.color_parse(self.color_list[x]) <TAB> <TAB> if util.get_hls_val(self.color_list[x], ""light"") < 99: <TAB> <TAB> <TAB> fgcolor = Gdk.color_parse(""#FFFFFF"") <TAB> <TAB> else: <TAB> <TAB> <TAB> fgcolor = Gdk.color_parse(""#000000"") <TAB> <TAB> button.set_label(self.color_list[x]) <TAB> <TAB> button.set_sensitive(True) <TAB> <TAB> button.modify_bg(Gtk.StateType.NORMAL, gcolor) <TAB> <TAB> button.modify_fg(Gtk.StateType.NORMAL, fgcolor)",true,"if util . get_hls_val ( self . color_list [ x ] , ""light"" ) < 99 :","if util . get_hls_val ( self . color_list [ x ] , ""light"" ) < 99 :",0.75,0.0
"def _set_text(self, data): <TAB> lines = [] <TAB> for key, value in data.items(): <TAB> <TAB> lines.append("""") <TAB> <TAB> txt = yaml.dump({key: value}, default_flow_style=False) <TAB> <TAB> title = self.titles.get(key) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> lines.append(""# %s"" % title) <TAB> <TAB> lines.append(txt.rstrip()) <TAB> txt = ""\n"".join(lines) + ""\n"" <TAB> txt = txt.lstrip() <TAB> self.edit.setPlainText(txt)",true,if title :,if title :,0.53,0.0
"def build_path(self): <TAB> for variable in re_path_template.findall(self.path): <TAB> <TAB> name = variable.strip(""{}"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # No 'user' parameter provided, fetch it from Auth instead. <TAB> <TAB> <TAB> value = self.api.auth.get_username() <TAB> <TAB> else: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> value = quote(self.session.params[name]) <TAB> <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> <TAB> raise TweepError( <TAB> <TAB> <TAB> <TAB> <TAB> ""No parameter value found for path variable: %s"" % name <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> del self.session.params[name] <TAB> <TAB> self.path = self.path.replace(variable, value)",false,"if name == ""user"" and ""user"" not in self . session . params and self . api . auth :",if name not in self . session . params :,0.15,0.0
"def _calculate_writes_for_built_in_indices(self, entity): <TAB> writes = 0 <TAB> for prop_name in entity.keys(): <TAB> <TAB> if not prop_name in entity.unindexed_properties(): <TAB> <TAB> <TAB> prop_vals = entity[prop_name] <TAB> <TAB> <TAB> if isinstance(prop_vals, (list)): <TAB> <TAB> <TAB> <TAB> num_prop_vals = len(prop_vals) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> num_prop_vals = 1 <TAB> <TAB> <TAB> writes += 2 * num_prop_vals <TAB> return writes",false,if not prop_name in entity . unindexed_properties ( ) :,"if isinstance ( prop_vals , ( list ) ) :",0.03,0.0
"def create_connection(self, address, protocol_factory=None, **kw): <TAB> """"""Helper method for creating a connection to an ``address``."""""" <TAB> protocol_factory = protocol_factory or self.create_protocol <TAB> if isinstance(address, tuple): <TAB> <TAB> host, port = address <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.logger.debug(""Create connection %s:%s"", host, port) <TAB> <TAB> _, protocol = await self._loop.create_connection( <TAB> <TAB> <TAB> protocol_factory, host, port, **kw <TAB> <TAB> ) <TAB> <TAB> await protocol.event(""connection_made"") <TAB> else: <TAB> <TAB> raise NotImplementedError(""Could not connect to %s"" % str(address)) <TAB> return protocol",false,if self . debug :,if host :,0.04,0.0
def _increment_bracket_num(self): <TAB> self._current_bracket -= 1 <TAB> if self._current_bracket < 0: <TAB> <TAB> self._current_bracket = self._get_num_brackets() - 1 <TAB> <TAB> self._current_iteration += 1 <TAB> <TAB> if self._current_iteration > self.hyperband_iterations: <TAB> <TAB> <TAB> self._current_bracket = 0,true,if self . _current_iteration > self . hyperband_iterations :,if self . _current_iteration > self . hyperband_iterations :,1.0,0.0
"def get_cycle_path(self, curr_node, goal_node_index): <TAB> for dep in curr_node[""deps""]: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return [curr_node[""address""]] <TAB> for dep in curr_node[""deps""]: <TAB> <TAB> path = self.get_cycle_path( <TAB> <TAB> <TAB> self.get_by_address(dep), goal_node_index <TAB> <TAB> )  # self.nodelist[dep], goal_node_index) <TAB> <TAB> if len(path) > 0: <TAB> <TAB> <TAB> path.insert(0, curr_node[""address""]) <TAB> <TAB> <TAB> return path <TAB> return []",false,if dep == goal_node_index :,if dep in self . nodelist :,0.05,0.0
"def as_dict(path="""", version=""latest"", section=""meta-data""): <TAB> result = {} <TAB> dirs = dir(path, version, section) <TAB> if not dirs: <TAB> <TAB> return None <TAB> for item in dirs: <TAB> <TAB> if item.endswith(""/""): <TAB> <TAB> <TAB> records = as_dict(path + item, version, section) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> result[item[:-1]] = records <TAB> <TAB> elif is_dict.match(item): <TAB> <TAB> <TAB> idx, name = is_dict.match(item).groups() <TAB> <TAB> <TAB> records = as_dict(path + idx + ""/"", version, section) <TAB> <TAB> <TAB> if records: <TAB> <TAB> <TAB> <TAB> result[name] = records <TAB> <TAB> else: <TAB> <TAB> <TAB> result[item] = valueconv(get(path + item, version, section)) <TAB> return result",true,if records :,if records :,0.53,0.0
"def preprocess_raw_enwik9(input_filename, output_filename): <TAB> with open(input_filename, ""r"") as f1: <TAB> <TAB> with open(output_filename, ""w"") as f2: <TAB> <TAB> <TAB> while True: <TAB> <TAB> <TAB> <TAB> line = f1.readline() <TAB> <TAB> <TAB> <TAB> if not line: <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> line = list(enwik9_norm_transform([line]))[0] <TAB> <TAB> <TAB> <TAB> if line != "" "" and line != """": <TAB> <TAB> <TAB> <TAB> <TAB> if line[0] == "" "": <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> line = line[1:] <TAB> <TAB> <TAB> <TAB> <TAB> f2.writelines(line + ""\n"")",true,"if line [ 0 ] == "" "" :","if line [ 0 ] == "" "" :",0.75,0.0
"def _handle_unsubscribe(self, web_sock): <TAB> index = None <TAB> with await self._subscriber_lock: <TAB> <TAB> for i, (subscriber_web_sock, _) in enumerate(self._subscribers): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> index = i <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if index is not None: <TAB> <TAB> <TAB> del self._subscribers[index] <TAB> <TAB> if not self._subscribers: <TAB> <TAB> <TAB> asyncio.ensure_future(self._unregister_subscriptions())",true,if subscriber_web_sock == web_sock :,if subscriber_web_sock == web_sock :,0.75,0.0
"def formatmonthname(self, theyear, themonth, withyear=True): <TAB> with TimeEncoding(self.locale) as encoding: <TAB> <TAB> s = month_name[themonth] <TAB> <TAB> if encoding is not None: <TAB> <TAB> <TAB> s = s.decode(encoding) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> s = ""%s %s"" % (s, theyear) <TAB> <TAB> return '<tr><th colspan=""7"" class=""month"">%s</th></tr>' % s",true,if withyear :,if withyear :,0.53,0.0
"def generate_sitemaps(filename): <TAB> rows = (line.strip().split(""\t"") for line in open(filename)) <TAB> for sortkey, chunk in itertools.groupby(rows, lambda row: row[0]): <TAB> <TAB> things = [] <TAB> <TAB> _chunk = list(chunk) <TAB> <TAB> for segment in _chunk: <TAB> <TAB> <TAB> sortkey = segment.pop(0) <TAB> <TAB> <TAB> last_modified = segment.pop(-1) <TAB> <TAB> <TAB> path = """".join(segment) <TAB> <TAB> <TAB> things.append(web.storage(path=path, last_modified=last_modified)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> write(""sitemaps/sitemap_%s.xml.gz"" % sortkey, sitemap(things))",false,if things :,if sortkey :,0.32,0.0
"def use_index( <TAB> self, term: Union[str, Index], *terms: Union[str, Index] ) -> ""QueryBuilder"": <TAB> for t in (term, *terms): <TAB> <TAB> if isinstance(t, Index): <TAB> <TAB> <TAB> self._use_indexes.append(t) <TAB> <TAB> elif isinstance(t, str): <TAB> <TAB> <TAB> self._use_indexes.append(Index(t))",false,"if isinstance ( t , Index ) :","elif isinstance ( t , str ) :",0.2,0.0
"def get_changed(self): <TAB> if self._is_expression(): <TAB> <TAB> result = self._get_node_text(self.ast) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> return result <TAB> else: <TAB> <TAB> collector = codeanalyze.ChangeCollector(self.source) <TAB> <TAB> last_end = -1 <TAB> <TAB> for match in self.matches: <TAB> <TAB> <TAB> start, end = match.get_region() <TAB> <TAB> <TAB> if start < last_end: <TAB> <TAB> <TAB> <TAB> if not self._is_expression(): <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> last_end = end <TAB> <TAB> <TAB> replacement = self._get_matched_text(match) <TAB> <TAB> <TAB> collector.add_change(start, end, replacement) <TAB> <TAB> return collector.get_changed()",false,if result == self . source :,if result is None :,0.04,0.0
"def quiet_f(*args): <TAB> vars = {arg_name: Real(arg) for arg_name, arg in zip(arg_names, args)} <TAB> value = dynamic_scoping(quiet_expr.evaluate, vars, evaluation) <TAB> if expect_list: <TAB> <TAB> if value.has_form(""List"", None): <TAB> <TAB> <TAB> value = [extract_pyreal(item) for item in value.leaves] <TAB> <TAB> <TAB> if any(item is None for item in value): <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> return value <TAB> <TAB> else: <TAB> <TAB> <TAB> return None <TAB> else: <TAB> <TAB> value = extract_pyreal(value) <TAB> <TAB> if value is None or isinf(value) or isnan(value): <TAB> <TAB> <TAB> return None <TAB> <TAB> return value",false,if any ( item is None for item in value ) :,"if value . has_form ( ""List"" , None ) :",0.02,0.0
"def _reemit_nested_event(self, event: Event): <TAB> source_index = self.index(event.source) <TAB> for attr in (""index"", ""new_index""): <TAB> <TAB> if hasattr(event, attr): <TAB> <TAB> <TAB> src_index = ensure_tuple_index(event.index) <TAB> <TAB> <TAB> setattr(event, attr, (source_index,) + src_index) <TAB> if not hasattr(event, ""index""): <TAB> <TAB> setattr(event, ""index"", source_index) <TAB> # reemit with this object's EventEmitter of the same type if present <TAB> # otherwise just emit with the EmitterGroup itself <TAB> getattr(self.events, event.type, self.events)(event)",true,"if hasattr ( event , attr ) :","if hasattr ( event , attr ) :",0.75,0.0
"def check(self): <TAB> """"""Perform required checks to conclude if it's safe to operate"""""" <TAB> if self.interpreter.manual is None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.error = self.process.error <TAB> <TAB> <TAB> self.tip = self.process.tip <TAB> <TAB> <TAB> return False <TAB> start = time.time() <TAB> while not self._status(): <TAB> <TAB> if time.time() - start >= 2:  # 2s <TAB> <TAB> <TAB> self.error = ""can't connect to the minserver on {}:{}"".format( <TAB> <TAB> <TAB> <TAB> self.interpreter.host, self.interpreter.port <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self.tip = ""check your vagrant machine is running"" <TAB> <TAB> <TAB> return False <TAB> <TAB> time.sleep(0.1) <TAB> return True",false,if not self . process . healthy :,if self . process . error :,0.2,0.0
"def apply(self): <TAB> new_block = self.block.copy() <TAB> new_block.clear() <TAB> for inst in self.block.body: <TAB> <TAB> if isinstance(inst, Assign) and inst.value in self.getattrs: <TAB> <TAB> <TAB> const_assign = self._assign_const(inst) <TAB> <TAB> <TAB> new_block.append(const_assign) <TAB> <TAB> <TAB> inst = self._assign_getitem(inst, index=const_assign.target) <TAB> <TAB> new_block.append(inst) <TAB> return new_block",false,"if isinstance ( inst , Assign ) and inst . value in self . getattrs :","if isinstance ( inst , Assign ) and inst . value in self . attrs :",0.94,0.0
"def _get_orientation(self): <TAB> if self.state: <TAB> <TAB> rotation = [0] * 9 <TAB> <TAB> inclination = [0] * 9 <TAB> <TAB> gravity = [] <TAB> <TAB> geomagnetic = [] <TAB> <TAB> gravity = self.listener_a.values <TAB> <TAB> geomagnetic = self.listener_m.values <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ff_state = SensorManager.getRotationMatrix( <TAB> <TAB> <TAB> <TAB> rotation, inclination, gravity, geomagnetic <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if ff_state: <TAB> <TAB> <TAB> <TAB> values = [0, 0, 0] <TAB> <TAB> <TAB> <TAB> values = SensorManager.getOrientation(rotation, values) <TAB> <TAB> <TAB> return values",false,if gravity [ 0 ] is not None and geomagnetic [ 0 ] is not None :,if self . listener_a . is_rotated :,0.01,0.0
def getFirstSubGraph(graph): <TAB> if len(graph) == 0: <TAB> <TAB> return None <TAB> subg = {} <TAB> todo = [graph.keys()[0]] <TAB> while len(todo) > 0: <TAB> <TAB> if todo[0] in graph.keys(): <TAB> <TAB> <TAB> subg[todo[0]] = graph[todo[0]] <TAB> <TAB> <TAB> todo.extend(graph[todo[0]]) <TAB> <TAB> <TAB> del graph[todo[0]] <TAB> <TAB> del todo[0] <TAB> return subg,true,if todo [ 0 ] in graph . keys ( ) :,if todo [ 0 ] in graph . keys ( ) :,0.75,0.0
"def decorated_function(*args, **kwargs): <TAB> rv = f(*args, **kwargs) <TAB> if ""Last-Modified"" not in rv.headers: <TAB> <TAB> try: <TAB> <TAB> <TAB> result = date <TAB> <TAB> <TAB> if callable(result): <TAB> <TAB> <TAB> <TAB> result = result(rv) <TAB> <TAB> <TAB> if not isinstance(result, basestring): <TAB> <TAB> <TAB> <TAB> from werkzeug.http import http_date <TAB> <TAB> <TAB> <TAB> result = http_date(result) <TAB> <TAB> <TAB> if result: <TAB> <TAB> <TAB> <TAB> rv.headers[""Last-Modified""] = result <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> logging.getLogger(__name__).exception( <TAB> <TAB> <TAB> <TAB> ""Error while calculating the lastmodified value for response {!r}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> rv <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return rv",false,"if not isinstance ( result , basestring ) :",if callable ( result ) :,0.04,0.0
"def set_invoice_details(self, row): <TAB> invoice_details = self.invoice_details.get(row.voucher_no, {}) <TAB> if row.due_date: <TAB> <TAB> invoice_details.pop(""due_date"", None) <TAB> row.update(invoice_details) <TAB> if row.voucher_type == ""Sales Invoice"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.set_delivery_notes(row) <TAB> <TAB> if self.filters.show_sales_person and row.sales_team: <TAB> <TAB> <TAB> row.sales_person = "", "".join(row.sales_team) <TAB> <TAB> <TAB> del row[""sales_team""]",false,if self . filters . show_delivery_notes :,if row . delivery_notes :,0.09,0.0
"def process(output): <TAB> modules = {} <TAB> for line in output: <TAB> <TAB> name, size, instances, depends, state, _ = line.split("" "", 5) <TAB> <TAB> instances = int(instances) <TAB> <TAB> module = { <TAB> <TAB> <TAB> ""size"": size, <TAB> <TAB> <TAB> ""instances"": instances, <TAB> <TAB> <TAB> ""state"": state, <TAB> <TAB> } <TAB> <TAB> if depends != ""-"": <TAB> <TAB> <TAB> module[""depends""] = [value for value in depends.split("","") if value] <TAB> <TAB> modules[name] = module <TAB> return modules",true,"if depends != ""-"" :","if depends != ""-"" :",0.75,0.0
"def _get_host_from_zc_service_info(service_info: zeroconf.ServiceInfo): <TAB> """"""Get hostname or IP + port from zeroconf service_info."""""" <TAB> host = None <TAB> port = None <TAB> if ( <TAB> <TAB> service_info <TAB> <TAB> and service_info.port <TAB> <TAB> and (service_info.server or len(service_info.addresses) > 0) <TAB> ): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> host = socket.inet_ntoa(service_info.addresses[0]) <TAB> <TAB> else: <TAB> <TAB> <TAB> host = service_info.server.lower() <TAB> <TAB> port = service_info.port <TAB> return (host, port)",false,if len ( service_info . addresses ) > 0 :,if service_info . server is None :,0.03,0.0
"def _init_weights(self, module): <TAB> if isinstance(module, nn.Linear): <TAB> <TAB> module.weight.data.normal_(mean=0.0, std=self.config.init_std) <TAB> <TAB> if module.bias is not None: <TAB> <TAB> <TAB> module.bias.data.zero_() <TAB> elif isinstance(module, nn.Embedding): <TAB> <TAB> module.weight.data.normal_(mean=0.0, std=self.config.init_std) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> module.weight.data[module.padding_idx].zero_()",true,if module . padding_idx is not None :,if module . padding_idx is not None :,0.75,0.0
"def visitFromImport(self, import_stmt, import_info): <TAB> new_pairs = [] <TAB> if not import_info.is_star_import(): <TAB> <TAB> for name, alias in import_info.names_and_aliases: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> pyname = self.pymodule[alias or name] <TAB> <TAB> <TAB> <TAB> if occurrences.same_pyname(self.pyname, pyname): <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> except exceptions.AttributeNotFoundError: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> new_pairs.append((name, alias)) <TAB> return importinfo.FromImport(import_info.module_name, import_info.level, new_pairs)",true,"if occurrences . same_pyname ( self . pyname , pyname ) :","if occurrences . same_pyname ( self . pyname , pyname ) :",1.0,0.0
"def _apply_patches(self): <TAB> try: <TAB> <TAB> s = Subprocess( <TAB> <TAB> <TAB> log=self.logfile, cwd=self.build_dir, verbose=self.options.verbose <TAB> <TAB> ) <TAB> <TAB> for patch in self.patches: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> for ed, source in patch.items(): <TAB> <TAB> <TAB> <TAB> <TAB> s.shell(""ed - %s < %s"" % (source, ed)) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> s.shell(""patch -p0 < %s"" % patch) <TAB> except: <TAB> <TAB> logger.error(""Failed to patch `%s`.\n%s"" % (self.build_dir, sys.exc_info()[1])) <TAB> <TAB> sys.exit(1)",false,if type ( patch ) is dict :,if self . options . verbose :,0.02,0.0
"def __init__(self, parent, dir, mask, with_dirs=True): <TAB> filelist = [] <TAB> dirlist = [""..""] <TAB> self.dir = dir <TAB> self.file = """" <TAB> mask = mask.upper() <TAB> pattern = self.MakeRegex(mask) <TAB> for i in os.listdir(dir): <TAB> <TAB> if i == ""."" or i == "".."": <TAB> <TAB> <TAB> continue <TAB> <TAB> path = os.path.join(dir, i) <TAB> <TAB> if os.path.isdir(path): <TAB> <TAB> <TAB> dirlist.append(i) <TAB> <TAB> <TAB> continue <TAB> <TAB> path = path.upper() <TAB> <TAB> value = i.upper() <TAB> <TAB> if pattern.match(value) is not None: <TAB> <TAB> <TAB> filelist.append(i) <TAB> self.files = filelist <TAB> if with_dirs: <TAB> <TAB> self.dirs = dirlist",true,if os . path . isdir ( path ) :,if os . path . isdir ( path ) :,1.0,0.0
"def remove_invalid_dirs(paths, bp_dir, module_name): <TAB> ret = [] <TAB> for path in paths: <TAB> <TAB> if os.path.isdir(os.path.join(bp_dir, path)): <TAB> <TAB> <TAB> ret.append(path) <TAB> <TAB> else: <TAB> <TAB> <TAB> logging.warning('Dir ""%s"" of module ""%s"" does not exist', path, module_name) <TAB> return ret",true,"if os . path . isdir ( os . path . join ( bp_dir , path ) ) :","if os . path . isdir ( os . path . join ( bp_dir , path ) ) :",1.0,0.0
"def update_sockets(self): <TAB> inputs = self.inputs <TAB> inputs_n = ""ABabcd"" <TAB> penta_sockets = pentagon_dict[self.grid_type].input_sockets <TAB> for socket in inputs_n: <TAB> <TAB> if socket in penta_sockets: <TAB> <TAB> <TAB> if inputs[socket].hide_safe: <TAB> <TAB> <TAB> <TAB> inputs[socket].hide_safe = False <TAB> <TAB> else: <TAB> <TAB> <TAB> inputs[socket].hide_safe = True",true,if inputs [ socket ] . hide_safe :,if inputs [ socket ] . hide_safe :,0.75,0.0
"def __cut(sentence): <TAB> global emit_P <TAB> prob, pos_list = viterbi(sentence, ""BMES"", start_P, trans_P, emit_P) <TAB> begin, nexti = 0, 0 <TAB> # print pos_list, sentence <TAB> for i, char in enumerate(sentence): <TAB> <TAB> pos = pos_list[i] <TAB> <TAB> if pos == ""B"": <TAB> <TAB> <TAB> begin = i <TAB> <TAB> elif pos == ""E"": <TAB> <TAB> <TAB> yield sentence[begin : i + 1] <TAB> <TAB> <TAB> nexti = i + 1 <TAB> <TAB> elif pos == ""S"": <TAB> <TAB> <TAB> yield char <TAB> <TAB> <TAB> nexti = i + 1 <TAB> if nexti < len(sentence): <TAB> <TAB> yield sentence[nexti:]",false,"elif pos == ""S"" :","elif pos == ""E"" :",0.64,0.0
"def validate(self): <TAB> if self.data.get(""encrypted"", True): <TAB> <TAB> key = self.data.get(""target_key"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise PolicyValidationError( <TAB> <TAB> <TAB> <TAB> ""Encrypted snapshot copy requires kms key on %s"" % (self.manager.data,) <TAB> <TAB> <TAB> ) <TAB> return self",false,if not key :,if key is None :,0.05,0.0
"def __init__(self, patch_files, patch_directories): <TAB> files = [] <TAB> files_data = {} <TAB> for filename_data in patch_files: <TAB> <TAB> if isinstance(filename_data, list): <TAB> <TAB> <TAB> filename, data = filename_data <TAB> <TAB> else: <TAB> <TAB> <TAB> filename = filename_data <TAB> <TAB> <TAB> data = None <TAB> <TAB> if not filename.startswith(os.sep): <TAB> <TAB> <TAB> filename = ""{0}{1}"".format(FakeState.deploy_dir, filename) <TAB> <TAB> files.append(filename) <TAB> <TAB> if data: <TAB> <TAB> <TAB> files_data[filename] = data <TAB> self.files = files <TAB> self.files_data = files_data <TAB> self.directories = patch_directories",false,if not filename . startswith ( os . sep ) :,"if isinstance ( filename_data , list ) :",0.03,0.0
"def validate_name_and_description(body, check_length=True): <TAB> for attribute in [""name"", ""description"", ""display_name"", ""display_description""]: <TAB> <TAB> value = body.get(attribute) <TAB> <TAB> if value is not None: <TAB> <TAB> <TAB> if isinstance(value, six.string_types): <TAB> <TAB> <TAB> <TAB> body[attribute] = value.strip() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> utils.check_string_length( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> body[attribute], attribute, min_length=0, max_length=255 <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> except exception.InvalidInput as error: <TAB> <TAB> <TAB> <TAB> <TAB> raise webob.exc.HTTPBadRequest(explanation=error.msg)",true,if check_length :,if check_length :,0.53,0.0
"def pick(items, sel): <TAB> for x, s in zip(items, sel): <TAB> <TAB> if match(s): <TAB> <TAB> <TAB> yield x <TAB> <TAB> elif not x.is_atom() and not s.is_atom(): <TAB> <TAB> <TAB> yield x.restructure(x.head, pick(x.leaves, s.leaves), evaluation)",true,elif not x . is_atom ( ) and not s . is_atom ( ) :,elif not x . is_atom ( ) and not s . is_atom ( ) :,1.0,0.0
"def wait_or_kill(self): <TAB> """"""Wait for the program to terminate, or kill it after 5s."""""" <TAB> if self.instance.poll() is None: <TAB> <TAB> # We try one more time to kill gracefully using Ctrl-C. <TAB> <TAB> logger.info(""Interrupting %s and waiting..."", self.coord) <TAB> <TAB> self.instance.send_signal(signal.SIGINT) <TAB> <TAB> # FIXME on py3 this becomes self.instance.wait(timeout=5) <TAB> <TAB> t = monotonic_time() <TAB> <TAB> while monotonic_time() - t < 5: <TAB> <TAB> <TAB> if self.instance.poll() is not None: <TAB> <TAB> <TAB> <TAB> logger.info(""Terminated %s."", self.coord) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> time.sleep(0.1) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.kill()",true,if self . instance . poll ( ) is not None :,if self . instance . poll ( ) is not None :,0.75,0.0
"def sort_collection(self, models, many): <TAB> ordering = self.ordering <TAB> if not many or not ordering: <TAB> <TAB> return models <TAB> for key in reversed(ordering): <TAB> <TAB> reverse = key[0] == ""-"" <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> key = key[1:] <TAB> <TAB> models = sorted(models, key=partial(deep_getattr, key=key), reverse=reverse) <TAB> return models",true,if reverse :,if reverse :,0.53,0.0
"def get_palette_for_custom_classes(self, class_names, palette=None): <TAB> if self.label_map is not None: <TAB> <TAB> # return subset of palette <TAB> <TAB> palette = [] <TAB> <TAB> for old_id, new_id in sorted(self.label_map.items(), key=lambda x: x[1]): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> palette.append(self.PALETTE[old_id]) <TAB> <TAB> palette = type(self.PALETTE)(palette) <TAB> elif palette is None: <TAB> <TAB> if self.PALETTE is None: <TAB> <TAB> <TAB> palette = np.random.randint(0, 255, size=(len(class_names), 3)) <TAB> <TAB> else: <TAB> <TAB> <TAB> palette = self.PALETTE <TAB> return palette",false,if new_id != - 1 :,if old_id in class_names :,0.03,0.0
"def _find_tcl_dir(): <TAB> lib_dirs = [os.path.dirname(_x) for _x in sys.path if _x.lower().endswith(""lib"")] <TAB> for lib_dir in lib_dirs: <TAB> <TAB> base_dir = os.path.join(lib_dir, TclLibrary.FOLDER) <TAB> <TAB> if os.path.exists(base_dir): <TAB> <TAB> <TAB> for root, _, files in os.walk(base_dir): <TAB> <TAB> <TAB> <TAB> if TclLibrary.INIT_TCL in files: <TAB> <TAB> <TAB> <TAB> <TAB> return root",true,if os . path . exists ( base_dir ) :,if os . path . exists ( base_dir ) :,0.75,0.0
"def __next__(self): <TAB> """"""Special paging functionality"""""" <TAB> if self.iter is None: <TAB> <TAB> self.iter = iter(self.objs) <TAB> try: <TAB> <TAB> return next(self.iter) <TAB> except StopIteration: <TAB> <TAB> self.iter = None <TAB> <TAB> self.objs = [] <TAB> <TAB> if int(self.page) < int(self.total_pages): <TAB> <TAB> <TAB> self.page += 1 <TAB> <TAB> <TAB> self._connection.get_response(self.action, self.params, self.page, self) <TAB> <TAB> <TAB> return next(self) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise",true,if int ( self . page ) < int ( self . total_pages ) :,if int ( self . page ) < int ( self . total_pages ) :,1.0,0.0
"def parse(cls, api, json): <TAB> lst = List(api) <TAB> setattr(lst, ""_json"", json) <TAB> for k, v in json.items(): <TAB> <TAB> if k == ""user"": <TAB> <TAB> <TAB> setattr(lst, k, User.parse(api, v)) <TAB> <TAB> elif k == ""created_at"": <TAB> <TAB> <TAB> setattr(lst, k, parse_datetime(v)) <TAB> <TAB> else: <TAB> <TAB> <TAB> setattr(lst, k, v) <TAB> return lst",true,"elif k == ""created_at"" :","elif k == ""created_at"" :",1.0,0.0
"def real_type(self): <TAB> # Find the real type representation by updating it as required <TAB> real_type = self.type <TAB> if self.flag_indicator: <TAB> <TAB> real_type = ""#"" <TAB> if self.is_vector: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> real_type = ""Vector<{}>"".format(real_type) <TAB> <TAB> else: <TAB> <TAB> <TAB> real_type = ""vector<{}>"".format(real_type) <TAB> if self.is_generic: <TAB> <TAB> real_type = ""!{}"".format(real_type) <TAB> if self.is_flag: <TAB> <TAB> real_type = ""flags.{}?{}"".format(self.flag_index, real_type) <TAB> return real_type",false,if self . use_vector_id :,if self . is_vector_type :,0.39,0.0
"def check_fs(path): <TAB> with open(path, ""rb"") as f: <TAB> <TAB> code = python_bytes_to_unicode(f.read(), errors=""replace"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> module = _load_module(evaluator, path, code) <TAB> <TAB> <TAB> module_name = sys_path.dotted_path_in_sys_path( <TAB> <TAB> <TAB> <TAB> evaluator.project.sys_path, path <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if module_name is not None: <TAB> <TAB> <TAB> <TAB> add_module(evaluator, module_name, module) <TAB> <TAB> <TAB> return module",false,if name in code :,if code is not None :,0.16,0.0
"def infoCalendar(users): <TAB> calendarId = normalizeCalendarId(sys.argv[5], checkPrimary=True) <TAB> i = 0 <TAB> count = len(users) <TAB> for user in users: <TAB> <TAB> i += 1 <TAB> <TAB> user, cal = buildCalendarGAPIObject(user) <TAB> <TAB> if not cal: <TAB> <TAB> <TAB> continue <TAB> <TAB> result = gapi.call( <TAB> <TAB> <TAB> cal.calendarList(), ""get"", soft_errors=True, calendarId=calendarId <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(f""User: {user}, Calendar:{display.current_count(i, count)}"") <TAB> <TAB> <TAB> _showCalendar(result, 1, 1)",true,if result :,if result :,0.53,0.0
"def set_hidestate_input_sockets_to_cope_with_switchnum(self): <TAB> tndict = get_indices_that_should_be_visible(self.node_state) <TAB> for key, value in tndict.items(): <TAB> <TAB> socket = self.inputs[key] <TAB> <TAB> desired_hide_state = not (value) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> socket.hide_safe = desired_hide_state",false,if not socket . hide == desired_hide_state :,if socket . hide_safe :,0.04,0.0
"def get_class_name(item): <TAB> class_name, module_name = None, None <TAB> for parent in reversed(item.listchain()): <TAB> <TAB> if isinstance(parent, pytest.Class): <TAB> <TAB> <TAB> class_name = parent.name <TAB> <TAB> elif isinstance(parent, pytest.Module): <TAB> <TAB> <TAB> module_name = parent.module.__name__ <TAB> <TAB> <TAB> break <TAB> # heuristic: <TAB> # - better to group gpu and task tests, since tests from those modules <TAB> #   are likely to share caching more <TAB> # - split up the rest by class name because slow tests tend to be in <TAB> #   the same module <TAB> if class_name and "".tasks."" not in module_name: <TAB> <TAB> return ""{}.{}"".format(module_name, class_name) <TAB> else: <TAB> <TAB> return module_name",true,"elif isinstance ( parent , pytest . Module ) :","elif isinstance ( parent , pytest . Module ) :",0.75,0.0
"def run(self): <TAB> versions = versioneer.get_versions() <TAB> tempdir = tempfile.mkdtemp() <TAB> generated = os.path.join(tempdir, ""rundemo"") <TAB> with open(generated, ""wb"") as f: <TAB> <TAB> for line in open(""src/rundemo-template"", ""rb""): <TAB> <TAB> <TAB> if line.strip().decode(""ascii"") == ""#versions"": <TAB> <TAB> <TAB> <TAB> f.write((""versions = %r\n"" % (versions,)).encode(""ascii"")) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> f.write(line) <TAB> self.scripts = [generated] <TAB> rc = build_scripts.run(self) <TAB> os.unlink(generated) <TAB> os.rmdir(tempdir) <TAB> return rc",true,"if line . strip ( ) . decode ( ""ascii"" ) == ""#versions"" :","if line . strip ( ) . decode ( ""ascii"" ) == ""#versions"" :",0.75,0.0
"def get_user_context(request, escape=False): <TAB> if isinstance(request, HttpRequest): <TAB> <TAB> user = getattr(request, ""user"", None) <TAB> <TAB> result = {""ip_address"": request.META[""REMOTE_ADDR""]} <TAB> <TAB> if user and user.is_authenticated(): <TAB> <TAB> <TAB> result.update( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> ""email"": user.email, <TAB> <TAB> <TAB> <TAB> <TAB> ""id"": user.id, <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if user.name: <TAB> <TAB> <TAB> <TAB> result[""name""] = user.name <TAB> else: <TAB> <TAB> result = {} <TAB> return mark_safe(json.dumps(result))",true,if user and user . is_authenticated ( ) :,if user and user . is_authenticated ( ) :,0.75,0.0
"def tokens_to_spans() -> Iterable[Tuple[str, Optional[Style]]]: <TAB> """"""Convert tokens to spans."""""" <TAB> tokens = iter(line_tokenize()) <TAB> line_no = 0 <TAB> _line_start = line_start - 1 <TAB> # Skip over tokens until line start <TAB> while line_no < _line_start: <TAB> <TAB> _token_type, token = next(tokens) <TAB> <TAB> yield (token, None) <TAB> <TAB> if token.endswith(""\n""): <TAB> <TAB> <TAB> line_no += 1 <TAB> # Generate spans until line end <TAB> for token_type, token in tokens: <TAB> <TAB> yield (token, _get_theme_style(token_type)) <TAB> <TAB> if token.endswith(""\n""): <TAB> <TAB> <TAB> line_no += 1 <TAB> <TAB> <TAB> if line_no >= line_end: <TAB> <TAB> <TAB> <TAB> break",true,"if token . endswith ( ""\n"" ) :","if token . endswith ( ""\n"" ) :",0.75,0.0
"def encode(self, encodeFun, value, defMode, maxChunkSize): <TAB> substrate, isConstructed = self.encodeValue(encodeFun, value, defMode, maxChunkSize) <TAB> tagSet = value.getTagSet() <TAB> if tagSet: <TAB> <TAB><IF-STMT>  # primitive form implies definite mode <TAB> <TAB> <TAB> defMode = 1 <TAB> <TAB> return ( <TAB> <TAB> <TAB> self.encodeTag(tagSet[-1], isConstructed) <TAB> <TAB> <TAB> + self.encodeLength(len(substrate), defMode) <TAB> <TAB> <TAB> + substrate <TAB> <TAB> <TAB> + self._encodeEndOfOctets(encodeFun, defMode) <TAB> <TAB> ) <TAB> else: <TAB> <TAB> return substrate  # untagged value",false,if not isConstructed :,if defMode == 0 :,0.04,0.0
def _run(self): <TAB> while True: <TAB> <TAB> request = self._requests.get() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.shutdown() <TAB> <TAB> <TAB> break <TAB> <TAB> self.process(request) <TAB> <TAB> self._requests.task_done(),true,if request is None :,if request is None :,0.75,0.0
"def _decode_payload(self, payload): <TAB> # we need to decrypt it <TAB> if payload[""enc""] == ""aes"": <TAB> <TAB> try: <TAB> <TAB> <TAB> payload[""load""] = self.crypticle.loads(payload[""load""]) <TAB> <TAB> except salt.crypt.AuthenticationError: <TAB> <TAB> <TAB> if not self._update_aes(): <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> payload[""load""] = self.crypticle.loads(payload[""load""]) <TAB> return payload",true,if not self . _update_aes ( ) :,if not self . _update_aes ( ) :,0.75,0.0
"def test_row(self, row): <TAB> for idx, test in self.patterns.items(): <TAB> <TAB> try: <TAB> <TAB> <TAB> value = row[idx] <TAB> <TAB> except IndexError: <TAB> <TAB> <TAB> value = """" <TAB> <TAB> result = test(value) <TAB> <TAB> if self.any_match: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return not self.inverse  # True <TAB> <TAB> else: <TAB> <TAB> <TAB> if not result: <TAB> <TAB> <TAB> <TAB> return self.inverse  # False <TAB> if self.any_match: <TAB> <TAB> return self.inverse  # False <TAB> else: <TAB> <TAB> return not self.inverse  # True",true,if result :,if result :,0.53,0.0
"def setup_parameter_node(self, param_node): <TAB> if param_node.bl_idname == ""SvNumberNode"": <TAB> <TAB> if self.use_prop or self.get_prop_name(): <TAB> <TAB> <TAB> value = self.sv_get()[0][0] <TAB> <TAB> <TAB> print(""V"", value) <TAB> <TAB> <TAB> if isinstance(value, int): <TAB> <TAB> <TAB> <TAB> param_node.selected_mode = ""int"" <TAB> <TAB> <TAB> <TAB> param_node.int_ = value <TAB> <TAB> <TAB> elif isinstance(value, float): <TAB> <TAB> <TAB> <TAB> param_node.selected_mode = ""float"" <TAB> <TAB> <TAB> <TAB> param_node.float_ = value",false,"elif isinstance ( value , float ) :",if self . use_prop or self . get_prop_name ( ) :,0.08,0.0
"def iter_modules(self, by_clients=False, clients_filter=None): <TAB> """"""iterate over all modules"""""" <TAB> clients = None <TAB> if by_clients: <TAB> <TAB> clients = self.get_clients(clients_filter) <TAB> <TAB> if not clients: <TAB> <TAB> <TAB> return <TAB> self._refresh_modules() <TAB> for module_name in self.modules: <TAB> <TAB> try: <TAB> <TAB> <TAB> module = self.get_module(module_name) <TAB> <TAB> except PupyModuleDisabled: <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> for client in clients: <TAB> <TAB> <TAB> <TAB> if module.is_compatible_with(client): <TAB> <TAB> <TAB> <TAB> <TAB> yield module <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> yield module",false,if clients is not None :,if clients :,0.05,0.0
"def filter_pricing_rule_based_on_condition(pricing_rules, doc=None): <TAB> filtered_pricing_rules = [] <TAB> if doc: <TAB> <TAB> for pricing_rule in pricing_rules: <TAB> <TAB> <TAB> if pricing_rule.condition: <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> if frappe.safe_eval(pricing_rule.condition, None, doc.as_dict()): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> filtered_pricing_rules.append(pricing_rule) <TAB> <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> filtered_pricing_rules.append(pricing_rule) <TAB> else: <TAB> <TAB> filtered_pricing_rules = pricing_rules <TAB> return filtered_pricing_rules",true,"if frappe . safe_eval ( pricing_rule . condition , None , doc . as_dict ( ) ) :","if frappe . safe_eval ( pricing_rule . condition , None , doc . as_dict ( ) ) :",0.75,0.0
"def build_query_string(kv_data, ignore_none=True): <TAB> # {""a"": 1, ""b"": ""test""} -> ""?a=1&b=test"" <TAB> query_string = """" <TAB> for k, v in kv_data.iteritems(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if query_string != """": <TAB> <TAB> <TAB> query_string += ""&"" <TAB> <TAB> else: <TAB> <TAB> <TAB> query_string = ""?"" <TAB> <TAB> query_string += k + ""="" + str(v) <TAB> return query_string",false,if ignore_none is True and kv_data [ k ] is None :,if ignore_none and k in ignore_none :,0.17,0.0
"def sample(self, **config): <TAB> """"""Sample a configuration from this search space."""""" <TAB> ret = {} <TAB> ret.update(self.data) <TAB> kwspaces = self.kwspaces <TAB> kwspaces.update(config) <TAB> striped_keys = [k.split(SPLITTER)[0] for k in config.keys()] <TAB> for k, v in kwspaces.items(): <TAB> <TAB> if k in striped_keys: <TAB> <TAB> <TAB> if isinstance(v, NestedSpace): <TAB> <TAB> <TAB> <TAB> sub_config = _strip_config_space(config, prefix=k) <TAB> <TAB> <TAB> <TAB> ret[k] = v.sample(**sub_config) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> ret[k] = v <TAB> return ret",true,"if isinstance ( v , NestedSpace ) :","if isinstance ( v , NestedSpace ) :",0.75,0.0
"def task_failed(self, task_id, hostname, reason): <TAB> logger.debug(""task %d failed with message %s"", task_id, str(reason)) <TAB> if hostname in self.host_dict: <TAB> <TAB> host_status = self.host_dict[hostname] <TAB> <TAB> host_status.task_failed(task_id) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.task_host_failed_dict[task_id] = set() <TAB> <TAB> self.task_host_failed_dict[task_id].add(hostname)",true,if task_id not in self . task_host_failed_dict :,if task_id not in self . task_host_failed_dict :,0.75,0.0
"def match(path): <TAB> for pat, _type, _property, default_title in patterns: <TAB> <TAB> m = web.re_compile(""^"" + pat).match(path) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> prefix = m.group() <TAB> <TAB> <TAB> extra = web.lstrips(path, prefix) <TAB> <TAB> <TAB> tokens = extra.split(""/"", 2) <TAB> <TAB> <TAB> # `extra` starts with ""/"". So first token is always empty. <TAB> <TAB> <TAB> middle = web.listget(tokens, 1, """") <TAB> <TAB> <TAB> suffix = web.listget(tokens, 2, """") <TAB> <TAB> <TAB> if suffix: <TAB> <TAB> <TAB> <TAB> suffix = ""/"" + suffix <TAB> <TAB> <TAB> return _type, _property, default_title, prefix, middle, suffix <TAB> return None, None, None, None, None, None",true,if m :,if m :,0.53,0.0
"def _get_cached_resources(self, ids): <TAB> key = self.get_cache_key(None) <TAB> if self._cache.load(): <TAB> <TAB> resources = self._cache.get(key) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.log.debug(""Using cached results for get_resources"") <TAB> <TAB> <TAB> m = self.get_model() <TAB> <TAB> <TAB> id_set = set(ids) <TAB> <TAB> <TAB> return [r for r in resources if r[m.id] in id_set] <TAB> return None",false,if resources is not None :,if resources :,0.05,0.0
"def has_api_behaviour(self, protocol): <TAB> config = get_config() <TAB> try: <TAB> <TAB> r = self.session.get( <TAB> <TAB> <TAB> f""{protocol}://{self.event.host}:{self.event.port}"", <TAB> <TAB> <TAB> timeout=config.network_timeout, <TAB> <TAB> ) <TAB> <TAB> if (""k8s"" in r.text) or ('""code""' in r.text and r.status_code != 200): <TAB> <TAB> <TAB> return True <TAB> except requests.exceptions.SSLError: <TAB> <TAB> logger.debug( <TAB> <TAB> <TAB> f""{[protocol]} protocol not accepted on {self.event.host}:{self.event.port}"" <TAB> <TAB> ) <TAB> except Exception: <TAB> <TAB> logger.debug( <TAB> <TAB> <TAB> f""Failed probing {self.event.host}:{self.event.port}"", exc_info=True <TAB> <TAB> )",true,"if ( ""k8s"" in r . text ) or ( '""code""' in r . text and r . status_code != 200 ) :","if ( ""k8s"" in r . text ) or ( '""code""' in r . text and r . status_code != 200 ) :",1.0,0.0
"def get_file_type(self, context, parent_context=None): <TAB> file_type = context.get(self.file_type_name, None) <TAB> if file_type == """": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> file_type = parent_context.get(self.file_type_name, self.default_file_type) <TAB> <TAB> else: <TAB> <TAB> <TAB> file_type = self.default_file_type <TAB> return file_type",true,if parent_context :,if parent_context :,0.53,0.0
"def selectionToChunks(self, remove=False, add=False): <TAB> box = self.selectionBox() <TAB> if box: <TAB> <TAB> if box == self.level.bounds: <TAB> <TAB> <TAB> self.selectedChunks = set(self.level.allChunks) <TAB> <TAB> <TAB> return <TAB> <TAB> selectedChunks = self.selectedChunks <TAB> <TAB> boxedChunks = set(box.chunkPositions) <TAB> <TAB> if boxedChunks.issubset(selectedChunks): <TAB> <TAB> <TAB> remove = True <TAB> <TAB> if remove and not add: <TAB> <TAB> <TAB> selectedChunks.difference_update(boxedChunks) <TAB> <TAB> else: <TAB> <TAB> <TAB> selectedChunks.update(boxedChunks) <TAB> self.selectionTool.selectNone()",true,if boxedChunks . issubset ( selectedChunks ) :,if boxedChunks . issubset ( selectedChunks ) :,0.75,0.0
"def _run_split_on_punc(self, text, never_split=None): <TAB> """"""Splits punctuation on a piece of text."""""" <TAB> if never_split is not None and text in never_split: <TAB> <TAB> return [text] <TAB> chars = list(text) <TAB> i = 0 <TAB> start_new_word = True <TAB> output = [] <TAB> while i < len(chars): <TAB> <TAB> char = chars[i] <TAB> <TAB> if _is_punctuation(char): <TAB> <TAB> <TAB> output.append([char]) <TAB> <TAB> <TAB> start_new_word = True <TAB> <TAB> else: <TAB> <TAB> <TAB> if start_new_word: <TAB> <TAB> <TAB> <TAB> output.append([]) <TAB> <TAB> <TAB> start_new_word = False <TAB> <TAB> <TAB> output[-1].append(char) <TAB> <TAB> i += 1 <TAB> return ["""".join(x) for x in output]",true,if _is_punctuation ( char ) :,if _is_punctuation ( char ) :,0.75,0.0
"def _save_images(notebook): <TAB> if os.getenv(""NB_NO_IMAGES"") == ""1"": <TAB> <TAB> return <TAB> logged = False <TAB> for filename, img_bytes in _iter_notebook_images(notebook): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> log.info(""Saving images"") <TAB> <TAB> <TAB> logged = True <TAB> <TAB> with open(filename, ""wb"") as f: <TAB> <TAB> <TAB> f.write(img_bytes)",true,if not logged :,if not logged :,0.75,0.0
"def pickPath(self, color): <TAB> self.path[color] = () <TAB> currentPos = self.starts[color] <TAB> while True: <TAB> <TAB> minDist = None <TAB> <TAB> minGuide = None <TAB> <TAB> for guide in self.guides[color]: <TAB> <TAB> <TAB> guideDist = dist(currentPos, guide) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> minDist = guideDist <TAB> <TAB> <TAB> <TAB> minGuide = guide <TAB> <TAB> if dist(currentPos, self.ends[color]) == 1: <TAB> <TAB> <TAB> return <TAB> <TAB> if minGuide == None: <TAB> <TAB> <TAB> return <TAB> <TAB> self.path[color] = self.path[color] + (minGuide,) <TAB> <TAB> currentPos = minGuide <TAB> <TAB> self.guides[color].remove(minGuide)",false,if minDist == None or guideDist < minDist :,if minDist == None :,0.16,0.0
"def _terminal_messenger(tp=""write"", msg="""", out=sys.stdout): <TAB> try: <TAB> <TAB> if tp == ""write"": <TAB> <TAB> <TAB> out.write(msg) <TAB> <TAB> elif tp == ""flush"": <TAB> <TAB> <TAB> out.flush() <TAB> <TAB> elif tp == ""write_flush"": <TAB> <TAB> <TAB> out.write(msg) <TAB> <TAB> <TAB> out.flush() <TAB> <TAB> elif tp == ""print"": <TAB> <TAB> <TAB> print(msg, file=out) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""Unsupported type: "" + tp) <TAB> except IOError as e: <TAB> <TAB> logger.critical(""{}: {}"".format(type(e).__name__, ucd(e))) <TAB> <TAB> pass",false,"if tp == ""write"" :","elif tp == ""flush"" :",0.06,0.0
"def __new__(mcs, name, bases, attrs): <TAB> include_profile = include_trace = include_garbage = True <TAB> bases = list(bases) <TAB> if name == ""SaltLoggingClass"": <TAB> <TAB> for base in bases: <TAB> <TAB> <TAB> if hasattr(base, ""trace""): <TAB> <TAB> <TAB> <TAB> include_trace = False <TAB> <TAB> <TAB> if hasattr(base, ""garbage""): <TAB> <TAB> <TAB> <TAB> include_garbage = False <TAB> if include_profile: <TAB> <TAB> bases.append(LoggingProfileMixin) <TAB> if include_trace: <TAB> <TAB> bases.append(LoggingTraceMixin) <TAB> if include_garbage: <TAB> <TAB> bases.append(LoggingGarbageMixin) <TAB> return super(LoggingMixinMeta, mcs).__new__(mcs, name, tuple(bases), attrs)",true,"if hasattr ( base , ""trace"" ) :","if hasattr ( base , ""trace"" ) :",0.75,0.0
"def generatePidEncryptionTable(): <TAB> table = [] <TAB> for counter1 in range(0, 0x100): <TAB> <TAB> value = counter1 <TAB> <TAB> for counter2 in range(0, 8): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> value = value >> 1 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> value = value >> 1 <TAB> <TAB> <TAB> <TAB> value = value ^ 0xEDB88320 <TAB> <TAB> table.append(value) <TAB> return table",false,if value & 1 == 0 :,if counter1 == counter2 :,0.02,0.0
"def pytest_collection_modifyitems(items): <TAB> for item in items: <TAB> <TAB> if item.nodeid.startswith(""tests/params""): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> item.add_marker(pytest.mark.stage(""unit"")) <TAB> <TAB> <TAB> if ""init"" not in item.keywords: <TAB> <TAB> <TAB> <TAB> item.add_marker(pytest.mark.init(rng_seed=123))",true,"if ""stage"" not in item . keywords :","if ""stage"" not in item . keywords :",0.75,0.0
"def python_value(self, value): <TAB> if value: <TAB> <TAB> if isinstance(value, basestring): <TAB> <TAB> <TAB> pp = lambda x: x.time() <TAB> <TAB> <TAB> return format_date_time(value, self.formats, pp) <TAB> <TAB> elif isinstance(value, datetime.datetime): <TAB> <TAB> <TAB> return value.time() <TAB> if value is not None and isinstance(value, datetime.timedelta): <TAB> <TAB> return (datetime.datetime.min + value).time() <TAB> return value",false,"elif isinstance ( value , datetime . datetime ) :","if isinstance ( value , basestring ) :",0.16,0.0
"def list_interesting_hosts(self): <TAB> hosts = [] <TAB> targets = self.target[""other""] <TAB> for target in targets: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> hosts.append( <TAB> <TAB> <TAB> <TAB> {""ip"": target.ip, ""description"": target.domain + "" / "" + target.name} <TAB> <TAB> <TAB> ) <TAB> return hosts",false,if self . is_interesting ( target ) and target . status and target . status != 400 :,if target . domain :,0.01,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB> if tt == 10: <TAB> <TAB> <TAB> length = d.getVarInt32() <TAB> <TAB> <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB> <TAB> <TAB> d.skip(length) <TAB> <TAB> <TAB> self.mutable_cost().TryMerge(tmp) <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.add_version(d.getVarInt64()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0: <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",false,if tt == 24 :,if tt == 16 :,0.39,0.0
"def _wait_for_finish(self) -> PollExitResponse: <TAB> while True: <TAB> <TAB> if self._backend: <TAB> <TAB> <TAB> poll_exit_resp = self._backend.interface.communicate_poll_exit() <TAB> <TAB> logger.info(""got exit ret: %s"", poll_exit_resp) <TAB> <TAB> if poll_exit_resp: <TAB> <TAB> <TAB> done = poll_exit_resp.done <TAB> <TAB> <TAB> pusher_stats = poll_exit_resp.pusher_stats <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self._on_finish_progress(pusher_stats, done) <TAB> <TAB> <TAB> if done: <TAB> <TAB> <TAB> <TAB> return poll_exit_resp <TAB> <TAB> time.sleep(2)",true,if pusher_stats :,if pusher_stats :,0.53,0.0
"def listing_items(method): <TAB> marker = None <TAB> once = True <TAB> items = [] <TAB> while once or items: <TAB> <TAB> for i in items: <TAB> <TAB> <TAB> yield i <TAB> <TAB> if once or marker: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> items = method(parms={""marker"": marker}) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> items = method() <TAB> <TAB> <TAB> if len(items) == 10000: <TAB> <TAB> <TAB> <TAB> marker = items[-1] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> marker = None <TAB> <TAB> <TAB> once = False <TAB> <TAB> else: <TAB> <TAB> <TAB> items = []",true,if marker :,if marker :,0.53,0.0
"def call(monad, *args): <TAB> for arg, name in izip(args, (""hour"", ""minute"", ""second"", ""microsecond"")): <TAB> <TAB> if not isinstance(arg, NumericMixin) or arg.type is not int: <TAB> <TAB> <TAB> throw( <TAB> <TAB> <TAB> <TAB> TypeError, <TAB> <TAB> <TAB> <TAB> ""'%s' argument of time(...) function must be of 'int' type. Got: %r"" <TAB> <TAB> <TAB> <TAB> % (name, type2str(arg.type)), <TAB> <TAB> <TAB> ) <TAB> <TAB> if not isinstance(arg, ConstMonad): <TAB> <TAB> <TAB> throw(NotImplementedError) <TAB> return ConstMonad.new(time(*tuple(arg.value for arg in args)))",true,"if not isinstance ( arg , ConstMonad ) :","if not isinstance ( arg , ConstMonad ) :",0.75,0.0
"def group_by_sign(seq, slop=sin(pi / 18), key=lambda x: x): <TAB> sign = None <TAB> subseq = [] <TAB> for i in seq: <TAB> <TAB> ki = key(i) <TAB> <TAB> if sign is None: <TAB> <TAB> <TAB> subseq.append(i) <TAB> <TAB> <TAB> if ki != 0: <TAB> <TAB> <TAB> <TAB> sign = ki / abs(ki) <TAB> <TAB> else: <TAB> <TAB> <TAB> subseq.append(i) <TAB> <TAB> <TAB> if sign * ki < -slop: <TAB> <TAB> <TAB> <TAB> sign = ki / abs(ki) <TAB> <TAB> <TAB> <TAB> yield subseq <TAB> <TAB> <TAB> <TAB> subseq = [i] <TAB> if subseq: <TAB> <TAB> yield subseq",true,if sign * ki < - slop :,if sign * ki < - slop :,0.75,0.0
"def walk_links(self): <TAB> link_info_list = [] <TAB> for item in self.content: <TAB> <TAB> if isinstance(item, Link): <TAB> <TAB> <TAB> link_info = LinkInfo(link=item, name=item.name, sections=()) <TAB> <TAB> <TAB> link_info_list.append(link_info) <TAB> <TAB> else: <TAB> <TAB> <TAB> link_info_list.extend(item.walk_links()) <TAB> return link_info_list",true,"if isinstance ( item , Link ) :","if isinstance ( item , Link ) :",0.75,0.0
"def get_subkeys(self, key): <TAB> # TODO: once we revamp the registry emulation, <TAB> # make this better <TAB> parent_path = key.get_path() <TAB> subkeys = [] <TAB> for k in self.keys: <TAB> <TAB> test_path = k.get_path() <TAB> <TAB> if test_path.lower().startswith(parent_path.lower()): <TAB> <TAB> <TAB> sub = test_path[len(parent_path) :] <TAB> <TAB> <TAB> if sub.startswith(""\\""): <TAB> <TAB> <TAB> <TAB> sub = sub[1:] <TAB> <TAB> <TAB> end_slash = sub.find(""\\"") <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> sub = sub[:end_slash] <TAB> <TAB> <TAB> if not sub: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> subkeys.append(sub) <TAB> return subkeys",false,if end_slash >= 0 :,if end_slash > - 1 :,0.06,0.0
"def load_dict(dict_path, reverse=False): <TAB> word_dict = {} <TAB> with open(dict_path, ""rb"") as fdict: <TAB> <TAB> for idx, line in enumerate(fdict): <TAB> <TAB> <TAB> line = cpt.to_text(line) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> word_dict[idx] = line.strip(""\n"") <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> word_dict[line.strip(""\n"")] = idx <TAB> return word_dict",true,if reverse :,if reverse :,0.53,0.0
"def test_network(coords, feats, model, batch_sizes, forward_only=True): <TAB> for batch_size in batch_sizes: <TAB> <TAB> bcoords = batched_coordinates([coords for i in range(batch_size)]) <TAB> <TAB> bfeats = torch.cat([feats for i in range(batch_size)], 0) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> with torch.no_grad(): <TAB> <TAB> <TAB> <TAB> time, length = forward(bcoords, bfeats, model) <TAB> <TAB> else: <TAB> <TAB> <TAB> time, length = train(bcoords, bfeats, model) <TAB> <TAB> print(f""{net.__name__}\t{voxel_size}\t{batch_size}\t{length}\t{time}"") <TAB> <TAB> torch.cuda.empty_cache()",true,if forward_only :,if forward_only :,0.53,0.0
"def markUVs(self, indices=None): <TAB> if isinstance(indices, tuple): <TAB> <TAB> indices = indices[0] <TAB> ntexco = len(self.texco) <TAB> if indices is None: <TAB> <TAB> self.utexc = True <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.utexc = np.zeros(ntexco, dtype=bool) <TAB> <TAB> if self.utexc is not True: <TAB> <TAB> <TAB> self.utexc[indices] = True",false,if self . utexc is False :,if self . utexc is None :,0.57,0.0
"def has_module(self, module, version): <TAB> has_module = False <TAB> for directory in self.directories: <TAB> <TAB> module_directory = join(directory, module) <TAB> <TAB> has_module_directory = isdir(module_directory) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> has_module = has_module_directory or exists( <TAB> <TAB> <TAB> <TAB> module_directory <TAB> <TAB> <TAB> )  # could be a bare modulefile <TAB> <TAB> else: <TAB> <TAB> <TAB> modulefile = join(module_directory, version) <TAB> <TAB> <TAB> has_modulefile = exists(modulefile) <TAB> <TAB> <TAB> has_module = has_module_directory and has_modulefile <TAB> <TAB> if has_module: <TAB> <TAB> <TAB> break <TAB> return has_module",false,if not version :,if version is None :,0.05,0.0
"def get_editops(self): <TAB> if not self._editops: <TAB> <TAB> if self._opcodes: <TAB> <TAB> <TAB> self._editops = editops(self._opcodes, self._str1, self._str2) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._editops = editops(self._str1, self._str2) <TAB> return self._editops",true,if self . _opcodes :,if self . _opcodes :,0.75,0.0
"def to_representation(self, data): <TAB> value = super(CredentialTypeSerializer, self).to_representation(data) <TAB> # translate labels and help_text for credential fields ""managed by Tower"" <TAB> if value.get(""managed_by_tower""): <TAB> <TAB> value[""name""] = _(value[""name""]) <TAB> <TAB> for field in value.get(""inputs"", {}).get(""fields"", []): <TAB> <TAB> <TAB> field[""label""] = _(field[""label""]) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> field[""help_text""] = _(field[""help_text""]) <TAB> return value",true,"if ""help_text"" in field :","if ""help_text"" in field :",0.75,0.0
"def sort_nested_dictionary_lists(d): <TAB> for k, v in d.items(): <TAB> <TAB> if isinstance(v, list): <TAB> <TAB> <TAB> for i in range(0, len(v)): <TAB> <TAB> <TAB> <TAB> if isinstance(v[i], dict): <TAB> <TAB> <TAB> <TAB> <TAB> v[i] = await sort_nested_dictionary_lists(v[i]) <TAB> <TAB> <TAB> <TAB> d[k] = sorted(v) <TAB> <TAB> if isinstance(v, dict): <TAB> <TAB> <TAB> d[k] = await sort_nested_dictionary_lists(v) <TAB> return d",false,"if isinstance ( v [ i ] , dict ) :","if isinstance ( v , dict ) :",0.24,0.0
"def messageSourceStamps(self, source_stamps): <TAB> text = """" <TAB> for ss in source_stamps: <TAB> <TAB> source = """" <TAB> <TAB> if ss[""branch""]: <TAB> <TAB> <TAB> source += ""[branch %s] "" % ss[""branch""] <TAB> <TAB> if ss[""revision""]: <TAB> <TAB> <TAB> source += str(ss[""revision""]) <TAB> <TAB> else: <TAB> <TAB> <TAB> source += ""HEAD"" <TAB> <TAB> if ss[""patch""] is not None: <TAB> <TAB> <TAB> source += "" (plus patch)"" <TAB> <TAB> discriminator = """" <TAB> <TAB> if ss[""codebase""]: <TAB> <TAB> <TAB> discriminator = "" '%s'"" % ss[""codebase""] <TAB> <TAB> text += ""Build Source Stamp%s: %s\n"" % (discriminator, source) <TAB> return text",false,"if ss [ ""patch"" ] is not None :","if ss [ ""branch"" ] :",0.12,0.0
"def fit_one(self, x): <TAB> for i, xi in x.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.median[i].update(xi) <TAB> <TAB> if self.with_scaling: <TAB> <TAB> <TAB> self.iqr[i].update(xi) <TAB> return self",false,if self . with_centering :,if self . with_scaling :,0.39,0.0
"def start_response(self, status, headers, exc_info=None): <TAB> if exc_info: <TAB> <TAB> try: <TAB> <TAB> <TAB> if self.started: <TAB> <TAB> <TAB> <TAB> six.reraise(exc_info[0], exc_info[1], exc_info[2]) <TAB> <TAB> finally: <TAB> <TAB> <TAB> exc_info = None <TAB> self.request.status = int(status[:3]) <TAB> for key, val in headers: <TAB> <TAB> if key.lower() == ""content-length"": <TAB> <TAB> <TAB> self.request.set_content_length(int(val)) <TAB> <TAB> elif key.lower() == ""content-type"": <TAB> <TAB> <TAB> self.request.content_type = val <TAB> <TAB> else: <TAB> <TAB> <TAB> self.request.headers_out.add(key, val) <TAB> return self.write",true,"if key . lower ( ) == ""content-length"" :","if key . lower ( ) == ""content-length"" :",0.75,0.0
"def _osp2ec(self, bytes): <TAB> compressed = self._from_bytes(bytes) <TAB> y = compressed >> self._bits <TAB> x = compressed & (1 << self._bits) - 1 <TAB> if x == 0: <TAB> <TAB> y = self._curve.b <TAB> else: <TAB> <TAB> result = self.sqrtp( <TAB> <TAB> <TAB> x ** 3 + self._curve.a * x + self._curve.b, self._curve.field.p <TAB> <TAB> ) <TAB> <TAB> if len(result) == 1: <TAB> <TAB> <TAB> y = result[0] <TAB> <TAB> elif len(result) == 2: <TAB> <TAB> <TAB> y1, y2 = result <TAB> <TAB> <TAB> y = y1 if (y1 & 1 == y) else y2 <TAB> <TAB> else: <TAB> <TAB> <TAB> return None <TAB> return ec.Point(self._curve, x, y)",true,elif len ( result ) == 2 :,elif len ( result ) == 2 :,0.75,0.0
"def trace(self, ee, rname): <TAB> print(type(self)) <TAB> self.traceIndent() <TAB> guess = """" <TAB> if self.inputState.guessing > 0: <TAB> <TAB> guess = "" [guessing]"" <TAB> print((ee + rname + guess)) <TAB> for i in xrange(1, self.k + 1): <TAB> <TAB> if i != 1: <TAB> <TAB> <TAB> print("", "") <TAB> <TAB> if self.LT(i): <TAB> <TAB> <TAB> v = self.LT(i).getText() <TAB> <TAB> else: <TAB> <TAB> <TAB> v = ""null"" <TAB> <TAB> print(""LA(%s) == %s"" % (i, v)) <TAB> print(""\n"")",true,if self . LT ( i ) :,if self . LT ( i ) :,0.75,0.0
"def _table_schema(self, table): <TAB> rows = self.db.execute_sql(""PRAGMA table_info('%s')"" % table).fetchall() <TAB> # Build list of fields from table information <TAB> result = {} <TAB> for _, name, data_type, not_null, _, primary_key in rows: <TAB> <TAB> parts = [data_type] <TAB> <TAB> if primary_key: <TAB> <TAB> <TAB> parts.append(""PRIMARY KEY"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> parts.append(""NOT NULL"") <TAB> <TAB> result[name] = "" "".join(parts) <TAB> return result",true,if not_null :,if not_null :,0.53,0.0
"def _parse_csrf(self, response): <TAB> for d in response: <TAB> <TAB> if d.startswith(""Set-Cookie:""): <TAB> <TAB> <TAB> for c in d.split("":"", 1)[1].split("";""): <TAB> <TAB> <TAB> <TAB> if c.strip().startswith(""CSRF-Token-""): <TAB> <TAB> <TAB> <TAB> <TAB> self._CSRFtoken = c.strip("" \r\n"") <TAB> <TAB> <TAB> <TAB> <TAB> log.verbose(""Got new cookie: %s"", self._CSRFtoken) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if self._CSRFtoken != None: <TAB> <TAB> <TAB> <TAB> break",false,if self . _CSRFtoken != None :,"if c . strip ( ) . startswith ( ""CSRF-Token-"" ) :",0.02,0.0
"def _update_from_item(self, row, download_item): <TAB> progress_stats = download_item.progress_stats <TAB> for key in self.columns: <TAB> <TAB> column = self.columns[key][0] <TAB> <TAB> if key == ""status"" and progress_stats[""playlist_index""]: <TAB> <TAB> <TAB> # Not the best place but we build the playlist status here <TAB> <TAB> <TAB> status = ""{0} {1}/{2}"".format( <TAB> <TAB> <TAB> <TAB> progress_stats[""status""], <TAB> <TAB> <TAB> <TAB> progress_stats[""playlist_index""], <TAB> <TAB> <TAB> <TAB> progress_stats[""playlist_size""], <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self.SetStringItem(row, column, status) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.SetStringItem(row, column, progress_stats[key])",true,"if key == ""status"" and progress_stats [ ""playlist_index"" ] :","if key == ""status"" and progress_stats [ ""playlist_index"" ] :",0.75,0.0
"def unmarshal_package_repositories(cls, data: Any) -> List[""PackageRepository""]: <TAB> repositories = list() <TAB> if data is not None: <TAB> <TAB> if not isinstance(data, list): <TAB> <TAB> <TAB> raise RuntimeError(f""invalid package-repositories: {data!r}"") <TAB> <TAB> for repository in data: <TAB> <TAB> <TAB> package_repo = cls.unmarshal(repository) <TAB> <TAB> <TAB> repositories.append(package_repo) <TAB> return repositories",true,"if not isinstance ( data , list ) :","if not isinstance ( data , list ) :",0.75,0.0
"def remove_message(e=None): <TAB> itop = scanbox.nearest(0) <TAB> sel = scanbox.curselection() <TAB> if not sel: <TAB> <TAB> dialog( <TAB> <TAB> <TAB> root, <TAB> <TAB> <TAB> ""No Message To Remove"", <TAB> <TAB> <TAB> ""Please select a message to remove"", <TAB> <TAB> <TAB> """", <TAB> <TAB> <TAB> 0, <TAB> <TAB> <TAB> ""OK"", <TAB> <TAB> ) <TAB> <TAB> return <TAB> todo = [] <TAB> for i in sel: <TAB> <TAB> line = scanbox.get(i) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> todo.append(string.atoi(scanparser.group(1))) <TAB> mhf.removemessages(todo) <TAB> rescan() <TAB> fixfocus(min(todo), itop)",false,if scanparser . match ( line ) >= 0 :,if line :,0.01,0.0
"def test_patches(): <TAB> print( <TAB> <TAB> ""Botocore version: {} aiohttp version: {}"".format( <TAB> <TAB> <TAB> botocore.__version__, aiohttp.__version__ <TAB> <TAB> ) <TAB> ) <TAB> success = True <TAB> for obj, digests in chain(_AIOHTTP_DIGESTS.items(), _API_DIGESTS.items()): <TAB> <TAB> digest = hashlib.sha1(getsource(obj).encode(""utf-8"")).hexdigest() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print( <TAB> <TAB> <TAB> <TAB> ""Digest of {}:{} not found in: {}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> obj.__qualname__, digest, digests <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> success = False <TAB> assert success",true,if digest not in digests :,if digest not in digests :,0.75,0.0
"def sample_admin_user(): <TAB> """"""List of iris messages"""""" <TAB> with iris_ctl.db_from_config(sample_db_config) as (conn, cursor): <TAB> <TAB> cursor.execute( <TAB> <TAB> <TAB> ""SELECT `name` FROM `target` JOIN `user` on `target`.`id` = `user`.`target_id` WHERE `user`.`admin` = TRUE LIMIT 1"" <TAB> <TAB> ) <TAB> <TAB> result = cursor.fetchone() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return result[0]",true,if result :,if result :,0.53,0.0
"def _addRightnames(groups, kerning, leftname, rightnames, includeAll=True): <TAB> if leftname in kerning: <TAB> <TAB> for rightname in kerning[leftname]: <TAB> <TAB> <TAB> if rightname[0] == ""@"": <TAB> <TAB> <TAB> <TAB> for rightname2 in groups[rightname]: <TAB> <TAB> <TAB> <TAB> <TAB> rightnames.add(rightname2) <TAB> <TAB> <TAB> <TAB> <TAB> if not includeAll: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> # TODO: in this case, pick the one rightname that has the highest <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> # ranking in glyphorder <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> rightnames.add(rightname)",true,"if rightname [ 0 ] == ""@"" :","if rightname [ 0 ] == ""@"" :",0.75,0.0
"def build(self, input_shape): <TAB> if isinstance(input_shape, list) and len(input_shape) == 2: <TAB> <TAB> self.data_mode = ""disjoint"" <TAB> <TAB> self.F = input_shape[0][-1] <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.data_mode = ""single"" <TAB> <TAB> else: <TAB> <TAB> <TAB> self.data_mode = ""batch"" <TAB> <TAB> self.F = input_shape[-1]",false,if len ( input_shape ) == 2 :,if len ( input_shape ) == 1 :,0.61,0.0
"def update_ranges(l, i): <TAB> for _range in l: <TAB> <TAB> # most common case: extend a range <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> _range[0] = i <TAB> <TAB> <TAB> merge_ranges(l) <TAB> <TAB> <TAB> return <TAB> <TAB> elif i == _range[1] + 1: <TAB> <TAB> <TAB> _range[1] = i <TAB> <TAB> <TAB> merge_ranges(l) <TAB> <TAB> <TAB> return <TAB> # somewhere outside of range proximity <TAB> l.append([i, i]) <TAB> l.sort(key=lambda x: x[0])",false,if i == _range [ 0 ] - 1 :,if i == _range [ 0 ] + 1 :,0.6,0.0
"def transform(a, cmds): <TAB> buf = a.split(""\n"") <TAB> for cmd in cmds: <TAB> <TAB> ctype, line, col, char = cmd <TAB> <TAB> if ctype == ""D"": <TAB> <TAB> <TAB> if char != ""\n"": <TAB> <TAB> <TAB> <TAB> buf[line] = buf[line][:col] + buf[line][col + len(char) :] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> buf[line] = buf[line] + buf[line + 1] <TAB> <TAB> <TAB> <TAB> del buf[line + 1] <TAB> <TAB> elif ctype == ""I"": <TAB> <TAB> <TAB> buf[line] = buf[line][:col] + char + buf[line][col:] <TAB> <TAB> buf = ""\n"".join(buf).split(""\n"") <TAB> return ""\n"".join(buf)",false,"if ctype == ""D"" :","if char != ""\n"" :",0.03,0.0
"def _media_files_drag_received(widget, context, x, y, data, info, timestamp): <TAB> uris = data.get_uris() <TAB> files = [] <TAB> for uri in uris: <TAB> <TAB> try: <TAB> <TAB> <TAB> uri_tuple = GLib.filename_from_uri(uri) <TAB> <TAB> except: <TAB> <TAB> <TAB> continue <TAB> <TAB> uri, unused = uri_tuple <TAB> <TAB> if os.path.exists(uri) == True: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> files.append(uri) <TAB> if len(files) == 0: <TAB> <TAB> return <TAB> open_dropped_files(files)",false,if utils . is_media_file ( uri ) == True :,if uri not in files :,0.01,0.0
"def __walk_proceed_remote_dir_act(self, r, args): <TAB> dirjs, filejs = args <TAB> j = r.json() <TAB> if ""list"" not in j: <TAB> <TAB> self.pd( <TAB> <TAB> <TAB> ""Key 'list' not found in the response of directory listing request:\n{}"".format( <TAB> <TAB> <TAB> <TAB> j <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> return const.ERequestFailed <TAB> paths = j[""list""] <TAB> for path in paths: <TAB> <TAB> if path[""isdir""]: <TAB> <TAB> <TAB> dirjs.append(path) <TAB> <TAB> else: <TAB> <TAB> <TAB> filejs.append(path) <TAB> return const.ENoError",true,"if path [ ""isdir"" ] :","if path [ ""isdir"" ] :",0.75,0.0
"def TaskUpdatesVerbose(task, progress): <TAB> if isinstance(task.info.progress, int): <TAB> <TAB> info = task.info <TAB> <TAB> if not isinstance(progress, str): <TAB> <TAB> <TAB> progress = ""%d%% (%s)"" % (info.progress, info.state) <TAB> <TAB> print( <TAB> <TAB> <TAB> ""Task %s (key:%s, desc:%s) - %s"" <TAB> <TAB> <TAB> % (info.name.info.name, info.key, info.description, progress) <TAB> <TAB> )",true,"if not isinstance ( progress , str ) :","if not isinstance ( progress , str ) :",0.75,0.0
"def dump_constants(header): <TAB> output = StringIO.StringIO() <TAB> output.write(header) <TAB> for attribute in dir(FSEvents): <TAB> <TAB> value = getattr(FSEvents, attribute) <TAB> <TAB> if attribute.startswith(""k"") and isinstance(value, int): <TAB> <TAB> <TAB> output.write("" <TAB>%s = %s\n"" % (attribute, hex(value))) <TAB> content = output.getvalue() <TAB> output.close() <TAB> return content",true,"if attribute . startswith ( ""k"" ) and isinstance ( value , int ) :","if attribute . startswith ( ""k"" ) and isinstance ( value , int ) :",0.75,0.0
"def _ensure_data_is_loaded( <TAB> self, <TAB> sql_object, <TAB> input_params, <TAB> stdin_file, <TAB> stdin_filename=""-"", <TAB> stop_after_analysis=False, ): <TAB> data_loads = [] <TAB> # Get each ""table name"" which is actually the file name <TAB> for filename in sql_object.qtable_names: <TAB> <TAB> data_load = self._load_data( <TAB> <TAB> <TAB> filename, <TAB> <TAB> <TAB> input_params, <TAB> <TAB> <TAB> stdin_file=stdin_file, <TAB> <TAB> <TAB> stdin_filename=stdin_filename, <TAB> <TAB> <TAB> stop_after_analysis=stop_after_analysis, <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> data_loads.append(data_load) <TAB> return data_loads",false,if data_load is not None :,if data_load :,0.05,0.0
"def _get_instantiation(self): <TAB> if self._data is None: <TAB> <TAB> f, l, c, o = c_object_p(), c_uint(), c_uint(), c_uint() <TAB> <TAB> SourceLocation_loc(self, byref(f), byref(l), byref(c), byref(o)) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> f = File(f) <TAB> <TAB> else: <TAB> <TAB> <TAB> f = None <TAB> <TAB> self._data = (f, int(l.value), int(c.value), int(c.value)) <TAB> return self._data",true,if f :,if f :,0.53,0.0
"def _get_all_info_lines(data): <TAB> infos = [] <TAB> for row in data: <TAB> <TAB> splitrow = row.split() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if splitrow[0] == ""INFO:"": <TAB> <TAB> <TAB> <TAB> infos.append("" "".join(splitrow[1:])) <TAB> return infos",false,if len ( splitrow ) > 0 :,if len ( splitrow ) > 1 :,0.61,0.0
"def _brush_modified_cb(self, settings): <TAB> """"""Updates the brush's base setting adjustments on brush changes"""""" <TAB> for cname in settings: <TAB> <TAB> adj = self.brush_adjustment.get(cname, None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> value = self.brush.get_base_value(cname) <TAB> <TAB> adj.set_value(value)",true,if adj is None :,if adj is None :,0.75,0.0
"def migrate_node_facts(facts): <TAB> """"""Migrate facts from various roles into node"""""" <TAB> params = { <TAB> <TAB> ""common"": (""dns_ip""), <TAB> } <TAB> if ""node"" not in facts: <TAB> <TAB> facts[""node""] = {} <TAB> # pylint: disable=consider-iterating-dictionary <TAB> for role in params.keys(): <TAB> <TAB> if role in facts: <TAB> <TAB> <TAB> for param in params[role]: <TAB> <TAB> <TAB> <TAB> if param in facts[role]: <TAB> <TAB> <TAB> <TAB> <TAB> facts[""node""][param] = facts[role].pop(param) <TAB> return facts",true,if param in facts [ role ] :,if param in facts [ role ] :,0.75,0.0
"def serialize_content_range(value): <TAB> if isinstance(value, (tuple, list)): <TAB> <TAB> if len(value) not in (2, 3): <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""When setting content_range to a list/tuple, it must "" <TAB> <TAB> <TAB> <TAB> ""be length 2 or 3 (not %r)"" % value <TAB> <TAB> <TAB> ) <TAB> <TAB> if len(value) == 2: <TAB> <TAB> <TAB> begin, end = value <TAB> <TAB> <TAB> length = None <TAB> <TAB> else: <TAB> <TAB> <TAB> begin, end, length = value <TAB> <TAB> value = ContentRange(begin, end, length) <TAB> value = str(value).strip() <TAB> if not value: <TAB> <TAB> return None <TAB> return value",true,"if len ( value ) not in ( 2 , 3 ) :","if len ( value ) not in ( 2 , 3 ) :",0.75,0.0
"def clean(self): <TAB> data = super().clean() <TAB> if data.get(""expires""): <TAB> <TAB> if isinstance(data[""expires""], date): <TAB> <TAB> <TAB> data[""expires""] = make_aware( <TAB> <TAB> <TAB> <TAB> datetime.combine(data[""expires""], time(hour=23, minute=59, second=59)), <TAB> <TAB> <TAB> <TAB> self.instance.event.timezone, <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> data[""expires""] = data[""expires""].replace(hour=23, minute=59, second=59) <TAB> <TAB> if data[""expires""] < now(): <TAB> <TAB> <TAB> raise ValidationError(_(""The new expiry date needs to be in the future."")) <TAB> return data",true,"if isinstance ( data [ ""expires"" ] , date ) :","if isinstance ( data [ ""expires"" ] , date ) :",0.75,0.0
"def _build(self, obj, stream, context): <TAB> if self.include_name: <TAB> <TAB> name, obj = obj <TAB> <TAB> for sc in self.subcons: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> sc._build(obj, stream, context) <TAB> <TAB> <TAB> <TAB> return <TAB> else: <TAB> <TAB> for sc in self.subcons: <TAB> <TAB> <TAB> stream2 = BytesIO() <TAB> <TAB> <TAB> context2 = context.__copy__() <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> sc._build(obj, stream2, context2) <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> context.__update__(context2) <TAB> <TAB> <TAB> <TAB> stream.write(stream2.getvalue()) <TAB> <TAB> <TAB> <TAB> return <TAB> raise SelectError(""no subconstruct matched"", obj)",false,if sc . name == name :,if name == sc . name :,0.37,0.0
"def records(account_id): <TAB> """"""Fetch locks data"""""" <TAB> s = boto3.Session() <TAB> table = s.resource(""dynamodb"").Table(""Sphere11.Dev.ResourceLocks"") <TAB> results = table.scan() <TAB> for r in results[""Items""]: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> r[""LockDate""] = datetime.fromtimestamp(r[""LockDate""]) <TAB> <TAB> if ""RevisionDate"" in r: <TAB> <TAB> <TAB> r[""RevisionDate""] = datetime.fromtimestamp(r[""RevisionDate""]) <TAB> print(tabulate.tabulate(results[""Items""], headers=""keys"", tablefmt=""fancy_grid""))",true,"if ""LockDate"" in r :","if ""LockDate"" in r :",0.75,0.0
"def visitIf(self, node, scope): <TAB> for test, body in node.tests: <TAB> <TAB> if isinstance(test, ast.Const): <TAB> <TAB> <TAB> if type(test.value) in self._const_types: <TAB> <TAB> <TAB> <TAB> if not test.value: <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> self.visit(test, scope) <TAB> <TAB> self.visit(body, scope) <TAB> if node.else_: <TAB> <TAB> self.visit(node.else_, scope)",false,if type ( test . value ) in self . _const_types :,"if isinstance ( test , ast . Const ) :",0.07,0.0
"def validate_max_discount(self): <TAB> if self.rate_or_discount == ""Discount Percentage"" and self.get(""items""): <TAB> <TAB> for d in self.items: <TAB> <TAB> <TAB> max_discount = frappe.get_cached_value(""Item"", d.item_code, ""max_discount"") <TAB> <TAB> <TAB> if max_discount and flt(self.discount_percentage) > flt(max_discount): <TAB> <TAB> <TAB> <TAB> throw( <TAB> <TAB> <TAB> <TAB> <TAB> _(""Max discount allowed for item: {0} is {1}%"").format( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self.item_code, max_discount <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> )",true,if max_discount and flt ( self . discount_percentage ) > flt ( max_discount ) :,if max_discount and flt ( self . discount_percentage ) > flt ( max_discount ) :,1.0,0.0
"def has_invalid_cce(yaml_file, product_yaml=None): <TAB> rule = yaml.open_and_macro_expand(yaml_file, product_yaml) <TAB> if ""identifiers"" in rule and rule[""identifiers""] is not None: <TAB> <TAB> for i_type, i_value in rule[""identifiers""].items(): <TAB> <TAB> <TAB> if i_type[0:3] == ""cce"": <TAB> <TAB> <TAB> <TAB> if not checks.is_cce_value_valid(""CCE-"" + str(i_value)): <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",false,"if not checks . is_cce_value_valid ( ""CCE-"" + str ( i_value ) ) :","if i_type [ 0 : 3 ] == ""cce"" :",0.01,0.0
"def parse_calendar_eras(data, calendar): <TAB> eras = data.setdefault(""eras"", {}) <TAB> for width in calendar.findall(""eras/*""): <TAB> <TAB> width_type = NAME_MAP[width.tag] <TAB> <TAB> widths = eras.setdefault(width_type, {}) <TAB> <TAB> for elem in width.getiterator(): <TAB> <TAB> <TAB> if elem.tag == ""era"": <TAB> <TAB> <TAB> <TAB> _import_type_text(widths, elem, type=int(elem.attrib.get(""type""))) <TAB> <TAB> <TAB> elif elem.tag == ""alias"": <TAB> <TAB> <TAB> <TAB> eras[width_type] = Alias( <TAB> <TAB> <TAB> <TAB> <TAB> _translate_alias([""eras"", width_type], elem.attrib[""path""]) <TAB> <TAB> <TAB> <TAB> )",true,"elif elem . tag == ""alias"" :","elif elem . tag == ""alias"" :",1.0,0.0
"def validate_grammar() -> None: <TAB> for fn in _NONTERMINAL_CONVERSIONS_SEQUENCE: <TAB> <TAB> fn_productions = get_productions(fn) <TAB> <TAB> if all(p.name == fn_productions[0].name for p in fn_productions): <TAB> <TAB> <TAB> # all the production names are the same, ensure that the `convert_` function <TAB> <TAB> <TAB> # is named correctly <TAB> <TAB> <TAB> production_name = fn_productions[0].name <TAB> <TAB> <TAB> expected_name = f""convert_{production_name}"" <TAB> <TAB> <TAB> if fn.__name__ != expected_name: <TAB> <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> <TAB> f""The conversion function for '{production_name}' "" <TAB> <TAB> <TAB> <TAB> <TAB> + f""must be called '{expected_name}', not '{fn.__name__}'."" <TAB> <TAB> <TAB> <TAB> )",true,if fn . __name__ != expected_name :,if fn . __name__ != expected_name :,0.75,0.0
"def split_ratio(row): <TAB> if float(row[""Numerator""]) > 0: <TAB> <TAB> if "":"" in row[""Splitratio""]: <TAB> <TAB> <TAB> n, m = row[""Splitratio""].split("":"") <TAB> <TAB> <TAB> return float(m) / float(n) <TAB> <TAB> else: <TAB> <TAB> <TAB> return eval(row[""Splitratio""]) <TAB> else: <TAB> <TAB> return 1",true,"if "":"" in row [ ""Splitratio"" ] :","if "":"" in row [ ""Splitratio"" ] :",0.75,0.0
"def _handle_def_errors(testdef): <TAB> # If the test generation had an error, raise <TAB> if testdef.error: <TAB> <TAB> if testdef.exception: <TAB> <TAB> <TAB> if isinstance(testdef.exception, Exception): <TAB> <TAB> <TAB> <TAB> raise testdef.exception <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise Exception(testdef.exception) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception(""Test parse failure"")",true,"if isinstance ( testdef . exception , Exception ) :","if isinstance ( testdef . exception , Exception ) :",0.75,0.0
"def _get_quota_availability(self): <TAB> quotas_ok = defaultdict(int) <TAB> qa = QuotaAvailability() <TAB> qa.queue(*[k for k, v in self._quota_diff.items() if v > 0]) <TAB> qa.compute(now_dt=self.now_dt) <TAB> for quota, count in self._quota_diff.items(): <TAB> <TAB> if count <= 0: <TAB> <TAB> <TAB> quotas_ok[quota] = 0 <TAB> <TAB> <TAB> break <TAB> <TAB> avail = qa.results[quota] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> quotas_ok[quota] = min(count, avail[1]) <TAB> <TAB> else: <TAB> <TAB> <TAB> quotas_ok[quota] = count <TAB> return quotas_ok",false,if avail [ 1 ] is not None and avail [ 1 ] < count :,if avail :,0.01,0.0
"def reverse(self): <TAB> """"""Reverse *IN PLACE*."""""" <TAB> li = self.leftindex <TAB> lb = self.leftblock <TAB> ri = self.rightindex <TAB> rb = self.rightblock <TAB> for i in range(self.len >> 1): <TAB> <TAB> lb.data[li], rb.data[ri] = rb.data[ri], lb.data[li] <TAB> <TAB> li += 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> lb = lb.rightlink <TAB> <TAB> <TAB> li = 0 <TAB> <TAB> ri -= 1 <TAB> <TAB> if ri < 0: <TAB> <TAB> <TAB> rb = rb.leftlink <TAB> <TAB> <TAB> ri = BLOCKLEN - 1",false,if li >= BLOCKLEN :,if li < BLOCKLEN :,0.08,0.0
"def __manipulate_item(self, item): <TAB> if self._Cursor__manipulate: <TAB> <TAB> db = self._Cursor__collection.database <TAB> <TAB> son = db._fix_outgoing(item, self._Cursor__collection) <TAB> else: <TAB> <TAB> son = item <TAB> if self.__wrap is not None: <TAB> <TAB> if self.__wrap.type_field in son: <TAB> <TAB> <TAB> return getattr(self._Cursor__collection, son[self.__wrap.type_field])(son) <TAB> <TAB> return self.__wrap(son, collection=self._Cursor__collection) <TAB> else: <TAB> <TAB> return son",true,if self . __wrap . type_field in son :,if self . __wrap . type_field in son :,0.75,0.0
"def apply_transforms(self): <TAB> """"""Apply all of the stored transforms, in priority order."""""" <TAB> self.document.reporter.attach_observer(self.document.note_transform_message) <TAB> while self.transforms: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # Unsorted initially, and whenever a transform is added. <TAB> <TAB> <TAB> self.transforms.sort() <TAB> <TAB> <TAB> self.transforms.reverse() <TAB> <TAB> <TAB> self.sorted = 1 <TAB> <TAB> priority, transform_class, pending, kwargs = self.transforms.pop() <TAB> <TAB> transform = transform_class(self.document, startnode=pending) <TAB> <TAB> transform.apply(**kwargs) <TAB> <TAB> self.applied.append((priority, transform_class, pending, kwargs))",false,if not self . sorted :,if self . sorted :,0.28,0.0
"def format_sql(sql, params): <TAB> rv = [] <TAB> if isinstance(params, dict): <TAB> <TAB> # convert sql with named parameters to sql with unnamed parameters <TAB> <TAB> conv = _FormatConverter(params) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> sql = sql_to_string(sql) <TAB> <TAB> <TAB> sql = sql % conv <TAB> <TAB> <TAB> params = conv.params <TAB> <TAB> else: <TAB> <TAB> <TAB> params = () <TAB> for param in params or (): <TAB> <TAB> if param is None: <TAB> <TAB> <TAB> rv.append(""NULL"") <TAB> <TAB> param = safe_repr(param) <TAB> <TAB> rv.append(param) <TAB> return sql, rv",false,if params :,if conv :,0.32,0.0
"def on_execution_item(self, cpath, execution): <TAB> if not isinstance(execution, dict): <TAB> <TAB> return <TAB> if ""executor"" in execution and execution.get(""executor"") != ""jmeter"": <TAB> <TAB> return <TAB> scenario = execution.get(""scenario"", None) <TAB><IF-STMT> <TAB> <TAB> return <TAB> if isinstance(scenario, str): <TAB> <TAB> scenario_name = scenario <TAB> <TAB> scenario = self.get_named_scenario(scenario_name) <TAB> <TAB> if not scenario: <TAB> <TAB> <TAB> scenario = None <TAB> <TAB> scenario_path = Path(""scenarios"", scenario_name) <TAB> else: <TAB> <TAB> scenario_path = cpath.copy() <TAB> <TAB> scenario_path.add_component(""scenario"") <TAB> if scenario is not None: <TAB> <TAB> self.check_jmeter_scenario(scenario_path, scenario)",true,if not scenario :,if not scenario :,0.75,0.0
"def _poll_ipc_requests(self) -> None: <TAB> try: <TAB> <TAB> if self._ipc_requests.empty(): <TAB> <TAB> <TAB> return <TAB> <TAB> while not self._ipc_requests.empty(): <TAB> <TAB> <TAB> args = self._ipc_requests.get() <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> for filename in args: <TAB> <TAB> <TAB> <TAB> <TAB> if os.path.isfile(filename): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self.get_editor_notebook().show_file(filename) <TAB> <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> <TAB> logger.exception(""Problem processing ipc request"", exc_info=e) <TAB> <TAB> self.become_active_window() <TAB> finally: <TAB> <TAB> self.after(50, self._poll_ipc_requests)",true,if os . path . isfile ( filename ) :,if os . path . isfile ( filename ) :,0.75,0.0
"def get_scroll_distance_to_element(driver, element): <TAB> try: <TAB> <TAB> scroll_position = driver.execute_script(""return window.scrollY;"") <TAB> <TAB> element_location = None <TAB> <TAB> element_location = element.location[""y""] <TAB> <TAB> element_location = element_location - 130 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> element_location = 0 <TAB> <TAB> distance = element_location - scroll_position <TAB> <TAB> return distance <TAB> except Exception: <TAB> <TAB> return 0",false,if element_location < 0 :,if element_location < 130 :,0.39,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB> if tt == 10: <TAB> <TAB> <TAB> self.set_access_token(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.set_expiration_time(d.getVarInt64()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0: <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 16 :,if tt == 16 :,0.75,0.0
"def _validate_and_define(params, key, value): <TAB> (key, force_generic) = _validate_key(_unescape(key)) <TAB> if key in params: <TAB> <TAB> raise SyntaxError(f'duplicate key ""{key}""') <TAB> cls = _class_for_key.get(key, GenericParam) <TAB> emptiness = cls.emptiness() <TAB> if value is None: <TAB> <TAB> if emptiness == Emptiness.NEVER: <TAB> <TAB> <TAB> raise SyntaxError(""value cannot be empty"") <TAB> <TAB> value = cls.from_value(value) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> value = cls.from_wire_parser(dns.wire.Parser(_unescape(value))) <TAB> <TAB> else: <TAB> <TAB> <TAB> value = cls.from_value(value) <TAB> params[key] = value",true,if force_generic :,if force_generic :,0.53,0.0
"def iter_fields(node, *, include_meta=True, exclude_unset=False): <TAB> exclude_meta = not include_meta <TAB> for field_name, field in node._fields.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> field_val = getattr(node, field_name, _marker) <TAB> <TAB> if field_val is _marker: <TAB> <TAB> <TAB> continue <TAB> <TAB> if exclude_unset: <TAB> <TAB> <TAB> if callable(field.default): <TAB> <TAB> <TAB> <TAB> default = field.default() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> default = field.default <TAB> <TAB> <TAB> if field_val == default: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield field_name, field_val",false,if exclude_meta and field . meta :,if field_name in meta_fields :,0.11,0.0
"def tearDown(self): <TAB> """"""Shutdown the server."""""" <TAB> try: <TAB> <TAB> if self.server: <TAB> <TAB> <TAB> self.server.stop() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.root_logger.removeHandler(self.sl_hdlr) <TAB> <TAB> <TAB> self.sl_hdlr.close() <TAB> finally: <TAB> <TAB> BaseTest.tearDown(self)",false,if self . sl_hdlr :,if self . root_logger :,0.39,0.0
"def _wait_for_async_copy(self, share_name, file_path): <TAB> count = 0 <TAB> share_client = self.fsc.get_share_client(share_name) <TAB> file_client = share_client.get_file_client(file_path) <TAB> properties = file_client.get_file_properties() <TAB> while properties.copy.status != ""success"": <TAB> <TAB> count = count + 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.fail(""Timed out waiting for async copy to complete."") <TAB> <TAB> self.sleep(6) <TAB> <TAB> properties = file_client.get_file_properties() <TAB> self.assertEqual(properties.copy.status, ""success"")",true,if count > 10 :,if count > 10 :,0.75,0.0
"def __new__( <TAB> cls, <TAB> message_type: OrderBookMessageType, <TAB> content: Dict[str, any], <TAB> timestamp: Optional[float] = None, <TAB> *args, <TAB> **kwargs, ): <TAB> if timestamp is None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""timestamp must not be None when initializing snapshot messages."" <TAB> <TAB> <TAB> ) <TAB> <TAB> timestamp = int(time.time()) <TAB> return super(KucoinOrderBookMessage, cls).__new__( <TAB> <TAB> cls, message_type, content, timestamp=timestamp, *args, **kwargs <TAB> )",true,if message_type is OrderBookMessageType . SNAPSHOT :,if message_type is OrderBookMessageType . SNAPSHOT :,0.75,0.0
"def _drop_unique_features( <TAB> X: DataFrame, feature_metadata: FeatureMetadata, max_unique_ratio ) -> list: <TAB> features_to_drop = [] <TAB> X_len = len(X) <TAB> max_unique_value_count = X_len * max_unique_ratio <TAB> for column in X: <TAB> <TAB> unique_value_count = len(X[column].unique()) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> features_to_drop.append(column) <TAB> <TAB> elif feature_metadata.get_feature_type_raw(column) in [ <TAB> <TAB> <TAB> R_CATEGORY, <TAB> <TAB> <TAB> R_OBJECT, <TAB> <TAB> ] and (unique_value_count > max_unique_value_count): <TAB> <TAB> <TAB> features_to_drop.append(column) <TAB> return features_to_drop",false,if unique_value_count == 1 :,if unique_value_count < max_unique_value_count :,0.06,0.0
"def get_src_findex_by_pad(s, S, padding_mode, align_corners): <TAB> if padding_mode == ""zero"": <TAB> <TAB> return get_src_findex_with_zero_pad(s, S) <TAB> elif padding_mode == ""reflect"": <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return get_src_findex_with_reflect_pad(s, S, True) <TAB> <TAB> else: <TAB> <TAB> <TAB> sf = get_src_findex_with_reflect_pad(s, S, False) <TAB> <TAB> <TAB> return get_src_findex_with_repeat_pad(sf, S) <TAB> elif padding_mode == ""repeat"": <TAB> <TAB> return get_src_findex_with_repeat_pad(s, S)",true,if align_corners :,if align_corners :,0.53,0.0
"def _iterate_self_and_parents(self, upto=None): <TAB> current = self <TAB> result = () <TAB> while current: <TAB> <TAB> result += (current,) <TAB> <TAB> if current._parent is upto: <TAB> <TAB> <TAB> break <TAB> <TAB> elif current._parent is None: <TAB> <TAB> <TAB> raise sa_exc.InvalidRequestError( <TAB> <TAB> <TAB> <TAB> ""Transaction %s is not on the active transaction list"" % (upto) <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> current = current._parent <TAB> return result",true,elif current . _parent is None :,elif current . _parent is None :,0.75,0.0
"def __setattr__(self, name: str, val: Any): <TAB> if name.startswith(""COMPUTED_""): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> old_val = self[name] <TAB> <TAB> <TAB> if old_val == val: <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> raise KeyError( <TAB> <TAB> <TAB> <TAB> ""Computed attributed '{}' already exists "" <TAB> <TAB> <TAB> <TAB> ""with a different value! old={}, new={}."".format(name, old_val, val) <TAB> <TAB> <TAB> ) <TAB> <TAB> self[name] = val <TAB> else: <TAB> <TAB> super().__setattr__(name, val)",true,if name in self :,if name in self :,0.75,0.0
"def get_fnlist(bbhandler, pkg_pn, preferred): <TAB> """"""Get all recipe file names"""""" <TAB><IF-STMT> <TAB> <TAB> (latest_versions, preferred_versions) = bb.providers.findProviders( <TAB> <TAB> <TAB> bbhandler.config_data, bbhandler.cooker.recipecaches[""""], pkg_pn <TAB> <TAB> ) <TAB> fn_list = [] <TAB> for pn in sorted(pkg_pn): <TAB> <TAB> if preferred: <TAB> <TAB> <TAB> fn_list.append(preferred_versions[pn][1]) <TAB> <TAB> else: <TAB> <TAB> <TAB> fn_list.extend(pkg_pn[pn]) <TAB> return fn_list",true,if preferred :,if preferred :,0.53,0.0
"def links_extracted(self, _, links): <TAB> links_deduped = {} <TAB> for link in links: <TAB> <TAB> link_fingerprint = link.meta[FIELD_FINGERPRINT] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> links_deduped[link_fingerprint] = link <TAB> [ <TAB> <TAB> self._redis_pipeline.hmset(fingerprint, self._create_link_extracted(link)) <TAB> <TAB> for (fingerprint, link) in links_deduped.items() <TAB> ] <TAB> self._redis_pipeline.execute()",true,if link_fingerprint in links_deduped :,if link_fingerprint in links_deduped :,0.75,0.0
"def __call__(self, name, rawtext, text, lineno, inliner, options=None, content=None): <TAB> options = options or {} <TAB> content = content or [] <TAB> issue_nos = [each.strip() for each in utils.unescape(text).split("","")] <TAB> config = inliner.document.settings.env.app.config <TAB> ret = [] <TAB> for i, issue_no in enumerate(issue_nos): <TAB> <TAB> node = self.make_node(name, issue_no, config, options=options) <TAB> <TAB> ret.append(node) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> sep = nodes.raw(text="", "", format=""html"") <TAB> <TAB> <TAB> ret.append(sep) <TAB> return ret, []",false,if i != len ( issue_nos ) - 1 :,if i == len ( issue_nos ) - 1 :,0.6,0.0
"def init_messengers(messengers): <TAB> for messenger in messengers: <TAB> <TAB> if ""."" in messenger[""type""]: <TAB> <TAB> <TAB> module_path = messenger[""type""] <TAB> <TAB> <TAB> messenger[""type""] = messenger[""type""].split(""."")[-1] <TAB> <TAB> else: <TAB> <TAB> <TAB> module_path = ""oncall.messengers."" + messenger[""type""] <TAB> <TAB> instance = getattr(importlib.import_module(module_path), messenger[""type""])( <TAB> <TAB> <TAB> messenger <TAB> <TAB> ) <TAB> <TAB> for transport in instance.supports: <TAB> <TAB> <TAB> _active_messengers[transport].append(instance)",true,"if ""."" in messenger [ ""type"" ] :","if ""."" in messenger [ ""type"" ] :",0.75,0.0
"def _process_enum_definition(self, tok): <TAB> fields = [] <TAB> for field in tok.fields: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> expression = self.expression_parser.parse(field.expression) <TAB> <TAB> else: <TAB> <TAB> <TAB> expression = None <TAB> <TAB> fields.append(c_ast.CEnumField(name=field.name.first, value=expression)) <TAB> name = tok.enum_name <TAB> if name: <TAB> <TAB> name = ""enum %s"" % tok.enum_name.first <TAB> else: <TAB> <TAB> name = self._make_anonymous_type(""enum"") <TAB> return c_ast.CTypeDefinition( <TAB> <TAB> name=name, <TAB> <TAB> type_definition=c_ast.CEnum( <TAB> <TAB> <TAB> attributes=tok.attributes, fields=fields, name=name <TAB> <TAB> ), <TAB> )",true,if field . expression :,if field . expression :,0.75,0.0
def result_iterator(): <TAB> try: <TAB> <TAB> # reverse to keep finishing order <TAB> <TAB> fs.reverse() <TAB> <TAB> while fs: <TAB> <TAB> <TAB> # Careful not to keep a reference to the popped future <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> yield fs.pop().result() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> yield fs.pop().result(end_time - time.time()) <TAB> finally: <TAB> <TAB> for future in fs: <TAB> <TAB> <TAB> future.cancel(),false,if timeout is None :,if end_time is None :,0.39,0.0
"def has_encrypted_ssh_key_data(self): <TAB> try: <TAB> <TAB> ssh_key_data = self.get_input(""ssh_key_data"") <TAB> except AttributeError: <TAB> <TAB> return False <TAB> try: <TAB> <TAB> pem_objects = validate_ssh_private_key(ssh_key_data) <TAB> <TAB> for pem_object in pem_objects: <TAB> <TAB> <TAB> if pem_object.get(""key_enc"", False): <TAB> <TAB> <TAB> <TAB> return True <TAB> except ValidationError: <TAB> <TAB> pass <TAB> return False",true,"if pem_object . get ( ""key_enc"" , False ) :","if pem_object . get ( ""key_enc"" , False ) :",0.75,0.0
"def test_seq_object_transcription_method(self): <TAB> for nucleotide_seq in test_seqs: <TAB> <TAB> if isinstance(nucleotide_seq, Seq.Seq): <TAB> <TAB> <TAB> self.assertEqual( <TAB> <TAB> <TAB> <TAB> repr(Seq.transcribe(nucleotide_seq)), <TAB> <TAB> <TAB> <TAB> repr(nucleotide_seq.transcribe()), <TAB> <TAB> <TAB> )",true,"if isinstance ( nucleotide_seq , Seq . Seq ) :","if isinstance ( nucleotide_seq , Seq . Seq ) :",1.0,0.0
"def max_elevation(self): <TAB> max_el = None <TAB> for y in xrange(self.height): <TAB> <TAB> for x in xrange(self.width): <TAB> <TAB> <TAB> el = self.elevation[""data""][y][x] <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> max_el = el <TAB> return max_el",true,if max_el is None or el > max_el :,if max_el is None or el > max_el :,0.75,0.0
"def stress(mapping, index): <TAB> for count in range(OPERATIONS): <TAB> <TAB> function = random.choice(functions) <TAB> <TAB> function(mapping, index) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(""\r"", len(mapping), "" "" * 7, end="""") <TAB> print()",false,if count % 1000 == 0 :,if count % 10000 == 0 :,0.39,0.0
"def sync_terminology(self): <TAB> if self.is_source: <TAB> <TAB> return <TAB> store = self.store <TAB> missing = [] <TAB> for source in self.component.get_all_sources(): <TAB> <TAB> if ""terminology"" not in source.all_flags: <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> _unit, add = store.find_unit(source.context, source.source) <TAB> <TAB> except UnitNotFound: <TAB> <TAB> <TAB> add = True <TAB> <TAB> # Unit is already present <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> missing.append((source.context, source.source, """")) <TAB> if missing: <TAB> <TAB> self.add_units(None, missing)",false,if not add :,if add :,0.1,0.0
"def get_generators(self): <TAB> """"""Get a dict with all registered generators, indexed by name"""""" <TAB> generators = {} <TAB> for core in self.db.find(): <TAB> <TAB> if hasattr(core, ""get_generators""): <TAB> <TAB> <TAB> _generators = core.get_generators({}) <TAB> <TAB> <TAB> if _generators: <TAB> <TAB> <TAB> <TAB> generators[str(core.name)] = _generators <TAB> return generators",true,"if hasattr ( core , ""get_generators"" ) :","if hasattr ( core , ""get_generators"" ) :",0.75,0.0
"def act(self, state): <TAB> if self.body.env.clock.frame < self.training_start_step: <TAB> <TAB> return policy_util.random(state, self, self.body).cpu().squeeze().numpy() <TAB> else: <TAB> <TAB> action = self.action_policy(state, self, self.body) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> action = self.scale_action(torch.tanh(action))  # continuous action bound <TAB> <TAB> return action.cpu().squeeze().numpy()",false,if not self . body . is_discrete :,if self . body . env . clock . frame < self . training_start_step :,0.14,0.0
"def try_open_completions_event(self, event=None): <TAB> ""(./) Open completion list after pause with no movement."" <TAB> lastchar = self.text.get(""insert-1c"") <TAB> if lastchar in TRIGGERS: <TAB> <TAB> args = TRY_A if lastchar == ""."" else TRY_F <TAB> <TAB> self._delayed_completion_index = self.text.index(""insert"") <TAB> <TAB> if self._delayed_completion_id is not None: <TAB> <TAB> <TAB> self.text.after_cancel(self._delayed_completion_id) <TAB> <TAB> self._delayed_completion_id = self.text.after( <TAB> <TAB> <TAB> self.popupwait, self._delayed_open_completions, args <TAB> <TAB> )",true,if self . _delayed_completion_id is not None :,if self . _delayed_completion_id is not None :,0.75,0.0
"def token_is_available(self): <TAB> if self.token: <TAB> <TAB> try: <TAB> <TAB> <TAB> resp = requests.get( <TAB> <TAB> <TAB> <TAB> ""https://api.shodan.io/account/profile?key={0}"".format(self.token) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if resp and resp.status_code == 200 and ""member"" in resp.json(): <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> except Exception as ex: <TAB> <TAB> <TAB> logger.error(str(ex)) <TAB> return False",true,"if resp and resp . status_code == 200 and ""member"" in resp . json ( ) :","if resp and resp . status_code == 200 and ""member"" in resp . json ( ) :",1.0,0.0
"def next_bar_(self, event): <TAB> bars = event.bar_dict <TAB> self._current_minute = self._minutes_since_midnight( <TAB> <TAB> self.ucontext.now.hour, self.ucontext.now.minute <TAB> ) <TAB> for day_rule, time_rule, func in self._registry: <TAB> <TAB> if day_rule() and time_rule(): <TAB> <TAB> <TAB> with ExecutionContext(EXECUTION_PHASE.SCHEDULED): <TAB> <TAB> <TAB> <TAB> with ModifyExceptionFromType(EXC_TYPE.USER_EXC): <TAB> <TAB> <TAB> <TAB> <TAB> func(self.ucontext, bars) <TAB> self._last_minute = self._current_minute",true,if day_rule ( ) and time_rule ( ) :,if day_rule ( ) and time_rule ( ) :,0.75,0.0
"def decoder(s): <TAB> r = [] <TAB> decode = [] <TAB> for c in s: <TAB> <TAB> if c == ""&"" and not decode: <TAB> <TAB> <TAB> decode.append(""&"") <TAB> <TAB> elif c == ""-"" and decode: <TAB> <TAB> <TAB> if len(decode) == 1: <TAB> <TAB> <TAB> <TAB> r.append(""&"") <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> r.append(modified_unbase64("""".join(decode[1:]))) <TAB> <TAB> <TAB> decode = [] <TAB> <TAB> elif decode: <TAB> <TAB> <TAB> decode.append(c) <TAB> <TAB> else: <TAB> <TAB> <TAB> r.append(c) <TAB> if decode: <TAB> <TAB> r.append(modified_unbase64("""".join(decode[1:]))) <TAB> bin_str = """".join(r) <TAB> return (bin_str, len(s))",true,"elif c == ""-"" and decode :","elif c == ""-"" and decode :",1.0,0.0
"def admin_audit_get(admin_id): <TAB> if settings.app.demo_mode: <TAB> <TAB> resp = utils.demo_get_cache() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return utils.jsonify(resp) <TAB> if not flask.g.administrator.super_user: <TAB> <TAB> return utils.jsonify( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> ""error"": REQUIRES_SUPER_USER, <TAB> <TAB> <TAB> <TAB> ""error_msg"": REQUIRES_SUPER_USER_MSG, <TAB> <TAB> <TAB> }, <TAB> <TAB> <TAB> 400, <TAB> <TAB> ) <TAB> admin = auth.get_by_id(admin_id) <TAB> resp = admin.get_audit_events() <TAB> if settings.app.demo_mode: <TAB> <TAB> utils.demo_set_cache(resp) <TAB> return utils.jsonify(resp)",true,if resp :,if resp :,0.53,0.0
"def vjp(self, argnum, outgrad, ans, vs, gvs, args, kwargs): <TAB> try: <TAB> <TAB> return self.vjps[argnum](outgrad, ans, vs, gvs, *args, **kwargs) <TAB> except KeyError: <TAB> <TAB> if self.vjps == {}: <TAB> <TAB> <TAB> errstr = ""Gradient of {0} not yet implemented."" <TAB> <TAB> else: <TAB> <TAB> <TAB> errstr = ""Gradient of {0} w.r.t. arg number {1} not yet implemented."" <TAB> <TAB> raise NotImplementedError(errstr.format(self.fun.__name__, argnum))",true,if self . vjps == { } :,if self . vjps == { } :,0.75,0.0
"def update(self, *args, **kwargs): <TAB> assert not self.readonly <TAB> longest_key = 0 <TAB> _dict = self._dict <TAB> reverse = self.reverse <TAB> casereverse = self.casereverse <TAB> for iterable in args + (kwargs,): <TAB> <TAB> if isinstance(iterable, (dict, StenoDictionary)): <TAB> <TAB> <TAB> iterable = iterable.items() <TAB> <TAB> for key, value in iterable: <TAB> <TAB> <TAB> longest_key = max(longest_key, len(key)) <TAB> <TAB> <TAB> _dict[key] = value <TAB> <TAB> <TAB> reverse[value].append(key) <TAB> <TAB> <TAB> casereverse[value.lower()][value] += 1 <TAB> self._longest_key = max(self._longest_key, longest_key)",true,"if isinstance ( iterable , ( dict , StenoDictionary ) ) :","if isinstance ( iterable , ( dict , StenoDictionary ) ) :",0.75,0.0
"def update_ui(self, window): <TAB> view = window.get_active_view() <TAB> self.set_status(view) <TAB> lang = ""plain_text"" <TAB> if view: <TAB> <TAB> buf = view.get_buffer() <TAB> <TAB> language = buf.get_language() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> lang = language.get_id() <TAB> <TAB> self.setup_smart_indent(view, lang)",true,if language :,if language :,0.53,0.0
"def number_operators(self, a, b, skip=[]): <TAB> dict = {""a"": a, ""b"": b} <TAB> for name, expr in self.binops.items(): <TAB> <TAB> if name not in skip: <TAB> <TAB> <TAB> name = ""__%s__"" % name <TAB> <TAB> <TAB> if hasattr(a, name): <TAB> <TAB> <TAB> <TAB> res = eval(expr, dict) <TAB> <TAB> <TAB> <TAB> self.binop_test(a, b, res, expr, name) <TAB> for name, expr in self.unops.items(): <TAB> <TAB> if name not in skip: <TAB> <TAB> <TAB> name = ""__%s__"" % name <TAB> <TAB> <TAB> if hasattr(a, name): <TAB> <TAB> <TAB> <TAB> res = eval(expr, dict) <TAB> <TAB> <TAB> <TAB> self.unop_test(a, res, expr, name)",true,"if hasattr ( a , name ) :","if hasattr ( a , name ) :",0.75,0.0
"def _getItemHeight(self, item, ctrl=None): <TAB> """"""Returns the full height of the item to be inserted in the form"""""" <TAB> if type(ctrl) == psychopy.visual.TextBox2: <TAB> <TAB> return ctrl.size[1] <TAB> if type(ctrl) == psychopy.visual.Slider: <TAB> <TAB> # Set radio button layout <TAB> <TAB> if item[""layout""] == ""horiz"": <TAB> <TAB> <TAB> return 0.03 + ctrl.labelHeight * 3 <TAB> <TAB> elif item[""layout""] == ""vert"": <TAB> <TAB> <TAB> # for vertical take into account the nOptions <TAB> <TAB> <TAB> return ctrl.labelHeight * len(item[""options""])",false,"if item [ ""layout"" ] == ""horiz"" :","elif item [ ""layout"" ] == ""vert"" :",0.26,0.0
"def test_cleanup_params(self, body, rpc_mock): <TAB> res = self._get_resp_post(body) <TAB> self.assertEqual(http_client.ACCEPTED, res.status_code) <TAB> rpc_mock.assert_called_once_with(self.context, mock.ANY) <TAB> cleanup_request = rpc_mock.call_args[0][1] <TAB> for key, value in body.items(): <TAB> <TAB> if key in (""disabled"", ""is_up""): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> value = value == ""true"" <TAB> <TAB> self.assertEqual(value, getattr(cleanup_request, key)) <TAB> self.assertEqual(self._expected_services(*SERVICES), res.json)",true,if value is not None :,if value is not None :,0.75,0.0
"def _read_json_content(self, body_is_optional=False): <TAB> if ""content-length"" not in self.headers: <TAB> <TAB> return self.send_error(411) if not body_is_optional else {} <TAB> try: <TAB> <TAB> content_length = int(self.headers.get(""content-length"")) <TAB> <TAB> if content_length == 0 and body_is_optional: <TAB> <TAB> <TAB> return {} <TAB> <TAB> request = json.loads(self.rfile.read(content_length).decode(""utf-8"")) <TAB> <TAB> if isinstance(request, dict) and (request or body_is_optional): <TAB> <TAB> <TAB> return request <TAB> except Exception: <TAB> <TAB> logger.exception(""Bad request"") <TAB> self.send_error(400)",true,"if isinstance ( request , dict ) and ( request or body_is_optional ) :","if isinstance ( request , dict ) and ( request or body_is_optional ) :",1.0,0.0
"def env_purge_doc(app: Sphinx, env: BuildEnvironment, docname: str) -> None: <TAB> modules = getattr(env, ""_viewcode_modules"", {}) <TAB> for modname, entry in list(modules.items()): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> code, tags, used, refname = entry <TAB> <TAB> for fullname in list(used): <TAB> <TAB> <TAB> if used[fullname] == docname: <TAB> <TAB> <TAB> <TAB> used.pop(fullname) <TAB> <TAB> if len(used) == 0: <TAB> <TAB> <TAB> modules.pop(modname)",false,if entry is False :,if modname not in used :,0.16,0.0
"def frames(self): <TAB> """"""an array of all the frames (including iframes) in the current window"""""" <TAB> from thug.DOM.W3C.HTML.HTMLCollection import HTMLCollection <TAB> frames = set() <TAB> for frame in self._findAll([""frame"", ""iframe""]): <TAB> <TAB> if not getattr(frame, ""_node"", None): <TAB> <TAB> <TAB> from thug.DOM.W3C.Core.DOMImplementation import DOMImplementation <TAB> <TAB> <TAB> DOMImplementation.createHTMLElement(self.window.doc, frame) <TAB> <TAB> frames.add(frame._node) <TAB> return HTMLCollection(self.doc, list(frames))",true,"if not getattr ( frame , ""_node"" , None ) :","if not getattr ( frame , ""_node"" , None ) :",0.75,0.0
"def check(self, **kw): <TAB> if not kw: <TAB> <TAB> return exists(self.strpath) <TAB> if len(kw) == 1: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return not kw[""dir""] ^ isdir(self.strpath) <TAB> <TAB> if ""file"" in kw: <TAB> <TAB> <TAB> return not kw[""file""] ^ isfile(self.strpath) <TAB> return super(LocalPath, self).check(**kw)",true,"if ""dir"" in kw :","if ""dir"" in kw :",0.75,0.0
"def __init__(self, folders): <TAB> self.folders = folders <TAB> self.duplicates = {} <TAB> for folder, path in folders.items(): <TAB> <TAB> duplicates = [] <TAB> <TAB> for other_folder, other_path in folders.items(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if other_path == path: <TAB> <TAB> <TAB> <TAB> duplicates.append(other_folder) <TAB> <TAB> if len(duplicates): <TAB> <TAB> <TAB> self.duplicates[folder] = duplicates",false,if other_folder == folder :,if folder == other_path :,0.29,0.0
"def next(self, buf, pos): <TAB> if pos >= len(buf): <TAB> <TAB> return EOF, """", pos <TAB> mo = self.tokens_re.match(buf, pos) <TAB> if mo: <TAB> <TAB> text = mo.group() <TAB> <TAB> type, regexp, test_lit = self.tokens[mo.lastindex - 1] <TAB> <TAB> pos = mo.end() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> type = self.literals.get(text, type) <TAB> <TAB> return type, text, pos <TAB> else: <TAB> <TAB> c = buf[pos] <TAB> <TAB> return self.symbols.get(c, None), c, pos + 1",false,if test_lit :,if regexp == test_lit :,0.1,0.0
"def step(self, action): <TAB> """"""Repeat action, sum reward, and max over last observations."""""" <TAB> total_reward = 0.0 <TAB> done = None <TAB> for i in range(self._skip): <TAB> <TAB> obs, reward, done, info = self.env.step(action) <TAB> <TAB> if i == self._skip - 2: <TAB> <TAB> <TAB> self._obs_buffer[0] = obs <TAB> <TAB> if i == self._skip - 1: <TAB> <TAB> <TAB> self._obs_buffer[1] = obs <TAB> <TAB> total_reward += reward <TAB> <TAB> if done: <TAB> <TAB> <TAB> break <TAB> # Note that the observation on the done=True frame <TAB> # doesn't matter <TAB> max_frame = self._obs_buffer.max(axis=0) <TAB> return max_frame, total_reward, done, info",true,if i == self . _skip - 2 :,if i == self . _skip - 2 :,0.75,0.0
"def convert(self, ctx, argument): <TAB> arg = argument.replace(""0x"", """").lower() <TAB> if arg[0] == ""#"": <TAB> <TAB> arg = arg[1:] <TAB> try: <TAB> <TAB> value = int(arg, base=16) <TAB> <TAB> if not (0 <= value <= 0xFFFFFF): <TAB> <TAB> <TAB> raise BadColourArgument(arg) <TAB> <TAB> return discord.Colour(value=value) <TAB> except ValueError: <TAB> <TAB> arg = arg.replace("" "", ""_"") <TAB> <TAB> method = getattr(discord.Colour, arg, None) <TAB> <TAB> if arg.startswith(""from_"") or method is None or not inspect.ismethod(method): <TAB> <TAB> <TAB> raise BadColourArgument(arg) <TAB> <TAB> return method()",true,"if arg . startswith ( ""from_"" ) or method is None or not inspect . ismethod ( method ) :","if arg . startswith ( ""from_"" ) or method is None or not inspect . ismethod ( method ) :",1.0,0.0
"def run(self, **inputs): <TAB> if self.inputs.copy_inputs: <TAB> <TAB> self.inputs.subjects_dir = os.getcwd() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> inputs[""subjects_dir""] = self.inputs.subjects_dir <TAB> <TAB> for originalfile in [self.inputs.in_file, self.inputs.in_norm]: <TAB> <TAB> <TAB> copy2subjdir(self, originalfile, folder=""mri"") <TAB> return super(SegmentCC, self).run(**inputs)",false,"if ""subjects_dir"" in inputs :",if self . inputs . subjects_dir :,0.03,0.0
"def get_queryset(self): <TAB> if not hasattr(self, ""_queryset""): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> qs = self.queryset <TAB> <TAB> else: <TAB> <TAB> <TAB> qs = self.model._default_manager.get_queryset() <TAB> <TAB> # If the queryset isn't already ordered we need to add an <TAB> <TAB> # artificial ordering here to make sure that all formsets <TAB> <TAB> # constructed from this queryset have the same form order. <TAB> <TAB> if not qs.ordered: <TAB> <TAB> <TAB> qs = qs.order_by(self.model._meta.pk.name) <TAB> <TAB> # Removed queryset limiting here. As per discussion re: #13023 <TAB> <TAB> # on django-dev, max_num should not prevent existing <TAB> <TAB> # related objects/inlines from being displayed. <TAB> <TAB> self._queryset = qs <TAB> return self._queryset",false,if self . queryset is not None :,if self . queryset :,0.23,0.0
"def visit_simple_stmt(self, node: Node) -> Iterator[Line]: <TAB> """"""Visit a statement without nested statements."""""" <TAB> is_suite_like = node.parent and node.parent.type in STATEMENT <TAB> if is_suite_like: <TAB> <TAB> if self.is_pyi and is_stub_body(node): <TAB> <TAB> <TAB> yield from self.visit_default(node) <TAB> <TAB> else: <TAB> <TAB> <TAB> yield from self.line(+1) <TAB> <TAB> <TAB> yield from self.visit_default(node) <TAB> <TAB> <TAB> yield from self.line(-1) <TAB> else: <TAB> <TAB> if not self.is_pyi or not node.parent or not is_stub_suite(node.parent): <TAB> <TAB> <TAB> yield from self.line() <TAB> <TAB> yield from self.visit_default(node)",true,if self . is_pyi and is_stub_body ( node ) :,if self . is_pyi and is_stub_body ( node ) :,0.75,0.0
"def rawDataReceived(self, data): <TAB> if self.timeout > 0: <TAB> <TAB> self.resetTimeout() <TAB> self._pendingSize -= len(data) <TAB> if self._pendingSize > 0: <TAB> <TAB> self._pendingBuffer.write(data) <TAB> else: <TAB> <TAB> passon = b"""" <TAB> <TAB> if self._pendingSize < 0: <TAB> <TAB> <TAB> data, passon = data[: self._pendingSize], data[self._pendingSize :] <TAB> <TAB> self._pendingBuffer.write(data) <TAB> <TAB> rest = self._pendingBuffer <TAB> <TAB> self._pendingBuffer = None <TAB> <TAB> self._pendingSize = None <TAB> <TAB> rest.seek(0, 0) <TAB> <TAB> self._parts.append(rest.read()) <TAB> <TAB> self.setLineMode(passon.lstrip(b""\r\n""))",true,if self . _pendingSize < 0 :,if self . _pendingSize < 0 :,0.75,0.0
"def handle(self, *args, **options): <TAB> app_name = options.get(""app_name"") <TAB> job_name = options.get(""job_name"") <TAB> # hack since we are using job_name nargs='?' for -l to work <TAB> if app_name and not job_name: <TAB> <TAB> job_name = app_name <TAB> <TAB> app_name = None <TAB> if options.get(""list_jobs""): <TAB> <TAB> print_jobs(only_scheduled=False, show_when=True, show_appname=True) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print(""Run a single maintenance job. Please specify the name of the job."") <TAB> <TAB> <TAB> return <TAB> <TAB> self.runjob(app_name, job_name, options)",false,if not job_name :,if app_name and job_name :,0.08,0.0
"def _exportReceived(self, content, error=False, server=None, context={}, **kwargs): <TAB> if error: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.error.emit(content[""message""], True) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.error.emit(""Can't export the project from the server"", True) <TAB> <TAB> self.finished.emit() <TAB> <TAB> return <TAB> self.finished.emit()",false,if content :,"if ""message"" in content :",0.1,0.0
"def __iter__(self): <TAB> n = self.n <TAB> k = self.k <TAB> j = int(np.ceil(n / k)) <TAB> for i in range(k): <TAB> <TAB> test_index = np.zeros(n, dtype=bool) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> test_index[i * j : (i + 1) * j] = True <TAB> <TAB> else: <TAB> <TAB> <TAB> test_index[i * j :] = True <TAB> <TAB> train_index = np.logical_not(test_index) <TAB> <TAB> yield train_index, test_index",false,if i < k - 1 :,if i % k == 0 :,0.29,0.0
"def addType(self, graphene_type): <TAB> meta = get_meta(graphene_type) <TAB> if meta: <TAB> <TAB> if not graphene_type in self._typeMap: <TAB> <TAB> <TAB> self._typeMap[meta.name] = graphene_type <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> ""Type {typeName} already exists in the registry."".format( <TAB> <TAB> <TAB> <TAB> <TAB> typeName=meta.name <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> else: <TAB> <TAB> raise Exception(""Cannot add unnamed type or a non-type to registry."")",true,if not graphene_type in self . _typeMap :,if not graphene_type in self . _typeMap :,0.75,0.0
"def test_len(self): <TAB> eq = self.assertEqual <TAB> eq(base64MIME.base64_len(""hello""), len(base64MIME.encode(""hello"", eol=""""))) <TAB> for size in range(15): <TAB> <TAB> if size == 0: <TAB> <TAB> <TAB> bsize = 0 <TAB> <TAB> elif size <= 3: <TAB> <TAB> <TAB> bsize = 4 <TAB> <TAB> elif size <= 6: <TAB> <TAB> <TAB> bsize = 8 <TAB> <TAB> elif size <= 9: <TAB> <TAB> <TAB> bsize = 12 <TAB> <TAB> elif size <= 12: <TAB> <TAB> <TAB> bsize = 16 <TAB> <TAB> else: <TAB> <TAB> <TAB> bsize = 20 <TAB> <TAB> eq(base64MIME.base64_len(""x"" * size), bsize)",true,elif size <= 6 :,elif size <= 6 :,0.75,0.0
"def _asStringList(self, sep=""""): <TAB> out = [] <TAB> for item in self._toklist: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> out.append(sep) <TAB> <TAB> if isinstance(item, ParseResults): <TAB> <TAB> <TAB> out += item._asStringList() <TAB> <TAB> else: <TAB> <TAB> <TAB> out.append(str(item)) <TAB> return out",false,if out and sep :,if sep :,0.07,0.0
"def open_file_input(cli_parsed): <TAB> files = glob.glob(os.path.join(cli_parsed.d, ""*report.html"")) <TAB> if len(files) > 0: <TAB> <TAB> print(""\n[*] Done! Report written in the "" + cli_parsed.d + "" folder!"") <TAB> <TAB> print(""Would you like to open the report now? [Y/n]"") <TAB> <TAB> while True: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> response = input().lower() <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> return strtobool(response) <TAB> <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> <TAB> print(""Please respond with y or n"") <TAB> else: <TAB> <TAB> print(""[*] No report files found to open, perhaps no hosts were successful"") <TAB> <TAB> return False",false,"if response == """" :",if response in files :,0.06,0.0
"def init_values(self): <TAB> config = self._raw_config <TAB> for valname, value in self.overrides.iteritems(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> realvalname, key = valname.split(""."", 1) <TAB> <TAB> <TAB> config.setdefault(realvalname, {})[key] = value <TAB> <TAB> else: <TAB> <TAB> <TAB> config[valname] = value <TAB> for name in config: <TAB> <TAB> if name in self.values: <TAB> <TAB> <TAB> self.__dict__[name] = config[name] <TAB> del self._raw_config",true,"if ""."" in valname :","if ""."" in valname :",0.75,0.0
"def get_result(self): <TAB> result_list = [] <TAB> exc_info = None <TAB> for f in self.children: <TAB> <TAB> try: <TAB> <TAB> <TAB> result_list.append(f.get_result()) <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> exc_info = sys.exc_info() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> if not isinstance(e, self.quiet_exceptions): <TAB> <TAB> <TAB> <TAB> <TAB> app_log.error(""Multiple exceptions in yield list"", exc_info=True) <TAB> if exc_info is not None: <TAB> <TAB> raise_exc_info(exc_info) <TAB> if self.keys is not None: <TAB> <TAB> return dict(zip(self.keys, result_list)) <TAB> else: <TAB> <TAB> return list(result_list)",true,if exc_info is None :,if exc_info is None :,0.75,0.0
"def test01e_json(self): <TAB> ""Testing GeoJSON input/output."" <TAB> if not GEOJSON: <TAB> <TAB> return <TAB> for g in self.geometries.json_geoms: <TAB> <TAB> geom = OGRGeometry(g.wkt) <TAB> <TAB> if not hasattr(g, ""not_equal""): <TAB> <TAB> <TAB> self.assertEqual(g.json, geom.json) <TAB> <TAB> <TAB> self.assertEqual(g.json, geom.geojson) <TAB> <TAB> self.assertEqual(OGRGeometry(g.wkt), OGRGeometry(geom.json))",true,"if not hasattr ( g , ""not_equal"" ) :","if not hasattr ( g , ""not_equal"" ) :",0.75,0.0
"def __init__(self, hub=None):  # pylint: disable=unused-argument <TAB> if resolver._resolver is None: <TAB> <TAB> _resolver = resolver._resolver = _DualResolver() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> _resolver.network_resolver.nameservers[:] = config.resolver_nameservers <TAB> <TAB> if config.resolver_timeout: <TAB> <TAB> <TAB> _resolver.network_resolver.lifetime = config.resolver_timeout <TAB> # Different hubs in different threads could be sharing the same <TAB> # resolver. <TAB> assert isinstance(resolver._resolver, _DualResolver) <TAB> self._resolver = resolver._resolver",true,if config . resolver_nameservers :,if config . resolver_nameservers :,0.75,0.0
"def __iadd__(self, term): <TAB> if isinstance(term, (int, long)): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> _gmp.mpz_add_ui(self._mpz_p, self._mpz_p, c_ulong(term)) <TAB> <TAB> <TAB> return self <TAB> <TAB> if -65535 < term < 0: <TAB> <TAB> <TAB> _gmp.mpz_sub_ui(self._mpz_p, self._mpz_p, c_ulong(-term)) <TAB> <TAB> <TAB> return self <TAB> <TAB> term = Integer(term) <TAB> _gmp.mpz_add(self._mpz_p, self._mpz_p, term._mpz_p) <TAB> return self",false,if 0 <= term < 65536 :,if 0 < term < 65535 :,0.3,0.0
"def copy(dst, src): <TAB> for (k, v) in src.iteritems(): <TAB> <TAB> if isinstance(v, dict): <TAB> <TAB> <TAB> d = {} <TAB> <TAB> <TAB> dst[k] = d <TAB> <TAB> <TAB> copy(d, v) <TAB> <TAB> else: <TAB> <TAB> <TAB> dst[k] = v",true,"if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",0.75,0.0
"def generator(self, data): <TAB> self.procs = OrderedDict() <TAB> for task in data: <TAB> <TAB> self.recurse_task(task, 0, 0, self.procs) <TAB> for offset, name, level, pid, ppid, uid, euid, gid in self.procs.values(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> 0, <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> Address(offset), <TAB> <TAB> <TAB> <TAB> <TAB> str(name), <TAB> <TAB> <TAB> <TAB> <TAB> str(level), <TAB> <TAB> <TAB> <TAB> <TAB> int(pid), <TAB> <TAB> <TAB> <TAB> <TAB> int(ppid), <TAB> <TAB> <TAB> <TAB> <TAB> int(uid), <TAB> <TAB> <TAB> <TAB> <TAB> int(gid), <TAB> <TAB> <TAB> <TAB> <TAB> int(euid), <TAB> <TAB> <TAB> <TAB> ], <TAB> <TAB> <TAB> )",true,if offset :,if offset :,0.53,0.0
"def apply(self, db, person): <TAB> families = person.get_parent_family_handle_list() <TAB> if families == []: <TAB> <TAB> return True <TAB> for family_handle in person.get_parent_family_handle_list(): <TAB> <TAB> family = db.get_family_from_handle(family_handle) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> father_handle = family.get_father_handle() <TAB> <TAB> <TAB> mother_handle = family.get_mother_handle() <TAB> <TAB> <TAB> if not father_handle: <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> if not mother_handle: <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",true,if family :,if family :,0.53,0.0
"def _arctic_task_exec(request): <TAB> request.start_time = time.time() <TAB> logging.debug( <TAB> <TAB> ""Executing asynchronous request for {}/{}"".format( <TAB> <TAB> <TAB> request.library, request.symbol <TAB> <TAB> ) <TAB> ) <TAB> result = None <TAB> try: <TAB> <TAB> request.is_running = True <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result = mongo_retry(request.fun)(*request.args, **request.kwargs) <TAB> <TAB> else: <TAB> <TAB> <TAB> result = request.fun(*request.args, **request.kwargs) <TAB> except Exception as e: <TAB> <TAB> request.exception = e <TAB> finally: <TAB> <TAB> request.data = result <TAB> <TAB> request.end_time = time.time() <TAB> <TAB> request.is_running = False <TAB> return result",false,if request . mongo_retry :,if request . retry :,0.39,0.0
"def _setup_styles(self): <TAB> for ttype, ndef in self.style: <TAB> <TAB> escape = EscapeSequence() <TAB> <TAB> if ndef[""color""]: <TAB> <TAB> <TAB> escape.fg = self._color_index(ndef[""color""]) <TAB> <TAB> if ndef[""bgcolor""]: <TAB> <TAB> <TAB> escape.bg = self._color_index(ndef[""bgcolor""]) <TAB> <TAB> if self.usebold and ndef[""bold""]: <TAB> <TAB> <TAB> escape.bold = True <TAB> <TAB> if self.useunderline and ndef[""underline""]: <TAB> <TAB> <TAB> escape.underline = True <TAB> <TAB> self.style_string[str(ttype)] = (escape.color_string(), escape.reset_string())",true,"if ndef [ ""color"" ] :","if ndef [ ""color"" ] :",0.75,0.0
"def process_string(self, remove_repetitions, sequence): <TAB> string = """" <TAB> for i, char in enumerate(sequence): <TAB> <TAB> if char != self.int_to_char[self.blank_index]: <TAB> <TAB> <TAB> # if this char is a repetition and remove_repetitions=true, <TAB> <TAB> <TAB> # skip. <TAB> <TAB> <TAB> if remove_repetitions and i != 0 and char == sequence[i - 1]: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> elif char == self.labels[self.space_index]: <TAB> <TAB> <TAB> <TAB> string += "" "" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> string = string + char <TAB> return string",false,elif char == self . labels [ self . space_index ] :,if remove_repetitions and i != 0 and char == sequence [ i - 1 ] :,0.26,0.0
"def arith_expr(self, nodelist): <TAB> node = self.com_node(nodelist[0]) <TAB> for i in range(2, len(nodelist), 2): <TAB> <TAB> right = self.com_node(nodelist[i]) <TAB> <TAB> if nodelist[i - 1].type == token.PLUS: <TAB> <TAB> <TAB> node = Add(node, right, lineno=nodelist[1].context) <TAB> <TAB> elif nodelist[i - 1].type == token.MINUS: <TAB> <TAB> <TAB> node = Sub(node, right, lineno=nodelist[1].context) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""unexpected token: %s"" % nodelist[i - 1][0]) <TAB> return node",false,if nodelist [ i - 1 ] . type == token . PLUS :,elif nodelist [ i - 1 ] . type == token . MINUS :,0.38,0.0
"def invert_index(cls, index, length): <TAB> if np.isscalar(index): <TAB> <TAB> return length - index <TAB> elif isinstance(index, slice): <TAB> <TAB> start, stop = index.start, index.stop <TAB> <TAB> new_start, new_stop = None, None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> new_stop = length - start <TAB> <TAB> if stop is not None: <TAB> <TAB> <TAB> new_start = length - stop <TAB> <TAB> return slice(new_start - 1, new_stop - 1) <TAB> elif isinstance(index, Iterable): <TAB> <TAB> new_index = [] <TAB> <TAB> for ind in index: <TAB> <TAB> <TAB> new_index.append(length - ind) <TAB> return new_index",true,if start is not None :,if start is not None :,0.75,0.0
"def getRoots(job): <TAB> if job not in visited: <TAB> <TAB> visited.add(job) <TAB> <TAB> if len(job._directPredecessors) > 0: <TAB> <TAB> <TAB> list(map(lambda p: getRoots(p), job._directPredecessors)) <TAB> <TAB> else: <TAB> <TAB> <TAB> roots.add(job) <TAB> <TAB> # The following call ensures we explore all successor edges. <TAB> <TAB> list(map(lambda c: getRoots(c), job._children + job._followOns))",true,if len ( job . _directPredecessors ) > 0 :,if len ( job . _directPredecessors ) > 0 :,0.75,0.0
"def visit_filter_projection(self, node, value): <TAB> base = self.visit(node[""children""][0], value) <TAB> if not isinstance(base, list): <TAB> <TAB> return None <TAB> comparator_node = node[""children""][2] <TAB> collected = [] <TAB> for element in base: <TAB> <TAB> if self._is_true(self.visit(comparator_node, element)): <TAB> <TAB> <TAB> current = self.visit(node[""children""][1], element) <TAB> <TAB> <TAB> if current is not None: <TAB> <TAB> <TAB> <TAB> collected.append(current) <TAB> return collected",true,"if self . _is_true ( self . visit ( comparator_node , element ) ) :","if self . _is_true ( self . visit ( comparator_node , element ) ) :",1.0,0.0
"def func(x, y): <TAB> try: <TAB> <TAB> if x > y: <TAB> <TAB> <TAB> z = x + 2 * math.sin(y) <TAB> <TAB> <TAB> return z ** 2 <TAB> <TAB> elif x == y: <TAB> <TAB> <TAB> return 4 <TAB> <TAB> else: <TAB> <TAB> <TAB> return 2 ** 3 <TAB> except ValueError: <TAB> <TAB> foo = 0 <TAB> <TAB> for i in range(4): <TAB> <TAB> <TAB> foo += i <TAB> <TAB> return foo <TAB> except TypeError: <TAB> <TAB> return 42 <TAB> else: <TAB> <TAB> return 33 <TAB> finally: <TAB> <TAB> print(""finished"")",true,elif x == y :,elif x == y :,1.0,0.0
"def set_filter(self, dataset_opt): <TAB> """"""This function create and set the pre_filter to the obj as attributes"""""" <TAB> self.pre_filter = None <TAB> for key_name in dataset_opt.keys(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> new_name = key_name.replace(""filters"", ""filter"") <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> filt = instantiate_filters(getattr(dataset_opt, key_name)) <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> log.exception( <TAB> <TAB> <TAB> <TAB> <TAB> ""Error trying to create {}, {}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> new_name, getattr(dataset_opt, key_name) <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> setattr(self, new_name, filt)",false,"if ""filter"" in key_name :","if ""filters"" in key_name :",0.39,0.0
"def _add_states_to_lookup( <TAB> self, trackers_as_states, trackers_as_actions, domain, online=False ): <TAB> """"""Add states to lookup dict"""""" <TAB> for states in trackers_as_states: <TAB> <TAB> active_form = self._get_active_form_name(states[-1]) <TAB> <TAB> if active_form and self._prev_action_listen_in_state(states[-1]): <TAB> <TAB> <TAB> # modify the states <TAB> <TAB> <TAB> states = self._modified_states(states) <TAB> <TAB> <TAB> feature_key = self._create_feature_key(states) <TAB> <TAB> <TAB> # even if there are two identical feature keys <TAB> <TAB> <TAB> # their form will be the same <TAB> <TAB> <TAB> # because of `active_form_...` feature <TAB> <TAB> <TAB> self.lookup[feature_key] = active_form",true,if active_form and self . _prev_action_listen_in_state ( states [ - 1 ] ) :,if active_form and self . _prev_action_listen_in_state ( states [ - 1 ] ) :,0.75,0.0
"def list_loaded_payloads(self): <TAB> print(helpers.color(""\n [*] Available Payloads:\n"")) <TAB> lastBase = None <TAB> x = 1 <TAB> for name in sorted(self.active_payloads.keys()): <TAB> <TAB> parts = name.split(""/"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> print() <TAB> <TAB> lastBase = parts[0] <TAB> <TAB> print(""\t%s)\t%s"" % (x, ""{0: <24}"".format(name))) <TAB> <TAB> x += 1 <TAB> print(""\n"") <TAB> return",false,if lastBase and parts [ 0 ] != lastBase :,if lastBase != name :,0.03,0.0
"def reprSmart(vw, item): <TAB> ptype = type(item) <TAB> if ptype is int: <TAB> <TAB> if -1024 < item < 1024: <TAB> <TAB> <TAB> return str(item) <TAB> <TAB> elif vw.isValidPointer(item): <TAB> <TAB> <TAB> return vw.reprPointer(item) <TAB> <TAB> else: <TAB> <TAB> <TAB> return hex(item) <TAB> elif ptype in (list, tuple): <TAB> <TAB> return reprComplex(vw, item)  # recurse <TAB> elif ptype is dict: <TAB> <TAB> return ""{%s}"" % "","".join( <TAB> <TAB> <TAB> [""%s:%s"" % (reprSmart(vw, k), reprSmart(vw, v)) for k, v in item.items()] <TAB> <TAB> ) <TAB> else: <TAB> <TAB> return repr(item)",true,elif vw . isValidPointer ( item ) :,elif vw . isValidPointer ( item ) :,0.75,0.0
"def ConfigSectionMap(section): <TAB> config = ConfigParser.RawConfigParser() <TAB> configurations = config_manager()  # Class from mkchromecast.config <TAB> configf = configurations.configf <TAB> config.read(configf) <TAB> dict1 = {} <TAB> options = config.options(section) <TAB> for option in options: <TAB> <TAB> try: <TAB> <TAB> <TAB> dict1[option] = config.get(section, option) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> DebugPrint(""skip: %s"" % option) <TAB> <TAB> except: <TAB> <TAB> <TAB> print(""Exception on %s!"" % option) <TAB> <TAB> <TAB> dict1[option] = None <TAB> return dict1",false,if dict1 [ option ] == - 1 :,if dict1 [ option ] is None :,0.29,0.0
"def on_success(result): <TAB> subtasks = {} <TAB> if result: <TAB> <TAB> subtasks = { <TAB> <TAB> <TAB> self.nodes_keys.inverse[s[""node_id""]]: s.get(""subtask_id"") <TAB> <TAB> <TAB> for s in result <TAB> <TAB> <TAB> if s.get(""status"") == ""Failure"" <TAB> <TAB> } <TAB> if subtasks: <TAB> <TAB> print(""subtask finished"") <TAB> <TAB> self.next() <TAB> else: <TAB> <TAB> print(""waiting for a subtask to finish"") <TAB> <TAB> time.sleep(10)",true,"if s . get ( ""status"" ) == ""Failure""","if s . get ( ""status"" ) == ""Failure""",0.75,0.0
"def redirect_aware_commmunicate(p, sys=_sys): <TAB> """"""Variant of process.communicate that works with in process I/O redirection."""""" <TAB> assert sys is not None <TAB> out, err = p.communicate() <TAB> if redirecting_io(sys=sys): <TAB> <TAB> if out: <TAB> <TAB> <TAB> # We don't unicodify in Python2 because sys.stdout may be a <TAB> <TAB> <TAB> # cStringIO.StringIO object, which does not accept Unicode strings <TAB> <TAB> <TAB> out = unicodify(out) <TAB> <TAB> <TAB> sys.stdout.write(out) <TAB> <TAB> <TAB> out = None <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> err = unicodify(err) <TAB> <TAB> <TAB> sys.stderr.write(err) <TAB> <TAB> <TAB> err = None <TAB> return out, err",true,if err :,if err :,0.53,0.0
"def __exit__(self, *args, **kwargs): <TAB> self._samples_cache = {} <TAB> if is_validation_enabled() and isinstance(self.prior, dict): <TAB> <TAB> extra = set(self.prior) - self._param_hits <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> warnings.warn( <TAB> <TAB> <TAB> <TAB> ""pyro.module prior did not find params ['{}']. "" <TAB> <TAB> <TAB> <TAB> ""Did you instead mean one of ['{}']?"".format( <TAB> <TAB> <TAB> <TAB> <TAB> ""', '"".join(extra), ""', '"".join(self._param_misses) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return super().__exit__(*args, **kwargs)",true,if extra :,if extra :,0.53,0.0
def __download_thread(self): <TAB> while True: <TAB> <TAB> if not self.__queue.empty(): <TAB> <TAB> <TAB> self.__current_download = self.__queue.get() <TAB> <TAB> <TAB> self.__download_file(self.__current_download) <TAB> <TAB> time.sleep(0.1),true,if not self . __queue . empty ( ) :,if not self . __queue . empty ( ) :,0.75,0.0
"def plot_timer_command(args): <TAB> import nnabla.monitor as M <TAB> format_unit = dict( <TAB> <TAB> s=""seconds"", <TAB> <TAB> m=""minutes"", <TAB> <TAB> h=""hours"", <TAB> <TAB> d=""days"", <TAB> ) <TAB> if not args.ylabel: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> args.ylabel = ""Total elapsed time [{}]"".format(format_unit[args.time_unit]) <TAB> <TAB> else: <TAB> <TAB> <TAB> args.ylabel = ""Elapsed time [{}/iter]"".format(format_unit[args.time_unit]) <TAB> plot_any_command( <TAB> <TAB> args, M.plot_time_elapsed, dict(elapsed=args.elapsed, unit=args.time_unit) <TAB> ) <TAB> return True",true,if args . elapsed :,if args . elapsed :,0.75,0.0
"def resolve_page(root: ChannelContext[models.MenuItem], info, **kwargs): <TAB> if root.node.page_id: <TAB> <TAB> requestor = get_user_or_app_from_context(info.context) <TAB> <TAB> requestor_has_access_to_all = requestor.is_active and requestor.has_perm( <TAB> <TAB> <TAB> PagePermissions.MANAGE_PAGES <TAB> <TAB> ) <TAB> <TAB> return ( <TAB> <TAB> <TAB> PageByIdLoader(info.context) <TAB> <TAB> <TAB> .load(root.node.page_id) <TAB> <TAB> <TAB> .then( <TAB> <TAB> <TAB> <TAB> lambda page: page <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> else None <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> return None",false,if requestor_has_access_to_all or page . is_visible,if requestor_has_access_to_all,0.04,0.0
"def find(self, pattern): <TAB> """"""Find pages in database."""""" <TAB> results = self._search_keyword(pattern) <TAB> pat = re.compile(""(.*?)(%s)(.*?)( \(.*\))?$"" % re.escape(pattern), re.I) <TAB> if results: <TAB> <TAB> for name, keyword, url in results: <TAB> <TAB> <TAB> if os.isatty(sys.stdout.fileno()): <TAB> <TAB> <TAB> <TAB> keyword = pat.sub( <TAB> <TAB> <TAB> <TAB> <TAB> r""\1\033[1;31m\2\033[0m\3\033[1;33m\4\033[0m"", keyword <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> print(""%s - %s"" % (keyword, name)) <TAB> else: <TAB> <TAB> raise RuntimeError(""%s: nothing appropriate."" % pattern)",true,if os . isatty ( sys . stdout . fileno ( ) ) :,if os . isatty ( sys . stdout . fileno ( ) ) :,0.75,0.0
"def _certonly_new_request_common(self, mock_client, args=None): <TAB> with mock.patch( <TAB> <TAB> ""certbot._internal.main._find_lineage_for_domains_and_certname"" <TAB> ) as mock_renewal: <TAB> <TAB> mock_renewal.return_value = (""newcert"", None) <TAB> <TAB> with mock.patch(""certbot._internal.main._init_le_client"") as mock_init: <TAB> <TAB> <TAB> mock_init.return_value = mock_client <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> args = [] <TAB> <TAB> <TAB> args += ""-d foo.bar -a standalone certonly"".split() <TAB> <TAB> <TAB> self._call(args)",true,if args is None :,if args is None :,0.75,0.0
"def __init__(self, *args, **kw): <TAB> if len(args) > 1: <TAB> <TAB> raise TypeError(""MultiDict can only be called with one positional "" ""argument"") <TAB> if args: <TAB> <TAB> if hasattr(args[0], ""iteritems""): <TAB> <TAB> <TAB> items = list(args[0].iteritems()) <TAB> <TAB> elif hasattr(args[0], ""items""): <TAB> <TAB> <TAB> items = list(args[0].items()) <TAB> <TAB> else: <TAB> <TAB> <TAB> items = list(args[0]) <TAB> <TAB> self._items = items <TAB> else: <TAB> <TAB> self._items = [] <TAB> if kw: <TAB> <TAB> self._items.extend(kw.items())",false,"if hasattr ( args [ 0 ] , ""iteritems"" ) :","elif hasattr ( args [ 0 ] , ""items"" ) :",0.35,0.0
"def test08_ExceptionTypes(self): <TAB> self.assertTrue(issubclass(db.DBError, Exception)) <TAB> for i, j in db.__dict__.items(): <TAB> <TAB> if i.startswith(""DB"") and i.endswith(""Error""): <TAB> <TAB> <TAB> self.assertTrue(issubclass(j, db.DBError), msg=i) <TAB> <TAB> <TAB> if i not in (""DBKeyEmptyError"", ""DBNotFoundError""): <TAB> <TAB> <TAB> <TAB> self.assertFalse(issubclass(j, KeyError), msg=i) <TAB> # This two exceptions have two bases <TAB> self.assertTrue(issubclass(db.DBKeyEmptyError, KeyError)) <TAB> self.assertTrue(issubclass(db.DBNotFoundError, KeyError))",true,"if i . startswith ( ""DB"" ) and i . endswith ( ""Error"" ) :","if i . startswith ( ""DB"" ) and i . endswith ( ""Error"" ) :",1.0,0.0
"def _delegate_to_sinks(self, value: Any) -> None: <TAB> for sink in self._sinks: <TAB> <TAB> if isinstance(sink, AgentT): <TAB> <TAB> <TAB> await sink.send(value=value) <TAB> <TAB> elif isinstance(sink, ChannelT): <TAB> <TAB> <TAB> await cast(TopicT, sink).send(value=value) <TAB> <TAB> else: <TAB> <TAB> <TAB> await maybe_async(cast(Callable, sink)(value))",true,"elif isinstance ( sink , ChannelT ) :","elif isinstance ( sink , ChannelT ) :",0.75,0.0
"def _select_block(str_in, start_tag, end_tag): <TAB> """"""Select first block delimited by start_tag and end_tag"""""" <TAB> start_pos = str_in.find(start_tag) <TAB> if start_pos < 0: <TAB> <TAB> raise ValueError(""start_tag not found"") <TAB> depth = 0 <TAB> for pos in range(start_pos, len(str_in)): <TAB> <TAB> if str_in[pos] == start_tag: <TAB> <TAB> <TAB> depth += 1 <TAB> <TAB> elif str_in[pos] == end_tag: <TAB> <TAB> <TAB> depth -= 1 <TAB> <TAB> if depth == 0: <TAB> <TAB> <TAB> break <TAB> sel = str_in[start_pos + 1 : pos] <TAB> return sel",true,elif str_in [ pos ] == end_tag :,elif str_in [ pos ] == end_tag :,1.0,0.0
"def confirm(request): <TAB> details = request.session.get(""reauthenticate"") <TAB> if not details: <TAB> <TAB> return redirect(""home"") <TAB> # Monkey patch request <TAB> request.user = User.objects.get(pk=details[""user_pk""]) <TAB> if request.method == ""POST"": <TAB> <TAB> confirm_form = PasswordConfirmForm(request, request.POST) <TAB> <TAB> if confirm_form.is_valid(): <TAB> <TAB> <TAB> request.session.pop(""reauthenticate"") <TAB> <TAB> <TAB> request.session[""reauthenticate_done""] = True <TAB> <TAB> <TAB> return redirect(""social:complete"", backend=details[""backend""]) <TAB> else: <TAB> <TAB> confirm_form = PasswordConfirmForm(request) <TAB> context = {""confirm_form"": confirm_form} <TAB> context.update(details) <TAB> return render(request, ""accounts/confirm.html"", context)",true,if confirm_form . is_valid ( ) :,if confirm_form . is_valid ( ) :,0.75,0.0
"def verify_credentials(self): <TAB> if self.enabled: <TAB> <TAB> response = requests.get( <TAB> <TAB> <TAB> ""https://api.exotel.com/v1/Accounts/{sid}"".format(sid=self.account_sid), <TAB> <TAB> <TAB> auth=(self.api_key, self.api_token), <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> frappe.throw(_(""Invalid credentials""))",true,if response . status_code != 200 :,if response . status_code != 200 :,0.75,0.0
"def pixbufrenderer(self, column, crp, model, it): <TAB> tok = model.get_value(it, 0) <TAB> if tok.type == ""class"": <TAB> <TAB> icon = ""class"" <TAB> else: <TAB> <TAB> if tok.visibility == ""private"": <TAB> <TAB> <TAB> icon = ""method_priv"" <TAB> <TAB> elif tok.visibility == ""protected"": <TAB> <TAB> <TAB> icon = ""method_prot"" <TAB> <TAB> else: <TAB> <TAB> <TAB> icon = ""method"" <TAB> crp.set_property(""pixbuf"", imagelibrary.pixbufs[icon])",false,"if tok . visibility == ""private"" :","elif tok . visibility == ""protected"" :",0.21,0.0
"def _omit_keywords(self, context): <TAB> omitted_kws = 0 <TAB> for event, elem in context: <TAB> <TAB> # Teardowns aren't omitted to allow checking suite teardown status. <TAB> <TAB> omit = elem.tag == ""kw"" and elem.get(""type"") != ""teardown"" <TAB> <TAB> start = event == ""start"" <TAB> <TAB> if omit and start: <TAB> <TAB> <TAB> omitted_kws += 1 <TAB> <TAB> if not omitted_kws: <TAB> <TAB> <TAB> yield event, elem <TAB> <TAB> elif not start: <TAB> <TAB> <TAB> elem.clear() <TAB> <TAB> if omit and not start: <TAB> <TAB> <TAB> omitted_kws -= 1",true,elif not start :,elif not start :,0.74,0.0
"def on_double_click(self, event): <TAB> # TODO: don't act when the click happens below last item <TAB> path = self.get_selected_path() <TAB> kind = self.get_selected_kind() <TAB> name = self.get_selected_name() <TAB> if kind == ""file"": <TAB> <TAB> if self.should_open_name_in_thonny(name): <TAB> <TAB> <TAB> self.open_file(path) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.open_path_with_system_app(path) <TAB> elif kind == ""dir"": <TAB> <TAB> self.request_focus_into(path) <TAB> return ""break""",true,if self . should_open_name_in_thonny ( name ) :,if self . should_open_name_in_thonny ( name ) :,0.75,0.0
"def search_cve(db: DatabaseInterface, product: Product) -> dict: <TAB> result = {} <TAB> for query_result in db.fetch_multiple(QUERIES[""cve_lookup""]): <TAB> <TAB> cve_entry = CveDbEntry(*query_result) <TAB> <TAB> if _product_matches_cve(product, cve_entry): <TAB> <TAB> <TAB> result[cve_entry.cve_id] = { <TAB> <TAB> <TAB> <TAB> ""score2"": cve_entry.cvss_v2_score, <TAB> <TAB> <TAB> <TAB> ""score3"": cve_entry.cvss_v3_score, <TAB> <TAB> <TAB> <TAB> ""cpe_version"": build_version_string(cve_entry), <TAB> <TAB> <TAB> } <TAB> return result",true,"if _product_matches_cve ( product , cve_entry ) :","if _product_matches_cve ( product , cve_entry ) :",0.75,0.0
"def find_go_files_mtime(app_files): <TAB> files, mtime = [], 0 <TAB> for f, mt in app_files.items(): <TAB> <TAB> if not f.endswith("".go""): <TAB> <TAB> <TAB> continue <TAB> <TAB> if APP_CONFIG.nobuild_files.match(f): <TAB> <TAB> <TAB> continue <TAB> <TAB> files.append(f) <TAB> <TAB> mtime = max(mtime, mt) <TAB> return files, mtime",true,if APP_CONFIG . nobuild_files . match ( f ) :,if APP_CONFIG . nobuild_files . match ( f ) :,0.75,0.0
"def wrapper(filename): <TAB> mtime = getmtime(filename) <TAB> with lock: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> old_mtime, result = cache.pop(filename) <TAB> <TAB> <TAB> if old_mtime == mtime: <TAB> <TAB> <TAB> <TAB> # Move to the end <TAB> <TAB> <TAB> <TAB> cache[filename] = old_mtime, result <TAB> <TAB> <TAB> <TAB> return result <TAB> result = function(filename) <TAB> with lock: <TAB> <TAB> cache[filename] = mtime, result  # at the end <TAB> <TAB> if len(cache) > max_size: <TAB> <TAB> <TAB> cache.popitem(last=False) <TAB> return result",false,if filename in cache :,if len ( cache ) > max_size :,0.03,0.0
"def Tokenize(s): <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE.findall(s): <TAB> <TAB> # The type checker can't know the true type of item! <TAB> <TAB> item = cast(TupleStr4, item) <TAB> <TAB> if item[0]: <TAB> <TAB> <TAB> typ = ""number"" <TAB> <TAB> <TAB> val = item[0] <TAB> <TAB> elif item[1]: <TAB> <TAB> <TAB> typ = ""name"" <TAB> <TAB> <TAB> val = item[1] <TAB> <TAB> elif item[2]: <TAB> <TAB> <TAB> typ = item[2] <TAB> <TAB> <TAB> val = item[2] <TAB> <TAB> elif item[3]: <TAB> <TAB> <TAB> typ = item[3] <TAB> <TAB> <TAB> val = item[3] <TAB> <TAB> yield Token(typ, val)",false,if item [ 0 ] :,elif item [ 3 ] :,0.06,0.0
"def _show_encoders(self, *args, **kwargs): <TAB> if issubclass(self.current_module.__class__, BasePayload): <TAB> <TAB> encoders = self.current_module.get_encoders() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> headers = (""Encoder"", ""Name"", ""Description"") <TAB> <TAB> <TAB> print_table(headers, *encoders, max_column_length=100) <TAB> <TAB> <TAB> return <TAB> print_error(""No encoders available"")",true,if encoders :,if encoders :,0.53,0.0
"def __init__(self): <TAB> Builder.__init__(self, commandName=""VCExpress.exe"", formatName=""msvcProject"") <TAB> for key in [""VS90COMNTOOLS"", ""VC80COMNTOOLS"", ""VC71COMNTOOLS""]: <TAB> <TAB> if os.environ.has_key(key): <TAB> <TAB> <TAB> self.programDir = os.path.join(os.environ[key], "".."", ""IDE"") <TAB> if self.programDir is None: <TAB> <TAB> for version in [""9.0"", ""8"", "".NET 2003""]: <TAB> <TAB> <TAB> msvcDir = ( <TAB> <TAB> <TAB> <TAB> ""C:\\Program Files\\Microsoft Visual Studio %s\\Common7\\IDE"" % version <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if os.path.exists(msvcDir): <TAB> <TAB> <TAB> <TAB> self.programDir = msvcDir",true,if os . environ . has_key ( key ) :,if os . environ . has_key ( key ) :,0.75,0.0
"def _inner(*args, **kwargs): <TAB> component_manager = args[0].component_manager <TAB> for condition_name in condition_names: <TAB> <TAB> condition_result, err_msg = component_manager.evaluate_condition(condition_name) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ComponentStartConditionNotMetError(err_msg) <TAB> if not component_manager.all_components_running(*components): <TAB> <TAB> raise ComponentsNotStartedError( <TAB> <TAB> <TAB> f""the following required components have not yet started: {json.dumps(components)}"" <TAB> <TAB> ) <TAB> return method(*args, **kwargs)",true,if not condition_result :,if not condition_result :,0.75,0.0
"def _gridconvvalue(self, value): <TAB> if isinstance(value, (str, _tkinter.Tcl_Obj)): <TAB> <TAB> try: <TAB> <TAB> <TAB> svalue = str(value) <TAB> <TAB> <TAB> if not svalue: <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> elif ""."" in svalue: <TAB> <TAB> <TAB> <TAB> return self.tk.getdouble(svalue) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return self.tk.getint(svalue) <TAB> <TAB> except (ValueError, TclError): <TAB> <TAB> <TAB> pass <TAB> return value",true,"elif ""."" in svalue :","elif ""."" in svalue :",0.75,0.0
"def check_songs(): <TAB> desc = numeric_phrase(""%d song"", ""%d songs"", len(songs)) <TAB> with Task(_(""Rescan songs""), desc) as task: <TAB> <TAB> task.copool(check_songs) <TAB> <TAB> for i, song in enumerate(songs): <TAB> <TAB> <TAB> song = song._song <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> app.library.reload(song) <TAB> <TAB> <TAB> task.update((float(i) + 1) / len(songs)) <TAB> <TAB> <TAB> yield",false,if song in app . library :,if song :,0.04,0.0
"def initialize(self): <TAB> nn.init.xavier_uniform_(self.linear.weight.data) <TAB> if self.linear.bias is not None: <TAB> <TAB> self.linear.bias.data.uniform_(-1.0, 1.0) <TAB> if self.self_layer: <TAB> <TAB> nn.init.xavier_uniform_(self.linear_self.weight.data) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.linear_self.bias.data.uniform_(-1.0, 1.0)",false,if self . linear_self . bias is not None :,if self . bias is not None :,0.47,0.0
"def test_row(self, row): <TAB> for idx, test in self.patterns.items(): <TAB> <TAB> try: <TAB> <TAB> <TAB> value = row[idx] <TAB> <TAB> except IndexError: <TAB> <TAB> <TAB> value = """" <TAB> <TAB> result = test(value) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if result: <TAB> <TAB> <TAB> <TAB> return not self.inverse  # True <TAB> <TAB> else: <TAB> <TAB> <TAB> if not result: <TAB> <TAB> <TAB> <TAB> return self.inverse  # False <TAB> if self.any_match: <TAB> <TAB> return self.inverse  # False <TAB> else: <TAB> <TAB> return not self.inverse  # True",true,if self . any_match :,if self . any_match :,0.75,0.0
"def toterminal(self, tw): <TAB> for element in self.chain: <TAB> <TAB> element[0].toterminal(tw) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tw.line("""") <TAB> <TAB> <TAB> tw.line(element[2], yellow=True) <TAB> super(ExceptionChainRepr, self).toterminal(tw)",false,if element [ 2 ] is not None :,if len ( element ) > 2 :,0.02,0.0
"def runMainLoop(self): <TAB> """"""The curses gui main loop."""""" <TAB> # pylint: disable=no-member <TAB> # <TAB> # Do NOT change g.app! <TAB> self.curses_app = LeoApp() <TAB> stdscr = curses.initscr() <TAB> if 1:  # Must follow initscr. <TAB> <TAB> self.dump_keys() <TAB> try: <TAB> <TAB> self.curses_app.run() <TAB> <TAB> # run calls CApp.main(), which calls CGui.run(). <TAB> finally: <TAB> <TAB> curses.nocbreak() <TAB> <TAB> stdscr.keypad(0) <TAB> <TAB> curses.echo() <TAB> <TAB> curses.endwin() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> g.pr(""Exiting Leo..."")",false,"if ""shutdown"" in g . app . debug :",if self . verbose :,0.02,0.0
"def test_chunkcoding(self): <TAB> for native, utf8 in zip(*[StringIO(f).readlines() for f in self.tstring]): <TAB> <TAB> u = self.decode(native)[0] <TAB> <TAB> self.assertEqual(u, utf8.decode(""utf-8"")) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.assertEqual(native, self.encode(u)[0])",false,if self . roundtriptest :,if u :,0.04,0.0
"def reload_sanitize_allowlist(self, explicit=True): <TAB> self.sanitize_allowlist = [] <TAB> try: <TAB> <TAB> with open(self.sanitize_allowlist_file) as f: <TAB> <TAB> <TAB> for line in f.readlines(): <TAB> <TAB> <TAB> <TAB> if not line.startswith(""#""): <TAB> <TAB> <TAB> <TAB> <TAB> self.sanitize_allowlist.append(line.strip()) <TAB> except OSError: <TAB> <TAB> if explicit: <TAB> <TAB> <TAB> log.warning( <TAB> <TAB> <TAB> <TAB> ""Sanitize log file explicitly specified as '%s' but does not exist, continuing with no tools allowlisted."", <TAB> <TAB> <TAB> <TAB> self.sanitize_allowlist_file, <TAB> <TAB> <TAB> )",true,"if not line . startswith ( ""#"" ) :","if not line . startswith ( ""#"" ) :",0.75,0.0
"def get_all_extensions(subtree=None): <TAB> if subtree is None: <TAB> <TAB> subtree = full_extension_tree() <TAB> result = [] <TAB> if isinstance(subtree, dict): <TAB> <TAB> for value in subtree.values(): <TAB> <TAB> <TAB> if isinstance(value, dict): <TAB> <TAB> <TAB> <TAB> result += get_all_extensions(value) <TAB> <TAB> <TAB> elif isinstance(value, (ContentTypeMapping, ContentTypeDetector)): <TAB> <TAB> <TAB> <TAB> result += value.extensions <TAB> <TAB> <TAB> elif isinstance(value, (list, tuple)): <TAB> <TAB> <TAB> <TAB> result += value <TAB> elif isinstance(subtree, (ContentTypeMapping, ContentTypeDetector)): <TAB> <TAB> result = subtree.extensions <TAB> elif isinstance(subtree, (list, tuple)): <TAB> <TAB> result = subtree <TAB> return result",true,"elif isinstance ( value , ( ContentTypeMapping , ContentTypeDetector ) ) :","elif isinstance ( value , ( ContentTypeMapping , ContentTypeDetector ) ) :",0.75,0.0
"def _configuration_dict_to_commandlist(name, config_dict): <TAB> command_list = [""config:%s"" % name] <TAB> for key, value in config_dict.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if value: <TAB> <TAB> <TAB> <TAB> b = ""true"" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> b = ""false"" <TAB> <TAB> <TAB> command_list.append(""%s:%s"" % (key, b)) <TAB> <TAB> else: <TAB> <TAB> <TAB> command_list.append(""%s:%s"" % (key, value)) <TAB> return command_list",false,if type ( value ) is bool :,if key in _DEFAULT_CONFIGURATION_KEYS :,0.02,0.0
"def _RewriteModinfo( <TAB> self, <TAB> modinfo, <TAB> obj_kernel_version, <TAB> this_kernel_version, <TAB> info_strings=None, <TAB> to_remove=None, ): <TAB> new_modinfo = """" <TAB> for line in modinfo.split(""\x00""): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if to_remove and line.split(""="")[0] == to_remove: <TAB> <TAB> <TAB> continue <TAB> <TAB> if info_strings is not None: <TAB> <TAB> <TAB> info_strings.add(line.split(""="")[0]) <TAB> <TAB> if line.startswith(""vermagic""): <TAB> <TAB> <TAB> line = line.replace(obj_kernel_version, this_kernel_version) <TAB> <TAB> new_modinfo += line + ""\x00"" <TAB> return new_modinfo",false,if not line :,"if line == """" :",0.05,0.0
"def zip_random_open_test(self, f, compression): <TAB> self.make_test_archive(f, compression) <TAB> # Read the ZIP archive <TAB> with zipfile.ZipFile(f, ""r"", compression) as zipfp: <TAB> <TAB> zipdata1 = [] <TAB> <TAB> with zipfp.open(TESTFN) as zipopen1: <TAB> <TAB> <TAB> while True: <TAB> <TAB> <TAB> <TAB> read_data = zipopen1.read(randint(1, 1024)) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> zipdata1.append(read_data) <TAB> <TAB> testdata = """".join(zipdata1) <TAB> <TAB> self.assertEqual(len(testdata), len(self.data)) <TAB> <TAB> self.assertEqual(testdata, self.data)",true,if not read_data :,if not read_data :,0.75,0.0
"def _memoized(*args): <TAB> now = time.time() <TAB> try: <TAB> <TAB> value, last_update = self.cache[args] <TAB> <TAB> age = now - last_update <TAB> <TAB> if self._call_count > self.ctl or age > self.ttl: <TAB> <TAB> <TAB> self._call_count = 0 <TAB> <TAB> <TAB> raise AttributeError <TAB> <TAB> if self.ctl: <TAB> <TAB> <TAB> self._call_count += 1 <TAB> <TAB> return value <TAB> except (KeyError, AttributeError): <TAB> <TAB> value = func(*args) <TAB> <TAB> if value: <TAB> <TAB> <TAB> self.cache[args] = (value, now) <TAB> <TAB> return value <TAB> except TypeError: <TAB> <TAB> return func(*args)",true,if self . _call_count > self . ctl or age > self . ttl :,if self . _call_count > self . ctl or age > self . ttl :,1.0,0.0
"def on_data(res): <TAB> if terminate.is_set(): <TAB> <TAB> return <TAB> if args.strings and not args.no_content: <TAB> <TAB> if type(res) == tuple: <TAB> <TAB> <TAB> f, v = res <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> f = f.encode(""utf-8"") <TAB> <TAB> <TAB> if type(v) == unicode: <TAB> <TAB> <TAB> <TAB> v = v.encode(""utf-8"") <TAB> <TAB> <TAB> self.success(""{}: {}"".format(f, v)) <TAB> <TAB> elif not args.content_only: <TAB> <TAB> <TAB> self.success(res) <TAB> else: <TAB> <TAB> self.success(res)",true,if type ( f ) == unicode :,if type ( f ) == unicode :,0.75,0.0
"def _finalize_setup_keywords(self): <TAB> for ep in pkg_resources.iter_entry_points(""distutils.setup_keywords""): <TAB> <TAB> value = getattr(self, ep.name, None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ep.require(installer=self.fetch_build_egg) <TAB> <TAB> <TAB> ep.load()(self, ep.name, value)",true,if value is not None :,if value is not None :,0.75,0.0
"def test_attributes_types(self): <TAB> if not self.connection.strategy.pooled: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.connection.refresh_server_info() <TAB> <TAB> self.assertEqual( <TAB> <TAB> <TAB> type(self.connection.server.schema.attribute_types[""cn""]), AttributeTypeInfo <TAB> <TAB> )",false,if not self . connection . server . info :,"if ""cn"" in self . connection . server . schema . attribute_types :",0.24,0.0
"def to_key(literal_or_identifier): <TAB> """"""returns string representation of this object"""""" <TAB> if literal_or_identifier[""type""] == ""Identifier"": <TAB> <TAB> return literal_or_identifier[""name""] <TAB> elif literal_or_identifier[""type""] == ""Literal"": <TAB> <TAB> k = literal_or_identifier[""value""] <TAB> <TAB> if isinstance(k, float): <TAB> <TAB> <TAB> return unicode(float_repr(k)) <TAB> <TAB> elif ""regex"" in literal_or_identifier: <TAB> <TAB> <TAB> return compose_regex(k) <TAB> <TAB> elif isinstance(k, bool): <TAB> <TAB> <TAB> return ""true"" if k else ""false"" <TAB> <TAB> elif k is None: <TAB> <TAB> <TAB> return ""null"" <TAB> <TAB> else: <TAB> <TAB> <TAB> return unicode(k)",false,"elif isinstance ( k , bool ) :",elif k is None :,0.12,0.0
"def list2rec(x, test=False): <TAB> if test: <TAB> <TAB> vid = ""{}_{:06d}_{:06d}"".format(x[0], int(x[1]), int(x[2])) <TAB> <TAB> label = -1  # label unknown <TAB> <TAB> return vid, label <TAB> else: <TAB> <TAB> vid = ""{}_{:06d}_{:06d}"".format(x[1], int(x[2]), int(x[3])) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> vid = ""{}/{}"".format(convert_label(x[0]), vid) <TAB> <TAB> else: <TAB> <TAB> <TAB> assert level == 1 <TAB> <TAB> label = class_mapping[convert_label(x[0])] <TAB> <TAB> return vid, label",false,if level == 2 :,if level == 0 :,0.39,0.0
"def _expand_env(self, snapcraft_yaml): <TAB> environment_keys = [""name"", ""version""] <TAB> for key in snapcraft_yaml: <TAB> <TAB> if any((key == env_key for env_key in environment_keys)): <TAB> <TAB> <TAB> continue <TAB> <TAB> replacements = environment_to_replacements( <TAB> <TAB> <TAB> get_snapcraft_global_environment(self.project) <TAB> <TAB> ) <TAB> <TAB> snapcraft_yaml[key] = replace_attr(snapcraft_yaml[key], replacements) <TAB> return snapcraft_yaml",true,if any ( ( key == env_key for env_key in environment_keys ) ) :,if any ( ( key == env_key for env_key in environment_keys ) ) :,0.75,0.0
"def enableCtrls(self): <TAB> # Check if each ctrl has a requirement or an incompatibility, <TAB> # look it up, and enable/disable if so <TAB> for data in self.storySettingsData: <TAB> <TAB> name = data[""name""] <TAB> <TAB> if name in self.ctrls: <TAB> <TAB> <TAB> if ""requires"" in data: <TAB> <TAB> <TAB> <TAB> set = self.getSetting(data[""requires""]) <TAB> <TAB> <TAB> <TAB> for i in self.ctrls[name]: <TAB> <TAB> <TAB> <TAB> <TAB> i.Enable(set not in [""off"", ""false"", ""0""])",true,if name in self . ctrls :,if name in self . ctrls :,0.75,0.0
"def __init__(self, *args, **kwargs): <TAB> super(ChallengePhaseCreateSerializer, self).__init__(*args, **kwargs) <TAB> context = kwargs.get(""context"") <TAB> if context: <TAB> <TAB> challenge = context.get(""challenge"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> kwargs[""data""][""challenge""] = challenge.pk <TAB> <TAB> test_annotation = context.get(""test_annotation"") <TAB> <TAB> if test_annotation: <TAB> <TAB> <TAB> kwargs[""data""][""test_annotation""] = test_annotation",true,if challenge :,if challenge :,0.53,0.0
"def set_inactive(self): <TAB> for title in self.gramplet_map: <TAB> <TAB> if self.gramplet_map[title].pui: <TAB> <TAB> <TAB> if self.gramplet_map[title].gstate != ""detached"": <TAB> <TAB> <TAB> <TAB> self.gramplet_map[title].pui.active = False",false,"if self . gramplet_map [ title ] . gstate != ""detached"" :","if self .gramplet_map [ title ] . gstate != ""detached"" :",0.59,0.0
"def authenticate(username, password): <TAB> try: <TAB> <TAB> u = User.objects.get(username=username) <TAB> <TAB> if check_password_hash(u.password, password): <TAB> <TAB> <TAB> userLogger.info(""User logged in : %s"", username) <TAB> <TAB> <TAB> return u <TAB> <TAB> else: <TAB> <TAB> <TAB> userLogger.warn(""Attempt to log in to : %s"", username) <TAB> <TAB> <TAB> return False <TAB> except DoesNotExist: <TAB> <TAB> return False",true,"if check_password_hash ( u . password , password ) :","if check_password_hash ( u . password , password ) :",1.0,0.0
def _check_date(self): <TAB> if not self.value: <TAB> <TAB> return None <TAB> if not self.allow_date_in_past: <TAB> <TAB> if self.value < self.date_or_datetime().today(): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.value = self.date_or_datetime().today() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.value = self.date_or_datetime().today() + datetime.timedelta(1),false,if self . allow_todays_date :,if self . allow_date_in_past :,0.39,0.0
"def update(self, E=None, **F): <TAB> if E: <TAB> <TAB> if hasattr(E, ""keys""): <TAB> <TAB> <TAB> # Update with `E` dictionary <TAB> <TAB> <TAB> for k in E: <TAB> <TAB> <TAB> <TAB> self[k] = E[k] <TAB> <TAB> else: <TAB> <TAB> <TAB> # Update with `E` items <TAB> <TAB> <TAB> for (k, v) in E: <TAB> <TAB> <TAB> <TAB> self[k] = v <TAB> # Update with `F` dictionary <TAB> for k in F: <TAB> <TAB> self[k] = F[k]",true,"if hasattr ( E , ""keys"" ) :","if hasattr ( E , ""keys"" ) :",0.75,0.0
"def _get_quota_availability(self): <TAB> quotas_ok = defaultdict(int) <TAB> qa = QuotaAvailability() <TAB> qa.queue(*[k for k, v in self._quota_diff.items() if v > 0]) <TAB> qa.compute(now_dt=self.now_dt) <TAB> for quota, count in self._quota_diff.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> quotas_ok[quota] = 0 <TAB> <TAB> <TAB> break <TAB> <TAB> avail = qa.results[quota] <TAB> <TAB> if avail[1] is not None and avail[1] < count: <TAB> <TAB> <TAB> quotas_ok[quota] = min(count, avail[1]) <TAB> <TAB> else: <TAB> <TAB> <TAB> quotas_ok[quota] = count <TAB> return quotas_ok",false,if count <= 0 :,if count == 0 :,0.33,0.0
"def gen_env_vars(): <TAB> for fd_id, fd in zip(STDIO_DESCRIPTORS, (stdin, stdout, stderr)): <TAB> <TAB> is_atty = fd.isatty() <TAB> <TAB> yield (cls.TTY_ENV_TMPL.format(fd_id), cls.encode_env_var_value(int(is_atty))) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> yield (cls.TTY_PATH_ENV.format(fd_id), os.ttyname(fd.fileno()) or b"""")",true,if is_atty :,if is_atty :,0.53,0.0
"def _convertDict(self, d): <TAB> r = {} <TAB> for k, v in d.items(): <TAB> <TAB> if isinstance(v, bytes): <TAB> <TAB> <TAB> v = str(v, ""utf-8"") <TAB> <TAB> elif isinstance(v, list) or isinstance(v, tuple): <TAB> <TAB> <TAB> v = self._convertList(v) <TAB> <TAB> elif isinstance(v, dict): <TAB> <TAB> <TAB> v = self._convertDict(v) <TAB> <TAB> if isinstance(k, bytes): <TAB> <TAB> <TAB> k = str(k, ""utf-8"") <TAB> <TAB> r[k] = v <TAB> return r",false,"if isinstance ( k , bytes ) :","elif isinstance ( v , list ) or isinstance ( v , tuple ) :",0.16,0.0
"def get_attribute_value(self, nodeid, attr): <TAB> with self._lock: <TAB> <TAB> self.logger.debug(""get attr val: %s %s"", nodeid, attr) <TAB> <TAB> if nodeid not in self._nodes: <TAB> <TAB> <TAB> dv = ua.DataValue() <TAB> <TAB> <TAB> dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadNodeIdUnknown) <TAB> <TAB> <TAB> return dv <TAB> <TAB> node = self._nodes[nodeid] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> dv = ua.DataValue() <TAB> <TAB> <TAB> dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadAttributeIdInvalid) <TAB> <TAB> <TAB> return dv <TAB> <TAB> attval = node.attributes[attr] <TAB> <TAB> if attval.value_callback: <TAB> <TAB> <TAB> return attval.value_callback() <TAB> <TAB> return attval.value",true,if attr not in node . attributes :,if attr not in node . attributes :,0.75,0.0
"def conninfo_parse(dsn): <TAB> ret = {} <TAB> length = len(dsn) <TAB> i = 0 <TAB> while i < length: <TAB> <TAB> if dsn[i].isspace(): <TAB> <TAB> <TAB> i += 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> param_match = PARAMETER_RE.match(dsn[i:]) <TAB> <TAB> if not param_match: <TAB> <TAB> <TAB> return <TAB> <TAB> param = param_match.group(1) <TAB> <TAB> i += param_match.end() <TAB> <TAB> if i >= length: <TAB> <TAB> <TAB> return <TAB> <TAB> value, end = read_param_value(dsn[i:]) <TAB> <TAB> if value is None: <TAB> <TAB> <TAB> return <TAB> <TAB> i += end <TAB> <TAB> ret[param] = value <TAB> return ret",true,if dsn [ i ] . isspace ( ) :,if dsn [ i ] . isspace ( ) :,0.75,0.0
"def connect(self, buttons): <TAB> for button in buttons: <TAB> <TAB> assert button is not None <TAB> <TAB> handled = False <TAB> <TAB> for handler_idx in range(0, len(self.__signal_handlers)): <TAB> <TAB> <TAB> (obj_class, signal, handler, handler_id) = self.__signal_handlers[ <TAB> <TAB> <TAB> <TAB> handler_idx <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> if isinstance(button, obj_class): <TAB> <TAB> <TAB> <TAB> handler_id = button.connect(signal, handler) <TAB> <TAB> <TAB> <TAB> handled = True <TAB> <TAB> <TAB> self.__signal_handlers[handler_idx] = ( <TAB> <TAB> <TAB> <TAB> obj_class, <TAB> <TAB> <TAB> <TAB> signal, <TAB> <TAB> <TAB> <TAB> handler, <TAB> <TAB> <TAB> <TAB> handler_id, <TAB> <TAB> <TAB> ) <TAB> <TAB> assert handled",true,"if isinstance ( button , obj_class ) :","if isinstance ( button , obj_class ) :",0.75,0.0
"def _parse_display(display): <TAB> """"""Parse an X11 display value"""""" <TAB> try: <TAB> <TAB> host, dpynum = display.rsplit("":"", 1) <TAB> <TAB> if host.startswith(""["") and host.endswith(""]""): <TAB> <TAB> <TAB> host = host[1:-1] <TAB> <TAB> idx = dpynum.find(""."") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> screen = int(dpynum[idx + 1 :]) <TAB> <TAB> <TAB> dpynum = dpynum[:idx] <TAB> <TAB> else: <TAB> <TAB> <TAB> screen = 0 <TAB> except (ValueError, UnicodeEncodeError): <TAB> <TAB> raise ValueError(""Invalid X11 display"") from None <TAB> return host, dpynum, screen",true,if idx >= 0 :,if idx >= 0 :,0.75,0.0
"def delete_all(path): <TAB> ppath = os.getcwd() <TAB> os.chdir(path) <TAB> for fn in glob.glob(""*""): <TAB> <TAB> fn_full = os.path.join(path, fn) <TAB> <TAB> if os.path.isdir(fn): <TAB> <TAB> <TAB> delete_all(fn_full) <TAB> <TAB> elif fn.endswith("".png""): <TAB> <TAB> <TAB> os.remove(fn_full) <TAB> <TAB> elif fn.endswith("".md""): <TAB> <TAB> <TAB> os.remove(fn_full) <TAB> <TAB> elif DELETE_ALL_OLD: <TAB> <TAB> <TAB> os.remove(fn_full) <TAB> os.chdir(ppath) <TAB> os.rmdir(path)",false,"elif fn . endswith ( "".png"" ) :",elif delete_ALL_OLD :,0.01,0.0
"def _sync_get(self, identifier, *args, **kw): <TAB> self._mutex.acquire() <TAB> try: <TAB> <TAB> try: <TAB> <TAB> <TAB> if identifier in self._values: <TAB> <TAB> <TAB> <TAB> return self._values[identifier] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self._values[identifier] = value = self.creator(identifier, *args, **kw) <TAB> <TAB> <TAB> <TAB> return value <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> self._values[identifier] = value = self.creator(identifier, *args, **kw) <TAB> <TAB> <TAB> return value <TAB> finally: <TAB> <TAB> self._mutex.release()",true,if identifier in self . _values :,if identifier in self . _values :,0.75,0.0
"def _query_fd(self): <TAB> if self.stream is None: <TAB> <TAB> self._last_stat = None, None <TAB> else: <TAB> <TAB> try: <TAB> <TAB> <TAB> st = os.stat(self._filename) <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> e = sys.exc_info()[1] <TAB> <TAB> <TAB> if e.errno != errno.ENOENT: <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> self._last_stat = None, None <TAB> <TAB> else: <TAB> <TAB> <TAB> self._last_stat = st[stat.ST_DEV], st[stat.ST_INO]",true,if e . errno != errno . ENOENT :,if e . errno != errno . ENOENT :,1.0,0.0
"def get_place_name(self, place_handle): <TAB> """"""Obtain a place name"""""" <TAB> text = """" <TAB> if place_handle: <TAB> <TAB> place = self.dbstate.db.get_place_from_handle(place_handle) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> place_title = place_displayer.display(self.dbstate.db, place) <TAB> <TAB> <TAB> if place_title != """": <TAB> <TAB> <TAB> <TAB> if len(place_title) > 25: <TAB> <TAB> <TAB> <TAB> <TAB> text = place_title[:24] + ""..."" <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> text = place_title <TAB> return text",true,if place :,if place :,0.53,0.0
"def test_decoder_state(self): <TAB> # Check that getstate() and setstate() handle the state properly <TAB> u = ""abc123"" <TAB> for encoding in all_unicode_encodings: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.check_state_handling_decode(encoding, u, u.encode(encoding)) <TAB> <TAB> <TAB> self.check_state_handling_encode(encoding, u, u.encode(encoding))",false,if encoding not in broken_unicode_with_stateful :,if encoding in unicode_encodings :,0.15,0.0
"def cleanup(self): <TAB> if os.path.exists(self.meta_gui_dir): <TAB> <TAB> for f in os.listdir(self.meta_gui_dir): <TAB> <TAB> <TAB> if os.path.splitext(f)[1] == "".desktop"": <TAB> <TAB> <TAB> <TAB> os.remove(os.path.join(self.meta_gui_dir, f))",true,"if os . path . splitext ( f ) [ 1 ] == "".desktop"" :","if os . path . splitext ( f ) [ 1 ] == "".desktop"" :",0.75,0.0
"def _have_applied_incense(self): <TAB> for applied_item in inventory.applied_items().all(): <TAB> <TAB> self.logger.info(applied_item) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> mins = format_time(applied_item.expire_ms * 1000) <TAB> <TAB> <TAB> self.logger.info( <TAB> <TAB> <TAB> <TAB> ""Not applying incense, currently active: %s, %s minutes remaining"", <TAB> <TAB> <TAB> <TAB> applied_item.item.name, <TAB> <TAB> <TAB> <TAB> mins, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return True <TAB> <TAB> else: <TAB> <TAB> <TAB> self.logger.info("""") <TAB> <TAB> <TAB> return False <TAB> return False",false,if applied_item . expire_ms > 0 :,if applied_item . active :,0.09,0.0
"def get_closest_point(self, point): <TAB> point = to_point(point) <TAB> cp, cd = None, None <TAB> for p0, p1 in iter_pairs(self.pts, self.connected): <TAB> <TAB> diff = p1 - p0 <TAB> <TAB> l = diff.length <TAB> <TAB> d = diff / l <TAB> <TAB> pp = p0 + d * max(0, min(l, (point - p0).dot(d))) <TAB> <TAB> dist = (point - pp).length <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> cp, cd = pp, dist <TAB> return cp",false,if not cp or dist < cd :,if dist > cp :,0.02,0.0
"def process_return(lines): <TAB> for line in lines: <TAB> <TAB> m = re.fullmatch(r""(?P<param>\w+)\s+:\s+(?P<type>[\w.]+)"", line) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # Once this is in scanpydoc, we can use the fancy hover stuff <TAB> <TAB> <TAB> yield f'**{m[""param""]}** : :class:`~{m[""type""]}`' <TAB> <TAB> else: <TAB> <TAB> <TAB> yield line",true,if m :,if m :,0.53,0.0
"def _classify(nodes_by_level): <TAB> missing, invalid, downloads = [], [], [] <TAB> for level in nodes_by_level: <TAB> <TAB> for node in level: <TAB> <TAB> <TAB> if node.binary == BINARY_MISSING: <TAB> <TAB> <TAB> <TAB> missing.append(node) <TAB> <TAB> <TAB> elif node.binary == BINARY_INVALID: <TAB> <TAB> <TAB> <TAB> invalid.append(node) <TAB> <TAB> <TAB> elif node.binary in (BINARY_UPDATE, BINARY_DOWNLOAD): <TAB> <TAB> <TAB> <TAB> downloads.append(node) <TAB> return missing, invalid, downloads",false,elif node . binary == BINARY_INVALID :,"elif node . binary in ( BINARY_UPDATE , BINARY_DOWNLOAD ) :",0.22,0.0
"def safe_parse_date(date_hdr): <TAB> """"""Parse a Date: or Received: header into a unix timestamp."""""" <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> date_hdr = date_hdr.split("";"")[-1].strip() <TAB> <TAB> msg_ts = long(rfc822.mktime_tz(rfc822.parsedate_tz(date_hdr))) <TAB> <TAB> if (msg_ts > (time.time() + 24 * 3600)) or (msg_ts < 1): <TAB> <TAB> <TAB> return None <TAB> <TAB> else: <TAB> <TAB> <TAB> return msg_ts <TAB> except (ValueError, TypeError, OverflowError): <TAB> <TAB> return None",true,"if "";"" in date_hdr :","if "";"" in date_hdr :",0.75,0.0
"def _on_change(self): <TAB> changed = False <TAB> self.save() <TAB> for key, value in self.data.items(): <TAB> <TAB> if isinstance(value, bool): <TAB> <TAB> <TAB> if value: <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if isinstance(value, int): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> elif value is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> elif len(value) != 0: <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> break <TAB> self._reset_button.disabled = not changed",false,if value != 1 :,if len ( value ) != 0 :,0.03,0.0
"def _rewrite_prepend_append(self, string, prepend, append=None): <TAB> if append is None: <TAB> <TAB> append = prepend <TAB> if not isinstance(string, StringElem): <TAB> <TAB> string = StringElem(string) <TAB> string.sub.insert(0, prepend) <TAB> if unicode(string).endswith(u""\n""): <TAB> <TAB> # Try and remove the last character from the tree <TAB> <TAB> try: <TAB> <TAB> <TAB> lastnode = string.flatten()[-1] <TAB> <TAB> <TAB> if isinstance(lastnode.sub[-1], unicode): <TAB> <TAB> <TAB> <TAB> lastnode.sub[-1] = lastnode.sub[-1].rstrip(u""\n"") <TAB> <TAB> except IndexError: <TAB> <TAB> <TAB> pass <TAB> <TAB> string.sub.append(append + u""\n"") <TAB> else: <TAB> <TAB> string.sub.append(append) <TAB> return string",true,"if isinstance ( lastnode . sub [ - 1 ] , unicode ) :","if isinstance ( lastnode . sub [ - 1 ] , unicode ) :",0.75,0.0
"def parse_indentless_sequence_entry(self): <TAB> if self.check_token(BlockEntryToken): <TAB> <TAB> token = self.get_token() <TAB> <TAB> if not self.check_token(BlockEntryToken, KeyToken, ValueToken, BlockEndToken): <TAB> <TAB> <TAB> self.states.append(self.parse_indentless_sequence_entry) <TAB> <TAB> <TAB> return self.parse_block_node() <TAB> <TAB> else: <TAB> <TAB> <TAB> self.state = self.parse_indentless_sequence_entry <TAB> <TAB> <TAB> return self.process_empty_scalar(token.end_mark) <TAB> token = self.peek_token() <TAB> event = SequenceEndEvent(token.start_mark, token.start_mark) <TAB> self.state = self.states.pop() <TAB> return event",true,"if not self . check_token ( BlockEntryToken , KeyToken , ValueToken , BlockEndToken ) :","if not self . check_token ( BlockEntryToken , KeyToken , ValueToken , BlockEndToken ) :",0.75,0.0
"def walk_directory(directory, verbose=False): <TAB> """"""Iterates a directory's text files and their contents."""""" <TAB> for dir_path, _, filenames in os.walk(directory): <TAB> <TAB> for filename in filenames: <TAB> <TAB> <TAB> file_path = os.path.join(dir_path, filename) <TAB> <TAB> <TAB> if os.path.isfile(file_path) and not filename.startswith("".""): <TAB> <TAB> <TAB> <TAB> with io.open(file_path, ""r"", encoding=""utf-8"") as file: <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> print(""Reading {}"".format(filename)) <TAB> <TAB> <TAB> <TAB> <TAB> doc_text = file.read() <TAB> <TAB> <TAB> <TAB> <TAB> yield filename, doc_text",true,if verbose :,if verbose :,0.53,0.0
"def set_bounds(self, x, y, width, height): <TAB> if self.native: <TAB> <TAB> # Root level widgets may require vertical adjustment to <TAB> <TAB> # account for toolbars, etc. <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> vertical_shift = self.frame.vertical_shift <TAB> <TAB> else: <TAB> <TAB> <TAB> vertical_shift = 0 <TAB> <TAB> self.native.Size = Size(width, height) <TAB> <TAB> self.native.Location = Point(x, y + vertical_shift)",false,if self . interface . parent is None :,if self . frame :,0.11,0.0
"def _check_x11(self, command=None, *, exc=None, exit_status=None, **kwargs): <TAB> """"""Check requesting X11 forwarding"""""" <TAB> with (yield from self.connect()) as conn: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> with self.assertRaises(exc): <TAB> <TAB> <TAB> <TAB> yield from _create_x11_process(conn, command, **kwargs) <TAB> <TAB> else: <TAB> <TAB> <TAB> proc = yield from _create_x11_process(conn, command, **kwargs) <TAB> <TAB> <TAB> yield from proc.wait() <TAB> <TAB> <TAB> self.assertEqual(proc.exit_status, exit_status) <TAB> yield from conn.wait_closed()",true,if exc :,if exc :,0.53,0.0
"def repr(self): <TAB> try: <TAB> <TAB> if isinstance(self.obj, (dict, web.threadeddict)): <TAB> <TAB> <TAB> from infogami.infobase.utils import prepr <TAB> <TAB> <TAB> return prepr(self.obj) <TAB> <TAB> else: <TAB> <TAB> <TAB> return repr(self.obj) <TAB> except: <TAB> <TAB> return ""failed"" <TAB> return render_template(""admin/memory/object"", self.obj)",true,"if isinstance ( self . obj , ( dict , web . threadeddict ) ) :","if isinstance ( self . obj , ( dict , web . threadeddict ) ) :",0.75,0.0
"def add(self, tag, values): <TAB> if tag not in self.different: <TAB> <TAB> if tag not in self: <TAB> <TAB> <TAB> self[tag] = values <TAB> <TAB> elif self[tag] != values: <TAB> <TAB> <TAB> self.different.add(tag) <TAB> <TAB> <TAB> self[tag] = [""""] <TAB> self.counts[tag] += 1",true,elif self [ tag ] != values :,elif self [ tag ] != values :,0.75,0.0
"def _on_geturl(self, event): <TAB> selected = self._status_list.get_selected() <TAB> if selected != -1: <TAB> <TAB> object_id = self._status_list.GetItemData(selected) <TAB> <TAB> download_item = self._download_list.get_item(object_id) <TAB> <TAB> url = download_item.url <TAB> <TAB> if not wx.TheClipboard.IsOpened(): <TAB> <TAB> <TAB> clipdata = wx.TextDataObject() <TAB> <TAB> <TAB> clipdata.SetText(url) <TAB> <TAB> <TAB> wx.TheClipboard.Open() <TAB> <TAB> <TAB> wx.TheClipboard.SetData(clipdata) <TAB> <TAB> <TAB> wx.TheClipboard.Close()",true,if not wx . TheClipboard . IsOpened ( ) :,if not wx . TheClipboard . IsOpened ( ) :,0.75,0.0
"def escape2null(text): <TAB> """"""Return a string with escape-backslashes converted to nulls."""""" <TAB> parts = [] <TAB> start = 0 <TAB> while True: <TAB> <TAB> found = text.find(""\\"", start) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> parts.append(text[start:]) <TAB> <TAB> <TAB> return """".join(parts) <TAB> <TAB> parts.append(text[start:found]) <TAB> <TAB> parts.append(""\x00"" + text[found + 1 : found + 2]) <TAB> <TAB> start = found + 2  # skip character after escape",true,if found == - 1 :,if found == - 1 :,0.75,0.0
"def _process_inner_views(self): <TAB> for view in self.baseviews: <TAB> <TAB> for inner_class in view.get_uninit_inner_views(): <TAB> <TAB> <TAB> for v in self.baseviews: <TAB> <TAB> <TAB> <TAB> if isinstance(v, inner_class) and v not in view.get_init_inner_views(): <TAB> <TAB> <TAB> <TAB> <TAB> view.get_init_inner_views().append(v)",true,"if isinstance ( v , inner_class ) and v not in view . get_init_inner_views ( ) :","if isinstance ( v , inner_class ) and v not in view . get_init_inner_views ( ) :",0.75,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB> if tt == 10: <TAB> <TAB> <TAB> self.set_url(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.set_app_version_id(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 26: <TAB> <TAB> <TAB> self.set_method(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 34: <TAB> <TAB> <TAB> self.set_queue(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0: <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 18 :,if tt == 18 :,0.75,0.0
"def test_sample_output(): <TAB> comment = ""SAMPLE OUTPUT"" <TAB> skip_files = [""__init__.py""] <TAB> errors = [] <TAB> for _file in sorted(MODULE_PATH.iterdir()): <TAB> <TAB> if _file.suffix == "".py"" and _file.name not in skip_files: <TAB> <TAB> <TAB> with _file.open() as f: <TAB> <TAB> <TAB> <TAB> if comment not in f.read(): <TAB> <TAB> <TAB> <TAB> <TAB> errors.append((comment, _file)) <TAB> if errors: <TAB> <TAB> line = ""Missing sample error(s) detected!\n\n"" <TAB> <TAB> for error in errors: <TAB> <TAB> <TAB> line += ""`{}` is not in module `{}`\n"".format(*error) <TAB> <TAB> print(line[:-1]) <TAB> <TAB> assert False",true,if comment not in f . read ( ) :,if comment not in f . read ( ) :,0.75,0.0
"def _get_planner(name, path, source): <TAB> for klass in _planners: <TAB> <TAB> if klass.detect(path, source): <TAB> <TAB> <TAB> LOG.debug(""%r accepted %r (filename %r)"", klass, name, path) <TAB> <TAB> <TAB> return klass <TAB> <TAB> LOG.debug(""%r rejected %r"", klass, name) <TAB> raise ansible.errors.AnsibleError(NO_METHOD_MSG + repr(invocation))",true,"if klass . detect ( path , source ) :","if klass . detect ( path , source ) :",0.75,0.0
"def _to_string_infix(self, ostream, idx, verbose): <TAB> if verbose: <TAB> <TAB> ostream.write("" , "") <TAB> else: <TAB> <TAB> hasConst = not ( <TAB> <TAB> <TAB> self._const.__class__ in native_numeric_types and self._const == 0 <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> idx -= 1 <TAB> <TAB> _l = self._coef[id(self._args[idx])] <TAB> <TAB> _lt = _l.__class__ <TAB> <TAB> if _lt is _NegationExpression or (_lt in native_numeric_types and _l < 0): <TAB> <TAB> <TAB> ostream.write("" - "") <TAB> <TAB> else: <TAB> <TAB> <TAB> ostream.write("" + "")",true,if hasConst :,if hasConst :,0.53,0.0
"def cluster_info_query(self): <TAB> if self._major_version >= 90600: <TAB> <TAB> extra = ( <TAB> <TAB> <TAB> "", CASE WHEN latest_end_lsn IS NULL THEN NULL ELSE received_tli END,"" <TAB> <TAB> <TAB> "" slot_name, conninfo FROM pg_catalog.pg_stat_get_wal_receiver()"" <TAB> <TAB> ) <TAB> <TAB> if self.role == ""standby_leader"": <TAB> <TAB> <TAB> extra = ""timeline_id"" + extra + "", pg_catalog.pg_control_checkpoint()"" <TAB> <TAB> else: <TAB> <TAB> <TAB> extra = ""0"" + extra <TAB> else: <TAB> <TAB> extra = ""0, NULL, NULL, NULL"" <TAB> return (""SELECT "" + self.TL_LSN + "", {2}"").format( <TAB> <TAB> self.wal_name, self.lsn_name, extra <TAB> )",true,"if self . role == ""standby_leader"" :","if self . role == ""standby_leader"" :",0.75,0.0
"def __init__(self, *args, **kwargs): <TAB> self.country = kwargs.pop(""country"") <TAB> self.fields_needed = kwargs.pop(""fields_needed"", []) <TAB> super(DynamicManagedAccountForm, self).__init__(*args, **kwargs) <TAB> # build our form using the country specific fields and falling <TAB> # back to our default set <TAB> for f in self.fields_needed: <TAB> <TAB> if f in FIELDS_BY_COUNTRY.get(self.country, {}):  # pragma: no branch <TAB> <TAB> <TAB> field_name, field = FIELDS_BY_COUNTRY[self.country][f] <TAB> <TAB> <TAB> self.fields[field_name] = field",true,"if f in FIELDS_BY_COUNTRY . get ( self . country , { } ) :","if f in FIELDS_BY_COUNTRY . get ( self . country , { } ) :",0.75,0.0
"def delete_map(self, query=None): <TAB> query_map = self.interpolated_map(query=query) <TAB> for alias, drivers in six.iteritems(query_map.copy()): <TAB> <TAB> for driver, vms in six.iteritems(drivers.copy()): <TAB> <TAB> <TAB> for vm_name, vm_details in six.iteritems(vms.copy()): <TAB> <TAB> <TAB> <TAB> if vm_details == ""Absent"": <TAB> <TAB> <TAB> <TAB> <TAB> query_map[alias][driver].pop(vm_name) <TAB> <TAB> <TAB> if not query_map[alias][driver]: <TAB> <TAB> <TAB> <TAB> query_map[alias].pop(driver) <TAB> <TAB> if not query_map[alias]: <TAB> <TAB> <TAB> query_map.pop(alias) <TAB> return query_map",true,"if vm_details == ""Absent"" :","if vm_details == ""Absent"" :",0.75,0.0
"def on_strokes_edited(self): <TAB> strokes = self._strokes() <TAB> if strokes: <TAB> <TAB> translation = self._engine.raw_lookup(strokes) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> fmt = _(""{strokes} maps to {translation}"") <TAB> <TAB> else: <TAB> <TAB> <TAB> fmt = _(""{strokes} is not in the dictionary"") <TAB> <TAB> info = self._format_label(fmt, (strokes,), translation) <TAB> else: <TAB> <TAB> info = """" <TAB> self.strokes_info.setText(info)",false,if translation is not None :,if translation :,0.05,0.0
"def release(self): <TAB> tid = _thread.get_ident() <TAB> with self.lock: <TAB> <TAB> if self.owner != tid: <TAB> <TAB> <TAB> raise RuntimeError(""cannot release un-acquired lock"") <TAB> <TAB> assert self.count > 0 <TAB> <TAB> self.count -= 1 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.owner = None <TAB> <TAB> <TAB> if self.waiters: <TAB> <TAB> <TAB> <TAB> self.waiters -= 1 <TAB> <TAB> <TAB> <TAB> self.wakeup.release()",true,if self . count == 0 :,if self . count == 0 :,0.75,0.0
"def _cat_blob(self, gcs_uri): <TAB> """""":py:meth:`cat_file`, minus decompression."""""" <TAB> blob = self._get_blob(gcs_uri) <TAB> if not blob: <TAB> <TAB> return  # don't cat nonexistent files <TAB> start = 0 <TAB> while True: <TAB> <TAB> end = start + _CAT_CHUNK_SIZE <TAB> <TAB> try: <TAB> <TAB> <TAB> chunk = blob.download_as_string(start=start, end=end) <TAB> <TAB> except google.api_core.exceptions.RequestRangeNotSatisfiable: <TAB> <TAB> <TAB> return <TAB> <TAB> yield chunk <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> start = end",false,if len ( chunk ) < _CAT_CHUNK_SIZE :,if not chunk :,0.02,0.0
"def device_iter(**kwargs): <TAB> for dev in backend.enumerate_devices(): <TAB> <TAB> d = Device(dev, backend) <TAB> <TAB> tests = (val == _try_getattr(d, key) for key, val in kwargs.items()) <TAB> <TAB> if _interop._all(tests) and (custom_match is None or custom_match(d)): <TAB> <TAB> <TAB> yield d",true,if _interop . _all ( tests ) and ( custom_match is None or custom_match ( d ) ) :,if _interop . _all ( tests ) and ( custom_match is None or custom_match ( d ) ) :,0.75,0.0
"def _get_vtkjs(self): <TAB> if self._vtkjs is None and self.object is not None: <TAB> <TAB> if isinstance(self.object, string_types) and self.object.endswith("".vtkjs""): <TAB> <TAB> <TAB> if isfile(self.object): <TAB> <TAB> <TAB> <TAB> with open(self.object, ""rb"") as f: <TAB> <TAB> <TAB> <TAB> <TAB> vtkjs = f.read() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> data_url = urlopen(self.object) <TAB> <TAB> <TAB> <TAB> vtkjs = data_url.read() <TAB> <TAB> elif hasattr(self.object, ""read""): <TAB> <TAB> <TAB> vtkjs = self.object.read() <TAB> <TAB> self._vtkjs = vtkjs <TAB> return self._vtkjs",false,"elif hasattr ( self . object , ""read"" ) :","if isinstance ( self . object , string_types ) and self . object . endswith ( "".vtkjs"" ) :",0.17,0.0
"def _execute_with_error(command, error, message): <TAB> try: <TAB> <TAB> cli.invocation = cli.invocation_cls( <TAB> <TAB> <TAB> cli_ctx=cli, <TAB> <TAB> <TAB> parser_cls=cli.parser_cls, <TAB> <TAB> <TAB> commands_loader_cls=cli.commands_loader_cls, <TAB> <TAB> <TAB> help_cls=cli.help_cls, <TAB> <TAB> ) <TAB> <TAB> cli.invocation.execute(command.split()) <TAB> except CLIError as ex: <TAB> <TAB> if error not in str(ex): <TAB> <TAB> <TAB> raise AssertionError( <TAB> <TAB> <TAB> <TAB> ""{}\nExpected: {}\nActual: {}"".format(message, error, ex) <TAB> <TAB> <TAB> ) <TAB> <TAB> return <TAB> except Exception as ex: <TAB> <TAB> raise ex <TAB> raise AssertionError(""exception not raised for '{0}'"".format(message))",true,if error not in str ( ex ) :,if error not in str ( ex ) :,0.75,0.0
"def ray_intersection(self, p, line): <TAB> p = Vector(center(line.sites)) <TAB> min_r = BIG_FLOAT <TAB> nearest = None <TAB> for v_i, v_j in self.edges: <TAB> <TAB> bound = LineEquation2D.from_two_points(v_i, v_j) <TAB> <TAB> intersection = bound.intersect_with_line(line) <TAB> <TAB> if intersection is not None: <TAB> <TAB> <TAB> r = (p - intersection).length <TAB> <TAB> <TAB> # info(""INT: [%s - %s] X [%s] => %s (%s)"", v_i, v_j, line, intersection, r) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> nearest = intersection <TAB> <TAB> <TAB> <TAB> min_r = r <TAB> return nearest",true,if r < min_r :,if r < min_r :,0.75,0.0
"def CalculateChecksum(data): <TAB> # The checksum is just a sum of all the bytes. I swear. <TAB> if isinstance(data, bytearray): <TAB> <TAB> total = sum(data) <TAB> elif isinstance(data, bytes): <TAB> <TAB> if data and isinstance(data[0], bytes): <TAB> <TAB> <TAB> # Python 2 bytes (str) index as single-character strings. <TAB> <TAB> <TAB> total = sum(map(ord, data)) <TAB> <TAB> else: <TAB> <TAB> <TAB> # Python 3 bytes index as numbers (and PY2 empty strings sum() to 0) <TAB> <TAB> <TAB> total = sum(data) <TAB> else: <TAB> <TAB> # Unicode strings (should never see?) <TAB> <TAB> total = sum(map(ord, data)) <TAB> return total & 0xFFFFFFFF",true,"if data and isinstance ( data [ 0 ] , bytes ) :","if data and isinstance ( data [ 0 ] , bytes ) :",0.75,0.0
"def __mul__(self, other: Union[""Tensor"", float]) -> ""Tensor"": <TAB> if isinstance(other, Tensor): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> errstr = ( <TAB> <TAB> <TAB> <TAB> f""Given backens are inconsistent. Found '{self.backend.name}'"" <TAB> <TAB> <TAB> <TAB> f""and '{other.backend.name}'"" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> raise ValueError(errstr) <TAB> <TAB> other = other.array <TAB> array = self.backend.multiply(self.array, other) <TAB> return Tensor(array, backend=self.backend)",true,if self . backend . name != other . backend . name :,if self . backend . name != other . backend . name :,1.0,0.0
"def next_item(self, direction): <TAB> """"""Selects next menu item, based on self._direction"""""" <TAB> start, i = -1, 0 <TAB> try: <TAB> <TAB> start = self.items.index(self._selected) <TAB> <TAB> i = start + direction <TAB> except: <TAB> <TAB> pass <TAB> while True: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # Cannot find valid menu item <TAB> <TAB> <TAB> self.select(start) <TAB> <TAB> <TAB> break <TAB> <TAB> if i >= len(self.items): <TAB> <TAB> <TAB> i = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> if i < 0: <TAB> <TAB> <TAB> i = len(self.items) - 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> if self.select(i): <TAB> <TAB> <TAB> break <TAB> <TAB> i += direction <TAB> <TAB> if start < 0: <TAB> <TAB> <TAB> start = 0",false,if i == start :,if start is None :,0.04,0.0
"def resolve_none(self, data): <TAB> # replace None to '_' <TAB> for tok_idx in range(len(data)): <TAB> <TAB> for feat_idx in range(len(data[tok_idx])): <TAB> <TAB> <TAB> if data[tok_idx][feat_idx] is None: <TAB> <TAB> <TAB> <TAB> data[tok_idx][feat_idx] = ""_"" <TAB> return data",true,if data [ tok_idx ] [ feat_idx ] is None :,if data [ tok_idx ] [ feat_idx ] is None :,0.75,0.0
"def distinct(expr, *on): <TAB> fields = frozenset(expr.fields) <TAB> _on = [] <TAB> append = _on.append <TAB> for n in on: <TAB> <TAB> if isinstance(n, Field): <TAB> <TAB> <TAB> if n._child.isidentical(expr): <TAB> <TAB> <TAB> <TAB> n = n._name <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise ValueError(""{0} is not a field of {1}"".format(n, expr)) <TAB> <TAB> if not isinstance(n, _strtypes): <TAB> <TAB> <TAB> raise TypeError(""on must be a name or field, not: {0}"".format(n)) <TAB> <TAB> elif n not in fields: <TAB> <TAB> <TAB> raise ValueError(""{0} is not a field of {1}"".format(n, expr)) <TAB> <TAB> append(n) <TAB> return Distinct(expr, tuple(_on))",false,elif n not in fields :,if n . _child . isidentical ( expr ) :,0.02,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> length = d.getVarInt32() <TAB> <TAB> <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB> <TAB> <TAB> d.skip(length) <TAB> <TAB> <TAB> self.mutable_cost().TryMerge(tmp) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 24: <TAB> <TAB> <TAB> self.add_version(d.getVarInt64()) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0: <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 10 :,if tt == 10 :,0.75,0.0
"def func_std_string(func_name):  # match what old profile produced <TAB> if func_name[:2] == (""~"", 0): <TAB> <TAB> # special case for built-in functions <TAB> <TAB> name = func_name[2] <TAB> <TAB> if name.startswith(""<"") and name.endswith("">""): <TAB> <TAB> <TAB> return ""{%s}"" % name[1:-1] <TAB> <TAB> else: <TAB> <TAB> <TAB> return name <TAB> else: <TAB> <TAB> return ""%s:%d(%s)"" % func_name",true,"if name . startswith ( ""<"" ) and name . endswith ( "">"" ) :","if name . startswith ( ""<"" ) and name . endswith ( "">"" ) :",1.0,0.0
"def f(): <TAB> try: <TAB> <TAB> # Intra-buffer read then buffer-flushing read <TAB> <TAB> for n in cycle([1, 19]): <TAB> <TAB> <TAB> s = bufio.read(n) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> # list.append() is atomic <TAB> <TAB> <TAB> results.append(s) <TAB> except Exception as e: <TAB> <TAB> errors.append(e) <TAB> <TAB> raise",true,if not s :,if not s :,0.75,0.0
"def stop(self): <TAB> # Try to shut the connection down, but if we get any sort of <TAB> # errors, go ahead and ignore them.. as we're shutting down anyway <TAB> try: <TAB> <TAB> self.rpcserver.stop() <TAB> <TAB> if self.backend_rpcserver: <TAB> <TAB> <TAB> self.backend_rpcserver.stop() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.cluster_rpcserver.stop() <TAB> except Exception: <TAB> <TAB> pass <TAB> if self.coordination: <TAB> <TAB> try: <TAB> <TAB> <TAB> coordination.COORDINATOR.stop() <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> pass <TAB> super(Service, self).stop(graceful=True)",true,if self . cluster_rpcserver :,if self . cluster_rpcserver :,0.75,0.0
"def download(cls, architecture, path=""./""): <TAB> if cls.sanity_check(architecture): <TAB> <TAB> architecture_file = download_file( <TAB> <TAB> <TAB> cls.architecture_map[architecture], directory=path <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> print(""Coreml model {} is saved in [{}]"".format(architecture, path)) <TAB> <TAB> return architecture_file <TAB> else: <TAB> <TAB> return None",false,if not architecture_file :,if architecture_file is None :,0.05,0.0
"def opps_output_converter(kpt_list): <TAB> kpts = [] <TAB> mpii_keys = to_opps_converter.keys() <TAB> for mpii_idx in range(0, 16): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> model_idx = to_opps_converter[mpii_idx] <TAB> <TAB> <TAB> x, y = kpt_list[model_idx] <TAB> <TAB> <TAB> if x < 0 or y < 0: <TAB> <TAB> <TAB> <TAB> kpts += [0.0, 0.0, -1.0] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> kpts += [x, y, 1.0] <TAB> <TAB> else: <TAB> <TAB> <TAB> kpts += [0.0, 0.0, -1.0] <TAB> return kpts",true,if mpii_idx in mpii_keys :,if mpii_idx in mpii_keys :,0.75,0.0
"def _get_headers(self, headers=None): <TAB> request_headers = headers or {} <TAB> # Auth headers if access_token is present <TAB> if self._client.client.config: <TAB> <TAB> config = self._client.client.config <TAB> <TAB> if ""Authorization"" not in request_headers and config.token: <TAB> <TAB> <TAB> request_headers.update( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> ""Authorization"": ""{} {}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> config.authentication_type, config.token <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> request_headers.update({config.header: config.header_service}) <TAB> return request_headers",false,if config . header and config . header_service :,if config . header_service :,0.3,0.0
"def get_last_traded_prices(cls, trading_pairs: List[str]) -> Dict[str, float]: <TAB> results = dict() <TAB> async with aiohttp.ClientSession() as client: <TAB> <TAB> resp = await client.get(f""{constants.REST_URL}/tickers"") <TAB> <TAB> resp_json = await resp.json() <TAB> <TAB> for trading_pair in trading_pairs: <TAB> <TAB> <TAB> resp_record = [ <TAB> <TAB> <TAB> <TAB> o <TAB> <TAB> <TAB> <TAB> for o in resp_json <TAB> <TAB> <TAB> <TAB> if o[""symbol""] == convert_to_exchange_trading_pair(trading_pair) <TAB> <TAB> <TAB> ][0] <TAB> <TAB> <TAB> results[trading_pair] = float(resp_record[""price""]) <TAB> return results",true,"if o [ ""symbol"" ] == convert_to_exchange_trading_pair ( trading_pair )","if o [ ""symbol"" ] == convert_to_exchange_trading_pair ( trading_pair )",0.75,0.0
"def reset_two_factor_hotp(): <TAB> uid = request.form[""uid""] <TAB> otp_secret = request.form.get(""otp_secret"", None) <TAB> if otp_secret: <TAB> <TAB> user = Journalist.query.get(uid) <TAB> <TAB> if not validate_hotp_secret(user, otp_secret): <TAB> <TAB> <TAB> return render_template(""admin_edit_hotp_secret.html"", uid=uid) <TAB> <TAB> db.session.commit() <TAB> <TAB> return redirect(url_for(""admin.new_user_two_factor"", uid=uid)) <TAB> else: <TAB> <TAB> return render_template(""admin_edit_hotp_secret.html"", uid=uid)",true,"if not validate_hotp_secret ( user , otp_secret ) :","if not validate_hotp_secret ( user , otp_secret ) :",0.75,0.0
"def ctx_for_video(self, vurl): <TAB> ""Get a context dict for a given video URL"" <TAB> ctx = self.get_context_dict() <TAB> for portal, match, context_fn in self.PORTALS: <TAB> <TAB> if match.search(vurl): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> ctx.update(context_fn(vurl)) <TAB> <TAB> <TAB> <TAB> ctx[""portal""] = portal <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> <TAB> continue <TAB> return ctx",true,if match . search ( vurl ) :,if match . search ( vurl ) :,0.75,0.0
"def get(self): <TAB> name = request.args.get(""filename"") <TAB> if name is not None: <TAB> <TAB> opts = dict() <TAB> <TAB> opts[""type""] = ""episode"" <TAB> <TAB> result = guessit(name, options=opts) <TAB> <TAB> res = dict() <TAB> <TAB> if ""episode"" in result: <TAB> <TAB> <TAB> res[""episode""] = result[""episode""] <TAB> <TAB> else: <TAB> <TAB> <TAB> res[""episode""] = 0 <TAB> <TAB> if ""season"" in result: <TAB> <TAB> <TAB> res[""season""] = result[""season""] <TAB> <TAB> else: <TAB> <TAB> <TAB> res[""season""] = 0 <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> res[""subtitle_language""] = str(result[""subtitle_language""]) <TAB> <TAB> return jsonify(data=res) <TAB> else: <TAB> <TAB> return """", 400",true,"if ""subtitle_language"" in result :","if ""subtitle_language"" in result :",0.75,0.0
"def package_files(package_path, directory_name): <TAB> paths = [] <TAB> directory_path = os.path.join(package_path, directory_name) <TAB> for (path, directories, filenames) in os.walk(directory_path): <TAB> <TAB> relative_path = os.path.relpath(path, package_path) <TAB> <TAB> for filename in filenames: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> paths.append(os.path.join(relative_path, filename)) <TAB> return paths",false,"if filename [ 0 ] == ""."" :",if filename in directories :,0.04,0.0
"def parse_simple(d, data): <TAB> units = {} <TAB> for v in data[d]: <TAB> <TAB> key = v[""name""] <TAB> <TAB> if not key: <TAB> <TAB> <TAB> continue <TAB> <TAB> key_to_insert = make_key(key) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> index = 2 <TAB> <TAB> <TAB> tmp = f""{key_to_insert}_{index}"" <TAB> <TAB> <TAB> while tmp in units: <TAB> <TAB> <TAB> <TAB> index += 1 <TAB> <TAB> <TAB> <TAB> tmp = f""{key_to_insert}_{index}"" <TAB> <TAB> <TAB> key_to_insert = tmp <TAB> <TAB> units[key_to_insert] = v[""id""] <TAB> return units",false,if key_to_insert in units :,if not units :,0.07,0.0
"def parse_clademodelc(branch_type_no, line_floats, site_classes): <TAB> """"""Parse results specific to the clade model C."""""" <TAB> if not site_classes or len(line_floats) == 0: <TAB> <TAB> return <TAB> for n in range(len(line_floats)): <TAB> <TAB> if site_classes[n].get(""branch types"") is None: <TAB> <TAB> <TAB> site_classes[n][""branch types""] = {} <TAB> <TAB> site_classes[n][""branch types""][branch_type_no] = line_floats[n] <TAB> return site_classes",true,"if site_classes [ n ] . get ( ""branch types"" ) is None :","if site_classes [ n ] . get ( ""branch types"" ) is None :",0.75,0.0
"def track_modules(self, *modules): <TAB> """"""Add module names to the tracked list."""""" <TAB> already_tracked = self.session.GetParameter(""autodetect_build_local_tracked"") or [] <TAB> needed = set(modules) <TAB> if not needed.issubset(already_tracked): <TAB> <TAB> needed.update(already_tracked) <TAB> <TAB> with self.session as session: <TAB> <TAB> <TAB> session.SetParameter(""autodetect_build_local_tracked"", needed) <TAB> <TAB> <TAB> for module_name in modules: <TAB> <TAB> <TAB> <TAB> module_obj = self.GetModuleByName(module_name) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> # Clear the module's profile. This will force it to <TAB> <TAB> <TAB> <TAB> <TAB> # reload a new profile. <TAB> <TAB> <TAB> <TAB> <TAB> module_obj.profile = None",true,if module_obj :,if module_obj :,0.53,0.0
"def set_job_on_hold(self, value, blocking=True): <TAB> trigger = False <TAB> # don't run any locking code beyond this... <TAB> if not self._job_on_hold.acquire(blocking=blocking): <TAB> <TAB> return False <TAB> try: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._job_on_hold.set() <TAB> <TAB> else: <TAB> <TAB> <TAB> self._job_on_hold.clear() <TAB> <TAB> <TAB> if self._job_on_hold.counter == 0: <TAB> <TAB> <TAB> <TAB> trigger = True <TAB> finally: <TAB> <TAB> self._job_on_hold.release() <TAB> # locking code is now safe to run again <TAB> if trigger: <TAB> <TAB> self._continue_sending() <TAB> return True",true,if value :,if value :,0.53,0.0
"def moveToThreadNext(self): <TAB> """"""Move a position to threadNext position."""""" <TAB> p = self <TAB> if p.v: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> p.moveToFirstChild() <TAB> <TAB> elif p.hasNext(): <TAB> <TAB> <TAB> p.moveToNext() <TAB> <TAB> else: <TAB> <TAB> <TAB> p.moveToParent() <TAB> <TAB> <TAB> while p: <TAB> <TAB> <TAB> <TAB> if p.hasNext(): <TAB> <TAB> <TAB> <TAB> <TAB> p.moveToNext() <TAB> <TAB> <TAB> <TAB> <TAB> break  # found <TAB> <TAB> <TAB> <TAB> p.moveToParent() <TAB> <TAB> <TAB> # not found. <TAB> return p",false,if p . v . children :,if p . firstChild :,0.16,0.0
"def best_image(width, height): <TAB> # A heuristic for finding closest sized image to required size. <TAB> image = images[0] <TAB> for img in images: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # Exact match always used <TAB> <TAB> <TAB> return img <TAB> <TAB> elif img.width >= width and img.width * img.height > image.width * image.height: <TAB> <TAB> <TAB> # At least wide enough, and largest area <TAB> <TAB> <TAB> image = img <TAB> return image",true,if img . width == width and img . height == height :,if img . width == width and img . height == height :,1.0,0.0
"def _check_input_types(self): <TAB> if len(self.base_features) == 0: <TAB> <TAB> return True <TAB> input_types = self.primitive.input_types <TAB> if input_types is not None: <TAB> <TAB> if type(input_types[0]) != list: <TAB> <TAB> <TAB> input_types = [input_types] <TAB> <TAB> for t in input_types: <TAB> <TAB> <TAB> zipped = list(zip(t, self.base_features)) <TAB> <TAB> <TAB> if all([issubclass(f.variable_type, v) for v, f in zipped]): <TAB> <TAB> <TAB> <TAB> return True <TAB> else: <TAB> <TAB> return True <TAB> return False",true,if type ( input_types [ 0 ] ) != list :,if type ( input_types [ 0 ] ) != list :,0.75,0.0
"def get_result(self): <TAB> result_list = [] <TAB> exc_info = None <TAB> for f in self.children: <TAB> <TAB> try: <TAB> <TAB> <TAB> result_list.append(f.get_result()) <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> if exc_info is None: <TAB> <TAB> <TAB> <TAB> exc_info = sys.exc_info() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> if not isinstance(e, self.quiet_exceptions): <TAB> <TAB> <TAB> <TAB> <TAB> app_log.error(""Multiple exceptions in yield list"", exc_info=True) <TAB> if exc_info is not None: <TAB> <TAB> raise_exc_info(exc_info) <TAB> if self.keys is not None: <TAB> <TAB> return dict(zip(self.keys, result_list)) <TAB> else: <TAB> <TAB> return list(result_list)",true,"if not isinstance ( e , self . quiet_exceptions ) :","if not isinstance ( e , self . quiet_exceptions ) :",0.75,0.0
"def _update_learning_params(self): <TAB> model = self.model <TAB> hparams = self.hparams <TAB> fd = self.runner.feed_dict <TAB> step_num = self.step_num <TAB> if hparams.model_type == ""resnet_tf"": <TAB> <TAB> if step_num < hparams.lrn_step: <TAB> <TAB> <TAB> lrn_rate = hparams.mom_lrn <TAB> <TAB> elif step_num < 30000: <TAB> <TAB> <TAB> lrn_rate = hparams.mom_lrn / 10 <TAB> <TAB> elif step_num < 35000: <TAB> <TAB> <TAB> lrn_rate = hparams.mom_lrn / 100 <TAB> <TAB> else: <TAB> <TAB> <TAB> lrn_rate = hparams.mom_lrn / 1000 <TAB> <TAB> fd[model.lrn_rate] = lrn_rate",false,elif step_num < 30000 :,elif step_num < 35000 :,0.39,0.0
"def topic_exists(self, arn): <TAB> response = self._conn.get_all_topics() <TAB> topics = response[""ListTopicsResponse""][""ListTopicsResult""][""Topics""] <TAB> current_topics = [] <TAB> if len(topics) > 0: <TAB> <TAB> for topic in topics: <TAB> <TAB> <TAB> topic_arn = topic[""TopicArn""] <TAB> <TAB> <TAB> current_topics.append(topic_arn) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return True <TAB> return False",false,if arn in current_topics :,if topic_arn == arn :,0.04,0.0
"def assertStartsWith(self, expectedPrefix, text, msg=None): <TAB> if not text.startswith(expectedPrefix): <TAB> <TAB> if len(expectedPrefix) + 5 < len(text): <TAB> <TAB> <TAB> text = text[: len(expectedPrefix) + 5] + ""..."" <TAB> <TAB> standardMsg = ""{} not found at the start of {}"".format( <TAB> <TAB> <TAB> repr(expectedPrefix), repr(text) <TAB> <TAB> ) <TAB> <TAB> self.fail(self._formatMessage(msg, standardMsg))",true,if len ( expectedPrefix ) + 5 < len ( text ) :,if len ( expectedPrefix ) + 5 < len ( text ) :,1.0,0.0
"def validate_memory(self, value): <TAB> for k, v in value.viewitems(): <TAB> <TAB><IF-STMT>  # use NoneType to unset a value <TAB> <TAB> <TAB> continue <TAB> <TAB> if not re.match(PROCTYPE_MATCH, k): <TAB> <TAB> <TAB> raise serializers.ValidationError(""Process types can only contain [a-z]"") <TAB> <TAB> if not re.match(MEMLIMIT_MATCH, str(v)): <TAB> <TAB> <TAB> raise serializers.ValidationError( <TAB> <TAB> <TAB> <TAB> ""Limit format: <number><unit>, where unit = B, K, M or G"" <TAB> <TAB> <TAB> ) <TAB> return value",true,if v is None :,if v is None :,0.75,0.0
"def open(self) -> ""KeyValueJsonDb"": <TAB> """"""Create a new data base or open existing one"""""" <TAB> if os.path.exists(self._name): <TAB> <TAB> if not os.path.isfile(self._name): <TAB> <TAB> <TAB> raise IOError(""%s exists and is not a file"" % self._name) <TAB> <TAB> try: <TAB> <TAB> <TAB> with open(self._name, ""r"") as _in: <TAB> <TAB> <TAB> <TAB> self.set_records(json.load(_in)) <TAB> <TAB> except json.JSONDecodeError: <TAB> <TAB> <TAB> # file corrupted, reset it. <TAB> <TAB> <TAB> self.commit() <TAB> else: <TAB> <TAB> # make sure path exists <TAB> <TAB> mkpath(os.path.dirname(self._name)) <TAB> <TAB> self.commit() <TAB> return self",true,if not os . path . isfile ( self . _name ) :,if not os . path . isfile ( self . _name ) :,0.75,0.0
"def _calculate(self): <TAB> before = self.before.data <TAB> after = self.after.data <TAB> self.deleted = {} <TAB> self.updated = {} <TAB> self.created = after.copy() <TAB> for path, f in before.items(): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.deleted[path] = f <TAB> <TAB> <TAB> continue <TAB> <TAB> del self.created[path] <TAB> <TAB> if f.mtime < after[path].mtime: <TAB> <TAB> <TAB> self.updated[path] = after[path]",false,if path not in after :,if path in self . deleted :,0.2,0.0
"def cache_sqs_queues_across_accounts() -> bool: <TAB> function: str = f""{__name__}.{sys._getframe().f_code.co_name}"" <TAB> # First, get list of accounts <TAB> accounts_d: list = async_to_sync(get_account_id_to_name_mapping)() <TAB> # Second, call tasks to enumerate all the roles across all accounts <TAB> for account_id in accounts_d.keys(): <TAB> <TAB> if config.get(""environment"") == ""prod"": <TAB> <TAB> <TAB> cache_sqs_queues_for_account.delay(account_id) <TAB> <TAB> else: <TAB> <TAB> <TAB> if account_id in config.get(""celery.test_account_ids"", []): <TAB> <TAB> <TAB> <TAB> cache_sqs_queues_for_account.delay(account_id) <TAB> stats.count(f""{function}.success"") <TAB> return True",false,"if config . get ( ""environment"" ) == ""prod"" :","if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :",0.13,0.0
"def remove(self, path, config=None, error_on_path=False, defaults=None): <TAB> if not path: <TAB> <TAB> if error_on_path: <TAB> <TAB> <TAB> raise NoSuchSettingsPath() <TAB> <TAB> return <TAB> if config is not None or defaults is not None: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> config = self._config <TAB> <TAB> if defaults is None: <TAB> <TAB> <TAB> defaults = dict(self._map.parents) <TAB> <TAB> chain = HierarchicalChainMap(config, defaults) <TAB> else: <TAB> <TAB> chain = self._map <TAB> try: <TAB> <TAB> chain.del_by_path(path) <TAB> <TAB> self._mark_dirty() <TAB> except KeyError: <TAB> <TAB> if error_on_path: <TAB> <TAB> <TAB> raise NoSuchSettingsPath() <TAB> <TAB> pass",true,if config is None :,if config is None :,0.75,0.0
"def PopulateProjectId(project_id=None): <TAB> """"""Fills in a project_id from the boto config file if one is not provided."""""" <TAB> if not project_id: <TAB> <TAB> default_id = boto.config.get_value(""GSUtil"", ""default_project_id"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ProjectIdException(""MissingProjectId"") <TAB> <TAB> return default_id <TAB> return project_id",true,if not default_id :,if not default_id :,0.75,0.0
"def set(self, name, value): <TAB> with self._object_cache_lock: <TAB> <TAB> old_value = self._object_cache.get(name) <TAB> <TAB> ret = not old_value or int(old_value.metadata.resource_version) < int( <TAB> <TAB> <TAB> value.metadata.resource_version <TAB> <TAB> ) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self._object_cache[name] = value <TAB> return ret, old_value",true,if ret :,if ret :,0.53,0.0
"def remove(self, url): <TAB> try: <TAB> <TAB> i = self.items.index(url) <TAB> except (ValueError, IndexError): <TAB> <TAB> pass <TAB> else: <TAB> <TAB> was_selected = i in self.selectedindices() <TAB> <TAB> self.list.delete(i) <TAB> <TAB> del self.items[i] <TAB> <TAB> if not self.items: <TAB> <TAB> <TAB> self.mp.hidepanel(self.name) <TAB> <TAB> elif was_selected: <TAB> <TAB> <TAB> if i >= len(self.items): <TAB> <TAB> <TAB> <TAB> i = len(self.items) - 1 <TAB> <TAB> <TAB> self.list.select_set(i)",true,elif was_selected :,elif was_selected :,0.51,0.0
"def add_directory_csv_files(dir_path, paths=None): <TAB> if not paths: <TAB> <TAB> paths = [] <TAB> for p in listdir(dir_path): <TAB> <TAB> path = join(dir_path, p) <TAB> <TAB> if isdir(path): <TAB> <TAB> <TAB> # call recursively for each dir <TAB> <TAB> <TAB> paths = add_directory_csv_files(path, paths) <TAB> <TAB> elif isfile(path) and path.endswith("".csv""): <TAB> <TAB> <TAB> # add every file to the list <TAB> <TAB> <TAB> paths.append(path) <TAB> return paths",false,if isdir ( path ) :,"elif isfile ( path ) and path . endswith ( "".csv"" ) :",0.08,0.0
"def _get_client(rp_mapping, resource_provider): <TAB> for key, value in rp_mapping.items(): <TAB> <TAB> if str.lower(key) == str.lower(resource_provider): <TAB> <TAB> <TAB> if isinstance(value, dict): <TAB> <TAB> <TAB> <TAB> return GeneralPrivateEndpointClient( <TAB> <TAB> <TAB> <TAB> <TAB> key, <TAB> <TAB> <TAB> <TAB> <TAB> value[""api_version""], <TAB> <TAB> <TAB> <TAB> <TAB> value[""support_list_or_not""], <TAB> <TAB> <TAB> <TAB> <TAB> value[""resource_get_api_version""], <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return value() <TAB> raise CLIError( <TAB> <TAB> ""Resource type must be one of {}"".format("", "".join(rp_mapping.keys())) <TAB> )",false,if str . lower ( key ) == str . lower ( resource_provider ) :,"if isinstance ( value , dict ) :",0.02,0.0
"def compute_rule_hash(self, rule): <TAB> buf = ""%d-%d-%s-"" % ( <TAB> <TAB> rule.get(""FromPort"", 0) or 0, <TAB> <TAB> rule.get(""ToPort"", 0) or 0, <TAB> <TAB> rule.get(""IpProtocol"", ""-1"") or ""-1"", <TAB> ) <TAB> for a, ke in self.RULE_ATTRS: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> ev = [e[ke] for e in rule[a]] <TAB> <TAB> ev.sort() <TAB> <TAB> for e in ev: <TAB> <TAB> <TAB> buf += ""%s-"" % e <TAB> # mask to generate the same numeric value across all Python versions <TAB> return zlib.crc32(buf.encode(""ascii"")) & 0xFFFFFFFF",true,if a not in rule :,if a not in rule :,0.75,0.0
"def analysis_sucess_metrics(analysis_time: float, allow_exception=False): <TAB> try: <TAB> <TAB> anchore_engine.subsys.metrics.counter_inc(name=""anchore_analysis_success"") <TAB> <TAB> anchore_engine.subsys.metrics.histogram_observe( <TAB> <TAB> <TAB> ""anchore_analysis_time_seconds"", <TAB> <TAB> <TAB> analysis_time, <TAB> <TAB> <TAB> buckets=ANALYSIS_TIME_SECONDS_BUCKETS, <TAB> <TAB> <TAB> status=""success"", <TAB> <TAB> ) <TAB> except: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise <TAB> <TAB> else: <TAB> <TAB> <TAB> logger.exception( <TAB> <TAB> <TAB> <TAB> ""Unexpected exception during metrics update for a successful analysis. Swallowing error and continuing"" <TAB> <TAB> <TAB> )",true,if allow_exception :,if allow_exception :,0.53,0.0
"def decide_file_icon(file): <TAB> if file.state == File.ERROR: <TAB> <TAB> return FileItem.icon_error <TAB> elif isinstance(file.parent, Track): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return FileItem.icon_saved <TAB> <TAB> elif file.state == File.PENDING: <TAB> <TAB> <TAB> return FileItem.match_pending_icons[int(file.similarity * 5 + 0.5)] <TAB> <TAB> else: <TAB> <TAB> <TAB> return FileItem.match_icons[int(file.similarity * 5 + 0.5)] <TAB> elif file.state == File.PENDING: <TAB> <TAB> return FileItem.icon_file_pending <TAB> else: <TAB> <TAB> return FileItem.icon_file",false,if file . state == File . NORMAL :,if file . state == File . Saved :,0.63,0.0
"def deleteMenu(self, menuName): <TAB> try: <TAB> <TAB> menu = self.getMenu(menuName) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.destroy(menu) <TAB> <TAB> <TAB> self.destroyMenu(menuName) <TAB> <TAB> else: <TAB> <TAB> <TAB> g.es(""can't delete menu:"", menuName) <TAB> except Exception: <TAB> <TAB> g.es(""exception deleting"", menuName, ""menu"") <TAB> <TAB> g.es_exception()",true,if menu :,if menu :,0.53,0.0
"def parser(cls, buf): <TAB> (type_, code, csum) = struct.unpack_from(cls._PACK_STR, buf) <TAB> msg = cls(type_, code, csum) <TAB> offset = cls._MIN_LEN <TAB> if len(buf) > offset: <TAB> <TAB> cls_ = cls._ICMPV6_TYPES.get(type_, None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> msg.data = cls_.parser(buf, offset) <TAB> <TAB> else: <TAB> <TAB> <TAB> msg.data = buf[offset:] <TAB> return msg, None, None",true,if cls_ :,if cls_ :,0.53,0.0
"def _load_dataset_area(self, dsid, file_handlers, coords): <TAB> """"""Get the area for *dsid*."""""" <TAB> try: <TAB> <TAB> return self._load_area_def(dsid, file_handlers) <TAB> except NotImplementedError: <TAB> <TAB> if any(x is None for x in coords): <TAB> <TAB> <TAB> logger.warning(""Failed to load coordinates for '{}'"".format(dsid)) <TAB> <TAB> <TAB> return None <TAB> <TAB> area = self._make_area_from_coords(coords) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> logger.debug(""No coordinates found for %s"", str(dsid)) <TAB> <TAB> return area",true,if area is None :,if area is None :,0.75,0.0
"def __getattr__(self, name): <TAB> if Popen.verbose: <TAB> <TAB> sys.stdout.write(""Getattr: %s..."" % name) <TAB> if name in Popen.__slots__: <TAB> <TAB> return object.__getattribute__(self, name) <TAB> else: <TAB> <TAB> if self.popen is not None: <TAB> <TAB> <TAB> if Popen.verbose: <TAB> <TAB> <TAB> <TAB> print(""from Popen"") <TAB> <TAB> <TAB> return getattr(self.popen, name) <TAB> <TAB> else: <TAB> <TAB> <TAB> if name == ""wait"": <TAB> <TAB> <TAB> <TAB> return self.emu_wait <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise Exception(""subprocess emulation: not implemented: %s"" % name)",true,"if name == ""wait"" :","if name == ""wait"" :",0.75,0.0
"def update(self, time_delta): <TAB> super().update(time_delta) <TAB> n = self.menu.selected_option <TAB> if n == self.last: <TAB> <TAB> return <TAB> self.last = n <TAB> s = """" <TAB> for i in range(len(self.files)): <TAB> <TAB> if self.files[i][0] == n: <TAB> <TAB> <TAB> for l in open(self.files[i][1]): <TAB> <TAB> <TAB> <TAB> x = l.strip() <TAB> <TAB> <TAB> <TAB> if len(x) > 1 and x[0] == ""#"": <TAB> <TAB> <TAB> <TAB> <TAB> x = ""<b><u>"" + x[1:] + "" </u></b>"" <TAB> <TAB> <TAB> <TAB> s += x + ""<br>"" <TAB> self.set_text(s)",false,if self . files [ i ] [ 0 ] == n :,"if len ( x ) > 1 and x [ 0 ] == ""#"" :",0.1,0.0
"def wrapper(*args, **kwargs): <TAB> list_args, empty = _apply_defaults(func, args, kwargs) <TAB> if len(dimensions) > len(list_args): <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> ""%s takes %i parameters, but %i dimensions were passed"" <TAB> <TAB> <TAB> % (func.__name__, len(list_args), len(dimensions)) <TAB> <TAB> ) <TAB> for dim, value in zip(dimensions, list_args): <TAB> <TAB> if dim is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> if not ureg.Quantity(value).check(dim): <TAB> <TAB> <TAB> val_dim = ureg.get_dimensionality(value) <TAB> <TAB> <TAB> raise DimensionalityError(value, ""a quantity of"", val_dim, dim) <TAB> return func(*args, **kwargs)",true,if not ureg . Quantity ( value ) . check ( dim ) :,if not ureg . Quantity ( value ) . check ( dim ) :,0.75,0.0
"def _check(self, name, size=None, *extra): <TAB> func = getattr(imageop, name) <TAB> for height in VALUES: <TAB> <TAB> for width in VALUES: <TAB> <TAB> <TAB> strlen = abs(width * height) <TAB> <TAB> <TAB> if size: <TAB> <TAB> <TAB> <TAB> strlen *= size <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> data = ""A"" * strlen <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> data = AAAAA <TAB> <TAB> <TAB> if size: <TAB> <TAB> <TAB> <TAB> arguments = (data, size, width, height) + extra <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> arguments = (data, width, height) + extra <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> func(*arguments) <TAB> <TAB> <TAB> except (ValueError, imageop.error): <TAB> <TAB> <TAB> <TAB> pass",false,if strlen < MAX_LEN :,if strlen > 0 :,0.06,0.0
"def wait_send_all_might_not_block(self) -> None: <TAB> with self._send_conflict_detector: <TAB> <TAB> if self._fd_holder.closed: <TAB> <TAB> <TAB> raise trio.ClosedResourceError(""file was already closed"") <TAB> <TAB> try: <TAB> <TAB> <TAB> await trio.lowlevel.wait_writable(self._fd_holder.fd) <TAB> <TAB> except BrokenPipeError as e: <TAB> <TAB> <TAB> # kqueue: raises EPIPE on wait_writable instead <TAB> <TAB> <TAB> # of sending, which is annoying <TAB> <TAB> <TAB> raise trio.BrokenResourceError from e",true,if self . _fd_holder . closed :,if self . _fd_holder . closed :,0.75,0.0
"def parse_win_proxy(val): <TAB> proxies = [] <TAB> for p in val.split("";""): <TAB> <TAB> if ""="" in p: <TAB> <TAB> <TAB> tab = p.split(""="", 1) <TAB> <TAB> <TAB> if tab[0] == ""socks"": <TAB> <TAB> <TAB> <TAB> tab[0] = ""SOCKS4"" <TAB> <TAB> <TAB> proxies.append( <TAB> <TAB> <TAB> <TAB> (tab[0].upper(), tab[1], None, None) <TAB> <TAB> <TAB> )  # type, addr:port, username, password <TAB> <TAB> else: <TAB> <TAB> <TAB> proxies.append((""HTTP"", p, None, None)) <TAB> return proxies",true,"if tab [ 0 ] == ""socks"" :","if tab [ 0 ] == ""socks"" :",0.75,0.0
"def _super_function(args): <TAB> passed_class, passed_self = args.get_arguments([""type"", ""self""]) <TAB> if passed_self is None: <TAB> <TAB> return passed_class <TAB> else: <TAB> <TAB> # pyclass = passed_self.get_type() <TAB> <TAB> pyclass = passed_class <TAB> <TAB> if isinstance(pyclass, pyobjects.AbstractClass): <TAB> <TAB> <TAB> supers = pyclass.get_superclasses() <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return pyobjects.PyObject(supers[0]) <TAB> <TAB> return passed_self",false,if supers :,if len ( supers ) == 1 :,0.05,0.0
"def update_output_mintime(job): <TAB> try: <TAB> <TAB> return output_mintime[job] <TAB> except KeyError: <TAB> <TAB> for job_ in chain([job], self.depending[job]): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> t = output_mintime[job_] <TAB> <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> <TAB> t = job_.output_mintime <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> output_mintime[job] = t <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> output_mintime[job] = None",false,if t is not None :,if t :,0.05,0.0
"def get_list_of_strings_to_mongo_objects(self, notifications_list=None): <TAB> result = [] <TAB> if len(notifications_list) > 0: <TAB> <TAB> for x in notifications_list: <TAB> <TAB> <TAB> split_provider_id = x.split("":"")  # email:id <TAB> <TAB> <TAB> if len(split_provider_id) == 2: <TAB> <TAB> <TAB> <TAB> _id = split_provider_id[1] <TAB> <TAB> <TAB> <TAB> cursor = self.get_by_id(_id) <TAB> <TAB> <TAB> <TAB><IF-STMT>  # Append if exists <TAB> <TAB> <TAB> <TAB> <TAB> result.append(cursor) <TAB> return result",true,if cursor :,if cursor :,0.53,0.0
"def stop(self): <TAB> with self.lock: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> self.task_queue.put(None) <TAB> <TAB> self.result_queue.put(None) <TAB> <TAB> process = self.process <TAB> <TAB> self.process = None <TAB> <TAB> self.task_queue = None <TAB> <TAB> self.result_queue = None <TAB> process.join(timeout=0.1) <TAB> if process.exitcode is None: <TAB> <TAB> os.kill(process.pid, signal.SIGKILL) <TAB> <TAB> process.join()",false,if not self . process :,if self . process is None :,0.1,0.0
"def on_api_command(self, command, data): <TAB> if command == ""select"": <TAB> <TAB> if not Permissions.PLUGIN_ACTION_COMMAND_PROMPT_INTERACT.can(): <TAB> <TAB> <TAB> return flask.abort(403, ""Insufficient permissions"") <TAB> <TAB> if self._prompt is None: <TAB> <TAB> <TAB> return flask.abort(409, ""No active prompt"") <TAB> <TAB> choice = data[""choice""] <TAB> <TAB> if not isinstance(choice, int) or not self._prompt.validate_choice(choice): <TAB> <TAB> <TAB> return flask.abort( <TAB> <TAB> <TAB> <TAB> 400, ""{!r} is not a valid value for choice"".format(choice) <TAB> <TAB> <TAB> ) <TAB> <TAB> self._answer_prompt(choice)",true,if self . _prompt is None :,if self . _prompt is None :,0.75,0.0
"def application_openFiles_(self, nsapp, filenames): <TAB> # logging.info('[osx] file open') <TAB> # logging.info('[osx] file : %s' % (filenames)) <TAB> for filename in filenames: <TAB> <TAB> logging.info(""[osx] receiving from macOS : %s"", filename) <TAB> <TAB> if os.path.exists(filename): <TAB> <TAB> <TAB> if sabnzbd.filesystem.get_ext(filename) in VALID_ARCHIVES + VALID_NZB_FILES: <TAB> <TAB> <TAB> <TAB> sabnzbd.add_nzbfile(filename, keep=True)",true,if os . path . exists ( filename ) :,if os . path . exists ( filename ) :,0.75,0.0
"def test_error_through_destructor(self): <TAB> # Test that the exception state is not modified by a destructor, <TAB> # even if close() fails. <TAB> rawio = self.CloseFailureIO() <TAB> with support.catch_unraisable_exception() as cm: <TAB> <TAB> with self.assertRaises(AttributeError): <TAB> <TAB> <TAB> self.tp(rawio).xyzzy <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.assertIsNone(cm.unraisable) <TAB> <TAB> elif cm.unraisable is not None: <TAB> <TAB> <TAB> self.assertEqual(cm.unraisable.exc_type, OSError)",false,if not IOBASE_EMITS_UNRAISABLE :,if cm . unraisable is not None :,0.16,0.0
"def http_wrapper(self, url, postdata={}): <TAB> try: <TAB> <TAB> if postdata != {}: <TAB> <TAB> <TAB> f = urllib.urlopen(url, postdata) <TAB> <TAB> else: <TAB> <TAB> <TAB> f = urllib.urlopen(url) <TAB> <TAB> response = f.read() <TAB> except: <TAB> <TAB> import traceback <TAB> <TAB> import logging, sys <TAB> <TAB> cla, exc, tb = sys.exc_info() <TAB> <TAB> logging.error(url) <TAB> <TAB> if postdata: <TAB> <TAB> <TAB> logging.error(""with post data"") <TAB> <TAB> else: <TAB> <TAB> <TAB> logging.error(""without post data"") <TAB> <TAB> logging.error(exc.args) <TAB> <TAB> logging.error(traceback.format_tb(tb)) <TAB> <TAB> response = """" <TAB> return response",true,if postdata != { } :,if postdata != { } :,0.75,0.0
"def check_single_file(fn, fetchuri): <TAB> """"""Determine if a single downloaded file is something we can't handle"""""" <TAB> with open(fn, ""r"", errors=""surrogateescape"") as f: <TAB> <TAB> if ""<html"" in f.read(100).lower(): <TAB> <TAB> <TAB> logger.error( <TAB> <TAB> <TAB> <TAB> 'Fetching ""%s"" returned a single HTML page - check the URL is correct and functional' <TAB> <TAB> <TAB> <TAB> % fetchuri <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> sys.exit(1)",true,"if ""<html"" in f . read ( 100 ) . lower ( ) :","if ""<html"" in f . read ( 100 ) . lower ( ) :",0.75,0.0
"def update_properties(self, update_dict): <TAB> signed_attribute_changed = False <TAB> for k, value in update_dict.items(): <TAB> <TAB> if getattr(self, k) != value: <TAB> <TAB> <TAB> setattr(self, k, value) <TAB> <TAB> <TAB> signed_attribute_changed = signed_attribute_changed or ( <TAB> <TAB> <TAB> <TAB> k in self.payload_arguments <TAB> <TAB> <TAB> ) <TAB> if signed_attribute_changed: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.status = UPDATED <TAB> <TAB> self.timestamp = clock.tick() <TAB> <TAB> self.sign() <TAB> return self",false,if self . status != NEW :,if self . status == UPDATED :,0.47,0.0
"def clean_items(event, items, variations): <TAB> for item in items: <TAB> <TAB> if event != item.event: <TAB> <TAB> <TAB> raise ValidationError(_(""One or more items do not belong to this event."")) <TAB> <TAB> if item.has_variations: <TAB> <TAB> <TAB> if not any(var.item == item for var in variations): <TAB> <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> <TAB> _( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""One or more items has variations but none of these are in the variations list."" <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> )",true,if not any ( var . item == item for var in variations ) :,if not any ( var . item == item for var in variations ) :,1.0,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB> if tt == 10: <TAB> <TAB> <TAB> length = d.getVarInt32() <TAB> <TAB> <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB> <TAB> <TAB> d.skip(length) <TAB> <TAB> <TAB> self.add_status().TryMerge(tmp) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 18: <TAB> <TAB> <TAB> self.add_doc_id(d.getPrefixedString()) <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 0 :,if tt == 0 :,0.75,0.0
"def connections(self): <TAB> # Connections look something like this: <TAB> # socket:[102422] <TAB> fds = self.open_files <TAB> socket = ""socket:["" <TAB> result = [] <TAB> functions = [pwndbg.net.tcp, pwndbg.net.unix, pwndbg.net.netlink] <TAB> for fd, path in fds.items(): <TAB> <TAB> if socket not in path: <TAB> <TAB> <TAB> continue <TAB> <TAB> inode = path[len(socket) : -1] <TAB> <TAB> inode = int(inode) <TAB> <TAB> for func in functions: <TAB> <TAB> <TAB> for x in func(): <TAB> <TAB> <TAB> <TAB> if x.inode == inode: <TAB> <TAB> <TAB> <TAB> <TAB> x.fd = fd <TAB> <TAB> <TAB> <TAB> <TAB> result.append(x) <TAB> return tuple(result)",true,if x . inode == inode :,if x . inode == inode :,1.0,0.0
"def _movement_finished(self): <TAB> if self.in_ship_map: <TAB> <TAB> # if the movement somehow stops, the position sticks, and the unit isn't at next_target any more <TAB> <TAB> if self._next_target is not None: <TAB> <TAB> <TAB> ship = self.session.world.ship_map.get(self._next_target.to_tuple()) <TAB> <TAB> <TAB> if ship is not None and ship() is self: <TAB> <TAB> <TAB> <TAB> del self.session.world.ship_map[self._next_target.to_tuple()] <TAB> super()._movement_finished()",true,if self . _next_target is not None :,if self . _next_target is not None :,0.75,0.0
"def print_addresses(self): <TAB> p = 3 <TAB> tmp_str = ""["" <TAB> if self.get_len() >= 7:  # at least one complete IP address <TAB> <TAB> while 1: <TAB> <TAB> <TAB> if p + 1 == self.get_ptr(): <TAB> <TAB> <TAB> <TAB> tmp_str += ""#"" <TAB> <TAB> <TAB> tmp_str += self.get_ip_address(p) <TAB> <TAB> <TAB> p += 4 <TAB> <TAB> <TAB> if p >= self.get_len(): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> tmp_str += "", "" <TAB> tmp_str += ""] "" <TAB> if self.get_ptr() % 4:  # ptr field should be a multiple of 4 <TAB> <TAB> tmp_str += ""nonsense ptr field: %d "" % self.get_ptr() <TAB> return tmp_str",true,if p >= self . get_len ( ) :,if p >= self . get_len ( ) :,0.75,0.0
"def source_shapes(self): <TAB> """"""Prints debug information about the sources in this provider."""""" <TAB> if logger.isEnabledFor(logging.DEBUG): <TAB> <TAB> for i, source in enumerate(self.sources): <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> name = ""anonymous"" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> name = self.keys[i] <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> shape = source.shape() <TAB> <TAB> <TAB> except NotImplementedError: <TAB> <TAB> <TAB> <TAB> shape = ""N/A"" <TAB> <TAB> <TAB> logger.debug( <TAB> <TAB> <TAB> <TAB> 'Data source ""%s"": entries=%s, shape=%s', name, len(source), shape <TAB> <TAB> <TAB> )",false,if self . keys is None :,if i == 0 :,0.02,0.0
"def swap_actions(actions): <TAB> for mutexgroup in mutex_groups: <TAB> <TAB> mutex_actions = mutexgroup._group_actions <TAB> <TAB> if contains_actions(mutex_actions, actions): <TAB> <TAB> <TAB> # make a best guess as to where we should store the group <TAB> <TAB> <TAB> targetindex = actions.index(mutexgroup._group_actions[0]) <TAB> <TAB> <TAB> # insert the _ArgumentGroup container <TAB> <TAB> <TAB> actions[targetindex] = mutexgroup <TAB> <TAB> <TAB> # remove the duplicated individual actions <TAB> <TAB> <TAB> actions = [action for action in actions if action not in mutex_actions] <TAB> return actions",true,"if contains_actions ( mutex_actions , actions ) :","if contains_actions ( mutex_actions , actions ) :",0.75,0.0
"def rec_deps(services, container_by_name, cnt, init_service): <TAB> deps = cnt[""_deps""] <TAB> for dep in deps.copy(): <TAB> <TAB> dep_cnts = services.get(dep) <TAB> <TAB> if not dep_cnts: <TAB> <TAB> <TAB> continue <TAB> <TAB> dep_cnt = container_by_name.get(dep_cnts[0]) <TAB> <TAB> if dep_cnt: <TAB> <TAB> <TAB> # TODO: avoid creating loops, A->B->A <TAB> <TAB> <TAB> if init_service and init_service in dep_cnt[""_deps""]: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_deps = rec_deps(services, container_by_name, dep_cnt, init_service) <TAB> <TAB> <TAB> deps.update(new_deps) <TAB> return deps",true,"if init_service and init_service in dep_cnt [ ""_deps"" ] :","if init_service and init_service in dep_cnt [ ""_deps"" ] :",0.75,0.0
"def make_dump_list_by_name_list(name_list): <TAB> info_list = [] <TAB> for info_name in name_list: <TAB> <TAB> info = next((x for x in DUMP_LIST if x.info_name == info_name), None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError('Unknown info name: ""{}""'.format(info_name)) <TAB> <TAB> info_list.append(info) <TAB> return info_list",false,if not info :,if info is None :,0.05,0.0
"def create(self, private=False): <TAB> try: <TAB> <TAB> if private: <TAB> <TAB> <TAB> log.info(""Creating private channel %s."", self) <TAB> <TAB> <TAB> self._bot.api_call( <TAB> <TAB> <TAB> <TAB> ""conversations.create"", data={""name"": self.name, ""is_private"": True} <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> log.info(""Creating channel %s."", self) <TAB> <TAB> <TAB> self._bot.api_call(""conversations.create"", data={""name"": self.name}) <TAB> except SlackAPIResponseError as e: <TAB> <TAB> if e.error == ""user_is_bot"": <TAB> <TAB> <TAB> raise RoomError(f""Unable to create channel. {USER_IS_BOT_HELPTEXT}"") <TAB> <TAB> else: <TAB> <TAB> <TAB> raise RoomError(e)",true,"if e . error == ""user_is_bot"" :","if e . error == ""user_is_bot"" :",0.75,0.0
"def talk(self, words): <TAB> if self.writeSentence(words) == 0: <TAB> <TAB> return <TAB> r = [] <TAB> while 1: <TAB> <TAB> i = self.readSentence() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> reply = i[0] <TAB> <TAB> attrs = {} <TAB> <TAB> for w in i[1:]: <TAB> <TAB> <TAB> j = w.find(""="", 1) <TAB> <TAB> <TAB> if j == -1: <TAB> <TAB> <TAB> <TAB> attrs[w] = """" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> attrs[w[:j]] = w[j + 1 :] <TAB> <TAB> r.append((reply, attrs)) <TAB> <TAB> if reply == ""!done"": <TAB> <TAB> <TAB> return r",false,if len ( i ) == 0 :,if len ( i ) < 2 :,0.52,0.0
"def _load_logfile(self, lfn): <TAB> enc_key = self.decryption_key_func() <TAB> with open(os.path.join(self.logdir, lfn)) as fd: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> with DecryptingStreamer( <TAB> <TAB> <TAB> <TAB> fd, mep_key=enc_key, name=""EventLog/DS(%s)"" % lfn <TAB> <TAB> <TAB> ) as streamer: <TAB> <TAB> <TAB> <TAB> lines = streamer.read() <TAB> <TAB> <TAB> <TAB> streamer.verify(_raise=IOError) <TAB> <TAB> else: <TAB> <TAB> <TAB> lines = fd.read() <TAB> <TAB> if lines: <TAB> <TAB> <TAB> for line in lines.splitlines(): <TAB> <TAB> <TAB> <TAB> event = Event.Parse(line.strip()) <TAB> <TAB> <TAB> <TAB> self._events[event.event_id] = event",true,if enc_key :,if enc_key :,0.53,0.0
"def set_ok_port(self, cookie, request): <TAB> if cookie.port_specified: <TAB> <TAB> req_port = request_port(request) <TAB> <TAB> if req_port is None: <TAB> <TAB> <TAB> req_port = ""80"" <TAB> <TAB> else: <TAB> <TAB> <TAB> req_port = str(req_port) <TAB> <TAB> for p in cookie.port.split("",""): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> int(p) <TAB> <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> <TAB> debug(""   bad port %s (not numeric)"", p) <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> debug(""   request port (%s) not found in %s"", req_port, cookie.port) <TAB> <TAB> <TAB> return False <TAB> return True",true,if p == req_port :,if p == req_port :,0.75,0.0
"def get_attribute_value(self, nodeid, attr): <TAB> with self._lock: <TAB> <TAB> self.logger.debug(""get attr val: %s %s"", nodeid, attr) <TAB> <TAB> if nodeid not in self._nodes: <TAB> <TAB> <TAB> dv = ua.DataValue() <TAB> <TAB> <TAB> dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadNodeIdUnknown) <TAB> <TAB> <TAB> return dv <TAB> <TAB> node = self._nodes[nodeid] <TAB> <TAB> if attr not in node.attributes: <TAB> <TAB> <TAB> dv = ua.DataValue() <TAB> <TAB> <TAB> dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadAttributeIdInvalid) <TAB> <TAB> <TAB> return dv <TAB> <TAB> attval = node.attributes[attr] <TAB> <TAB> if attval.value_callback: <TAB> <TAB> <TAB> return attval.value_callback() <TAB> <TAB> return attval.value",true,if nodeid not in self . _nodes :,if nodeid not in self . _nodes :,0.75,0.0
"def data_logging_status(self, trail_name, trail_details, api_client): <TAB> for es in api_client.get_event_selectors(TrailName=trail_name)[""EventSelectors""]: <TAB> <TAB> has_wildcard = { <TAB> <TAB> <TAB> u""Values"": [u""arn:aws:s3:::""], <TAB> <TAB> <TAB> u""Type"": u""AWS::S3::Object"", <TAB> <TAB> } in es[""DataResources""] <TAB> <TAB> is_logging = trail_details[""IsLogging""] <TAB> <TAB> if has_wildcard and is_logging and self.is_fresh(trail_details): <TAB> <TAB> <TAB> return True <TAB> return False",true,if has_wildcard and is_logging and self . is_fresh ( trail_details ) :,if has_wildcard and is_logging and self . is_fresh ( trail_details ) :,0.75,0.0
"def pytest_deselected(items): <TAB> if sb_config.dashboard: <TAB> <TAB> sb_config.item_count -= len(items) <TAB> <TAB> for item in items: <TAB> <TAB> <TAB> test_id, display_id = _get_test_ids_(item) <TAB> <TAB> <TAB> if test_id in sb_config._results.keys(): <TAB> <TAB> <TAB> <TAB> sb_config._results.pop(test_id)",true,if test_id in sb_config . _results . keys ( ) :,if test_id in sb_config . _results . keys ( ) :,0.75,0.0
"def _visit(self, func): <TAB> fname = func[0] <TAB> if fname in self._flags: <TAB> <TAB> if self._flags[fname] == 1: <TAB> <TAB> <TAB> logger.critical(""Fatal error! network ins not Dag."") <TAB> <TAB> <TAB> import sys <TAB> <TAB> <TAB> sys.exit(-1) <TAB> <TAB> else: <TAB> <TAB> <TAB> return <TAB> else: <TAB> <TAB> if fname not in self._flags: <TAB> <TAB> <TAB> self._flags[fname] = 1 <TAB> <TAB> for output in func[3]: <TAB> <TAB> <TAB> for f in self._orig: <TAB> <TAB> <TAB> <TAB> for input in f[2]: <TAB> <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self._visit(f) <TAB> self._flags[fname] = 2 <TAB> self._sorted.insert(0, func)",false,if output == input :,if input == output :,0.29,0.0
"def printWiki(): <TAB> firstHeading = False <TAB> for m in protocol: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if firstHeading: <TAB> <TAB> <TAB> <TAB> output(""|}"") <TAB> <TAB> <TAB> __printWikiHeader(m[1], m[2]) <TAB> <TAB> <TAB> firstHeading = True <TAB> <TAB> else: <TAB> <TAB> <TAB> output(""|-"") <TAB> <TAB> <TAB> output( <TAB> <TAB> <TAB> <TAB> '| <span style=""white-space:nowrap;""><tt>' <TAB> <TAB> <TAB> <TAB> + m[0] <TAB> <TAB> <TAB> <TAB> + ""</tt></span> || || "" <TAB> <TAB> <TAB> <TAB> + m[1] <TAB> <TAB> <TAB> ) <TAB> output(""|}"")",false,"if m [ 0 ] == """" :","if m [ 0 ] == ""heading"" and m [ 1 ] == ""header"" and m [ 2 ] == ""heading"" :",0.36,0.0
"def test_getitem(self): <TAB> n = 200 <TAB> d = deque(range(n)) <TAB> l = list(range(n)) <TAB> for i in range(n): <TAB> <TAB> d.popleft() <TAB> <TAB> l.pop(0) <TAB> <TAB> if random.random() < 0.5: <TAB> <TAB> <TAB> d.append(i) <TAB> <TAB> <TAB> l.append(i) <TAB> <TAB> for j in range(1 - len(l), len(l)): <TAB> <TAB> <TAB> assert d[j] == l[j] <TAB> d = deque(""superman"") <TAB> self.assertEqual(d[0], ""s"") <TAB> self.assertEqual(d[-1], ""n"") <TAB> d = deque() <TAB> self.assertRaises(IndexError, d.__getitem__, 0) <TAB> self.assertRaises(IndexError, d.__getitem__, -1)",true,if random . random ( ) < 0.5 :,if random . random ( ) < 0.5 :,1.0,0.0
"def get_num(line, char_ptr, num_chars): <TAB> char_ptr = char_ptr + 1 <TAB> numstr = """" <TAB> good = ""-.0123456789"" <TAB> while char_ptr < num_chars: <TAB> <TAB> digit = line[char_ptr] <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> numstr = numstr + digit <TAB> <TAB> <TAB> char_ptr = char_ptr + 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> break <TAB> return numstr",false,if good . find ( digit ) != - 1 :,if digit in good :,0.01,0.0
"def read_digits(source, start, first_code): <TAB> body = source.body <TAB> position = start <TAB> code = first_code <TAB> if code is not None and 48 <= code <= 57:  # 0 - 9 <TAB> <TAB> while True: <TAB> <TAB> <TAB> position += 1 <TAB> <TAB> <TAB> code = char_code_at(body, position) <TAB> <TAB> <TAB> if not (code is not None and 48 <= code <= 57): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> return position <TAB> raise GraphQLSyntaxError( <TAB> <TAB> source, <TAB> <TAB> position, <TAB> <TAB> u""Invalid number, expected digit but got: {}."".format(print_char_code(code)), <TAB> )",true,if not ( code is not None and 48 <= code <= 57 ) :,if not ( code is not None and 48 <= code <= 57 ) :,1.0,0.0
"def get_aws_metadata(headers, provider=None): <TAB> if not provider: <TAB> <TAB> provider = boto.provider.get_default() <TAB> metadata_prefix = provider.metadata_prefix <TAB> metadata = {} <TAB> for hkey in headers.keys(): <TAB> <TAB> if hkey.lower().startswith(metadata_prefix): <TAB> <TAB> <TAB> val = urllib.unquote_plus(headers[hkey]) <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> metadata[hkey[len(metadata_prefix) :]] = unicode(val, ""utf-8"") <TAB> <TAB> <TAB> except UnicodeDecodeError: <TAB> <TAB> <TAB> <TAB> metadata[hkey[len(metadata_prefix) :]] = val <TAB> <TAB> <TAB> del headers[hkey] <TAB> return metadata",true,if hkey . lower ( ) . startswith ( metadata_prefix ) :,if hkey . lower ( ) . startswith ( metadata_prefix ) :,0.75,0.0
"def _process_rtdest(self): <TAB> LOG.debug(""Processing RT NLRI destination..."") <TAB> if self._rtdest_queue.is_empty(): <TAB> <TAB> return <TAB> else: <TAB> <TAB> processed_any = False <TAB> <TAB> while not self._rtdest_queue.is_empty(): <TAB> <TAB> <TAB> # We process the first destination in the queue. <TAB> <TAB> <TAB> next_dest = self._rtdest_queue.pop_first() <TAB> <TAB> <TAB> if next_dest: <TAB> <TAB> <TAB> <TAB> next_dest.process() <TAB> <TAB> <TAB> <TAB> processed_any = True <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> # Since RT destination were updated we update RT filters <TAB> <TAB> <TAB> self._core_service.update_rtfilters()",true,if processed_any :,if processed_any :,0.53,0.0
"def _get_header(self, requester, header_name): <TAB> hits = sum([header_name in headers for _, headers in requester.requests]) <TAB> self.assertEquals(hits, 2 if self.revs_enabled else 1) <TAB> for url, headers in requester.requests: <TAB> <TAB> if header_name in headers: <TAB> <TAB> <TAB> if self.revs_enabled: <TAB> <TAB> <TAB> <TAB> self.assertTrue(url.endswith(""/latest""), msg=url) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.assertTrue(url.endswith(""/download_urls""), msg=url) <TAB> <TAB> <TAB> return headers.get(header_name)",false,if self . revs_enabled :,if self . vs_enabled :,0.39,0.0
"def add_external_deps(self, deps): <TAB> for dep in deps: <TAB> <TAB> if hasattr(dep, ""el""): <TAB> <TAB> <TAB> dep = dep.el <TAB> <TAB> if not isinstance(dep, dependencies.Dependency): <TAB> <TAB> <TAB> raise InvalidArguments(""Argument is not an external dependency"") <TAB> <TAB> self.external_deps.append(dep) <TAB> <TAB> if isinstance(dep, dependencies.Dependency): <TAB> <TAB> <TAB> self.process_sourcelist(dep.get_sources())",false,"if not isinstance ( dep , dependencies . Dependency ) :","if isinstance ( dep , dependencies . Dependency ) :",0.41,0.0
"def _consume_msg(self): <TAB> ws = self._ws <TAB> try: <TAB> <TAB> while True: <TAB> <TAB> <TAB> r = await ws.recv() <TAB> <TAB> <TAB> if isinstance(r, bytes): <TAB> <TAB> <TAB> <TAB> r = r.decode(""utf-8"") <TAB> <TAB> <TAB> msg = json.loads(r) <TAB> <TAB> <TAB> stream = msg.get(""stream"") <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> await self._dispatch(stream, msg) <TAB> except websockets.WebSocketException as wse: <TAB> <TAB> logging.warn(wse) <TAB> <TAB> await self.close() <TAB> <TAB> asyncio.ensure_future(self._ensure_ws())",false,if stream is not None :,if stream :,0.05,0.0
"def generate_and_check_random(): <TAB> random_size = 256 <TAB> while True: <TAB> <TAB> random = os.urandom(random_size) <TAB> <TAB> a = int.from_bytes(random, ""big"") <TAB> <TAB> A = pow(g, a, p) <TAB> <TAB> if is_good_mod_exp_first(A, p): <TAB> <TAB> <TAB> a_for_hash = big_num_for_hash(A) <TAB> <TAB> <TAB> u = int.from_bytes(sha256(a_for_hash, b_for_hash), ""big"") <TAB> <TAB> <TAB> if u > 0: <TAB> <TAB> <TAB> <TAB> return (a, a_for_hash, u)",true,"if is_good_mod_exp_first ( A , p ) :","if is_good_mod_exp_first ( A , p ) :",0.75,0.0
"def write(self, datagram, address): <TAB> """"""Write a datagram."""""" <TAB> try: <TAB> <TAB> return self.socket.sendto(datagram, address) <TAB> except OSError as se: <TAB> <TAB> no = se.args[0] <TAB> <TAB> if no == EINTR: <TAB> <TAB> <TAB> return self.write(datagram, address) <TAB> <TAB> elif no == EMSGSIZE: <TAB> <TAB> <TAB> raise error.MessageLengthError(""message too long"") <TAB> <TAB> elif no == EAGAIN: <TAB> <TAB> <TAB> # oh, well, drop the data. The only difference from UDP <TAB> <TAB> <TAB> # is that UDP won't ever notice. <TAB> <TAB> <TAB> # TODO: add TCP-like buffering <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> raise",true,elif no == EAGAIN :,elif no == EAGAIN :,1.0,0.0
"def doDir(elem): <TAB> for child in elem.childNodes: <TAB> <TAB> if not isinstance(child, minidom.Element): <TAB> <TAB> <TAB> continue <TAB> <TAB> if child.tagName == ""Directory"": <TAB> <TAB> <TAB> doDir(child) <TAB> <TAB> elif child.tagName == ""Component"": <TAB> <TAB> <TAB> for grandchild in child.childNodes: <TAB> <TAB> <TAB> <TAB> if not isinstance(grandchild, minidom.Element): <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> if grandchild.tagName != ""File"": <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> files.add(grandchild.getAttribute(""Source"").replace(os.sep, ""/""))",false,"if not isinstance ( child , minidom . Element ) :","if grandchild . tagName != ""File"" :",0.01,0.0
"def add_reversed_tensor(i, X, reversed_X): <TAB> # Do not keep tensors that should stop the mapping. <TAB> if X in stop_mapping_at_tensors: <TAB> <TAB> return <TAB> if X not in reversed_tensors: <TAB> <TAB> reversed_tensors[X] = {""id"": (nid, i), ""tensor"": reversed_X} <TAB> else: <TAB> <TAB> tmp = reversed_tensors[X] <TAB> <TAB> if ""tensor"" in tmp and ""tensors"" in tmp: <TAB> <TAB> <TAB> raise Exception(""Wrong order, tensors already aggregated!"") <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> tmp[""tensors""] = [tmp[""tensor""], reversed_X] <TAB> <TAB> <TAB> del tmp[""tensor""] <TAB> <TAB> else: <TAB> <TAB> <TAB> tmp[""tensors""].append(reversed_X)",false,"if ""tensor"" in tmp :","if ""tensors"" not in tmp :",0.13,0.0
"def walk(source, path, default, delimiter="".""): <TAB> """"""Walk the sourch hash given the path and return the value or default if not found"""""" <TAB> if not isinstance(source, dict): <TAB> <TAB> raise RuntimeError( <TAB> <TAB> <TAB> ""The source is not a walkable dict: {} path: {}"".format(source, path) <TAB> <TAB> ) <TAB> keys = path.split(delimiter) <TAB> max_depth = len(keys) <TAB> cur_depth = 0 <TAB> while cur_depth < max_depth: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> source = source[keys[cur_depth]] <TAB> <TAB> <TAB> cur_depth = cur_depth + 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> return default <TAB> return source",true,if keys [ cur_depth ] in source :,if keys [ cur_depth ] in source :,0.75,0.0
"def _from_txt_get_vulns(self): <TAB> file_vulns = [] <TAB> vuln_regex = ( <TAB> <TAB> 'SQL injection in a .*? was found at: ""(.*?)""' <TAB> <TAB> ', using HTTP method (.*?). The sent .*?data was: ""(.*?)""' <TAB> ) <TAB> vuln_re = re.compile(vuln_regex) <TAB> for line in file(self.OUTPUT_FILE): <TAB> <TAB> mo = vuln_re.search(line) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> v = MockVuln(""TestCase"", None, ""High"", 1, ""plugin"") <TAB> <TAB> <TAB> v.set_url(URL(mo.group(1))) <TAB> <TAB> <TAB> v.set_method(mo.group(2)) <TAB> <TAB> <TAB> file_vulns.append(v) <TAB> return file_vulns",true,if mo :,if mo :,0.53,0.0
"def __get__(self, instance, instance_type=None): <TAB> if instance: <TAB> <TAB> if self.att_name not in instance._obj_cache: <TAB> <TAB> <TAB> rel_obj = self.get_obj(instance) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> instance._obj_cache[self.att_name] = rel_obj <TAB> <TAB> return instance._obj_cache.get(self.att_name) <TAB> return self",true,if rel_obj :,if rel_obj :,0.53,0.0
"def get_ranges_from_func_set(support_set): <TAB> pos_start = 0 <TAB> pos_end = 0 <TAB> ranges = [] <TAB> for pos, func in enumerate(network.function): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> pos_end = pos <TAB> <TAB> else: <TAB> <TAB> <TAB> if pos_end >= pos_start: <TAB> <TAB> <TAB> <TAB> ranges.append((pos_start, pos_end)) <TAB> <TAB> <TAB> pos_start = pos + 1 <TAB> if pos_end >= pos_start: <TAB> <TAB> ranges.append((pos_start, pos_end)) <TAB> return ranges",false,if func . type in support_set :,if func in support_set :,0.16,0.0
"def get_all_active_plugins(self) -> List[BotPlugin]: <TAB> """"""This returns the list of plugins in the callback ordered defined from the config."""""" <TAB> all_plugins = [] <TAB> for name in self.plugins_callback_order: <TAB> <TAB> # None is a placeholder for any plugin not having a defined order <TAB> <TAB> if name is None: <TAB> <TAB> <TAB> all_plugins += [ <TAB> <TAB> <TAB> <TAB> plugin <TAB> <TAB> <TAB> <TAB> for name, plugin in self.plugins.items() <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> ] <TAB> <TAB> else: <TAB> <TAB> <TAB> plugin = self.plugins[name] <TAB> <TAB> <TAB> if plugin.is_activated: <TAB> <TAB> <TAB> <TAB> all_plugins.append(plugin) <TAB> return all_plugins",false,if name not in self . plugins_callback_order and plugin . is_activated,if name in self . plugins_callback_order,0.26,0.0
"def render_token_list(self, tokens): <TAB> result = [] <TAB> vars = [] <TAB> for token in tokens: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result.append(token.contents.replace(""%"", ""%%"")) <TAB> <TAB> elif token.token_type == TOKEN_VAR: <TAB> <TAB> <TAB> result.append(""%%(%s)s"" % token.contents) <TAB> <TAB> <TAB> vars.append(token.contents) <TAB> msg = """".join(result) <TAB> if self.trimmed: <TAB> <TAB> msg = translation.trim_whitespace(msg) <TAB> return msg, vars",false,if token . token_type == TOKEN_TEXT :,if token . token_type == TOKEN_CHAR :,0.57,0.0
"def test_build_root_config_overwrite(self): <TAB> cfg = build_root_config(""tests.files.settings_overwrite"") <TAB> for key, val in DEFAULT_SPIDER_GLOBAL_CONFIG.items(): <TAB> <TAB> if key == ""spider_modules"": <TAB> <TAB> <TAB> self.assertEqual(cfg[""global""][key], [""zzz""]) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.assertEqual(cfg[""global""][key], val)",true,"if key == ""spider_modules"" :","if key == ""spider_modules"" :",0.75,0.0
"def get_limit(self, request): <TAB> if self.limit_query_param: <TAB> <TAB> try: <TAB> <TAB> <TAB> limit = int(request.query_params[self.limit_query_param]) <TAB> <TAB> <TAB> if limit < 0: <TAB> <TAB> <TAB> <TAB> raise ValueError() <TAB> <TAB> <TAB> # Enforce maximum page size, if defined <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> if limit == 0: <TAB> <TAB> <TAB> <TAB> <TAB> return settings.MAX_PAGE_SIZE <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> return min(limit, settings.MAX_PAGE_SIZE) <TAB> <TAB> <TAB> return limit <TAB> <TAB> except (KeyError, ValueError): <TAB> <TAB> <TAB> pass <TAB> return self.default_limit",true,if settings . MAX_PAGE_SIZE :,if settings . MAX_PAGE_SIZE :,0.75,0.0
"def track_handler(handler): <TAB> tid = handler.request.tid <TAB> for event in events_monitored: <TAB> <TAB> if event[""handler_check""](handler): <TAB> <TAB> <TAB> e = Event(event, handler.request.execution_time) <TAB> <TAB> <TAB> State.tenant_state[tid].RecentEventQ.append(e) <TAB> <TAB> <TAB> State.tenant_state[tid].EventQ.append(e) <TAB> <TAB> <TAB> break",true,"if event [ ""handler_check"" ] ( handler ) :","if event [ ""handler_check"" ] ( handler ) :",0.75,0.0
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB> <TAB> tt = d.getVarInt32() <TAB> <TAB> if tt == 10: <TAB> <TAB> <TAB> length = d.getVarInt32() <TAB> <TAB> <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB> <TAB> <TAB> d.skip(length) <TAB> <TAB> <TAB> self.add_subscription().TryMerge(tmp) <TAB> <TAB> <TAB> continue <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> <TAB> d.skipData(tt)",true,if tt == 0 :,if tt == 0 :,0.75,0.0
"def GetCreateInstanceBinder(self, info): <TAB> with self._lock: <TAB> <TAB> if self._createInstanceBinders.ContainsKey(info): <TAB> <TAB> <TAB> return self._createInstanceBinders[info] <TAB> <TAB> b = runtime.SymplCreateInstanceBinder(info) <TAB> <TAB> self._createInstanceBinders[info] = b <TAB> return b",true,if self . _createInstanceBinders . ContainsKey ( info ) :,if self . _createInstanceBinders . ContainsKey ( info ) :,0.75,0.0
"def process_task(self, body, message): <TAB> if ""control"" in body: <TAB> <TAB> try: <TAB> <TAB> <TAB> return self.control(body, message) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> logger.exception(""Exception handling control message:"") <TAB> <TAB> <TAB> return <TAB> if len(self.pool): <TAB> <TAB> if ""uuid"" in body and body[""uuid""]: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> queue = UUID(body[""uuid""]).int % len(self.pool) <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> queue = self.total_messages % len(self.pool) <TAB> <TAB> else: <TAB> <TAB> <TAB> queue = self.total_messages % len(self.pool) <TAB> else: <TAB> <TAB> queue = 0 <TAB> self.pool.write(queue, body) <TAB> self.total_messages += 1 <TAB> message.ack()",true,"if ""uuid"" in body and body [ ""uuid"" ] :","if ""uuid"" in body and body [ ""uuid"" ] :",1.0,0.0
"def is_defined_in_base_class(self, var: Var) -> bool: <TAB> if var.info: <TAB> <TAB> for base in var.info.mro[1:]: <TAB> <TAB> <TAB> if base.get(var.name) is not None: <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return True <TAB> return False",false,if var . info . fallback_to_any :,if base . get ( var . name ) is not None :,0.03,0.0
"def ant_map(m): <TAB> tmp = ""rows %s\ncols %s\n"" % (len(m), len(m[0])) <TAB> players = {} <TAB> for row in m: <TAB> <TAB> tmp += ""m "" <TAB> <TAB> for col in row: <TAB> <TAB> <TAB> if col == LAND: <TAB> <TAB> <TAB> <TAB> tmp += ""."" <TAB> <TAB> <TAB> elif col == BARRIER: <TAB> <TAB> <TAB> <TAB> tmp += ""%"" <TAB> <TAB> <TAB> elif col == FOOD: <TAB> <TAB> <TAB> <TAB> tmp += ""*"" <TAB> <TAB> <TAB> elif col == UNSEEN: <TAB> <TAB> <TAB> <TAB> tmp += ""?"" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> players[col] = True <TAB> <TAB> <TAB> <TAB> tmp += chr(col + 97) <TAB> <TAB> tmp += ""\n"" <TAB> tmp = (""players %s\n"" % len(players)) + tmp <TAB> return tmp",false,elif col == BARRIER :,elif col == FOOD :,0.64,0.0
"def prompt_for_resume(config): <TAB> logger = logging.getLogger(""changeme"") <TAB> logger.error( <TAB> <TAB> ""A previous scan was interrupted. Type R to resume or F to start a fresh scan"" <TAB> ) <TAB> answer = """" <TAB> while not (answer == ""R"" or answer == ""F""): <TAB> <TAB> prompt = ""(R/F)> "" <TAB> <TAB> answer = """" <TAB> <TAB> try: <TAB> <TAB> <TAB> answer = raw_input(prompt) <TAB> <TAB> except NameError: <TAB> <TAB> <TAB> answer = input(prompt) <TAB> <TAB> if answer.upper() == ""F"": <TAB> <TAB> <TAB> logger.debug(""Forcing a fresh scan"") <TAB> <TAB> elif answer.upper() == ""R"": <TAB> <TAB> <TAB> logger.debug(""Resuming previous scan"") <TAB> <TAB> <TAB> config.resume = True <TAB> return config.resume",true,"if answer . upper ( ) == ""F"" :","if answer . upper ( ) == ""F"" :",0.75,0.0
"def f(view, s): <TAB> if mode == modes.INTERNAL_NORMAL: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> if view.line(s.b).size() > 0: <TAB> <TAB> <TAB> <TAB> eol = view.line(s.b).b <TAB> <TAB> <TAB> <TAB> return R(s.b, eol) <TAB> <TAB> <TAB> return s <TAB> return s",false,if count == 1 :,if s . b :,0.03,0.0
"def flush(self): <TAB> if not self.cuts: <TAB> <TAB> return <TAB> for move, (x, y, z), cent in douglas(self.cuts, self.tolerance, self.plane): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.write(""%s X%.4f Y%.4f Z%.4f %s"" % (move, x, y, z, cent)) <TAB> <TAB> <TAB> self.lastgcode = None <TAB> <TAB> <TAB> self.lastx = x <TAB> <TAB> <TAB> self.lasty = y <TAB> <TAB> <TAB> self.lastz = z <TAB> <TAB> else: <TAB> <TAB> <TAB> self.move_common(x, y, z, gcode=""G1"") <TAB> self.cuts = []",false,if cent :,if move :,0.32,0.0
"def copy_shell(self): <TAB> cls = self.__class__ <TAB> old_id = cls.id <TAB> new_i = cls()  # create a new group <TAB> new_i.id = self.id  # with the same id <TAB> cls.id = old_id  # Reset the Class counter <TAB> # Copy all properties <TAB> for prop in cls.properties: <TAB> <TAB> if prop is not ""members"": <TAB> <TAB> <TAB> if self.has(prop): <TAB> <TAB> <TAB> <TAB> val = getattr(self, prop) <TAB> <TAB> <TAB> <TAB> setattr(new_i, prop, val) <TAB> # but no members <TAB> new_i.members = [] <TAB> return new_i",true,"if prop is not ""members"" :","if prop is not ""members"" :",0.75,0.0
"def find_region_by_value(key, value): <TAB> for region in cognitoidp_backends: <TAB> <TAB> backend = cognitoidp_backends[region] <TAB> <TAB> for user_pool in backend.user_pools.values(): <TAB> <TAB> <TAB> if key == ""client_id"" and value in user_pool.clients: <TAB> <TAB> <TAB> <TAB> return region <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return region <TAB> # If we can't find the `client_id` or `access_token`, we just pass <TAB> # back a default backend region, which will raise the appropriate <TAB> # error message (e.g. NotAuthorized or NotFound). <TAB> return list(cognitoidp_backends)[0]",true,"if key == ""access_token"" and value in user_pool . access_tokens :","if key == ""access_token"" and value in user_pool . access_tokens :",0.75,0.0
"def __init__( <TAB> self, fixed: MQTTFixedHeader = None, variable_header: PacketIdVariableHeader = None ): <TAB> if fixed is None: <TAB> <TAB> header = MQTTFixedHeader(PUBREL, 0x02)  # [MQTT-3.6.1-1] <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise HBMQTTException( <TAB> <TAB> <TAB> <TAB> ""Invalid fixed packet type %s for PubrelPacket init"" % fixed.packet_type <TAB> <TAB> <TAB> ) <TAB> <TAB> header = fixed <TAB> super().__init__(header) <TAB> self.variable_header = variable_header <TAB> self.payload = None",true,if fixed . packet_type is not PUBREL :,if fixed . packet_type is not PUBREL :,0.75,0.0
"def _on_event_MetadataStatisticsUpdated(self, event, data): <TAB> with self._selectedFileMutex: <TAB> <TAB> if self._selectedFile: <TAB> <TAB> <TAB> self._setJobData( <TAB> <TAB> <TAB> <TAB> self._selectedFile[""filename""], <TAB> <TAB> <TAB> <TAB> self._selectedFile[""filesize""], <TAB> <TAB> <TAB> <TAB> self._selectedFile[""sd""], <TAB> <TAB> <TAB> <TAB> self._selectedFile[""user""], <TAB> <TAB> <TAB> )",true,if self . _selectedFile :,if self . _selectedFile :,0.75,0.0
"def _validate_parameter_range(self, value_hp, parameter_range): <TAB> """"""Placeholder docstring"""""" <TAB> for ( <TAB> <TAB> parameter_range_key, <TAB> <TAB> parameter_range_value, <TAB> ) in parameter_range.__dict__.items(): <TAB> <TAB> if parameter_range_key == ""scaling_type"": <TAB> <TAB> <TAB> continue <TAB> <TAB> # Categorical ranges <TAB> <TAB> if isinstance(parameter_range_value, list): <TAB> <TAB> <TAB> for categorical_value in parameter_range_value: <TAB> <TAB> <TAB> <TAB> value_hp.validate(categorical_value) <TAB> <TAB> # Continuous, Integer ranges <TAB> <TAB> else: <TAB> <TAB> <TAB> value_hp.validate(parameter_range_value)",true,"if parameter_range_key == ""scaling_type"" :","if parameter_range_key == ""scaling_type"" :",0.75,0.0
"def visit_filter_projection(self, node, value): <TAB> base = self.visit(node[""children""][0], value) <TAB> if not isinstance(base, list): <TAB> <TAB> return None <TAB> comparator_node = node[""children""][2] <TAB> collected = [] <TAB> for element in base: <TAB> <TAB> if self._is_true(self.visit(comparator_node, element)): <TAB> <TAB> <TAB> current = self.visit(node[""children""][1], element) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> collected.append(current) <TAB> return collected",true,if current is not None :,if current is not None :,0.75,0.0
"def _getSubstrings(self, va, size, ltyp): <TAB> # rip through the desired memory range to populate any substrings <TAB> subs = set() <TAB> end = va + size <TAB> for offs in range(va, end, 1): <TAB> <TAB> loc = self.getLocation(offs, range=True) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> subs.add((loc[L_VA], loc[L_SIZE])) <TAB> <TAB> <TAB> if loc[L_TINFO]: <TAB> <TAB> <TAB> <TAB> subs = subs.union(set(loc[L_TINFO])) <TAB> return list(subs)",false,if loc and loc [ L_LTYPE ] == LOC_STRING and loc [ L_VA ] > va :,if loc [ L_VA ] == ltyp :,0.14,0.0
"def run(self): <TAB> while not self._stopped: <TAB> <TAB> try: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> test_name = next(self.pending) <TAB> <TAB> <TAB> except StopIteration: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> mp_result = self._runtest(test_name) <TAB> <TAB> <TAB> self.output.put((False, mp_result)) <TAB> <TAB> <TAB> if must_stop(mp_result.result, self.ns): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> except ExitThread: <TAB> <TAB> <TAB> break <TAB> <TAB> except BaseException: <TAB> <TAB> <TAB> self.output.put((True, traceback.format_exc())) <TAB> <TAB> <TAB> break",true,"if must_stop ( mp_result . result , self . ns ) :","if must_stop ( mp_result . result , self . ns ) :",0.75,0.0
"def get_in_inputs(key, data): <TAB> if isinstance(data, dict): <TAB> <TAB> for k, v in data.items(): <TAB> <TAB> <TAB> if k == key: <TAB> <TAB> <TAB> <TAB> return v <TAB> <TAB> <TAB> elif isinstance(v, (list, tuple, dict)): <TAB> <TAB> <TAB> <TAB> out = get_in_inputs(key, v) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return out <TAB> elif isinstance(data, (list, tuple)): <TAB> <TAB> out = [get_in_inputs(key, x) for x in data] <TAB> <TAB> out = [x for x in out if x] <TAB> <TAB> if out: <TAB> <TAB> <TAB> return out[0]",true,if out :,if out :,0.53,0.0
"def act_mapping(self, items, actions, mapping): <TAB> """"""Executes all the actions on the list of pods."""""" <TAB> success = True <TAB> for action in actions: <TAB> <TAB> for key, method in mapping.items(): <TAB> <TAB> <TAB> if key in action: <TAB> <TAB> <TAB> <TAB> params = action.get(key) <TAB> <TAB> <TAB> <TAB> ret = method(items, params) <TAB> <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> success = False <TAB> return success",false,if not ret :,if ret is False :,0.05,0.0
"def _apply(self, plan): <TAB> desired = plan.desired <TAB> changes = plan.changes <TAB> self.log.debug(""_apply: zone=%s, len(changes)=%d"", desired.name, len(changes)) <TAB> domain_name = desired.name[:-1] <TAB> try: <TAB> <TAB> nsone_zone = self._client.loadZone(domain_name) <TAB> except ResourceException as e: <TAB> <TAB> if e.message != self.ZONE_NOT_FOUND_MESSAGE: <TAB> <TAB> <TAB> raise <TAB> <TAB> self.log.debug(""_apply:   no matching zone, creating"") <TAB> <TAB> nsone_zone = self._client.createZone(domain_name) <TAB> for change in changes: <TAB> <TAB> class_name = change.__class__.__name__ <TAB> <TAB> getattr(self, ""_apply_{}"".format(class_name))(nsone_zone, change)",true,if e . message != self . ZONE_NOT_FOUND_MESSAGE :,if e . message != self . ZONE_NOT_FOUND_MESSAGE :,0.75,0.0
"def split_artists(self, json): <TAB> if len(json) == 0: <TAB> <TAB> ([], []) <TAB> elif len(json) == 1: <TAB> <TAB> artist = Artist.query.filter_by(name=json[0][""name""]).first() <TAB> <TAB> return ([artist], []) <TAB> my_artists = [] <TAB> other_artists = [] <TAB> for artist_dict in json: <TAB> <TAB> artist = Artist.query.filter_by(name=artist_dict[""name""]) <TAB> <TAB> if artist.count(): <TAB> <TAB> <TAB> my_artists.append(artist.first()) <TAB> <TAB> else: <TAB> <TAB> <TAB> del artist_dict[""thumb_url""] <TAB> <TAB> <TAB> other_artists.append(artist_dict) <TAB> return (my_artists, other_artists)",true,if artist . count ( ) :,if artist . count ( ) :,0.75,0.0
"def update_metadata(self): <TAB> for attrname in dir(self): <TAB> <TAB> if attrname.startswith(""__""): <TAB> <TAB> <TAB> continue <TAB> <TAB> attrvalue = getattr(self, attrname, None) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if attrname == ""salt_version"": <TAB> <TAB> <TAB> attrname = ""version"" <TAB> <TAB> if hasattr(self.metadata, ""set_{0}"".format(attrname)): <TAB> <TAB> <TAB> getattr(self.metadata, ""set_{0}"".format(attrname))(attrvalue) <TAB> <TAB> elif hasattr(self.metadata, attrname): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> setattr(self.metadata, attrname, attrvalue) <TAB> <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> <TAB> pass",false,if attrvalue == 0 :,if attrvalue is None :,0.06,0.0
"def close(self, code=errno.ECONNRESET): <TAB> with self.shutdown_lock: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> super(RemoteIPRoute, self).close(code=code) <TAB> <TAB> <TAB> self.closed = True <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> self._mitogen_call.get() <TAB> <TAB> <TAB> except mitogen.core.ChannelError: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> if self._mitogen_broker is not None: <TAB> <TAB> <TAB> <TAB> self._mitogen_broker.shutdown() <TAB> <TAB> <TAB> <TAB> self._mitogen_broker.join()",true,if not self . closed :,if not self . closed :,0.75,0.0
"def untokenize(self, iterable): <TAB> for t in iterable: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.compat(t, iterable) <TAB> <TAB> <TAB> break <TAB> <TAB> tok_type, token, start, end, line = t <TAB> <TAB> self.add_whitespace(start) <TAB> <TAB> self.tokens.append(token) <TAB> <TAB> self.prev_row, self.prev_col = end <TAB> <TAB> if tok_type in (NEWLINE, NL): <TAB> <TAB> <TAB> self.prev_row += 1 <TAB> <TAB> <TAB> self.prev_col = 0 <TAB> return """".join(self.tokens)",false,if len ( t ) == 2 :,if t in self . compat_tokens :,0.02,0.0
"def __call__(self, x, uttid=None): <TAB> if self.utt2spk is not None: <TAB> <TAB> spk = self.utt2spk[uttid] <TAB> else: <TAB> <TAB> spk = uttid <TAB> if not self.reverse: <TAB> <TAB> if self.norm_means: <TAB> <TAB> <TAB> x = np.add(x, self.bias[spk]) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> x = np.multiply(x, self.scale[spk]) <TAB> else: <TAB> <TAB> if self.norm_vars: <TAB> <TAB> <TAB> x = np.divide(x, self.scale[spk]) <TAB> <TAB> if self.norm_means: <TAB> <TAB> <TAB> x = np.subtract(x, self.bias[spk]) <TAB> return x",true,if self . norm_vars :,if self . norm_vars :,0.75,0.0
"def get_party_total(self, args): <TAB> self.party_total = frappe._dict() <TAB> for d in self.receivables: <TAB> <TAB> self.init_party_total(d) <TAB> <TAB> # Add all amount columns <TAB> <TAB> for k in list(self.party_total[d.party]): <TAB> <TAB> <TAB> if k not in [""currency"", ""sales_person""]: <TAB> <TAB> <TAB> <TAB> self.party_total[d.party][k] += d.get(k, 0.0) <TAB> <TAB> # set territory, customer_group, sales person etc <TAB> <TAB> self.set_party_details(d)",true,"if k not in [ ""currency"" , ""sales_person"" ] :","if k not in [ ""currency"" , ""sales_person"" ] :",0.75,0.0
"def get_databases(request): <TAB> dbs = {} <TAB> global_env = globals() <TAB> for (key, value) in global_env.items(): <TAB> <TAB> try: <TAB> <TAB> <TAB> cond = isinstance(value, GQLDB) <TAB> <TAB> except: <TAB> <TAB> <TAB> cond = isinstance(value, SQLDB) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> dbs[key] = value <TAB> return dbs",true,if cond :,if cond :,0.53,0.0
"def check_twobit_file(dbkey, GALAXY_DATA_INDEX_DIR): <TAB> twobit_file = ""%s/twobit.loc"" % GALAXY_DATA_INDEX_DIR <TAB> twobit_path = """" <TAB> twobits = {} <TAB> for i, line in enumerate(open(twobit_file)): <TAB> <TAB> line = line.rstrip(""\r\n"") <TAB> <TAB> if line and not line.startswith(""#""): <TAB> <TAB> <TAB> fields = line.split(""\t"") <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> twobits[(fields[0])] = fields[1] <TAB> if dbkey in twobits: <TAB> <TAB> twobit_path = twobits[(dbkey)] <TAB> return twobit_path",false,if len ( fields ) < 2 :,if len ( fields ) != 2 :,0.55,0.0
"def action(scheduler, _): <TAB> nonlocal state <TAB> nonlocal has_result <TAB> nonlocal result <TAB> nonlocal first <TAB> nonlocal time <TAB><IF-STMT> <TAB> <TAB> observer.on_next(result) <TAB> try: <TAB> <TAB> if first: <TAB> <TAB> <TAB> first = False <TAB> <TAB> else: <TAB> <TAB> <TAB> state = iterate(state) <TAB> <TAB> has_result = condition(state) <TAB> <TAB> if has_result: <TAB> <TAB> <TAB> result = state <TAB> <TAB> <TAB> time = time_mapper(state) <TAB> except Exception as e:  # pylint: disable=broad-except <TAB> <TAB> observer.on_error(e) <TAB> <TAB> return <TAB> if has_result: <TAB> <TAB> mad.disposable = scheduler.schedule_relative(time, action) <TAB> else: <TAB> <TAB> observer.on_completed()",true,if has_result :,if has_result :,0.53,0.0
def orthogonalEnd(self): <TAB> if self.type == Segment.LINE: <TAB> <TAB> O = self.AB.orthogonal() <TAB> <TAB> O.norm() <TAB> <TAB> return O <TAB> else: <TAB> <TAB> O = self.B - self.C <TAB> <TAB> O.norm() <TAB> <TAB> if self.type == Segment.CCW: <TAB> <TAB> <TAB> return -O <TAB> <TAB> else: <TAB> <TAB> <TAB> return O,true,if self . type == Segment . CCW :,if self . type == Segment . CCW :,0.75,0.0
"def remove(self, values): <TAB> if not isinstance(values, (list, tuple, set)): <TAB> <TAB> values = [values] <TAB> for v in values: <TAB> <TAB> v = str(v) <TAB> <TAB> if isinstance(self._definition, dict): <TAB> <TAB> <TAB> self._definition.pop(v, None) <TAB> <TAB> elif self._definition == ""ANY"": <TAB> <TAB> <TAB> if v == ""ANY"": <TAB> <TAB> <TAB> <TAB> self._definition = [] <TAB> <TAB> elif v in self._definition: <TAB> <TAB> <TAB> self._definition.remove(v) <TAB> if ( <TAB> <TAB> self._value is not None <TAB> <TAB> and self._value not in self._definition <TAB> <TAB> and self._not_any() <TAB> ): <TAB> <TAB> raise ConanException(bad_value_msg(self._name, self._value, self.values_range))",false,"if v == ""ANY"" :","if isinstance ( self . _definition , dict ) :",0.02,0.0
"def __enter__(self) -> None: <TAB> try: <TAB> <TAB> if threading.current_thread() == threading.main_thread(): <TAB> <TAB> <TAB> signal.signal(signal.SIGALRM, self.handle_timeout) <TAB> <TAB> <TAB> signal.alarm(self.seconds) <TAB> except ValueError as ex: <TAB> <TAB> logger.warning(""timeout can't be used in the current context"") <TAB> <TAB> logger.exception(ex)",true,if threading . current_thread ( ) == threading . main_thread ( ) :,if threading . current_thread ( ) == threading . main_thread ( ) :,1.0,0.0
"def __init__(self, fixed: MQTTFixedHeader = None): <TAB> if fixed is None: <TAB> <TAB> header = MQTTFixedHeader(PINGRESP, 0x00) <TAB> else: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> raise HBMQTTException( <TAB> <TAB> <TAB> <TAB> ""Invalid fixed packet type %s for PingRespPacket init"" <TAB> <TAB> <TAB> <TAB> % fixed.packet_type <TAB> <TAB> <TAB> ) <TAB> <TAB> header = fixed <TAB> super().__init__(header) <TAB> self.variable_header = None <TAB> self.payload = None",true,if fixed . packet_type is not PINGRESP :,if fixed . packet_type is not PINGRESP :,0.75,0.0
"def _put_nowait(self, data, *, sender): <TAB> if not self._running: <TAB> <TAB> logger.warning(""Pub/Sub listener message after stop: %r, %r"", sender, data) <TAB> <TAB> return <TAB> self._queue.put_nowait((sender, data)) <TAB> if self._waiter is not None: <TAB> <TAB> fut, self._waiter = self._waiter, None <TAB> <TAB> if fut.done(): <TAB> <TAB> <TAB> assert fut.cancelled(), (""Waiting future is in wrong state"", self, fut) <TAB> <TAB> <TAB> return <TAB> <TAB> fut.set_result(None)",true,if fut . done ( ) :,if fut . done ( ) :,0.75,0.0
"def OnAssignBuiltin(self, cmd_val): <TAB> # type: (cmd_value__Assign) -> None <TAB> buf = self._ShTraceBegin() <TAB> if not buf: <TAB> <TAB> return <TAB> for i, arg in enumerate(cmd_val.argv): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> buf.write("" "") <TAB> <TAB> buf.write(arg) <TAB> for pair in cmd_val.pairs: <TAB> <TAB> buf.write("" "") <TAB> <TAB> buf.write(pair.var_name) <TAB> <TAB> buf.write(""="") <TAB> <TAB> if pair.rval: <TAB> <TAB> <TAB> _PrintShValue(pair.rval, buf) <TAB> buf.write(""\n"") <TAB> self.f.write(buf.getvalue())",false,if i != 0 :,if i :,0.07,0.0
"def convertDict(obj): <TAB> obj = dict(obj) <TAB> for k, v in obj.items(): <TAB> <TAB> del obj[k] <TAB> <TAB> if not (isinstance(k, str) or isinstance(k, unicode)): <TAB> <TAB> <TAB> k = dumps(k) <TAB> <TAB> <TAB> # Keep track of which keys need to be decoded when loading. <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> obj[Types.KEYS] = [] <TAB> <TAB> <TAB> obj[Types.KEYS].append(k) <TAB> <TAB> obj[k] = convertObjects(v) <TAB> return obj",true,if Types . KEYS not in obj :,if Types . KEYS not in obj :,0.75,0.0
"def _ArgumentListHasDictionaryEntry(self, token): <TAB> """"""Check if the function argument list has a dictionary as an arg."""""" <TAB> if _IsArgumentToFunction(token): <TAB> <TAB> while token: <TAB> <TAB> <TAB> if token.value == ""{"": <TAB> <TAB> <TAB> <TAB> length = token.matching_bracket.total_length - token.total_length <TAB> <TAB> <TAB> <TAB> return length + self.stack[-2].indent > self.column_limit <TAB> <TAB> <TAB> if token.ClosesScope(): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if token.OpensScope(): <TAB> <TAB> <TAB> <TAB> token = token.matching_bracket <TAB> <TAB> <TAB> token = token.next_token <TAB> return False",false,if token . OpensScope ( ) :,"if token . value == ""{"" :",0.09,0.0
"def get_editable_dict(self): <TAB> ret = {} <TAB> for ref, ws_package in self._workspace_packages.items(): <TAB> <TAB> path = ws_package.root_folder <TAB> <TAB> if os.path.isdir(path): <TAB> <TAB> <TAB> path = os.path.join(path, CONANFILE) <TAB> <TAB> ret[ref] = {""path"": path, ""layout"": ws_package.layout} <TAB> return ret",true,if os . path . isdir ( path ) :,if os . path . isdir ( path ) :,1.0,0.0
"def serialize(self, name=None): <TAB> data = super(WebLink, self).serialize(name) <TAB> data[""contentType""] = self.contentType <TAB> if self.width: <TAB> <TAB> if self.width not in [100, 50, 33, 25]: <TAB> <TAB> <TAB> raise InvalidWidthException(self.width) <TAB> <TAB> data[""inputOptions""] = {} <TAB> <TAB> data[""width""] = self.width <TAB> data.update({""content"": {""url"": self.linkUrl, ""text"": self.linkText}}) <TAB> return data",true,"if self . width not in [ 100 , 50 , 33 , 25 ] :","if self . width not in [ 100 , 50 , 33 , 25 ] :",0.75,0.0
"def callback(lexer, match, context): <TAB> text = match.group() <TAB> extra = """" <TAB> if start: <TAB> <TAB> context.next_indent = len(text) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> while context.next_indent < context.indent: <TAB> <TAB> <TAB> <TAB> context.indent = context.indent_stack.pop() <TAB> <TAB> <TAB> if context.next_indent > context.indent: <TAB> <TAB> <TAB> <TAB> extra = text[context.indent :] <TAB> <TAB> <TAB> <TAB> text = text[: context.indent] <TAB> else: <TAB> <TAB> context.next_indent += len(text) <TAB> if text: <TAB> <TAB> yield match.start(), TokenClass, text <TAB> if extra: <TAB> <TAB> yield match.start() + len(text), TokenClass.Error, extra <TAB> context.pos = match.end()",false,if context . next_indent < context . indent :,if context . indent_stack :,0.19,0.0
"def _handle_unsubscribe(self, web_sock): <TAB> index = None <TAB> with await self._subscriber_lock: <TAB> <TAB> for i, (subscriber_web_sock, _) in enumerate(self._subscribers): <TAB> <TAB> <TAB> if subscriber_web_sock == web_sock: <TAB> <TAB> <TAB> <TAB> index = i <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> del self._subscribers[index] <TAB> <TAB> if not self._subscribers: <TAB> <TAB> <TAB> asyncio.ensure_future(self._unregister_subscriptions())",false,if index is not None :,if index :,0.05,0.0
"def test_missing_dict_param(): <TAB> expected_err = ""params dictionary did not contain value for placeholder"" <TAB> try: <TAB> <TAB> substitute_params( <TAB> <TAB> <TAB> ""SELECT * FROM cust WHERE salesrep = %(name)s"", {""foobar"": ""John Doe""} <TAB> <TAB> ) <TAB> <TAB> assert False, ""expected exception b/c dict did not contain replacement value"" <TAB> except ValueError as exc: <TAB> <TAB> if expected_err not in str(exc): <TAB> <TAB> <TAB> raise",true,if expected_err not in str ( exc ) :,if expected_err not in str ( exc ) :,0.75,0.0
"def one_gpr_reg_one_mem_scalable(ii): <TAB> n, r = 0, 0 <TAB> for op in _gen_opnds(ii): <TAB> <TAB> if op_agen(op) or (op_mem(op) and op.oc2 in [""v""]): <TAB> <TAB> <TAB> n += 1 <TAB> <TAB> elif op_gprv(op): <TAB> <TAB> <TAB> r += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> return False <TAB> return n == 1 and r == 1",false,"if op_agen ( op ) or ( op_mem ( op ) and op . oc2 in [ ""v"" ] ) :",elif op_gprv ( op ) :,0.02,0.0
"def on_enter(self): <TAB> """"""Fired when mouse enter the bbox of the widget."""""" <TAB> if hasattr(self, ""md_bg_color"") and self.focus_behavior: <TAB> <TAB> if hasattr(self, ""theme_cls"") and not self.focus_color: <TAB> <TAB> <TAB> self.md_bg_color = self.theme_cls.bg_normal <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> self.md_bg_color = App.get_running_app().theme_cls.bg_normal <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.md_bg_color = self.focus_color",false,if not self . focus_color :,if self . focus_behavior :,0.05,0.0
"def __init__(self, *args, **kwargs): <TAB> BaseCellExporter.__init__(self, *args, **kwargs) <TAB> self.comment = ""#"" <TAB> for key in [""cell_marker""]: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> self.metadata[key] = self.unfiltered_metadata[key] <TAB> if self.fmt.get(""rst2md""): <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> ""The 'rst2md' option is a read only option. The reverse conversion is not "" <TAB> <TAB> <TAB> ""implemented. Please either deactivate the option, or save to another format."" <TAB> <TAB> )  # pragma: no cover",true,if key in self . unfiltered_metadata :,if key in self . unfiltered_metadata :,0.75,0.0
"def sendQueryQueueByAfterNate(self): <TAB> for i in range(10): <TAB> <TAB> queryQueueByAfterNateRsp = self.session.httpClint.send(urls.get(""queryQueue"")) <TAB> <TAB> if not queryQueueByAfterNateRsp.get(""status""): <TAB> <TAB> <TAB> print( <TAB> <TAB> <TAB> <TAB> """".join(queryQueueByAfterNateRsp.get(""messages"")) <TAB> <TAB> <TAB> <TAB> or queryQueueByAfterNateRsp.get(""validateMessages"") <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> time.sleep(1) <TAB> <TAB> else: <TAB> <TAB> <TAB> sendEmail(ticket.WAIT_ORDER_SUCCESS) <TAB> <TAB> <TAB> sendServerChan(ticket.WAIT_ORDER_SUCCESS) <TAB> <TAB> <TAB> raise ticketIsExitsException(ticket.WAIT_AFTER_NATE_SUCCESS)",true,"if not queryQueueByAfterNateRsp . get ( ""status"" ) :","if not queryQueueByAfterNateRsp . get ( ""status"" ) :",0.75,0.0
"def filter_errors(self, errors: List[str]) -> List[str]: <TAB> real_errors: List[str] = list() <TAB> current_file = __file__ <TAB> current_path = os.path.split(current_file) <TAB> for line in errors: <TAB> <TAB> line = line.strip() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> fn, lno, lvl, msg = self.parse_trace_line(line) <TAB> <TAB> if fn is not None: <TAB> <TAB> <TAB> _path = os.path.split(fn) <TAB> <TAB> <TAB> if _path[-1] != current_path[-1]: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> real_errors.append(line) <TAB> return real_errors",true,if not line :,if not line :,0.75,0.0
"def pretty(self, n, comment=True): <TAB> if isinstance(n, (str, bytes, list, tuple, dict)): <TAB> <TAB> r = repr(n) <TAB> <TAB> if not comment:  # then it can be inside a comment! <TAB> <TAB> <TAB> r = r.replace(""*/"", r""\x2a/"") <TAB> <TAB> return r <TAB> if not isinstance(n, six.integer_types): <TAB> <TAB> return n <TAB> if isinstance(n, constants.Constant): <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> return ""%s /* %s */"" % (n, self.pretty(int(n))) <TAB> <TAB> else: <TAB> <TAB> <TAB> return ""%s (%s)"" % (n, self.pretty(int(n))) <TAB> elif abs(n) < 10: <TAB> <TAB> return str(n) <TAB> else: <TAB> <TAB> return hex(n)",false,if comment :,if abs ( n ) < 10 :,0.04,0.0
"def get_pricings(self, subscription_id: str): <TAB> try: <TAB> <TAB> client = self.get_client(subscription_id) <TAB> <TAB> pricings_list = await run_concurrently(lambda: client.pricings.list()) <TAB> <TAB> if hasattr(pricings_list, ""value""): <TAB> <TAB> <TAB> return pricings_list.value <TAB> <TAB> else: <TAB> <TAB> <TAB> return [] <TAB> except Exception as e: <TAB> <TAB> print_exception(f""Failed to retrieve pricings: {e}"") <TAB> <TAB> return []",true,"if hasattr ( pricings_list , ""value"" ) :","if hasattr ( pricings_list , ""value"" ) :",0.75,0.0
"def add_doc(target, variables, body_lines): <TAB> if isinstance(target, ast.Name): <TAB> <TAB> # if it is a variable name add it to the doc <TAB> <TAB> name = target.id <TAB> <TAB> if name not in variables: <TAB> <TAB> <TAB> doc = find_doc_for(target, body_lines) <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> variables[name] = doc <TAB> elif isinstance(target, ast.Tuple): <TAB> <TAB> # if it is a tuple then iterate the elements <TAB> <TAB> # this can happen like this: <TAB> <TAB> # a, b = 1, 2 <TAB> <TAB> for e in target.elts: <TAB> <TAB> <TAB> add_doc(e, variables, body_lines)",false,if doc is not None :,if doc :,0.05,0.0
"def find_word_bounds(self, text, index, allowed_chars): <TAB> right = left = index <TAB> done = False <TAB> while not done: <TAB> <TAB> if left == 0: <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self.word_boundary_char(text[left - 1]): <TAB> <TAB> <TAB> left -= 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> done = True <TAB> done = False <TAB> while not done: <TAB> <TAB> if right == len(text): <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self.word_boundary_char(text[right]): <TAB> <TAB> <TAB> right += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> done = True <TAB> return left, right",false,if right == len ( text ) :,elif not self . word_boundary_char ( text [ right - 1 ] ) :,0.03,0.0
"def pxrun_nodes(self, *args, **kwargs): <TAB> cell = self._px_cell <TAB> if re.search(r""^\s*%autopx\b"", cell): <TAB> <TAB> self._disable_autopx() <TAB> <TAB> return False <TAB> else: <TAB> <TAB> try: <TAB> <TAB> <TAB> result = self.view.execute(cell, silent=False, block=False) <TAB> <TAB> except: <TAB> <TAB> <TAB> self.shell.showtraceback() <TAB> <TAB> <TAB> return True <TAB> <TAB> else: <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> <TAB> result.get() <TAB> <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> <TAB> self.shell.showtraceback() <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> result.display_outputs() <TAB> <TAB> <TAB> return False",false,if self . view . block :,if result :,0.02,0.0
"def candidates() -> Generator[""Symbol"", None, None]: <TAB> s = self <TAB> if Symbol.debug_lookup: <TAB> <TAB> Symbol.debug_print(""searching in self:"") <TAB> <TAB> print(s.to_string(Symbol.debug_indent + 1), end="""") <TAB> while True: <TAB> <TAB> if matchSelf: <TAB> <TAB> <TAB> yield s <TAB> <TAB> if recurseInAnon: <TAB> <TAB> <TAB> yield from s.children_recurse_anon <TAB> <TAB> else: <TAB> <TAB> <TAB> yield from s._children <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> s = s.siblingAbove <TAB> <TAB> if Symbol.debug_lookup: <TAB> <TAB> <TAB> Symbol.debug_print(""searching in sibling:"") <TAB> <TAB> <TAB> print(s.to_string(Symbol.debug_indent + 1), end="""")",true,if s . siblingAbove is None :,if s . siblingAbove is None :,0.75,0.0
"def decTaskGen(): <TAB> cnt = intbv(0, min=-n, max=n) <TAB> while 1: <TAB> <TAB> yield clock.posedge, reset.negedge <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> cnt[:] = 0 <TAB> <TAB> <TAB> count.next = 0 <TAB> <TAB> else: <TAB> <TAB> <TAB> # print count <TAB> <TAB> <TAB> decTaskFunc(cnt, enable, reset, n) <TAB> <TAB> <TAB> count.next = cnt",true,if reset == ACTIVE_LOW :,if reset == ACTIVE_LOW :,0.75,0.0
"def __call__(self, *args, **kwargs): <TAB> if not NET_INITTED: <TAB> <TAB> return self.raw(*args, **kwargs) <TAB> for stack in traceback.walk_stack(None): <TAB> <TAB> if ""self"" in stack[0].f_locals: <TAB> <TAB> <TAB> layer = stack[0].f_locals[""self""] <TAB> <TAB> <TAB> if layer in layer_names: <TAB> <TAB> <TAB> <TAB> log.pytorch_layer_name = layer_names[layer] <TAB> <TAB> <TAB> <TAB> print(layer_names[layer]) <TAB> <TAB> <TAB> <TAB> break <TAB> out = self.obj(self.raw, *args, **kwargs) <TAB> # if isinstance(out,Variable): <TAB> # <TAB> out=[out] <TAB> return out",true,"if ""self"" in stack [ 0 ] . f_locals :","if ""self"" in stack [ 0 ] . f_locals :",0.75,0.0
"def to_json_dict(self): <TAB> d = super().to_json_dict() <TAB> d[""bullet_list""] = RenderedContent.rendered_content_list_to_json(self.bullet_list) <TAB> if self.header is not None: <TAB> <TAB> if isinstance(self.header, RenderedContent): <TAB> <TAB> <TAB> d[""header""] = self.header.to_json_dict() <TAB> <TAB> else: <TAB> <TAB> <TAB> d[""header""] = self.header <TAB> if self.subheader is not None: <TAB> <TAB> if isinstance(self.subheader, RenderedContent): <TAB> <TAB> <TAB> d[""subheader""] = self.subheader.to_json_dict() <TAB> <TAB> else: <TAB> <TAB> <TAB> d[""subheader""] = self.subheader <TAB> return d",false,"if isinstance ( self . subheader , RenderedContent ) :","if isinstance ( self . header , RenderedContent ) :",0.58,0.0
"def add(request): <TAB> form_type = ""servers"" <TAB> if request.method == ""POST"": <TAB> <TAB> form = BookMarkForm(request.POST) <TAB> <TAB> if form.is_valid(): <TAB> <TAB> <TAB> form_type = form.save() <TAB> <TAB> <TAB> messages.add_message(request, messages.INFO, ""Bookmark created"") <TAB> <TAB> else: <TAB> <TAB> <TAB> messages.add_message(request, messages.INFO, form.errors) <TAB> <TAB> if form_type == ""server"": <TAB> <TAB> <TAB> url = reverse(""servers"") <TAB> <TAB> else: <TAB> <TAB> <TAB> url = reverse(""metrics"") <TAB> <TAB> return redirect(url) <TAB> else: <TAB> <TAB> return redirect(reverse(""servers""))",true,if form . is_valid ( ) :,if form . is_valid ( ) :,0.75,0.0
"def fee_amount_in_quote(self, trading_pair: str, price: Decimal, order_amount: Decimal): <TAB> fee_amount = Decimal(""0"") <TAB> if self.percent > 0: <TAB> <TAB> fee_amount = (price * order_amount) * self.percent <TAB> base, quote = trading_pair.split(""-"") <TAB> for flat_fee in self.flat_fees: <TAB> <TAB> if interchangeable(flat_fee[0], base): <TAB> <TAB> <TAB> fee_amount += flat_fee[1] * price <TAB> <TAB> elif interchangeable(flat_fee[0], quote): <TAB> <TAB> <TAB> fee_amount += flat_fee[1] <TAB> return fee_amount",false,"elif interchangeable ( flat_fee [ 0 ] , quote ) :","if interchangeable ( flat_fee [ 0 ] , base ) :",0.35,0.0
"def load_batch(fpath): <TAB> with open(fpath, ""rb"") as f: <TAB> <TAB> if sys.version_info > (3, 0): <TAB> <TAB> <TAB> # Python3 <TAB> <TAB> <TAB> d = pickle.load(f, encoding=""latin1"") <TAB> <TAB> else: <TAB> <TAB> <TAB> # Python2 <TAB> <TAB> <TAB> d = pickle.load(f) <TAB> data = d[""data""] <TAB> labels = d[""labels""] <TAB> return data, labels",true,"if sys . version_info > ( 3 , 0 ) :","if sys . version_info > ( 3 , 0 ) :",0.75,0.0
"def clear_entries(options): <TAB> """"""Clear pending entries"""""" <TAB> with Session() as session: <TAB> <TAB> query = session.query(db.PendingEntry).filter(db.PendingEntry.approved == False) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> query = query.filter(db.PendingEntry.task_name == options.task_name) <TAB> <TAB> deleted = query.delete() <TAB> <TAB> console(""Successfully deleted %i pending entries"" % deleted)",true,if options . task_name :,if options . task_name :,0.75,0.0
"def attribute_table(self, attribute): <TAB> """"""Return a tuple (schema, table) for attribute."""""" <TAB> dimension = attribute.dimension <TAB> if dimension: <TAB> <TAB> schema = self.naming.dimension_schema or self.naming.schema <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> table = self.fact_name <TAB> <TAB> else: <TAB> <TAB> <TAB> table = self.naming.dimension_table_name(dimension) <TAB> else: <TAB> <TAB> table = self.fact_name <TAB> <TAB> schema = self.naming.schema <TAB> return (schema, table)",false,if dimension . is_flat and not dimension . has_details :,if schema :,0.05,0.0
"def remove_rating(self, songs, librarian): <TAB> count = len(songs) <TAB> if count > 1 and config.getboolean(""browsers"", ""rating_confirm_multiple""): <TAB> <TAB> parent = qltk.get_menu_item_top_parent(self) <TAB> <TAB> dialog = ConfirmRateMultipleDialog(parent, _(""_Remove Rating""), count, None) <TAB> <TAB> if dialog.run() != Gtk.ResponseType.YES: <TAB> <TAB> <TAB> return <TAB> reset = [] <TAB> for song in songs: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> del song[""~#rating""] <TAB> <TAB> <TAB> reset.append(song) <TAB> librarian.changed(reset)",false,"if ""~#rating"" in song :","if ""#rating"" in song :",0.39,0.0
"def find_word_bounds(self, text, index, allowed_chars): <TAB> right = left = index <TAB> done = False <TAB> while not done: <TAB> <TAB> if left == 0: <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self.word_boundary_char(text[left - 1]): <TAB> <TAB> <TAB> left -= 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> done = True <TAB> done = False <TAB> while not done: <TAB> <TAB> if right == len(text): <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self.word_boundary_char(text[right]): <TAB> <TAB> <TAB> right += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> done = True <TAB> return left, right",false,elif not self . word_boundary_char ( text [ right ] ) :,elif not self . word_boundary_char ( text [ right - 1 ] ) :,0.45,0.0
"def handle_read(self): <TAB> """"""Called when there is data waiting to be read."""""" <TAB> try: <TAB> <TAB> chunk = self.recv(self.ac_in_buffer_size) <TAB> except RetryError: <TAB> <TAB> pass <TAB> except socket.error: <TAB> <TAB> self.handle_error() <TAB> else: <TAB> <TAB> self.tot_bytes_received += len(chunk) <TAB> <TAB> if not chunk: <TAB> <TAB> <TAB> self.transfer_finished = True <TAB> <TAB> <TAB> # self.close()  # <-- asyncore.recv() already do that... <TAB> <TAB> <TAB> return <TAB> <TAB> if self._data_wrapper is not None: <TAB> <TAB> <TAB> chunk = self._data_wrapper(chunk) <TAB> <TAB> try: <TAB> <TAB> <TAB> self.file_obj.write(chunk) <TAB> <TAB> except OSError as err: <TAB> <TAB> <TAB> raise _FileReadWriteError(err)",true,if self . _data_wrapper is not None :,if self . _data_wrapper is not None :,0.75,0.0
"def toggle(self, event=None): <TAB> if self.absolute: <TAB> <TAB> if self.save == self.split: <TAB> <TAB> <TAB> self.save = 100 <TAB> <TAB> if self.split > 20: <TAB> <TAB> <TAB> self.save = self.split <TAB> <TAB> <TAB> self.split = 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> self.split = self.save <TAB> else: <TAB> <TAB> if self.save == self.split: <TAB> <TAB> <TAB> self.save = 0.3 <TAB> <TAB> if self.split <= self.min or self.split >= self.max: <TAB> <TAB> <TAB> self.split = self.save <TAB> <TAB> elif self.split < 0.5: <TAB> <TAB> <TAB> self.split = self.min <TAB> <TAB> else: <TAB> <TAB> <TAB> self.split = self.max <TAB> self.placeChilds()",true,elif self . split < 0.5 :,elif self . split < 0.5 :,0.75,0.0
"def readAtOffset(self, offset, size, shortok=False): <TAB> ret = b"""" <TAB> self.fd.seek(offset) <TAB> while len(ret) != size: <TAB> <TAB> rlen = size - len(ret) <TAB> <TAB> x = self.fd.read(rlen) <TAB> <TAB> if x == b"""": <TAB> <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> return ret <TAB> <TAB> ret += x <TAB> return ret",false,if not shortok :,if shortok :,0.1,0.0
"def webfinger(environ, start_response, _): <TAB> query = parse_qs(environ[""QUERY_STRING""]) <TAB> try: <TAB> <TAB> rel = query[""rel""] <TAB> <TAB> resource = query[""resource""][0] <TAB> except KeyError: <TAB> <TAB> resp = BadRequest(""Missing parameter in request"") <TAB> else: <TAB> <TAB> if rel != [OIC_ISSUER]: <TAB> <TAB> <TAB> resp = BadRequest(""Bad issuer in request"") <TAB> <TAB> else: <TAB> <TAB> <TAB> wf = WebFinger() <TAB> <TAB> <TAB> resp = Response(wf.response(subject=resource, base=OAS.baseurl)) <TAB> return resp(environ, start_response)",true,if rel != [ OIC_ISSUER ] :,if rel != [ OIC_ISSUER ] :,0.75,0.0
"def _tokenize(self, text): <TAB> if format_text(text) == EMPTY_TEXT: <TAB> <TAB> return [self.additional_special_tokens[0]] <TAB> split_tokens = [] <TAB> if self.do_basic_tokenize: <TAB> <TAB> for token in self.basic_tokenizer.tokenize( <TAB> <TAB> <TAB> text, never_split=self.all_special_tokens <TAB> <TAB> ): <TAB> <TAB> <TAB> # If the token is part of the never_split set <TAB> <TAB> <TAB> if token in self.basic_tokenizer.never_split: <TAB> <TAB> <TAB> <TAB> split_tokens.append(token) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> split_tokens += self.wordpiece_tokenizer.tokenize(token) <TAB> else: <TAB> <TAB> split_tokens = self.wordpiece_tokenizer.tokenize(text) <TAB> return split_tokens",true,if token in self . basic_tokenizer . never_split :,if token in self . basic_tokenizer . never_split :,0.75,0.0
"def send_packed_command(self, command, check_health=True): <TAB> if not self._sock: <TAB> <TAB> self.connect() <TAB> try: <TAB> <TAB> if isinstance(command, str): <TAB> <TAB> <TAB> command = [command] <TAB> <TAB> for item in command: <TAB> <TAB> <TAB> self._sock.sendall(item) <TAB> except socket.error as e: <TAB> <TAB> self.disconnect() <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> _errno, errmsg = ""UNKNOWN"", e.args[0] <TAB> <TAB> else: <TAB> <TAB> <TAB> _errno, errmsg = e.args <TAB> <TAB> raise ConnectionError( <TAB> <TAB> <TAB> ""Error %s while writing to socket. %s."" % (_errno, errmsg) <TAB> <TAB> ) <TAB> except Exception: <TAB> <TAB> self.disconnect() <TAB> <TAB> raise",false,if len ( e . args ) == 1 :,if check_health :,0.01,0.0
"def to_value(self, value): <TAB> # Tip: 'value' is the object returned by <TAB> # <TAB>  taiga.projects.history.models.HistoryEntry.values_diff() <TAB> ret = {} <TAB> for key, val in value.items(): <TAB> <TAB> if key in [""attachments"", ""custom_attributes"", ""description_diff""]: <TAB> <TAB> <TAB> ret[key] = val <TAB> <TAB> elif key == ""points"": <TAB> <TAB> <TAB> ret[key] = {k: {""from"": v[0], ""to"": v[1]} for k, v in val.items()} <TAB> <TAB> else: <TAB> <TAB> <TAB> ret[key] = {""from"": val[0], ""to"": val[1]} <TAB> return ret",true,"elif key == ""points"" :","elif key == ""points"" :",1.0,0.0
"def to_child(cls, key=None, process=None): <TAB> if process is not None: <TAB> <TAB> if type(process) is not dict: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> 'Invalid value provided for ""process"" parameter, expected a dictionary' <TAB> <TAB> <TAB> ) <TAB> <TAB> if cls.__process__: <TAB> <TAB> <TAB> # Merge class `__process__` parameters with provided parameters <TAB> <TAB> <TAB> result = {} <TAB> <TAB> <TAB> result.update(deepcopy(cls.__process__)) <TAB> <TAB> <TAB> result.update(process) <TAB> <TAB> <TAB> process = result <TAB> class Child(cls): <TAB> <TAB> __key__ = key <TAB> <TAB> __process__ = process <TAB> <TAB> __root__ = False <TAB> Child.__name__ = cls.__name__ <TAB> return Child",true,if cls . __process__ :,if cls . __process__ :,0.75,0.0
"def _super_function(args): <TAB> passed_class, passed_self = args.get_arguments([""type"", ""self""]) <TAB> if passed_self is None: <TAB> <TAB> return passed_class <TAB> else: <TAB> <TAB> # pyclass = passed_self.get_type() <TAB> <TAB> pyclass = passed_class <TAB> <TAB> if isinstance(pyclass, pyobjects.AbstractClass): <TAB> <TAB> <TAB> supers = pyclass.get_superclasses() <TAB> <TAB> <TAB> if supers: <TAB> <TAB> <TAB> <TAB> return pyobjects.PyObject(supers[0]) <TAB> <TAB> return passed_self",true,"if isinstance ( pyclass , pyobjects . AbstractClass ) :","if isinstance ( pyclass , pyobjects . AbstractClass ) :",0.75,0.0
"def get_data(row): <TAB> data = [] <TAB> for field_name, field_xpath in fields: <TAB> <TAB> result = row.xpath(field_xpath) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> result = "" "".join( <TAB> <TAB> <TAB> <TAB> text <TAB> <TAB> <TAB> <TAB> for text in map( <TAB> <TAB> <TAB> <TAB> <TAB> six.text_type.strip, map(six.text_type, map(unescape, result)) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> if text <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> result = None <TAB> <TAB> data.append(result) <TAB> return data",true,if result :,if result :,0.53,0.0
"def say(jarvis, s): <TAB> """"""Reads what is typed."""""" <TAB> if not s: <TAB> <TAB> jarvis.say(""What should I say?"") <TAB> else: <TAB> <TAB> voice_state = jarvis.is_voice_enabled() <TAB> <TAB> jarvis.enable_voice() <TAB> <TAB> jarvis.say(s) <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> jarvis.disable_voice()",false,if not voice_state :,if voice_state :,0.1,0.0
"def __import__(name, globals=None, locals=None, fromlist=(), level=0): <TAB> module = orig___import__(name, globals, locals, fromlist, level) <TAB> if fromlist and module.__name__ in modules: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> fromlist = list(fromlist) <TAB> <TAB> <TAB> fromlist.remove(""*"") <TAB> <TAB> <TAB> fromlist.extend(getattr(module, ""__all__"", [])) <TAB> <TAB> for x in fromlist: <TAB> <TAB> <TAB> if isinstance(getattr(module, x, None), types.ModuleType): <TAB> <TAB> <TAB> <TAB> from_name = ""{}.{}"".format(module.__name__, x) <TAB> <TAB> <TAB> <TAB> if from_name in modules: <TAB> <TAB> <TAB> <TAB> <TAB> importlib.import_module(from_name) <TAB> return module",true,"if ""*"" in fromlist :","if ""*"" in fromlist :",0.75,0.0
"def _read_pricing_file(self, region=None, pricing_file=None): <TAB> if not self.__pricing_file_cache: <TAB> <TAB><IF-STMT> <TAB> <TAB> <TAB> logging.info(""Reading pricing file..."") <TAB> <TAB> <TAB> with open(pricing_file) as data_file: <TAB> <TAB> <TAB> <TAB> self.__pricing_file_cache = json.load(data_file) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.__pricing_file_cache = self._download_pricing_file(region) <TAB> return self.__pricing_file_cache",true,if pricing_file :,if pricing_file :,0.53,0.0
